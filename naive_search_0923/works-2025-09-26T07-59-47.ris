TY  - JOUR
TI  - Haptic-enabled collaborative learning in virtual reality for schools
PY  - 2021
PB  - Springer Science+Business Media
SN  - 1360-2357
T2  - Education and Information Technologies
DO  - 10.1007/s10639-021-10639-4
UR  - https://doi.org/10.1007/s10639-021-10639-4
DA  - 2021-07-02
AU  - Webb, Mary
C1  - School of Education, Communication and Society, King's College London, Franklin-Wilkins Building - Waterloo Bridge Wing, Waterloo Rd., London, SE1 9NN, UK
AU  - Tracey, Megan
C1  - School of Education, Communication and Society, King's College London, Franklin-Wilkins Building - Waterloo Bridge Wing, Waterloo Rd., London, SE1 9NN, UK
AU  - Harwin, William
C1  - School of Biological Sciences, University of Reading, Reading, UK
AU  - Tokatlı, Ozan
C1  - School of Biological Sciences, University of Reading, Reading, UK
AU  - Hwang, Faustina
C1  - School of Biological Sciences, University of Reading, Reading, UK
AU  - Johnson, Ros
C1  - The Abbey, Reading, UK
AU  - Barrett, Natasha
C1  - School of Biological Sciences, University of Reading, Reading, UK
AU  - Jones, Chris
C1  - School of Biological Sciences, University of Reading, Reading, UK
LA  - en
KW  - Headset
KW  - Interface (matter)
KW  - Immersion
VL  - 27
IS  - 1
SP  - 937
EP  - 960
AB  - Abstract This paper reports on a study which designed and developed a multi-fingered haptic interface in conjunction with a three-dimensional (3D) virtual model of a section of the cell membrane in order to enable students to work collaboratively to learn cell biology. Furthermore, the study investigated whether the addition of haptic feedback to the 3D virtual reality (VR) simulation affected learning of key concepts in nanoscale cell biology for students aged 12 to 13. The haptic interface was designed so that the haptic feedback could be turned on or switched off. Students (N = 64), in two secondary schools, worked in pairs, on activities designed to support learning of specific difficult concepts. Findings from observation of the activities and interviews revealed that students believed that being immersed in the 3D VR environment and being able to feel structures and movements within the model and work collaboratively assisted their learning. More specifically, the pilot/co-pilot model that we developed was successful for enabling collaborative learning and reducing the isolating effects of immersion with a 3D headset. Results of pre and post-tests of conceptual knowledge showed significant knowledge gains but addition of haptic feedback did not affect the knowledge gains significantly. The study enabled identification of important issues to consider when designing and using haptic-enabled 3D VR environments for collaborative learning.
ER  -
TY  - JOUR
TI  - Experiments for a Collaborative Haptic Virtual Reality
PY  - 2006
DO  - 10.1109/icat.2006.60
UR  - https://doi.org/10.1109/icat.2006.60
DA  - 2006-01-01
AU  - Sung, Mee
C1  - Department of Computer Science & Engineering, University of Incheon, Incheon, South Korea
AU  - Yoo, Yonghee
C1  - Department of Computer Science & Engineering, University of Incheon, Incheon, South Korea
AU  - Jun, Kyungkoo
C1  - Department of Multimedia Systems Engineering, University of Incheon, Incheon, South Korea
AU  - Kim, Nam-joong
C1  - Department of Computer Science & Engineering, University of Incheon, Incheon, South Korea
AU  - Chae, Jinseok
C1  - Department of Computer Science & Engineering, University of Incheon, Incheon, South Korea
LA  - en
KW  - Teleoperation
SP  - 174
EP  - 179
ER  -
TY  - JOUR
TI  - A Collaborative Virtual Reality Escape Room with Passive Haptics
PY  - 2019
T2  - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)
DO  - 10.1109/vr.2019.8798241
UR  - https://doi.org/10.1109/vr.2019.8798241
DA  - 2019-03-01
AU  - Hanus, Austin
C1  - Iowa State University
AU  - Hoover, Melynda
C1  - Iowa State University
AU  - Lim, Alex
C1  - Iowa State University
AU  - Miller, Jack
C1  - Iowa State University
LA  - en
AB  - Escape rooms have recently become a popular way to socialize and problem solve in an immersive environment. However, it can be difficult and expensive to create elaborate escape rooms with realistic props. Virtual reality (VR) technology allows developers to create and customize escape rooms more easily. However, to truly make the VR escape room immersive, physical and cooperative interactions are necessary. In this paper, the authors propose and demonstrate a two-player VR escape room developed for the HTC Vive. Physical interactions were made possible by using passive haptics in the form of simple props tracked using HTC Vive trackers and controllers. Additionally, the HTC Vives were networked, and players hands were tracked using the Leap Motion to provide head and hand position cues to teammates.
ER  -
TY  - JOUR
TI  - Robotic Haptic Proxies for Collaborative Virtual Reality
PY  - 2017
PB  - Cornell University
T2  - arXiv (Cornell University)
DO  - 10.48550/arxiv.1701.08879
UR  - https://doi.org/10.48550/arxiv.1701.08879
DA  - 2017-01-01
AU  - He, Zhenyi
AU  - Zhu, Fengyuan
AU  - Gaudette, Aaron
AU  - Perlin, Ken
LA  - en
AB  - We propose a new approach for interaction in Virtual Reality (VR) using mobile robots as proxies for haptic feedback. This approach allows VR users to have the experience of sharing and manipulating tangible physical objects with remote collaborators. Because participants do not directly observe the robotic proxies, the mapping between them and the virtual objects is not required to be direct. In this paper, we describe our implementation, various scenarios for interaction, and a preliminary user study.
ER  -
TY  - JOUR
TI  - Study of co-located and distant collaboration with symbolic support via a haptics-enhanced virtual reality task
PY  - 2012
PB  - Taylor & Francis
SN  - 1049-4820
T2  - Interactive Learning Environments
DO  - 10.1080/10494820.2012.705854
UR  - https://doi.org/10.1080/10494820.2012.705854
DA  - 2012-07-30
AU  - Yeh, Shih‐Ching
C1  - Department of Computer Science and Information , National Central University , No. 300, Jhongda Rd, Jhongli City, Taoyuan County , Taiwan , 32001 , Republic of China
AU  - Hwang, Wu‐Yuin
C1  - Institute of Network Learning Technology, National Central University , No. 300, Jhongda Rd, Jhongli City, Taoyuan County , Taiwan , 32001 , Republic of China
AU  - Wang, Jin-Liang
C1  - Department of Computer Science and Information , National Central University , No. 300, Jhongda Rd, Jhongli City, Taoyuan County , Taiwan , 32001 , Republic of China
AU  - Zhan, Shi-Yi
C1  - Institute of Network Learning Technology, National Central University , No. 300, Jhongda Rd, Jhongli City, Taoyuan County , Taiwan , 32001 , Republic of China
LA  - en
VL  - 21
IS  - 2
SP  - 184
EP  - 198
ER  -
TY  - JOUR
TI  - INC-Hg: An Intelligent Collaborative Haptic-Gripper Virtual Reality System
PY  - 2022
PB  - Association for Computing Machinery
SN  - 1936-7236
T2  - ACM Transactions on Accessible Computing
DO  - 10.1145/3487606
UR  - https://doi.org/10.1145/3487606
DA  - 2022-03-04
AU  - Zhao, Huan
C1  - Treatment and Research Institute for Autism Spectrum Disorders, Vanderbilt University, Nashville, Tennessee
AU  - Amat, Ashwaq
C1  - Treatment and Research Institute for Autism Spectrum Disorders, Vanderbilt University, Nashville, Tennessee Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, Tennessee
AU  - Migovich, Miroslava
C1  - Treatment and Research Institute for Autism Spectrum Disorders, Vanderbilt University, Nashville, Tennessee Department of Mechanical Engineering, Vanderbilt University, Nashville, Tennessee
AU  - Swanson, Amy
C1  - Treatment and Research Institute for Autism Spectrum Disorders, Vanderbilt University, Nashville, Tennessee
AU  - Weitlauf, Amy
C1  - Treatment and Research Institute for Autism Spectrum Disorders, Vanderbilt University, Nashville, Tennessee
AU  - Warren, Zachary
C1  - Treatment and Research Institute for Autism Spectrum Disorders, Vanderbilt University, Nashville, Tennessee
AU  - Sarkar, Nilanjan
C1  - Department of Mechanical Engineering, Vanderbilt University, Nashville, Tennessee
LA  - en
KW  - Pace
VL  - 15
IS  - 1
SP  - 1
EP  - 23
ER  -
TY  - JOUR
TI  - A Haptic-enabled, Distributed and Networked Immersive System for Multi-User Collaborative Virtual Reality
PY  - 2023
DO  - 10.1145/3607546.3616804
UR  - https://doi.org/10.1145/3607546.3616804
DA  - 2023-10-18
AU  - Van Damme, Sam
C1  - Ghent University - imec &amp; KU Leuven, Ghent &amp; Leuven, Belgium
AU  - Van De Velde, F.
C1  - Ghent University - imec, Ghent, Belgium
AU  - Sameri, Javad
C1  - Ghent University - imec, Ghent, Belgium
AU  - De Turck, Filip
C1  - Ghent University - imec, Ghent, Belgium
AU  - Vega, Maria
C1  - Ghent University - imec &amp; KU Leuven, Ghent &amp; Leuven, Belgium
LA  - en
SP  - 11
EP  - 19
AB  - Virtual Reality (VR) is gaining attention in various domains such as entertainment, industry, mental healthcare and VR training. Al- though most of these use-cases are still limited to single-user tasks, a lot of applications are heavily depending on multi-user collaboration. Existing multi-user VR systems are most often created in a classic server-client architecture, however, which induces unpredictable network behaviour which can affect the end-user's Quality-of-Experience (QoE) and performance. In addition, the interaction methods in these systems are often constrained to either traditional VR controllers or very use-case specific interaction methods, such that general purpose haptic gloves form a somewhat under-explored part of literature. Therefore, we (i) present a networked, distributed multi-user VR system with synchronization of environments over a low-bandwidth networked connection. In addition, we (ii) enhance the experience by adding haptic gloves to the system, which we compare to the traditional VR controllers in a subjective experiment. As a proof-of-concept, a use case is implemented in which two users have to prepare and bake a virtual pizza. The results show that high framerates (> 90 Frames Per Second (FPS)) can be obtained while keeping network throughput to a minimum ( < 1 Mbps). The accompanying user study shows that haptic gloves are preferred when immersiveness is the main emphasis of the virtual environment, while controllers are more suited when performance is in the center of attention. In objective terms, the applicability of haptic feedback is highly dependent on the task at hand.
ER  -
TY  - JOUR
TI  - Evaluation of New Collaboration method in Virtual Reality Game based on Human Haptic Emotion for Artificial Life Simulation
PY  - 2008
DO  - 10.5176/978-981-08-8227-3_cgat08-55
UR  - https://doi.org/10.5176/978-981-08-8227-3_cgat08-55
DA  - 2008-04-28
AU  - Basori, Ahmad
AU  - Daman, Daut
AU  - Bade, Abdullah
AU  - Sunar, Mohd
LA  - en
KW  - Artificial life
ER  -
TY  - JOUR
TI  - Improved interaction with collaborative robots - evaluation of event-specific haptic feedback in virtual reality
PY  - 2024
PB  - Elsevier BV
SN  - 1877-0509
T2  - Procedia Computer Science
DO  - 10.1016/j.procs.2024.01.104
UR  - https://doi.org/10.1016/j.procs.2024.01.104
DA  - 2024-01-01
AU  - Andersson, My
C1  - University of Skövde, Högskolevägen 3, Skövde, 541 45, Sweden
AU  - Syberfeldt, Anna
C1  - University of Skövde, Högskolevägen 3, Skövde, 541 45, Sweden
LA  - en
VL  - 232
SP  - 1055
EP  - 1064
AB  - Industry 5.0 adopts a human-centric approach that views humans as a natural part of introducing new technology, such as collaborative robots. However, one of the main challenges in implementing collaborative robots is safety, including the sense of safety. Trust is also a primary challenge when establishing functional collaboration. Influencing factors includes experience and expertise, and research shows that Virtual Reality has the potential to perform such training. This research aims to investigate whether using virtual reality with appropriate feedback can be an effective platform for familiarization and training. In our experiment, we utilized haptic feedback from commercial Virtual Reality controllers to simulate physical interactions with collaborative robots. The experiment involved the participation of fifteen individuals. The results showed that participants regarded haptic feedback while moving as the most appropriate representation. This research aims to identify whether Virtual Reality with suitable feedback can serve as a familiarization and training platform.
ER  -
TY  - JOUR
TI  - Integration of haptic virtual reality simulators in undergraduate dental curricula: A survey-based study in Gulf Cooperation Council countries
PY  - 2025
PB  - Public Library of Science
SN  - 1932-6203
T2  - PLoS ONE
DO  - 10.1371/journal.pone.0322810
UR  - https://doi.org/10.1371/journal.pone.0322810
DA  - 2025-05-28
AU  - Matoug‐Elwerfelli, Manal
C1  - Department of Pre-Clinical Oral Sciences, College of Dental Medicine, QU Health, Qatar University, Doha, Qatar.
AU  - Alkhabuli, Juma
C1  - Department of Pre-Clinical Oral Sciences, College of Dental Medicine, QU Health, Qatar University, Doha, Qatar.
AU  - Alhobeira, Hazza
C1  - Department of Restorative Dentistry, College of Dentistry, University of Hail, Hail, Kingdom of Saudi Arabia.
AU  - Daas, Hanin
C1  - Department of Pre-Clinical Oral Sciences, College of Dental Medicine, QU Health, Qatar University, Doha, Qatar.
AU  - Abdou, Ahmed
C1  - Department of Restorative Dentistry, Faculty of Dentistry, University of Malaya, Kuala Lumpur, Malaysia.
AU  - Ali, Kamran
C1  - Department of Pre-Clinical Oral Sciences, College of Dental Medicine, QU Health, Qatar University, Doha, Qatar.
LA  - en
KW  - Dental technician
KW  - Dental education
VL  - 20
IS  - 5
SP  - e0322810
EP  - e0322810
AB  - Background The integration of haptic simulators in contemporary dental education has been reported to improve students’ hand-eye coordination and fine motor skills during pre-clinical education to facilitate a smooth transition to the clinical setting. The aim of this study was to assess the integration of haptic virtual reality simulation (HVRS) in undergraduate dental curricula in the Gulf Cooperation Council countries. Methods All dental schools offering undergraduate dental programs in the Gulf Cooperation Council countries were invited to participate in this cross-sectional study design. Data was collected using an online survey on a voluntary basis and analyzed using Microsoft Excel. Results Out of 34 dental schools, responses were received from 30 dental schools (response rate 88.2%). In terms of haptic integration, only two (6.7%) dental institutions have adopted haptic simulation in undergraduate dental education. However, a considerable proportion of schools (n = 13, 46.4%) expressed an interest in the future use of haptic technology. The key strengths of HRVS included the integration of modern technology, opportunities for self-directed learning, development and consolidation of manual skills, and boosting self-confidence amongst undergraduate dental students. Financial cost and limited patient cases in the HRVS library were regarded as the main barriers to widespread use of this technology. Conclusion Although the Gulf Cooperation Council countries have strong economies with a high gross domestic product (GDP), only a limited number of dental schools have incorporated haptic technology in their curricula. Nevertheless, a high proportion of dental schools in the region are actively considering purchasing and implementation of haptic devices in undergraduate dental programs.
ER  -
TY  - JOUR
TI  - Virtual and Augmented Reality on the 5G Highway
PY  - 2017
SN  - 1882-6652
T2  - Journal of Information Processing
DO  - 10.2197/ipsjjip.25.133
UR  - https://doi.org/10.2197/ipsjjip.25.133
DA  - 2017-01-01
AU  - Orlosky, Jason
C1  - Cybermedia Center, Osaka University
AU  - Kiyokawa, Kiyoshi
C1  - Cybermedia Center, Osaka University
AU  - Takemura, Haruo
C1  - Cybermedia Center, Osaka University
LA  - en
VL  - 25
IS  - 0
SP  - 133
EP  - 141
AB  - In recent years, virtual and augmented reality have begun to take advantage of the high speed capabilities of data streaming technologies and wireless networks. However, limitations like bandwidth and latency still prevent us from achieving high fidelity telepresence and collaborative virtual and augmented reality applications. Fortunately, both researchers and engineers are aware of these problems and have set out to design 5G networks to help us to move to the next generation of virtual interfaces. This paper reviews state of the art virtual and augmented reality communications technology and outlines current efforts to design an effective, ubiquitous 5G network to help to adapt to virtual application demands. We discuss application needs in domains like telepresence, education, healthcare, streaming media, and haptics, and provide guidelines and future directions for growth based on this new network infrastructure.
ER  -
TY  - JOUR
TI  - Augmented Reality for Robotics: A Review
PY  - 2020
PB  - Multidisciplinary Digital Publishing Institute
SN  - 2218-6581
T2  - Robotics
DO  - 10.3390/robotics9020021
UR  - https://doi.org/10.3390/robotics9020021
DA  - 2020-04-02
AU  - Makhataeva, Zhanat
C1  - Department of Robotics, Nazarbayev University, Nur-Sultan City Z05H0P9, Kazakhstan
AU  - Varol, Hüseyin
C1  - Department of Robotics, Nazarbayev University, Nur-Sultan City Z05H0P9, Kazakhstan
LA  - en
KW  - Teleoperation
KW  - Work space
KW  - Rehabilitation robotics
VL  - 9
IS  - 2
SP  - 21
EP  - 21
AB  - Augmented reality (AR) is used to enhance the perception of the real world by integrating virtual objects to an image sequence acquired from various camera technologies. Numerous AR applications in robotics have been developed in recent years. The aim of this paper is to provide an overview of AR research in robotics during the five year period from 2015 to 2019. We classified these works in terms of application areas into four categories: (1) Medical robotics: Robot-Assisted surgery (RAS), prosthetics, rehabilitation, and training systems; (2) Motion planning and control: trajectory generation, robot programming, simulation, and manipulation; (3) Human-robot interaction (HRI): teleoperation, collaborative interfaces, wearable robots, haptic interfaces, brain-computer interfaces (BCIs), and gaming; (4) Multi-agent systems: use of visual feedback to remotely control drones, robot swarms, and robots with shared workspace. Recent developments in AR technology are discussed followed by the challenges met in AR due to issues of camera localization, environment mapping, and registration. We explore AR applications in terms of how AR was integrated and which improvements it introduced to corresponding fields of robotics. In addition, we summarize the major limitations of the presented applications in each category. Finally, we conclude our review with future directions of AR research in robotics. The survey covers over 100 research works published over the last five years.
ER  -
TY  - JOUR
TI  - Haptic Feedback Helps Me? A VR-SAR Remote Collaborative System with Tangible Interaction
PY  - 2020
PB  - Taylor & Francis
SN  - 1044-7318
T2  - International Journal of Human-Computer Interaction
DO  - 10.1080/10447318.2020.1732140
UR  - https://doi.org/10.1080/10447318.2020.1732140
DA  - 2020-03-02
AU  - Wang, Peng
C1  - Cyber-Physical Interaction Lab, Northwestern Polytechnical University, Xi'an, China
AU  - Bai, Xiaoliang
C1  - Cyber-Physical Interaction Lab, Northwestern Polytechnical University, Xi'an, China
AU  - Billinghurst, Mark
C1  - Cyber-Physical Interaction Lab, Northwestern Polytechnical University, Xi'an, China
C1  - Empathic Computing Lab, University of South Australia, Mawson Lakes, Australia
AU  - Zhang, Shusheng
C1  - Cyber-Physical Interaction Lab, Northwestern Polytechnical University, Xi'an, China
AU  - Han, Dechuan
C1  - Cyber-Physical Interaction Lab, Northwestern Polytechnical University, Xi'an, China
AU  - Sun, Mengmeng
C1  - Cyber-Physical Interaction Lab, Northwestern Polytechnical University, Xi'an, China
AU  - Wang, Zhuo
C1  - Cyber-Physical Interaction Lab, Northwestern Polytechnical University, Xi'an, China
AU  - Lv, Hao
C1  - Cyber-Physical Interaction Lab, Northwestern Polytechnical University, Xi'an, China
AU  - Han, Shu
C1  - Cyber-Physical Interaction Lab, Northwestern Polytechnical University, Xi'an, China
LA  - en
KW  - Interface (matter)
VL  - 36
IS  - 13
SP  - 1242
EP  - 1257
ER  -
TY  - JOUR
TI  - Simulation in Neurosurgery: A Review of Computer-Based Simulation Environments and Their Surgical Applications
PY  - 2010
PB  - Lippincott Williams & Wilkins
SN  - 0148-396X
T2  - Neurosurgery
DO  - 10.1227/neu.0b013e3181ee46d0
UR  - https://doi.org/10.1227/neu.0b013e3181ee46d0
DA  - 2010-09-28
AU  - Malone, Hani
C1  - Department of Neurosurgery, Columbia University Medical Center, New York, New York, USA.
AU  - Syed, Omar
C1  - Department of Neurosurgery, Columbia University Medical Center, New York, New York.
AU  - Downes, Michael
C1  - Department of Neurosurgery, Columbia University Medical Center, New York, New York.
AU  - D’Ambrosio, Anthony
C1  - Department of Neurosurgery, Columbia University Medical Center, New York, New York.
AU  - Quest, Donald
C1  - Department of Neurosurgery, Columbia University Medical Center, New York, New York.
AU  - Kaiser, Michael
C1  - Department of Neurosurgery, Columbia University Medical Center, New York, New York.
LA  - en
KW  - Surgical simulation
KW  - Surgical Planning
VL  - 67
IS  - 4
SP  - 1105
EP  - 1116
ER  -
TY  - JOUR
TI  - NeuroTouch
PY  - 2012
PB  - Lippincott Williams & Wilkins
SN  - 2332-4252
T2  - Operative Neurosurgery
DO  - 10.1227/neu.0b013e318249c744
UR  - https://doi.org/10.1227/neu.0b013e318249c744
DA  - 2012-01-10
AU  - Delorme, Stefan
C1  - National Research Council Canada, Boucherville, Quebec, Canada
C1  - Sébastien Delorme, PhD, National Research Council Canada, 75 de Mortagne Blvd., Boucherville, QC, Canada J4B 6Y4. E-mail: [email protected]
AU  - Laroche, Denis
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - DiRaddo, Robert
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Del Maestro, Rolando
C1  - Brain Tumour Research Centre, Department of Neurosurgery and Neurology, Montreal Neurological Institute and Hospital, Montreal, Quebec, Canada
LA  - en
KW  - Aspirator
KW  - Debulking
VL  - 71
SP  - ons32
EP  - ons42
ER  -
TY  - JOUR
TI  - Exploring the synergies between collaborative robotics, digital twins, augmentation, and industry 5.0 for smart manufacturing: A state-of-the-art review
PY  - 2024
PB  - Elsevier BV
SN  - 0736-5845
T2  - Robotics and Computer-Integrated Manufacturing
DO  - 10.1016/j.rcim.2024.102769
UR  - https://doi.org/10.1016/j.rcim.2024.102769
DA  - 2024-04-06
AU  - Zafar, Muhammad
C1  - Department of Engineering Sciences, University of Agder, Grimstad, 4879, Norway
AU  - Langås, Even
C1  - Department of Engineering Sciences, University of Agder, Grimstad, 4879, Norway
AU  - Sanfilippo, Filippo
C1  - Department of Engineering Sciences, University of Agder, Grimstad, 4879, Norway
C1  - Department of Software Engineering, Kaunas University of Technology, Kaunas, 51368, Lithuania
LA  - en
KW  - Industry 4.0
KW  - Manufacturing
KW  - Component (thermodynamics)
VL  - 89
SP  - 102769
EP  - 102769
AB  - Industry 5.0 aims at establishing an inclusive, smart and sustainable production process that encourages human creativity and expertise by leveraging enhanced automation and machine intelligence. Collaborative robotics, or "cobotics",is a major enabling technology of Industry 5.0, which aspires at improving human dexterity by elevating robots to extensions of human capabilities and, ultimately, even as team members. A pivotal element that has the potential to operate as an interface for the teaming aspiration of Industry 5.0 is the adoption of novel technologies such as virtual reality (VR), augmented reality (AR), mixed reality (MR) and haptics, together known as "augmentation". Industry 5.0 also benefit from Digital Twins (DTs), which are digital representations of a physical assets that serves as their counterpart — or twins. Another essential component of Industry 5.0 is artificial intelligence (AI), which has the potential to create a more intelligent and efficient manufacturing process. In this study, a systematic review of the state of the art is presented to explore the synergies between cobots, DTs, augmentation, and Industry 5.0 for smart manufacturing. To the best of the author's knowledge, this is the first attempt in the literature to provide a comprehensive review of the synergies between the various components of Industry 5.0. This work aims at increasing the global efforts to realize the large variety of application possibilities offered by Industry 5.0 and to provide an up-to-date reference as a stepping-stone for new research and development within this field.
ER  -
TY  - JOUR
TI  - Homotopy switching model for dyad haptic interaction in physical collaborative tasks
PY  - 2009
DO  - 10.1109/whc.2009.4810879
UR  - https://doi.org/10.1109/whc.2009.4810879
DA  - 2009-01-01
AU  - Evrard, Paul
C1  - CNRS-LIRMM, CNRS-AIST JRL, USA#TAB#
AU  - Kheddar, Abderrahmane
C1  - CNRS-LIRMM, CNRS-AIST JRL, USA#TAB#
LA  - en
KW  - Dyad
SP  - 45
EP  - 50
AB  - The main result of this paper is a new model based on homotopy switching between intrinsically distinct controllers that encompass most behaviors encountered in dyadic haptic collaborative tasks. The basic idea is to switch continuously between two distinct extreme behaviors (leader and follower) for each individual, which creates an implicit bilateral coupling within the dyad. The physical collaborative interaction is then described only with two distinct homotopy time-functions that vary independently. These functions can likely describe the signature of a collaborative task. A virtual reality haptic set-up is used to assess the proposed theory.
ER  -
TY  - JOUR
TI  - Haptic Data Compression and Communication
PY  - 2010
PB  - Institute of Electrical and Electronics Engineers
SN  - 1053-5888
T2  - IEEE Signal Processing Magazine
DO  - 10.1109/msp.2010.938753
UR  - https://doi.org/10.1109/msp.2010.938753
DA  - 2010-12-22
AU  - Steinbach, Eckehard
C1  - [He received the engineering doctorate from the University of Erlangen-Nürnberg, Germany, in 1999.]
AU  - Hirche, Sandra
C1  - She was a postdoctoral at the Tokyo Institute of Technology, Japan.
AU  - Kammerl, Julius
C1  - He is currently working as a member of the research and teaching staff.
AU  - Vittorias, Iason
C1  - He has been a research assistant at the Institute of Automatic Control Engineering, Technische Universit???t M???nchen, Munich, Germany, pursuing his Ph.D. degree.
AU  - Chaudhari, Rahul
C1  - He received an undergraduate degree (bachelor of engineering) in electronics and telecommunications from the University of Pune, India, graduating in 2006 as the top engineering student in his class.
LA  - en
KW  - Telerobotics
KW  - Immersion
KW  - Modality (human–computer interaction)
KW  - Stereotaxy
VL  - 28
IS  - 1
SP  - 87
EP  - 96
ER  -
TY  - JOUR
TI  - Revealing the realities of collaborative virtual reality
PY  - 2000
DO  - 10.1145/351006.351010
UR  - https://doi.org/10.1145/351006.351010
DA  - 2000-09-01
AU  - Fraser, Mike
C1  - Communications Research Group, School of Computer Science, University of Nottingham, University Park, Nottingham NG7 2RD, U.K.#TAB#
AU  - Glover, Tony
C1  - Communications Research Group, School of Computer Science, University of Nottingham, University Park, Nottingham NG7 2RD, U.K.#TAB#
AU  - Vaghi, Ivan
C1  - Communications Research Group, School of Computer Science, University of Nottingham, University Park, Nottingham NG7 2RD, U.K.#TAB#
AU  - Benford, Steve
C1  - Communications Research Group, School of Computer Science, University of Nottingham, University Park, Nottingham NG7 2RD, U.K.#TAB#
AU  - Greenhalgh, Chris
C1  - Communications Research Group, School of Computer Science, University of Nottingham, University Park, Nottingham NG7 2RD, U.K.#TAB#
AU  - Hindmarsh, Jon
C1  - Work, Interaction and Technology Research Group, The Management Centre, King's College London, Franklin-Wilkins Building, London SE1 8WA, U.K.
AU  - Heath, Christian
C1  - King ‘s College London
LA  - en
KW  - Virtual world
KW  - Instructional simulation
AB  - We look at differences between the experience of virtual environments and physical reality, and consider making the technical limitations which cause these differences 'visible', aiming to provide resources to enhance communication between users. Three causes of such discrepancies are considered to illustrate this idea: field-of-view; haptic feedback; and network delays. For each, we examine ways of revealing the limitations of the virtual world as resources to better understand the intricacies of system and co-user behaviour. These examples introduce a broader discussion of design issues involved in producing interfaces for day-to-day collaboration through virtual environments. Issues include: the application and activity undertaken through the virtual world; the ability to focus on the business at hand rather than the system in use; and extent of users' familiarity with application and system.
ER  -
TY  - JOUR
TI  - Visuo-haptic collaborative augmented reality ping-pong
PY  - 2007
DO  - 10.1145/1255047.1255065
UR  - https://doi.org/10.1145/1255047.1255065
DA  - 2007-06-13
AU  - Knoerlein, Benjamin
C1  - Computer Vision Laboratory - ETH Zurich, Zurich, Switzerland, Switzerland
AU  - Székely, Gábor
C1  - Computer Vision Laboratory - ETH Zurich, Zurich, Switzerland, Switzerland
AU  - Harders, Matthias
C1  - Computer Vision Laboratory - ETH Zurich, Zurich, Switzerland, Switzerland
LA  - en
KW  - Ping pong
SP  - 91
EP  - 94
ER  -
TY  - JOUR
TI  - The Development of a Virtual Simulator for Training Neurosurgeons to Perform and Perfect Endoscopic Endonasal Transsphenoidal Surgery
PY  - 2013
PB  - Lippincott Williams & Wilkins
SN  - 0148-396X
T2  - Neurosurgery
DO  - 10.1227/neu.0000000000000112
UR  - https://doi.org/10.1227/neu.0000000000000112
DA  - 2013-09-20
AU  - Rosseau, Gail
C1  - Department of Neurosurgery, NorthShore University Health System, Evanston, Illinois
AU  - Bailes, Julian
C1  - Department of Neurosurgery, NorthShore University Health System, Evanston, Illinois
AU  - Del Maestro, Rolando
C1  - Neurosurgical Simulation Research Centre, Montreal Neurological Institute and Hospital, Montreal, Quebec, Canada
AU  - Cabral, Anne
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Choudhury, Nusrat
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Comas, Olivier
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Debergue, Patricia
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - De Luca, Gino
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Hovdebo, Jordan
C1  - National Research Council Canada, Winnipeg, Manitoba, Canada
AU  - Jiang, Di
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Laroche, Denis
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Neubauer, André
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Pazos, Valérie
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Thibault, F.
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - DiRaddo, Robert
C1  - National Research Council Canada, Boucherville, Quebec, Canada
LA  - en
KW  - Transsphenoidal surgery
VL  - 73
IS  - supplement 1
SP  - S85
EP  - S93
ER  -
TY  - JOUR
TI  - Spatial User Interfaces for Large-Scale Projector-Based Augmented Reality
PY  - 2014
PB  - Institute of Electrical and Electronics Engineers
SN  - 0272-1716
T2  - IEEE Computer Graphics and Applications
DO  - 10.1109/mcg.2014.117
UR  - https://doi.org/10.1109/mcg.2014.117
DA  - 2014-11-01
AU  - Marner, Michael
C1  - University of South Australia
AU  - Smith, Ross
C1  - University of South Australia
AU  - Walsh, James
C1  - University of South Australia
AU  - Thomas, Bruce
C1  - University of South Australia
LA  - en
VL  - 34
IS  - 6
SP  - 74
EP  - 82
ER  -
TY  - JOUR
TI  - Role of haptics in teaching structural molecular biology
PY  - 2003
DO  - 10.1109/haptic.2003.1191312
UR  - https://doi.org/10.1109/haptic.2003.1191312
DA  - 2003-12-08
AU  - Sankaranarayanan, Ganesh
C1  - Human Interface Technol. Lab., Washington Univ., St. Louis, MO, USA
AU  - Weghorst, Suzanne
C1  - Human Interface Technol. Lab., Washington Univ., St. Louis, MO, USA
AU  - Sanner, Michel
C1  - Human Interface Technol. Lab., Washington Univ., St. Louis, MO, USA
AU  - Gillet, Alexandre
C1  - Human Interface Technol. Lab., Washington Univ., St. Louis, MO, USA
AU  - Olson, Arthur
C1  - Human Interface Technol. Lab., Washington Univ., St. Louis, MO, USA
LA  - en
KW  - Modality (human–computer interaction)
KW  - Interface (matter)
KW  - Graphical user interface
SP  - 363
EP  - 366
ER  -
TY  - JOUR
TI  - A network architecture supporting consistent rich behavior in collaborative interactive applications
PY  - 2006
PB  - Institute of Electrical and Electronics Engineers
SN  - 1077-2626
T2  - IEEE Transactions on Visualization and Computer Graphics
DO  - 10.1109/tvcg.2006.40
UR  - https://doi.org/10.1109/tvcg.2006.40
DA  - 2006-03-22
AU  - Marsh, James
C1  - School of Computer Science, Manchester University
AU  - Glencross, Mashhuda
C1  - School of Computer Science, Manchester University
AU  - Pettifer, Steve
C1  - School of Computer Science, Manchester University
AU  - Hubbold, Roger
C1  - School of Computer Science, Manchester University
LA  - en
VL  - 12
IS  - 3
SP  - 405
EP  - 416
ER  -
TY  - JOUR
TI  - Comparison of the effectiveness of virtual reality-based education and conventional teaching methods in dental education: a systematic review
PY  - 2024
PB  - BioMed Central
SN  - 1472-6920
T2  - BMC Medical Education
DO  - 10.1186/s12909-023-04954-2
UR  - https://doi.org/10.1186/s12909-023-04954-2
DA  - 2024-01-03
AU  - Koolivand, Hossain
C1  - Dental Students' Research Committee, School of Dentistry, Kermanshah University of Medical Sciences, Kermanshah, Iran
AU  - Shooreshi, Mohammad
C1  - Dental Students' Research Committee, School of Dentistry, Tehran University of Medical Sciences, Tehran, Iran
AU  - Safari‐Faramani, Roya
C1  - Assistant Professor of Epidemiology Department of Epidemiology, School of Health Research Center for Environmental Determinants of Health Research Institute, Kermanshah University of Medical Sciences, Kermanshah, Iran
AU  - Borji, Milad
C1  - Faculty Member, Department of Nursing, Kermanshah University of Medical Sciences, Kermanshah, Iran
AU  - Mansoory, Meysam
C1  - Faculty Member, Department of Biomedical Engineering, School of Medicine, Kermanshah University of Medical Sciences, Kermanshah, Iran
AU  - Moradpoor, Hedaiat
C1  - Associate Professor in Prosthodontics, Department of Prosthodontics, School of Dentistry, Kermanshah University of Medical Sciences, Kermanshah, Iran
AU  - Bahrami, Masoud
C1  - Research assistance, Arak University of Medical Sciences, Arak, Iran
AU  - Azizi, Seyyed
C1  - Medical Education and Development Center, Arak University of Medical Sciences, Arak, Iran
LA  - en
KW  - Dental education
VL  - 24
IS  - 1
AB  - Abstract Background and objectives Virtual reality dental simulators as an educational tool may create specific training conditions for dental students, allowing them to practice dental skills in a safe and controlled condition. This study aimed to investigate the effectiveness of virtual reality-based education in dental education compared to traditional education approaches. Methods In this systematic review, four databases (PubMed, Scopus, Web of Science, and Science Direct) were searched until 2023 following PRISMA guidelines. The Quality assessment and risk of bias were assessed by the Cochrane Collaboration Tool for RCTs and GRADE, respectively. Inclusion criteria were restricted to randomized or quasi-randomized trials about virtual reality efficacy in dental education. Two authors independently evaluated the data and reviewed the overall risk of bias for all selected studies. Study design, sample size, hardware, onset time of intervention, duration, and number of procedures performed were among the data extracted. Results From the 703 titles, 48 full texts were chosen for review, yielding 14 articles for final inclusion. The review of these articles indicated the effective role of virtual reality dental simulators in improving students' knowledge and practical skills. Conclusions Based on our findings, adding haptic technology to virtual reality can improve students' practical skills, hand skills, theoretical knowledge, self-confidence, and learning environment. Although a fair amount of research needs to be done, notably on cost-effectiveness, student satisfaction, and other potentially adverse effects, virtual reality is a growing phenomenon with immense potential.
ER  -
TY  - JOUR
TI  - Mixed Reality Ventriculostomy Simulation
PY  - 2014
PB  - Lippincott Williams & Wilkins
SN  - 2332-4252
T2  - Operative Neurosurgery
DO  - 10.1227/neu.0000000000000503
UR  - https://doi.org/10.1227/neu.0000000000000503
DA  - 2014-07-22
AU  - Hooten, Kristopher
C1  - Department of Neurological Surgery, University of Florida, Gainesville, Florida
AU  - Lister, J.
C1  - Department of Neurological Surgery, University of Florida, Gainesville, Florida
AU  - Lombard, Gwen
C1  - Department of Neurological Surgery, University of Florida, Gainesville, Florida
AU  - Lizdas, David
C1  - Department of Anesthesiology, Center for Safety, Simulation & Advanced Learning Technologies, University of Florida, Gainesville, Florida
AU  - Lampotang, Samsun
C1  - Department of Anesthesiology, Center for Safety, Simulation & Advanced Learning Technologies, University of Florida, Gainesville, Florida
AU  - Rajon, Didier
C1  - Department of Neurological Surgery, University of Florida, Gainesville, Florida
AU  - Bova, Frank
C1  - Department of Neurological Surgery, University of Florida, Gainesville, Florida
AU  - Murad, Gregory
C1  - Department of Neurological Surgery, University of Florida, Gainesville, Florida
LA  - en
KW  - Ventriculostomy
KW  - Simulation training
VL  - 10
IS  - 4
SP  - 576
EP  - 581
ER  -
TY  - BOOK
TI  - Haptics Technologies: Bringing Touch to Multimedia
PY  - 2011
DA  - 2011-09-10
AU  - Saddik, Abdulmotaleb
AU  - Orozco, Mauricio
AU  - Eid, Mohamad
AU  - Cha, Jongeun
LA  - en
KW  - Stereotaxy
KW  - Haptic perception
ER  -
TY  - JOUR
TI  - DLR's robotics technologies for on-orbit servicing
PY  - 2004
PB  - Taylor & Francis
SN  - 0169-1864
T2  - Advanced Robotics
DO  - 10.1163/156855304322758006
UR  - https://doi.org/10.1163/156855304322758006
DA  - 2004-01-01
AU  - Hirzinger, Gerd
AU  - Landzettel, K.
AU  - Brunner, Bernhard
AU  - Fischer, Max
AU  - Preusche, Carsten
AU  - Reintsema, Detlef
AU  - Albu‐Schäffer, Alin
AU  - Schreiber, G.
AU  - Steinmetz, Bernhard-Michael
LA  - en
KW  - Telerobotics
KW  - Payload (computing)
KW  - Robotic spacecraft
VL  - 18
IS  - 2
SP  - 139
EP  - 174
ER  -
TY  - JOUR
TI  - Collaborative Virtual Surgery: Techniques, Applications and Challenges
PY  - 2010
SN  - 1081-1451
T2  - International Journal of Virtual Reality
DO  - 10.20870/ijvr.2010.9.3.2773
UR  - https://doi.org/10.20870/ijvr.2010.9.3.2773
DA  - 2010-01-01
AU  - Qin, Jing
C1  - Centre Européen de Réalité Virtuelle
AU  - Choi, Kup‐Sze
C1  - Centre Européen de Réalité Virtuelle
AU  - Pang, Wai‐Man
C1  - Centre Européen de Réalité Virtuelle
AU  - Zhang, Yi
C1  - Centre Européen de Réalité Virtuelle
AU  - Heng, Pheng‐Ann
C1  - Centre Européen de Réalité Virtuelle
LA  - en
KW  - Collaborative virtual environment
KW  - Collaborative software
VL  - 9
IS  - 3
SP  - 1
EP  - 7
AB  - While considerable effort has been dedicated to improve medical education with virtual reality based surgical simulators, relatively little attention is given to the simulation of the collaborative procedures in distributed environments. In this paper, we first present a literature review of techniques involved in the development of collaborative simulators, including network architecture, transmission protocol, collaboration mechanism, schedule algorithm, collaborative user-interaction feature and haptic communication. We introduce the details of each technique and discuss the advantages and drawbacks. Then, we review some of the existing applications to illustrate how to apply these techniques to implement an efficient and robust collaborative simulator. Finally, we discuss the challenges that need to be addressed in the future.
ER  -
TY  - JOUR
TI  - Performance related energy exchange in haptic human-human interaction in a shared virtual object manipulation task
PY  - 2009
DO  - 10.1109/whc.2009.4810854
UR  - https://doi.org/10.1109/whc.2009.4810854
DA  - 2009-01-01
AU  - Feth, Daniela
C1  - Institute of Automatic Control Engineering, Technische Universität München, Germany
AU  - Groten, Raphaela
C1  - Institute of Automatic Control Engineering, Technische Universität München, Germany
AU  - Peer, Angelika
C1  - Institute of Automatic Control Engineering, Technische Universität München, Germany
AU  - Hirche, Sandra
C1  - Institute of Automatic Control Engineering, Technische Universität München, Germany
AU  - Buss, Martin
C1  - Institute of Automatic Control Engineering, Technische Universität München, Germany
LA  - en
KW  - Human–robot interaction
KW  - Virtual image
KW  - Energy exchange
KW  - Tracking (education)
SP  - 338
EP  - 343
ER  -
TY  - JOUR
TI  - A volumetric approach to virtual simulation of functional endoscopic sinus surgery.
PY  - 1997
PB  - National Institutes of Health
T2  - PubMed
DA  - 1997-01-01
AU  - Wiet, Gregory
C1  - Department of Otolaryngology, Ohio State University Hospitals, Columbus, USA.
AU  - Yagel, Roni
AU  - Stredney, D
AU  - Schmalbrock, Petra
AU  - Sessanna, D
AU  - Kurzion, Yair
AU  - Rosenberg, Louis
AU  - Levin, Michael
AU  - Martin, Katherine
LA  - en
KW  - Surgical simulation
VL  - 39
SP  - 167
EP  - 79
ER  -
TY  - JOUR
TI  - Virtual Endoscopy in Neurosurgery
PY  - 2012
PB  - Lippincott Williams & Wilkins
SN  - 0148-396X
T2  - Neurosurgery
DO  - 10.1227/neu.0b013e31827393c9
UR  - https://doi.org/10.1227/neu.0b013e31827393c9
DA  - 2012-12-20
AU  - Neubauer, André
C1  - André Neubauer, PhD, National Research Council Canada, 75 de Mortagne Boulevard, Boucherville, QC, Canada, J4B 6Y4. E-mail: [email protected]
C1  - National Research Council of Canada, Boucherville, Quebec, Canada
AU  - Wolfsberger, Stefan
C1  - Department of Clinical Neurosciences and the Hotchkiss Brain Institute, Division of Neurosurgery, University of Calgary, Calgary, Alberta, Canada
C1  - Department of Neurosurgery, Medical University Vienna, Vienna, Austria
LA  - en
KW  - Neuronavigation
VL  - 72
IS  - Supplement 1
SP  - A97
EP  - A106
ER  -
TY  - JOUR
TI  - Development of the McGill Simulator for Endoscopic Sinus Surgery: A New High-fidelity Virtual Reality Simulator for Endoscopic Sinus Surgery
PY  - 2014
PB  - SAGE Publishing
SN  - 1945-8932
T2  - American Journal of Rhinology and Allergy
DO  - 10.2500/ajra.2014.28.4046
UR  - https://doi.org/10.2500/ajra.2014.28.4046
DA  - 2014-07-01
AU  - Varshney, Rickul
C1  - Department of Otolaryngology-Head and Neck Surgery; McGill University; Montreal Canada
AU  - Frenkiel, Saul
C1  - Department of Otolaryngology–Head and Neck Surgery, Montreal, Canada
AU  - Nguyen, Lily
C1  - Center for Medical Education, Montreal, Canada
C1  - Department of Otolaryngology–Head and Neck Surgery, Montreal, Canada
AU  - Young, Meredith
C1  - Center for Medical Education, Montreal, Canada
C1  - Department of Medicine, Montreal, Canada
AU  - Del Maestro, Rolando
C1  - Neurosurgical Simulation Research Center, McGill University, Montreal, Canada
AU  - Zeitouni, Anthony
C1  - Department of Otolaryngology–Head and Neck Surgery, Montreal, Canada
AU  - Tewfik, Marc
C1  - Department of Otolaryngology–Head and Neck Surgery, Montreal, Canada
LA  - en
KW  - Rhinology
KW  - Endoscopic sinus surgery
KW  - Learning curve
VL  - 28
IS  - 4
SP  - 330
EP  - 334
AB  - Background The technical challenges of endoscopic sinus surgery (ESS) and the high risk of complications support the development of alternative modalities to train residents in these procedures. Virtual reality simulation is becoming a useful tool for training the skills necessary for minimally invasive surgery; however, there are currently no ESS virtual reality simulators available with valid evidence supporting their use in resident education. Our aim was to develop a new rhinology simulator, as well as to define potential performance metrics for trainee assessment. Methods The McGill simulator for endoscopic sinus surgery (MSESS), a new sinus surgery virtual reality simulator with haptic feedback, was developed (a collaboration between the McGill University Department of Otolaryngology–Head and Neck Surgery, the Montreal Neurologic Institute Simulation Lab, and the National Research Council of Canada). A panel of experts in education, performance assessment, rhinology, and skull base surgery convened to identify core technical abilities that would need to be taught by the simulator, as well as performance metrics to be developed and captured. Results The MSESS allows the user to perform basic sinus surgery skills, such as an ethmoidectomy and sphenoidotomy, through the use of endoscopic tools in a virtual nasal model. The performance metrics were developed by an expert panel and include measurements of safety, quality, and efficiency of the procedure. Conclusion The MSESS incorporates novel technological advancements to create a realistic platform for trainees. To our knowledge, this is the first simulator to combine novel tools such as the endonasal wash and elaborate anatomic deformity with advanced performance metrics for ESS.
ER  -
TY  - JOUR
TI  - Virtual reality simulation for the optimization of endovascular procedures: current perspectives
PY  - 2015
PB  - Dove Medical Press
SN  - 1176-6344
T2  - Vascular Health and Risk Management
DO  - 10.2147/vhrm.s46194
UR  - https://doi.org/10.2147/vhrm.s46194
DA  - 2015-03-01
AU  - Rudarakanchana, Nung
C1  - Department of Surgery, Imperial College London,London, UK.
AU  - Desender, Liesbeth
C1  - Department of Thoracic and Vascular Surgery Ghent University Hospital Ghent Belgium
AU  - Van Herzeele, Isabelle
C1  - Department of Thoracic and Vascular Surgery Ghent University Hospital Ghent Belgium
AU  - Cheshire, Nicholas
C1  - Department of Surgery, Imperial College London,London, UK.
LA  - en
KW  - Endovascular surgery
SP  - 195
EP  - 195
AB  - Abstract: Endovascular technologies are rapidly evolving, often requiring coordination and cooperation between clinicians and technicians from diverse specialties. These multidisciplinary interactions lead to challenges that are reflected in the high rate of errors occurring during endovascular procedures. Endovascular virtual reality (VR) simulation has evolved from simple benchtop devices to full physic simulators with advanced haptics and dynamic imaging and physiological controls. The latest developments in this field include the use of fully immersive simulated hybrid angiosuites to train whole endovascular teams in crisis resource management and novel technologies that enable practitioners to build VR simulations based on patient-specific anatomy. As our understanding of the skills, both technical and nontechnical, required for optimal endovascular performance improves, the requisite tools for objective assessment of these skills are being developed and will further enable the use of VR simulation in the training and assessment of endovascular interventionalists and their entire teams. Simulation training that allows deliberate practice without danger to patients may be key to bridging the gap between new endovascular technology and improved patient outcomes. Keywords: virtual reality, simulation, endovascular, aneurysm
ER  -
TY  - JOUR
TI  - Multi-Agent Reinforcement Learning-Based Distributed Channel Access for Next Generation Wireless Networks
PY  - 2022
PB  - Institute of Electrical and Electronics Engineers
SN  - 0733-8716
T2  - IEEE Journal on Selected Areas in Communications
DO  - 10.1109/jsac.2022.3143251
UR  - https://doi.org/10.1109/jsac.2022.3143251
DA  - 2022-01-14
AU  - Guo, Ziyang
C1  - Wireless Technology Lab, 2012 Laboratories, Huawei Technologies Company Ltd., Shenzhen, China
AU  - Chen, Zhenyu
C1  - School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen, China
AU  - Liu, Peng
C1  - Wireless Technology Lab, 2012 Laboratories, Huawei Technologies Company Ltd., Shenzhen, China
AU  - Luo, Jianjun
C1  - Wireless Technology Lab, 2012 Laboratories, Huawei Technologies Company Ltd., Shenzhen, China
AU  - Yang, Xun
C1  - Wireless Technology Lab, 2012 Laboratories, Huawei Technologies Company Ltd., Shenzhen, China
AU  - Sun, Xinghua
C1  - School of Electronics and Communication Engineering, Sun Yat-sen University, Shenzhen, China
LA  - en
VL  - 40
IS  - 5
SP  - 1587
EP  - 1599
ER  -
TY  - JOUR
TI  - Trends in robot-assisted and virtual reality-assisted neuromuscular therapy: a systematic review of health-related multiplayer games
PY  - 2018
PB  - BioMed Central
SN  - 1743-0003
T2  - Journal of NeuroEngineering and Rehabilitation
DO  - 10.1186/s12984-018-0449-9
UR  - https://doi.org/10.1186/s12984-018-0449-9
DA  - 2018-11-19
AU  - Baur, Kilian
C1  - Sensory-Motor Systems Lab, Department of Health Sciences and Technology, ETH Zurich, Tannenstrasse 1, Zurich, 8092, Switzerland
AU  - Schättin, Alexandra
C1  - Department of Health Sciences and Technology, Institute of Human Movement Sciences and Sport, Swiss Federal Institute of Technology (ETH Zurich), Zurich, Switzerland, Leopold-Ruzicka-Weg 4, Zurich, 8093, Switzerland
AU  - de Bruin, Eling
C1  - Department of Health Sciences and Technology, Institute of Human Movement Sciences and Sport, Swiss Federal Institute of Technology (ETH Zurich), Zurich, Switzerland, Leopold-Ruzicka-Weg 4, Zurich, 8093, Switzerland
AU  - Riener, Robert
C1  - Sensory-Motor Systems Lab, Department of Health Sciences and Technology, ETH Zurich, Tannenstrasse 1, Zurich, 8092, Switzerland
AU  - Duarte, Jaime
C1  - Spinal Cord Injury Center, University Hospital Balgrist, University of Zurich, Zurich, Switzerland, Forchstrasse 340, Zurich, 8008, Switzerland
AU  - Wolf, Peter
C1  - Sensory-Motor Systems Lab, Department of Health Sciences and Technology, ETH Zurich, Tannenstrasse 1, Zurich, 8092, Switzerland
LA  - en
KW  - PsycINFO
KW  - CINAHL
KW  - Neurorehabilitation
VL  - 15
IS  - 1
AB  - Multiplayer games have emerged as a promising approach to increase the motivation of patients involved in rehabilitation therapy. In this systematic review, we evaluated recent publications in health-related multiplayer games that involved patients with cognitive and/or motor impairments. The aim was to investigate the effect of multiplayer gaming on game experience and game performance in healthy and non-healthy populations in comparison to individual game play. We further discuss the publications within the context of the theory of flow and the challenge point framework. A systematic search was conducted through EMBASE, Medline, PubMed, Cochrane, CINAHL and PsycINFO. The search was complemented by recent publications in robot-assisted multiplayer neurorehabilitation. The search was restricted to robot-assisted or virtual reality-based training. Thirteen articles met the inclusion criteria. Multiplayer modes used in health-related multiplayer games were: competitive, collaborative and co-active multiplayer modes. Multiplayer modes positively affected game experience in nine studies and game performance in six studies. Two articles reported increased game performance in single-player mode when compared to multiplayer mode. The multiplayer modes of training reviewed improved game experience and game performance compared to single-player modes. However, the methods reviewed were quite heterogeneous and not exhaustive. One important take-away is that adaptation of the game conditions can individualize the difficulty of a game to a player's skill level in competitive multiplayer games. Robotic assistance and virtual reality can enhance individualization by, for example, adapting the haptic conditions, e.g. by increasing haptic support or by providing haptic resistance. The flow theory and the challenge point framework support these results and are used in this review to frame the idea of adapting players' game conditions.
ER  -
TY  - JOUR
TI  - An IoMT based cyber training framework for orthopedic surgery using Next Generation Internet technologies
PY  - 2018
PB  - Elsevier BV
SN  - 2352-9148
T2  - Informatics in Medicine Unlocked
DO  - 10.1016/j.imu.2018.05.002
UR  - https://doi.org/10.1016/j.imu.2018.05.002
DA  - 2018-01-01
AU  - Cecil, J.
C1  - MSCS 219, Center for Cyber Physical Systems, Department of Computer Science, Oklahoma State University, Stillwater, OK, 74078, USA
AU  - Gupta, Avinash
C1  - MSCS 219, Center for Cyber Physical Systems, Department of Computer Science, Oklahoma State University, Stillwater, OK, 74078, USA
AU  - Pirela-Cruz, Miguel
C1  - Paul Foster School of Medicine, Department of Orthopedic Surgery, Texas Tech Health Sciences Center, El Paso, USA
AU  - Ramanathan, Parmesh
C1  - Department of Electrical and Computer Engineering, University of Wisconsin, Madison, USA
LA  - en
VL  - 12
SP  - 128
EP  - 137
AB  - Internet of Things based approaches and frameworks hold significant potential in changing the way in which engineering activities are accomplished. The information centric revolution underway has served as a catalyst in the design of innovative methods and practices in several engineering and other domains. In this paper, an Internet of Medical Things based framework for surgical training is discussed in the broader context of Next Generation frameworks. The design and development of this Internet of Medical Things based framework involving adoption of Global Environment for Network Innovations based networking principles is elaborated. The Virtual Reality based simulation environments incorporate haptic based interfaces which support collaborative training and interactions among expert surgeons and residents in orthopedic surgery from distributed locations. The impact of using this Internet of Medical Things based framework for medical education has also been studied; the outcomes underscore the potential of adopting such Internet of Medical Things based approaches for medical education.
ER  -
TY  - GEN
TI  - None
PY  - 2009
PB  - Wiley
SN  - 1546-4261
T2  - Computer Animation and Virtual Worlds
DO  - 10.1002/cav.v20:1
UR  - https://doi.org/10.1002/cav.v20:1
DA  - 2009-01-01
AU  - Çakmak, Hüseyin
C1  - (Correspd.) Forschungszentrum Karlsruhe, Institut für Angewandte Informatik, Karlsruhe, Germany.#TAB#
AU  - Maaß, H.
AU  - Trantakis, C.
AU  - Strauß, G.
AU  - Nowatius, E.
AU  - Kühnapfel, Uwe
LA  - en
VL  - 20
IS  - 1
ER  -
TY  - JOUR
TI  - Early experience and validation work with Procedicus VA--the Prosolvia virtual reality shoulder arthroscopy trainer.
PY  - 1999
PB  - National Institutes of Health
T2  - PubMed
DA  - 1999-01-01
AU  - Smith, Samuel
C1  - Imperial College School of Medicine, St. Mary's Hospital, London, UK.
AU  - Wan, Andrew
AU  - Taffinder, N
AU  - Read, Sanna
AU  - Emery, Rachel
AU  - Darzi, A.
LA  - en
KW  - Trainer
VL  - 62
SP  - 337
EP  - 43
ER  -
TY  - JOUR
TI  - The virtual reality arthroscopy training simulator.
PY  - 1998
PB  - National Institutes of Health
T2  - PubMed
DA  - 1998-01-01
AU  - Müller, Wolfgang
C1  - Fraunhofer Institute for Computer Graphics (Fraunhofer-IGD), Department Visualization & Virtual Reality, Darmstadt, Germany.
AU  - Bockholt, Ulrich
LA  - en
KW  - Interface (matter)
KW  - Representation
VL  - 50
SP  - 13
EP  - 9
ER  -
TY  - JOUR
TI  - Ultrareliable and Low-Latency Communication Techniques for Tactile Internet Services
PY  - 2018
PB  - Institute of Electrical and Electronics Engineers
SN  - 0018-9219
T2  - Proceedings of the IEEE
DO  - 10.1109/jproc.2018.2868995
UR  - https://doi.org/10.1109/jproc.2018.2868995
DA  - 2018-09-27
AU  - Kim, Kwang
C1  - School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea
AU  - Kim, Dong
C1  - School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea
AU  - Chae, Chan‐Byoung
C1  - School of Integrated Technology, Yonsei University, Seoul, South Korea
AU  - Choi, Sunghyun
C1  - Department of Electrical and Computer Engineering, Seoul National University, Seoul, South Korea
AU  - Ko, Young‐Chai
C1  - School of Integrated Technology, Yonsei University, Seoul, South Korea
AU  - Kim, Jonghyun
C1  - School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea
AU  - Lim, Yeon-Geun
C1  - School of Integrated Technology, Yonsei University, Seoul, South Korea
AU  - Yang, Minho
C1  - School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea
AU  - Kim, Sundo
C1  - School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea
AU  - Lim, Byungju
C1  - School of Integrated Technology, Yonsei University, Seoul, South Korea
AU  - Lee, Kwang-Hoon
C1  - School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea
AU  - Ryu, kyung
C1  - School of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea
LA  - en
VL  - 107
IS  - 2
SP  - 376
EP  - 393
AB  - This paper presents novel ultrareliable and low-latency communication (URLLC) techniques for URLLC services, such as Tactile Internet services. Among typical use-cases of URLLC services are tele-operation, immersive virtual reality, cooperative automated driving, and so on. In such URLLC services, new kinds of traffic such as haptic information including kinesthetic information and tactile information need to be delivered in addition to high-quality video and audio traffic in traditional multimedia services. Further, such a variety of traffic has various characteristics in terms of packet sizes and data rates with a variety of requirements of latency and reliability. Furthermore, some traffic may occur in a sporadic manner but require reliable delivery of packets of medium to large sizes within a low latency, which is not supported by current state-of-the-art wireless communication systems and is very challenging for future wireless communication systems. Thus, to meet such a variety of tight traffic requirements in a wireless communication system, novel technologies from the physical layer to the network layer need to be devised. In this paper, some novel physical layer technologies such as waveform multiplexing, multiple access scheme, channel code design, synchronization, and full-duplex transmission for spectrally-efficient URLLC are introduced. In addition, a novel performance evaluation approach, which combines a ray-tracing tool and system-level simulation, is suggested for evaluating the performance of the proposed schemes. Simulation results show the feasibility of the proposed schemes providing realistic URLLC services in realistic geographical environments, which encourages further efforts to substantiate the proposed work.
ER  -
TY  - JOUR
TI  - Adaptive tactile interaction transfer via digitally embroidered smart gloves
PY  - 2024
PB  - Nature Portfolio
SN  - 2041-1723
T2  - Nature Communications
DO  - 10.1038/s41467-024-45059-8
UR  - https://doi.org/10.1038/s41467-024-45059-8
DA  - 2024-01-29
AU  - Luo, Yiyue
C1  - Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA
AU  - Liu, Chao
C1  - Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA
AU  - Lee, Young
C1  - Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA
AU  - DelPreto, Joseph
C1  - Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA
AU  - Wu, Kui
C1  - LightSpeed Studios, 12777 W Jefferson Boulevard, Los Angeles, CA, 90066, USA
AU  - Foshey, Michael
C1  - Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA
AU  - Rus, Daniela
C1  - Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA
AU  - Palacios, Tomás
C1  - Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA
AU  - Li, Yunzhu
C1  - Department of Computer Science, University of Illinois Urbana-Champaign, 201 North Goodwin Avenue, Urbana, IL, 61801, USA
AU  - Torralba, Antonio
C1  - Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA
AU  - Matusik, Wojciech
C1  - Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, 32 Vassar Street, Cambridge, MA, 02139, USA
LA  - en
KW  - Tactile sensor
KW  - Teleoperation
KW  - Interface (matter)
KW  - Tactile Perception
VL  - 15
IS  - 1
AB  - Abstract Human-machine interfaces for capturing, conveying, and sharing tactile information across time and space hold immense potential for healthcare, augmented and virtual reality, human-robot collaboration, and skill development. To realize this potential, such interfaces should be wearable, unobtrusive, and scalable regarding both resolution and body coverage. Taking a step towards this vision, we present a textile-based wearable human-machine interface with integrated tactile sensors and vibrotactile haptic actuators that are digitally designed and rapidly fabricated. We leverage a digital embroidery machine to seamlessly embed piezoresistive force sensors and arrays of vibrotactile actuators into textiles in a customizable, scalable, and modular manner. We use this process to create gloves that can record, reproduce, and transfer tactile interactions. User studies investigate how people perceive the sensations reproduced by our gloves with integrated vibrotactile haptic actuators. To improve the effectiveness of tactile interaction transfer, we develop a machine-learning pipeline that adaptively models how each individual user reacts to haptic sensations and then optimizes haptic feedback parameters. Our interface showcases adaptive tactile interaction transfer through the implementation of three end-to-end systems: alleviating tactile occlusion, guiding people to perform physical skills, and enabling responsive robot teleoperation.
ER  -
TY  - JOUR
TI  - ColabAR: A Toolkit for Remote Collaboration in Tangible Augmented Reality Laboratories
PY  - 2022
PB  - Association for Computing Machinery
SN  - 2573-0142
T2  - Proceedings of the ACM on Human-Computer Interaction
DO  - 10.1145/3512928
UR  - https://doi.org/10.1145/3512928
DA  - 2022-03-30
AU  - Villanueva, Ana
C1  - Purdue University, West Lafayette, IN, USA
AU  - Zhu, Zhengzhe
C1  - Purdue University, West Lafayette, IN, USA
AU  - Liu, Ziyi
C1  - Purdue University, West Lafayette, IN, USA
AU  - Wang, Feiyang
C1  - Purdue University, West Lafayette, IN, USA
AU  - Chidambaram, Subramanian
C1  - Purdue University, West Lafayette, IN, USA
AU  - Ramani, Karthik
C1  - Purdue University, West Lafayette, IN, USA
LA  - en
VL  - 6
IS  - CSCW1
SP  - 1
EP  - 22
AB  - Current times are accelerating new technologies to provide high-quality education for remote collaboration, as well as hands-on learning. This is particularly important in the case of laboratory-based classes, which play an essential role in STEM education. In this paper, we introduce ColabAR, a toolkit that uses physical proxies to manipulate virtual objects in Tangible Augmented Reality (TAR) laboratories. ColabAR introduces haptic-based customizable interaction techniques to promote remote collaboration between students. Our toolkit provides hardware and software that enable haptic feedback to improve user experience and promote collaboration during learning. Also, we present the architecture of our cloud platform for haptic interaction that supports information sharing between students in a TAR laboratory. We performed two user studies (N=40) to test the effect of our toolkit in enriching local and remote collaborative experiences. Finally, we demonstrated that our TAR laboratory enables students' performance (i.e., lab completion rate, lab scores) to be similar to their performance in an in-person laboratory.
ER  -
TY  - GEN
TI  - Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology
PY  - 2019
DO  - 10.1145/3332165
UR  - https://doi.org/10.1145/3332165
DA  - 2019-10-17
AU  - Wilson, Andrew
C1  - Microsoft Research,USA
AU  - Guimbretière, François
C1  - Cornell University,USA
LA  - en
KW  - Interface (matter)
KW  - Rebuttal
ER  -
TY  - JOUR
TI  - Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology
PY  - 2006
DA  - 2006-06-14
AU  - Ishii, Hiroshi
C1  - Tangible Media Group, MIT Media Laboratory#TAB#
AU  - Lee, Newton
C1  - Association for Computing Machinery (ACM), Disney Online, Woodbury University, and Bell Labs#TAB#
AU  - Natkin, Stéphane
C1  - CNAM Paris, CEDRIC#TAB#
AU  - Tsushima, Katsuhide
C1  - Osaka Electro-Communication Univ (Japan)
LA  - en
KW  - Entertainment industry
ER  -
TY  - JOUR
TI  - PhyShare
PY  - 2017
DO  - 10.1145/3131785.3131795
UR  - https://doi.org/10.1145/3131785.3131795
DA  - 2017-10-20
AU  - He, Zhenyi
C1  - New York University, New York, NY, USA
AU  - Zhu, Fengyuan
C1  - New York University, New York, NY, USA
AU  - Perlin, Ken
C1  - New York University, New York City, NY, USA
LA  - en
KW  - Interface (matter)
ER  -
TY  - GEN
TI  - ACM SIGGRAPH 2018 Emerging Technologies
PY  - 2018
DO  - 10.1145/3214907
UR  - https://doi.org/10.1145/3214907
DA  - 2018-08-12
AU  - Elliott-Famularo, Heather
C1  - [Bowling Green State University]
LA  - en
KW  - Emerging Technologies
ER  -
TY  - JOUR
TI  - HapticBots: Distributed Encountered-type Haptics for VR with Multiple Shape-changing Mobile Robots
PY  - 2021
DO  - 10.1145/3472749.3474821
UR  - https://doi.org/10.1145/3472749.3474821
DA  - 2021-10-10
AU  - Suzuki, Ryo
C1  - University of Calgary, Canada
AU  - Ofek, Eyal
C1  - Microsoft Research, United States
AU  - Sinclair, Mike
C1  - Microsoft Research Microsoft, United States
AU  - Leithinger, Daniel
C1  - ATLAS Institute University of Colorado, Boulder, United States
AU  - González-Franco, Mar
C1  - Microsoft Research, United States
LA  - en
SP  - 1269
EP  - 1281
AB  - HapticBots introduces a novel encountered-type haptic approach for Virtual Reality (VR) based on multiple tabletop-size shape-changing robots. These robots move on a tabletop and change their height and orientation to haptically render various surfaces and objects on-demand. Compared to previous encountered-type haptic approaches like shape displays or robotic arms, our proposed approach has an advantage in deployability, scalability, and generalizability—these robots can be easily deployed due to their compact form factor. They can support multiple concurrent touch points in a large area thanks to the distributed nature of the robots. We propose and evaluate a novel set of interactions enabled by these robots which include: 1) rendering haptics for VR objects by providing just-in-time touch-points on the user's hand, 2) simulating continuous surfaces with the concurrent height and position change, and 3) enabling the user to pick up and move VR objects through graspable proxy objects. Finally, we demonstrate HapticBots with various applications, including remote collaboration, education and training, design and 3D modeling, and gaming and entertainment.
ER  -
TY  - JOUR
TI  - Encountered-type haptic interface for virtual interaction with real objects based on implicit surface haptic rendering for remote palpation
PY  - 2015
T2  - 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
DO  - 10.1109/iros.2015.7354216
UR  - https://doi.org/10.1109/iros.2015.7354216
DA  - 2015-09-01
AU  - Filippeschi, Alessandro
C1  - Percetual Robotics Laboratory, TECIP Institute, Scuola Superiore Sant' Anna, Pisa, Italy
AU  - Brizzi, Filippo
C1  - Percetual Robotics Laboratory, TECIP Institute, Scuola Superiore Sant' Anna, Pisa, Italy
AU  - Ruffaldi, Emanuele
C1  - Percetual Robotics Laboratory, TECIP Institute, Scuola Superiore Sant' Anna, Pisa, Italy
AU  - Jacinto‐Villegas, Juan
C1  - Percetual Robotics Laboratory, TECIP Institute, Scuola Superiore Sant' Anna, Pisa, Italy
AU  - Avizzano, Carlo
C1  - Percetual Robotics Laboratory, TECIP Institute, Scuola Superiore Sant' Anna, Pisa, Italy
LA  - en
KW  - Palpation
KW  - Interface (matter)
KW  - Stereotaxy
SP  - 5904
EP  - 5909
ER  -
TY  - GEN
TI  - Proceedings of the 2006 ACM SIGCHI international conference on Advances in computer entertainment technology
PY  - 2006
DO  - 10.1145/1178823
UR  - https://doi.org/10.1145/1178823
DA  - 2006-06-14
LA  - en
KW  - Entertainment industry
ER  -
TY  - JOUR
TI  - HoloBots: Augmenting Holographic Telepresence with Mobile Robots for Tangible Remote Collaboration in Mixed Reality
PY  - 2023
DO  - 10.1145/3586183.3606727
UR  - https://doi.org/10.1145/3586183.3606727
DA  - 2023-10-21
AU  - Ihara, Keiichi
C1  - University of Tsukuba, Japan
AU  - Faridan, Mehrad
C1  - University of Calgary, Canada
AU  - Ichikawa, Ayumi
C1  - University of Tsukuba, Japan
AU  - Kawaguchi, Ikkaku
C1  - University of Tsukuba, Japan
AU  - Suzuki, Ryo
C1  - University of Calgary, Canada
LA  - en
KW  - Synchronizing
KW  - Telerobotics
SP  - 1
EP  - 12
AB  - This paper introduces HoloBots, a mixed reality remote collaboration system that augments holographic telepresence with synchronized mobile robots. Beyond existing mixed reality telepresence, HoloBots lets remote users not only be visually and spatially present, but also physically engage with local users and their environment. HoloBots allows the users to touch, grasp, manipulate, and interact with the remote physical environment as if they were co-located in the same shared space. We achieve this by synchronizing holographic user motion (Hololens 2 and Azure Kinect) with tabletop mobile robots (Sony Toio). Beyond the existing physical telepresence, HoloBots contributes to an exploration of broader design space, such as object actuation, virtual hand physicalization, world-in-miniature exploration, shared tangible interfaces, embodied guidance, and haptic communication. We evaluate our system with twelve participants by comparing it with hologram-only and robot-only conditions. Both quantitative and qualitative results confirm that our system significantly enhances the level of co-presence and shared experience, compared to the other conditions.
ER  -
TY  - JOUR
TI  - Creation of a novel simulator for minimally invasive neurosurgery: fusion of 3D printing and special effects
PY  - 2017
SN  - 1933-0707
T2  - Journal of Neurosurgery Pediatrics
DO  - 10.3171/2017.1.peds16568
UR  - https://doi.org/10.3171/2017.1.peds16568
DA  - 2017-04-25
AU  - Weinstock, Peter
C1  - Department of Anesthesia, Perioperative and Pain Medicine–Division of Critical Care Medicine,
C1  - Harvard Medical School, Boston, Massachusetts; and
C1  - Simulator Program (SIMPeds),
AU  - Rehder, Roberta
C1  - Division of Pediatric Neurosurgery, Johns Hopkins Hospital, Baltimore, Maryland
AU  - Prabhu, Sanjay
C1  - Department of Radiology, and
C1  - Department of Radiology, and; Harvard Medical School, Boston, Massachusetts; and; Simulator Program (SIMPeds),
C1  - Harvard Medical School, Boston, Massachusetts; and
AU  - Forbes, Peter
C1  - Clinical Research Program, Boston Children's Hospital;
AU  - Roussin, Christopher
C1  - Department of Anesthesia, Perioperative and Pain Medicine–Division of Critical Care Medicine,
C1  - Harvard Medical School, Boston, Massachusetts; and
C1  - Simulator Program (SIMPeds),
AU  - Cohen, Alan
C1  - Division of Pediatric Neurosurgery, Johns Hopkins Hospital, Baltimore, Maryland
LA  - en
VL  - 20
IS  - 1
SP  - 1
EP  - 9
AB  - OBJECTIVE Recent advances in optics and miniaturization have enabled the development of a growing number of minimally invasive procedures, yet innovative training methods for the use of these techniques remain lacking. Conventional teaching models, including cadavers and physical trainers as well as virtual reality platforms, are often expensive and ineffective. Newly developed 3D printing technologies can recreate patient-specific anatomy, but the stiffness of the materials limits fidelity to real-life surgical situations. Hollywood special effects techniques can create ultrarealistic features, including lifelike tactile properties, to enhance accuracy and effectiveness of the surgical models. The authors created a highly realistic model of a pediatric patient with hydrocephalus via a unique combination of 3D printing and special effects techniques and validated the use of this model in training neurosurgery fellows and residents to perform endoscopic third ventriculostomy (ETV), an effective minimally invasive method increasingly used in treating hydrocephalus. METHODS A full-scale reproduction of the head of a 14-year-old adolescent patient with hydrocephalus, including external physical details and internal neuroanatomy, was developed via a unique collaboration of neurosurgeons, simulation engineers, and a group of special effects experts. The model contains “plug-and-play” replaceable components for repetitive practice. The appearance of the training model (face validity) and the reproducibility of the ETV training procedure (content validity) were assessed by neurosurgery fellows and residents of different experience levels based on a 14-item Likert-like questionnaire. The usefulness of the training model for evaluating the performance of the trainees at different levels of experience (construct validity) was measured by blinded observers using the Objective Structured Assessment of Technical Skills (OSATS) scale for the performance of ETV. RESULTS A combination of 3D printing technology and casting processes led to the creation of realistic surgical models that include high-fidelity reproductions of the anatomical features of hydrocephalus and allow for the performance of ETV for training purposes. The models reproduced the pulsations of the basilar artery, ventricles, and cerebrospinal fluid (CSF), thus simulating the experience of performing ETV on an actual patient. The results of the 14-item questionnaire showed limited variability among participants' scores, and the neurosurgery fellows and residents gave the models consistently high ratings for face and content validity. The mean score for the content validity questions (4.88) was higher than the mean score for face validity (4.69) (p = 0.03). On construct validity scores, the blinded observers rated performance of fellows significantly higher than that of residents, indicating that the model provided a means to distinguish between novice and expert surgical skills. CONCLUSIONS A plug-and-play lifelike ETV training model was developed through a combination of 3D printing and special effects techniques, providing both anatomical and haptic accuracy. Such simulators offer opportunities to accelerate the development of expertise with respect to new and novel procedures as well as iterate new surgical approaches and innovations, thus allowing novice neurosurgeons to gain valuable experience in surgical techniques without exposing patients to risk of harm.
ER  -
TY  - JOUR
TI  - Scene Synchronization for Real-Time Interaction in Distributed Mixed Reality and Virtual Reality Environments
PY  - 2004
PB  - The MIT Press
SN  - 1054-7460
T2  - PRESENCE Virtual and Augmented Reality
DO  - 10.1162/1054746041422343
UR  - https://doi.org/10.1162/1054746041422343
DA  - 2004-06-01
AU  - Hamza-Lup, Felix
C1  - School of Electrical Engineering and Computer Science, University of Central Florida#TAB#
AU  - Rolland, Jannick
C1  - School of Electrical Engineering and Computer Science & School of Optics-CREOL, University of Central Florida,
LA  - en
KW  - Interactivity
KW  - Synchronization networks
VL  - 13
IS  - 3
SP  - 315
EP  - 327
AB  - Advances in computer networks and rendering systems facilitate the creation of distributed collaborative environments in which the distribution of information at remote locations allows efficient communication. One of the challenges in networked virtual environments is maintaining a consistent view of the shared state in the presence of inevitable network latency and jitter. A consistent view in a shared scene may significantly increase the sense of presence among participants and facilitate their interactivity. The dynamic shared state is directly affected by the frequency of actions applied on the objects in the scene. Mixed Reality (MR) and Virtual Reality (VR) environments contain several types of action producers including human users, a wide range of electronic motion sensors, and haptic devices. In this paper, we propose a novel criterion for categorization of distributed MR/VR systems and present an adaptive synchronization algorithm for distributed MR/VR collaborative environments. In spite of significant network latency, results show that for low levels of update frequencies the dynamic shared state can be kept consistent at multiple remotely located sites.
ER  -
TY  - JOUR
TI  - A Virtual Reality Enhanced Cyber-Human Framework for Orthopedic Surgical Training
PY  - 2019
PB  - Institute of Electrical and Electronics Engineers
SN  - 1932-8184
T2  - IEEE Systems Journal
DO  - 10.1109/jsyst.2019.2896061
UR  - https://doi.org/10.1109/jsyst.2019.2896061
DA  - 2019-04-25
AU  - Gupta, Avinash
C1  - Center for Cyber Physical Systems, Computer Science Department, Oklahoma State University, Stillwater, OK, USA
AU  - Cecil, J.
C1  - Center for Cyber Physical Systems, Computer Science Department, Oklahoma State University, Stillwater, OK, USA
AU  - Pirela-Cruz, Miguel
C1  - Department of Orthopedic Surgery, Texas Tech University Health Sciences Center, El Paso, TX, USA
AU  - Ramanathan, Parmesh
C1  - University of Wisconsin-Madison, Madison, WI, USA
LA  - en
KW  - Training System
VL  - 13
IS  - 3
SP  - 3501
EP  - 3512
AB  - This paper discusses the adoption of information-centric systems engineering (ICSE) principles to design a cyber-human systems-based simulator framework to train orthopedic surgery medical residents using haptic and immersive virtual reality platforms; the surgical procedure of interest is a less invasive stabilization system plating surgery that is used to treat fractures of the femur. Developing such training systems is a complex task involving multiple systems, technologies, and human experts. The information-centric approach proposed provides a structured foundation to plan, design, and build the simulators using the ICSE approach; in addition, the information models of the surgical processes were built to capture the surgical complexities and relationships between the various systems/components in the simulator framework, along with the controlling factors, performing mechanisms, and decision outcomes at various levels of abstraction. The simulator platforms include a haptic-based training system and a fully immersive training system for six training environments. Next-generation networking principles were adopted to support the collaborative training activities within this framework. As part of the proposed approach, expert surgeons played an important role in the design of the training environments. The outcomes of the learning assessment conducted demonstrate the effectiveness of using such simulator-based cyber-human training frameworks.
ER  -
TY  - JOUR
TI  - Framework for haptic interaction with virtual avatars
PY  - 2008
DO  - 10.1109/roman.2008.4600636
UR  - https://doi.org/10.1109/roman.2008.4600636
DA  - 2008-08-01
AU  - Evrard, Paul
C1  - CNRS, AIST, Tsukuba
AU  - Keith, François
C1  - CNRS, AIST, Tsukuba
AU  - Chardonnet, Jean-Rémy
C1  - CNRS, AIST, Tsukuba
AU  - Kheddar, Abderrahmane
C1  - CNRS, AIST, Tsukuba
LA  - en
KW  - Avatar
KW  - Virtual Prototyping
KW  - Virtual image
SP  - 15
EP  - 20
AB  - In this paper we present an integrative frame work centered on haptic interaction with virtual avatars. This framework is devised for general prototyping and collaborative scenario studies with haptic feedback. First we present the software architecture of the framework and give details on some of its components. Then we show how this framework can be used to derive in a short time a virtual reality simulation. In this simulation, a user directly interacts with a virtual avatar to collaboratively manipulate a virtual object, with haptic feedback and using fast dynamics computation and constraint based methods with friction.
ER  -
TY  - JOUR
TI  - Virtual Reality and Haptic Cardiopulmonary Resuscitation Training Approaches: A Review
PY  - 2021
PB  - Institute of Electrical and Electronics Engineers
SN  - 1932-8184
T2  - IEEE Systems Journal
DO  - 10.1109/jsyst.2020.3048140
UR  - https://doi.org/10.1109/jsyst.2020.3048140
DA  - 2021-01-21
AU  - Everson, Timothy
C1  - School of Engineering, Deakin University, Waurn Ponds, VIC, Australia
AU  - Joordens, Matthew
C1  - School of Engineering, Deakin University, Waurn Ponds, VIC, Australia
AU  - Forbes, Helen
C1  - School of Nursing and Midwifery, Deakin University, Burwood, VIC, Australia
AU  - Horan, Ben
C1  - School of Engineering, Deakin University, Waurn Ponds, VIC, Australia
LA  - en
KW  - Kinesthetic learning
KW  - Training System
KW  - Torso
KW  - Immersion
VL  - 16
IS  - 1
SP  - 1391
EP  - 1399
ER  -
TY  - JOUR
TI  - A comparison of immersive HMD, fish tank VR and fish tank with haptics displays for volume visualization
PY  - 2006
DO  - 10.1145/1140491.1140502
UR  - https://doi.org/10.1145/1140491.1140502
DA  - 2006-07-28
AU  - Qi, Wen
C1  - EINDHOVEN UNIVERSITY OF TECHNOLOGY
C1  - Eindhoven University of Technology
AU  - Taylor, Russell
C1  - UNC Chapel Hill
C1  - unc-chapel hill
AU  - Healey, Christopher
C1  - North Carolina State University,
AU  - Martens, Jean-Bernard
C1  - EINDHOVEN UNIVERSITY OF TECHNOLOGY
C1  - Eindhoven University of Technology
LA  - en
KW  - Immersion
VL  - 2002
SP  - 51
EP  - 58
ER  -
TY  - JOUR
TI  - Cranial implant design using augmented reality immersive system.
PY  - 2007
PB  - National Institutes of Health
T2  - PubMed
DA  - 2007-01-01
AU  - Ai, Zhuming
C1  - Virtual Reality in Medicine Lab, Department of Biomedical and Health Information Sciences, University of Illinois at Chicago, Chicago, IL 60612, USA. zai@uic.edu
AU  - Evenhouse, Ray
C1  - University of Illinois at #TAB#Chicago
AU  - Leigh, Jason
AU  - Charbel, Fady
C1  - Neurological Surgery
AU  - Rasmussen, Mary
C1  - University of Illinois at #TAB#Chicago
LA  - en
KW  - Work space
VL  - 125
SP  - 7
EP  - 12
ER  -
TY  - JOUR
TI  - Fundamentals of Force Feedback and Application to a Surgery Simulator
PY  - 2003
PB  - Taylor & Francis
SN  - 1092-9088
T2  - Computer Aided Surgery
DO  - 10.3109/10929080309146066
UR  - https://doi.org/10.3109/10929080309146066
DA  - 2003-01-01
AU  - Maaß, H.
C1  - Institut für Angewandte Informatik, Forscbungszentrum Karlsruhe, Karlsruhe, Germany
AU  - Chantier, Benjamin
C1  - Institut für Angewandte Informatik, Forscbungszentrum Karlsruhe, Karlsruhe, Germany
AU  - Çakmak, Hüseyin
C1  - Institut für Angewandte Informatik, Forscbungszentrum Karlsruhe, Karlsruhe, Germany
AU  - Trantakis, C.
C1  - Klinik und Poliklinik für Neurochirurgie, Universität Leipzig, Leipzig, Germany
AU  - Kuehnapfel, Uwe
C1  - Institut für Angewandte Informatik, Forscbungszentrum Karlsruhe, Karlsruhe, Germany
LA  - en
KW  - Interface (matter)
KW  - Impedance Control
VL  - 8
IS  - 6
SP  - 283
EP  - 291
AB  - Force feedback increases the effectiveness of virtual-reality surgery training systems. An overview of the fundamentals of applying force feedback is presented. An impedance control technique and data processing methods for stability preservation are illustrated. A flexible interface for general force-feedback applications has been developed. This interface is capable of controlling several different force-feedback hardware systems, including the SensAble PHANTOM, the Laparoscopic Impulse Engines from Immersion, and the VS-One virtual endoscopic surgery trainer. The findings are evaluated using the main simulation system, KISMET, and the modeling tools KISMO and VESUV. Within the scope of a cooperative project called HapticIO (funded by the German Ministry of Education and Research [BMBF]), new haptic devices have been designed for virtual neuroendoscopy and laparoscopy. The concept and implementations presented in this paper have been found to be flexible, stable and suitable for universal use. The impedance method, combined with the open-loop feed-forward control technique, is well suited and appropriate for the task.
ER  -
TY  - JOUR
TI  - A platform for bimanual virtual assembly training with haptic feedback in large multi-object environments
PY  - 2016
DO  - 10.1145/2993369.2993386
UR  - https://doi.org/10.1145/2993369.2993386
DA  - 2016-11-02
AU  - Sagardia, Mikel
C1  - Institute of Robotics and Mechatronics, Wessling, Germany
AU  - Hulin, Thomas
C1  - Institute of Robotics and Mechatronics, Wessling, Germany
AU  - Hertkorn, Katharina
C1  - Institute of Robotics and Mechatronics, Wessling, Germany
AU  - Kremer, Philipp
C1  - Institute of Robotics and Mechatronics, Wessling, Germany
AU  - Schätzle, Simon
C1  - Institute of Robotics and Mechatronics, Wessling, Germany
LA  - en
KW  - Work space
KW  - Solid modeling
VL  - 3
SP  - 153
EP  - 162
AB  - We present a virtual reality platform which addresses and integrates some of the currently challenging research topics in the field of virtual assembly: realistic and practical scenarios with several complex geometries, bimanual six-DoF haptic interaction for hands and arms, and intuitive navigation in large workspaces. We put an especial focus on our collision computation framework, which is able to display stiff and stable forces in 1 kHz using a combination of penalty- and constraint-based haptic rendering methods. Interaction with multiple arbitrary geometries is supported in realtime simulations, as well as several interfaces, allowing for collaborative training experiences. Performance results for an exemplary car assembly sequence which show the readiness of the system are provided.
ER  -
TY  - THES
TI  - Networked haptic interaction in virtual reality for collaborative design
PY  - 2004
DO  - 10.31274/rtd-180813-10994
UR  - https://doi.org/10.31274/rtd-180813-10994
DA  - 2004-01-01
AU  - Kim, Chang-Eun
C1  - Iowa State University
LA  - en
KW  - Collaborative Design
ER  -
TY  - JOUR
TI  - Touching Virtual Humans: Haptic Responses Reveal the Emotional Impact of Affective Agents
PY  - 2020
PB  - Institute of Electrical and Electronics Engineers
SN  - 1949-3045
T2  - IEEE Transactions on Affective Computing
DO  - 10.1109/taffc.2020.3038137
UR  - https://doi.org/10.1109/taffc.2020.3038137
DA  - 2020-11-13
AU  - Ahmed, Imtiaj
C1  - Department of Computer Science, University of Helsinki, Helsinki, Finland
AU  - Harjunen, Ville
C1  - Department of Psychology and Logopedics, University of Helsinki, Helsinki, Finland
AU  - Jacucci, Giulio
C1  - Department of Computer Science, University of Helsinki, Helsinki, Finland
AU  - Ravaja, Niklas
C1  - Department of Psychology and Logopedics, University of Helsinki, Helsinki, Finland
AU  - Ruotsalo, Tuukka
C1  - Department of Computer Science, University of Helsinki, Helsinki, Finland
AU  - Spapé, Michiel
C1  - Department of Psychology and Logopedics, University of Helsinki, Helsinki, Finland
LA  - en
KW  - Emotional expression
KW  - Immersion
KW  - Affect
VL  - 14
IS  - 1
SP  - 331
EP  - 342
AB  - Interpersonal touch is critical for social-emotional development and presents a powerful modality for communicating emotions. Virtual agents of the future could capitalize on touch to establish social bonds with humans and facilitate cooperation in virtual reality (VR). We studied whether the emotional expression of a virtual agent would affect the way humans touch the agent. Participants were asked to hold a pressure-sensing tube presented as the agent's arm in VR. Upon seeing the agent's emotional expression change, participants briefly squeezed the arm. The effect of emotional expressions on affective state was measured using self-reported valence and arousal as well as physiology-based indices. Onset, duration, and intensity of the squeeze were recorded to examine the haptic responses. Emotional expression of agents affected squeeze intensity and duration through changes in emotional perception and experience. Haptic responses may thus provide an implicit measure of persons' experience towards their virtual companion.
ER  -
TY  - JOUR
TI  - Virtual reality simulator for scoliosis surgery training: Transatlantic collaborative tests
PY  - 2008
T2  - IEEE International Workshop on Haptic Audio visual Environments and Games
DO  - 10.1109/have.2008.4685289
UR  - https://doi.org/10.1109/have.2008.4685289
DA  - 2008-10-01
AU  - Cote, Melissa
C1  - Department of Computer Engineering, Ecole polytechnique, Montreal, QUE, Canada
C1  - Research Center, Sainte-Justine University Hospital Center, Montreal, QUE, Canada
AU  - Boulay, Jacques-Andre
C1  - Department of Computer Engineering, Ecole polytechnique, Montreal, QUE, Canada
C1  - Research Center, Sainte-Justine University Hospital Center, Montreal, QUE, Canada
AU  - Ozell, Benoı̂t
C1  - Department of Computer Engineering, Ecole polytechnique, Montreal, QUE, Canada
AU  - Labelle, Hubert
C1  - Research Center, Sainte-Justine University Hospital Center, Montreal, QUE, Canada
AU  - Aubin, Carl-Eric
C1  - Department of Computer Engineering, Ecole polytechnique, Montreal, QUE, Canada
C1  - Research Center, Sainte-Justine University Hospital Center, Montreal, QUE, Canada
LA  - en
SP  - 1
EP  - 6
ER  -
TY  - JOUR
TI  - Transcending from Virtual Reality into Tele-Immersive Technologies and Applications
PY  - 2008
PB  - Association for Computing Machinery
SN  - 1530-2180
T2  - Ubiquity
DO  - 10.1145/1403922.1399615
UR  - https://doi.org/10.1145/1403922.1399615
DA  - 2008-06-01
AU  - Singh, Ramesh
C1  - National Informatics Centre, New Delhi, India
AU  - Singh, Anubhav
C1  - National Institute of Technology, Surat, India
LA  - en
KW  - Immersion
KW  - Converse
KW  - Immersive technology
KW  - Videoconferencing
KW  - Teleconference
KW  - Instructional simulation
VL  - 2008
IS  - June
SP  - 3
EP  - 3
ER  -
TY  - BOOK
TI  - The Resonant Interface: HCI Foundations for Interaction Design
PY  - 2007
DA  - 2007-03-15
AU  - Heim, Steven
LA  - en
KW  - Interface (matter)
KW  - Interface design
ER  -
TY  - JOUR
TI  - Haptic Shared Control for Human-Robot Collaboration: A Game-Theoretical Approach
PY  - 2020
PB  - Elsevier BV
SN  - 2405-8963
T2  - IFAC-PapersOnLine
DO  - 10.1016/j.ifacol.2020.12.2751
UR  - https://doi.org/10.1016/j.ifacol.2020.12.2751
DA  - 2020-01-01
AU  - Musić, Selma
C1  - Chair of Information-oriented Control, Technical University of Munich, Munich, Germany
AU  - Hirche, Sandra
C1  - Chair of Information-oriented Control, Technical University of Munich, Munich, Germany
LA  - en
KW  - Human–robot interaction
VL  - 53
IS  - 2
SP  - 10216
EP  - 10222
AB  - Complementing human and robot capabilities is essential for many tasks, e.g. rehabilitation and collaborative manufacturing. However, it is still not clear how control between humans and robots should be shared in order to ensure efficient task execution and intuitive interaction. Game theory seems as a promising mathematical framework that allows: i) posing this challenge as a dynamic negotiation (game) among human and robot (players) and ii) solving it to obtain optimal solution. In this work, we propose a differential game-theoretic shared control approach for human-robot haptic collaboration with Nash equilibrium optimal solution. We validate the proposed approach experimentally in a scenario where human is physically coupled with a haptic device and interacts with a virtual reality to perform a trajectory tracking task.
ER  -
TY  - JOUR
TI  - Object manipulation in visuo-haptic augmented reality with physics-based animation
PY  - 2010
DO  - 10.1109/roman.2010.5598707
UR  - https://doi.org/10.1109/roman.2010.5598707
DA  - 2010-09-01
AU  - Aleotti, Jacopo
C1  - [RIMLab-Robotics and Intelligent Machines Laboratory, Dipartimento di Ingegneria dell'Informazione, University of Parma, Italy]
AU  - Denaro, Francesco
C1  - [RIMLab-Robotics and Intelligent Machines Laboratory, Dipartimento di Ingegneria dell'Informazione, University of Parma, Italy]
AU  - Caselli, Stefano
C1  - [RIMLab-Robotics and Intelligent Machines Laboratory, Dipartimento di Ingegneria dell'Informazione, University of Parma, Italy]
LA  - en
KW  - Work space
KW  - Virtual image
KW  - Stereotaxy
KW  - Representation
SP  - 38
EP  - 43
ER  -
TY  - JOUR
TI  - Implementation of virtual reality systems for simulation of human-robot collaboration
PY  - 2018
PB  - Elsevier BV
SN  - 2351-9789
T2  - Procedia Manufacturing
DO  - 10.1016/j.promfg.2018.01.023
UR  - https://doi.org/10.1016/j.promfg.2018.01.023
DA  - 2018-01-01
AU  - Rückert, Patrick
C1  - University of Bremen, Bremen Insitute for Mechanical Engineering, Badgasteiner Str. 1, 28359 Bremen, Germany
AU  - Wohlfromm, Laura
C1  - University of Bremen, Bremen Insitute for Mechanical Engineering, Badgasteiner Str. 1, 28359 Bremen, Germany
AU  - Tracht, Kirsten
C1  - University of Bremen, Bremen Insitute for Mechanical Engineering, Badgasteiner Str. 1, 28359 Bremen, Germany
LA  - en
KW  - Adaptability
KW  - Immersion
VL  - 19
SP  - 164
EP  - 170
AB  - A collaboration between human and robot can implicate many advantages for complex industrial assembly processes, especially as increased flexibility and adaptability become a key feature of production systems. The use of virtual reality (VR) systems has the potential to simulate cooperative processes in advance and to include workers and their individual behavior into the simulation. The use of VR simulations makes it possible to secure processes and reduce physical and mental barriers between human and robot. This paper presents a methodical approach for the implementation of systems for the virtual testing of collaborative assembly processes. Following the aim of replicating the assembly process with the highest possible immersion, a specific VR system is derived from an analysis of the assembly process. Core features of the system are the physical simulation of the assembly process, the integration of the robot control and a haptic feedback for the operator.
ER  -
TY  - JOUR
TI  - Multisensory platform for surgical simulation
PY  - 1996
PB  - Institute of Electrical and Electronics Engineers
SN  - 1087-8270
T2  - Proceedings of the IEEE Virtual Reality Annual International Symposium
DO  - 10.1109/vrais.1996.490513
UR  - https://doi.org/10.1109/vrais.1996.490513
DA  - 1996-01-01
AU  - Yagel, Roni
C1  - Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA
AU  - Stredney, D
C1  - Ohio Supercomputer Center, Columbus, OH, USA
AU  - Wiet, Gregory
C1  - Department of Otolaryngology, Ohio State University Hospitals, Columbus, OH, USA
C1  - Ohio Supercomputer Center, Columbus, OH, USA
AU  - Schmalbrock, Petra
C1  - Department of Radiology, Ohio State University Hospitals, Columbus, OH, USA
AU  - Rosenberg, Louis
C1  - Immersion Corporation, San Jose, CA, USA
AU  - Sessanna, D
C1  - Ohio Supercomputer Center, Columbus, OH, USA
AU  - Kurzion, Yair
C1  - Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA
AU  - King, Samuel
C1  - Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA
LA  - en
KW  - Surgical simulation
VL  - 43
SP  - 72
EP  - 78
ER  -
TY  - JOUR
TI  - ChronoPilot — Modulating Time Perception
PY  - 2021
DO  - 10.1109/aivr52153.2021.00049
UR  - https://doi.org/10.1109/aivr52153.2021.00049
DA  - 2021-11-01
AU  - Botev, Jean
C1  - VR/AR Lab, University of Luxembourg, Esch-sur-Alzette, Luxembourg
AU  - Drewing, Knut
C1  - HapLab, Experimental Psychology Justus-Liebig University Giessen, Giessen, Germany
AU  - Hamann, Heiko
C1  - Institute of Computer Engineering University of Lübeck, Lübeck, Germany
AU  - Khaluf, Yara
C1  - Information Technology Group, Wageningen University and Research, Wageningen, Netherlands
AU  - Simoens, Pieter
C1  - ID Lab, Ghent University - imec, Ghent, Belgium
AU  - Vatakis, Argiro
C1  - Multi Time Lab, Panteion University, Athens, Greece
LA  - en
KW  - Affect
KW  - Time perception
SP  - 215
EP  - 218
AB  - Although time can be measured objectively, human time perception is remarkably subjective and influenced by cognitive states, individual motivations, and social factors. This malleability of perceived time can be evidenced, for instance, in stressful situations where one might experience a lack of time, while one might lose track of time in more relaxing circumstances. Based on fundamental knowledge from psychology and cognitive science, the ChronoPilot project aims at developing a prototype technology driven by artificial intelligence to extend or compress human subjective time adaptively and whenever required. Mediated-reality approaches, such as virtual and augmented reality, have enormous potential for presenting the users with visual, auditory, and haptic stimulation patterns that directly or indirectly influence their subjective time and which are difficult to reproduce in the real world. Going beyond individual settings, ChronoPilot will also investigate how to coordinate time plasticity in collaborative environments where one group member's actions may affect other members' perception. Different scenarios, where humans alone or humans and robots have to collaborate in realistic and virtual environments, will validate the planned research. In this paper, we present the fundamental concepts of our project ChronoPilot, which is a work in progress.
ER  -
TY  - JOUR
TI  - PhyShare: Sharing Physical Interaction in Virtual Reality
PY  - 2017
PB  - Cornell University
T2  - arXiv (Cornell University)
DO  - 10.48550/arxiv.1708.04139
UR  - https://doi.org/10.48550/arxiv.1708.04139
DA  - 2017-01-01
AU  - He, Zhenyi
C1  - New York University,New York,NY,USA
AU  - Zhu, Fengyuan
C1  - New York University,New York,NY,USA
AU  - Perlin, Ken
C1  - New York University, New York City, NY, USA,
LA  - en
KW  - Interface (matter)
AB  - We present PhyShare, a new haptic user interface based on actuated robots. Virtual reality has recently been gaining wide adoption, and an effective haptic feedback in these scenarios can strongly support user's sensory in bridging virtual and physical world. Since participants do not directly observe these robotic proxies, we investigate the multiple mappings between physical robots and virtual proxies that can utilize the resources needed to provide a well rounded VR experience. PhyShare bots can act either as directly touchable objects or invisible carriers of physical objects, depending on different scenarios. They also support distributed collaboration, allowing remotely located VR collaborators to share the same physical feedback.
ER  -
TY  - JOUR
TI  - Virtual Reality with Haptic Gloves for Human-robot Collaborative Assembly
PY  - 2025
DO  - 10.1109/arso64737.2025.11124945
UR  - https://doi.org/10.1109/arso64737.2025.11124945
DA  - 2025-07-17
AU  - Lin, Chih‐Jer
C1  - Graduate Institute of Automation Technology, National Taipei University of Technology,Taipei,Taiwan
AU  - Liu, Run
C1  - Graduate Institute of Automation Technology, National Taipei University of Technology,Taipei,Taiwan
LA  - en
KW  - Human–robot interaction
SP  - 355
EP  - 360
ER  -
TY  - JOUR
TI  - ViTAWiN - Developing Multiprofessional Medical Emergency Training with Mixed Reality
PY  - 2021
DO  - 10.1109/segah52098.2021.9551890
UR  - https://doi.org/10.1109/segah52098.2021.9551890
DA  - 2021-08-04
AU  - Schild, Jonas
C1  - Interactive Reality Experiences, Hochschule Hannover, Hannover, Germany
AU  - Elsenbast, Christian
C1  - Fraunhofer Institute for Experimental Software Engineering IESE, Kaiserslautern, Germany
AU  - Carbonell, Guillermo
C1  - Interactive Reality Experiences, Hochschule Hannover, Hannover, Germany
LA  - en
SP  - 1
EP  - 9
ER  -
TY  - JOUR
TI  - A New Virtual World? The Future of Immersive Environments in Anesthesiology
PY  - 2022
PB  - Lippincott Williams & Wilkins
SN  - 0003-2999
T2  - Anesthesia & Analgesia
DO  - 10.1213/ane.0000000000006118
UR  - https://doi.org/10.1213/ane.0000000000006118
DA  - 2022-07-05
AU  - Alam, Fahad
C1  - Collaborative Human ImmerSive Interaction Laboratory, Toronto, Ontario, Canada
C1  - Department of Anesthesia, Sunnybrook Health Sciences Centre
C1  - Department of Anesthesiology and Pain Medicine, University of Toronto, Toronto, Ontario, Canada
C1  - Sunnybrook Simulation Centre, Toronto, Ontario, Canada
C1  - Wilson Centre for Research in Medical Education, Temerty Faculty of Medicine, University of Toronto, Toronto, Ontario, Canada
AU  - Matava, Clyde
C1  - Collaborative Human ImmerSive Interaction Laboratory, Toronto, Ontario, Canada
C1  - Department of Anesthesia and Pain Medicine, Hospital for Sick Children, Toronto, Ontario, Canada.
C1  - Department of Anesthesiology and Pain Medicine, University of Toronto, Toronto, Ontario, Canada
LA  - en
VL  - 135
IS  - 2
SP  - 230
EP  - 238
AB  - See Article, page 220 Immersive virtual environments (IVEs), including virtual reality (VR) and augmented reality (AR), have gained immense popularity in medical education health care.1 Over the last 10 years, the expansion of gaming and development platforms, such as Unreal Engine and Unity, along with head-mounted displays (HMDs), has been fueled by major commercial interests, such as Meta, Microsoft, and Google, with huge investments in this immersive reality market. The immersive reality market is currently valued at 6.1 billion US dollars (USD) and is predicted to reach >20 billion USD by 2025.2 This commercial expansion has led to the rapid advancement of affordable, accessible, high-powered VR/AR technology and development tools supporting IVEs in medical education including anesthesia. IVEs date back to the early 19th century with the advent of the stereoscope. This ingenious device allowed 2 separate images, taken at slightly different angles, to be viewed as a single image with depth. The stereoscope led to the creation of a children's toy: the View-Master (View-Master Ideal Group, Inc), a pioneer for modern-day VR. Subsequently, the invention of the microchip represented a significant leap, leading to a myriad of devices and technologies that make up IVEs today. Virtual environments have been described in 2 domains: immersive (HMD-based) and nonimmersive (desktop-based). Nonimmersive, desktop-based virtual environments do not use an HMD, but instead, the participant controls and manipulates the virtual environment on a screen with a traditional keyboard and mouse or a joystick.3,4 Playing a video game on one's television screen using popular hardware such as the Sony PlayStation or the Microsoft Xbox is a basic example of desktop-based VR. In medical education, the American Society of Anesthesiologists (ASA) recently partnered with CAE Healthcare to create desktop-based virtual environments for managing anesthesia emergencies,5 which, when completed, fulfill the American Board of Anesthesiology Maintenance of Certification in Anesthesiology (MOCA) 2.0 Part 2 and 4 requirements.6 Although nonimmersive desktop-based virtual environments have been popular for decades and are an important part of our current medical education system, the focus of this article is on HMD-based IVEs. HMD-based IVEs have been described as "typically multi-modal in nature by providing a sense of immersion in the environment through 360° visuals by aid of an HMD, auditory stimulation through the use of earphones, and increasing the proprioception of limbs by way of controllers and tracking."4 Using HMDs, IVEs "transport" users to alternate simulated environments while creating a sense of immersion. Imagine playing a video game, but instead of watching it on a 2-dimensional screen, actually being transported into the game itself, akin to the experience of the characters in the movie "Jumanji." The HMDs used vary in complexity from simple cardboard-based stereoscopic lenses that pair with a mobile device to expensive helmets and goggles with advanced haptics. A tenet of IVE is presence. Presence is the extent to which a participant feels that they are submerged within the simulated IVE. Presence is a key term that describes the difference between VR and AR (Table). VR is the process of being completely immersed in a "new" environment (filmed or computer-generated), while AR overlays digital elements on real-life surroundings. As an example, VR would completely alter the sensory input of users via an HMD and transport them into a virtual trauma room, while AR would project, again via an HMD, a virtual patient into an actual real-world operating room (OR). Table. - Virtual Reality Versus Augmented Reality: Differences and Similarities Virtual Reality Augmented Reality Creates entire virtual world Creates a combination of virtual and real world Immersive Holographic Computer generated or filmed using 360° camera elements Computer-generated elements that are superimposed onto real life Requires a headset Requires multiple devices Immersed completely into the projected environment using a head-mounted display that completely suppresses the real world (eg, Google Cardboard and Oculus Rift) Immersed partially from screen-based devices with cameras (ie, smartphones, laptop, or tablet) using a head-mounted display with see-through lenses, allowing for visualization of the real world and virtual elements overlaid into it (eg, Microsoft Hololens) Object manipulation Object manipulation Only digital objects in virtual world Combines physical simulation with virtual objects Pricing Pricing Cost for creation and equipment can vary from a few hundred to thousands of dollars, depending on the level of immersion and complexity. Cost for creation and equipment can vary from a few hundred to thousands of dollars, depending on the level of immersion and complexity. In the same manner that IVEs have evolved from the stereoscope, Anesthesia & Analgesia has evolved over the past 100 years, from being the world's first anesthesia journal to one that is a leading source for innovation and education. Using lessons learned from other health care specialties and the non-health care industry, this article serves as a futuristic report that describes how IVEs, specifically VR and AR, can enhance medical training and subsequent delivery of patient care within the field of anesthesia. We suggest future directions and next steps in the evolution of this technology within the specialty of anesthesia. Technical aspects on "how-to" create and develop immersive environments are beyond the scope of this article; however, we hope to create excitement around the potential for the use of IVEs in anesthesia. IVEs AND ANESTHESIA EDUCATION Before the coronavirus disease 2019 (COVID-19) pandemic, the staple discourse in medical education included 3 prevalent themes. The first dealt with health care worker fatigue and working hour restrictions implemented to prevent human errors and to maintain learning.7 The second reflected the seismic shift in medical curriculums that have moved toward competency-based rather than time-based training.8 The third dominant theme revolved around the growing need for continuing education programs, especially considering recent retrospective literature, which has suggested correlations of increasing physician age and duration from graduation with patient complications.9,10 The result of these significant issues has tasked educators with finding innovative and effective methods to enhance learning curriculums. Despite this need, health care delivery continues to fall behind other service industries with regard to its investment into, and adoption of, new disruptive technologies. Furthermore, the COVID-19 pandemic has only accelerated the need for innovative educational approaches and emphasized the need for technology, including Zoom and Teams. IVE is a technology that is likely to grow beyond the pandemic.11,12 Discovering and using adjuncts to trainee curriculums and creating pathways to extend the reach of health care beyond the physical boundaries of the hospital are some of the new themes of medical education.11–13 Technical Skills Training for a career in anesthesiology requires expertise in both technical and nontechnical skills. The field of anesthesiology has led the way in creating and adapting mannequin-based simulation as a gold standard for training without risk to patients.14 However, to date, procedural dominant specialties such as surgery have pioneered the use of IVEs to teach and practice surgical skills and to instruct anatomy in an interactive manner.15,16 IVE-based anesthesia training has been reported for procedural areas such as bronchoscopy, central line insertion, and regional anesthesia simulators.17–20 Studies investigating such procedural training have shown that practicing technical skills in virtual environments can lead to effective knowledge acquisition and retention with subsequent successful clinical application.15,17 Furthermore, IVEs can be easily manipulated, allowing iterative skill-building within evolving virtual scenarios. If a trainee typically takes 50 attempts at intubation to become proficient, that goal may be achieved more quickly using a VR simulator that evolves in difficulty and variance. The learning curve would be enhanced because the scenarios change (as they would in the real world). However, they do so repeatedly, over a shorter time period compared to a traditional training system that would have the trainee wait hours for each surgery to complete before having a chance to perform another intubation procedure. Nontechnical Skills IVEs may have significant potential in teaching and assessing nontechnical skills, such as empathy, communication, and decision-making. At a basic level, observational learning, in which a learner watches a teacher demonstrate or model "correct" behavior or steps, has been used as a teaching tool for decades.21 However, with busier clinical environments, reduced trainee working hours, and amid pandemic-based restrictions, direct observation opportunities are also becoming limited.22,23 One solution to supplement observation learning is the use of VR-360 video (Figure 1). Asynchronously, we can use VR-360 cameras to film core concepts of a teaching curriculum for learners to view using HMDs, allowing them to feel as though they are physically present24 in the learning environment, learning from the teacher, when not there.25,26 Synchronously, such technology has been used to broadcast live surgeries to trainees when not present in the OR. VR-360 streams do not need advanced HMDs; instead, they can be viewed using simple HMDs such as the Google Cardboard combined with a user's mobile device.Figure 1.: VR-360 video of an operating room. This is a fisheye perspective, as it is not being viewed through an HMD (source: www.CHISIL.ca). HMD indicates head-mounted display.Filming core concepts of a teaching curriculum for learners to watch is not new. VR-360 videos have been used to create IVEs to raise the participation factor and improve the learning experience.25,27–30 Existing examples are already in place, such as the Oxford Medical Education lab (www.oxfordmedicaleducation.com) and the Collaborative Human ImmerSive Interaction Laboratory (CHISIL; www.chisil.ca) at the University of Toronto. These sites have released teaching programs in an effort to improve decision-making skills around topics such as advanced life support, trauma management, and cardiac arrest/code blue scenarios using VR-360 video simulations. Fully immersive computer-generated video game software mimicking clinical environments can also be used to effectively teach decision-making around uncommon crises, such as OR fires and malignant hyperthermia, and more common scenarios, such as trauma management, anaphylaxis, and obstetrical emergencies.31 Unlike passive VR-360 video, these advanced immersive crisis management "video games" require advanced HMDs to allow users to interact with their environment and the virtual components to respond to their actions. In these virtual environments, scenarios can change quickly or adapt to suit learners' needs or specific objectives. Virtual patients will improve or deteriorate in real time, depending on the actions taken by learners (Figure 2A). Like a video game, learners can "restart" and manage crises repeatedly with feedback processes built into the software. Furthermore, these scenarios can be recorded for future viewing or even observed live by a facilitator to provide coaching or assessment remotely (ie, from another location).Figure 2.: IVEs for clinical education. A, An advanced IVE depicting a trauma crisis with interactive avatars and responsive patients (source: www.CHISIL.ca). B, Dr Julian Wiegelmann demonstrates the use of augmented reality by using an HMD, converting the operating room into a crisis scenario with a virtual patient and responsive hemodynamics broadcast live on anesthesia monitors (source: www.Holosim.ca). HMD indicates head-mounted display; IVE, immersive virtual environment.Similarly, augmented virtual environments can make any physical space a virtual learning environment. For instance, at our local site, the onset of the pandemic required training and implementation of multidisciplinary COVID intubation teams within a short time frame. Using proprietary, locally developed AR software (www.HOLOSIM.ca), we converted our ORs and native monitoring equipment into virtual COVID care rooms with virtual patients requiring intubation and hemodynamic management (Figure 2B). Their simulated vitals were broadcast on our live OR monitors in response to the actions of the team. VALIDATING IVEs A significant challenge with IVEs is that their implementation may be outpacing the ability of the education community to validate them as effective teaching tools. Validation of IVEs for anesthesia by medical educators is vital to ensure they offer teaching interventions that align with curriculum goals using relevant educational frameworks. The current literature has shown that research in this field has been heterogeneous and lacks a basis in foundational learning theory.32,33 Opportunity exists to test and validate the use of IVEs for anesthesia education, including improved patient outcomes. To help advance appropriate validation when implementing a VR teaching program, medical educators should consider sound learning theory and learning outcomes as the structural foundation of the project. Learning theory, at its basic level, can be thought of as a foundation that helps achieve learning outcomes. Similar to biological research, it can be thought of as "biological plausibility." Like all new technologies, the urge to just "build an app" without really considering the learning outcomes and how intelligent design can best facilitate achieving these outcomes is a common setup in which this "just do" mentality will fail. Learning theory is a complex topic, but for this article, we highlight that one must consider normative and cognitive learning theories when designing immersive virtual applications. Normative theories emphasize that the educator must consider the type of learner they are targeting, and cognitive theories "are concerned with how the brain actively processes information to produce effective learning."34 Common theories in technology are multimedia design learning and cognitive load, meaning one must consider how learners process the new 3-dimensional audio and visual stimuli in immersive environments and how easily the content can be filtered by a learner and hence, absorbed.34 Our laboratory has developed a design framework called "LOOP" to be applied to every project. The designers are obliged to create based on sound learning theory, considering what learning outcomes the educator is aiming for, and to shape and guide the actual immersive software output (Figure 3).Figure 3.: LOOP framework. Design framework developed to advance appropriate validation when implementing IVE teaching programs by considering learning theory, desired learning outcomes and the actual immersive software output. AR indicates augmented reality; IVE, immersive virtual environment; VR, virtual reality.Future directions of anesthesia-based training with immersive environments and emerging educational areas for development include: (1) remote teaching/coaching, (2) teaching communication skills, and (3) equity, diversity, and inclusivity perspective learning. Using live broadcast features of VR-360 video, a teacher or expert may be capable of joining a health care team in a remote location by simply donning an HMD and linking digitally with their headset.35 The teacher or expert can then directly assist, in a digital "first-person" capacity, with procedures or decision-making during certain clinical crises to address specific clinical needs or offer learning opportunities. More work is warranted to determine the optimal method of coaching using learning theory in the context of these potential developments. Lessons can be learned from previous telesimulation-based studies and can be applied to immersive coaching. For instance, Burckett-St-Laurent et al36 (2016) used 2-dimensional screen-based telesimulation software to teach ultrasound-guided regional anesthesia skills. They incorporated the theories of observational learning and deliberate practice into their design to have a positive learning impact on their learners. This can be taken further and, as an example, developed into a virtual immersive teaching tool with which coaches and learners (in different geographical locations) can be immersed in the "same room" using VR. This way, the learner can simultaneously observe the expert demonstrating the skill and then practice under their direct supervision. This work is currently being done with ongoing investigations at our tertiary academic center of the University of Toronto. Furthermore, teaching communication skills using immersive and interactive virtual environments can potentially be a valuable tool.37 For instance, in one study, learners and practicing primary care providers interacted with avatars, and changes in simulated prescribing behaviors were seen in some of the primary care providers, despite participants knowing they were interacting with simulated patients.38 Thus, this can be applied to anesthesia clinic-based teaching curriculums. Virtual patients can be voiced by live facilitators in remote locations or respond to live learners when practicing communication techniques such as difficult conversations or history taking. However, even beyond this, technology is evolving so that computer-controlled patients can detect and respond appropriately to a live learner's communication technique with the appropriate sentiment. An important and often overlooked issue in the future of using immersive environments for teaching is a lack of diversity in anesthesia-based simulation training and the lack of diversity training as a whole. The literature has revealed that simulation technology has been limited in presenting the full spectrum of diversity seen in the general patient population.39,40 The use of VR, in which an avatar's appearance and responses can be easily altered, may allow clinicians to understand diversity and the culture in which they practice. A relatively simple but profound example would be learning intravenous cannulation in a dark-skinned patient. The potential for immersive VR-360 videos or entirely digitized interactive environments is significant in diversity training. The presence and the sense of immersion that these technologies provide may allow for a more empathetic perspective for the learner who can more realistically "walk in the shoes" of an individual from a very different background. Outside of medicine, it has been seen that White participants exhibited less implicit and unconscious bias scores after taking part in immersive VR experiences during which they were asked to embody characters that were a different skin color than their own while completing routine tasks.41–43 Furthermore, medical schools have used VR to allow their trainees to experience what their patients face when it comes to their illnesses and how they navigate the health system.44 This is a form of empathy training to familiarize medical students with information resources related to the health of older adults. Overall, through 360° videos, creating digital avatars, donning an HMD, and taking on the role of marginalized individuals and patients, health care providers can begin to take steps toward "feeling" what these groups experience. PATIENT EDUCATION In addition to medical education for health care workers, IVEs are beginning to disrupt clinical anesthesia management and health care delivery vis-à-vis patient engagement and education. IVEs show promise as interventions to reduce pain and anxiety and provide stress relief to patients. Studies have shown that IVEs viewed through HMDs can be an effective supplement to analgesic regimens of adult and pediatric patients undergoing wound dressing changes in burn management, in early labor pain, for dental procedures, intravenous insertion, procedures requiring sedation such as endoscopy, and for acute ischemic pain.45–50 Using IVEs for pain management has been mainly based on the principle of distraction through the sense of presence in another nonpainful or nonstressful environment.50 Functional magnetic resonance imaging studies have graphically revealed the additive effect on pain relief using distraction-based IVE.51 Currently, there are more questions than answers in this nascent field, and the issue of how to properly develop "pain curriculum"-based tools remains uncertain. To achieve complete "distraction," the patient should feel "present" in the simulated IVE they are viewing with the HMD. Questions of how best to achieve this using, for instance, computer-generated environments versus real-world VR-360 camera film, remain to be investigated. In addition, does the "dose" of IVE correlate to the sense of presence and realism of the IVE? In other words, how capable is the IVE of fully engaging the subject's mind, so it no longer relates to its actual location and becomes wholly engrossed within the new reality presented to it? Importantly, as with any pharmacological intervention, the optimal prescribing protocols for pain relief have yet to be delineated, and how their impact will vary with different presenting conditions must also be ascertained. Furthermore, most of these studies investigated acute pain conditions, and further research is needed to assess the optimal approach for using IVEs and their effectiveness in the chronic pain population. Commercial IVE software tools have been developed to target chronic pain specifically, but there is a dearth of literature and research in this specific area that needs to be addressed. Closely related to pain management are the conditions of anxiety and stress. Up to 90% of patients experience anxiety during the perioperative period, and this anxiety has been correlated with increased morbidity and, remarkably, mortality in the postoperative period.52 Research in psychiatry has already demonstrated that IVEs can be used to treat anxiety and posttraumatic stress disorder as well as to reduce stress.53–55 IVEs have been applied to the perioperative experience as a patient education tool. The literature has shown them to be an effective method to relieve anxiety and reduce stress for patients undergoing surgery.56 This evidence has provided clinicians and educators with a tempting target for nonpharmacological interventions using exposure therapy and distraction therapy. IVEs have been used as a form of exposure therapy by educating patients about their hospital experience with virtual tours of ORs or first-person point-of-view films of the procedure before they even set foot in a hospital.57 Other studies have used IVEs as a form of distraction to reduce patient anxiety during hospital admission and while undergoing procedures.58 Trying to demonstrate whether these reductions in subjective and objective anxiety measures may translate into improved clinical outcomes will be an enormous logistical undertaking, and so it remains an intriguing goal. Using the principles of accessibility and virtual presence described beforehand, future uses of IVEs in clinical management can leverage the advantage of dismantling geographic boundaries and connecting expertise to remote areas. The ability to virtually connect a physician with a remote patient and the added immersive first-person experience that traditional 2-dimensional video cannot offer can potentially change the practice of medicine significantly. Expert anesthesia providers located in urban hospital settings can use HMDs to assess rural patients for surgery without requiring either party to travel very far. Improving patient education and accessibility to care is another area in which VR may be of benefit. Immersive high-definition virtual broadcasting capabilities can allow health care providers to take part in a whole new manner of remote consultation for patients or postoperative care with family members who are not easily accessible. A provider can be immersed in the patient's 3D environment to truly appreciate the patient in their environment and overcome geographical barriers. Similarly, an anesthesiologist may not have to work independently all the time while in the OR, as a colleague, mentor, or teacher can be transported into their virtual setting to offer "just-in-time" coaching and teaching to help with a spectrum of issues, such as a specific clinical question, an unfamiliar or daunting clinical scenario, as well as an unanticipated clinical crisis. Overall, multidisciplinary teams with representation from both remote and larger tertiary centers as well as from the virtual software development and telecommunication industry are needed to collaborate on determining the gaps in remote education and care. They can then determine the optimal approach to create and scale these solutions for underserviced areas. In addition, IVEs may prove useful in the subject of brain health in the perioperative period. IVEs have been used in screening, diagnosing, and rehabilitation of memory deficits, and the neurocognitive literature has investigated the impact of IVEs on improving sleep patterns and cognitive impairments linked with age or trauma.59–63 IVEs have also been implemented as strategies to aid neurorehabilitation.53,64 A recent systematic review concluded that VR can be a tool for cognitive rehabilitation after brain injury.65 Extending these study designs to assess problems of brain health in the perioperative period, specifically, the profound malady of postoperative delirium, is another tantalizing possibility. Postoperative delirium is a widespread and highly debilitating condition that has a significant impact on mortality and results in a significant material burden to hospitals in terms of patient length of stay and labor requirements.63 IVEs are now being investigated as part of a multimodal approach in screening for and preventing cognitive impairments as well as treating delirium in critical care settings.65–68 Ideally, as these studies evolve, anesthesiologists will be able to use IVE software in their clinics to stratify delirium risk preoperatively, educate patients and their families about risks, and then implement a protocol (potentially with IVEs as a structural element) postoperatively to prevent or treat delirium. Imagine virtually transporting a delirious patient back into their home, where they can interact with their native environment and virtually present family? Overall, IVEs have the potential to be a positively disruptive technology in the anesthesia education and health care delivery fields. Development is happening at a rapid pace, fueled by the commercial industry. To ensure the optimal development of IVEs in the context of education, medical educators must guide this process using as its foundation sound learning theory and allowing for appropriate guidance by our end users: the learners. ACKNOWLEDGMENTS We thank Drs Lilia Kaustov, Julian Wiegelmann, Bill Kapralos, Paul McHardy, Jordan Tarshis, Stephen Choi, and Shelly Au, as well as Monica Caldeira and Kyle Wilcocks, for their help with our research programs. We are grateful to Khatidja Moloo for advanced edits of the manuscript. DISCLOSURES Name: Fahad Alam, MD, MHSC, FRCPC. Contribution: This author developed the initial idea and wrote the manuscript. Name: Clyde Matava, MBChB, DA, MMed. Contribution: This author completed advanced edits.
ER  -
TY  - JOUR
TI  - Virtual Reality Haptic Simulator for Endoscopic Sinus and Skull Base Surgeries
PY  - 2020
PB  - Lippincott Williams & Wilkins
SN  - 1049-2275
T2  - Journal of Craniofacial Surgery
DO  - 10.1097/scs.0000000000006395
UR  - https://doi.org/10.1097/scs.0000000000006395
DA  - 2020-04-16
AU  - Kim, Hyun
C1  - Department of Otolaryngology-Head and Neck Surgery, Seoul St. Mary's Hospital, College of Medicine, The Catholic University of Korea, Seoul
AU  - Kim, Hyun
C1  - Humancare Technology Center, Kyungpook National University, Daegu
AU  - Park, Jae‐Sung
C1  - Department of Neurosurgery, Seoul St. Mary's Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea.
AU  - Kim, Sung
C1  - Department of Otolaryngology-Head and Neck Surgery, Seoul St. Mary's Hospital, College of Medicine, The Catholic University of Korea, Seoul
C1  - reprint requests to Sung Won Kim, MD, PhD, Department of Otolaryngology-Head and Neck Surgery, Seoul St. Mary's Hospital, College of Medicine, The Catholic University of Korea, Banpo-daero 222, Seocho-gu, Seoul 137-701, Republic of Korea
LA  - en
KW  - Endoscope
KW  - Nostril
VL  - 31
IS  - 6
SP  - 1811
EP  - 1814
ER  -
TY  - JOUR
TI  - The Utility of Artificial Intelligence for Systematic Reviews and Boolean Query Formulation and Translation
PY  - 2023
PB  - Wolters Kluwer
SN  - 2169-7574
T2  - Plastic & Reconstructive Surgery Global Open
DO  - 10.1097/gox.0000000000005339
UR  - https://doi.org/10.1097/gox.0000000000005339
DA  - 2023-10-01
AU  - Alaniz, Leonardo
C1  - Department of Plastic Surgery, University of California Irvine Medical Center, Orange, Calif.
C1  - School of Medicine, University of California Irvine, Irvine, Calif.
AU  - Vu, Cindy
C1  - School of Medicine, University of California Irvine, Irvine, Calif.
AU  - Pfaff, Miles
C1  - Department of Plastic Surgery, University of California Irvine Medical Center, Orange, Calif.
C1  - Pediatric Plastic Surgery, Children's Hospital of California, Orange, Calif.
LA  - en
VL  - 11
IS  - 10
SP  - e5339
EP  - e5339
AB  - The formulation of precise search strings and syntax translation between databases is pivotal to a successful systematic review. By using the subscription-based ChatGPT,1 researchers can harness natural language processing to generate refined search strings and Boolean queries, streamlining the process and enhancing the accuracy of the systematic review. Although there are few publications addressing ChatGPT's utility as a general research aid,2–4 there are no reports on how ChatGPT-4 can be leveraged as a collaborative tool to collectively build a search string and translate Boolean queries into other database languages. We conducted a mock systematic review describing the utility of augmented and virtual reality systems for preoperative planning in craniosynostosis surgery. We compiled a list of medical subject heading [MeSH] terms and keywords relevant to the research question. Next, we incorporated ChatGPT-4 as a Boolean query aid to formulate an optimal PubMed search string (Table 1). Its first task was to analyze our study aim and provide additional databases to query for relevant articles. It then assisted us in refining our list of relevant MeSH terms and keywords for PubMed. Although it successfully added terms and enhanced our term list, researchers should still cross-reference MeSH terms with the database given ChatGPT-4's training cutoff date of 2021. (See table 1, Supplemental Digital Content 1, which shows a comprehensive list of original and modified MeSH terms and keywords. https://links.lww.com/PRSGO/C836.) Table 1. - ChatGPT-4 Prompts and Query Formulation Results Step Prompt Response PubMed Yield 1 We are conducting a systematic review and meta-analysis describing the utility of augmented and virtual systems for preoperative planning in craniosynostosis surgery. We are first going to start with a search on PubMed and then proceed to other databases. We have two questions: To ensure we include as most relevant articles as possible and as few irrelevant articles as possible, which other databases (aside from PubMed), can we conduct a literature search on? [provided our original MeSH terms and keywords] What other MeSH Terms or keywords available on PubMed, can we add to include a more comprehensive search and ensure we don't miss any key articles? What MeSH Terms or keywords from the list above should we remove to ensure we obtain as few irrelevant articles as possible? Certainly! Your existing search strategy seems quite comprehensive already. Here are some additional suggestions for other databases, as well as potentially relevant MeSH terms and keywords.1. Other databases you might want to consider include: Embase, Web of Science, Cochraine Library, IEEE Xplore, ACM Digital Library, CINAHL, Scopus, and Google Scholar2. MeSH terms and keywords:-For the Anatomical Area/Procedure, consider adding MeSH terms and keywords like:• MeSH terms: "Skull"[Mesh], "Cranial Sutures"[Mesh]• Keywords: suturectomy, craniofacial anomalies-For preoperative planning:• MeSH terms: "Preoperative Care"[Mesh], "Neuronavigation"[Mesh], "Computer Simulation"[Mesh]• Keywords: preoperative simulation, surgical simulation, preoperative assessment, surgical rehearsal-For augmented reality and virtual reality:• MeSH Terms: "Computer Simulation"[Mesh], "Imaging, Three-Dimensional"[Mesh]• Keywords: Computer-assisted surgery, mixed reality, haptic feedback, 3D simulation, 3D printing — 2 Based on the following list of MeSH terms and key words, can you create a Boolean Query (ie, search string) for PubMed to ensure we maximize the number of relevant articles and minimize the number of irrelevant articles? Remember, this is for a systematic review describing the utility of augmented and virtual systems for preoperative planning in craniosynostosis surgery. In other words, we are interested in assessing how virtual or augmented reality can help with planning for craniosynostosis. Please use Boolean operators, search field tags, proximity searching, and wildcards as needed to optimize the search. [We then provided updated list of MeSH Terms and Key Words with modifications from Step 1.] Sure, I can help create a search strategy using Boolean operators, search field tags, proximity searching, and wildcards.(("Craniosynostoses"[Mesh] OR "Skull"[Mesh] OR "Cranial Sutures"[Mesh] OR "Sagittal Synostosis"[Tiab] OR "Coronal Synostosis"[Tiab] OR "Metopic Synostosis"[Tiab] OR "Craniosynostosis"[Tiab] OR "Suturectomy"[Tiab] OR "Craniofacial Anomalies"[Tiab]) AND ("Surgical Navigation Systems"[Mesh] OR "Preoperative Care"[Mesh] OR "Neuronavigation"[Mesh] OR "Computer Simulation"[Mesh] OR "Preoperative Planning"[Tiab] OR "Virtual Surgical Planning"[Tiab] OR "Preoperative Simulation"[Tiab] OR "Surgical Simulation"[Tiab] OR "Preoperative Assessment"[Tiab] OR "Surgical Rehearsal"[Tiab])AND("Augmented Reality"[Mesh] OR "Computer Simulation"[Mesh] OR "Imaging, Three-Dimensional"[Mesh] OR "Virtual Reality"[Mesh] OR "Augmented Reality"[Tiab] OR "AR"[Tiab] OR "Computer-Assisted Surgery"[Tiab] OR "Mixed Reality"[Tiab] OR "Haptic Feedback"[Tiab] OR "3D Simulation"[Tiab] OR "3D Printing"[Tiab] OR "Virtual Reality"[Tiab] OR "VR"[Tiab])) 766 3 This search strategy resulted in too many results: 766, many of which are irrelevant. Can you help refine the search strategy to focus our results and minimize irrelevant studies? Perhaps you can try removing and/or changing some of the more general MeSH terms simply into keywords if you think that is a good idea. Certainly, here's a revised strategy:("Craniosynostoses"[Mesh] OR "Skull"[Mesh] OR "Sagittal Synostosis"[tiab] OR "Coronal Synostosis"[tiab] OR "Metopic Synostosis"[tiab] OR "Craniosynostosis"[tiab] OR "Suturectomy"[tiab]) AND ("Surgical Navigation Systems"[Mesh] OR "Preoperative Care"[Mesh] OR "Neuronavigation"[Mesh] OR "Computer Simulation"[Mesh] OR "Preoperative Planning"[tiab] OR "Virtual Surgical Planning"[tiab] OR "Preoperative Simulation"[tiab] OR "Surgical Simulation"[tiab] OR "Preoperative Assessment"[tiab] OR "Surgical Rehearsal"[tiab]) AND ("Augmented Reality"[Mesh] OR "Imaging, Three-Dimensional"[Mesh] OR "Virtual Reality"[Mesh] OR "Augmented Reality"[tiab] OR "AR"[tiab] OR "Computer-Assisted Surgery"[tiab] OR "Mixed Reality"[tiab] OR "3D Simulation"[tiab] OR "3D Printing"[tiab] OR "Virtual Reality"[tiab] OR "VR"[tiab]) 435 4 Can you translate the following PubMed search string into search strings that can be used for the following databases: Embase, Web of Science, Cochrane Library, IEEE Xplore, ACM Digital Library, Scopus, and Google Scholar. Please be as accurate as possible, and do not add additional terms that were not included in the original search string unless it is really needed. Please note that although I'm translating your search string, the databases you mentioned may not support MeSH terms or the same level of Boolean logic as PubMed does. Also, it's important to note that each database has its own unique search functionality, which may require adjustments to the syntax. Below are approximations for the search strings in each of the databases. [See Figure 1 for example of translations] - Its next task was to formulate a Boolean query for PubMed, which was comprehensive and yielded 766 results. After instructing it to minimize the number of irrelevant articles, ChatGPT-4 changed certain MeSH terms to keywords and added field tags, yielding 435 results. ChatGPT-4's final task was to translate the PubMed Boolean query into a search string compatible with other databases (Fig. 1). All translated search strings were reliable and produced relevant results. Google Scholar, as ChatGPT-4 warned, was the only exception, as it does not support search strings.Fig. 1.: Translation of search string from PubMed to other databases.To confirm the generalizability across diverse topics, we implemented our process on existing systematic reviews published in Plastic and Reconstructive Surgery within the reconstructive and cosmetic sections. (See table 2, Supplemental Digital Content 2, which shows five validation examples. https://links.lww.com/PRSGO/C837.) Our process was successfully able to recreate comprehensive search strategies and Boolean query translations that aligned with the author-generated strategies. Although the power of large language models (LLM's) can allow human researchers to focus their efforts on study methodology and data analysis, it is essential to proceed cautiously. Many LLM's training datasets have a cut-off date (eg, 2021) and can therefore result in incomplete information. As such, researchers should always verify AI-assisted work and references to ensure both accuracy and relevance.5 At all times, the use of AI tools must be disclosed to ensure transparency, and they cannot be authors of any produced content. Although ChatGPT should not replace researchers, we have demonstrated how it can enhance and streamline the process of conducting thorough literature searches. Ultimately, the collaborative effort between AI and human expertise has the potential to augment research output. DISCLOSURE The authors have no financial interest to declare in relation to the content of this article.
ER  -
TY  - JOUR
TI  - Healthcare Metaverse: Applications, Challenges, and Future Development
PY  - 2023
PB  - RELX Group (Netherlands)
SN  - 1556-5068
T2  - SSRN Electronic Journal
DO  - 10.2139/ssrn.4637901
UR  - https://doi.org/10.2139/ssrn.4637901
DA  - 2023-01-01
AU  - Rane, Nitin
C1  - University of Mumbai
AU  - Choudhary, Saurabh
C1  - University of Mumbai
AU  - Rane, Jayesh
C1  - University of Mumbai
LA  - en
KW  - Metaverse
ER  -
TY  - JOUR
TI  - Immersidata Management: Challenges in Management of Data Generated within an Immersive Environment.
PY  - 1999
DA  - 1999-01-01
AU  - Shahabi, Cyrus
AU  - Barish, Greg
AU  - Ellenberger, Brian
AU  - Kolahdouzan, Mohammad
AU  - Jiang, Ning
AU  - Nam, Seong-Rim
AU  - Zimmermann, Roger
C1  - University of Southern California
LA  - en
KW  - Implementation
KW  - Data type
SP  - 107
EP  - 114
ER  -
TY  - JOUR
TI  - Dissection laboratory is vital to medical gross anatomy education
PY  - 2004
PB  - Wiley
SN  - 1552-4906
T2  - The Anatomical Record Part B The New Anatomist
DO  - 10.1002/ar.b.20039
UR  - https://doi.org/10.1002/ar.b.20039
DA  - 2004-11-01
AU  - Granger, Noelle
C1  - Department of Cell and Developmental Biology, 302 Taylor Hall, CB#7090, University of North Carolina, Chapel Hill, NC 27599
C1  - Dr. Granger has taught human anatomy for 23 years in the University of North Carolina School of Medicine, where she directs the first-year medical course “Human Anatomy, Embryology and Imaging” and teaches histology. Her research has focused on invertebrate development endocrinology, but she now does educational research as well.
C1  - Fax: 919-966-1856
LA  - en
KW  - Gross anatomy
VL  - 281B
IS  - 1
SP  - 6
EP  - 8
AB  - The medical anatomy course has become a complex and complicated educational experience, in which dissection of the human body instructs not only in structure and function, but also in psychosocial areas critical to the development of the whole physician (Dyer and Thorndike, 2000; Gregory and Cole, 2002; Rizzolo, 2002). As the need to teach newer areas (such as molecular biology, cell biology, and medical genetics) has severely compressed the time spent in the dissection laboratory, and a generation of anatomists has reached retirement age without replacement (Marks, 1996; Fitzharris, 1998; Cottam, 1999; Parker, 2002), elimination of dissection is seen as one way to resolve these pressures. Can an anatomy course fulfill its objectives if it no longer includes dissection, using instead two- or three-dimensional virtual representations and computer-assisted learning programs? I would argue that it cannot. I have listed the major reasons why I believe dissection is so important to the learning of anatomy and the creation of the mature physician, gleaned from my own experiences and that of many in the field more eloquent than I, including some of the thoughts of students at the University of North Carolina School of Medicine. Student quotations are taken from e-mails sent to me in response to the Los Angeles Times article “Cutting Out the Cadaver” (Zarembo, 2004). Roman numerals refer to the student's medical school (MS) educational level. Dissection teaches the following: Patients are three-dimensional beings, changing as they age. It is in the dissection laboratory where students form their ideas and mental images of the structure of the human body at different levels over time (Marks, 2000). There is little educational research on how students learn three dimensionally, but it is clear that education on real cadavers allows them to recall this information on demand (Moore, 1998). “Although it is true that much of what we learn in our first 2 years has nothing to do with clinical medicine, dissection does …. The only way to truly know the body is to get up close and personal with it … to feel the tendons and nerves, the fascia and the vessels. There are times when I have to do a femoral stick or an a-line or a central line and I remember the anatomy not from some picture but from what I saw during my own dissection” (MS IV student). The dissection laboratory is the only place where the three-dimensional structure of the human body is reinforced by visual, auditory, and tactile pathways (Mutyala and Cahill, 1996; Aziz et al., 2002). A simulated haptic experience that can adequately replace dissection of the cadaver is not yet available and may not be for many years. “I can't figure out why technology is so often championed as a substitute rather than a supplement in anatomy when, after all, a patient is human—with smells and fluids and all the ‘dirty’ stuff …. When a baby is being delivered in my arms, pointing and clicking on a computer screen will not help me” (MS IV student). The dissection laboratory is the only place where the three-dimensional structure of the human body is reinforced by visual, auditory, and tactile pathways. A simulated haptic experience that can adequately replace dissection of the cadaver is not yet available and may not be for many years. The dissection laboratory provides an introduction to the variability of the human body and the uniqueness of each cadaver. Discussions of variability have been dropped from many of the current textbooks, and lack of this information, or even of an awareness of variability, can lead to misdiagnosis and malpractice (Willan and Humpherson, 1999). “For me, one of the most important lessons I learned in anatomy was that a vast range of structures are considered normal (or at least will never cause dysfunction)” (MS III student). Terminologica anatomica (Federative Committee on Anatomical Terminology, 1998) is the anatomical vocabulary used throughout medical training and practice, and the use of this terminology facilitates a common discourse about anatomy in both healthy and diseased patients (Whitmore, 1999; Rosse, 2001). It is in the dissection laboratory that this vocabulary is acquired and learned, not by rote memorization, but by conceptualization based on what is seen and felt. The routine performance of dissection provides students with training in spatial appreciation and orientation and in the use of instruments. Most of these are directly related to surgery, but the acquired skill in eye-hand coordination and manual dexterity is relevant in a variety of clinical settings (Moore, 1998; Newell, 1999; Ellis, 2001). The normally small dissection groups force students early on in their professional education to communicate effectively, engage in cooperative interaction, and utilize “both self-directed and directed self-learning” (Newell, 1999). This establishes the routine by which they will continue to work, as a part of a medical team in many different practice settings (Moore, 1998; Aziz et al., 2002). In addition, the bonding of the dissection team fosters coping with the distress of the laboratory (Coulehan et al., 1995) and the stress of the first year of medical school. “I feel gross anatomy was like deriving the equation instead of being handed the equation” (MS III student). “Sharing the struggle of assimilating tons of information, learning a new ‘language’ and dealing with the implications and magnitude of dissecting a human being is, in my opinion, one of the more formative experiences in the first 2 years of medical school” (MS IV student). Their first encounter with a cadaver establishes for the students the reality of a human life, connects them to their ultimate objective—the living patient—and confronts them with the tremendous responsibility they will assume in treating that patient as their physician (Coulehan et al., 1995; Aziz et al., 2002). The anatomy dissection laboratory is often where the process of professional acculturation is initiated, fostering knowledge, skills, attitudes, values, and behaviors that will enable physicians to function appropriately within their chosen discipline. “It is the only course in the first 2 years that makes explicit the privilege and challenge of being a physician, because only the anatomy lab teaches you to be intimate with the bodies of strangers” (MD graduate, class of 2004). Introduction of the concepts of humanistic care in a medical curriculum is a formidable task in the face of increasing educational technology and procedurally based patient treatment. The anatomy laboratory is where this education can begin, with attention to end-of-life issues and to opportunities for student expression of their emotions and attitudes (Rizzolo, 2002). The students' emotional responses to their cadaver and, for many, their first confrontation with death and dying present a true teaching opportunity. “Compassion and true understanding go hand in hand, and it is only with a hands on dissection (as messy and smelly and frustrating as it may get) that both may be maximized” (MS III student). Memorial services for the donors are standard ritual in many curricula (Tchernig and Pabst, 2001). Thus, the dissection laboratory plays an essential role in “initiating a balanced attitude to death and dying in trainee medical doctors” (Tchernig et al., 2000). “I never want to dissect again. But I also recognize what an amazing experience this was. Someone gave herself to me. She forced me to confront death in a very real way, a way that I will have to contend with as a future physician …. Dissection was a critical part of my development of compassion towards my future patients” (MS II student). It is interesting to note that the University of Washington discontinued full dissection in the 1970s and made the dissection laboratory an elective. Dissection returned to the curriculum 2 years later, when nearly 90% of their students signed up for the elective (Clark, 2003). Would this happen today, with the wealth of computer programs available to replace dissection? Perhaps so. A recent study at the Rush Medical School indicated that even the students who dissect little (30 h total) sense that this process is somehow important to their training (Dinsmore et al., 1999). A far better measure of the students' anatomical knowledge than the United States Medical Licensing Examination (USMLE) part 1 score is the measure of the clerkship and residency directors who subsequently train them. In a recent study, a majority of the reporting residency program directors felt that gross anatomy was either extremely important or very important to the mastery of their discipline, and 57% of them felt residents needed a refresher course in gross anatomy upon arrival (Cottam, 1999). Is this situation only going to worsen if dissection is no longer part of an anatomy course? This article is one of four invited papers that address the following question in a moderated debate format: “To what extent is dissection necessary in the learning of medical gross anatomy?” These articles were published in the November 2004 issue of The Anatomical Record Part B: The New Anatomist (Vol. 281B#1, pp 2–14). These articles can also be accessed online through our virtual issue on dissection and medical education (www.wiley.com/anatomy/dissection).
ER  -
TY  - JOUR
TI  - Augmented Virtuality in a Digital Learning Factory for Collaborative Robotics
PY  - 2021
PB  - RELX Group (Netherlands)
SN  - 1556-5068
T2  - SSRN Electronic Journal
DO  - 10.2139/ssrn.3858350
UR  - https://doi.org/10.2139/ssrn.3858350
DA  - 2021-01-01
AU  - Sievers, Torsten
C1  - University of Bremen, Bremen Institute of Mechanical Engineering (bime)
AU  - Neumann, Florian
C1  - University of Bremen - Bremen Institute of Mechanical Engineering
AU  - Tracht, Kirsten
C1  - University of Bremen - Bremen Institute of Mechanical Engineering
LA  - en
KW  - Virtuality (gaming)
KW  - Factory (object-oriented programming)
ER  -
TY  - JOUR
TI  - Could engineers work in the metaverse?
PY  - 2022
PB  - Institution of Engineering and Technology
SN  - 1750-9637
T2  - Engineering & Technology
DO  - 10.1049/et.2022.0408
UR  - https://doi.org/10.1049/et.2022.0408
DA  - 2022-05-01
AU  - Pozniak, H.
LA  - en
KW  - Metaverse
VL  - 17
IS  - 4
SP  - 99
EP  - 106
ER  -
TY  - CHAP
TI  - QoE Assessment of Cooperative Work in Networked Virtual Reality Environment with Haptic Sense: Influence of Network Latency
PY  - 2024
PB  - Springer International Publishing
SN  - 2367-3389
T2  - Lecture notes in networks and systems
DO  - 10.1007/978-981-97-6103-6_6
UR  - https://doi.org/10.1007/978-981-97-6103-6_6
DA  - 2024-01-01
AU  - Win, Khaing
AU  - Ishibashi, Yutaka
AU  - Win, Khaing
LA  - en
SP  - 69
EP  - 83
ER  -
TY  - JOUR
TI  - Path planning of an AFM-based nanomanipulator using virtual force reflection
PY  - 2005
DO  - 10.1109/iros.2004.1389414
UR  - https://doi.org/10.1109/iros.2004.1389414
DA  - 2005-04-01
AU  - Arnmi, M.
C1  - Laboratoire Vision et Robotique, Université d'Orlénas, Bourges, France
AU  - Ferreira, Antoine
C1  - Laboratoire Vision et Robotique, Université d'Orlénas, Bourges, France
LA  - en
KW  - Planner
KW  - Obstacle avoidance
KW  - Operator (biology)
KW  - Reflection
ER  -
TY  - JOUR
TI  - Haptic-Feedback Ring Enabled Human-Machine Interface (HMI) Aiming at Immersive Virtual Reality Experience
PY  - 2021
DO  - 10.1109/transducers50396.2021.9495698
UR  - https://doi.org/10.1109/transducers50396.2021.9495698
DA  - 2021-06-20
AU  - Sun, Zhongda
C1  - SIMTech-NUS Joint Lab on Large-area Flexible Hybrid Electronics, National University of Singapore, Singapore
AU  - Zhu, Minglu
C1  - SIMTech-NUS Joint Lab on Large-area Flexible Hybrid Electronics, National University of Singapore, Singapore
AU  - Chen, Zhaocong
C1  - National University of Singapore Suzhou Research Institute (NUSRI),China,215123
AU  - Shan, Xuechuan
C1  - SIMTech-NUS Joint Lab on Large-area Flexible Hybrid Electronics, National University of Singapore, Singapore
AU  - Lee, Chengkuo
C1  - SIMTech-NUS Joint Lab on Large-area Flexible Hybrid Electronics, National University of Singapore, Singapore
LA  - en
KW  - Interface (matter)
KW  - Nanogenerator
SP  - 333
EP  - 336
ER  -
TY  - JOUR
TI  - I’m in Control! Transferring Object Ownership Between Remote Users with Haptic Props in Virtual Reality
PY  - 2021
T2  - Symposium on Spatial User Interaction
DO  - 10.1145/3485279.3485287
UR  - https://doi.org/10.1145/3485279.3485287
DA  - 2021-10-27
AU  - Auda, Jonas
C1  - HCI Group, University of Duisburg-Essen, Germany
AU  - Busse, Leon
C1  - LMU Munich, Germany
AU  - Pfeuffer, Ken
C1  - Bundeswehr University Munich, Germany
AU  - Gruenefeld, Uwe
C1  - University of Duisburg-Essen, Germany
AU  - Rivu, Radiah
C1  - Bundeswehr University Munich, Germany
AU  - Alt, Florian
C1  - Bundeswehr University Munich, Germany
AU  - Schneegaß, Stefan
C1  - HCI Group, University of Duisburg-Essen, Germany
LA  - en
KW  - Virtual image
ER  -
TY  - DATA
TI  - Evaluation of New Collaboration method in Virtual Reality Game based on Human Haptic Emotion for Artificial Life Simulation
PY  - 2008
T2  - PsycEXTRA Dataset
DO  - 10.1037/e602152011-033
UR  - https://doi.org/10.1037/e602152011-033
DA  - 2008-01-01
AU  - Basori, Ahmad
AU  - Daman, Daut
AU  - Bade, Abdullah
AU  - Sunar, Mohd
LA  - en
KW  - Artificial life
ER  -
TY  - JOUR
TI  - Collaborative virtual training using force feedback devices
PY  - 2004
DO  - 10.1109/sibgra.2004.1352978
UR  - https://doi.org/10.1109/sibgra.2004.1352978
DA  - 2004-11-30
AU  - Rodriguês, Maria
C1  - Centro de Ciencias Tecnologicas, Univ. de Fortaleza, Brazil
AU  - Chaves, Ricardo
C1  - Centro de Ciencias Tecnologicas, Univ. de Fortaleza, Brazil
AU  - da Silva, Wagner
C1  - Universidade de Fortaleza (Unifor),  Brasil
LA  - en
KW  - Joystick
KW  - Extensibility
KW  - Input device
SP  - 332
EP  - 339
AB  - Force feedback plays an important role in collaborative virtual reality environments, mainly for programmers of haptic visualization tools. Whereas a great deal of work has gone into graphical displays over the past years, little has changed on the input side. One of the problems that has slowed down development in this area is the difficulty of integrating the visualization of a scene, the interaction of the user with the scene, the feeling for the user to be immersed inside the scene, and finally, the input devices. We describe the architecture we have designed, implemented and tested for a collaborative virtual training using force feedback devices. In particular, it provides device independence and easy extensibility through a compartmentalized and multilayered model. We also present examples of how force feedback joysticks can be integrated into training exercises using our prototype.
ER  -
TY  - LETTER
TI  - Metaverse in diagnosis of skin diseases
PY  - 2022
PB  - Wiley
SN  - 1473-2130
T2  - Journal of Cosmetic Dermatology
DO  - 10.1111/jocd.15409
UR  - https://doi.org/10.1111/jocd.15409
DA  - 2022-09-24
AU  - Kumari, Jyoti
C1  - Silchar Medical College and Hospital, Silchar, India
AU  - Das, Kinnor
C1  - Consultant Dermatolgist, Apollo clinic, Silchar, India
AU  - Goldust, Mohamad
C1  - Department of Dermatology, University Medical Center Mainz, Mainz, Germany
LA  - en
KW  - Metaverse
VL  - 22
IS  - 2
SP  - 698
EP  - 699
AB  - The metaverse is the upcoming frontier in human connectivity. It is a post-reality cosmos that combines the physical world with digital virtuality in a continuous and enduring multiuser environment. The metaverse is an augmented reality (AR)/virtual reality (VR) interface where users may interact with other users in a digitally enhanced reality while being fully immersed in visual, aural, and haptic senses. Artificial intelligence (AI), AR, and VR are three important technical advances that have come together to create the metaverse, which opens up entirely new channels for providing healthcare, including disease diagnosis.1 The scope of metaverse is expected to be more widespread, especially in the field of science. It is predicted to have implications on both the healthcare as well as financial sector. We are all aware that the current healthcare system is unsustainable due to the pressures of chronic disease, population explosion, a shortage of qualified healthcare professionals, constrained resources, and other factors. One of the most important aspects in the transformation of health care over the coming years will be the introduction of digital services including metaverse. The most important part of health care is disease diagnosis. Dermatology is a primarily visual science where most disorders are diagnosed by visual inspection of the skin. On various occasions, the cutaneous diseases can be missed due to inadequate examination. The use of this cutting-edge technology of metaverse can improve diagnostic accuracy of dermatological ailments. Using its application, the treating dermatologist can analyze a skin lesion and project its size, depth, progression, and other characteristics which cannot be evaluated with naked eye.2, 3 For many years, dermatology has successfully used AI, notably for the early diagnosis of skin cancer. In metaverse, the haptic feedback might be quite useful while using AR/VR as well. This relates to sensory data in dermatology, such as skin temperature, roughness, or stiffness, which may offer useful extra data to enhance diagnostic assessment. When determining the difference between epidermal conditions like psoriasis and atopic dermatitis or when determining the depth, induration, and edema of a leg ulcer, examining the skin's surface texture can be helpful. Another model creates virtual 3-dimensional (3D) pictures that may be felt with a haptic device from 2-dimensional (2D) images obtained from conventional full-body optical imaging systems. With this technique, the user may simultaneously visualize and touch the skin's surface. Currently, a specialized portable imager that provides 3D imaging of skin lesions is available, enabling dermatologists to see the texture and elevation of individual lesions when examining clinical images. To monitor pigmented lesions or other skin conditions, full-body 3D mapping of the skin's surface is also possible.4, 5 Metaverse can aid in radiological diagnostics by enabling new radiologic skills by real-time image viewing and manipulation; the ability to see dynamic images with greater information for improved disease/injury diagnosis; and the facilitation of close physician cooperation on 3D medical imaging.4 The use of virtual reality and augmented reality in education and practice has the potential to enhance and transform dermatological practice by examining the skin lesions in real-time. To become pioneers in these technologies and implement them into their practices, dermatologists should try to capitalize on the metaverse revolution. Although numerous researches are needed to implement metaverse factor in dermatology clinics to enhance patient outcomes and boost practice efficiency. Jyoti Kumari wrote and revised the manuscript. Kinnor Das reviewed and revised the manuscript. Mohamad Goldust conceptualized, wrote, reviewed, and revised the manuscript. Open Access funding enabled and organized by Projekt DEAL. None. Authors declare human ethics approval was not needed for this study. We confirm that the manuscript has been read and approved by all the authors, that the requirements for authorship as stated earlier in this document have been met and that each author believes that the manuscript represents honest work.
ER  -
TY  - JOUR
TI  - Haptic ventriculostomy simulation in a grid environment
PY  - 2009
PB  - Wiley
SN  - 1546-4261
T2  - Computer Animation and Virtual Worlds
DO  - 10.1002/cav.272
UR  - https://doi.org/10.1002/cav.272
DA  - 2009-01-01
AU  - Çakmak, Hüseyin
C1  - Forschungszentrum Karlsruhe, Institut für Angewandte Informatik, Karlsruhe, Germany.
AU  - Maaß, H.
AU  - Trantakis, C.
AU  - Strauß, G.
AU  - Nowatius, E.
AU  - Kühnapfel, Uwe
LA  - en
KW  - Ventriculostomy
VL  - 20
IS  - 1
SP  - 25
EP  - 38
ER  -
TY  - JOUR
TI  - A Physics-Based Virtual Reality Haptic System Design and Evaluation by Simulating Human-Robot Collaboration
PY  - 2024
PB  - Institute of Electrical and Electronics Engineers
SN  - 2168-2291
T2  - IEEE Transactions on Human-Machine Systems
DO  - 10.1109/thms.2024.3407109
UR  - https://doi.org/10.1109/thms.2024.3407109
DA  - 2024-06-06
AU  - Mubarrat, Syed
C1  - Texas Tech University, Lubbock, TX, USA
AU  - Fernandes, Antonio
C1  - Texas Tech University, Lubbock, TX, USA
AU  - Chowdhury, S.
C1  - Texas Tech University, Lubbock, TX, USA
LA  - en
VL  - 54
IS  - 4
SP  - 375
EP  - 384
ER  -
TY  - JOUR
TI  - Smart Manufacturing and Tactile Internet Powered by 5G: Investigation of Current Developments, Challenges, and Future Trends
PY  - 2021
PB  - Elsevier BV
SN  - 2212-8271
T2  - Procedia CIRP
DO  - 10.1016/j.procir.2021.11.331
UR  - https://doi.org/10.1016/j.procir.2021.11.331
DA  - 2021-01-01
AU  - Mourtzis, Dimitris
C1  - Laboratory for Manufacturing Systems and Automation, Department of Mechanical Engineering and Aeronautics, University of Patras, Rio Patras, 26504, Greece
LA  - en
KW  - Industrial Internet
VL  - 104
SP  - 1960
EP  - 1969
AB  - Communication latency has been a significant barrier for many applications deployed in manufacturing networks. Despite the constant development of improved communication protocols and standards during Industry 4.0, the latency problem still exists, decreasing the Quality of Services (QoS) and Quality of experience (QoE). Therefore, high availability, security and ultra-low latency offered by Tactile Internet (TI), will create a new dimension to human-to-machine interaction (HMI) by enabling haptic and tactile sensations. The 5G mobile communication systems will support this emerging Internet at the wireless edge. Consequently, TI can be used as backbone for delay mitigation in cooperation with 5G networks, for ultra-reliable low-latency applications such as Smart Manufacturing, Virtual and Augmented Reality. Therefore, the aim of this paper is to present the state-of-the-art of 5G and TI, the challenges, the trends for 5G networks beyond 2020 and to provide a conceptual framework integrating 5G and TI to existing industrial case studies.
ER  -
TY  - JOUR
TI  - Development of a New Backdrivable Actuator for Haptic Interfaces and Collaborative Robots
PY  - 2016
PB  - Multidisciplinary Digital Publishing Institute
SN  - 2076-0825
T2  - Actuators
DO  - 10.3390/act5020017
UR  - https://doi.org/10.3390/act5020017
DA  - 2016-06-09
AU  - Gosselin, Florian
C1  - Interactive Robotics Laboratory, French Alternative Energies and Atomic Energy Commission, Laboratory of Applied Research on Software Intensive Technologies (CEA, LIST), Gif-sur-Yvette F-91190, France
AU  - Ferlay, Fabien
C1  - Mechanical Projects Engineering Group, French Alternative Energies and Atomic Energy Commission, Institute for Magnetic Fusion Research (CEA, IRFM), Saint-Paul Lez Durance F-13108, France
AU  - Janot, Alexandre
C1  - Office National d’Etudes et de Recherches Aérospatiales (ONERA, The French Aerospace Lab), Toulouse F-31055, France
LA  - en
KW  - Teleoperation
VL  - 5
IS  - 2
SP  - 17
EP  - 17
AB  - Industrial robots are most often position controlled and insensitive to external forces. In many robotic applications, however, such as teleoperation, haptics for virtual reality, and collaborative robotics, a close cooperation between humans and robots is required. For such applications, force sensing and control capabilities are required for stable interactions with the operator and environment. The robots must also be backdrivable, i.e., the robot must be able to follow user’s induced movements with the least possible resistance. High force efficiency is also desirable. These requirements are different from the design drivers of traditional industrial robots and call for specific actuators and reducers. Many such devices were proposed in the literature. However, they suffer from several drawbacks, offering either a limited reduction ratio or being complex and bulky. This paper introduces a novel solution to this problem. A new differential cable drive reducer is presented. It is backdrivable, has a high efficiency, and a potentially infinite reduction ratio. A prototype actuator using such a reducer has been developed and integrated on a test bench. The experimental characterization of its performance confirms its theoretical advantages.
ER  -
TY  - JOUR
TI  - Transcending from Virtual Reality into Tele-Immersive Technologies and Applications: A Perspective
PY  - 2008
PB  - Association for Computing Machinery
SN  - 1530-2180
T2  - Ubiquity
DO  - 10.1145/1399612.1399615
UR  - https://doi.org/10.1145/1399612.1399615
DA  - 2008-06-01
AU  - Singh, Ramesh
C1  - National Informatics Centre, New Delhi, India
AU  - Singh, Anubhav
C1  - National Institute of Technology, Surat, India
LA  - en
KW  - Immersion
KW  - Converse
KW  - Immersive technology
KW  - Videoconferencing
KW  - Teleconference
KW  - Instructional simulation
VL  - 2008
SP  - 6
ER  -
TY  - JOUR
TI  - An experimental study on CHVE's performance evaluation.
PY  - 2012
PB  - National Institutes of Health
T2  - PubMed
DA  - 2012-01-01
AU  - Paiva, Paulo
C1  - LabTEVE - Universidade Federal da Paraíba (UFPB) - Brazil.
AU  - Machado, Liliane
AU  - de Oliveira, Jauvane
LA  - en
VL  - 173
SP  - 328
EP  - 30
ER  -
TY  - JOUR
TI  - VR-based dynamics learning system using haptic device and its evaluation
PY  - 2005
DO  - 10.1109/icalt.2005.306
UR  - https://doi.org/10.1109/icalt.2005.306
DA  - 2005-01-01
AU  - Inoue, Manabu
C1  - Fac. of Information Sci., Hiroshima City Univ., Japan
AU  - Matsubara, Y.
C1  - Fac. of Information Sci., Hiroshima City Univ., Japan
AU  - Iwane, Noriyuki
C1  - Fac. of Information Sci., Hiroshima City Univ., Japan
AU  - Nakamura, M.
C1  - Fac. of Information Sci., Hiroshima City Univ., Japan
AU  - Ichitsubo, M.
C1  - Fac. of Information Sci., Hiroshima City Univ., Japan
LA  - en
KW  - Interface (matter)
ER  -
TY  - JOUR
TI  - Foundational elements of next generation cyber physical and IoT frameworks for distributed collaboration
PY  - 2017
DO  - 10.1109/coase.2017.8256200
UR  - https://doi.org/10.1109/coase.2017.8256200
DA  - 2017-08-01
AU  - Cecil, J.
C1  - Computer Science Department, Oklahoma State University (OSU), Stillwater, OK, USA
AU  - Cecil-Xavier, Aaron
C1  - Stillwater High School and the OSU Soaring Eagle Program, Stillwater, OK
AU  - Gupta, Avinash
C1  - Computer Science Department, Oklahoma State University, Stillwater, OK
LA  - en
KW  - Cyber-physical system
SP  - 789
EP  - 794
ER  -
TY  - GEN
TI  - ACM SIGGRAPH 2004 Emerging technologies on - SIGGRAPH '04
PY  - 2004
DO  - 10.1145/1186155
UR  - https://doi.org/10.1145/1186155
DA  - 2004-01-01
LA  - en
KW  - Emerging Technologies
KW  - Digital art
ER  -
TY  - JOUR
TI  - Metric-Based Virtual Reality Simulation
PY  - 2018
PB  - Lippincott Williams & Wilkins
SN  - 0039-2499
T2  - Stroke
DO  - 10.1161/strokeaha.118.021089
UR  - https://doi.org/10.1161/strokeaha.118.021089
DA  - 2018-06-04
AU  - Liebig, Thomas
C1  - From the Institute of Neuroradiology, Charité–Universitätsmedizin Berlin, Germany (T.L.)
AU  - Holtmannspötter, Markus
C1  - Department of Neuroradiology, Rigshospitalet, University of Copenhagen, Denmark (M.H.)
AU  - Crossley, Robert
C1  - Robert Crossley Neuroradiology, North Bristol National Health Service Trust, Southmead Hospital, United Kingdom (R.C.)
AU  - Lindkvist, Johan
C1  - Johan Lindkvist Mentice AB, Gothenburg, Sweden (J.L.)
AU  - Henn, Patrick
C1  - Patrick Henn Medical Education, School of Medicine (P.H.)
AU  - Lönn, Lars
C1  - University College Cork, Ireland; and Department of Cardiovascular Radiology, National Hospital, Copenhagen University, Denmark (P.L.).
AU  - Gallagher, Anthony
C1  - Application of Science to Simulation-Based Education and Research on Training (ASSERT) Centre and School of Medicine (A.G.G.)
LA  - en
KW  - Stroke
VL  - 49
IS  - 7
AB  - HomeStrokeVol. 49, No. 7Metric-Based Virtual Reality Simulation Free AccessReview ArticlePDF/EPUBAboutView PDFView EPUBSections ToolsAdd to favoritesDownload citationsTrack citationsPermissions ShareShare onFacebookTwitterLinked InMendeleyReddit Jump toFree AccessReview ArticlePDF/EPUBMetric-Based Virtual Reality SimulationA Paradigm Shift in Training for Mechanical Thrombectomy in Acute Stroke Thomas Liebig, MD, PhD, Markus Holtmannspötter, MD, Robert Crossley, MRCS, Johan Lindkvist, MSc, Patrick Henn, MB, Lars Lönn, MD, PhD and Anthony G. Gallagher, PhD, DSc Thomas LiebigThomas Liebig From the Institute of Neuroradiology, Charité–Universitätsmedizin Berlin, Germany (T.L.) , Markus HoltmannspötterMarkus Holtmannspötter Department of Neuroradiology, Rigshospitalet, University of Copenhagen, Denmark (M.H.) , Robert CrossleyRobert Crossley Neuroradiology, North Bristol National Health Service Trust, Southmead Hospital, United Kingdom (R.C.) , Johan LindkvistJohan Lindkvist Mentice AB, Gothenburg, Sweden (J.L.) , Patrick HennPatrick Henn Medical Education, School of Medicine (P.H.) , Lars LönnLars Lönn University College Cork, Ireland; and Department of Cardiovascular Radiology, National Hospital, Copenhagen University, Denmark (P.L.). and Anthony G. GallagherAnthony G. Gallagher Correspondence to Anthony G. Gallagher, PhD, DSc, School of Medicine, Brookfield Health Sciences Complex, University College Cork, College Rd, Ireland. E-mail E-mail Address: [email protected] Application of Science to Simulation-Based Education and Research on Training (ASSERT) Centre and School of Medicine (A.G.G.) Originally published30 Jul 2018https://doi.org/10.1161/STROKEAHA.118.021089Stroke. 2018;49:e239–e242Ischemic stroke is the second leading cause of death and the predominant cause of long-term disability in the Western world. Until recently, the standard treatment for ischemic stroke was intravenous administration of r-tPA (recombinant tissue-type plasminogen activator) within the accepted time limit of 4.5 hours from the onset of symptoms. Given later, risks such as intracranial hemorrhage outweigh the potential benefits. In large vessel occlusion (if no contraindication), r-tPA followed by mechanical thrombectomy improves outcomes. In a meta-analysis of large multicenter trials,1 patients receiving usual care (most often r-tPA) followed by mechanical thrombectomy showed significantly higher rates of functional independence at 90 days (46%) than those receiving usual care alone (26.5%). Benefits from mechanical thrombectomy have also been demonstrated in selected patient groups ≤162 and 24 hours3 after they were last known to be well.Despite the proven effectiveness of mechanical thrombectomy, access is limited. One of the main reasons is because of a shortage of interventional neuroradiologists trained to perform this procedure. Traditionally, doctors acquire their skills on new procedures on patients. However, image-guided procedures impose unique human factor challenges on the operator, which expose patients to potential risk during their learning curve. This current traditional process–driven approach to training4 (ie, procedure numbers done and time in training are assumed to signify skill) does not guarantee that the trained clinician has acquired the ability to effectively and readily execute as independent practitioners by the end of their training.5A novel approach to enhance the learning experience and training of doctors to competently perform mechanical thrombectomy is metric-based virtual simulation training to proficiency.5 A group of senior interventional neuroradiologists and the ASSERT Center at University College Cork, in conjunction with industry partner Mentice AB (Gothenburg, Sweden), have pioneered this method to help prepare physicians to perform this life-changing procedure.This vascular intervention system trainer (VIST) utilizes a physics-based high-fidelity endovascular virtual reality (VR) simulator, which enables hands-on procedural training for clinicians. This tool can objectively, consistently, and reliably quantify performance levels of trainees, in a safe environment.6 This technology allows the actual endovascular devices, such as guidewires, catheters, and thrombectomy devices, to be used for simulated endovascular procedures. The VIST VR simulator is a high-powered personal computer–based system that uses a geometric vessel representation together with physics-based calculations to determine the behavior of the endovascular devices and the blood flow in the vessels.7 The simulator (Figure [B1]; VIST; Mentice AB, Gothenburg, Sweden) senses the user's manipulation of the real endovascular devices via the haptic device (ie, haptics is the science and engineering that deals with the sense of touch8) transfering the real movements to the virtual representation of the devices. It calculates the interaction between the virtual devices and vessels by the use of real physical properties, such as mass, stiffness, and friction. The result of the calculations determines the position and the shape of the devices and the interactions between devices and vessels. It also determines the forces applied on the devices that will be fed back to the user through the endovascular devices via the interface haptic device (aka force feedback device). This emulates the tactile feedback experienced by the user in vivo. The result of the user's actions is calculated in real-time, fed back instantly to them via the haptic device, and displayed on the virtual fluoroscopy screen (shown in Figure [B1 through B3]). The computer-generated simulation can thus measure precisely and reliably the performance of the user.Download figureDownload PowerPointFigure. Mechanical thrombectomy in vivo and simulated. A1, Intervention room and the mechanical thrombectomy procedure setup. A2, Angiography showing interruption of the blood supply to part of the brain of the stroke patient pre-thrombectomy procedure. A3, Blood flow of the same stroke patient post-thrombectomy procedure. B1, Coauthor (J.L.) training mechanical thrombectomy procedure on the vascular intervention system trainer virtual reality (VR) simulator. B2, VR simulation angiography showing interruption of the blood supply to part of the brain of the stroke patient (as shown in A2) pre-thrombectomy procedure. B3, VR simulation of blood flow of the same stroke patient post-thrombectomy procedure (as shown in A3). Lt ACA indicates left anterior cerebral artery; Lt ICA, left internal carotid artery; Lt MCA, left middle cerebral artery; M1, from the origin to bifurcation/trifurcation (the limen insulae); and Rt ACA, right anterior cerebral artery.A performance characterization of mechanical thrombectomy, derived from experienced interventional neuroradiologists, was utilized to establish procedure metrics. Once validated, these metrics were used to establish a performance benchmark—the level of proficiency—that trainees must demonstrate before progressing to the next level of training or real patients. This approach (proficiency-based progression) ensures a more homogeneous skill set in graduating trainees and can be applied to any level of training. Prospective, randomized, and blinded clinical studies have demonstrated that trainees who acquired their skills to a level of proficiency on a simulator perform significantly better (40%–69% better) in vivo in comparison with their traditionally trained colleagues.9 VR simulation has also been used to retrain experienced physicians in the performance of high-risk procedures novel to them.7 VIST also allows for the implementation of neurointerventional societies' recommendations on state-of-the-art thrombectomy performance guidelines.High-fidelity simulation affords the opportunity in replicated real-world scenarios, to provide step-by-step guidance and metric-based feedback to the trainee throughout the procedure. Figure (A2) demonstrates a 75-year-old previously healthy man who experienced an ischemic stroke at 8:00 PM and arrived at the primary stroke unit 1 hour later. A computed tomography angiography was performed and intravenous r-tPA administered at 10 PM.A right-sided occlusion of the internal carotid artery at its cervical origin and a left-sided middle cerebral artery occlusion without early signs of infarction was interpreted from the computed tomography (CT) data. The patient was transferred to a tertiary center for thrombectomy, arriving at 11:15 PM, and procedure start at 11:30 PM. Thrombectomy was successfully performed with 2 different types of stentrievers within a total procedure time of 45 minutes with near-total reperfusion (Thrombolysis in Cerebral Infarction 2b; Figure [A3]). However, the first control CT showed contrast enhancement and some swelling of the left hemisphere that corresponded to the frontal middle cerebral artery territory.Figure (B2 and B3) shows virtual representation of the identical same patient anatomy as described above (ie, Figure [A2 and A3]). A CT digital imaging and communications in medicine angiography scan from the real patient—a high-resolution 2-dimensional gray scale images were used to extract the important anatomic structures for the virtual simulation and to create a VIST-specific 3D representation of the patient (Figure [B2 and B3]). The concordance between the physical behavior of the devices and visual appearance of the anatomy, in vivo and in the VR simulator, is high.The developments (outlined above) in physics-based simulation provide/offer the use of real patient cases to augment the training of high-skill and high-risk procedures, such as mechanical thrombectomy. Furthermore, metric-based characterization of optimal and suboptimal performance, derived from proficient/master interventionists means that trainees can be given objective, transparent, and fair quantitative feedback on their performance, and this training can be repeated over and over and is standardized.8 The simulator and the validated metrics can in addition be used to quantitatively define a proficiency benchmark based on the performance of experienced practitioners.5,10 Trainees would not progress to performing the procedure on real patients until they had demonstrated this performance level, consistently. Evidence from prospective and randomized clinical trials has demonstrated that this approach to training produces a much more homogeneous skill set that translates into significantly improved intraoperative performance.7,9 It has, however, also been demonstrated that the exact same simulation training without the validated performance metrics achieved a training outcome only marginally better than traditional training (ie, standard training, 29%, versus simulation training, 36%, versus proficiency-based progression simulation training, 75%, demonstrated the proficiency benchmark at the end of training).9 This approach to training will not replace clinical in vivo training, but it has the potential to supplant a significant part of the learning curve on real patients. The trainee will have learned to perform the procedure on the simulator to a quantitatively defined performance level (defined on the performance of experienced and proficient practitioners) but not performed on a real patient. This means that the consultant/attending will in future be teaching a pretrained novice in the intervention suite.5,8,10 Training in this way is more than an interesting educational experience.8 Trainers will know precisely the performance level of their trainee if they have successfully navigated a proficiency-based progression simulation training curriculum.4High-fidelity, veridical VR simulations afford operators the opportunity to acquire and maintain new skills. It also permits expansion of their procedure experience because they can engage in deliberate practice rather than simply repeated practice. Crucially, this capability presumes the truthful nature of the simulation training cases. The trainee can accurately experience the span of appropriate sensory responses and physical actions that are consistent with what would be experienced in real life. This includes the opportunity to enact both appropriate and inappropriate actions and receive performance feedback that accurately depicts their performance level. VR simulation training programs allow professionals of all levels to increase proficiency in the detailed steps for a given procedure, as well as an awareness of the potential pitfalls and crucial moments in a safe environment.Physics-based simulations do have difficulties; they are expensive because they run on high-end personal computer platforms and have associated interface platforms, which are also not inexpensive (Figure [B1]). With the development of sensor technologies, the simulations run considerably more stably than they did a decade ago but not if used incorrectly or inappropriately (ie, the user should not do anything with thrombectomy devices they would not do in a real patient). Real patient cases derived from the CT or magnetic resonance imaging digital imaging and communications in Medicine data take 2 to 5 days work by a computer engineer/scientist to produce a simulation of sufficient fidelity that would be acceptable for a proficiency-based progression simulation training curriculum. These issues aside, physics-based VR simulation for mechanical thrombectomy and other high-risk and neurovascular procedures is a game changer. It affords the trainee (no matter how senior) the opportunity to acquire and hone their skills outside the intervention suite to a quality-assured performance level using real-time metric-based performance feedback operating with the exact same devices, in the same order as they would on a patient.ConclusionsIt is feasible and practical to take CT digital imaging and communications in Medicine data from a real stroke case and recreate it in VR. Metric-based simulation training can supplant parts of the learning curve for endovascular procedures, with consequently safer operations, particularly for high-skill, high-risk procedures, such as mechanical thrombectomy for ischemic stroke. It should not be viewed as a replacement for traditional fellowship training but as a powerful tool to reproducibly augment the training experience when fully integrated into the current in vivo education curriculum. This approach to training is conceptually and intellectually appealing, and it represents a paradigm shift in how doctors are educated and trained. Training for these procedures must be more than an interesting educational experience.AcknowledgmentsAll of the authors contributed to the writing of the article. Drs Liebig and Holtmannspötter and R. Crossley are experienced mechanical thrombectomy interventional neuroradiologists. Dr Lönn and P. Henn are experienced clinicians and medical education specialists. J. Lindkvist is a senior computer engineer. Dr Gallagher developed and helped validate proficiency-based progression simulation training. Dr Liebig, Dr Holtmannspötter, R. Crossley, Dr Lönn, J. Lindkvist, and Dr Gallagher have characterized a reference approach to mechanical thrombectomy. J. Lindkvist developed and formatted the virtual reality simulation from the computed tomographic angiography of the stroke patients reported in this article. Dr Gallagher and P. Henn produced the first draft of this article. All authors contributed to editing the paper post-editorial review.DisclosuresThe research and researchers on this article were supported by a grant from the Swedish government agency for innovation (Vinnova) to Mentice AB (Gothenburg, Sweden) to characterize, develop, and then validate the metrics for a reference approach to performance of mechanical thrombectomy. Dr Holtmannspötter has received honoraria from Microvention, Medtronic Neurovascular, Mentice AB, and Stryker Neurovascular for consulting and proctoring. R. Crossley has received honorarium for speaking (Stryker Neurovascular, United Kingdom) and educational sponsorship to attend meetings/conferences from Microvention, Stryker, Medtronic, Penumbra, Johnson & Johnson. J. Lindkvist works as an engineer at Mentice and developed the virtual reality model of the real patient data. Dr Lönn has served as a clinical advisor and then as medical director for Mentice.FootnotesCorrespondence to Anthony G. Gallagher, PhD, DSc, School of Medicine, Brookfield Health Sciences Complex, University College Cork, College Rd, Ireland. E-mail ag.[email protected]ieReferences1. Goyal M, Menon BK, van Zwam WH, Dippel DW, Mitchell PJ, Demchuk AMet al; HERMES Collaborators. Endovascular thrombectomy after large-vessel ischaemic stroke: a meta-analysis of individual patient data from five randomised trials.Lancet. 2016; 387:1723–1731. doi: 10.1016/S0140-6736(16)00163-X.CrossrefMedlineGoogle Scholar2. Albers GW, Marks MP, Kemp S, Christensen S, Tsai JP, Ortega-Gutierrez Set al; DEFUSE 3 Investigators. Thrombectomy for stroke at 6 to 16 hours with selection by perfusion imaging.N Engl J Med. 2018; 378:708–718. doi: 10.1056/NEJMoa1713973.CrossrefMedlineGoogle Scholar3. Nogueira RG, Jadhav AP, Haussen DC, Bonafe A, Budzik RF, Bhuva Pet al; DAWN Trial Investigators. Thrombectomy 6 to 24 hours after stroke with a mismatch between deficit and infarct.N Engl J Med. 2018; 378:11–21. doi: 10.1056/NEJMoa1706442.CrossrefMedlineGoogle Scholar4. Asch DA, Weinstein DF. Innovation in medical education.N Engl J Med. 2014; 371:794–795. doi: 10.1056/NEJMp1407463.CrossrefMedlineGoogle Scholar5. Gallagher AG, Ritter EM, Champion H, Higgins G, Fried MP, Moses Get al. Virtual reality simulation for the operating room: proficiency-based training as a paradigm shift in surgical skills training.Ann Surg. 2005; 241:364–372.CrossrefMedlineGoogle Scholar6. Patel AD, Gallagher AG, Nicholson WJ, Cates CU. Learning curves and reliability measures for virtual reality simulation in the performance assessment of carotid angiography.J Am Coll Cardiol. 2006; 47:1796–1802. doi: 10.1016/j.jacc.2005.12.053.CrossrefMedlineGoogle Scholar7. Cates CU, Lönn L, Gallagher AG. Prospective, randomised and blinded comparison of proficiency-based progression full-physics virtual reality simulator training versus invasive vascular experience for learning carotid artery angiography by very experienced operators.BMJ Simul Technol Enhanc Learn. 2016; 2:1–5.CrossrefGoogle Scholar8. Gallagher AG, O'Sullivan GC. Fundamentals of Surgical Simulation; Principles & Practices. London: Springer Verlag; 2011.Google Scholar9. Angelo RL, Ryu RK, Pedowitz RA, Beach W, Burns J, Dodds Jet al. A proficiency-based progression training curriculum coupled with a model simulator results in the acquisition of a superior arthroscopic bankart skill set.Arthroscopy. 2015; 31:1854–1871. doi: 10.1016/j.arthro.2015.07.001.CrossrefMedlineGoogle Scholar10. Gallagher AG. Metric-based simulation training to proficiency in medical education:- what it is and how to do it.Ulster Med J. 2012; 81:107–113.MedlineGoogle Scholar Previous Back to top Next FiguresReferencesRelatedDetailsCited ByCompagne K, Kappelhof M, Hinsenveld W, Brouwer J, Goldhoorn R, Uyttenboogaart M, Bokkers R, Schonewille W, Martens J, Hofmeijer J, van der Worp H, Lo R, Keizer K, Yo L, Lycklama à Nijeholt G, den Hertog H, Sturm E, Brouwers P, van Walderveen M, Wermer M, de Bruijn S, van Dijk L, Boogaarts H, van Dijk E, van Tuijl J, Peluso J, de Kort P, van Hasselt B, Fransen P, Schreuder T, Heijboer R, Jenniskens S, Sprengers M, Ghariq E, van den Wijngaard I, Roosendaal S, Meijer A, Beenen L, Postma A, van den Berg R, Yoo A, van Doormaal P, van Proosdij M, Krietemeijer M, Gerrits D, Hammer S, Vos J, Boiten J, Coutinho J, Emmer B, van Es A, Roozenbeek B, Roos Y, van Zwam W, van Oostenbrugge R, Majoie C, Dippel D, van der Lugt A, Jansen I, Mulder M, Brouwer J, den Hartog S, Schonewille W, Albert Vos J, Wermer M, van Walderveen M, Staals J, van Oostenbrugge R, Hofmeijer J, Martens J, Lycklama à Nijeholt G, de Bruijn S, van Dijk L, van der Worp H, Lo R, van Dijk E, Boogaarts H, de Vries J, de Kort P, van Tuijl J, Peluso J, Fransen P, van den Berg J, van Hasselt B, Aerden L, Dallinga R, Eschgi O, Schreuder T, Heijboer R, Keizer K, Yo L, den Hertog H, Bulut T, Brouwers P, Lycklama à Nijeholt G, van Walderveen M, Sprengers M, Jenniskens S, van den Berg R, Yoo A, Beenen L, Postma A, Roosendaal S, van der Kallen B, van den Wijngaard I, Martens J, Yo L, Bot J, van Doormaal P, Meijer A, Ghariq E, Bokkers R, Peluso J, Boogaarts H, Lo R, Dinkelaar W, Appelman A, Hammer B, Pegge S, van der Hoorn A, Vinke S, Majoie C, Lycklama à Nijeholt G, Albert Vos J, Schonewille W, Hofmeijer J, Martens J, van der Worp H, Lo R, Hofmeijer J, Flach H, Lingsma H, el Ghannouti N, Sterrenberg M, Pellikaan W, Sprengers R, Elfrink M, Simons M, Vossers M, de Meris J, Vermeulen T, Geerlings A, van Vemde G, Simons T, Messchendorp G, Nicolaij N, Bongenaar H, Bodde K, Kleijn S, Lodico J, Droste H, Wollaert M, Verheesen S, Jeurrissen D, Bos E, Drabbe Y, Sandiman M, Aaldering N, Zweedijk B, Vervoort J, Ponjee E, Romviel S, Kanselaar K, Barning D, Venema E, Chalos V, Geuskens R, van Straaten T, Ergezen S, Harmsma R, Muijres D, de Jong A, Berkhemer O, Boers A, Huguet J, Groot P, Mens M, van Kranendonk K, Treurniet K, Tolhuisen M, Alves H, Weterings A, Kirkels E, Voogd E, Schupp L, Collette S, Groot A, LeCouffe N, Konduri P, Prasetya H, Arrarte-Terreros N and Ramos L (2022) Improvements in Endovascular Treatment for Acute Ischemic Stroke: A Longitudinal Study in the MR CLEAN Registry, Stroke, 53:6, (1863-1872), Online publication date: 1-Jun-2022. Yang Y, Bao H, Jin H, Li L, Fang Y, Ren C, Wang J and Chu L (2022) Bone Marrow-derived Mesenchymal Stem Cells Promote Microglia/Macrophage M2 Polarization and Enhance Neurogenesis in the Acute and Chronic Stages after Ischemic Stroke, Clinical Complementary Medicine and Pharmacology, 10.1016/j.ccmp.2022.100040, (100040), Online publication date: 1-Apr-2022. Mathern N, Sandmann J, Sichtermann T, Ridwan H, Riabikin A, Stockero A, Nikoubashman O, Wiesmann M and Marquez-Romero J (2022) Can training on ex-vivo models increase neurointerventionalists' subjective self-confidence in the operating room?, PLOS ONE, 10.1371/journal.pone.0264180, 17:2, (e0264180) Mishra R, Narayanan M, Umana G, Montemurro N, Chaurasia B and Deora H (2022) Virtual Reality in Neurosurgery: Beyond Neurosurgical Planning, International Journal of Environmental Research and Public Health, 10.3390/ijerph19031719, 19:3, (1719) Amato M and Gallagher A (2022) Proficiency-Based Progression Simulation Training: Shortening the Learning Curve Practical Simulation in Urology, 10.1007/978-3-030-88789-6_4, (41-62), . Gupta A, Metzke R, Struk O and Popovic A (2022) Augmented, Virtual and Robotic Capabilities in Cardiovascular Program Capacity Building Global Cardiac Surgery Capacity Development in Low and Middle Income Countries, 10.1007/978-3-030-83864-5_33, (447-458), . Liimatainen K, Latonen L, Valkonen M, Kartasalo K and Ruusuvuori P (2021) Virtual reality for 3D histology: multi-scale visualization of organs with interactive feature exploration, BMC Cancer, 10.1186/s12885-021-08542-9, 21:1, Online publication date: 1-Dec-2021. Goyal M, Cimflova P, Ospel J and Chapot R (2021) Endovascular treatment of anterior cerebral artery occlusions, Journal of NeuroInterventional Surgery, 10.1136/neurintsurg-2021-017735, 13:11, (1007-1011), Online publication date: 1-Nov-2021. Yang C, Liu J, Wang J, Yin A, Jiang Z, Ye S, Liu X, Zhang X, Wang F and Xiong L (2021) Activation of astroglial CB1R mediates cerebral ischemic tolerance induced by electroacupuncture, Journal of Cerebral Blood Flow & Metabolism, 10.1177/0271678X21994395, 41:9, (2295-2310), Online publication date: 1-Sep-2021. Zhu F, Ben Hassen W, Bricout N, Kerleroux B, Janot K, Gory B, Anxionnat R, Richard S, Marchal A, Blanc R, Piotin M, Consoli A, Trystram D, Rodriguez Regent C, Desilles J, Weisenburger-Lile D, Escalard S, Herbreteau D, Ifergan H, Lima Maldonado I, Labreuche J, Henon H, Naggara O, Lapergue B, Boulouis G, Hocine R, Gabriele C, Stanislas S, Benjamin M, Mikael M, Mikael O, Candice S, Roxanne P, Ovide C, Thomas D, Didier S, Sonia A, Olivier I, Eric M, Pierre-Yves G, Guillaume T, Malek B, Adrien W, Serge E, Maya T, Nadia A, Lucas G, Géraldine B, Oguzhan C, Maria Federico D, Georges R, Sergio Z, Morgan L, Julie G, Fernando P, Haja R, Philippe T, Roxanna P, Sylvie M, Norbert N, Roberto R, Omer E, Francis T, Laurent D, Tae-Hee C, Laura M, Lukaszewicz Anne C, Frédéric P, Serkan C, Karine B, Anne-Evelyne V, Gaultier M, Florent G, Xavier B, Jérôme B, Patrice M, Igor S, Sebastien L, Stéphane O, Pauline R, Sharmila S, Mathilde P, Sabrina D, Nicolas P, Romain B, Lili D, Benjamin D, Pierre-Louis A, Monica R, Cédric L, Vincent L, Jean-Baptiste G, Hubert D, Serge B, Marc B, Anne-Laure D, Romain T, Liang L, Patricio M, Emmanuelle S, Sophie P, Lisa H, Gioia M, Jean-Christophe L, Nolwenn R, Gérard A, Marcela V, Ionel A, Marie R, Madalina B, Agnès M, Ioana T, Francisco M, Suzanna S, Charbel M, Aymeric R, Vincent C, Caroline A, Cyril D, Grégory G, Pierre-Henri L, Imad D, Carlos R, Nicolas G, Isabelle M, Lucas C, Eugene F, Stéphane V, Jean-Christophe F, Helene R, Thomas R, Maria L, Christophe P, Jean-Yves G, Clément T, Sophie L, Yves S, Charlotte R, Anne L, Sandrine D, Frederic C, Eimad S, Laurent S, Christian D, Olivier C, Vanessa C, Jildaz C, Olivier C, Laura V, Guillaume T, Pierre S, Valérie D, Catherine L, Julia B, Clothilde I, Alain V, Christophe C, Anne C, Jean-Marc O, Nicolas R, Fabrice B, Albucher Jean F, Lionel C, Emmanuel T, Charlotte B, Romain S, Marion B, Julien C, Sophie G, Serge T, Jean-Christophe G, Julien O, Francois M, Ozlem O, Evelyne M, Chrysanthi P, Frédéric B, Bernady P, Laurent L, Hélène C, Louis V, David H, Valérie W, Raoul P, Rémi B, Dan-Sorin M, Monica M, Anthony L, Sarah E, Arnaud L, Sebastian R, Regis H, Stéphanie D, Bruno B, Mathieu Z, Wassim F, Quentin A, François L, Delphine S, Olivier H, Sylvie G, Valentin B and Jérôme G (2021) Effect of Operator's Experience on Proficiency in Mechanical Thrombectomy: A Multicenter Study, Stroke, 52:9, (2736-2742), Online publication date: 1-Sep-2021. Mass-Ramírez S, Vergara-Burgos H, Sierra-Ochoa C, Lozada-Martinez I, Moscote-Salazar L, Janjua T, Rahman M, Rahman S and Picón-Jaimes Y (2021) Utility of medical simulation in neurovascular critical care education, Journal of Neurocritical Care, 10.18700/jnc.210010, 14:1, (8-17) Kreiser K, Ströber L, Gehling K, Schneider F, Kohlbecher S, Schulz C, Zimmer C and Kirschke J (2020) Simulation Training in Neuroangiography—Validation and Effectiveness, Clinical Neuroradiology, 10.1007/s00062-020-00902-5, 31:2, (465-473), Online publication date: 1-Jun-2021. Liang C, Das S, Ortega-Gutierrez S, Liebeskind D, Grotta J, Jovin T, Nguyen T, Nogueira R, Masoud H, Elijovich L, Zaidat O, Hassan A, Linfante I, Fifi J and Sheth S (2021) Education Research: Challenges Faced by Neurology Trainees in a Neuro-Intervention Career Track, Neurology, 10.1212/WNL.0000000000011629, 96:15, (e2028-e2032), Online publication date: 13-Apr-2021. de Oliveira M, Nicolato A, Malheiros J, Vieira Costa P, Fidelis A, Tibães Oliveira M, Ramos T, Lima Junior G and Avellar L (2021) Stroke Microsurgical Thrombectomy Human Placenta Simulator, World Neurosurgery, 10.1016/j.wneu.2020.12.177, 148, (e115-e120), Online publication date: 1-Apr-2021. Bechstein M, Buhk J, Frölich A, Broocks G, Hanning U, Erler M, Anđelković M, Debeljak D, Fiehler J and Goebell E (2019) Training and Supervision of Thrombectomy by Remote Live Streaming Support (RESS), Clinical Neuroradiology, 10.1007/s00062-019-00870-5, 31:1, (181-187), Online publication date: 1-Mar-2021. Evans N, Minhas J, Mehdi Z and Mistri A (2020) Incorporating Simulation-Based Education Into Stroke Training, Stroke, 52:1, (e6-e9), Online publication date: 1-Jan-2021. Patchana T, Wiginton J, Ghanchi H, Favre A, Tayag E, Schiraldi M and Miulli D Use of Endovascular Simulator in Training of Neurosurgery Residents – A Review and Single Institution Experience, Cureus, 10.7759/cureus.11931 Casolla B, Leciñana M, Neves R, Pfeilschifter W, Svobodova V, Jung S, Kemmling A, Mikulik R and Santalucia P (2020) Simulation training programs for acute stroke care: Objectives and standards of methodology, European Stroke Journal, 10.1177/2396987320971105, 5:4, (328-335), Online publication date: 1-Dec-2020. Tou S, Gómez Ruiz M, Gallagher A, Matzel K, Amin S, Bianchi P, Crolla R, Croner R, Eardley N, Espin‐Basany E, Evans C, Fernández C, Gallagher A, Gerjy R, Ruiz M, Hahnloser D, Khan J, Lelong B, Matzel K, Neary P, Perez D, Spinoglio G, Tou S, van Eetvelde E and Zawadzki M (2020) European expert consensus on a structured approach to training robotic‐assisted low anterior resection using performance metrics, Colorectal Disease, 10.1111/codi.15269, 22:12, (2232-2242), Online publication date: 1-Dec-2020. Fiani B, De Stefano F, Kondilis A, Covarrubias C, Reier L and Sarhadi K (2020) Virtual Reality in Neurosurgery: "Can You See It?"–A Review of the Current Applications and Future Potential, World Neurosurgery, 10.1016/j.wneu.2020.06.066, 141, (291-298), Online publication date: 1-Sep-2020. Lonn L and Konge L (2020) Commentary on Simulation Training in Neuroangiography: Transfer to Reality, CardioVascular and Interventional Radiology, 10.1007/s00270-020-02559-6, 43:8, (1192-1193), Online publication date: 1-Aug-2020. Melcher C, Korge A, Cunningham M, Foley K and Härtl R (2020) Metrics Development for Minimal Invasive Unilateral Laminotomy for Bilateral Decompression of Lumbar Spinal Stenosis With and Without Spondylolisthesis by an International Expert Panel, Global Spine Journal, 10.1177/2192568219893675, 10:2_suppl, (168S-175S), Online publication date: 1-Apr-2020. Zhou R Research on Information Management Based on Image Recognition and Virtual Reality, IEEE Access, 10.1109/ACCESS.2020.3001142, 8, (109232-109240) Dardick J, Allen S, Scoco A, Zampolin R and Altschul D (2019) Virtual reality simulation of neuroendovascular intervention improves procedure speed in a cohort of trainees, Surgical Neurology International, 10.25259/SNI_313_2019, 10, (184) Sandmann J, Müschenich F, Riabikin A, Kramer M, Wiesmann M and Nikoubashman O (2019) Can silicone models replace animal models in hands-on training for endovascular stroke therapy?, Interventional Neuroradiology, 10.1177/1591019919833843, 25:4, (397-402), Online publication date: 1-Aug-2019. Crossley R, Liebig T, Holtmannspoetter M, Lindkvist J, Henn P, Lonn L and Gallagher A (2019) Validation studies of virtual reality simulation performance metrics for mechanical thrombectomy in ischemic stroke, Journal of NeuroInterventional Surgery, 10.1136/neurintsurg-2018-014510, 11:8, (775-780), Online publication date: 1-Aug-2019. Schirmer C, Siddiqui A, Frid I, Khalessi A, Mocco J, Griessenauer C, Goren O, Dalal S, Weiner G and Arthur A (2019)(2019) Modern Training and Credentialing in Neuroendovascular Acute Ischemic Stroke Therapy, Neurosurgery, 10.1093/neuros/nyz014, 85:suppl_1, (S52-S57), Online publication date: 1-Jul-2019. Morris N, Czeisler B and Sarwal A (2018) Simulation in Neurocritical Care: Past, Present, and Future, Neurocritical Care, 10.1007/s12028-018-0629-2, 30:3, (522-533), Online publication date: 1-Jun-2019. Zheng X, Shan C, Xu Q, Wang Y, Shi Y, Wang Y and Zheng G (2018) Buyang Huanwu Decoction Targets SIRT1/VEGF Pathway to Promote Angiogenesis After Cerebral Ischemia/Reperfusion Injury, Frontiers in Neuroscience, 10.3389/fnins.2018.00911, 12 Rudran B and Logishetty K (2018) Virtual reality simulation: a paradigm shift for therapy and medical education, British Journal of Hospital Medicine, 10.12968/hmed.2018.79.12.666, 79:12, (666-667), Online publication date: 2-Dec-2018. July 2018Vol 49, Issue 7 Advertisement Article InformationMetrics © 2018 American Heart Association, Inc.https://doi.org/10.1161/STROKEAHA.118.021089PMID: 29866758 Manuscript receivedFebruary 6, 2018Manuscript acceptedMay 9, 2018Originally publishedJuly 30, 2018 Keywordsbrain ischemiacause of deathstrokehumansWestern worldPDF download Advertisement
ER  -
TY  - CHAP
TI  - Human-Machine Interaction in the Metaverse
PY  - 2024
PB  - IGI Global
SN  - 2327-039X
T2  - Advances in computer and electrical engineering book series
DO  - 10.4018/979-8-3693-5762-0.ch001
UR  - https://doi.org/10.4018/979-8-3693-5762-0.ch001
DA  - 2024-07-26
AU  - Sayyed, Mudassar
C1  - Institute of Management Studies Career Development and Research, India
AU  - Jadhav, Babasaheb
C1  - Dr. D.Y. Patil Vidyapeeth, India
AU  - Barnabas, Vikram
C1  - Institute of Management Studies Career Development and Research, India
AU  - Gupta, Shashi
C1  - Eudoxia Research University, USA
LA  - en
KW  - Metaverse
SP  - 1
EP  - 28
ER  -
TY  - JOUR
TI  - The Development of a Virtual Simulator for Training Neurosurgeons to Perform and Perfect Endoscopic Endonasal Transsphenoidal Surgery
PY  - 2013
PB  - Lippincott Williams & Wilkins
SN  - 0148-396X
T2  - Neurosurgery
DO  - 10.1093/neurosurgery/73.suppl_1.s85
UR  - https://doi.org/10.1093/neurosurgery/73.suppl_1.s85
DA  - 2013-10-01
AU  - Rosseau, Gail
C1  - Department of Neurosurgery, NorthShore University Health System, Evanston, Illinois
AU  - Bailes, Julian
C1  - Department of Neurosurgery, NorthShore University Health System, Evanston, Illinois
AU  - Del Maestro, Rolando
C1  - Neurosurgical Simulation Research Centre, Montreal Neurological Institute and Hospital, Montreal, Quebec, Canada
AU  - Cabral, Anne
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Choudhury, Nusrat
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Comas, Olivier
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Debergue, Patricia
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - De Luca, Gino
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Hovdebo, Jordan
C1  - National Research Council Canada, Winnipeg, Manitoba, Canada
AU  - Jiang, Di
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Laroche, Denis
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Neubauer, André
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Pazos, Valérie
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - Thibault, F.
C1  - National Research Council Canada, Boucherville, Quebec, Canada
AU  - DiRaddo, Robert
C1  - National Research Council Canada, Boucherville, Quebec, Canada
LA  - en
KW  - Transsphenoidal surgery
KW  - Sella turcica
VL  - 73
IS  - suppl_1
SP  - S85
EP  - S93
AB  - Abstract BACKGROUND: A virtual reality (VR) neurosurgical simulator with haptic feedback may provide the best model for training and perfecting surgical techniques for transsphenoidal approaches to the sella turcica and cranial base. Currently there are 2 commercially available simulators: NeuroTouch (Cranio and Endo) developed by the National Research Council of Canada in collaboration with surgeons at teaching hospitals in Canada, and the Immersive Touch. Work in progress on other simulators at additional institutions is currently unpublished. OBJECTIVE: This article describes a newly developed application of the NeuroTouch simulator that facilitates the performance and assessment of technical skills for endoscopic endonasal transsphenoidal surgical procedures as well as plans for collecting metrics during its early use. METHODS: The main components of the NeuroTouch-Endo VR neurosurgical simulator are a stereovision system, bimanual haptic tool manipulators, and high-end computers. The software engine continues to evolve, allowing additional surgical tasks to be performed in the VR environment. Device utility for efficient practice and performance metrics continue to be developed by its originators in collaboration with neurosurgeons at several teaching hospitals in the United States. Training tasks are being developed for teaching 1- and 2-nostril endonasal transsphenoidal approaches. Practice sessions benefit from anatomic labeling of normal structures along the surgical approach and inclusion (for avoidance) of critical structures, such as the internal carotid arteries and optic nerves. CONCLUSION: The simulation software for NeuroTouch-Endo VR simulation of transsphenoidal surgery provides an opportunity for beta testing, validation, and evaluation of performance metrics for use in neurosurgical residency training.
ER  -
TY  - JOUR
TI  - A Scheme for Haptic Data Transmission Under Various Network Conditions
PY  - 2007
DO  - 10.1109/icme.2007.4285131
UR  - https://doi.org/10.1109/icme.2007.4285131
DA  - 2007-07-01
AU  - You, Yonghee
C1  - University of Incheon Incheon
AU  - Sung, Mee
C1  - University of Incheon Incheon
AU  - Jun, Kyungkoo
C1  - University of Incheon Incheon
LA  - en
KW  - Network delay
SP  - 2238
EP  - 2241
ER  -
TY  - JOUR
TI  - CoboDeck: A Large-Scale Haptic VR System Using a Collaborative Mobile Robot
PY  - 2023
DO  - 10.1109/vr55154.2023.00045
UR  - https://doi.org/10.1109/vr55154.2023.00045
DA  - 2023-03-01
AU  - Mortezapoor, Soroosh
C1  - TU Wien, Vienna, Austria
AU  - Vasylevska, Khrystyna
C1  - TU Wien, Vienna, Austria
AU  - Vonach, Emanuel
C1  - TU Wien, Vienna, Austria
AU  - Kaufmann, Hannes
C1  - TU Wien, Vienna, Austria
LA  - en
KW  - Doors
SP  - 297
EP  - 307
ER  -
TY  - JOUR
TI  - Investigating a Combination of Input Modalities, Canvas Geometries, and Inking Triggers on On-Air Handwriting in Virtual Reality
PY  - 2022
PB  - Association for Computing Machinery
SN  - 1544-3558
T2  - ACM Transactions on Applied Perception
DO  - 10.1145/3560817
UR  - https://doi.org/10.1145/3560817
DA  - 2022-09-01
AU  - Venkatakrishnan, Roshan
C1  - Clemson University, Clemson, South Carolina, USA
AU  - Venkatakrishnan, Rohith
C1  - Clemson University, Clemson, South Carolina, USA
AU  - Chung, Chih-Han
C1  - National Yang Ming Chiao Tung University, Hsinchu City, Taiwan
AU  - Wang, Yu-Shuen
C1  - National Yang Ming Chiao Tung University, Hsinchu City, Taiwan
AU  - Babu, Sabarish
C1  - Clemson University, Clemson, South Carolina, USA
LA  - en
KW  - Modality (human–computer interaction)
KW  - Handwriting
KW  - Affect
KW  - Modalities
VL  - 19
IS  - 4
SP  - 1
EP  - 19
ER  -
TY  - JOUR
TI  - Haptically generated paths of an AFM-based nanomanipulator using potential fields
PY  - 2005
DO  - 10.1109/nano.2004.1392349
UR  - https://doi.org/10.1109/nano.2004.1392349
DA  - 2005-04-01
AU  - Ammi, Mehdi
C1  - Lab. Vision et Robotique, Bourges, France
AU  - Ferreira, Antoine
C1  - Lab. Vision et Robotique, Bourges, France
LA  - en
KW  - Planner
KW  - Obstacle avoidance
KW  - Representation
KW  - Operator (biology)
SP  - 355
EP  - 357
ER  -
TY  - JOUR
TI  - An Experimental Study on the Performance of Haptic Data Transmission in Networked Haptic Collaboration
PY  - 2007
PB  - Institute of Electrical and Electronics Engineers
SN  - 1738-9445
T2  - International Conference on Advanced Communication Technology
DO  - 10.1109/icact.2007.358441
UR  - https://doi.org/10.1109/icact.2007.358441
DA  - 2007-02-01
AU  - You, Yonghee
C1  - Computer Science & Engineering Department, University of Incheon, Incheon 402-749, South Korea. e-mail: yhinfuture@incheon.ac.kr
AU  - Sung, Mee
C1  - Computer Science & Engineering Department, University of Incheon, Incheon 402-749, South Korea. phone: 82-32-770-8496; fax: 82-32-766-6894; e-mail: mysung@incheon.ac.kr
AU  - Kim, Nam-joong
C1  - Computer Science & Engineering Department, University of Incheon, Incheon 402-749, South Korea. e-mail: water09z@incheon.ac.kr
AU  - Jun, Kyungkoo
C1  - Multimedia Systems Engineering Department, University of Incheon, Incheon 402-749, South Korea. e-mail: kjun@incheon.ac.kr
LA  - en
SP  - 657
EP  - 662
ER  -
TY  - JOUR
TI  - GAVRe<sup>2</sup>: Towards Data-Driven Upper-Limb Rehabilitation with Adaptive-Feedback Gamification
PY  - 2018
T2  - 2021 IEEE International Conference on Robotics and Biomimetics (ROBIO)
DO  - 10.1109/robio.2018.8665105
UR  - https://doi.org/10.1109/robio.2018.8665105
DA  - 2018-12-01
AU  - Lai, Yujun
C1  - Centre for Autonomous Systems (CAS), University of Technology Sydney (UTS)
AU  - Sutjipto, Sheila
C1  - Centre for Autonomous Systems (CAS), University of Technology Sydney (UTS)
AU  - Clout, Matthew
C1  - Centre for Autonomous Systems (CAS), University of Technology Sydney (UTS)
AU  - Carmichael, Marc
C1  - Centre for Autonomous Systems (CAS), University of Technology Sydney (UTS)
AU  - Paul, Gavin
C1  - Centre for Autonomous Systems (CAS), University of Technology Sydney (UTS)
LA  - en
SP  - 164
EP  - 169
AB  - This paper presents Game Adaptive Virtual Reality Rehabilitation (GAVRe <sup xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">2</sup> ), a framework to augment upper limb rehabilitation using Virtual Reality (VR) gamification and haptic robotic manipulator feedback. GAVRe <sup xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">2</sup> integrates independent systems in a modular fashion, connecting patients with therapists remotely to increase patient engagement during rehabilitation. GAVRe <sup xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">2</sup> exploits VR capabilities to not only increase the productivity of therapists administering rehabilitation, but also to improve rehabilitation mobility for patients. Conventional rehabilitation requires face-to-face physical interactions in a clinical setting which can be inconvenient for patients. The GAVRe <sup xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">2</sup> approach provides an avenue for rehabilitation in a domestic setting by remotely customizing a routine for the patient. Results are then reported back to therapists for data analysis and future training regime development. GAVRe <sup xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">2</sup> is evaluated experimentally through a system that integrates a popular VR system, a RGB-D camera, and a collaborative industrial robot, with results indicating potential benefits for long-term rehabilitation and the opportunity for upper limb rehabilitation in a domestic setting.
ER  -
TY  - JOUR
TI  - Virtual reality platform for design and evaluation of human-robot collaboration in assembly manufacturing
PY  - 2023
PB  - Inderscience Publishers
SN  - 1750-0591
T2  - International Journal of Manufacturing Research
DO  - 10.1504/ijmr.2023.129303
UR  - https://doi.org/10.1504/ijmr.2023.129303
DA  - 2023-01-01
AU  - Gustavsson, Patrik
C1  - Production and Automation Engineering, University of Skövde, Högskolevägen 1 - 541 40, Skövde, Sweden
AU  - Syberfeldt, Anna
C1  - Production and Automation Engineering, University of Skövde, Högskolevägen 1 - 541 40, Skövde, Sweden
AU  - Holm, Magnus
C1  - Production and Automation Engineering, University of Skövde, Högskolevägen 1 - 541 40, Skövde, Sweden
LA  - en
KW  - Human–robot interaction
VL  - 18
IS  - 1
SP  - 28
EP  - 28
ER  -
TY  - JOUR
TI  - An Integrated Haptic Data Transmission in Haptic Collaborative Virtual Environments
PY  - 2007
DO  - 10.1109/icis.2007.58
UR  - https://doi.org/10.1109/icis.2007.58
DA  - 2007-01-01
AU  - You, Yonghee
C1  - Univ. of lncheon, Incheon
AU  - Sung, Mee
C1  - Univ. of lncheon, Incheon
AU  - Jun, Kyungkoo
C1  - University of Incheon, Korea#TAB#
LA  - en
KW  - Stereotaxy
SP  - 834
EP  - 839
ER  -
TY  - JOUR
TI  - What Is Happening Behind The Wall?
PY  - 2022
PB  - Association for Computing Machinery
SN  - 2573-0142
T2  - Proceedings of the ACM on Human-Computer Interaction
DO  - 10.1145/3546731
UR  - https://doi.org/10.1145/3546731
DA  - 2022-09-19
AU  - Kassem, Khaled
C1  - TU Wien, Vienna, Austria
AU  - Ungerböck, Tobias
C1  - TU Wien, Vienna, Austria
AU  - Wintersberger, Philipp
C1  - TU Wien, Vienna, Austria
AU  - Michahelles, Florian
C1  - TU Wien, Vienna, Austria
LA  - en
KW  - Modalities
KW  - Human–robot interaction
KW  - Modality (human–computer interaction)
KW  - Audio feedback
KW  - Cognitive Load
KW  - Sight
KW  - Baseline (sea)
VL  - 6
IS  - MHCI
SP  - 1
EP  - 19
AB  - Research in human-robot collaboration explores aspects of using interaction modalities and their effect on human perception. Particular attention is paid to intent communication, which is essential for successful interaction and collaboration. This work investigates the effect of using audio, visual, and haptic feedback on intent communication in a human-robot collaboration task where the collaborators do not share a direct line of sight. A user study was conducted in virtual reality with 20 participants. Qualitative and quantitative feedback was collected from all participants. When compared with a baseline of no feedback given to the participants, results show that using visual feedback had a significant impact on task efficiency, user experience, and cognitive load. Audio feedback was slightly less impactful, while haptic feedback had a divisive effect. Multimodal feedback combining the three modalities showed the highest impact compared to the individual modalities, leading to the highest task efficiency and user experience, and the lowest cognitive load.
ER  -
TY  - JOUR
TI  - Consumer Electronics Technologies for Enabling an Immersive Metaverse Experience
PY  - 2023
PB  - Institute of Electrical and Electronics Engineers
SN  - 2162-2248
T2  - IEEE Consumer Electronics Magazine
DO  - 10.1109/mce.2023.3327530
UR  - https://doi.org/10.1109/mce.2023.3327530
DA  - 2023-10-25
AU  - Sai, Siva
C1  - Birla Institute of Technology and Science Pilani, Pilani campus, India
AU  - Goyal, D.P.
C1  - Birla Institute of Technology and Science Pilani, Pilani campus, India
AU  - Chamola, Vinay
C1  - Birla Institute of Technology and Science Pilani, Pilani campus, India
AU  - Sikdar, Biplab
C1  - National University of Singapore, Singapore
LA  - en
KW  - Metaverse
VL  - 13
IS  - 3
SP  - 16
EP  - 24
ER  -
TY  - JOUR
TI  - Design and Evaluation of a Virtual Training Environment for Industrial Assembly Tasks
PY  - 2021
PB  - RELX Group (Netherlands)
SN  - 1556-5068
T2  - SSRN Electronic Journal
DO  - 10.2139/ssrn.3862367
UR  - https://doi.org/10.2139/ssrn.3862367
DA  - 2021-01-01
AU  - Niedermayr, Daniel
C1  - Upper Austria - University of Applied Sciences Upper Austria
AU  - Wolfartsberger, Josef
C1  - Upper Austria - University of Applied Sciences Upper Austria
LA  - en
ER  -
TY  - JOUR
TI  - Enaction and Enactive Interfaces: A Handbook of Terms
PY  - 2017
DA  - 2017-11-30
AU  - Aprile, Walter
C1  - PERCRO - Perceptual Robotics Laboratory (PERCRO - Scuola Superiore Sant'Anna Via Martiri 11, 56127 Pisa - Italy Via Rinaldo Piaggio 34, 56025 Pontedera (PI) - Italy Via Valdicocchi 15, 19135 La Spezia - Italy - Italy)
AU  - Avanzini, Federico
C1  - DEI - Departamento de Engenharia Informática / Department of Informatics Engineering (Departamento de Engenharia Informática Faculdade de Ciências e Tecnologia Universidade de Coimbra Pólo II - Pinhal de Marrocos 3030-290 Coimbra - Portugal)
AU  - Barbero, J.
C1  - LABEIN (France)
AU  - Bardy, Benoît
C1  - UM1 Médecine - Université Montpellier 1 - UFR de Médecine (2 rue École de Médecine - CS 59001 - 34060 Montpellier cedex 2 - France)
AU  - Boulic, Ronan
C1  - EPFL - Ecole Polytechnique Fédérale de Lausanne (CH-1015 Lausanne, Switzerland - Switzerland)
AU  - Bullot, Nicolas
C1  - IJN - Institut Jean-Nicod (Pavillon Jardin 29, rue d'Ulm 75005 Paris - France)
AU  - Bülthoff, HH
C1  - Max Planck Institute for Biological Cybernetics (Spemannstr. 44, 72076 Tübingen, Germany - Germany)
AU  - Cadoz, Claude
C1  - ACROE - ACROE (46 av. Félix Viallet - 38031 Grenoble Cedex - France)
AU  - Camurri, Antonio
C1  - DIST - Dipartimento di Informatica, Sistemistica e Telematica (Dipartimento di Informatica, Sistemistica e Telematica Viale F. Causa, 13 16145 GENOVA - ITALIA - France)
AU  - Carozzino, Marcello
C1  - PERCRO - Perceptual Robotics Laboratory (PERCRO - Scuola Superiore Sant'Anna Via Martiri 11, 56127 Pisa - Italy Via Rinaldo Piaggio 34, 56025 Pontedera (PI) - Italy Via Valdicocchi 15, 19135 La Spezia - Italy - Italy)
AU  - Carvalho, Schubert
C1  - VRLab - Virtual Reality Lab [EPFL] (Ecole Polytechnique Fédérale de Lausanne (EPFL) IC ISIM VRLAB Station 14 CH-1015 LAUSANNE - Switzerland)
AU  - Castagné, Nicolas
C1  - Grenoble INP - Institut polytechnique de Grenoble - Grenoble Institute of Technology (46 avenue Félix Viallet 38031 Grenoble Cedex 1 - France)
AU  - Chaudhuri, Parag
C1  - UniGe - Università degli studi di Genova = University of Genoa (Via Balbi, 5 - 16126 Genova - Italy)
AU  - Couroussé, Damien
C1  - ACROE - ACROE (46 av. Félix Viallet - 38031 Grenoble Cedex - France)
AU  - Davy, Pierre
C1  - UniGe - Università degli studi di Genova = University of Genoa (Via Balbi, 5 - 16126 Genova - Italy)
AU  - De Boeck, Joan
C1  - UHasselt - Hasselt University (Campus Hasselt | Martelarenlaan 42 | BE3500 Hasselt
Campus Diepenbeek | Agoralaan gebouw D | BE3590 Diepenbeek - Belgium)
AU  - de Götzen, Amalia
C1  - DEI - Departamento de Engenharia Informática / Department of Informatics Engineering (Departamento de Engenharia Informática Faculdade de Ciências e Tecnologia Universidade de Coimbra Pólo II - Pinhal de Marrocos 3030-290 Coimbra - Portugal)
AU  - Delignière, Didier
C1  - UM1 Médecine - Université Montpellier 1 - UFR de Médecine (2 rue École de Médecine - CS 59001 - 34060 Montpellier cedex 2 - France)
AU  - Eftring, Håkan
C1  - Department of Communication and Media (Lund - Sweden)
AU  - Evrard, Matthieu
C1  - Grenoble INP - Institut polytechnique de Grenoble - Grenoble Institute of Technology (46 avenue Félix Viallet 38031 Grenoble Cedex 1 - France)
AU  - Faste, Haakon
C1  - PERCRO - Perceptual Robotics Laboratory (PERCRO - Scuola Superiore Sant'Anna Via Martiri 11, 56127 Pisa - Italy Via Rinaldo Piaggio 34, 56025 Pontedera (PI) - Italy Via Valdicocchi 15, 19135 La Spezia - Italy - Italy)
AU  - Florens, Jean-Loup
C1  - ACROE - ACROE (46 av. Félix Viallet - 38031 Grenoble Cedex - France)
AU  - Fontana, Marco
C1  - PERCRO - Perceptual Robotics Laboratory (PERCRO - Scuola Superiore Sant'Anna Via Martiri 11, 56127 Pisa - Italy Via Rinaldo Piaggio 34, 56025 Pontedera (PI) - Italy Via Valdicocchi 15, 19135 La Spezia - Italy - Italy)
AU  - García-Rojas, Alejandra
C1  - VRLab - Virtual Reality Lab [EPFL] (Ecole Polytechnique Fédérale de Lausanne (EPFL) IC ISIM VRLAB Station 14 CH-1015 LAUSANNE - Switzerland)
AU  - Jorge, Juan
C1  - CEIT and Tecnun (Spain)
AU  - Glowinski, Donald
C1  - DIST - Dipartimento di Informatica, Sistemistica e Telematica (Dipartimento di Informatica, Sistemistica e Telematica Viale F. Causa, 13 16145 GENOVA - ITALIA - France)
AU  - Grillon, Helena
C1  - VRLab - Virtual Reality Lab [EPFL] (Ecole Polytechnique Fédérale de Lausanne (EPFL) IC ISIM VRLAB Station 14 CH-1015 LAUSANNE - Switzerland)
AU  - Gutierrez, Tereza
C1  - LABEIN (Spain)
AU  - Isableu, Brice
C1  - UM1 Médecine - Université Montpellier 1 - UFR de Médecine (2 rue École de Médecine - CS 59001 - 34060 Montpellier cedex 2 - France)
AU  - Jansson, Gunnar
C1  - Uppsala Universitet [Uppsala] (P.O. Box 256, SE-751 05 Uppsala - Sweden)
AU  - Khatchatourov, Armen
C1  - COSTECH - Connaissance Organisation et Systèmes TECHniques (Université de Technologie de Compiègne - Centre de Recherche de Royallieu - rue du Docteur Schweitzer- CS 60319 - 60203 COMPIEGNE Cedex - France)
AU  - Lagarde, Julien
C1  - UM1 Médecine - Université Montpellier 1 - UFR de Médecine (2 rue École de Médecine - CS 59001 - 34060 Montpellier cedex 2 - France)
AU  - Lenay, Charles
C1  - COSTECH - Connaissance Organisation et Systèmes TECHniques (Université de Technologie de Compiègne - Centre de Recherche de Royallieu - rue du Docteur Schweitzer- CS 60319 - 60203 COMPIEGNE Cedex - France)
AU  - Magnusson, Charlotte
C1  - Department of Communication and Media (Lund - Sweden)
AU  - Mantel, Bruno
C1  - UM1 Médecine - Université Montpellier 1 - UFR de Médecine (2 rue École de Médecine - CS 59001 - 34060 Montpellier cedex 2 - France)
AU  - Marín, Ludovic
C1  - UM1 Médecine - Université Montpellier 1 - UFR de Médecine (2 rue École de Médecine - CS 59001 - 34060 Montpellier cedex 2 - France)
AU  - Marogna, Riccardo
C1  - DEI - Departamento de Engenharia Informática / Department of Informatics Engineering (Departamento de Engenharia Informática Faculdade de Ciências e Tecnologia Universidade de Coimbra Pólo II - Pinhal de Marrocos 3030-290 Coimbra - Portugal)
AU  - Maupu, Damien
C1  - VRLab - Virtual Reality Lab [EPFL] (Ecole Polytechnique Fédérale de Lausanne (EPFL) IC ISIM VRLAB Station 14 CH-1015 LAUSANNE - Switzerland)
AU  - Mazzarino, Barbara
C1  - DIST - Dipartimento di Informatica, Sistemistica e Telematica (Dipartimento di Informatica, Sistemistica e Telematica Viale F. Causa, 13 16145 GENOVA - ITALIA - France)
AU  - Mion, Luca
C1  - DEI - Departamento de Engenharia Informática / Department of Informatics Engineering (Departamento de Engenharia Informática Faculdade de Ciências e Tecnologia Universidade de Coimbra Pólo II - Pinhal de Marrocos 3030-290 Coimbra - Portugal)
AU  - Nusseck, Manfred
C1  - Max Planck Institute for Biological Cybernetics (Spemannstr. 44, 72076 Tübingen, Germany - Germany)
AU  - O’reagan, Kevin
C1  - LPP - Laboratoire psychologie de la perception (ENS PARIS 29, rue d'Ulm 75005 PARIS - France)
AU  - Ott, Renaud
C1  - VRLab - Virtual Reality Lab [EPFL] (Ecole Polytechnique Fédérale de Lausanne (EPFL) IC ISIM VRLAB Station 14 CH-1015 LAUSANNE - Switzerland)
AU  - Pasquinelli, Elena
C1  - IJN - Institut Jean-Nicod (Pavillon Jardin 29, rue d'Ulm 75005 Paris - France)
AU  - Peternier, Achille
C1  - VRLab - Virtual Reality Lab [EPFL] (Ecole Polytechnique Fédérale de Lausanne (EPFL) IC ISIM VRLAB Station 14 CH-1015 LAUSANNE - Switzerland)
AU  - Polvani, Ilaria
C1  - PERCRO - Perceptual Robotics Laboratory (PERCRO - Scuola Superiore Sant'Anna Via Martiri 11, 56127 Pisa - Italy Via Rinaldo Piaggio 34, 56025 Pontedera (PI) - Italy Via Valdicocchi 15, 19135 La Spezia - Italy - Italy)
AU  - Portillo-Rodríguez, Otniel
C1  - PERCRO - Perceptual Robotics Laboratory (PERCRO - Scuola Superiore Sant'Anna Via Martiri 11, 56127 Pisa - Italy Via Rinaldo Piaggio 34, 56025 Pontedera (PI) - Italy Via Valdicocchi 15, 19135 La Spezia - Italy - Italy)
AU  - Sánchez, Emilio
C1  - CEIT & TECNUM (San Sebastian - France)
AU  - Stewart, John
C1  - COSTECH - Connaissance Organisation et Systèmes TECHniques (Université de Technologie de Compiègne - Centre de Recherche de Royallieu - rue du Docteur Schweitzer- CS 60319 - 60203 COMPIEGNE Cedex - France)
AU  - Stoffregen, Thomas
C1  - HFRL - Human Factors of Research Laboratory (United States)
AU  - Summer, Ian
C1  - University of Exeter Medical School (St Luke's Campus, Heavitree Road, Exeter, EX1 2LU - United Kingdom)
AU  - Tache, Olivier
C1  - ACROE - ACROE (46 av. Félix Viallet - 38031 Grenoble Cedex - France)
AU  - Thouvenin, Indira
C1  - COSTECH - Connaissance Organisation et Systèmes TECHniques (Université de Technologie de Compiègne - Centre de Recherche de Royallieu - rue du Docteur Schweitzer- CS 60319 - 60203 COMPIEGNE Cedex - France)
AU  - Varni, Giovanna
C1  - DIST - Dipartimento di Informatica, Sistemistica e Telematica (Dipartimento di Informatica, Sistemistica e Telematica Viale F. Causa, 13 16145 GENOVA - ITALIA - France)
AU  - Volpe, Gualtiero
C1  - DIST - Dipartimento di Informatica, Sistemistica e Telematica (Dipartimento di Informatica, Sistemistica e Telematica Viale F. Causa, 13 16145 GENOVA - ITALIA - France)
AU  - Ziat, Mounia
C1  - COSTECH - Connaissance Organisation et Systèmes TECHniques (Université de Technologie de Compiègne - Centre de Recherche de Royallieu - rue du Docteur Schweitzer- CS 60319 - 60203 COMPIEGNE Cedex - France)
AU  - Luciani, Annie
C1  - ACROE - ACROE (46 av. Félix Viallet - 38031 Grenoble Cedex - France)
LA  - en
KW  - Paradigm shift
KW  - Teleoperation
AB  - Enaction is a recent approach in psychology and in cognitive sciences and it remains not easy to understand and to situate. Its introduction in the field of Computer Technology and Multimodal Interfaces has been initiated explicitly in the FP6 Enactive Interfaces Network of Excellence. It is nothing less than a conceptual revolution, an important paradigm shift. Enaction and Enactive Interfaces: an handbook of Terms aims at overcoming the interdisciplinary gap inherent to this new paradigm. It has been designed as a tool to constitute a common vision on Enaction, Enactive Interaction, Enaction Knowledge and Enactive systems, allowing students and researchers to reach, at a glance, a sufficient interdisciplinary level, in order to tackle efficiently the new question of  Enaction and Technology . Differently from dictionaries, terms are related to research in progress, addressing debates or schools differentiations, addressing other unfamiliar frameworks for laypersons of other disciplines. The handbook comprises about 200 terms covering the different fields necessary to explore the landscape of enaction and technologies: sensory-motor theories of interaction, multimodal integration, haptic and multimodal interfaces, instrumental interaction, virtual reality, design, human-computer interfaces, paradigms in cognitive sciences, robotics and teleoperation. Most of them have been written in collaboration by authors from different disciplines. Some had already a long history. The text does not only provide a definition, but revisits the term in depth, under the light of Enaction and Enactive Interfaces. Other terms are fully novel, in which case the text allows introducing the new concepts at hand. Some of them led to multiple definitions, whether because they represent stabilized different definitions in different disciplines whether because they underlie non-reducible schools and approaches.
ER  -
TY  - JOUR
TI  - VR-Based Haptic Simulator for Subsea Robot Teleoperations
PY  - 2022
PB  - American Society of Civil Engineers
T2  - Computing in Civil Engineering
DO  - 10.1061/9780784483893.126
UR  - https://doi.org/10.1061/9780784483893.126
DA  - 2022-05-24
AU  - Xu, Fang
C1  - Assistant Professor, Dept. of Civil and Environmental Engineering, Univ. of Tennessee, Knoxville, TN.
C1  - Assistant Professor, Dept. of Mechanical Engineering, Univ. of Hawaii at Manoa, Honolulu, HI.
C1  - Associate Professor, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
C1  - Ph.D. Student, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
AU  - Zhu, Qi
C1  - Assistant Professor, Dept. of Civil and Environmental Engineering, Univ. of Tennessee, Knoxville, TN.
C1  - Assistant Professor, Dept. of Mechanical Engineering, Univ. of Hawaii at Manoa, Honolulu, HI.
C1  - Associate Professor, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
C1  - Ph.D. Student, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
AU  - Li, Shuai
C1  - Assistant Professor, Dept. of Civil and Environmental Engineering, Univ. of Tennessee, Knoxville, TN.
C1  - Assistant Professor, Dept. of Mechanical Engineering, Univ. of Hawaii at Manoa, Honolulu, HI.
C1  - Associate Professor, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
C1  - Ph.D. Student, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
AU  - Song, Zhuoyuan
C1  - Assistant Professor, Dept. of Civil and Environmental Engineering, Univ. of Tennessee, Knoxville, TN.
C1  - Assistant Professor, Dept. of Mechanical Engineering, Univ. of Hawaii at Manoa, Honolulu, HI.
C1  - Associate Professor, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
C1  - Ph.D. Student, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
AU  - Du, Jing
C1  - Assistant Professor, Dept. of Civil and Environmental Engineering, Univ. of Tennessee, Knoxville, TN.
C1  - Assistant Professor, Dept. of Mechanical Engineering, Univ. of Hawaii at Manoa, Honolulu, HI.
C1  - Associate Professor, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL
C1  - Associate Professor, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
C1  - Ph.D. Student, Informatics, Cobots, and Intelligent Construction (ICIC) Lab, Dept. of Civil and Coastal Engineering, Univ. of Florida, Gainesville, FL.
LA  - en
KW  - Subsea
KW  - Telerobotics
KW  - Remotely operated vehicle
KW  - Operator (biology)
SP  - 1024
EP  - 1032
ER  -
TY  - JOUR
TI  - Haptic Simulation of the Liver with Respiratory Motion
PY  - 2009
PB  - IOS Press
SN  - 0926-9630
T2  - Studies in health technology and informatics
DO  - 10.3233/978-1-58603-964-6-401
UR  - https://doi.org/10.3233/978-1-58603-964-6-401
DA  - 2009-01-01
AU  - Villard, Pierre-Frédéric
C1  - Biosurgery and Surgical Technology, Imperial College, London, UK. p.villard@imperial.ac.uk
AU  - Jacob, Mathieu
AU  - Gould, Derek
AU  - Bello, Fernando
LA  - en
AB  - During a standard procedure of liver biopsy, the motion due to respiration may be difficult to handle. The patient is often requested to hold his breath or to breathe shallowly. Ideally, this physiological behaviour should be taken into account in a virtual reality biopsy simulator. This paper presents a framework that accurately simulates respiratory motion, allowing for the fine tuning of relevant parameters in order to produce a patient-specific breathing pattern that can then be incorporated into a simulation with real-rime haptic interaction. This work has been done as part of the CRaIVE collaboration [1], which aims to build interventional radiology simulators.
ER  -
TY  - JOUR
TI  - Application of virtual reality and haptics system Simodont in Chinese dental education: A scoping review
PY  - 2023
PB  - Wiley
SN  - 1396-5883
T2  - European Journal Of Dental Education
DO  - 10.1111/eje.12984
UR  - https://doi.org/10.1111/eje.12984
DA  - 2023-12-26
AU  - Huang, Yudong
C1  - Hospital of Stomatology, Guanghua School of Stomatology, Guangdong Provincial Key Laboratory of Stomatology, Sun Yat-Sen University, Guangzhou, Guangdong, China
AU  - Huang, Shuheng
C1  - Hospital of Stomatology, Guanghua School of Stomatology, Guangdong Provincial Key Laboratory of Stomatology, Sun Yat-Sen University, Guangzhou, Guangdong, China
AU  - Liu, Yangjingwen
C1  - Hospital of Stomatology, Guanghua School of Stomatology, Guangdong Provincial Key Laboratory of Stomatology, Sun Yat-Sen University, Guangzhou, Guangdong, China
AU  - Lin, Zhengmei
C1  - Hospital of Stomatology, Guanghua School of Stomatology, Guangdong Provincial Key Laboratory of Stomatology, Sun Yat-Sen University, Guangzhou, Guangdong, China
AU  - Hong, Yun
C1  - Hospital of Stomatology, Guanghua School of Stomatology, Guangdong Provincial Key Laboratory of Stomatology, Sun Yat-Sen University, Guangzhou, Guangdong, China
AU  - Li, Xiaolan
C1  - Hospital of Stomatology, Guanghua School of Stomatology, Guangdong Provincial Key Laboratory of Stomatology, Sun Yat-Sen University, Guangzhou, Guangdong, China
LA  - en
KW  - Dental education
ER  -
TY  - JOUR
TI  - A Physics-based Virtual Reality System Design and Evaluation by Simulating Human-Robot Collaboration
PY  - 2022
DO  - 10.36227/techrxiv.18972773.v1
UR  - https://doi.org/10.36227/techrxiv.18972773.v1
DA  - 2022-01-28
AU  - Chowdhury, S.
AU  - Mubarrat, Syed
AU  - Fernandes, Antonio
LA  - en
KW  - Kinesthetic learning
KW  - Physics engine
AB  - Recent advancements in VR technology facilitate tracking real-world objects and users' movements in the virtual environment (VE) and inspire researchers to develop a physics-based haptic system (i.e., real object haptics) instead of computer-generated haptic feedback. However, there is limited research on the efficacy of such VR systems in enhancing operators’ sensorimotor learning for tasks that require high motor and physical demands. Therefore, this study aimed to design and evaluate the efficacy of a physics-based virtual reality (VR) system that provides users realistic cutaneous and kinesthetic haptic feedback. We designed a physics-based VR system, named PhyVirtual, and simulated human-robot collaborative (HRC) sequential pick-and-place lifting tasks in the VE. Participants performed the same tasks in the real environment (RE) with human-human collaboration instead of human-robot collaboration. We used a custom-designed questionnaire, the NASA-TLX, and electromyography activities from biceps, middle and anterior deltoid muscles to determine user experience, workload, and neuromuscular dynamics, respectively. Overall, the majority of responses (&gt;65%) demonstrated that the system is easy-to-use, easy-to-learn, and effective in improving motor skill performance. While compared to tasks performed in the RE, the PhyVirtual system placed significantly lower physical demand (124.90%; p &lt; 0.05) on the user. The electromyography data exhibited similar trends (p &gt; 0.05; r &gt; 0.89) for both environments. These results show that the PhyVirtual system is an effective tool to simulate safe human-robot collaboration commonly seen in many modern warehousing settings. Moreover, it can be used as a viable replacement for live sensorimotor training in a wide range of fields.
ER  -
TY  - JOUR
TI  - A multimodal teleoperation interface for human-robot collaboration
PY  - 2023
DO  - 10.1109/icm54990.2023.10102060
UR  - https://doi.org/10.1109/icm54990.2023.10102060
DA  - 2023-03-15
AU  - Si, Weiyong
C1  - Faculty of Environment and Technology and Bristol Robotics Lab at the University of the West of England,Bristol,UK,BS16 1QY
AU  - Zhong, Tianjian
C1  - University of Bristol and Bristol Robotics Laboratory,Faculty of Engineering,Bristol,UK,Bristol BS8 1TH
AU  - Wang, Ning
C1  - Faculty of Environment and Technology and Bristol Robotics Lab at the University of the West of England,Bristol,UK,BS16 1QY
AU  - Yang, Chenguang
C1  - Faculty of Environment and Technology and Bristol Robotics Lab at the University of the West of England,Bristol,UK,BS16 1QY
LA  - en
KW  - Teleoperation
KW  - Human–robot interaction
KW  - Interface (matter)
KW  - Multimodal Interaction
KW  - Telerobotics
SP  - 1
EP  - 6
ER  -
TY  - JOUR
TI  - Discrimination of Virtual Environments Under Visual and Haptic Rendering Delays
PY  - 2007
T2  - Frontiers in Convergence of Bioscience and Information Technologies
DO  - 10.1109/fbit.2007.124
UR  - https://doi.org/10.1109/fbit.2007.124
DA  - 2007-01-01
AU  - Lee, In
C1  - Dept. of Comput. Sci. & Eng., Haptics & Virtual Reality Lab., Pohang
AU  - Choi, Seungmoon
C1  - Dept. of Comput. Sci. & Eng., Haptics & Virtual Reality Lab., Pohang
LA  - en
KW  - Software portability
SP  - 554
EP  - 562
ER  -
TY  - JOUR
TI  - Pseudo-Haptics Survey: Human-Computer Interaction in Extended Reality and Teleoperation
PY  - 2024
PB  - Institute of Electrical and Electronics Engineers
SN  - 2169-3536
T2  - IEEE Access
DO  - 10.1109/access.2024.3409449
UR  - https://doi.org/10.1109/access.2024.3409449
DA  - 2024-01-01
AU  - Xavier, Rui
C1  - Instituto Superior T&#x00E9;cnico (IST), University of Lisbon, Lisboa, Portugal
AU  - Silva, José
C1  - ITI/Laboratory of Robotics and Systems in Engineering and Science (LARSyS), Instituto Universit&#x00E1;rio de Lisboa (ISCTE-IUL), Lisboa, Portugal
AU  - Ventura, Rodrigo
C1  - Instituto Superior T&#x00E9;cnico (IST), University of Lisbon, Lisboa, Portugal
AU  - Jorge, Joaquim
C1  - Instituto Superior T&#x00E9;cnico (IST), University of Lisbon, Lisboa, Portugal
LA  - en
KW  - Teleoperation
KW  - Kinesthetic learning
KW  - Multimodal Interaction
VL  - 12
SP  - 80442
EP  - 80467
AB  - Pseudo-haptic techniques are becoming increasingly popular in human-computer interaction. They replicate haptic sensations by leveraging primarily visual feedback rather than mechanical actuators. These techniques bridge the gap between the real and virtual worlds by exploring the brain's ability to integrate visual and haptic information. One of the many advantages of pseudo-haptic techniques is that they are cost-effective, portable, and flexible. They eliminate the need for direct attachment of haptic devices to the body, which can be heavy and large and require a lot of power and maintenance. Recent research has focused on applying these techniques to extended reality and mid-air interactions. To better understand the potential of pseudo-haptic techniques, the authors developed a novel taxonomy encompassing tactile feedback, kinesthetic feedback, and combined categories in multimodal approaches, ground not covered by previous surveys. This survey highlights multimodal strategies and potential avenues for future studies, particularly regarding integrating these techniques into extended reality and collaborative virtual environments.
ER  -
TY  - JOUR
TI  - A hardware and software architecture to deal with multimodal and collaborative interactions in multiuser virtual reality environments
PY  - 2014
PB  - SPIE
SN  - 0277-786X
T2  - Proceedings of SPIE, the International Society for Optical Engineering/Proceedings of SPIE
DO  - 10.1117/12.2042499
UR  - https://doi.org/10.1117/12.2042499
DA  - 2014-02-28
AU  - Martin, Pierre
C1  - Lab. d'Informatique pour la Mécanique et les Sciences de l'Ingénieur, CNRS, Univ. Paris Sud (France)
AU  - Tseu, A.
C1  - Lab. d'Informatique pour la Mécanique et les Sciences de l'Ingénieur, CNRS, Univ. Paris Sud (France)
AU  - Férey, Nicolas
C1  - Lab. d'Informatique pour la Mécanique et les Sciences de l'Ingénieur, CNRS, Univ. Paris Sud (France)
AU  - Touraine, Damien
C1  - Lab. d'Informatique pour la Mécanique et les Sciences de l'Ingénieur, CNRS, Univ. Paris Sud (France)
AU  - Bourdot, Patrick
C1  - Lab. d'Informatique pour la Mécanique et les Sciences de l'Ingénieur, CNRS, Univ. Paris Sud (France)
LA  - en
VL  - 9012
SP  - 901209
EP  - 901209
ER  -
TY  - JOUR
TI  - A Platform for Mechanical Assembly Education Using the Microsoft Kinect
PY  - 2014
DO  - 10.1115/imece2014-38606
UR  - https://doi.org/10.1115/imece2014-38606
DA  - 2014-11-14
AU  - Chang, Yizhe
C1  - Stevens Institute of Technology, Hoboken, NJ
AU  - Aziz, El‐Sayed
C1  - Stevens Institute of Technology, Hoboken, NJ
AU  - Zhang, Zhou
C1  - Stevens Institute of Technology, Hoboken, NJ
AU  - Zhang, Mingshao
C1  - Stevens Institute of Technology, Hoboken, NJ
AU  - Esche, Sven
C1  - Stevens Institute of Technology, Hoboken, NJ
AU  - Chassapis, Constantin
C1  - Stevens Institute of Technology, Hoboken, NJ
LA  - en
KW  - Implementation
KW  - Match moving
KW  - Tracking (education)
ER  -
TY  - JOUR
TI  - Recent Advances in Social &amp; Cognitive Robotics and Imminent Ethical Challenges
PY  - 2018
DO  - 10.2991/rais-18.2018.12
UR  - https://doi.org/10.2991/rais-18.2018.12
DA  - 2018-01-01
AU  - Meghdari, Ali
C1  - Social & Cognitive Robotics Laboratory, Sharif University of Technology, Tehran, Iran,
AU  - Alemi, Minoo
C1  - Department of Humanities, Islamic Azad University-West Tehran Branch, Tehran, Iran
C1  - Social & Cognitive Robotics Laboratory, Sharif University of Technology, Tehran, Iran,
LA  - en
AB  - One of the main challenges in developing and applying modern technologies in our societies is the identification and consideration of ethical issues.With the dramatic growth of emerging technologies in today's societies, such as social robots, lifelike computer graphics (avatars), and virtual reality tools and haptic systems, the social complexity of these challenges is on the rise.To be prepared to face these challenges, researchers in engineering sciences and humanities are forming interdisciplinary research groups/activities and try to determine the rate of evolution as well as the effects of socio-cognitive systems on human interaction with intelligent tools and/or artificial agents.A growing number of social robotics researchers are seeking to create a framework to benefit from humanities, philosophy, sociology, and social neuroscience expertise and research.Likewise, growing trends of mutual collaboration among scholars in the field of human sciences, linguistics, and psychology with the robotics scientists are producing quite noticeable valuable results.This paper presents an overview of the novel and multidisciplinary area of socio-cognitive robotics, and further explores the possible ethical challenges of emerging technologies on education, culture, entertainment, gaming, nursing, and therapy.In addition, some key ethical features based on our past and present research experiences in a variety of areas in designing safe social robots are also presented.
ER  -
TY  - JOUR
TI  - A modular bilateral haptic control framework for teleoperation of robots
PY  - 2018
PB  - Cambridge University Press
SN  - 0263-5747
T2  - Robotica
DO  - 10.1017/s0263574718001042
UR  - https://doi.org/10.1017/s0263574718001042
DA  - 2018-10-30
AU  - Bayraktaroglu, Zeki
C1  - Istanbul Technical University
AU  - Argin, Omer
C1  - Istanbul Technical University
AU  - Haliyo, Sinan
C1  - Institut des Systèmes Intelligents et de Robotique
C1  - Interactions Multi-échelles
LA  - en
KW  - Teleoperation
KW  - Modularity
KW  - Human-in-the-loop
KW  - Remote operation
VL  - 37
IS  - 2
SP  - 338
EP  - 357
AB  - SUMMARY This paper presents a novel approach to implement bilateral control loops between local haptic devices and remote industrial manipulators using a layer of simulation and virtual reality. The remote scene of manipulation has been visualized in an open-source software environment, where forward and inverse kinematics of the manipulators can be computed. Therefore, the explicit knowledge of mathematical models of the robots is not required for the implementation of the proposed bilateral control schemes. A haptic coupling has been designed between the human operator and the task in the remote environment. Virtually introduced force feedback has contributed to the performance of the proposed bilateral loop by facilitating the adaptation of unexperienced human operators. Teleoperation of one remote manipulator has been experimentally demonstrated with the proposed controllers. Structural modularity of the bilateral haptic control schemes makes them directly extendable for the teleoperation of multiple collaborative robots. Stability and transparency of the proposed bilateral haptic controllers have been theoretically and experimentally investigated.
ER  -
TY  - JOUR
TI  - Development of a Teaching Factory Framework Fusing a Virtual Simulated Machine Shop With The Physical Counterpart For Upscaling Human Machine Interface
PY  - 2021
PB  - RELX Group (Netherlands)
SN  - 1556-5068
T2  - SSRN Electronic Journal
DO  - 10.2139/ssrn.3859139
UR  - https://doi.org/10.2139/ssrn.3859139
DA  - 2021-01-01
AU  - Mourtzis, Dimitris
C1  - Laboratory for Manufacturing Systems & Automation, Department of Mechanical Engineering & Aeronautics, University of Patras, Patras, 26504, Greece
AU  - Angelopoulos, John
C1  - Laboratory for Manufacturing Systems & Automation, Department of Mechanical Engineering & Aeronautics, University of Patras, Patras, 26504, Greece
AU  - Panopoulos, Nikos
C1  - Laboratory for Manufacturing Systems & Automation, Department of Mechanical Engineering & Aeronautics, University of Patras, Patras, 26504, Greece
LA  - en
KW  - Factory (object-oriented programming)
KW  - Interface (matter)
KW  - Human–machine interface
ER  -
TY  - JOUR
TI  - Human-Scale Haptic Interaction using the SPIDAR
PY  - 2009
PB  - Centre National de la Recherche Scientifique
T2  - HAL (Le Centre pour la Communication Scientifique Directe)
DA  - 2009-12-07
AU  - Chamaret, Damien
C1  - LISA - Laboratoire d'Ingéniérie des Systèmes Automatisés (62, avenue notre Dame du Lac 49000 ANGERS - France)
AU  - Naud, Mickaël
C1  - LISA - Laboratoire d'Ingéniérie des Systèmes Automatisés (62, avenue notre Dame du Lac 49000 ANGERS - France)
AU  - Hamon, Ludovic
C1  - LISA - Laboratoire d'Ingéniérie des Systèmes Automatisés (62, avenue notre Dame du Lac 49000 ANGERS - France)
AU  - Ullah, Sehat
C1  - IBISC - Informatique, Biologie Intégrative et Systèmes Complexes (40,rue du pelvoux, Courcouronnes 91020 EVRY CEDEX - France)
C1  - LISA - Laboratoire d'Ingéniérie des Systèmes Automatisés (62, avenue notre Dame du Lac 49000 ANGERS - France)
AU  - Richard, Émmanuelle
C1  - LISA - Laboratoire d'Ingéniérie des Systèmes Automatisés (62, avenue notre Dame du Lac 49000 ANGERS - France)
AU  - Richard, Paul
C1  - LISA - Laboratoire d'Ingéniérie des Systèmes Automatisés (62, avenue notre Dame du Lac 49000 ANGERS - France)
LA  - en
KW  - Immersion
AB  - This paper describes the human-scale virtual reality (VR) platform with force feedback developed at the LISA laboratory in Angers (France) in collaboration with Professor Makoto SATO. A human-scale SPIDAR system provides force feedback to user’s hands using 8 motors placed on the corners of a cubic frame (2m x 2.5m) surrounding the user. Stereoscopic images are displayed on a rear-projected large screen and are viewed using polarized glasses. An immersive sound system and olfactory displays are used for simulation realism and immersion. We present different VR applications that involve and benefit from human-scale string-based haptic interaction. These applications include, virtual prototyping, collaborative work, human factors, virtual fashion design and education.
ER  -
TY  - JOUR
TI  - Force control with hybrid actuator for virtual needle insertion
PY  - 2011
DO  - 10.1109/whc.2011.5945481
UR  - https://doi.org/10.1109/whc.2011.5945481
DA  - 2011-06-01
AU  - Gonenc, Berk
C1  - School of Engineering & Computer Science Washington State University,Vancouver,USA
AU  - Gürocak, Hakan
C1  - School of Engineering & Computer Science Washington State University,Vancouver,USA
LA  - en
KW  - Pneumatic actuator
SP  - 173
EP  - 177
ER  -
TY  - JOUR
TI  - Collaborative software design and modeling in virtual reality
PY  - 2023
PB  - Elsevier BV
SN  - 0950-5849
T2  - Information and Software Technology
DO  - 10.1016/j.infsof.2023.107369
UR  - https://doi.org/10.1016/j.infsof.2023.107369
DA  - 2023-11-20
AU  - Stancek, Martin
C1  - Gratex International a.s., Galvaniho 17/C, Bratislava, 821 04, Slovakia
AU  - Polášek, Ivan
C1  - Comenius University, Faculty of Mathematics, Physics and Informatics, Mlynská dolina F1, Bratislava, 842 48, Slovakia
C1  - Gratex International a.s., Galvaniho 17/C, Bratislava, 821 04, Slovakia
AU  - Zalabai, Tibor
C1  - Gratex International a.s., Galvaniho 17/C, Bratislava, 821 04, Slovakia
AU  - Vincúr, Juraj
C1  - Comenius University, Faculty of Mathematics, Physics and Informatics, Mlynská dolina F1, Bratislava, 842 48, Slovakia
AU  - Jolak, Rodi
C1  - RISE Research Institutes of Sweden, Box 857, Borås, 501 15, Sweden
AU  - Chaudron, Michel
C1  - Eindhoven University of Technology, O.L. Vrouwestraat 1, Eindhoven, 5612 AW, Netherlands
LA  - en
KW  - Interface (matter)
VL  - 166
SP  - 107369
EP  - 107369
AB  - Context: Software engineering is becoming more and more distributed. Developers and other stakeholders are often located in different locations, departments, and countries and operating within different time zones. Most online software design and modeling tools are not adequate for distributed collaboration since they do not support awareness and lack features for effective communication. Objective: The aim of our research is to support distributed software design activities in Virtual Reality (VR). Method: Using design science research methodology, we design and evaluate a tool for collaborative design in VR. We evaluate the collaboration efficiency and recall of design information when using the VR software design environment compared to a non-VR software design environment. Moreover, we collect the perceptions and preferences of users to explore the opportunities and challenges that were incurred by using the VR software design environment. Results: We find that there is no significant difference in the efficiency and recall of design information when using the VR compared to the non-VR environment. Furthermore, we find that developers are more satisfied with collaboration in VR. Conclusion: The results of our research and similar studies show that working in VR is not yet faster or more efficient than working on standard desktops. It is very important to improve the interface in VR (gestures with haptics, keyboard and voice input), as confirmed by the difference in results between the first and second evaluation.
ER  -
TY  - JOUR
TI  - Haptic-enabled Mixed Reality System for Mixed-initiative Remote Robot Control
PY  - 2021
PB  - Cornell University
T2  - arXiv (Cornell University)
DO  - 10.48550/arxiv.2102.03521
UR  - https://doi.org/10.48550/arxiv.2102.03521
DA  - 2021-01-01
AU  - Tian, Yuan
AU  - Li, Lianjun
AU  - Fumagalli, Andrea
AU  - Tanesse, Yonas
AU  - Prabhakaran, Balakrishnan
LA  - en
KW  - Viewpoints
AB  - Robots assist in many areas that are considered unsafe for humans to operate. For instance, in handling pandemic diseases such as the recent Covid-19 outbreak and other outbreaks like Ebola, robots can assist in reaching areas dangerous for humans and do simple tasks such as pick up the correct medicine (among a set of bottles prescribed) and deliver to patients. In such cases, it might not be good to rely on the fully autonomous operation of robots. Since many mobile robots are fully functional with low-level tasks such as grabbing and moving, we consider the mixed-initiative control where the user can guide the robot remotely to finish such tasks. For this mixed-initiative control, the user controlling the robot needs to visualize a 3D scene as seen by the robot and guide it. Mixed reality can virtualize reality and immerse users in the 3D scene that is reconstructed from the real-world environment. This technique provides the user more freedom such as choosing viewpoints at view time. In recent years, benefiting from the high-quality data from Light Detection and Ranging (LIDAR) and RGBD cameras, mixed reality is widely used to build networked platforms to improve the performance of robot teleoperations and robot-human collaboration, and enhanced feedback for mixed-initiative control. In this paper, we proposed a novel haptic-enabled mixed reality system, that provides haptic interfaces to interact with the virtualized environments and give remote guidance for mobile robots towards high-level tasks. The experimental results show the effectiveness and flexibility of the proposed haptic enabled mixed reality system.
ER  -
TY  - JOUR
TI  - Pedagogy of uncertainty
PY  - 2022
PB  - Tuwhera Open Access Publisher
SN  - 2624-4705
T2  - Pacific Journal of Technology Enhanced Learning
DO  - 10.24135/pjtel.v4i1.147
UR  - https://doi.org/10.24135/pjtel.v4i1.147
DA  - 2022-02-08
AU  - Videla, Ronnie
C1  - Universidad de La Serena
AU  - Aguayo, Claudio
C1  - Auckland University of Technology
LA  - en
KW  - Emerging Technologies
VL  - 4
IS  - 1
SP  - 29
EP  - 30
AB  - Educators around the world are facing the challenges and opportunities of 21st Century education, such as the COVID-19 pandemic, STEAM education, and the rise of digital immersive technologies presenting a promising field for the development of new ways to maximize the learning experience (Bakker, Cai &amp; Zenger, 2021) The integration of science, technology, engineering, art and mathematics (STEAM) offers an approach to educational design based on curricular integration and learning by doing with analog and virtual technologies (Quigley et al., 2020). In turn, STEAM promotes important pedagogical changes that encourage the development of new skills focused on collaborative work, inquiry and creativity in the face of a challenge or problem to be solved, as well as optimal sensorimotor deployment through haptic and visual perception when using emerging digital immersion technologies such as virtual and augmented reality (Videla-Reyes, Aguayo &amp; Veloz, 2021). All these changes lead to a new framework of pedagogical action based on uncertainty, since they are unfamiliar or unknown in the field of traditional education.&#x0D; &#x0D; Based on the above, we propose here the idea of a ​​’pedagogy of uncertainty’, which can be read in light of the latest and unpredictable changes that 21st Century education is experiencing due to the COVID-19 pandemic, the emergence of technological tools and unfamiliar virtual and online platforms that teachers and students had to learn and use during the march of the virus. The approach that we suggest here is based on the potential of STEAM educational environment design that focuses on providing signs or patterns of an emerging world, unlike traditional teaching methods in which the path to which students should arrive is already laid down in advance. From a STEAM educational design approach, the teacher and her/his students lay down a path in walking together, a motto used by the enactive approach to cognition that considers "cognition as embodied action that is always oriented towards something absent: on the one hand, there is always a next step for the system in its perceptually guided action; for the rest, the acts of the system are always directed towards situations that are not yet in act” (Varela, Thompson &amp; Rosch, 1991, p.238). In this presentation, we explore the notion of pedagogy of uncertainty in the light of enactivism, based on theoretical and empirical evidence about how teachers and students deal with an uncertain world by actively participating in integrated educational environments based on learning by doing approaches (Abrahamson, Dutton &amp; Bakker, 2021). In particular, we make special reference to how teachers can make their students learn from clues, impoverished traces, or traces of information available within their learning environments to solve a challenge or problem, to the extent that they investigate, create, manufacture and/or actively participate in technology inside and beyond the classroom.
ER  -
TY  - JOUR
TI  - A haptic interface design for a VR-based unskilled doctor training system in Vascular Interventional Surgery
PY  - 2014
DO  - 10.1109/icma.2014.6885880
UR  - https://doi.org/10.1109/icma.2014.6885880
DA  - 2014-08-01
AU  - Guo, Jin
C1  - Grad. Sch. of Eng., Kagawa Univ., Kagawa, Japan
AU  - Guo, Shuxiang
C1  - Intell. Mech. Syst. Eng. Dept., Kagawa Univ., Kagawa, Japan
LA  - en
KW  - Interface (matter)
KW  - Interface design
SP  - 1259
EP  - 1263
ER  -
TY  - JOUR
TI  - Collaborative voxel-based surgical virtual environments.
PY  - 2008
PB  - National Institutes of Health
T2  - PubMed
DA  - 2008-01-01
AU  - Acosta, Eric
C1  - The National Capital Area Medical Simulation Center, Uniformed Services University, USA.
AU  - Muniz, Gilbert
AU  - Armonda, Rocco
AU  - Bowyer, Mark
AU  - Liu, Alan
LA  - en
VL  - 132
SP  - 1
EP  - 3
ER  -
TY  - JOUR
TI  - Realizing the Tactile Internet through Intelligent Zero Touch Networks
PY  - 2022
PB  - Institute of Electrical and Electronics Engineers
SN  - 0890-8044
T2  - IEEE Network
DO  - 10.1109/mnet.117.2200016
UR  - https://doi.org/10.1109/mnet.117.2200016
DA  - 2022-01-01
AU  - Al Ridhawi, Ismaeel
AU  - Aloqaily, Moayad
AU  - Karray, Fakhri
AU  - Guizani, Mohsen
AU  - Debbah, Mérouane
LA  - en
KW  - Provisioning
KW  - Edge device
SP  - 1
EP  - 8
ER  -
TY  - JOUR
TI  - Leading-edge Metaverse in education: framework, applications, challenges, and future development
PY  - 2024
SN  - 2709-6696
T2  - TESOL and Technology Studies
DO  - 10.48185/tts.v5i2.1002
UR  - https://doi.org/10.48185/tts.v5i2.1002
DA  - 2024-06-09
AU  - Rane, Nitin
C1  - 2Vivekanand Education Society's College of Architecture (VESCOA), Mumbai, India
AU  - Choudhary, Saurabh
C1  - Vivekanand Education Society's College of Architecture (VESCOA), Mumbai, India
AU  - Rane, Jayesh
C1  - Pillai HOC College of Engineering & Technology, Rasayani, India
LA  - en
KW  - Metaverse
VL  - 5
IS  - 2
AB  - The incorporation of cutting-edge metaverse technologies into the field of education has emerged as a transformative paradigm, reshaping conventional learning environments and paving the way for novel immersive and interactive educational experiences. This paper undertakes a comprehensive examination of the framework, applications, challenges, and future development prospects of metaverse technologies within the educational domain, focusing on a diverse array of techniques that contribute to the continuous evolution of this innovative educational landscape. The framework analysis delves into the design and implementation strategies that form the foundation of metaverse-based educational platforms. Utilizing augmented reality (AR), virtual reality (VR), and mixed reality (MR), these frameworks strive to create dynamic and captivating learning environments that transcend geographical limitations. The paper explores how these technologies enable realistic simulations, collaborative problem-solving, and experiential learning, thereby fostering a more interactive and participatory educational experience. Case studies and examples illustrate their utilization across disciplines, spanning from science and mathematics to humanities and vocational training. The paper underscores the significance of artificial intelligence (AI) and machine learning (ML) algorithms in tailoring educational content to individual learning styles, thereby enhancing personalization and adaptability within metaverse-based educational systems. Nevertheless, the research also addresses the challenges associated with implementing metaverse technologies in education. Issues such as accessibility, digital equity, and data privacy are discussed, accompanied by considerations for overcoming these challenges to ensure a more inclusive and secure educational landscape. Looking ahead, the paper outlines potential developments in metaverse education, exploring emerging technologies and trends such as blockchain-based credentialing, haptic feedback integration, and the incorporation of the Internet of Things (IoT). The paper acknowledges the diverse techniques contributing to its ongoing evolution, emphasizing the dynamic nature of this transformative educational landscape.
ER  -
TY  - JOUR
TI  - The Design of a Graphics Engine for the Development of Virtual Reality Applications
PY  - 2009
SN  - 0103-4308
T2  - Revista de Informática Teórica e Aplicada
DO  - 10.22456/2175-2745.8261
UR  - https://doi.org/10.22456/2175-2745.8261
DA  - 2009-04-17
AU  - Malfatti, Silvano
C1  - Laboratório Nacional de Computação Científica, Laboratório ACiMA - RJ
AU  - dos Santos, Selan
C1  - Universidade Federal do Rio Grande do Norte - RN
AU  - Fraga, Luciane
C1  - Laboratório Nacional de Computação Científica, Laboratório ACiMA - RJ
AU  - Justel, Cláudia
C1  - Instituto Militar de Engenharia - RJ
AU  - Rosa, Paulo
C1  - Instituto Militar de Engenharia - RJ
AU  - de Oliveira, Jauvane
C1  - Laboratório Nacional de Computação Científica, Laboratório ACiMA - RJ
LA  - en
KW  - Game engine
KW  - Testbed
VL  - 15
IS  - 3
SP  - 25
EP  - 46
AB  - This work presents the design and the features of a flexible realtime 3D graphics engine aimed at the development of multimedia applications and collaborative virtual environments. The engine, called EnCIMA (Engine for Collaborative andImmersive Multimedia Applications), enables a fast development process of applications by providing a high level interface, which has been implemented using the C++object-oriented programming paradigm. The main features of the proposed engine are the support to scene management, ability to load static and animated 3D models, particle system effects, network connection management to support collaboration, and collision detection. In addition, the engine supports several specialized interaction devices such as 3D mice, haptic devices, 3D motion trackers, data-gloves, and joystickswith and without force feedback. The engine also enables the developer to choose the way the scene should be rendered to, i.e. using standard display devices, stereoscopy, or even several simultaneous projection for spatially immersive devices. As part of the evaluation process, we have compared the performance of EnCIMA to a game engine and two scene graph toolkits, through the use of a testbed application. The performanceresults and the wide variety of non-conventional interaction devices supported are evidences that EnCIMA can be considered a real time virtual reality engine.
ER  -
TY  - JOUR
TI  - Haptic simulators with virtual reality environments in dental education: A preliminary teaching diagnosis
PY  - 2017
PB  - Servei de Formació Permanent i Innovació Educativa, Universitat de València
SN  - 1989-3477
T2  - tic revista d innovació educativa
DO  - 10.7203/attic.18.9077
UR  - https://doi.org/10.7203/attic.18.9077
DA  - 2017-06-23
AU  - Montanet, Gleyvis
C1  - Universidad Europea
AU  - Sánchez, Margarita
C1  - Universidad Europea
AU  - Suárez, Ana
C1  - Universidad Europea
LA  - en
KW  - Dental education
VL  - 0
IS  - 18
AB  - A descriptive exploratory study was performed at the Universidad Europea in Madrid with a sample of 22 professors of dentistry with a distinguished career in simulation. A community of practice of was created for collaborative learning using the Simondont® Dental Trainer, a dental training simulator developed by Moog and the Academic Centre for Dentistry Amsterdam (ACTA) that combines haptic and virtual reality interfaces. A post-experimental questionnaire was administered to assess the performance of the Simondont® and to determine whether or not the professors would be willing to incorporate it into their curriculum. IBM SPSS Statistics V21.0 software was used for the data analysis and statistics of mean, standard deviation and correlation of the results. Tables and box plots were developed applying Kolmogorov-Smirnov and Kruskal-Wallis tests, with a level of significance of ?=0.05. The results indicated that the educational contributions of the Simodont® exceeded its technical features. In addition, an inverse relationship was described between the variables Age and Ease of use of the simulator. It became apparent that the use of state-of-the-art technology begins to decrease as teaching age increases. This indicated the need to train faculty in the use of the technology and in the introduction of innovative teaching methods to make the best use of the basic and additional opportunities the simulator offers.
ER  -
TY  - JOUR
TI  - A Design and Analysis of a Hybrid Multicast Transport Protocol for the Haptic Virtual Reality Tracheotomy Tele-Surgery Application
PY  - 2007
DO  - 10.1109/ipdps.2007.370592
UR  - https://doi.org/10.1109/ipdps.2007.370592
DA  - 2007-01-01
AU  - Boukerche, Azzedine
C1  - PARADISE Res. Lab, Ottawa Univ., Ont.
AU  - Maamar, Haifa
C1  - PARADISE Res. Lab, Ottawa Univ., Ont.
AU  - Hossain, A.B.M.
C1  - PARADISE Res. Lab, Ottawa Univ., Ont.
LA  - en
KW  - Tracheotomy
SP  - 1
EP  - 6
AB  - Nowadays, distributed collaborative virtual environments are used in many scenarios such as tele-surgery, gaming, and industrial training, however several challenging issues remain to be resolved before haptic virtual reality based class of applications become a common place. In this paper, we focus upon a tracheotomy tele-surgery application that is based on closely coupled and highly synchronized haptic tasks that require a high-level of coordination among the participants. We also propose a hybrid protocol that is able to satisfy all the collaborative and haptic virtual environment requirements in general and tracheotomy tele-surgery in particular. We discuss our C-HAVE tracheotomy tele-surgery framework and report on the performance results we have obtained to evaluate our protocol using an extensive set of experiments.
ER  -
TY  - JOUR
TI  - Leading-edge Metaverse in Education: Framework, Applications, Challenges, and Future Development
PY  - 2023
PB  - RELX Group (Netherlands)
SN  - 1556-5068
T2  - SSRN Electronic Journal
DO  - 10.2139/ssrn.4642196
UR  - https://doi.org/10.2139/ssrn.4642196
DA  - 2023-01-01
AU  - Rane, Nitin
C1  - University of Mumbai
AU  - Choudhary, Saurabh
C1  - University of Mumbai
AU  - Rane, Jayesh
C1  - University of Mumbai
LA  - en
KW  - Metaverse
ER  -
TY  - JOUR
TI  - Realizing the Tactile Internet through Intelligent Zero Touch Networks
PY  - 2022
PB  - Institute of Electrical and Electronics Engineers
SN  - 0890-8044
T2  - IEEE Network
DO  - 10.1109/mnet.001.2200016
UR  - https://doi.org/10.1109/mnet.001.2200016
DA  - 2022-11-01
AU  - Al Ridhawi, Ismaeel
C1  - Kuwait College of Science and Technology, Kuwait
AU  - Aloqaily, Moayad
C1  - Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), UAE
AU  - Karray, Fakhri
C1  - Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), UAE
AU  - Guizani, Mohsen
C1  - Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), UAE
AU  - Debbah, Mérouane
C1  - Technology Innovation Institute (TII), UAE
LA  - en
KW  - Provisioning
KW  - Edge device
VL  - 36
IS  - 6
SP  - 243
EP  - 250
ER  -
TY  - JOUR
TI  - Multi-touch - the future of design interaction
PY  - 2011
T2  - Computer-Aided Architectural Design Futures
DO  - 10.25455/wgtn.16418742.v1
UR  - https://doi.org/10.25455/wgtn.16418742.v1
DA  - 2011-01-01
AU  - Rui, Irene
AU  - Schnabel, Marc
LA  - en
KW  - Leverage (statistics)
ER  -
TY  - JOUR
TI  - Demonstrating HapticBots
PY  - 2021
DO  - 10.1145/3474349.3480202
UR  - https://doi.org/10.1145/3474349.3480202
DA  - 2021-10-08
AU  - Suzuki, Ryo
C1  - University of Calgary, Canada
AU  - Ofek, Eyal
C1  - Microsoft Research, United States
AU  - Sinclair, Mike
C1  - Microsoft Research, Microsoft, United States
AU  - Leithinger, Daniel
C1  - ATLAS Institute, University of Colorado, Boulder, United States
AU  - González-Franco, Mar
C1  - Microsoft Research, United States
LA  - en
ER  -
TY  - JOUR
TI  - Prototype of Force Feedback Tool for Mixed Reality Applications
PY  - 2021
T2  - 2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)
DO  - 10.1109/ismar-adjunct54149.2021.00123
UR  - https://doi.org/10.1109/ismar-adjunct54149.2021.00123
DA  - 2021-10-01
AU  - Gonsher, Ian
C1  - Brown University
AU  - Lei, Zhenhong
C1  - Rhode Island School of Design
LA  - en
SP  - 508
EP  - 509
ER  -
TY  - JOUR
TI  - Omnidirectional Haptic Stimulation System via Pneumatic Actuators for Presence Presentation
PY  - 2023
PB  - Multidisciplinary Digital Publishing Institute
SN  - 1424-8220
T2  - Sensors
DO  - 10.3390/s23020584
UR  - https://doi.org/10.3390/s23020584
DA  - 2023-01-04
AU  - Yoshida, Shogo
C1  - School of Knowledge Science, Japan Advanced Institute of Science and Technology, Nomi 923-1292, Japan
AU  - Xie, Haoran
C1  - School of Knowledge Science, Japan Advanced Institute of Science and Technology, Nomi 923-1292, Japan
AU  - Miyata, Kazunori
C1  - School of Knowledge Science, Japan Advanced Institute of Science and Technology, Nomi 923-1292, Japan
LA  - en
KW  - Presentation (obstetrics)
VL  - 23
IS  - 2
SP  - 584
EP  - 584
AB  - Recently, remote meetings and work-from-home have become more common, reducing the opportunities for face-to-face communication. To facilitate communication among remote workers, researchers have focused on virtual space technology and spatial augmented reality technology. Although these technologies can enhance immersiveness in collaborative work, they face the challenge of fostering a sense of physical contact. In this work, we aimed to foster a sense of presence through haptic stimulation using pneumatic actuators. Specifically, we developed a choker-type wearable device that presents various pressure patterns around the neck; the pattern presented depends on the message the device must convey. Various combinations of haptic presentation are achieved by pumping air to the multiple pneumatic actuators attached to the choker. In addition, we conducted experiments involving actuators of different shapes to optimize the haptic presentation. When linked with a smartphone, the proposed device can present pressure patterns to indicate incoming calls and notifications, to give warning about an obstacle that one who is texting might miss while walking, and to provide direction to a pedestrian. Furthermore, the device can be used in a wide range of applications, from those necessary in daily living to those that enhance one’s experience in the realm of entertainment. For example, haptic feedback that synchronizes with the presence of a singer or with the rhythm of a song one listens to or with a performer’s movements during a stage performance will immerse users in an enjoyable experience.
ER  -
TY  - JOUR
TI  - Real-time Interactions and Synchronization of Voxel-based Collaborative Virtual Environments
PY  - 2007
DO  - 10.1109/3dui.2007.340785
UR  - https://doi.org/10.1109/3dui.2007.340785
DA  - 2007-01-01
AU  - Acosta, Eric
C1  - National Capital Area Med. Simulation Center, Uniformed Services Univ., Bethesda, MD
AU  - Liu, Alan
C1  - National Capital Area Med. Simulation Center, Uniformed Services Univ., Bethesda, MD
LA  - en
ER  -
TY  - JOUR
TI  - HexTouch: A Wearable Haptic Robot for Complementary Interactions to Companion Agents in Virtual Reality
PY  - 2020
DO  - 10.1145/3415255.3422881
UR  - https://doi.org/10.1145/3415255.3422881
DA  - 2020-11-17
AU  - Zhou, Ran
C1  - Parsons School of Design
AU  - Wu, Yanzhe
C1  - Parsons School of Design
AU  - Sareen, Harpreet
C1  - Parsons School of Design
LA  - en
KW  - Disgust
KW  - Immersion
SP  - 1
EP  - 2
ER  -
TY  - JOUR
TI  - Original computer aided support system for safe and accurate implant placement—Collaboration with an university originated venture company
PY  - 2010
PB  - Elsevier BV
SN  - 1882-7616
T2  - Japanese Dental Science Review
DO  - 10.1016/j.jdsr.2010.01.002
UR  - https://doi.org/10.1016/j.jdsr.2010.01.002
DA  - 2010-01-28
AU  - Sohmura, Taiji
C1  - Division of Oralmaxillofacial Regeneration, Osaka University Graduate School of Dentistry, 1-8 Yamadaoka, Suita 565-0871, Japan
AU  - Kumazawa, Yoich
C1  - Bionic Co. Ltd. 2-7-14 Higashiawaji, Higashiyodogawa-Ku, Osaka 533-0023, Japan
LA  - en
KW  - Rapid Prototyping
KW  - Computer-aided
VL  - 46
IS  - 2
SP  - 150
EP  - 158
AB  - An original implant surgery support system with computer simulation to determine the position of implant placement and fabrication of a surgical guide that helps in bone drilling was developed by collaboration of Osaka University Faculty of Dentistry and Dental Prostheses Fabrication Company. A virtual reality haptic device that gives the sense of touch was used for simulation and a surgical template was fabricated by CAD/CAM method. A patented technology enabled to remove artifact due to metallic prostheses by replacing the damaged teeth of CT image by precise 3D measured image of dental cast. Surgical guide was designed using haptic device and fabricated including bone model by a computer-aided rapid prototyping modeling machine with a UV-cured acrylic-based resin material. Two clinical cases with implant placement on the three lower molars by flap operation using bone supported surgical guide and flapless operation with teeth supported surgical guide and immediate loading with provisional prostheses prepared beforehand are introduced. The present simulation and drilling support using the surgical guide may help to perform safe and accurate implant surgery.
ER  -
TY  - JOUR
TI  - An Internet-of-Things Based Framework for Collaborative Manufacturing
PY  - 2017
DO  - 10.1115/imece2017-72293
UR  - https://doi.org/10.1115/imece2017-72293
DA  - 2017-11-03
AU  - Krishnamurthy, Rajesh
C1  - Oklahoma State University, Stillwater, OK
AU  - Cecil, J.
C1  - Oklahoma State University, Stillwater, OK
AU  - Perera, Damith
C1  - Oklahoma State University, Stillwater, OK
LA  - en
KW  - Concurrent engineering
KW  - Cyber-physical system
KW  - Cloud Manufacturing
ER  -
TY  - BOOK
TI  - Medicine meets virtual reality 17 : nextmed : design for/the well being
PY  - 2009
PB  - IOS Press
T2  - IOS Press eBooks
DA  - 2009-01-01
AU  - Westwood, James
LA  - en
ER  -
TY  - JOUR
TI  - An Experimental Implementation of a Networked Hapto-Acoustic Virtual Reality Environment Applied to Surgical Education using the High Speed CeNTIE Research Network
PY  - 2003
T2  - Digital Image Computing: Techniques and Applications
DA  - 2003-01-01
AU  - Adriaansen, Tony
AU  - Gunn, Chris
LA  - en
KW  - Instructional simulation
KW  - Virtual space
KW  - Immersion
SP  - 359
EP  - 368
ER  -
TY  - JOUR
TI  - Interactive Dynamic Simulator for Humanoid With Haptic Feedback
PY  - 2008
DA  - 2008-07-01
AU  - Chardonnet, Jean-Rémy
C1  - Laboratoire d'Informatique de Robotique et de Microélectronique de Montpellier
AU  - Keith, François
C1  - Interactive Digital Humans
AU  - Kheddar, Abderrahmane
C1  - Interactive Digital Humans
AU  - Yokoi, Kazuhito
C1  - Joint Robotics Laboratory [Japan]
AU  - Pierrot, François
C1  - Conception et commande de robots pour la manipulation
LA  - en
KW  - Physics engine
SP  - 8
ER  -
TY  - JOUR
TI  - Dynamic shared state maintenance in distributed virtual environments
PY  - 2004
DA  - 2004-01-01
AU  - Hughes, Charles
C1  - UNIVERSITY OF CENTRAL FLORIDA
AU  - Rolland, Jannick
C1  - UNIVERSITY OF CENTRAL FLORIDA
AU  - Hamza-Lup, Felix
C1  - UNIVERSITY OF CENTRAL FLORIDA
LA  - en
KW  - Testbed
ER  -
TY  - JOUR
TI  - Potential of Mixed Reality in Online Practicum Learning
PY  - 2022
SN  - 2443-258X
T2  - Jurnal Sosioteknologi
DO  - 10.5614/sostek.itbj.2022.21.3.2
UR  - https://doi.org/10.5614/sostek.itbj.2022.21.3.2
DA  - 2022-12-28
AU  - Zen, Adrian
C1  - Telkom University
AU  - Hidayat, Syarip
C1  - Telkom University
LA  - en
KW  - Practicum
KW  - Instructional simulation
KW  - Metaverse
KW  - Virtual learning environment
KW  - Digital Learning
VL  - 21
IS  - 3
SP  - 242
EP  - 249
AB  - The world is facing new challenges in the digital era, especially when presented with the metaverse and other online platforms. The sector that is affected by this challenge is the education sector. Academics are faced with the challenge to keep up with digital developments toward society 5.0. The challenge is in the form of online learning. The use of software in online learning still benefits learning that is theoretical but ineffective in practicum learning due to unsupported technology. With the emergence of Augmented Reality and Virtual Reality technology, it is possible to make online learning by combining AR and VR technology, namely Mix Reality. Mix Reality provides enormous potential for online learning because it provides features that cannot be done with conventional online learning in general. The combination of Haptic AR, Audio AR, and gustatory and olfactory AR make online learning possible. Its application in online practicum, MR technology, has a crucial role because teachers can use MR to produce digital content with no restrictions and interact online with their students. Either through virtual spaces or a collaborative learning environment. This article discusses details about the potential of Mixed Reality for online practicum learning.
ER  -
TY  - JOUR
TI  - Proceedings of the 1st Symposium on Applied perception in graphics and visualization
PY  - 2004
T2  - Applied Perception in Graphics and Visualization
DA  - 2004-08-07
AU  - Interrante, Victoria
C1  - University of Minnesota
AU  - McNamara, Ann
C1  - St. Louis University
AU  - Bülthoff, HH
C1  - Max Planck Institute for Biological Cybernetics,
AU  - Rushmeier, Holly
C1  - Yale University  ;
LA  - en
KW  - Impromptu
KW  - Scrolling
ER  -
TY  - GEN
TI  - Proceedings of the 18th ACM symposium on Virtual reality software and technology
PY  - 2012
DO  - 10.1145/2407336
UR  - https://doi.org/10.1145/2407336
DA  - 2012-12-05
LA  - en
KW  - Presentation (obstetrics)
ER  -
TY  - LETTER
TI  - In Reply: A New Trend of Blended Learning in Neurosurgical Training: Fellowship of Neuroendoscopy
PY  - 2021
PB  - Lippincott Williams & Wilkins
SN  - 0148-396X
T2  - Neurosurgery
DO  - 10.1227/neu.0000000000001806
UR  - https://doi.org/10.1227/neu.0000000000001806
DA  - 2021-12-16
AU  - Azzam, Ahmed
C1  - Faculty of Medicine, October 6 University, Giza, Egypt
AU  - Ghozy, Sherief
C1  - Department of Radiology, Mayo Clinic, Rochester, Minnesota, USA
LA  - en
VL  - 90
IS  - 2
SP  - e55
EP  - e56
AB  - To the Editor: We read the letter by El Refaee et al1 about the blended learning in neurosurgical training for neuroendoscopy. The neuroendoscopy fellowship paradigm provided by Cairo and Greifswald Universities is promising to develop the neurosurgical education. The implementation of the training system within the fellowship program is achieving a remarkable example for the development of global neurosurgery goals and equalization of training quality aiming for a better patient care and healthcare quality. In addition to that, presenting connections between a middle-income country and a high-income country and strengthening the medical collaboration between Germany and Egypt are essential. We appreciate those behind the idea of this fellowship, and we will be happy to see further similar collaborations in the near future between other institutions around the world. After understanding the present structure of Cairo Greifswald Neuroendoscopy fellowship program, we had the zeal to join the conversation discussing and suggesting future considerations from our humble knowledge and opinion for the program that may have revolutionary implications on the feasibility of fellowship training system—especially that the fellowship program is developed by top neuroendoscopy clinicians. The field of virtual reality has been emerging around the world during the current century, allowing new horizons and facilitating easier educational opportunities to be involved efficiently.2 Since the past decade, haptics were involved as a part of the commercial use in educational virtual reality purposes.3 Virtual reality haptics are integration between the virtual reality facilities in addition to tactile feedback from the simulator, which offers the user an interface with sensational feelings.3 Using the virtual reality haptics in the surgical education allows the trainee to interact with a full operation room virtually, experimenting the sensation of instruments, bone, flesh, fat, and skin feeling without the need of physical presence in a real-world–based operation theater in a patient or a cadaver. Using the haptics in neuroendoscopy training will provide the trainees with a magnificent opportunity to fully operate and learn confidently without the need to travel for another country for a minimal period of time and establishing better hands-on skills without the need of a human patient or a cadaver. As the neuroendoscopy fellowship program requires face-to-face presence for 6 d within Germany, this may create financial, social, and workplace-related burdens for some of the trainees, especially those who have busy residency training program schedule or trainees encountering low socioeconomic status or in ad hoc events such as the global pandemic of COVID-19, which has affected the international aircraft and transportation services for all people all over the world. This also created a challenge for the trainees to complete their training program within other country than their home country. With the mutations and new variants of COVID-19 and the limited vaccination plans around the world in the current situation especially in low-income and middle-income countries, burdens on travel might not be resolved in the near future yet; therefore, additional plans on using alternative solutions are necessary to maintain the quality and the structure of the training system of the fellowship. In addition, integrating the haptics in the training program will expose an extended training experience during the whole fellowship duration instead of 6 d only, eg, 1 virtual reality training session per week or per 2 wk during the timeline of program. We illustrated a simple diagram concluding the suggested ideas to the current pathway for the fellowship (Figure).FIGURE.: Suggested alternative plan integrated with haptics training. Blue refers to the suggested additional suggestions.The limitations regarding the haptics are embedded to the limited companies and corporations that work on production and developing those types of simulators. After an extended search on several different scientific and nonscientific databases, we found that Fundamental Surgery, a medical technology manufacturer, works on developing and building haptic-supported virtual reality surgical simulators, with the availability of building custom simulation builds on request.4 The current available simulations they offer are limited to orthopedics (total hip and total knee arthroplasty), spine (spinal pedicle screw fixation and facetectomy), and ophthalmology.5-7 Despite that, the corporation claims that they offer “custom simulation builds” with low cost for educational purposes.8 Requesting a custom simulator for the training on neuroendoscopy procedures might be appropriate to fulfill the gap. However, we declare that we do not have financial interest with the Fundamental Surgery, and this is only a suggestion based on humble opinion. The second limitation about the haptics project is the funding capability because access to an established funding source to fund the building of haptics project in neuroendoscopy is essential, and collaboration with the German Academic Exchange Service (DAAD) may serve as possible solution for this limitation as a supportive funding sponsor; otherwise, funding sources should be secured to guarantee the success of the project. To conclude, from our humble knowledge, we estimate that integrating the virtual reality haptics in the field of neurosurgical education generally and neuroendoscopy especially will result in a revolutionary training system for the next generation of neurosurgeons using the emerging technology, serving the global neurosurgical community aims. Taking advantage of the current global conditions is presenting a strong motivation to the start the development plan and processing it without hesitation.
ER  -
TY  - JOUR
TI  - Low-cost VR collaborative system equipped with haptic feedback
PY  - 2018
DO  - 10.1145/3281505.3281615
UR  - https://doi.org/10.1145/3281505.3281615
DA  - 2018-11-28
AU  - Benbelkacem, Samir
C1  - Centre for Development of Advanced Technologies (CDTA), Algiers, Algeria
AU  - Bellarbi, Abdelkader
C1  - Centre for Development of Advanced Technologies (CDTA), Algiers, Algeria
AU  - Zenati-Henda, Nadia
C1  - Centre for Development of Advanced Technologies (CDTA), Algiers, Algeria
AU  - Bentaleb, Ahmed
C1  - Institute of Electrical and Electronic Engineering (IGEE), Boumerdes, Algiers
AU  - Bellabaci, Ahmed
C1  - Institute of Electrical and Electronic Engineering (IGEE), Boumerdes, Algiers
AU  - Otmane, Samir
C1  - University of Evry, Paris, France
LA  - en
KW  - Game engine
SP  - 1
EP  - 2
AB  - In this paper, we present a low-cost virtual reality (VR) collaborative system equipped with a haptic feedback sensation system. This system is composed of a Kinect sensor for bodies and gestures detection, a microcontroller and vibrators to simulate outside interactions, and smartphone powered cardboard, all of this are put into a network implemented with Unity 3D game engine.
ER  -
TY  - JOUR
TI  - ACM SIGCHI international conference on advances in computer entertainment technology
PY  - 2004
PB  - Association for Computing Machinery
SN  - 1544-3981
T2  - Computers in entertainment
DO  - 10.1145/973801.973809
UR  - https://doi.org/10.1145/973801.973809
DA  - 2004-01-01
AU  - Cheok, Adrian
C1  - National University of Singapore
LA  - en
VL  - 2
IS  - 1
SP  - 3
EP  - 3
ER  -
TY  - JOUR
TI  - Novel Interaction Techniques for Collaboration in VR
PY  - 2018
DO  - 10.1145/3170427.3170628
UR  - https://doi.org/10.1145/3170427.3170628
DA  - 2018-04-20
AU  - Sra, Misha
C1  - Massachusetts Institute of Technology, Cambridge, MA, USA
AU  - Perlin, Ken
C1  - New York University, New York, NY, USA
AU  - Velho, Luiz
C1  - Instituto de Matematica Pura e Aplicada, Rio de Janiero, Brazil
AU  - Bolas, Mark
C1  - Microsoft, Redmond, WA, USA
LA  - en
KW  - Immersion
KW  - Relevance
KW  - Immersive technology
SP  - 1
EP  - 8
ER  -
TY  - JOUR
TI  - Ultrasound simulators in obstetrics and gynecology: state of the art
PY  - 2014
PB  - Wiley
SN  - 0960-7692
T2  - Ultrasound in Obstetrics and Gynecology
DO  - 10.1002/uog.14707
UR  - https://doi.org/10.1002/uog.14707
DA  - 2014-10-27
AU  - Chalouhi, G.
C1  - Obstetrics and Fetal Medicine Department, Necker-Enfants-Malades Hospital, APHP; Université Paris Descartes, Sorbonne Paris Cité; Paris France
AU  - Bernardi, V.
C1  - Department of Women and Children's Health; Università degli Studi di Padova; Padova Italy
C1  - Obstetrics and Fetal Medicine Department, Necker-Enfants-Malades Hospital, APHP; Université Paris Descartes, Sorbonne Paris Cité; Paris France
AU  - Ville, Y.
C1  - Obstetrics and Fetal Medicine Department, Necker-Enfants-Malades Hospital, APHP; Université Paris Descartes, Sorbonne Paris Cité; Paris France
LA  - en
VL  - 46
IS  - 3
SP  - 255
EP  - 263
AB  - Ultrasound is the primary method of imaging in obstetrics and gynecology1. Its use encompasses screening as well as expert examination of normal and abnormal cases2. It has become an essential part of practice in obstetrics, including maternal–fetal medicine, as well as in gynecology, often irrespective of the ability, competence and experience of the operators3, 4; the lack of standardization in training and assessment of skill has become a matter of concern worldwide. The majority of international institutions have set criteria and a minimum number of procedures that are required to perform obstetric and gynecological ultrasound in clinical settings5. These, however, vary between institutions and there is a wide range in skill level of both trainees and practitioners. For instance, the International Society of Ultrasound in Obstetrics and Gynecology (ISUOG) has suggested a minimum of 200 obstetric scans for residents in obstetrics and gynecology6. The American Institute of Ultrasound in Medicine (AIUM) has defined standards for training to be applied to sonologists. They also require specific ultrasound training for at least 3 months or the performance of at least 300 ultrasound examinations as part of an accredited residency or fellowship program. Their determination of competency for trainees is, however, based on residency review-committee standards, which do not define specific numbers of scans for trainees, but require competency assessment by program directors and faculty7. The American College of Obstetricians and Gynecologists (ACOG) requires specific ultrasound training for at least 3 months for completion of a fellowship graduate medical education of maternal–fetal medicine8. Training standards and assessment of competency are likewise not standardized across the different European countries. Performance of a minimum number of scans is required in Germany, Switzerland and Denmark, while no formal curriculum for ultrasound teaching is provided nor is any minimum number of scans required in Italy and Sweden. Attending a dedicated course and achieving a certificate of competency is mandatory in France, Germany, Switzerland and the UK9. In the UK, the Royal College of Obstetricians and Gynaecologists (RCOG)10 and in France, the National College of Obstetricians and Gynecologists (CNGOF)11 require that trainees should be assessed on their ability rather than through any given number of examinations. In both countries, candidates also sit both a theoretical and a practical examination10. To date, teaching and training have been mostly patient-centered5. Theoretical knowledge is not sufficient, and practical training can either be achieved on actual patients or on volunteers. However, this conventional patient-centered approach involves numerous difficulties and disadvantages. It puts the trainees in an uncomfortable situation, especially during the initial phase of training, when the interaction with the patient may distract them from becoming familiarized with handling and manipulation of the ultrasound probe and with interpretation of the ultrasound images12. Furthermore, developing competency in ultrasound is largely dependent upon the variety and number of cases encountered during clinical practice and there is a great diversity of opportunities among different students13. Often, the concept of trainees practicing on them is also stressful for the patient12, particularly in cases undergoing transvaginal sonography or in the presence of a fetal malformation. Even for volunteers, repeat examination by inexperienced and often stressed trainees can be uncomfortable and has the potential to cause anxiety. The limited availability of ultrasound machines dedicated to training is an additional limiting factor even for motivated trainees who are willing to train after hours, and the presence of trainees during working hours interferes significantly with the normal activity of the unit. We view as unacceptable the process of inexperienced trainees practicing on actual patients as the very first step of their learning process, which may be characterized by a significant number of errors and extensive time requirements. The increased focus on medical errors and patient safety also calls for development of alternative methods of continuous education and assessment of skills14. This has, understandably, led to insurance companies becoming involved in the development of simulation in medicine. For example, the patient safety and medical malpractice company of the Harvard medical community, 'CRICO', decided to offer premium incentives not only to anesthesiologists but also to obstetricians and gynecologists who participated in simulation-based courses, after proving that training with simulators results in reduced costs from malpractice claims12, 15-17. Moreover, patients are more likely to allow students to perform procedures on them following prior simulation training18. These changes in the context of medical education and training have paved the way for a new concept of learning, focused mainly on student's needs and the protection of patients, in which virtual reality and simulation can find important and complementary roles19. In this Editorial we review the current literature to provide an overview regarding the use of simulation in ultrasound in the field of obstetrics and gynecology. According to the Society for Simulation in Healthcare (SSH), simulation can be defined as the 'imitation or representation of one act or system by another'20. David Gaba, a pioneer in medical simulation, has defined it as a 'technique to replace or amplify real experiences with guided experiences that evoke or replicate substantial aspects of the real world in a fully interactive manner' and he has underlined that standardization, reproducibility and safety are some important aspects made possible by simulation21. Simulation and virtual reality were first introduced into the field of education by the military and the aviation and nuclear power industries. Their aim was to find an effective and safe method of training, considering that training a team and system testing in the real world were dangerous and expensive22. The introduction of simulators into medical education followed, the first being Resusci AnneTM, developed for the teaching of cardiopulmonary resuscitation in the 1950s by the Norwegian toy-maker Åsmund Laerdal, in cooperation with a group of anesthesiologists23. Then came 'Sim One'24, created in the 1960s by Abrahamson and Denson, which was followed in the 1980s by two similar high-fidelity anesthesia simulators, CASETM 25 and GASTM 26. Since then, simulation has been used in multiple medical fields and specialties, and its development has continued in various areas, including anesthesiology25, emergency care27, 28, cardiology29, obstetrics30-32 and surgery33, 34. Simulation offers the possibility of making errors without risk of negative patient outcomes, such as death, misdiagnosis, complaints and claims19. Additionally, the negative emotions generated by failure or error, which are considered to be critical to the medical learning process, are experienced more constructively in a simulation context than they are in real life12. Simulation presents, therefore, the possibility of shifting the perspective of education from the conventional patient-centered approach to a newer and more innovative learner-centered approach5. Several authors have demonstrated the importance of integrating simulation technology into medical education, not only for skills training, but also for assessment of competency12, 19, 35, particularly in the fields of internal medicine, anesthesiology36 and minimally-invasive surgery37, as well as in obstetrics with the widely used maternal birthing simulators (CAE Fidelis Maternal Fetal Simulator; Gaumard's NOELLE® Maternal Birthing Simulator). Ultrasound simulators are integrated simulators, generally composed of a human mannequin, a mock probe and a computer. Usually, the mock probe is connected directly to the computer, whose screen displays the ultrasound image depending upon the probe's position and movements. Most of these simulators use electromagnetic tracking systems to define the probe's position. The mock probe usually contains a three-dimensional (3D) sensor, capable of acquiring virtual position data instantaneously. As these data are transferred to the computer, it evaluates the location and position of the probe on the mannequin and displays the related two-dimensional (2D) images38-43. A haptic device can be used instead of a mannequin, allowing measurement of the pressure applied to the probe and providing realistic feedback on this force44, 45. This, however, is limited in that it allows a lower range of movements to the probe, while lacking a simulated environment in the absence of a mannequin or a 'patient-look-alike' structure. Furthermore, variations in the pressure applied to the probe do not show differences in the force-feedback nor in image quality (in contrast to live scanning)46. Most of these systems provide a 3D animated illustration of the anatomy surrounding the probe and its position and relations with the different organs and systems44. This option is particularly useful in the first phases of training, in order to help the trainees to become familiar with ultrasound scanning ergonomy and improve their hand–eye coordination and to locate the insonation planes within the examined structure. This animated illustration can be hidden on demand or in the subsequent steps of training. Ultrasound simulators have been applied mainly to teach the basic skills of cardiac ultrasound examination to students and residents in emergency and internal medicine (Table 1). Over the last few years, several studies have investigated the effectiveness of simulation-based echocardiography training compared with conventional methods such as theoretical lectures and hands-on training on patients. Most of these studies have been underpowered, with limited sample size, but they suggest significant improvements among simulation-trained students with regards to anxiety levels, performance, efficiency, competence and recognition of clinical scenarios, as well as a high level of compliance and satisfaction4. Findings of these studies include, for example, that the use of echocardiographic simulators gave very positive results regarding motivation and a decrease in anxiety compared with examination of real patients47, while use of transesophageal echocardiographic simulation proved not only to be realistic and helpful50, but also to be superior to conventional methods of teaching48, 49. Simulation has also been found to be helpful for introducing to surgery residents the use of ultrasound in trauma cases51. CAE Vimedix Ultrasound Simulator System (CAE Healthcare, Montreal, Quebec, Canada) 12 third- or fourth-year medical students or physicians currently in their first 3 years of residency training CAE Vimedix Ultrasound Simulator System (CAE Healthcare, Montreal, Quebec, Canada) It has been established that there is improvement in knowledge and better recognition of clinical scenarios after training sessions on the simulator52, however, the necessity of supervised training even in simulation situations is still under debate. A study by Cawthorn et al.53 underlines the importance of supervised training, stating the necessity of combining both teaching methods. Simulators in the field of obstetric ultrasound appeared at the beginning of this century38. In 2003, Newey and colleagues50 used the virtual ultrasound scanner 'VirUS' to assess inter- and intraoperator repeatability of nuchal translucency thickness measurements among expert ultrasound operators and suggested its potential in operator training (Table 2). Comparison of training in first- and second-trimester screening by only theoretical lectures vs theoretical lectures & practical sessions on simulator In 2004, Maul et al.38 evaluated the SonoTrainerTM system for training in first- and second-trimester ultrasound screening. They divided 45 certified obstetricians into two groups, the first receiving theoretical and practical training on the SonoTrainerTM, and the second receiving only theoretical teaching. The results were significantly better in the former group, suggesting the utility of practical phantom training. However, the study did not demonstrate whether the improvement was related to the simulation training specifically or, more generally, to the fact that these operators had undergone hands-on training (Table 2). Staboulidou et al.54, in 2010, aimed to evaluate the effectiveness of simulation integrated into obstetric ultrasound training courses over 100 courses held with 1266 participants over 2 years. Each participant answered a questionnaire for evaluation of knowledge before and after the course. The results suggested a significant improvement of knowledge after completion of the course (P < 0.0001), although the specific contribution of simulation to any improvement was not clear (Table 2). Nitsche and Brost5, in 2013, underlined the utility of simulation training and proposed a 'fetal pig ultrasound training model' as an alternative to the expensive and still limited commercial models. This simulator consisted of a fetal pig heat-sealed within a formalin-filled plastic bag. While offering economic benefits, this model presents various limitations, including obvious anatomical differences from the human fetus (Table 2). A recent study by Burden and colleagues52 evaluated the trend of improvement among 26 participants, including 18 trainees and eight certified experts in obstetric ultrasound using virtual-reality ultrasound simulation. Participants performed five sequential modules measuring crown–rump length and three repetitions of a late-pregnancy growth scan. Outcome measures included mean percentage deviation from target measures and time needed to complete a scan. Even with the small sample size, results showed significant improvement over subsequent scans, particularly among the trainee group (Table 2). However, only five scans may be insufficient to demonstrate any real improvement in the participants' ultrasound technique. Transvaginal ultrasonography is particularly difficult to teach within a clinical setting, requiring extensive training time, experienced tutors with plenty of available time and a wide variety of compliant patients, both with normal and with pathological findings, who are willing to undergo examination on multiple occasions55. The transvaginal probe is a dedicated one, and displays anatomical structures in a way that is unique to this approach56, with ergonomy different from that of the transabdominal probe. Clearly these are limiting factors both for training and even more so for assessment of skills13, when the patient is usually a volunteer undergoing a supplementary scan, thus necessitating a search for complementary methods to implement in ultrasound educational programs44. Heer and colleagues13, in 2004, developed a software-based training system, with cases previously recorded during a normal pelvic examination defining interpolative model-based simulation (Table 3). In the first phase of the study, they evaluated the congruence of the actual gynecological scan with the virtual one, submitting three virtual cases to 25 sonologists experienced in gynecological ultrasound. Secondly, they tested the simulator on 24 fourth-year medical students with no experience in ultrasound. Following a 6-min presentation, the students were able to perform a basic pelvic scan on the simulator, including measurements of endometrial thickness comparable to the ones measured by expert sonographers. Training with this technique suggested that standardized ultrasound teaching and learning with the model was comparable to performing a live gynecological ultrasound scan. However, it could be argued that these conclusions might not be relevant in clinical practice as the judgment criteria used for assessment (uterus position, presence or absence of pathology, endometrial thickness measurement, demonstration of ovaries and pouch of Douglas) might have been too simple. Blue Phantom (Redmond, WA) female pelvis models 16 final-year medical students (ultrasound novices) + 12 Ob/Gyn consultants (experienced US practitioners) A prospective randomized controlled trial56 conducted on 134 medical students compared the effectiveness of transvaginal ultrasound training delivered using an ultrasound simulator with that delivered using volunteers. This study found that simulators did not perform as well as did live models, concluding that they should be regarded as an adjunct to, rather than a substitute for, live models. In a recent experimental study, Madsen et al.44 explored trainees' learning curves using a high-fidelity transvaginal ultrasound simulator, and tested the validity and reliability of the different metrics used. They compared results obtained by a group of 16 novices with those obtained by 12 consultants in obstetrics and gynecology, determining 48 metrics which could discriminate the level of expertise, and established the validity and reliability of the simulator in assessment of skill. Furthermore, they observed the trend of improvement of novices, finding them to reach a level considered suitable for clinical practice after 3–4 hours of virtual training. Whenever a new training method is implemented, ideally it should create a chain of impact at several levels. The most credible and most widely used training evaluation methodology in the world is the evaluation model that emerged from the work by Donald Kirkpatrick and Jack Phillips57, 58. It measures training outcomes at five levels, starting at reaction/planned action and ending with return on investment (ROI). The five levels are summarized as follows: Level 1 – Reaction and Satisfaction: of the participants to the training, usually measured in surveys, and their Planned Action (their plans to use what they have learned); Level 2 – Learning: assesses how much participants have learned (with pre- and post-tests); Level 3 - Behavior, Application and Implementation: assesses whether the skills and knowledge gained in training are applied and practiced in the workplace or have changed learners' behavior; Level 4 - Results: measures the extent to which the institutions' measures (output, quality, costs and time) have improved after training; although this can be considered as the goal of a strategy, it is important to go beyond this level of evaluation to verify that the program's costs do not outweigh its benefits; Level 5 - Return on Investment (ROI): the ultimate level of evaluation, this compares the benefits from the program with its cost59, 60. The evaluation of simulation in obstetric and gynecological ultrasound has until now remained mainly at Levels 1 and 2 of the Kirkpatrick and Phillips model. Most studies have evaluated reaction, satisfaction54 or learning38, 52. Although several ultrasound simulators currently available include measurement of time to complete tasks and accuracy of measurement, most studies have not yet evaluated the transfer to clinical practice of knowledge acquired during simulation training61. In addition to the measurable benefits, most training programs will have intangible benefits, including stress reduction and increased commitment of trainees, improved patient satisfaction, reduction of patient complaints as well as reduction or avoidance of conflict62. According to Phillips63: 'In some programs, the intangible (non monetary) benefits can be more important than tangible (monetary) measures. Consequently, these measures should be monitored and reported as part of the overall evaluation. The challenge is to efficiently identify and report them.' These benefits should also be addressed in the future. The best or most effective method of training students in obstetric and gynecological ultrasound has yet to be defined. The importance of hands-on repeat-training until proficiency is reached is well known, and has superseded the previous, no longer acceptable principle of 'see one, do one, teach one'46. So far, standardization of the teaching of ultrasound among different institutions and countries has been achieved neither for educational purposes nor for assessment of practitioners' skills and accreditation. In particular, given the high variability between people in the time and training needed to gain proficiency, it is unlikely that a minimum set number of scans can reflect adequately candidates' skills; some trainees reach a level of competency that is suitable for clinical practice after a few scans, while others need more time to reach the same level64. Thus, assessment of skill should be based on practical tests during which the candidate demonstrates their abilities, as in the 'competency-based' method proposed by RCOG10, 54. There is broad consensus on the utility of integrating virtual reality into ultrasound education and training programs6, 10, 12-14, 19, 21, 22, 38, 44, 46, 48, 50, 52-54, 61, 64-72. It has been proposed as a valid and reliable method for assessment of skills, implying its potential for use in accreditation procedures44. However, simulation might never replace completely clinical training and there will always be a need for tutor supervision53. It could be useful as a method for introducing students to ultrasound practice, allowing them to become familiar with image optimization and probe orientation, without being confronted with a clinical setting that might be stressful and disturbing44. Whilst the number of commercially available ultrasound simulators continues to increase (Table 4), they remain expensive devices which require maintenance and adequate training for their use. These factors may limit the widespread adoption of the technology. Some distributors claim that acquisition of simulators can be economically benefical45, by allowing trainees to improve their performance without monopolising ultrasound machines required in the clinical setting. However, not only do such claims need to be verified, but evaluation studies on their efficacy need to be performed, both of which rely on constructive interaction between clinicians and engineers. Internal medicine, emergency medicine, cardiology, TTE, gynecology, obstetrics, breast sonography, vaginal sonography, urology, rectal sonography, freehand punctures for different pathologies, neonatal hip sonography
ER  -
TY  - JOUR
TI  - Data visualization of crime data using immersive virtual reality
PY  - 2022
SN  - 2470-1173
T2  - Electronic Imaging
DO  - 10.2352/ei.2022.34.12.ervr-187
UR  - https://doi.org/10.2352/ei.2022.34.12.ervr-187
DA  - 2022-01-16
AU  - Reehl, Aishwarya
C1  - Department of Computer Science Bowie State University Bowie, MD 20715, USA
AU  - Sharma, Sharad
C1  - Department of Computer Science Bowie State University Bowie, MD 20715, USA
LA  - en
KW  - Headset
KW  - Scientific visualization
KW  - Creative visualization
KW  - Bar chart
VL  - 34
IS  - 12
SP  - 187
EP  - 5
AB  - Visualization explores quantitative content of data with human intuition and plays an integral part in the data mining process. When the data is big there are different analysis methods and approaches used to find inherent patterns and relationships. However, sometimes a human in loop intervention is needed to find new connections and relationships that the existing algorithms cannot provide. Immersive Virtual Reality (VR) provides the &#x201C;sense of presence&#x201D; and gives the ability to discover new connections and relationships by visual inspection. The goal of this work is to investigate the merging of immersive VR and data science for advanced visualization. VR and immersive visualization involve interplay between novel technology and human perception to generate insight into both. We propose to use immersive VR for exploring the higher dimensionality and abstraction that are associated with big data. VR can use an abstract representation of high-dimensional data in support of advanced scientific visualization. This paper demonstrates the data visualization tool with real-time feed of Baltimore crime data in immersive environment, non-immersive environment, and mobile environment. We have combined virtual reality interaction techniques and 3D geographical information representation to enhance the visualization of situational impacts as shown in Figure 1. The data visualization tool is developed using the Unity gaming engine. We have presented bar graphs with oculus controller to combine the bar chart visualization with a zooming feature that allows users to view the details more effectively. The Oculus Touch headset allows the users to navigate and experience the environment with full immersion. Oculus Touch controllers also give haptic feedback to the user when using objects such as laser pointer. We are interested in extending our VR data visualization tools to enable collaborative, multi-user data exploration and to explore the impact of VR on collaborative analytics tasks, in comparison with traditional 2D visualizations. The benefits of our proposed work include providing a data visualization tool for immersive visualization and visual analysis. We also suggest key features that immersive analytics can provide with situational awareness and in loop human intervention for decision making.
ER  -
TY  - JOUR
TI  - 대형 복합건물을 대상으로 하는 소방관 팀 훈련용 시뮬레이터 개발
PY  - 2011
T2  - 한국CAD/CAM학회 학술발표회 논문집
DA  - 2011-10-01
AU  - , 이재경
AU  - , 차무현
AU  - , 최병일
AU  - , 김태성
LA  - en
VL  - 16
IS  - 5
SP  - 370
EP  - 379
ER  -
TY  - JOUR
TI  - A Team-based Firefighter Training Simulator for Complex Buildings
PY  - 2011
SN  - 2508-4003
T2  - Korean Journal of Computational Design and Engineering
DA  - 2011-01-01
AU  - Lee, Jai-Kyung
AU  - Cha, Moohyun
AU  - Choi, Byung-Il
AU  - Kim, Taesung
LA  - en
VL  - 16
IS  - 5
SP  - 370
EP  - 379
ER  -
TY  - JOUR
TI  - Virtual reality interfaces for seamless interaction with the physical reality
PY  - 2020
DA  - 2020-09-29
AU  - George, Ceenu
LA  - en
KW  - Headset
ER  -
TY  - CHAP
TI  - A Volumetric Approach to Virtual Simulation of Functional Endoscopic Sinus Surgery
PY  - 1997
PB  - IOS Press
SN  - 0926-9630
T2  - Studies in health technology and informatics
DO  - 10.3233/978-1-60750-883-0-167
UR  - https://doi.org/10.3233/978-1-60750-883-0-167
DA  - 1997-01-01
AU  - J, W
AU  - Roni, Yagel
AU  - Don, Steven
AU  - Petra, Schmalbrock
AU  - Sitek, Emilia
AU  - Yair, Kurzion
AU  - Rony, Louis
AU  - Michael, Levin
AU  - Kenneth, M.
LA  - en
KW  - Endoscopic sinus surgery
ER  -
TY  - JOUR
TI  - A feasibility study on the use of a remote supercomputer in a collaborative virtual environment with force feedback
PY  - 2007
T2  - Annual Conference on Computers
DA  - 2007-07-26
AU  - De Paolis, Lucio
C1  - Department of Innovation Engineering, Salento University, Lecce and SPACI Consortium, Italy#TAB#
AU  - Agrimi, Alessio
C1  - Department of Innovation Engineering, Salento University, Lecce and SPACI Consortium, Italy#TAB#
AU  - Zocco, Alessandro
C1  - Department of Innovation Engineering, Salento University, Lecce and SPACI Consortium, Italy#TAB#
AU  - Aloisio, Giovanni
C1  - Department of Innovation Engineering, Salento University, Lecce and SPACI Consortium, Italy#TAB#
LA  - en
KW  - Collaborative software
SP  - 514
EP  - 517
ER  -
TY  - JOUR
TI  - Recent Advances in Social &amp;amp; Cognitive Robotics and Imminent Ethical Challenges
PY  - 2018
PB  - RELX Group (Netherlands)
SN  - 1556-5068
T2  - SSRN Electronic Journal
DO  - 10.2139/ssrn.3266627
UR  - https://doi.org/10.2139/ssrn.3266627
DA  - 2018-01-01
AU  - Meghdari, Ali
C1  - Sharif University of Technology
AU  - Alemi, Minoo
C1  - Islamic Azad University (IAU)
C1  - Sharif University of Technology
LA  - en
ER  -
TY  - GEN
TI  - The Adjunct Publication of the 32nd Annual ACM Symposium on User Interface Software and Technology
PY  - 2019
DO  - 10.1145/3332167
UR  - https://doi.org/10.1145/3332167
DA  - 2019-10-14
LA  - en
KW  - Interface (matter)
KW  - Rebuttal
ER  -
TY  - JOUR
TI  - Neural Functional Analysis in Virtual Reality Simulation: Example of a Human-Robot Collaboration Tasks
PY  - 2020
T2  - 2018 Winter Simulation Conference (WSC)
DO  - 10.1109/wsc48552.2020.9384065
UR  - https://doi.org/10.1109/wsc48552.2020.9384065
DA  - 2020-12-14
AU  - Zhu, Qi
C1  - University of Florida, Gainesville, FL, USA
AU  - Du, Jing
C1  - University of Florida, Gainesville, FL, USA
LA  - en
KW  - Testbed
KW  - Interface (matter)
KW  - Human–robot interaction
SP  - 2424
EP  - 2434
ER  -
TY  - JOUR
TI  - HapticPuppet: A Kinesthetic Mid-air Multidirectional Force-Feedback Drone-based Interface
PY  - 2022
DO  - 10.1145/3526114.3558694
UR  - https://doi.org/10.1145/3526114.3558694
DA  - 2022-10-28
AU  - Feick, Martin
C1  - DFKI, Saarland Informatics Campus, Germany
AU  - Tang, Anthony
C1  - University of Toronto, Canada
AU  - Krüger, Antonio
C1  - DFKI, Saarland Informatics Campus, Germany
LA  - en
KW  - Kinesthetic learning
KW  - Drone
KW  - Interface (matter)
SP  - 1
EP  - 3
AB  - Providing kinesthetic force-feedback for human-scale interactions is challenging due to the relatively large forces needed. Therefore, robotic actuators are predominantly used to deliver this kind of haptic feedback; however, they offer limited flexibility and spatial resolution. In this work, we introduce HapticPuppet, a drone-based force-feedback interface which can exert multidirectional forces onto the human body. This can be achieved by attaching strings to different parts of the human body such as fingers, hands or ankles, which can then be affixed to multiple coordinated drones - puppeteering the user. HapticPuppet opens up a wide range of potential applications in virtual, augmented and mixed reality, exercising, physiotherapy, remote collaboration as well as haptic guidance.
ER  -
TY  - BOOK
TI  - Gesture-Based Communication in Human-Computer Interaction: 5th International Gesture Workshop, GW 2003, Genova, Italy, April 15-17, 2003, Selected Revised Papers
PY  - 2004
DA  - 2004-02-18
AU  - Camurri, Antonio
AU  - Volpe, Gualtiero
LA  - en
KW  - Coarticulation
ER  -
TY  - JOUR
TI  - Virtual Reality Therapy for the Psychological Well-being of Palliative Care Patients in Hong Kong
PY  - 2022
T2  - 2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)
DO  - 10.1109/ismar-adjunct57072.2022.00010
UR  - https://doi.org/10.1109/ismar-adjunct57072.2022.00010
DA  - 2022-10-01
AU  - Eckhoff, Daniel
C1  - School of Creative Media, City University of Hong Kong, Hong Kong
AU  - Ng, Royce
C1  - School of Creative Media, City University of Hong Kong, Hong Kong
AU  - Cassinelli, Álvaro
C1  - School of Creative Media, City University of Hong Kong, Hong Kong
LA  - en
KW  - Psychological therapy
SP  - 1
EP  - 5
AB  - In this paper we introduce novel Virtual Reality (VR) and Aug-mented Reality (AR) treatments to improve the psychological well being of patients in palliative care, based on interviews with a clin-ical psychologist who has successfully implemented VR assisted interventions on palliative care patients in the Hong Kong hospital system. Our VR and AR assisted interventions are adaptations of traditional palliative care therapies which simultaneously facilitate patients communication with family and friends while isolated in hospital due to physical weakness and COVID-19 related restrictions. The first system we propose is a networked, metaverse platform for palliative care patients to create customized virtual environments with therapists, family and friends which function as immersive and collaborative versions of 'life review' and 'reminiscence therapy'. The second proposed system will investigate the use of Mixed Real-ity telepresence and haptic touch in an AR environment, which will allow palliative care patients to physically feel friends and family in a virtual space, adding to the sense of presence and immersion in that environment.
ER  -
TY  - JOUR
TI  - Security for the Metaverse: Blockchain and Machine Learning Techniques for Intrusion Detection
PY  - 2023
DO  - 10.36227/techrxiv.22858817
UR  - https://doi.org/10.36227/techrxiv.22858817
DA  - 2023-05-19
AU  - Truong, Vu
AU  - Le, Long
LA  - en
KW  - Metaverse
AB  - &lt;p&gt;The Metaverse, which is emerging as the next-generation (NextG) Internet, offers an immersive 3D virtual world in which people can organize various virtual activities and interact with each other seamlessly through digital avatars. As the NextG Internet, however, the Metaverse also faces severe security risks inherited from its predecessor as well as various new emerging threats. Furthermore, the decentralized nature of the Metaverse even makes it more challenging to mitigate these issues in a large-scale setting with numerous interactive wearable devices such as augmented, virtual reality (AR/VR) headsets and haptic devices. In this article, we aim to analyze the security aspect of the Metaverse thoroughly with special discussions of solutions enabled by blockchain and machine learning (ML). Firstly, we present a 4-layer architecture of the Metaverse and discuss potential solutions for Metaverse security based on blockchain and ML. Next, we develop a decentralized collaborative intrusion detection system (CIDS) based on blockchain and federated learning (FL) that allows such the Metaverse users to collaboratively protect this digital world, thereby solving the scalability and single-point-of-failure (SPoF) issues of traditional security approaches, which may not be effective in protecting the Metaverse with increasingly sophisticated attacks. Finally, we outline some key challenges and discuss future research directions for Metaverse security.&lt;/p&gt;
ER  -
TY  - JOUR
TI  - Workshop 2: storytelling in virtual reality environments
PY  - 2005
DO  - 10.1109/vr.2002.996553
UR  - https://doi.org/10.1109/vr.2002.996553
DA  - 2005-08-24
AU  - Mostafawy, Sina
C1  - new media gmbh
LA  - en
KW  - Metaverse
KW  - Instructional simulation
SP  - 306
EP  - 306
ER  -
TY  - JOUR
TI  - Semi‐Solid Stretchable Carbon Nanotubes Inkpad for Hand‐Based Haptic Interaction
PY  - 2024
PB  - Wiley
SN  - 2365-709X
T2  - Advanced Materials Technologies
DO  - 10.1002/admt.202301877
UR  - https://doi.org/10.1002/admt.202301877
DA  - 2024-02-14
AU  - Wang, Ziqi
C1  - State Key Laboratory of Virtual Reality Technology and Systems Beihang University  37 Xueyuan Road Beijing 100191 China
AU  - Zhou, Zejian
C1  - State Key Laboratory of Virtual Reality Technology and Systems Beihang University  37 Xueyuan Road Beijing 100191 China
AU  - Tian, Yingzhe
C1  - State Key Laboratory of Virtual Reality Technology and Systems Beihang University  37 Xueyuan Road Beijing 100191 China
AU  - Lei, Dongyue
C1  - State Key Laboratory of Virtual Reality Technology and Systems Beihang University  37 Xueyuan Road Beijing 100191 China
AU  - Liu, Yan
C1  - State Key Laboratory of Virtual Reality Technology and Systems Beihang University  37 Xueyuan Road Beijing 100191 China
AU  - Huang, Tianjia
C1  - State Key Laboratory of Virtual Reality Technology and Systems Beihang University  37 Xueyuan Road Beijing 100191 China
AU  - Tang, Qingyun
C1  - State Key Laboratory of Virtual Reality Technology and Systems Beihang University  37 Xueyuan Road Beijing 100191 China
AU  - Zhang, Yuru
C1  - State Key Laboratory of Virtual Reality Technology and Systems Beihang University  37 Xueyuan Road Beijing 100191 China
AU  - Wang, Dangxiao
C1  - Beijing Advanced Innovation Center for Biomedical Engineering Beihang University  37 Xueyuan Road Beijing 100191 China
C1  - Peng Cheng Laboratory  Shenzhen 518000 China
C1  - State Key Laboratory of Virtual Reality Technology and Systems Beihang University  37 Xueyuan Road Beijing 100191 China
LA  - en
KW  - Wired glove
KW  - Tactile sensor
KW  - Extensibility
KW  - Gauge factor
VL  - 9
IS  - 8
ER  -
TY  - JOUR
TI  - Intelligent Collaborative Platform for Development of Personalized Surgical Orthopedic Guides
PY  - 2015
PB  - Trans Tech Publications
SN  - 1013-9826
T2  - Key engineering materials
DO  - 10.4028/www.scientific.net/kem.638.303
UR  - https://doi.org/10.4028/www.scientific.net/kem.638.303
DA  - 2015-03-01
AU  - Popescu, Diana
C1  - University Politehnica of Bucharest,,,,,
AU  - Lăptoiu, Dan
C1  - Colentina Clinical Hospital
AU  - Hadăr, Anton
C1  - University Politehnica of Bucharest,,,,,
LA  - en
KW  - Bridge (graph theory)
VL  - 638
SP  - 303
EP  - 309
ER  -
TY  - GEN
TI  - Proceedings of the 3rd International Workshop on Multimedia Alternate Realities
PY  - 2018
DO  - 10.1145/3268998
UR  - https://doi.org/10.1145/3268998
DA  - 2018-10-15
LA  - en
KW  - Interactive media
ER  -
TY  - JOUR
TI  - Virtual reality telerehabilitation: an inter-disciplinary collaboration
PY  - 2003
DO  - 10.1109/nebc.2003.1216104
UR  - https://doi.org/10.1109/nebc.2003.1216104
DA  - 2003-11-04
AU  - Deutsch, Judith
C1  - RiVRR Laboratory, UkWNJ, UK
AU  - Lewis, Jeffrey
C1  - RiVRR Laboratory, UkWNJ, UK
AU  - Boian, Rareș
C1  - CAIP Center, Rutgers University, USA
AU  - Burdea, Grigore
C1  - CAIP Center, Rutgers University, USA
LA  - en
KW  - Telerehabilitation
KW  - Interface (matter)
KW  - Health care delivery
SP  - 281
EP  - 282
ER  -
TY  - JOUR
TI  - MMT+AVR
PY  - 2015
DO  - 10.1145/2713168.2713170
UR  - https://doi.org/10.1145/2713168.2713170
DA  - 2015-03-09
AU  - Venkatraman, Karthik
C1  - University of Texas, Dallas
AU  - Tian, Yuan
C1  - University of Texas, Dallas
AU  - Raghuraman, Suraj
C1  - University of Texas, Dallas
AU  - Prabhakaran, Balakrishnan
C1  - University of Texas, Dallas
AU  - Nguyen, Nhut
C1  - TIN Consulting
LA  - en
SP  - 112
EP  - 119
ER  -
TY  - JOUR
TI  - P088 Utilising virtual reality for remote joint injection training for the post-pandemic rheumatologist
PY  - 2022
PB  - Oxford University Press
SN  - 1462-0324
T2  - Lara D. Veeken
DO  - 10.1093/rheumatology/keac133.087
UR  - https://doi.org/10.1093/rheumatology/keac133.087
DA  - 2022-04-23
AU  - Clarke, Benjamin
C1  - Centre for Rheumatic Diseases, King's College London, London, UNITED KINGDOM
AU  - Balachandran, Sathiyaa
C1  - Centre for Rheumatic Diseases, King's College London, London, UNITED KINGDOM
AU  - Nagra, Deepak
C1  - Centre for Rheumatic Diseases, King's College London, London, UNITED KINGDOM
AU  - Russell, Mark
C1  - Centre for Rheumatic Diseases, King's College London, London, UNITED KINGDOM
AU  - Bechman, Katie
C1  - Centre for Rheumatic Diseases, King's College London, London, UNITED KINGDOM
AU  - Adas, Maryam
C1  - Centre for Rheumatic Diseases, King's College London, London, UNITED KINGDOM
AU  - Hope-Smith, Anthony
C1  - Anthony Hope-Smith Design, Anthony Hope-Smith Design, Redbridge, UNITED KINGDOM
AU  - Yates, Mark
C1  - Centre for Rheumatic Diseases, King's College London, London, UNITED KINGDOM
AU  - Barrow, Alastair
C1  - Generic Robotics, Generic Robotics Ltd, Reading, UNITED KINGDOM
AU  - Smith, Tom
C1  - Generic Robotics, Generic Robotics Ltd, Reading, UNITED KINGDOM
AU  - Galloway, James
C1  - Centre for Rheumatic Diseases, King's College London, London, UNITED KINGDOM
LA  - en
VL  - 61
IS  - Supplement_1
ER  -
TY  - JOUR
TI  - Role of telerehabilitation in the rehabilitation of children with cerebral palsy during COVID-19: A review
PY  - 2024
PB  - Wolters Kluwer
SN  - 0025-7974
T2  - Medicine
DO  - 10.1097/md.0000000000037214
UR  - https://doi.org/10.1097/md.0000000000037214
DA  - 2024-03-01
AU  - Kashif, Muhammad
C1  - Department of Physical Therapy, Riphah College of Rehabilitation and Allied Health Sciences, Riphah International University, Islamabad, Pakistan
C1  - Muhammad Kashif, Department of Physical Therapy, Riphah College of Rehabilitation and Allied Health Sciences, Riphah International University, Lahore, Pakistan (e-mail
AU  - Albalwi, Abdulaziz
C1  - Faculty of Applied Medical Sciences, Department of Health Rehabilitation Sciences, University of Tabuk, Tabuk, Saudi Arabia
AU  - Kazmi, Syed
C1  - Department of Clinical Services, Ziauddin Group of Hospitals, Ziauddin University & Hospitals, Karachi, Pakistan
AU  - Alharbi, Ahmad
C1  - Faculty of Applied Medical Sciences, Department of Health Rehabilitation Sciences, University of Tabuk, Tabuk, Saudi Arabia
AU  - Bashir, Kiran
C1  - Department of Physical Therapy, Margalla Institute of Health Sciences, Islamabad, Pakistan
AU  - Aslam, Muhammad
C1  - Department of Oral Medicine, Muhammad Dental College, Mirpur Khas, Pakistan
AU  - Ghaffar, Tamjeed
C1  - Faculty of Medical Sciences, Department of Physical Therapy, Government College University, Faisalabad, Pakistan.
LA  - en
KW  - Telerehabilitation
VL  - 103
IS  - 9
SP  - e37214
EP  - e37214
AB  - Individuals with cerebral palsy (CP) have limited mobility and are unable to actively participate in tasks that are part of their daily living. Thus, continuous therapeutic sessions are required to keep such individuals active and engaged in the environment. Due to the coronavirus disease of 2019 (COVID-19) lockdowns, rehabilitation for children with CP was inhibited which consequently put them at risk of losing their functional gains which were obtained through previous in-person therapies. In order to avoid this, an alternate to conventional therapy was required and this rendered it necessary to review the role of telerehabilitation (TR) and its various modes for the rehabilitation of children with CP. This study aimed to explore the effectiveness of TR for children with CP during COVID-19 through the present literature and to determine if TR is an alternate to conventional physical therapy in children with CP during the coronavirus outbreak. This scoping review was conducted by searching different databases such as PubMed, Cochrane Collaboration, Medline, and Google Scholar on the basis of inclusion criteria. Screening was performed from January 2019 to June 2022 and the initial screening attempt returned 469 studies. After applying the aforementioned criteria, all impertinent studies were excluded which resulted in 28 studies being included for this review as they contained information about the effectiveness of TR on children with CP during COVID-19. These 28 articles included randomised controlled trials, surveys, reviews, clinical trials, case reports, prospective studies, editorials, and longitudinal studies. Three out of the 7 randomised controlled trial studies revealed that action observation treatment can be a useful approach for TR in child with CP during similar pandemics. The other 3 studies supported the use of computer-based games, robots, nonimmersive virtual reality, and wearable haptic devices as a significant means of TR in child with CP as an alternate to routine therapy during COVID-19. TR is an affable mode of rehabilitation specifically for the pediatric population. In the future, it can be an alternate to routine therapy for those who are unlikely to get daily access to in-person therapeutic sessions due to various reasons or circumstances.
ER  -
TY  - JOUR
TI  - Virtual Environments and Haptics for Ankle Rehabilitation
PY  - 2003
SN  - 1225-9845
T2  - Journal of Control Automation and Systems Engineering
DO  - 10.5302/j.icros.2003.9.8.577
UR  - https://doi.org/10.5302/j.icros.2003.9.8.577
DA  - 2003-08-01
LA  - en
KW  - Interface (matter)
VL  - 9
IS  - 8
SP  - 577
EP  - 584
AB  - Traditional ankle rehabilitation procedures are tedious, repetitive, and require therapist's help. Therefore, they do not provide patients with good motivation to actively participate in the rehabilitation exercises. In addition, objective diagnosis and evaluation of the treatment progress have been difficult because records of exercise history are made by passive instruments from time to time. The virtual reality technology can make these procedures more fun so that patients can perform everyday rehabilitation exercises more actively. Moreover, haptics technology can give active resistance to the patients ankle motion to improve strength of muscles as well as can record ankle's motion and force histories for objective diagnosis and evaluation. This paper summarizes development of a virtual environment fur reforming the conventional ankle rehabilitation procedures. First of all, conventional rehabilitation procedures have been summarized. Secondly, haptic design and control, user interface design, virtual environment contents design are described. Lastly, mutual cooperation among many developers including medical doctors and therapists and future works are commented.
ER  -
TY  - JOUR
TI  - Virtual reality-enhanced rehabilitation for improving musculoskeletal function and recovery after trauma
PY  - 2025
PB  - BioMed Central
SN  - 1749-799X
T2  - Journal of Orthopaedic Surgery and Research
DO  - 10.1186/s13018-025-05705-3
UR  - https://doi.org/10.1186/s13018-025-05705-3
DA  - 2025-04-23
AU  - Paladugu, Phani
C1  - Harvard Medical School, Brigham and Women's Hospital, 75 Francis Street, Boston, MA, 02115, USA.
C1  - Sidney Kimmel Medical College, Thomas Jefferson University, 1025 Walnut Street, Philadelphia, PA, 19107, USA.
AU  - Kumar, Rahul
C1  - Department of Biochemistry and Molecular Biology, University of Miami Miller School of Medicine, 1011 NW 15Th Street, Miami, FL, 33136, USA.
AU  - Ong, Joshua
C1  - Department of Ophthalmology and Visual Sciences, University of Michigan Kellogg Eye Center, 1000 Wall Street, Ann Arbor, MI, 48105, USA.
AU  - Waisberg, Ethan
C1  - Department of Clinical Neurosciences, University of Cambridge, Cambridge Biomedical Campus, Hills Road, Cambridge, CB2 0SP, UK.
AU  - Sporn, Kyle
C1  - Department of Medicine, SUNY Upstate Medical University Norton College of Medicine, Syracuse, NY, USA. spornk@upstate.edu.
LA  - en
VL  - 20
IS  - 1
AB  - Orthopedic trauma remains a critical challenge in modern healthcare, often resulting in severe mobility limitations, acute pain, and delayed recovery. Conventional rehabilitation techniques, though effective, fail to address the individualized, high-precision interventions needed for musculoskeletal injuries like fractures, joint instability, ligament tears, and muscular atrophy. Virtual reality (VR) technologies, such as Apple Vision Pro and HTC Vive Pro, offer a transformative approach by enhancing diagnostic precision, rehabilitation effectiveness, and patient engagement through interactive, immersive environments that improve clinical outcomes. These VR technologies provide real-time biomechanical data, such as joint mechanics, muscle coordination, and movement patterns, allowing clinicians to design personalized rehabilitation programs. These technologies can thus facilitate neuromuscular re-education, improve muscle proprioception, and enhance muscle coordination. Studies have shown that VR-based rehabilitation advances functional recovery, improves pain management, and reduces psychological barriers associated with immobility. VR also facilitates telemedicine, increasing accessibility for patients with geographic or mobility issues. However, while VR may provide biomechanical data, it is important to note that they fall short in accurate motion tracking, particularly in fine motor control tasks. This scoping review follows PRISMA guidelines to explore the potential of VR in orthopedic rehabilitation, analyzing its diagnostic capabilities, personalized interventions, and real-time feedback systems. Despite this, barriers remain, including regulatory challenges, limitations in haptic feedback, high cost, and patient compliance. By presenting a balanced perspective on the landscape of VR in orthopedic care, this paper emphasizes the need for rigorous clinical validation, regulatory advancements, and interdisciplinary collaboration. Ultimately, VR offers the potential to significantly improve recovery outcomes, enhance patient engagement, and streamline rehabilitation protocols, but its successful integration into clinical practice must be approached with both optimism and caution.
ER  -
TY  - CHAP
TI  - Development of a Finger Pad Force Display for a Hand Haptic Interface
PY  - 2010
PB  - Springer Science+Business Media
SN  - 1359-4338
T2  - Virtual Reality
DO  - 10.5772/13160
UR  - https://doi.org/10.5772/13160
DA  - 2010-12-08
AU  - Kawasaki, Haruhisa
C1  - Gifu University, Japan
AU  - Koide, Shinya
C1  - Gifu University, Japan
AU  - Mouri, Tetuya
C1  - Gifu University, Japan
AU  - Endo, Takahiro
C1  - Gifu University, Japan
LA  - en
KW  - Palpation
KW  - Interface (matter)
KW  - Sensation
AB  - Most human interfaces in virtual environments use information of visual sensation and auditory sensation. By adding tactile sensation to these human interfaces, the human operator can handle objects with a realistic tactile sense and can perform complex tasks in the virtual reality environment. Haptic interfaces that present force and tactile feeling to the fingertips of a human operator have been investigated extensively over the last two decades [1]-[12]. Although some of these interfaces [9]-[12] provide three-dimensional force feeling to the human fingertip, few haptic interfaces cover the workspace of the human arm. These interfaces are classified into two types: wearable type interfaces [9], which are mounted firmly to the human hand, and opposed type interfaces [12], which are mounted in a position opposed to the human hand. These interfaces apply three-dimensional (3D) forces only to the human fingertips. Medical doctors must use palpation in examining patients, and the force and tactile sensation on both the fingertips and the finger pads are important in such palpation. However, training doctors to perform palpation is difficult, because this requires the cooperation of the patient. Thus a breast palpation training system in a virtual reality environment [13] would be useful as a training tool for palpation. However, due to the limitation of human finger length, developing a haptic interface that displays 3D force feeling to both the fingertips and the finger pads is not easy. The density of tactile sense organs in the human finger [14] is high in the fingertip and low in the finger pad. Hence, the human finger has a high sensitivity to 3D force at the fingertip but a low sensitivity at the finger pad. This suggests that a haptic interface that consists of 1D finger pad force display devices and a 3D fingertip force device would be effective for use in a virtual environment such as a virtual breast palpation training system. The present paper describes a hand haptic interface for use in a virtual training system in which not only fingertip force display but also finger pad force display is required. The hand haptic interface consists of novel finger pad force display devices and a 3D fingertip haptic interface, known as HIRO II [12], which was developed by our group. The developed finger pad force display device is driven by a flat-type brushless DC motor and is easy attachable to the finger pad. The applied force is controlled by a time interval control, which is an open-loop control. Here we present the design concept of the hand haptic interface, the control method and specifications of the finger pad force display device, and the results of an experimental evaluation of manipulating a virtual object. We also provide a comparative
ER  -
TY  - JOUR
TI  - Special Issue on Collaborative Engineering
PY  - 2006
PB  - ASM International
SN  - 1530-9827
T2  - Journal of Computing and Information Science in Engineering
DO  - 10.1115/1.2201728
UR  - https://doi.org/10.1115/1.2201728
DA  - 2006-05-26
AU  - Sriram, Ram
C1  - National Institute of Standards and Technology, Gaithersburg, MD 20899
AU  - Szykman, Simon
C1  - National Coordination Office for Networking and Information Technology Research and Development, Arlington, VA 22230
AU  - Durham, Delcie
C1  - National Science Foundation, Arlington, VA 22230.
LA  - en
VL  - 6
IS  - 2
SP  - 93
EP  - 95
AB  - Design of complex engineering systems is increasingly becoming a collaborative task among designers or design teams that are physically, geographically, and temporally distributed. The complexity of modern products means that a single designer or design team can no longer manage the complete product development effort. Developing products without sufficient expertise in a broad set of disciplines can result in extended product development cycles, higher development costs, and quality problems. On the other hand, ensuring comprehensive technical proficiency in a world where trends are toward more multidisciplinary design can become a costly undertaking for a company.Driven by such issues, companies are increasingly staffing only their core competencies in-house and depending on other firms to provide the complementary design knowledge and design effort needed for a complete product. Designers are no longer merely exchanging geometric data, but also more general knowledge about design and the product development process, including specifications, design rules, constraints, and rationale. Furthermore, this exchange of knowledge more and more often crosses corporate boundaries. As design becomes increasingly knowledge-intensive and collaborative, the need for computational frameworks to support a collaborative product development environment becomes more critical. There are several research and development issues that need to be addressed for the effective realization of such a collaborative design environment; the first issue of JCISE (March 2001) contains several papers that are pertinent to our discussions. These issues, along with relevant papers from this special issue, are discussed below.Architectural Frameworks. Software frameworks are complex software applications, or software systems composed of an integration of multiple applications, designed to provide an infrastructure for addressing a given problem. Key issues associated with development of software frameworks include traditional systems engineering principles, such as requirements gathering, functional analysis, architecture design, detailed design, validation, etc. Concerns of interest in the development of architecture frameworks include the traditional importance of cost, quality, schedule, and functionality, as well as key needs for usability, interoperability, modularity, and effective integration into a collaborative product development process. Examples of architecture frameworks include blackboard-based systems, service oriented architectures, and support for multimedia interactions.Shared Representations. The representation of product information that supports sharing forms the fundamental cornerstone of any collaborative engineering (or collaborative product development) application. This product information should include not only the geometric data corresponding to the physical parts and their relationships, but it should include non-geometric information such as material characteristics, function, behavior, and design intent as well. The current focus on product families supports this shared representation requirement for distributed design. Support should be provided for dealing with multiple levels of functional abstraction, geometric representation, constraints, and for generating multiple functional views through the entire product life cycle. In the recent past, various groups within industry, academia, and government have been developing sharable and reusable information models known as ontologies. All ontologies consist of a vocabulary along with some specification of the meaning or semantics of the terminology within the vocabulary. In doing so, ontologies aid in sharing information and facilitating interoperability by providing a common vocabulary with a shared semantics.Engineering Repositories and Long-Term Knowledge Management. Engineering repositories are the electronic substitute for and successor of the traditional file cabinets where information on past designs is stored. Design repositories store descriptions of past designs in a form suitable for browsing and retrieval for direct use and reuse in the active design process. Various knowledge-based extensions to design repositories can be made to document general knowledge about design and the product development process, design rationale, design rules, ontologies and taxonomies, catalogs of successful designs, etc. Manufacturing repositories contain manufacturing process knowledge and can aid the designer in avoiding costly downstream errors. Currently, proprietary repositories are maintained in an ad-hoc fashion by individual organizations. Hence, in order to fully leverage the shared representations described above, there is a need for the development of standardized knowledge capture, storage, and retrieval methods, including case-based reasoning. These knowledge stores can further aid in the automated generation of new engineering knowledge.Constraint Management. In a large class of engineering problems, much of the associated knowledge can be represented by a set of mathematical relations between symbols or real-valued quantities. Maintaining these relationships, which can be viewed as constraints, and performing inferences on these relationships is the realm of constraint management or satisfaction techniques. The general problem of constraint satisfaction involves the following: given a set of variables and a set of constraints, find a set of assignments for each variable consistent with the set of constraints. The variables may be discrete or continuous. Constraint solvers can be broadly classified into numerical constraint solvers and symbolic constraint solvers. In general, the constraint satisfaction problem is NP-complete (non-deterministic polynomial time). Various heuristic algorithms and techniques that exploit certain characteristics of a domain, e.g., geometry, have been developed to reduce the computational complexity associated with this class of problems.Coordination and Transaction Management. Collaborative engineering environments necessitate a powerful and flexible transaction management framework to temporally coordinate the concurrent activities of multiple users. The key requirements for supporting coordination in a collaborative engineering environment are (1) the transaction framework should be dynamic, so as to support highly interactive, iterative, and interleaved engineering transactions; (2) locking mechanisms, including appropriate security controls, must be interactive and flexible enough to allow multiple transactions to proceed concurrently without having to wait indefinitely for other transactions to complete; (3) extensive records of the clients/agents and their activities must be maintained, to include the data used, dependencies between clients and data, and time-stamping of data and operations; (4) the version management system should keep track of the design evolution, in addition to supporting version merging; (5) nested transactions should be supported, in order to allow hierarchical subdivision of design effort and provide smaller units of control for various transaction management facilities; (6) nesting of database partitioning should be supported, where each partition serves one or more divisions of the design activity; and (7) long duration transactions, which are very different from the short duration transactions supported by traditional database management systems, should be supported as well. Design decision-making assignments and records must be implicitly captured within the transaction management framework.Negotiation and Conflict Mitigation. Conflicts due to differing perspectives among designers or among participants in different stages of the product realization process often lead to expensive designs, delays in product development, or undesirable compromises in the final product. One reason for conflicts is the lack of information that designers have about other designers' or stakeholders' objectives, and reasons for rejecting or accepting a given alternative. Other reasons, such as self-enrichment and the need to achieve an upper hand, contribute to conflicts. Hence, effective negotiation and conflict management techniques are crucial for mitigating conflicts. Taxonomies of design conflicts and design rationale encoding would greatly facilitate conflict mitigation strategies. Additionally, techniques developed in economics, mathematics, and political science should provide knowledge that can be used to enhance the effectiveness of negotiation approaches.Organizational Issues. Collaborative engineering (CE) activities can be classified into minute (task-level), small (project-level), large (program-level), and mega (enterprise-wide). Minute CE involves two to three individuals working on a small unit (e.g., a power supply) and requires knowledge in a single domain; small CE involves a group working in a single domain (e.g., mechanism design); large CE involves multiple disciplines (e.g., structural, mechanical, thermal, etc.); and mega CE crosses company boundaries and involves considerable outsourcing. In all these activities, managing engineering requirements is of paramount importance. Efficient allocation of tasks (task decomposition), smooth workflow management, and effective product development supply chain management could result in considerable benefits to the collaborative design enterprise. Finally, there is a need to conduct empirical studies of designers performing real world collaborative design, along with assessing the effectiveness of various tools and techniques.Virtual Reality and Collaborative Design Issues. While traditional CAD (computer-aided design) systems provide comprehensive tools for generating geometric forms, which encourages designers to come up with a form first and think about function later (i.e., form-to-function transformation), and knowledge-based design systems focus on the symbolic aspects of design first and later map the symbolic structure to a geometric model, in virtual reality-based systems (also called immersive CAD), the human being becomes part of the design by using various immersive environments, including haptic, visual, and speech interfaces. In distributed design, the application of virtual reality methods that allow exploration of the design space and the visualization of alternatives by stakeholders across the organization and throughout the supply chain could accelerate the design process with benefit to the overall time to market.Decision-based Design Issues. Decision-based design addresses the cognitive “structuring” of a problem; the drive for innovation where the existing “structure” or solution space is ill-defined or insufficient; the need to reduce complexity by mapping to what we know; and the consistent use of decision technologies to optimize the decision-making capabilities within the design space that has been created. The principles and methods developed from game theory, decision and risk analysis, and utility models are incorporated into the design process for complex systems, where consistency is necessary at all levels of decision making in order to resolve conflict and intransivity, and to facilitate negotiation and optimization.Papers in this Special Issue. This issue contains nine full length papers and three technical notes. Below we discuss how these papers address the collaborative engineering research issues described earlier. Some of these papers address more than one issue, as we note in our discussions.The paper by Su et al., “Scalable Vector Graphics (SVG) Based Multi-Level Graphics Representation for Engineering Rich-Content Exchange in Mobile Collaboration Computing Environments,” deals with both the development of an architectural framework for supporting multimedia information on mobile platforms and the representation of multimedia information. The proposed architecture uses a multi-level decomposition method that hierarchically subdivides graphics content, which is in the scalable vector graphics (SVG) format, and distributes the information at the appropriate level needed. This obviates the need for transferring all the information across the internet. The current prototype deals with two-dimensional graphics and plans are underway to extended to it other multimedia content, e.g., video and audio. This paper falls in the categories Architectural frameworks and Shared representation.Many of the techniques in vogue today for building ontologies are fairly ad-hoc. Nanda et al., in their paper “A Methodology for Product Family Ontology Development Using Formal Concept Analysis and Web Ontology Language,” describe a methodology for rational construction of product ontologies. They utilize a method called Formal Concept Analysis (FCA), which has been successfully applied in computational linguistics. They use FCA to identify the common features of various engineering objects and then classify them accordingly into a concept lattice. This concept lattice is mapped into an OWL (web ontology language) representation, making it amenable to semantic web applications. This paper falls in the category Shared representation.Features have been the subject of study for over a decade. Chen et al. extend the earlier work of others in this area to develop a model for representing features that includes both geometry and non-geometric information. In their paper “Associations in a Unified Feature Modeling Scheme,” they discuss how their model aids in sharing different views of a product while maintaining the integrity of relationships between various artifacts in a collaborative environment. A related approach, where shared features and relationships are stored in a table, is described by Bouikini et al. in their technical note “A Product Feature Evolution Validation Model for Engineering Change Management.” While the paper of Chen et al. focuses on various relationships between objects, Wang and Nnaji, in “Document Driven Design for Distributed CAD Services in Service-Oriented Architecture,” focus on a formal representation of a feature-based representation augmenting a feature-based model by including design intent. An implementation of their model is provided in RDF (resource description framework). Another related piece is the technical note “Design Modification in a Collaborative Assembly Design Environment” by Lu et al. This work describes the development of a hierarchical assembly model that associates client-IDs with leaf nodes, enabling any changes in the part (leaf-node) to be propagated to the appropriate designer. Papers discussed in this paragraph also fall in the category Shared representation.For many problems in computer-aided design, the spatial relationships between objects result in sets of non-linear equations. Geometric operations, such as moving, applied to these objects involves the solution of these equations. Algebraic techniques, such as the Newton-Raphson method, are computationally very expensive. Geometric reasoning techniques, which reason symbolically about geometry, provide efficient solution methods for such problems. The geometric constraint satisfaction problem (GCSP) can be stated as follows: “Given a collection of geometric bodies, and constraints that describe how the bodies interact with their neighbors, where must all the bodies be located in space so as to satisfy all constraints simultaneously?” The paper of Jaon-Arinyo et al., “Constraint-Based Techniques to Support Collaborative Design,” addresses the GCSP in a collaborative design environment. A framework that involves a geometry-based master model that supports client views and change propagation from clients is presented. The paper discusses theoretical underpinnings of such an approach. This paper falls in the category Constraint management.In order to support security for nested transactions, which allow hierarchical subdivision of design effort and provide smaller units of control for various transaction management facilities, Wang et al. propose a role-based access mechanism in their paper “Intellectual Property Protection in Collaborative Design through Lean Information Modeling and Sharing.” Data is shared between applications through UL-PML (Universal Linkage-Product Markup Language), an XML-based data modeling scheme that the authors have developed, which has many of the features discussed earlier. As data is shared at different levels of granularity, the advantages are similar to the SVG-based approach described by Su et al., while providing appropriate levels of security. This paper falls in the category Coordination and transaction management.Most of the papers on computer-supported collaborative engineering in the engineering literature focus on technical aspects of the problem. However, the social and economic considerations should be taken into account for any successful implementation. In their paper “A Socio-Technical Framework for Collaborative Product Development,” Lu et al. focus on the social and technical aspects of collaborative engineering. The framework proposed by Lu et al. is very comprehensive and includes eight stages: (1) defining a baseline process; (2) identifying various stakeholders; (3) proposing a product information structure (which they call a concept structure); (4) establishing perspectives of various stakeholders (e.g., thermal, mechanical); (5) building perspective model state diagrams (PMSDs) for each concept in their concept structure; (6) performing perspective analysis on PMSDs; (7) conducting conflict management based on the results of perspective analysis; and (8) obtaining a shared reality as a final outcome. One of the novel features of their framework is the conflict management system, which consists of two parts: conflict classification and conflict resolution. Conflict classification organizes conflicts into a taxonomy of conflicts, which is used to classify conflicts, after which appropriate conflict resolution strategies are applied. Lu et al. demonstrate their framework for facility planning and development in the construction domain. This paper falls in the categories Architectural frameworks and Negotiation and conflict mitigation.Rather than developing and offering a large number of unrelated products, manufacturers find it advantageous to deal with families of products, where product variety is obtained by variations of a generic product platform. Having access to manufacturing process knowledge during the development of the generic product platform and during the generation of product variations will result in superior quality designs. In their paper “Reuse of Manufacturing Knowledge to Facilitate Platform-based Product Realization,” Alizon et al. describe a three stage process for retrieval and use of process knowledge in repositories. The first step involves a search to find the appropriate cases in the repository. This search may produce several alternatives, which are then ranked. Finally, ranked cases are mapped to the current situation, which could involve selecting either snippets or a complete case. The authors illustrate their method with examples of assembly line design for an air conditioner module in automobile production. This paper falls in the category Engineering repositories and long-term knowledge management.Empirical studies are very important to researching and understanding engineering design. A substantial move towards observational studies, however, has yet to take hold in the engineering disciplines in any significant fashion. The paper “Empirical Studies on Inter-Organizational Collaborative Product Development in Asia Pacific Region” by Chu et al. addresses this issue by conducting six case studies in Taiwan. Their studies indicate that the companies have yet to effectively utilize software tools for collaboration. This paper falls in the category Organizational issues.The initial stages of any product development involve the generation of various specifications or requirements, which evolve through the entire product life cycle. Several approaches have been taken to mapping customer requirements to engineering requirements and engineering requirements to design parameters. In the technical note “ERMM: An Engineering Requirements Management Method,” Becker and Wang use a matrix-based method, similar to the Design Structure Matrix, to capture relationships and associations between various engineering components. They illustrate their technique by representing requirements for an automotive A-pillar design. These papers are representative of the category Organizational issues.Looking Forward. There are several issues for distributed collaborative design that are not addressed in this issue, but are topics for further consideration and concern. One issue that relates to the effects of globalization on design is the concern for sustainable product development. The need to consider design for reuse, remanufacture, and recycle are at the forefront of numerous industry product development plans, as information concerning products, their production, and product take-back requirements extend the need for accessible design repositories, product information structures, and new collaboration tools to support concurrent life cycle assessment analysis within the design process. Globalization also necessitates a design for the supply chain approach. Current research on platform families, on exploring the interrelationships between enterprise product planning and engineering product development using multilevel optimization, and on an ontology-based semantic approach for real-time collaboration and communication all hold promise for future advances in collaborative product development.Disclaimer. This Guest Editorial represents the opinions of the guest editors and does not imply the endorsement of NIST, NSF, and NITRD, nor does it imply recommendation of any material or equipment identified as necessarily the best available for the purpose.
ER  -
TY  - LETTER
TI  - Letter: Haptics in Neurosurgery: A Much-Needed Tool for Neurosurgery Training
PY  - 2021
PB  - Lippincott Williams & Wilkins
SN  - 0148-396X
T2  - Neurosurgery
DO  - 10.1227/neu.0000000000001796
UR  - https://doi.org/10.1227/neu.0000000000001796
DA  - 2021-12-22
AU  - Azzam, Ahmed
C1  - Faculty of Medicine, October 6 University, Giza, Egypt
AU  - Ghozy, Sherief
C1  - Department of Neuroradiology, Mayo Clinic, Rochester, Minnesota, USA
AU  - Negida, Ahmed
C1  - Global Neurosurgery Initiative, Program in Global Surgery and Social Change, Harvard Medical School, Boston, Massachusetts, USA
C1  - Research Department, Association of Future African Neurosurgeons, Yaounde, Cameroon
LA  - en
VL  - 90
IS  - 3
SP  - e76
EP  - e77
AB  - To the Editor: Continuous hands-on surgical training is necessary to build a competent surgeon. However, life does not always overcome with the perfect opportunities. Many factors can affect the quality of the neurosurgical training including, low socioeconomic status, lack of knowledge and support, and ad hoc events such as COVID-19 pandemic. Simulators act as an integral part of any training system, even outside the medical field. For example, pilots train on flight simulators hundreds of times before attempts on real flights; the simulation training system for aircraft pilots has been approved that it has a positive impact in providing an effective training and decreasing the overall cost of training each pilot individually.1 The goal of simulation-based training is to offer a near-real opportunity to learn from the mistakes before being engaged to a real situation and to build the skills and experience. Standard simulators currently in use are animal models, cadavers, synthetic physical models, and virtual reality models. Current simulators in neurosurgery training are limited by the following: (1) They are not widely available in neurosurgical training programs, (2) they do not provide tactical feedback to the trainee, (3) they do not fully provide the real operating room environment for the trainee, and (4) they have not been developed yet for most types and situations of surgery. Haptics are types of simulators that provide a tactile feedback to the trainee besides the virtual and mental training.2 This allows the neurosurgeon to experience "how it feels" while performing the operation on a virtual platform; this avails an almost-real experience of the neurosurgical theater without the need for physical presence. Haptics in spine surgery have emerged recently; however, they are not widely available in most of the neurosurgery training systems. We would like to exhibit the current evidence of haptics in spine surgery, what is missed, and what are the necessary future prospections to be involved. In Table, we listed all available evidence about haptic simulators in spine surgery from the current literature. TABLE. - The Present Spine Surgery Haptics Simulator Year Procedures Country Vortex, CM Labs3 2012 Disk removalPlate insertionBone drillingBone milling Canada Luciano et al4 2013 Open thoracic pedicle screw placementVentriculostomy catheter placement The United States Xing et al5 2015 Lumbar bone drillingLumbar pedicle screw insertion China Fundamental Surgery6 2018 FacetectomySpinal pedicle screw The United Kingdom Topps et al7 2018 Spinal tap Canada Immersive View™ VR8 2019 Not listed The United States We acknowledge the need to increase the use of haptics in neurosurgery training generally and spine surgery in particular. We expect that the development of haptics-based simulations and including them in the neurosurgical training will improve the neurosurgical training particularly in low-resource settings. Haptics are an excellent alternative for the standard training facilities, such as cadavers, and it supports the regular virtual reality training systems with the realistic feedback for giving the atmosphere, interaction, and sensation of how a real surgery feels like. What we miss in the current haptics of spine surgery is concerned about the selection of available procedures for training, more realistic graphics, and more involvement in the field by introducing it for more trainees. Focusing the efforts to innovate, collaborate, and develop the haptics from the current shortcomings will result in a new generation of neurosurgeons who are better trained, more confident, and more oriented with major operations that they had never the chance to do it before, especially for low-income and middle-income countries. The quality of surgical education should never be monopolized in specific society groups, eg, urban cities better than rural areas, and some geographical areas to be better than others. Treating and managing surgery required patients in the best way is not an optional decision; it is necessary from the patients' rights.
ER  -
TY  - JOUR
TI  - S15-04 SESSION 15: PLANNING/IMAGING - PART I Immersive-Touch Virtual-Reality Surgical Platform for Craniofacial Surgery by Craniofacial Surgeons: Taking back the control
PY  - 2019
PB  - Wolters Kluwer
SN  - 2169-7574
T2  - Plastic & Reconstructive Surgery Global Open
DO  - 10.1097/01.gox.0000583848.46832.e5
UR  - https://doi.org/10.1097/01.gox.0000583848.46832.e5
DA  - 2019-08-01
AU  - Alkureishi, L.
C1  - This is an open-access article distributed under the terms of the Creative Commons Attribution-Non Commercial-No Derivatives License 4.0 (CCBY-NC-ND), where it is permissible to download and share the work provided it is properly cited. The work cannot be changed in any way or used commercially without permission from the journal.
AU  - Patel, Pravin
C1  - This is an open-access article distributed under the terms of the Creative Commons Attribution-Non Commercial-No Derivatives License 4.0 (CCBY-NC-ND), where it is permissible to download and share the work provided it is properly cited. The work cannot be changed in any way or used commercially without permission from the journal.
AU  - Cohen, Martin
C1  - This is an open-access article distributed under the terms of the Creative Commons Attribution-Non Commercial-No Derivatives License 4.0 (CCBY-NC-ND), where it is permissible to download and share the work provided it is properly cited. The work cannot be changed in any way or used commercially without permission from the journal.
AU  - Zhao, Laurence
C1  - This is an open-access article distributed under the terms of the Creative Commons Attribution-Non Commercial-No Derivatives License 4.0 (CCBY-NC-ND), where it is permissible to download and share the work provided it is properly cited. The work cannot be changed in any way or used commercially without permission from the journal.
AU  - Banerjee, P.
C1  - This is an open-access article distributed under the terms of the Creative Commons Attribution-Non Commercial-No Derivatives License 4.0 (CCBY-NC-ND), where it is permissible to download and share the work provided it is properly cited. The work cannot be changed in any way or used commercially without permission from the journal.
LA  - en
KW  - Craniofacial surgery
KW  - Surgical Planning
VL  - 7
IS  - 8S-2
SP  - 175
EP  - 176
AB  - Introduction: For nearly half-a-century, craniofacial surgery planning has primarily utilized 2-dimensional photographs and radiographs, relying on the surgeon’s eye and experience to integrate these into a “virtual” 3-dimensional image. The introduction 3D-reconstructed CT has greatly improved the ability to visualize anatomical deformity, but true surgical simulation remains elusive because of 1) inability to visualize the third dimension on 2D flat-screen displays, 2) inability of the surgeon to use their skilled sense of touch and 3) the complexity of existing software relies heavily on the use of technicians to guide the surgeons. Moreover, 3D printed models, while giving surgeons the familiarity to rehearse the operation, are expensive. With recent developments in immersive virtual reality (VR), augmented-reality and haptic feedback, true 3D surgical simulation has become a viable option for presurgical planning and for resident training. Methods The Immersive-Touch Virtual-Reality Surgical Platform (IVSP) was developed in collaboration between the Plastic Surgery and Mechanical/Industrial Engineering Department. To visualize volume data vividly and smoothly, a graphics processing unit (GPU) based technique was designed to render the volume on a head-mounted display with ultra-fine resolution and fast frame-rate. The volume-rendering technique can be based on either a specified transfer function, or rendered as a polygon mesh, defining the surface of interest. Changes made to rendered volumes are updated in real-time and reflected immediately on the 3D-rendering. Discrete anatomical structures can be identified and segmented from source CT/CBCT data, and each segmentation was converted into a polygon mesh. Currently we have utilized VR planning in 98 orthognathic, 14 craniofacial, 42 maxillofacial trauma cases. Discussion: Our experience with over 150 cases has been that IVSP gave back the ability to the surgeon to better visualize the anatomy, design the osteotomies, reposition the skeletal elements with haptic control of the occlusion. Within this immersive environment, the surgeon more accurately made measurements that were difficult when visualizing the 3D skeleton in a 2D display compared to conventional software. We additionally found that IVSP eliminated the need to physically print 3D models. Moreover, our surgical residents found that they had a greater understanding of the anatomy and preparation for the surgery more relevant when in the VR environment.
ER  -
TY  - JOUR
TI  - Evaluating Visual-Spatiotemporal Coregistration of a Physics-based Virtual Reality Haptic Interface
PY  - 2022
DO  - 10.36227/techrxiv.19242951.v1
UR  - https://doi.org/10.36227/techrxiv.19242951.v1
DA  - 2022-03-03
AU  - Chowdhury, S.
AU  - Mubarrat, Syed
AU  - Fernandes, Antonio
AU  - Binkley, Kieran
LA  - en
KW  - Kinesthetic learning
KW  - Interface (matter)
KW  - Motion Capture
AB  - This study aimed to evaluate the visual-spatiotemporal coregistration of the real and virtual objects’ movement dynamics in a low-cost physics-based virtual reality (VR) system that provides real cutaneous and kinesthetic haptic feedback of the objects instead of computer-generated haptic feedback. Twelve healthy participants performed three human-robot collaborative (HRC) sequential pick-and-place lifting tasks while both motion capture and VR systems respectively traced the movement kinematics of the real and virtual objects. We used an iterative closest point algorithm to transform the 3D spatial point clouds of the VR system into the motion capture system. We employed a novel algorithm and principal component analysis to respectively calculate visual and spatiotemporal coregistration precisions between virtual and real objects. Results showed a high correlation (r &gt; 0.96) between real and virtual objects’ movement dynamics and linear and angular coregistration errors of less than 5 cm and 8°, respectively. The trend also revealed a low temporal registration error of &lt;12 ms and was only found along the vertical axis. The visual registration data indicated that the real cutaneous and kinesthetic haptics provided by the physical objects in the virtual environment enhanced proprioception and visuomotor functions of the users.
ER  -
TY  - JOUR
TI  - A virtual and haptic milling surgery simulator
PY  - 2006
DA  - 2006-01-01
AU  - Eriksson, Magnus
LA  - en
IS  - 4
ER  -
TY  - CHAP
TI  - Improving Sense-Making for Construction Planning Tasks Using Visual and Haptic Stimuli in Virtual Reality Environments
PY  - 2023
PB  - Firenze University Press
SN  - 2704-5846
T2  - Proceedings e report
DO  - 10.36253/979-12-215-0289-3.14
UR  - https://doi.org/10.36253/979-12-215-0289-3.14
DA  - 2023-01-01
AU  - Mutis, Iván
C1  - Illinois Institute of Technology, US
AU  - Оберемок, Марина
C1  - Illinois Institute of Technology, US
AU  - Purushotham, Nishanth
C1  - Illinois Institute of Technology, US
LA  - en
KW  - Sense of presence
SP  - 142
EP  - 154
ER  -
TY  - JOUR
TI  - New Technologies for Teaching Anatomy (Preprint)
PY  - 2023
DO  - 10.2196/preprints.49977
UR  - https://doi.org/10.2196/preprints.49977
DA  - 2023-06-15
AU  - Bankar, Maithili
AU  - Bankar, Nandkishor
AU  - Gajbe, Ujwal
AU  - Singh, Brij
AU  - Shambharkar, Shweta
AU  - Bahadure, Sweta
AU  - Bandre, Gulshan
AU  - Bankar, Swati
AU  - Shelke, Yogendra
LA  - en
ER  -
TY  - BOOK
TI  - Advances in Ergonomics in Manufacturing
PY  - 2012
PB  - Informa
T2  - CRC Press eBooks
DO  - 10.1201/b12322
UR  - https://doi.org/10.1201/b12322
DA  - 2012-07-10
AU  - Trzcieliński, Stefan
AU  - Karwowski, Waldemar
LA  - en
ER  -
TY  - GEN
TI  - None
PY  - 2007
PB  - Wiley
SN  - 1546-4261
T2  - Computer Animation and Virtual Worlds
DO  - 10.1002/cav.v18:3
UR  - https://doi.org/10.1002/cav.v18:3
DA  - 2007-07-01
AU  - Sun, Hanqiu
C1  - ENHUA WU University of Macau
C1  - The Chinese University of Hong Kong.
C1  - The Hong Kong Polytechnic University
AU  - Baciu, George
C1  - ENHUA WU University of Macau
C1  - The Chinese University of Hong Kong.
C1  - The Hong Kong Polytechnic University
LA  - en
VL  - 18
IS  - 3
ER  -
TY  - JOUR
TI  - Evaluating Visual-Spatiotemporal Co-Registration of a Physics-Based Virtual Reality Haptic Interface
PY  - 2024
PB  - Institute of Electrical and Electronics Engineers
SN  - 2169-3536
T2  - IEEE Access
DO  - 10.1109/access.2024.3391186
UR  - https://doi.org/10.1109/access.2024.3391186
DA  - 2024-01-01
AU  - Mubarrat, Syed
C1  - Department of Industrial Engineering, Texas Tech University, Lubbock, TX, USA
AU  - Chowdhury, S.
C1  - Department of Industrial Engineering, Texas Tech University, Lubbock, TX, USA
AU  - Fernandes, Antonio
C1  - Department of Industrial Engineering, Texas Tech University, Lubbock, TX, USA
LA  - en
KW  - Interface (matter)
VL  - 12
SP  - 57017
EP  - 57032
AB  - This study aimed to evaluate the visual-spatiotemporal co-registration of the real and virtual objects' movement dynamics in a low-cost physics-based virtual reality (VR) system that provides real cutaneous and kinesthetic haptic feedback of the objects instead of computer-generated haptic feedback. Twelve healthy participants performed three human-robot collaborative (HRC) sequential pick-and-place lifting tasks while both motion capture and VR systems respectively traced the movement kinematics of the real and virtual objects. We used an iterative closest point algorithm to transform the 3D spatial point clouds of the VR system into the motion capture system. We employed a novel algorithm and principal component analysis to respectively calculate visual and spatiotemporal co-registration precisions between virtual and real objects. Results showed a high correlation ( <italic xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">r</i> > 0.96) between real and virtual objects' movement dynamics and linear and angular co-registration errors of less than 5 cm and 8°, respectively. The trend also revealed a low temporal registration error of <12 ms and was only found along the vertical axis. The visual registration data indicated that the real cutaneous and kinesthetic haptics provided by the physical objects in the virtual environment enhanced proprioception and visuomotor functions of the users.
ER  -
TY  - JOUR
TI  - STEAM Apps: Weaving numerical and geometric comprehension with the fingers
PY  - 2021
SN  - 2744-4015
T2  - Link Symposium
DO  - 10.24135/link2021.v2i1.73
UR  - https://doi.org/10.24135/link2021.v2i1.73
DA  - 2021-12-31
AU  - Videla, Ronnie
C1  - Universidad de La Serena
LA  - en
KW  - Learning Sciences
KW  - Weaving
AB  - STEM and STEAM education promote integration between science, technology, engineering, math, and the arts. The latter aims to promote deep and collaborative learning of students, through the integration of the curriculum in K-12 science education. STEAM promotes the embodiment of cognition through learning by doing. The enactive and ecological approaches to cognition presented auspicious evidence for the role of incarnation and gesture in learning with digital technology. This work aims to provide design and concept evidence on the scope of enactive and ecological approaches within the framework of STEAM learning with digital and emerging technologies focused on the concept of tissue. We place ourselves epistemologically from the embodied design for the development of educational technology centered on "learning is moving in some way" following Dor Abrahamson who reveals the enactive and ecological approaches to learning science. Also, we are framed in Claudio Aguayo's UX and UI user experience designs with emerging technologies. In the case of digital technologies, we pay special attention to learning mathematics through the knowledge of numbers and operations with the fingers. To do this, we present a prototype of Apps inspired by Nathalie Sinclair's Touchcounts and Touchtimes, with variations in haptic perception for the emergence of numbers and operations through touching and tracing movements with the fingers on the touch screen. Regarding emerging technologies, we rely on augmented reality and virtual reality. In the case of augmented reality, we focus on learning science and geometry through the spider web. The idea is that students can see the different planes of a spider web and identify different regular and irregular geometric figures, as well as explore the architecture of the web and its properties. In relation to virtual reality, we focus on Mapuche textile art (indigenous people of southern Chile) where we explore the characteristic fabrics of the culture within the “ruca” (characteristic home of the Mapuches). First, students design Mapuche textile fabrics from geometric patterns, applying symmetry and fractals. Then with virtual reality glasses, they can navigate inside the ruca to learn details of its architecture and the fabrics most used by the Mapuche culture. Our STEAM approach to app development consists of an integrated learning ecosystem that enhances digital and immersive experiences for learning about math, science, and art using engineering and technology. Finally, we can conclude that our approach describes education as a process of cognitive assembly embodied in perception and guided action with different types of artifacts through digital affordances. We highlight the role of the disciplinary integration of Science, Technology, Engineering, Arts and Mathematics to understand and strategically reveal the scientific cultural potential of our native people "Los Mapuches".
ER  -
TY  - JOUR
TI  - Designing a reconfigurable multimodal and collaborative supervisor for Virtual Environment
PY  - 2011
T2  - IEEE Virtual Reality Conference
DO  - 10.1109/vr.2011.5759480
UR  - https://doi.org/10.1109/vr.2011.5759480
DA  - 2011-03-01
AU  - Martin, Pierre
C1  - V&AR VENISE team, CNRS/LIMSI, B.P 133, 91403 Orsay (France)#TAB#
AU  - Bourdot, Patrick
C1  - V&AR VENISE team, CNRS/LIMSI, B.P 133, 91403 Orsay (France)#TAB#
LA  - en
KW  - Supervisor
KW  - Multimodal Interaction
KW  - Merge (version control)
KW  - Collaborative software
SP  - 225
EP  - 226
ER  -
TY  - JOUR
TI  - 3D Games for Tuning and Learning About Hearing Aids
PY  - 2016
PB  - Lippincott Williams & Wilkins
SN  - 0745-7472
T2  - The Hearing Journal
DO  - 10.1097/01.hj.0000481810.74569.d8
UR  - https://doi.org/10.1097/01.hj.0000481810.74569.d8
DA  - 2016-02-27
AU  - Eastgate, Richard
C1  - Dr. Eastgate, left, is the technical director of the Human Factors Research Group at the University of Nottingham and a founding member of VIRART, the Virtual Reality Applications Research Team. Dr. Picinali, second from left, is a senior lecturer in audio experience design and the director of undergraduate studies in the Dyson School of Design Engineering. Dr. Patel is the University of Nottingham principal investigator for 3D-Tune-In, a senior research fellow in the Human Factors Research Group at the University of Nottingham, a chartered research psychologist, and an associate fellow of the British Psychological Society. Dr. D'Cruz, right, is the director of European Research for the Human Factors Research Group (HFRG) at the University of Nottingham, and a research development manager for the faculty of engineering.
AU  - Picinali, Lorenzo
C1  - Dr. Eastgate, left, is the technical director of the Human Factors Research Group at the University of Nottingham and a founding member of VIRART, the Virtual Reality Applications Research Team. Dr. Picinali, second from left, is a senior lecturer in audio experience design and the director of undergraduate studies in the Dyson School of Design Engineering. Dr. Patel is the University of Nottingham principal investigator for 3D-Tune-In, a senior research fellow in the Human Factors Research Group at the University of Nottingham, a chartered research psychologist, and an associate fellow of the British Psychological Society. Dr. D'Cruz, right, is the director of European Research for the Human Factors Research Group (HFRG) at the University of Nottingham, and a research development manager for the faculty of engineering.
AU  - Patel, Harshada
C1  - Dr. Eastgate, left, is the technical director of the Human Factors Research Group at the University of Nottingham and a founding member of VIRART, the Virtual Reality Applications Research Team. Dr. Picinali, second from left, is a senior lecturer in audio experience design and the director of undergraduate studies in the Dyson School of Design Engineering. Dr. Patel is the University of Nottingham principal investigator for 3D-Tune-In, a senior research fellow in the Human Factors Research Group at the University of Nottingham, a chartered research psychologist, and an associate fellow of the British Psychological Society. Dr. D'Cruz, right, is the director of European Research for the Human Factors Research Group (HFRG) at the University of Nottingham, and a research development manager for the faculty of engineering.
AU  - D’Cruz, Mirabelle
C1  - Dr. Eastgate, left, is the technical director of the Human Factors Research Group at the University of Nottingham and a founding member of VIRART, the Virtual Reality Applications Research Team. Dr. Picinali, second from left, is a senior lecturer in audio experience design and the director of undergraduate studies in the Dyson School of Design Engineering. Dr. Patel is the University of Nottingham principal investigator for 3D-Tune-In, a senior research fellow in the Human Factors Research Group at the University of Nottingham, a chartered research psychologist, and an associate fellow of the British Psychological Society. Dr. D'Cruz, right, is the director of European Research for the Human Factors Research Group (HFRG) at the University of Nottingham, and a research development manager for the faculty of engineering.
LA  - en
KW  - Hearing aid
VL  - 69
IS  - 4
SP  - 30
EP  - 30
ER  -
TY  - JOUR
TI  - Function-Based Haptic Interaction in Cyberworlds
PY  - 2011
DO  - 10.1109/cw.2011.19
UR  - https://doi.org/10.1109/cw.2011.19
DA  - 2011-10-01
AU  - Wei, Lei
C1  - Nanyang Technological University, Singapore
AU  - Sourin, Alexei
C1  - Nanyang Technological University, Singapore
LA  - en
KW  - Stereotaxy
KW  - Parametric surface
KW  - Polygon (computer graphics)
SP  - 217
EP  - 221
ER  -
TY  - JOUR
TI  - Learning Module of PEM Fuel Cells
PY  - 2020
T2  - 2020 ASEE Virtual Annual Conference Content Access Proceedings
DO  - 10.18260/1-2--34903
UR  - https://doi.org/10.18260/1-2--34903
DA  - 2020-09-08
AU  - Husanu, Irina
C1  - Delaware County Commu-nity College in 2018,
C1  - Drexel University
C1  - Drexel University (Eng. & Eng. Tech.
C1  - Drexel University Drexel University student studying Mechanical Engineering Technology.
C1  - Drexel University,
C1  - Engineering Technology Department at Drexel Uni-versity, Philadelphia, USA.
AU  - Frank, Kevin
C1  - Delaware County Commu-nity College in 2018,
C1  - Drexel University
C1  - Drexel University (Eng. & Eng. Tech.
C1  - Drexel University Drexel University student studying Mechanical Engineering Technology.
C1  - Drexel University,
C1  - Engineering Technology Department at Drexel Uni-versity, Philadelphia, USA.
AU  - Gardner, Ayanna
C1  - Delaware County Commu-nity College in 2018,
C1  - Drexel University
C1  - Drexel University (Eng. & Eng. Tech.
C1  - Drexel University Drexel University student studying Mechanical Engineering Technology.
C1  - Drexel University,
C1  - Engineering Technology Department at Drexel Uni-versity, Philadelphia, USA.
AU  - Chiou, Richard
C1  - Delaware County Commu-nity College in 2018,
C1  - Drexel University
C1  - Drexel University (Eng. & Eng. Tech.
C1  - Drexel University Drexel University student studying Mechanical Engineering Technology.
C1  - Drexel University,
C1  - Engineering Technology Department at Drexel Uni-versity, Philadelphia, USA.
LA  - en
AB  - Abstract An important role of undergraduate education is stimulating critical thinking and enabling engineering students to be creative while developing analytical skills. Virtual Reality is becoming a powerful tool for multisensory teaching which enhances learning by using imagery and haptics to represent and study concepts and notions. Project-based interdisciplinary learning offer students a broader perspective over systems integration while exploring fundamental notions of the topics studied [1, 2]. Several studies that were developed during the past decade classified the VR impact upon learning as follows: the VR evolved towards competency based learning from a resource type format [1], while enabling students to take an active role in investigating the notions and concepts studied. The VR platform offers the possibility of exploring real-like scenarios that otherwise would be difficult or unachievable due to financial and/or lab space issues. In addition, VR, AR (augmented reality) and MR (mixed reality) platform gain acceptance and use in many STEM courses, as it enhances face-to-face, online and distance learning, creating a collaborative environment and engaging students in learning.[3]. However, creating the learning modules using different engines is not without challenge [4]. The Proton Exchange Member (PEM) fuel cell is a power source that is environmentally friendly with the bonus of having high efficiency and a low operational temperature. While these types of fuel cells are efficient, conducting an experiment with them can be very expensive. A PEM fuel cell consists of three main parts: a polymer electrolyte membrane, an anode and a cathode. The anode and cathode themselves have three separate regions: the catalyst layer, the gas diffusion layer and the gas channel. As part of the undergraduate research efforts, an undergraduate student explored the VR technology (engine) and developed the framework for developing learning modules using a real-like industrial scenario. The major tasks described are the description of the developmental platform and the modeling of the VR framework as applied to a PEM fuel cell and using Phase Change Materials (PCM) to enhance performance. Students explore concepts as parametric characterization of the thermo-chemical system. VR technology will enable students to explore new ways to implement their knowledge in a practical manner, enhancing information retention and promoting critical thinking. The goal of this investigation is to develop a cyber learning module using immersive Virtual Reality Learning Environment and a VR learning module based on simulation of a PEM fuel cell to enable students to enhance their learning in the area of renewable and green energy technology, while exploring fundamental concepts in fuel cell design, including thermodynamics and thermochemistry and fluid mechanics associated with this module. This will introduce students to a more integrative learning rather than simple experiments or animations that enhances topic comprehension and student motivation While PEM fuel cells can be described using basic theoretical notions, developing reliable and efficient fuel cells for educational purposes can be very expensive. It has been proven that computational fluid dynamics (CFD) models can be a critical tool to model fuel cells. Our goal is to take a CFD model from a CAD platform and put it into a virtual reality platform. By doing this, students will be able to learn about these more intuitive processes within the subject taught. After making a model in SolidWorks and running a simulation with the fuel cell, an undergrad student compared the results to experimental results from the lab to validate the simulated model. Moreover, this Virtual Reality Learning Environment (VRLE) is used to bridge the gap between theoretical approach and experimental activities in face-to-face learning. The module will be beta-tested during this Fall term and potentially fully implemented during subsequent terms. The results and assessment will be presented in the full paper. This paper will focus not only on technical aspects of developing the learning platform and the VR module but more upon educational aspects of undertaking undergraduate research and assessment of the learning module. Comparisons will be made regarding student knowledge retention with and without VR learning enhancement to test the efficacy of the VR module in beta-testing environment and then during course implementation.
ER  -
TY  - BOOK
TI  - Research into Design for a Connected World Proceedings of ICoRD 2019 Volume 1
PY  - 2019
DA  - 2019-01-01
AU  - Chakrabarti, Amaresh
LA  - en
KW  - Conceptual design
KW  - Design management
ER  -
TY  - JOUR
TI  - Horizon Report: Knowledge Obsolescence, Artificial Intelligence, and Rethinking the Educator Role
PY  - 2017
PB  - Lippincott Williams & Wilkins
SN  - 1536-5026
T2  - Nursing Education Perspectives
DO  - 10.1097/01.nep.0000000000000154
UR  - https://doi.org/10.1097/01.nep.0000000000000154
DA  - 2017-05-01
AU  - Skiba, Diane
C1  - The author declares no conflict of interest.
LA  - en
KW  - Obsolescence
KW  - Blended Learning
VL  - 38
IS  - 3
SP  - 165
EP  - 167
AB  - The New Medium Consortium Horizon Report 2017 is a mixture of old, continuing, and a few new concepts (Adams Becker et al., 2017). Each year I summarize the results of this report, which identifies trends, challenges, and emerging technologies on the horizon. (The method used to determine these factors is outlined in the report.) TRENDS As in the past, the report presents short-term, mid-term, and long-term trends. The short-term trends highlighted for 2017 are blended and collaborative learning. Blended learning has been a consistent trend since 2012. As online learning has become more accepted in the academy (Skiba, 2017a), research to identify best practices in online and face-to-face learning has spearheaded the offering of blended learning opportunities. With the availability of more dynamic learning management platforms, universities are able to offer flexibility, ease of access, and various multimedia technologies to complement the occasional face-to-face meetings. Adams Becker et al. (2017, p. 9) note that the "current focus of this trend has shifted to understanding how applications of digital modes of teaching are impacting students." Collaborative learning, mentioned in 2012, has now resurfaced and focuses on four principles: "placing the learner at the center, emphasizing interaction, working in groups, and developing solutions to real challenges" (Adams Becker et al., 2017, p. 9). The term has been around for a long time as many in the online arena have formed communities of practice. What has changed is the technology. We now have cloud-based services and shared workspace tools that facilitate the ability of groups and teams to work together, anytime and anywhere. A mid-term trend, mentioned since 2013, is the measurement of learning and the use of assessment tools to document academic readiness, learning progress, and educational outcomes. What is different now is the availability of data mining and visualization tools. One continuing difficulty is how to measure the soft skills that employers value, such as collaboration and creativity. The other mid-term trend, mentioned since 2015, is the redesign of learning spaces with more digital tools to promote active learning and engagement in classroom settings. The two long-term trends are both familiar. The goal of deeper learning (project based, challenge based, or inquiry based), first mentioned in 2012, is "mastery of content that engages students in critical thinking, problem-solving, collaboration, and self-directed learning" (Adams Becker et al., 2017, p. 9). In nursing, deeper learning could be intertwined with the interprofessional team goals outlined in your curriculum. The second long-term trend is advancing cultures of innovation, mentioned since 2015. As many faculty know, it is difficult to foster an environment of innovation. As noted by Adams Becker et al. (2017, p. 10), a recent Chronicle of Higher Education study (http://chroniclegreatcolleges.com/blog/indicators-cultureinnovation/) identified five overarching themes to foster innovation: "the need for open communication, collaboration within departments, job security when challenging the status quo, shared responsibility, and top-down support." I remember when we first transitioned courses to an online format in 1998. As associate dean, I wrote letters extolling the leadership and creativity of those early faculty who were fearful of getting terrible course evaluations because they were challenging the status quo. CHALLENGES Two solvable challenges have been on the list since 2015: improving digital literacy and integrating formal and informal learning. We need to push our institutions to have general requirements about digital literacy and provide educational materials to prepare all students and faculty. In nursing education, we need to build on this foundation and expand our teaching from merely judging the validity and veracity of web pages to encompass the social media tools and mobile applications used by our patients. The integration of informal and formal learning should lead students to develop a commitment to lifelong learning. Institutions in many countries have begun to develop strategies for recognition of prior learning. Information about Australia's recognition program is online (www.mq.edu.au/study/admissions/recognition-of-priorlearning), as is information about Trinity College's program (www.tcd.ie/teaching-learning/assets/pdf/RPL%20Policy%20Final.pdf). California State University offers the Channel Islands Digital Badges project (http://nursingdigitalbadges.jaimeahannans.com/). A student must complete QSEN learning modules and various activities to earn a digital badge. For example, the Caregiver Empathy digital badge requires completion of the QSEN module, submission of a reflective discussion paper, and nomination by a peer or faculty member highlighting an event where the student demonstrated caregiver empathy. Two new difficult challenges are the achievement gap and achieving digital equity. According to Adams Becker et al. (2017, p. 28), "the achievement gap…reflects a disparity in the enrollment and academic performance between student groups, defined by socioeconomic status, race, ethnicity, or gender." Rising tuition costs is certainly one major issue, but the question for most institutions is how to use data analytics for personalized learning and to connect students with necessary support systems, such as writing centers and tutors. Digital equity refers to inadequate access to the Internet, especially broadband access. Although many think this is an issue only in developing countries, Holmes (2016), writing for the Center for Public Integrity, reports that 30 million Americans lack broadband access. It is important to note that access can also refer to making web content accessible to disabled populations. To learn more, you can visit www.w3.org/WAI/intro/accessibility.php. Two new wicked challenges — those that are complex to even define, much less address — are of particular importance to faculty. The first is managing knowledge obsolescence. It is hard enough in health care to keep pace with the growth of knowledge in one's own discipline or specialty. As faculty, we are constantly updating courses, trying to stay one step ahead of our students. On top of that, we are expected to manage knowledge related to teaching-learning, educational technologies, and devices that are accelerating at warp speed. In some universities, the emphasis on research and scholarship overrides the recognition of teaching innovations. Pennsylvania State University offers faculty support with a three-pronged approach that encompasses faculty experimentation, programmer and instructional design support, and faculty and administration problem solving. A good example explores smart watches and learning (www.centerdigitaled.com/higher-ed/How-to-Help-Faculty-Explore-Wearable-Technology-for-Learning.html). The second wicked challenge involves rethinking the roles of educators. Remember the prediction that we, as educators, would move from Sage on the Stage to Guide on the Side? Now, more than ever, this is becoming a reality. Faculty are being asked to incorporate many new teaching strategies that focus on concepts such as learner-centered education and competency-based education, with, of course, all education being supported by use of the latest and greatest educational technologies. As this shift occurs, many schools are beginning to rethink the role of the educator and what faculty models should guide institutions in the future. The TIAA Institute (2016) commissioned a study to examine higher education stakeholders' views of faculty models. Read the executive summary or full report to learn more. ON THE HORIZON For the category Educational Technology Developments on the Horizon, there are four previously listed technologies and two that emerged recently. Adaptive learning technologies are in the category one year or less. For the marriage between personalized learning and learning analytics, these technologies monitor student learning and adjust the presentation of content based on the learner's performance, accelerating or remediating as needed. The 2016 Digital Learning Innovation Award was given to an adaptive learning project at Tougaloo College (https://onlinelearningconsortium.org/about/2016-dliaward-recipient-tougaloo-college). The other technology on the one-year or less horizon, mobile learning, was on the list in 2012 and reemerged. "Mobile devices have become the gateways to personalized working and learning environments that facilitate the exploration of new subjects at each user's pace" (Adams Becker et al., 2017, p. 40). Learning management tools are being adapted for use on smartphones and tablets as fewer students have desktop computers. We use a video-conferencing program for team meetings, virtual office hours, applicant interviews, and comprehensive exams in our MS program. Most students connect via their tablet or smartphone. The use of mobile technology is also highlighted in classrooms and large lecture halls as a mechanism to engage students and have them become more interactive. At Purdue University, students use an app, called Hotseat (www.itap.purdue.edu/studio/hotseat/), to ask questions and comment in real time in class. Students can then ask each other questions or add to the comments. Faculty find that the app helps them modify their teaching, engage students, and give voice to those "quiet" students. Here is a good link to how m-learning is helping nurses in African countries maintain their professional licensure (www.nursinglibrary.org/vhl/bitstream/10755/617333/1/Mukami_D_s22990_1.pdf). On the two- to three-year horizon are two technologies: the Internet of Things (IOT), on the list in 2012, 2015, and 2017, and next-generation learning management system (LMS), a new entry. Asseo, Johnson, Nilsson, Chalapathy, and Costello (2016), industry leaders representing various companies (Salesforce, Google, Extreme Networks, Education Innovation, and Cisco), describe the impact of the Internet of Things on education. The next-generation LMS is exciting. I like the idea of a next-generation digital learning ecosystem that represents a mixture of IT systems to enhance learning, support personalized learning, conduct formative assessments, and have interoperability with common tools provided by other vendors. With the growing use of learning analytics and open educational resources, this ecosystem will be more important as we structure competency-based education and adaptive learning strategies. Similar to nurses providing holistic care to a patient, the next-generation LMS ecosystem should provide a holistic picture of learning. On the four- to five-year horizon, there are natural user interfaces, which first appeared in 2012 and are now resurfacing. With the development of gesture-sensing technology, voice recognition, and haptic technology, the learner can engage in virtual activities using a multitude of natural user interfaces. These are perfect for engaging students who may have disabilities. Natural user interfaces also allow students to feel the experience, such as when nursing students at Hong Kong Polytechnical University use a haptic feedback system to learn how to insert a nasogastric tube (https://www.polyu.edu.hk/cpa/milestones/en/201609/research_innovation/life_sciences/computerised_haptic_system_facilitates_nasogastric/index.html). Another example is HoloMed, a holographic system paired with a gesture-based interface that helps students more accurately visualize the childbirth process (Adams Becker et al., 2017; https://arxiv.org/pdf/1607.05812.pdf). The newest and most fascinating technology in the four- to five-year window is artificial intelligence. As I mentioned in my last column (Skiba, 2017b), cognitive computing and virtual assistants are already surfacing in the health care arena. IBM's Watson is being used at Deakin University as a 24/7 online help desk (www.deakin.edu.au/about-deakin/media-releases/articles/ibm-watson-helps-deakin-drive-the-digital-frontier). Imagine that the next-generation LMS will come with virtual assistants that can help tutor students who are struggling with understanding a particular concept or figuring out how to calculate drug dosages for a premature baby. Soon you will call upon Siri, Cortana, and Alexa to help you conduct a literature search to find the best practices for a particular nursing intervention. I would hope for a virtual writing tutor so students can get guidance when they have an incomplete sentence or a sentence that does not make sense. What will be really exciting is to have tools to mine and analyze the mounds of data we can collect on a learner and use machine learning to create personalized learning pathways and help faculty with student engagement, retention, and the demonstration of learning outcomes. It will be exciting to see what the future holds as artificial intelligence and cognitive computing become more commonplace. SUMMARY The Horizon Report 2017 offers a reinforcement of previous trends, challenges, and technologies. As faculty, we need to embrace some of these technologies and envision how to tackle the challenges before us. I am also excited to see new additions, particularly in the technology realm. These new technologies offer much to help us provide a holistic learning experience for our students. I am also pleased to see that we are starting to rethink the role of the educator and beginning to explore new faculty models. I look forward to your thoughts and ideas as we venture forth in the new horizon. As always, you can email me at [email protected].
ER  -
TY  - JOUR
TI  - Perspectives of medical students on local medical education during COVID-19
PY  - 2020
PB  - Medknow
SN  - 0037-5675
T2  - Singapore Medical Journal
DO  - 10.11622/smedj.2020105
UR  - https://doi.org/10.11622/smedj.2020105
DA  - 2020-07-16
AU  - Teo, DesmondB
C1  - Chronic Programme, Alexandra Hospital, Singapore
C1  - Division of Advanced Internal Medicine, Department of Medicine, National University Hospital, Singapore
C1  - Dr Desmond B Teo, Consultant, Division of Advanced Internal Medicine, Department of Medicine, National University Hospital, 5 Lower Kent Ridge Road, Singapore 119074. E-mail: [email protected]
C1  - Yong Loo Lin School of Medicine, National University of Singapore, Singapore
AU  - Tan, KuangIan
C1  - Ministry of Health Holdings, Alexandra Hospital, Singapore
AU  - Foo, Jenies
C1  - Ministry of Health Holdings, Alexandra Hospital, Singapore
AU  - Ang, B.
C1  - Ministry of Health Holdings, Alexandra Hospital, Singapore
AU  - Chua, Joo
C1  - Chronic Programme, Alexandra Hospital, Singapore
C1  - Division of Respiratory and Critical Care Medicine, National University Hospital, Singapore
C1  - Fast Programme, Alexandra Hospital, Singapore
C1  - Yong Loo Lin School of Medicine, National University of Singapore, Singapore
LA  - en
KW  - Preparedness
KW  - Pandemic
KW  - Contingency plan
VL  - 63
IS  - 7
SP  - 402
EP  - 404
AB  - INTRODUCTION The coronavirus disease 2019 (COVID-19) pandemic has led to major disruptions worldwide. Cessation of non-essential services and overseas travel bans have been implemented throughout the world. Medical education is not spared either. Clinical postings are suspended and medical students are barred from direct patient contact.[1] However, this is not new to us, as we have experienced several disease outbreaks since the severe acute respiratory syndrome (SARS) epidemic in 2003 and the H1N1 pandemic in 2009. The SARS outbreak highlighted a unique set of challenges that accompanied the delivery of medical education worldwide during an epidemic. To reduce the transmission of infection, patient contact and didactic lectures were prohibited.[23] This curtailed learning for students, and medical schools responded by implementing measures to minimise disruption to their curriculum.[3] After the H1N1 pandemic in 2009, local educators proposed a contingency plan for our medical education system if similar containment measures are implemented in future outbreaks.[4] After more than a decade, the preparedness of medical schools in continuing medical education is being tested once again. It is imperative to have viable alternatives for this ever-present risk of disruption to education. Have we learnt from our previous experiences? As medical students who have recently graduated from Yong Loo Lin School of Medicine, National University of Singapore, we examined the measures implemented by the school through our observations and experiences, and provide suggestions to cope with the current and future outbreaks. WHAT WAS DONE FOR CLINICAL TEACHING AND EXAMINATIONS? The national Disease Outbreak Response System Condition (DORSCON) was raised to Orange on 7 February 2020 owing to possible community spread, resulting in the implementation of enhanced measures such as the cancellation of large-scale events and inter-institution/external activities. In response, medical schools in Singapore issued a circular to cease clinical rotations for medical students. Since then, lectures had been shifted online, while case-based learning and virtual simulations had been introduced to replace direct clinical exposure. Near-peer and alumni were also roped in to conduct small group online tutorials, with a mixture of case-based tutorials and revision on core topics, to supplement the school's efforts in continuing medical education. These tutorials focused on imparting clinical experience to fill the knowledge gaps. Clinical examinations had been also disrupted. Final year practical examinations, which traditionally involve actual patients, had been replaced with simulated patients. This ensured that communication and history-taking skills were still assessed. The ability to detect abnormal signs, such as heart murmurs, breath sounds, abdominal or rectal masses, was assessed using models of body parts and the Harvey mannequin. This allowed practical examinations to be conducted as realistically as possible, without sacrificing important clinical components, before graduation. The validity of the examinations was not compromised, as the pass-fail criterion remained the same. Even though changes to the conduct of examination (such as substituting a standardised patient in place of a live patient) were necessary, students were reassured that standards would not be compromised and examinable domains would remain. This allowed for a more objective assessment, as the same assessment criteria could be better applied with the same examination content for the cohort. PROMISING ALTERNATIVES FOR MEDICAL STUDENTS Our medical school was flexible in modifying schedules, allowing holidays to be brought forward and postponing clinical attachments in the hope of minimising loss of clinical exposure while monitoring the situation. However, this was only a temporising measure. Intermediate plans should be put in place and conveyed to students as early as possible, despite the uncertainties, to allay students' concerns, anxieties and fears regarding training disruption. Furthermore, the focus of the clinical curriculum initially shifted to important topics such as public health, health literacy and ethics, where patient interactions were not required for teaching. These areas tend to be neglected by students, as they are deemed unimportant for assessment. However, in the current climate, they provide an excellent contextualised learning opportunity for students to witness the importance of having a good grasp of epidemiology and ethics first-hand. For example, real-life application of epidemiological studies could be demonstrated through the analysis of COVID-19 and its spread, and how it has played a major role in the surveillance and prevention policies implemented by our government. Furthermore, students can witness how justice, one of the key pillars of medical ethics, comes into play in equal and fair resource distribution in times of scarcity. Teaching students to better appreciate the correlations (or links) between basic sciences and clinical medicine can be reinforced. A study has shown that self-explanation can be used as a tool to improve diagnostic performances, because it helps students to achieve a more coherent mental representation of diseases (illness scripts).[5] This helps students to synthesise clinical features into useful problem representations during history-taking, which improves their ability to compare and contrast key features in patients' presenting complaint.[6] Following this, the school can teach students to generate a prioritised list of differential diagnoses. This can be taught by taking students through case-based clinical reasoning scenarios that illustrate an expert's thought process during a clinical encounter.[7] The pandemic has hastened the process of incorporating technology into medical education. Along with it comes a 'new normal' – reduced exposure to actual patients and increased exposure to technology. Other than going online for traditional in-person teaching sessions, clinical attachments can also go virtual. With the Ministry of Health encouraging selected patients with chronic diseases to use video-consultations through secured platforms,[8] participating in these telehealth sessions could be a good alternative to clinical exposure. As consultation is conducted online, more students can 'sit in' as compared to actual clinic attachment, where only one or two students are present. This maximises learning opportunities from limited clinical materials. However, students may not have been able to examine the patient clinically to fully appreciate the extent of clinical medicine. Careful consideration of patient autonomy and privacy is also important in the implementation of this alternative. Collaboration between medical schools is vital and should be fostered in these times. Pooling of resources such as teaching materials, simulation software and other technologies would allow for a smoother transition from clinical teaching. One example is PIVOT MedEd,[9] an overseas initiative that aims to gather resources across medical schools to facilitate clinical learning through an online platform. Medical schools can also consider collaborating with hospitals to improve technologies such as augmented reality and haptic simulation.[10] This would replicate not only the visual perceptions of real-life experience but also sensations of physical touch. Such technology allows both medical students and junior surgeons to simulate surgical procedures that can further enhance their practical skills. Lastly, we could consider implementing a bold but controversial measure – introducing medical students to the public health systems, such as staffing them to assist with contact tracing.[11] Not only does this help with reducing the manpower crunch, but it also exposes medical students to the workforce, allowing them to gain invaluable experience without significantly increasing the risk of contracting the virus. However, the risk and benefits to both the student and community should be weighed before such measures are implemented. Undoubtedly, the 'new normal' in medical education has its drawbacks. Changes beget uncertainties, but one thing remains unchanged over the years – no medical student will ever feel prepared enough to be a doctor immediately after graduation. The ever-daunting prospect that a patient's life is dependent on our actions while under our care will drive every student and doctor to ensure that their learning is not compromised. CONCLUSION Clinical experience and patient interactions are vital in medical education. They cannot be fully replaced. Alternatives must be explored to ensure that medical students remain competent despite major disruption to clinical postings. Contingency planning, rather than reactive measures, must take place to prepare for scenarios such as an infectious disease outbreak, and this will be a recurring theme. Being at the crux of an evolving landscape also means a potential for breakthroughs in learning when medical students choose to embrace the challenges ahead. The use of technology in simulations and virtual reality is promising, and more should be done to enhance learning during these difficult times and to ensure its continuity after the pandemic, so that medical education can be pandemic proof.
ER  -
TY  - JOUR
TI  - Security for the Metaverse: Blockchain and Machine Learning Techniques for Intrusion Detection
PY  - 2023
DO  - 10.36227/techrxiv.22858817.v1
UR  - https://doi.org/10.36227/techrxiv.22858817.v1
DA  - 2023-05-19
AU  - Truong, Vu
AU  - Le, Long
LA  - en
KW  - Metaverse
AB  - &lt;p&gt;The Metaverse, which is emerging as the next-generation (NextG) Internet, offers an immersive 3D virtual world in which people can organize various virtual activities and interact with each other seamlessly through digital avatars. As the NextG Internet, however, the Metaverse also faces severe security risks inherited from its predecessor as well as various new emerging threats. Furthermore, the decentralized nature of the Metaverse even makes it more challenging to mitigate these issues in a large-scale setting with numerous interactive wearable devices such as augmented, virtual reality (AR/VR) headsets and haptic devices. In this article, we aim to analyze the security aspect of the Metaverse thoroughly with special discussions of solutions enabled by blockchain and machine learning (ML). Firstly, we present a 4-layer architecture of the Metaverse and discuss potential solutions for Metaverse security based on blockchain and ML. Next, we develop a decentralized collaborative intrusion detection system (CIDS) based on blockchain and federated learning (FL) that allows such the Metaverse users to collaboratively protect this digital world, thereby solving the scalability and single-point-of-failure (SPoF) issues of traditional security approaches, which may not be effective in protecting the Metaverse with increasingly sophisticated attacks. Finally, we outline some key challenges and discuss future research directions for Metaverse security.&lt;/p&gt;
ER  -
TY  - JOUR
TI  - A Virtual Reality Platform for Musical Creation
PY  - 2013
PB  - Centre National de la Recherche Scientifique
T2  - HAL (Le Centre pour la Communication Scientifique Directe)
DA  - 2013-10-15
AU  - Leonard, James
C1  - ACROE-ICA - ACROE - Ingénierie de la Création Artistique (46 av. Félix Viallet - 38031 Grenoble Cedex - France)
AU  - Cadoz, Claude
C1  - ACROE-ICA - ACROE - Ingénierie de la Création Artistique (46 av. Félix Viallet - 38031 Grenoble Cedex - France)
AU  - Castagné, Nicolas
C1  - ACROE-ICA - ACROE - Ingénierie de la Création Artistique (46 av. Félix Viallet - 38031 Grenoble Cedex - France)
AU  - Luciani, Annie
C1  - ACROE-ICA - ACROE - Ingénierie de la Création Artistique (46 av. Félix Viallet - 38031 Grenoble Cedex - France)
LA  - en
KW  - Musical instrument
AB  - Virtual reality aims at interacting with a computer in a similar form to interacting with an object of the real world. This research presents a VR platform allowing the user (1) to interactively create physically-based musical instruments and sounding objects, (2) play them in real time by using multisensory interaction by ways of haptics, 3D visualisation during playing, and real time physically-based sound synthesis. So doing, our system presents the two main properties expected in VR systems: the possibility of designing any type of objects and manipulating them in a multisensory real time fashion. By presenting our environment, we discuss the scientific underlying questions: (1) concerning the real time simulation, the way to manage simultaneous audio-haptic-visual cooperation during the real time multisensory simulations and (2) the Computer Aided Design functionalities for the creation of new physically-based musical instruments and sounding objects.
ER  -
TY  - JOUR
TI  - The Study of Using Eye Movements to Control the Laparoscope Under a Haptically-Enabled Laparoscopic Surgery Simulation Environment
PY  - 2018
T2  - 2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)
DO  - 10.1109/smc.2018.00513
UR  - https://doi.org/10.1109/smc.2018.00513
DA  - 2018-10-01
AU  - Zhou, Hailing
C1  - IISRI Deakin University, Geelong, Australia
AU  - Wei, Lei
C1  - IISRI Deakin University, Geelong, Australia
AU  - Cao, Ran
C1  - Surgery Department First People's Hospital of YunNan Province New KunHua Hospital, YunNan, China
AU  - Hanoun, Samer
C1  - IISRI Deakin university, Geelong, Australia
AU  - Bhatti, Asim
C1  - IISRI Deakin University, Geelong, Australia
AU  - Tai, Yonghang
C1  - IISRI Deakin University, Geelong, Australia
AU  - Nahavandi, Saeid
C1  - IISRI Deakin University, Geelong, Australia
LA  - en
SP  - 3022
EP  - 3026
ER  -
TY  - JOUR
TI  - Future of cadaveric dissection in anatomical science education
PY  - 2022
PB  - Medknow
SN  - 2277-4025
T2  - National Journal of Clinical Anatomy
DO  - 10.4103/njca.njca_126_22
UR  - https://doi.org/10.4103/njca.njca_126_22
DA  - 2022-01-01
AU  - Ravi, Kumar
C1  - Assistant Professor, Department of Anatomy, All India Institute of Medical Sciences, Bathinda, Punjab, India
C1  - Dr. Kumar Satish Ravi, Department of Anatomy, All India Institute of Medical Sciences, Rishikesh, Uttarakhand, India. E-mail: [email protected]
AU  - Patra, Apurba
C1  - Assistant Professor, Department of Anatomy, All India Institute of Medical Sciences, Bathinda, Punjab, India
AU  - Pushpa, N.
C1  - Assistant Professor, Department of Anatomy, All India Institute of Medical Sciences, Bathinda, Punjab, India
LA  - en
KW  - Cadaveric spasm
VL  - 11
IS  - 3
SP  - 123
EP  - 123
AB  - Shreds of evidence of human cadaveric dissection date back to the 3rd century BC.[1] Herophilus and Erassistratus from Greece, were the first to conduct systematic dissection of human cadaver. 2nd century witnessed Galen, a Greek physician, and the Latin versions of his texts became the standard for teaching anatomy in the Western world. However, the social, religious, and ethical taboos prevented scholars from conducting dissection, and barber surgeons were dissecting the instructions of anatomists. Andreas Vesalius, the father of Anatomy, asserted that doing dissection by himself is the best way to learn anatomy. In that way, he spearheaded a paradigm shift from learning anatomy through a series of illustrations to accepting cadaveric dissection as the crucial tool and challenged various notions of Galen in his book-De humani corporis fabrica.[23] Since then, human cadaveric dissection has remained the primary channel of teaching anatomy to medical students.[4] However, in recent years, teaching anatomy by dissection is becoming challenging for various reasons, the most essential being cadaver shortage. Anatomy teachers across the world started using different modern technology like virtual cadavers or simulators to make the anatomy teaching–learning more exciting and to overcome the cadaver scarcity.[5] Before COVID 19, the rampant usage of advanced technology in anatomy teaching was just an "option". However, the COVID pandemic has led to a paradigm shift; what was an "option" earlier is now an "obligation."[6] At present, although most medical schools have reopened, body donation is still at an all-time low, making the situation "back to square one. As far as the global scenario is concerned, most countries of Africa, North America, and Asia use cadaveric dissection as the primary modality of teaching gross anatomy. However, in European countries, cadaveric dissection is optional and not overwhelmingly used.[78] In India, the majority of the institute religiously follow cadaveric dissection, and slowly, there is changing trend to utilize other modalities in place of cadaveric dissection to teach anatomy[9] such as virtual dissection table, synthetic cadavers, high-fidelity simulation, three-dimensional (3D) anatomy education program, 3D-printing technology, and so on [Figure 1].Figure 1: Cadaveric dissection and other modalities of teachingVirtual dissection table simulation technology is utilized in virtual dissection table to offer realistic visualization of the 3D anatomical details of the virtual cadaver. Unlike real corpses, the students can "do-undo-redo" the dissection repeatedly on this virtual dissection table. Apart from virtual dissection, this software can also cater to the need for virtual 3D atlas and virtual simulators of different structures.[10] SYNTHETIC CADAVERS SynDavers are head-to-toe replicas of the human body consisting of skin with fat, ligaments, tendons, muscles, bones, etc., Their main content is water (85%); they provide a life-like experience of dissecting human cadavers. Although expensive, one of the most significant advantages is it can be used for repeated dissection. Still, the major drawbacks are students will not be able to remove the organs as they do on real cadavers. Another disadvantage is their careful storage to prevent the growth of bacteria and fungi.[11] THREE-DIMENSIONAL PRINTING 3D-printing technologies are another newer modality for making a 3D model of dissected specimens. 3D printing is a stirring application for creating models of organ or particular structure. One can develop models that students can explore to interact and learn. It can decrease the time spent planning and designing models.[12] IMMERSION/HAPTIC TECHNOLOGY Virtual reality and augmented reality technologies can create a unique scenario where learners get benefit from simulations generated by computers. The human-computer interface help in developing a virtual environment and students will experience the 3D architecture of the structure. This technology offers the varied experience of immersion, interactivity, and fidelity compared to others.[13] ANATOMY STUDIO Is a collaborative mixed reality dissection table approach in which a user can investigate a whole anatomical details of the body and perform manual 3D reconstructions virtually. Anatomy studio consists of a drafting table, while users are provided with head-mounted see-through displays and tablets with styli. With hand gestures and mobile touchscreens, the operator can decode cryosection or 2D contour to 3D reconstructed model.[14] THREE-DIMENSIONAL STEREOSCOPY Here, the depth of illusion is augmented using a stereoscope or binocular vision recent stereoscopes aid viewers in appreciating the 3D depth of 2D images. Stereoscopic 3D instructional videos can be accessed with smartphones hence can be well utilized to understand the 3D complexity of the anatomical structures. Studies have shown better test scores with stereoscopic 3D teaching for neuroanatomy.[15] However, recent literature suggests that cadaveric dissection remains the most persuasive means of delivering fundamental anatomical knowledge to medical students to develop clinical acumen for efficient clinical practice.[9] Holding the scalpel and giving an incision on the human body for the first time provides a thrilling experience for every medical student, so decreased use of cadavers or virtual dissectors can negatively influence the learner and ultimately lead to poor performance. Medical students are of the opinion that cadavers impart a real-time 3D perspective about human body complexities, which interactive multimedia can never substitute.[16] Hence, virtual modalities can only supplement the traditional pedagogy of human cadaveric dissection, but to think that 1 day it will substitute the latter is fictitious and deleterious for the entire medical fraternity. However, there appears a need to enhance or give different dimensions to traditional teaching concerning the requirement of current surgical practice, a few of which include. CADAVERIC WORKSHOP Cadaveric workshops using soft embalming have been used widely in western countries. They play a significant role where patient safety and prior experience cannot be controlled; hence, the main aim of the cadaveric workshop is to train future surgeons/residents before they operate on patients. This will overcome the limitations of limited exposure to patients and reduce untoward effects while performing on the patients.[17] LAPAROSCOPIC SURGERIES Although human anatomy remains the same, advanced technical operations demand simultaneous advancement in surgical management. In laparoscopic surgery, initial entry is often performed blindly, which may sometimes lead to vascular/organ damage. Hence, a laparoscopic surgeon's operative quality and technical competency begin with the optimal anatomical insight of the operative area and port/trocar placement. A significant challenge for an operating surgeon is visualizing the region by the small aperture of the anatomy through the small aperture in contrast to laparotomy, where the broad area is exposed, and visualization is better during initial entry.[18] Hence, there should be an adaptation to teach the internal anatomy, which will aid in better visualization in laparoscopic surgeries. ENDOSCOPIC TECHNOLOGY In this procedure, endoscopy is used to visualize the internal anatomy of the hollow organ/cavity of the body. Unlike many other medical imaging techniques, endoscopes are inserted directly into the organ.[19] Hence, there should be an option/exposure by which medical students can visualize the internal anatomy in a narrow view in addition to traditional dissection. Decreased teaching h and admittance to cadaveric dissection or prosection-based training in anatomical sciences education have prompted many specialist doctors revealing lacking anatomical knowledge of junior doctors. This pattern represents a critical gamble. Cadaveric-based instructing has for some time been its center and is perceived by medical students, instructors, and clinicians similarly as the most gainful approach to learning anatomical sciences. Cadaveric-based showing stays a foundation of most anatomical sciences curricula; notwithstanding, there has been a new pattern away from cadaveric dissection or prosection instructing and toward various models and technology-based anatomical learning devices. In a study conducted by Sheikh et al. in 2016, most of the surgeons, regardless of vocation stage accept that cadaveric-based anatomical sciences education is the best strategy for teaching and training anatomical sciences and that it ought to be improved in the medical teaching. Radiological imaging to be coordinated more into undergrad teaching and training. Thus, a sensitive equilibrium should be struck between fitting instructing approaches that guarantee medical students are good for practicing medicine.[20] The National Medical Commission of India may start working on preparing the guidelines or requirements to commence super specialty courses in anatomical sciences such as DM/MCh in neuroanatomy, developmental anatomy, structural anatomy, radiological anatomy, and surgical anatomy.
ER  -
TY  - JOUR
TI  - Artistic Exploration of Stop-Motion Animation in Virtual Reality: Spatializing the Analog Techniques of 2D Replacement and Object Animation by Using Digital Cutout and Realtime Rendering
PY  - 2023
T2  - 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)
DO  - 10.1109/vrw58643.2023.00009
UR  - https://doi.org/10.1109/vrw58643.2023.00009
DA  - 2023-03-01
AU  - Brückner, Franziska
C1  - Institute of Creative\Media/Technologies, St. P&#x00F6;lten University of Applied Sciences,St. P&#x00F6;lten,Austria,3100
AU  - Salhofer, Julian
C1  - Institute of Creative\Media/Technologies, St. P&#x00F6;lten University of Applied Sciences,St. P&#x00F6;lten,Austria,3100
AU  - Gürtler, Clemens
C1  - Institute of Creative\Media/Technologies, St. P&#x00F6;lten University of Applied Sciences,St. P&#x00F6;lten,Austria,3100
AU  - Hattler, Max
C1  - School of Creative Media, City University of Hong Kong,Kowloon Tong,Hong Kong
AU  - Husinsky, Matthias
C1  - Institute of Creative\Media/Technologies, St. P&#x00F6;lten University of Applied Sciences,St. P&#x00F6;lten,Austria,3100
LA  - en
KW  - Skeletal animation
SP  - 7
EP  - 12
ER  -
TY  - JOUR
TI  - Virtual Reality: The Next Frontier of Audiology
PY  - 2017
PB  - Lippincott Williams & Wilkins
SN  - 0745-7472
T2  - The Hearing Journal
DO  - 10.1097/01.hj.0000525521.39398.8f
UR  - https://doi.org/10.1097/01.hj.0000525521.39398.8f
DA  - 2017-09-01
AU  - Murphy, John
C1  - Mr. Murphy is a medical writer and editor in Philadelphia, PA.
LA  - en
KW  - Headset
KW  - Laptop
KW  - Avatar
VL  - 70
IS  - 9
SP  - 24,26,27
EP  - 24,26,27
ER  -
TY  - GEN
TI  - Proceedings of the 1st Symposium on Applied perception in graphics and visualization
PY  - 2004
DO  - 10.1145/1012551
UR  - https://doi.org/10.1145/1012551
DA  - 2004-08-07
LA  - en
KW  - Impromptu
KW  - Scrolling
ER  -
TY  - JOUR
TI  - Smart interfaces to assist the operator in the context of industry 4.0 with a 5S human-centric approach
PY  - 2024
PB  - Cambridge University Press
SN  - 2631-7176
T2  - Wearable Technologies
DO  - 10.1017/wtc.2024.17
UR  - https://doi.org/10.1017/wtc.2024.17
DA  - 2024-01-01
AU  - Rojas, Mario
C1  - Institute of Advanced Materials for Sustainable Manufacturing, Tecnologico de Monterrey, Monterrey 64849, Nuevo Leon, Mexico.
AU  - Maldonado-Romo, Javier
C1  - Institute of Advanced Materials for Sustainable Manufacturing, Tecnologico de Monterrey, Monterrey 64849, Nuevo Leon, Mexico.
AU  - Méndez, Juana
C1  - Institute of Advanced Materials for Sustainable Manufacturing, Tecnologico de Monterrey, Monterrey 64849, Nuevo Leon, Mexico.
AU  - Ponce, Pedro
C1  - Institute of Advanced Materials for Sustainable Manufacturing, Tecnologico de Monterrey, Monterrey 64849, Nuevo Leon, Mexico.
AU  - Molina, Arturo
C1  - Institute of Advanced Materials for Sustainable Manufacturing, Tecnologico de Monterrey, Monterrey 64849, Nuevo Leon, Mexico.
LA  - en
KW  - Industry 4.0
KW  - Transformative Learning
KW  - Adaptability
VL  - 5
AB  - Abstract This paper explores the integration of haptic gloves and virtual reality (VR) environments to enhance industrial training and operational efficiency within the framework of Industry 4.0 and Industry 5.0. It examines the alignment of these technologies with the Sustainable Development Goals (SDGs), mainly focusing on SDG 8 (Decent Work and Economic Growth) and SDG 9 (Industry, Innovation, and Infrastructure). By incorporating a human-centric approach, the study leverages haptic gloves to provide realistic feedback and immersive experiences in virtual training environments. The gloves enable intuitive interaction, enhancing the training efficacy and reducing real-world operational errors. Using the 5S principles—Social, Sustainable, Sensing, Smart, and Safe—this research evaluates the system’s impact across various dimensions. The findings indicate significant improvements in user comfort, productivity, and overall well-being, alongside enhanced sustainability and operational efficiency. However, challenges related to realistic hand-object interactions and algorithmic enhancements were identified. The study underscores the importance of continuous improvement and cross-disciplinary collaboration to advance the usability and effectiveness of these technologies. Future research should focus on customization, AI-driven adaptability, sustainability, real-world scalability, and comprehensive impact assessment to further develop smart interfaces in industrial settings. This integration represents a transformative opportunity to enhance workplace safety, skills development, and contribute to global sustainable development goals.
ER  -
TY  - JOUR
TI  - Virtual Reality Glove for Falconry
PY  - 2018
T2  - Qatar Foundation Annual Research Conference Proceedings Volume 2016 Issue 1
DO  - 10.5339/qfarc.2018.ictpd603
UR  - https://doi.org/10.5339/qfarc.2018.ictpd603
DA  - 2018-01-01
AU  - Al-Hathal, Turkea
C1  - Computer Engineering student at Qatar University
LA  - en
AB  - Falconry hunting is an Arabic traditional sport and has great significance in Qatari society, as it is a major part of their culture. Falconry is about hunting small birds or animals, by using different types of falcons. The falconry in virtual reality (VR) can preserve Qatari culture by making the sport easy to access for all stream of people. The main idea behind this project is to educate and experience real time falconry to the people living in Qatar and the visitors for 2022 football world cup. The proposed design in our project could also help the professional falconers to use and learn the VR technology that can make them a better handler. Moreover, The rapid development in technologies related to Virtual Reality has made imitation of real world in real time equally possible. The VR environment is possible to be integrated with software mediums such as Unity3D, but to realize the real time feel, weight, pressure, movement, and vibration of any kind in the VR is hard and still under process. There are also various new technologies in this field such as haptics, but these technologies are expensive and there is no definite hardware that actually mimics movement of the falcon when it stands on the hand The main hardware design is a glove that can be detected virtually and can detect movement of different types of falcon on the player's hand. The designs proposed in our project will have extensive real time feel of the falcon on the user's hand using various available hardware components, which are cheap and easy to maintain. The design of our gloves paves way to further enhancement of movement realization in VR for other form of sports, medicine etc., The major requirements for the game of falconry where obtained from Qatari Society of Al-Gannas with whom we have collaboration for this project.
ER  -
TY  - JOUR
TI  - The Effects of Whole-Hand Interactions with One Fingertip Vibrotactile Feedback on Cooperative VR Game Experience and Performance
PY  - 2023
PB  - The MIT Press
SN  - 1054-7460
T2  - PRESENCE Virtual and Augmented Reality
DO  - 10.1162/pres_a_00403
UR  - https://doi.org/10.1162/pres_a_00403
DA  - 2023-01-01
AU  - Moon, Hye
C1  - Virginia Tech, Blacksburg, VA, USA
AU  - Moon, Hayoun
C1  - Virginia Tech, Blacksburg, VA, USA
AU  - Orr, Grady
C1  - Virginia Tech, Blacksburg, VA, USA
AU  - Jeon, Myounghoon
C1  - Virginia Tech, Blacksburg, VA, USA
LA  - en
KW  - Headset
KW  - Modalities
VL  - 32
SP  - 99
EP  - 115
ER  -
TY  - JOUR
TI  - New medical technologies of the future
PY  - 2013
DO  - 10.1109/dt.2013.6566293
UR  - https://doi.org/10.1109/dt.2013.6566293
DA  - 2013-05-01
AU  - Graschew, Georgi
C1  - Exp. & Clinical Res. Center (ECRC), Univ. Med. Berlin, Berlin, Germany
AU  - Rakowsky, Stefan
C1  - Exp. & Clinical Res. Center (ECRC), Univ. Med. Berlin, Berlin, Germany
AU  - Roelofs, Theo
C1  - Exp. & Clinical Res. Center (ECRC), Univ. Med. Berlin, Berlin, Germany
AU  - Schlag, Peter
C1  - Exp. & Clinical Res. Center (ECRC), Univ. Med. Berlin, Berlin, Germany
LA  - en
KW  - eHealth
KW  - Videoconferencing
KW  - Collaborative software
SP  - 84
EP  - 89
ER  -
TY  - JOUR
TI  - Multimodal Ambivalence: A Manifesto for Producing in S@!#t Times
PY  - 2021
PB  - Wiley
SN  - 0002-7294
T2  - American Anthropologist
DO  - 10.1111/aman.13565
UR  - https://doi.org/10.1111/aman.13565
DA  - 2021-05-04
AU  - Astacio, Patricia
C1  - Brandeis University
AU  - Dattatreyan, Ethiraj
C1  - Goldsmiths, University of London
AU  - Shankar, Arjun
C1  - Georgetown University
LA  - en
KW  - Manifesto
KW  - Ambivalence
VL  - 123
IS  - 2
SP  - 420
EP  - 427
ER  -
TY  - JOUR
TI  - Editorial
PY  - 2001
PB  - ASM International
SN  - 1530-9827
T2  - Journal of Computing and Information Science in Engineering
DO  - 10.1115/1.1354993
UR  - https://doi.org/10.1115/1.1354993
DA  - 2001-03-01
AU  - Shah, Jami
LA  - en
VL  - 1
IS  - 1
SP  - 1
EP  - 2
ER  -
TY  - JOUR
TI  - The catheterization laboratory and interventional vascular suite of the future: Anticipating innovations in design and function
PY  - 2011
PB  - Wiley
SN  - 1522-1946
T2  - Catheterization and Cardiovascular Interventions
DO  - 10.1002/ccd.22872
UR  - https://doi.org/10.1002/ccd.22872
DA  - 2011-01-13
AU  - Klein, Lloyd
C1  - Department of Medicine, Rush Medical College, Chicago, Illinois
AU  - Miller, Donald
C1  - Department of Radiology, Naval Medical Center and F Edward Hebert School of Medicine, Uniformed Services University, Bethesda, Maryland
AU  - Goldstein, James
C1  - Department of Medicine, Beaumont Hospitals, Royal Oak, Michigan
AU  - Haines, David
C1  - Department of Medicine, Beaumont Hospitals, Royal Oak, Michigan
AU  - Balter, Stephen
C1  - Department of Medicine, Columbia University Medical Center, New York, New York
AU  - Fairobent, Lynne
C1  - American Association of Physicists in Medicine, College Park, Maryland
AU  - Norbash, Alexander
C1  - Department of Radiology, Boston University School of Medicine, Boston, Massachusetts
LA  - en
KW  - Blueprint
KW  - Cardiac catheterization
VL  - 77
IS  - 3
SP  - 447
EP  - 455
AB  - Any attempt to forecast the function and design of the interventional catheterization laboratory and vascular suite presumes that current trends are an accurate window into the future. This must be recognized as a fallacious assumption; indeed, it can be quite amusing years later to review predictions of the future based on then-current proclivities. In fact, cardiovascular practice over the past 25 years suggests that one cannot predict accurately which innovations will succeed and which will fail based either on theoretical considerations or on initial clinical experience. Moreover, the "future" is a nebulous time and place; certainly, it anticipates progress that renders obsolete the current state of the art laboratory. It may be most practical to characterize the "medium" future, perhaps 5–10 years, rather than the "longer term" future, which grows increasingly indistinct. By beginning with certain economic and scientific realities, it may be possible to generate reasonable, educated guesses regarding the design and use of the catheterization laboratory and interventional vascular suite of the future. Despite these inherent pitfalls, the MultiSpecialty Occupational Health Group (MSOHG), a committee composed of practicing physicians representing all of the major cardiac, radiologic, and electrophysiological societies, has prepared this study and is making this document public for two reasons. First, in an effort to represent the needs of each society's members in influencing industry to improve and alter current laboratory designs [1], the committee determined that an attempt to develop a blueprint of the possible future laboratory would assist in such discussions. Second, MSOHG seeks to reach out beyond medical personnel to engineering and industrial interests in an effort to inspire thought, and perhaps invention, to bring a positive future much closer. By gathering together our current thoughts regarding trajectory, the consequent stimulus may lead to even better ideas than those currently conceived. MSOHG believes that a shared vision of the future could synchronize perspectives, whether optimistic or simply pragmatic, and could also encourage a sense of excitement where the potential for positive developments is concerned. The collaborative energy generated from such a dialogue can align physicians, paramedical personnel, and manufacturers in raising their expectations for the future and to actively participate in innovation, development, and positive change, rather than leaving all such constituents to passively react to their environment and wait for others to construct the pathway to an indistinct and nebulous future. Considering a shared vision may result in an energized sense of optimism and proactivity, which could help us move faster and farther than otherwise possible. An intentional conversation regarding the future may cultivate reasonable imagination rather than breed acceptance of relative technological stasis. We therefore consider a proactive open dialogue regarding the future as a constructive, and hopefully catalytic, effort. Naturally, the precepts on which one builds a conception of the future should be coherent and realistic, or the consequent predictions will be flawed. Although inevitably predictions are bright with the vision of limitless innovation and industry, and an ideal economic climate, reality typically is less utopian. A more balanced view, grounded in realistic prospects recognizing that tomorrow's opportunities are today's problems, is therefore more apt to lead to an accurate forecast. In this regard, the committee selected several observations as plausible starting points. Economics will play an ever-increasing role in the speed and nature of which emerging technologies ultimately are incorporated into clinical use. The pressure on physicians and the healthcare delivery system for economic responsibility is only gaining momentum. Few areas of the hospital have seen technology evolve as rapidly as the catheterization laboratory, and new imaging and diagnostic adjuncts have the potential to dramatically impact the financial landscape of profitability. Economic and technical dependencies will determine which of today's brainstorms will become tomorrow's standard therapy. Hence, it is mandatory that expenditures for new technology are justified by proven benefit and clinical importance, and that cost expenditures are minimized to sustain profits. Cardiovascular programs increasingly rely on diagnostic and therapeutic procedures, particularly the ones performed in the interventional laboratory, to maintain a large revenue stream, which frequently is expected to be sufficient to offset other revenue deficient areas and services. Despite all of the predictions and efforts to stabilize and even reduce the costs of medical testing and treatment over the past 25 years [2], total expenditures continued to rise at a dizzying pace. This is not a sustainable trend. Therefore, new techniques cannot be conceived as "add-ons" to the cost burden, but must be proposed as replacements or alternatives for already existing diagnostic and therapeutic procedures. Competition between hospitals and institutions for the latest technique or equipment, particularly in densely populated urban markets, is a significant cause of accelerated implementation of technology. The medical institution or practice that gains local prestige for pioneering the latest technique is widely perceived to gain a substantial marketing advantage, even if the actual benefit in terms of outcomes and healthcare delivery is marginally, or only fleetingly, realized. Further, the pressure to spend large sums of money to acquire the technique spurs high costs and reduces the profit margin, particularly in an era of diminishing clinical reimbursement. The most likely sustainable trends in coronary heart disease include: (1) increased technology utilization with more frequent noninvasive imaging technology utilization as well as invasive direct vascular imaging tools, (2) shifted case mix with fewer diagnostic catheterizations other than those likely to lead to coronary interventions and fewer acute interventions, and more elective interventions, as a consequences of increased screening and improved medical therapy, (3) earlier diagnosis and improved pathophysiologic understanding such as diagnosing vulnerable plaque before presentation as an acute coronary syndrome with newer diagnostic information integrated into the traditional angiogram in borderline and equivocal cases, and (4) novel technical developments such as more combined or hybrid procedures. Improvements in catheter-based therapies could be expected to lead to increased caseloads, but these improvements may be offset in the longer term future by the development of better medical therapies and preventive agents. Structural heart disease will almost certainly become a larger percentage of catheter-based treatment. Valvular heart disease treatment is likely to undergo dramatic changes as aortic and mitral valve replacement will increasingly be catheterization based. Closure of patent foramen ovale and atrial septal defect, already a part of the interventional laboratory armamentarium, will probably become more frequently performed with earlier diagnosis. Shifting expenditures, resources, and manpower from traditional surgical operations to catheter-based procedures is a critical trend for the future. Vascular medicine has evolved to a crossover specialty connecting interventional radiology, cardiovascular medicine, and cardiovascular surgery; with further improvements, these procedures will be performed more frequently and will involve more complex cases. A team approach, involving specialists working together rather than in competition, is most likely to lead to better outcomes for patients. At many sites, increasing peripheral vascular volume currently outpaces growth in coronary procedures, and this case mix evolution will continue and directly affect the design of tomorrow's catheterization laboratory. Treatment of abdominal aortic aneurysms and other diagnoses traditionally within the surgical realm will increasingly be performed percutaneously, and hybrid laboratories designed for these procedures may well incorporate multiple imaging or robotic modalities. Similarly, carotid disease and stroke treatment will be treated by a wider variety of practitioners in an ever-increasing number of centers. Electrophysiologic techniques have become more complex, and there are significant technical aspects to placement of newer pacemakers and AICDs that mandate high image quality. Cardiologists performing electrophysiology studies no longer work in archaic catheterization laboratories or with inadequate fluoroscopic C-arms. Electrophysiologists with new, sophisticated catheterization and ablation techniques rely on visualization of fine details of cardiac structure and require high-quality fluoroscopy. The electrophysiologic laboratory will most likely develop broadly applied complex three-dimensional spatial electrophysiologic mapping and visualization tools. Most importantly, case volume may be anticipated to skyrocket as electromechanical devices are introduced both to prevent stroke in atrial fibrillation [3] and for the treatment of congestive heart failure. Over the past 3 decades, innovations in biomedical technology have facilitated progressively more minimally invasive therapeutic procedures, and percutaneous vascular interventions are one profound example of this revolution. Although 30 years ago, 8–10 French guides were used to perform simple balloon angioplasty, the evolution of technology now facilitates delivery of sophisticated drug-eluting stent systems using miniaturized (most recently 3 French!) systems [4]. Although at the current time it has not been demonstrated that smaller catheter sizes will provide a technical advantage, future improvements may be anticipated. These improvements in equipment and technique have resulted in routinely high procedural success and are safer and more effective for patients while also rendering the procedure itself technically easier and quicker for the operator. What will the "state-of-the-art" look like in the future? Developments in robotic catheter manipulation guided by ever more sophisticated indirect and direct imaging systems give promise of a future of greater miniaturization and precision. Therapeutic devices promise to make present interventions even more efficacious: bioabsorbable stents and innovative drug delivery platforms are already being tested [5], and stents based on a guide wire platform may be in our armamentarium [6]. Catheter-based valve replacement and repair are already in intensive clinical trials and will undoubtedly become standard therapeutic techniques. For all such applications, percutaneous miniaturization can be anticipated. One may foresee an era of access sites the size of small wires with guidance performed based on imaging from miniature devices controlled remotely by computer-based navigation and manipulation systems. As a result of technology and reimbursement trends, the primary focus in the interventional laboratory of the future will be the integration of imaging modalities in a seamless manner in which the information gained by one technique enhances and is incorporated in an additive manner to the information acquired by other techniques. The composition of the plaque, the presence of vulnerable plaque, its three-dimensional geometric character, its physiologic consequence, and the simulated effect of the planned therapy will all be considered in the context of natural history and procedural morbidity, contributing to therapeutic decision making. There are currently multiple modalities that permit assessment and visualization of blood vessels and vascular structures, each interpreted independently of the others; the opportunity to fuse these data sets to interact with all the necessary information to provide an optimized pre-or intraprocedural perspective is the future of integrated imaging. Currently, imaging workstations include cumbersome packages that attempt to facilitate such multimodality fusion [7]. Similarly, importing physiological information such as blood flow, electrical activity, or metabolic and cellular imaging could dramatically enhance and expand intraprocedural therapeutic latitude, specificity, scope, and scale. As a representative example, importing functional MRI information into a neuroembolization procedure would be beneficial to determine that a particular branch being embolized will not result in injury to the eloquent cortex. The standard coronary or vascular angiogram, a silhouette X-ray image of the lumen of the vessel created with contrast media, will continue to play a central role for the medium-term future. However, advanced digital imaging and detailed three-dimensional reconstructions will enable more accurate diagnosis and effective treatment. Very likely, integration of CT and MRI data into vascular reconstructions based on angiographic techniques will result in a new fused "standard" imaging modality. These advanced and integrated analyses will be available online with immediate postacquisition processing to allow for reproducible decision pathways in real time. Angiographically equivocal lesions will be routinely evaluated in the laboratory using fractional flow reserve or intravascular ultrasound, and potential clinical decisions evaluated real time using validated predictions of procedural and clinical outcomes. As simulation technology is advanced and incorporated into the teaching process, one possible outcome may be increased utilization of virtual interfaces with haptic feedback [8]. To call such systems "robotic" is an over-simplification, although current, initial implementation versions of robotic angiography exist where the operator is separated from the procedural bedside in order to protect the operator from the radiation environment [9]. The possibility of transforming virtual reality into procedural reality is just one aspect of a general movement away from the direct and inconsistent manual twisting, pushing, and pulling of catheters and wires as operators move toward interacting with graphic user interfaces connected to electromechanical intermediaries. These techniques will ultimately result in the use of intelligent navigation, perhaps by pointing and clicking on an image of an artery as physician–operators "supervise" the semiautomated process and watch the catheter and wire automatically engage and enter the selected vessel. The technique may well incorporate MEMS technologies with microfabrication and piggybacking of various ablative and in vitro diagnostic tools on a multicapable catheter package. Additional benefits of this technology will be the development of simulations built on graphic user interfaces as a practical training tool and testing instrument [10]. By developing simulations of "nightmare" scenarios, future physicians will learn how best to respond before actually encountering critical situations in "real-life" patients. Techniques to analyze the wall and physiology of the vessel rather than just the lumen are currently in development and will be critically important. The components will include an assessment of arterial remodeling, plaque composition, and lesion morphology. These characteristics may determine which therapies are most likely to be successful [11, 12]. Specifically, intraplaque hemorrhage, vulnerable or free lipid-pool components, ulcerations, and other morphologies likely to lead to accelerated plaque progression and impending vascular compromise in asymptomatic patients will be more fully and routinely characterized [13]. Intravascular tools such as ultrasound, dual photon spectroscopy, near-infrared spectroscopy, and optical coherence tomography undoubtedly will gain even further in utility, and defining fractional flow reserve in borderline lesions will become standard [14-17]. Molecular imaging is also on the horizon [18], promising insights into pathophysiologic processes that may be clinically important (e.g., plaque inflammation and its implications for plaque vulnerability). Furthermore, these imaging modalities are now being developed as single multimodality catheters that promise to provide these important data efficiently. Given the wealth of data provided by such direct vascular imaging systems, and the undesirable effects of radiation and contrast dye, it may be foreseen that in the future patients might undergo the bulk of imaging by direct techniques. For example, a patient undergoing coronary intervention might have a single injection each of the left and right coronary arteries to serve as a "roadmap," with the remainder of the diagnostic and therapeutic aspects of the procedure facilitated by direct imaging using a multimodality catheter. This approach would minimize radiation to patient and operators, minimize contrast dye burden, and provide more information on the vessel wall pathology. Integration of different imaging modalities (fluoroscopy, ultrasound, CT, and MRI) has already been implemented in limited ways in the interventional laboratory. Multimodality-guided treatment of tumors has proven to be more effective than treatment guided only by fluoroscopy and will probably become the norm for many interventional oncology therapies [19, 20]. Not only will the capability to perform these procedures be present in all laboratories, but the findings will also be integrated in real time. A comprehensive psychological and cognitive understanding of how operators process information has not yet developed into a refined field, but advances in this area will be required to produce the next generation of imaging. The rapid assimilation of morphologic and physiological information will be required to compose a coherent understanding of how the interventionist can best interact with a particular patient. As an example, a neurointerventionalist may be interested in information displayed simultaneously on eight monitors suspended from the ceiling: lateral and frontal reference angiograms, lateral and frontal live fluoroscopy, lateral and frontal road maps, a hemodynamic monitor, and a three-dimensional image of the vasculature tree or structure. This is too much information displayed across too much spatial real estate to access by turning one's head to survey a wide geographic span of monitor screens. A better way of integrating this information into a single set of images that can be viewed interactively is needed. A similar evolution in the psychological ergonomics of multiple visual information streams has led to dramatic advances in information visualization and processing in such environments as jet-fighter cockpits. This discipline of ergonomic multistream visualization could be described as "psychovisualization" or an understanding of the needs of the operator for processing multiple converging streams of information to optimally "visualize" the therapeutic intentions and target while performing a complex procedure. Industry will be asked to find ways to implement these technologies in the interventional laboratory, to aid the interventionalist in integrating visual and other data from multiple sources. Archival solutions must also be easily available and transferable to other laboratories and environments when consultation and long- or short-distance partnering is sought. It is easy to imagine geographically dispersed individuals serving simultaneously in a consulting capacity during a procedure, participating through virtual environments. The challenge of providing up-to-date medical care in rural communities might be addressed with such techniques. However, the demand for on-site responsibility is unlikely to permit large-scale fully centralized telesurgery or teleprocedures. Digital imaging is the cornerstone of today's catheterization laboratory and will continue to be the basis of future developments. The technical advances of the last few years, especially flat-panel digital detector imaging systems [21], have made it possible to build functional, high-quality combination coronary and peripheral interventional rooms. The essential ingredients for a multipurpose system that supports both vascular and other interventions are already features of modern laboratories, including a wide field of view, digital subtraction, three-dimensional angiography, road mapping features, and even multimodality fusion. Digital imaging improves image quality and not only enables catheterization laboratories to produce high-quality postprocessed images but also facilitates integration of other imaging modalities. Digital archiving, monitoring, and reporting systems markedly decrease wasted physician time by storing images and information instantly and providing immediate access to patient information. The key to advancement rests in enhancing the digital environment to measure and demonstrably improve patient care and workflow. The drive to create this new environment will, of necessity, affect the equipment architecture and manpower models the laboratory uses. Each hospital needs a comprehensive understanding of the expected procedures and volumes it performs with trending and quality measures. This information will impact the selection of the equipment and workflow that best supports these efforts, as framed by the institution's strategic and investment plans. For example, anticipated growth in peripheral vascular and structural cardiac procedures will guide decisions about which X-ray systems, adjunctive robotic systems, and visualization tools best meet the hospital's needs. Further advancements in digital imaging will bring improvements in both image quality and workflow. Integrated systems to support digital workflow, such as structured reporting tools and electronic image and report distribution systems, will define the manpower needs of the next-generation interventional laboratory. Information technology (IT) services involvement in the daily activities of the laboratory will become a critical component of staffing. Centralization of such services in the laboratory will be necessary, including dedicated IT staff to facilitate implementation, maintenance, and integration of functionality and ever-changing applications with archival, hemodynamic monitoring, and hospital information systems. Significant effort will be required to manage the obsolescence of provincial RIS, HIS, IT, and PACS hardware; retirement and archival of these functions will necessitate intensive IT involvement, as they are replaced by universalized medical application sets with robust interoperability and rapidly updated application changes. Such evolution implies that updates are progressively thinner with concentration on applications, and the dependent hardware is progressively outsourced with very different capitalization and rental models from current systems. Procedural data will be immediately sent electronically to insurance companies, Medicare, and specialty quality assurance programs with rapidly expanding quality assurance initiatives and integrated and dependent reimbursement. Incorporating such disparate needs as hemodynamic monitoring, billing, hospital information, and archival will require a much greater and more rapid level of integration and development of IT to achieve the necessary efficiencies. Demographic data will be entered just once; in addition, all images will be retrievable on hospital and network office computers and system PDA's for immediate review. By avoiding errors associated with manual data entry, billing and archiving will be simplified. Efficiency is improved as information resides in one integrated database instead of several disparate locations. This will also make it possible to rapidly retrieve data and images from examinations performed at other hospitals and institutions. Patient satisfaction will increase as there will no longer be a need to answer the same questions multiple times as the patient progresses from admitting, through the procedure, to recovery. Similarly, practitioners will be automatically identified by systems analogous to radiofrequency identification tags, and elements as disparate as their exposure information and practice connectivity will be automated and integrated. As noted, one anticipated central trend is that increasing numbers of patients and procedures traditionally treated with open surgical procedures will instead be treated with minimally invasive approaches in the catheterization laboratory in increasingly sterile environments. Such "laboratories" will likely become more similar to surgical/operating rooms in terms of infrastructure, demanding scrub-only access and including multiple air turnovers similar to open surgical rooms. These needs will be as important as the need for enhanced imaging and diagnosis. In contradistinction, increased outpatient utilization and throughput will be a direct result of more frequent and accurate screening and will increase the need for greater safety, sterility, and procedural consistency. Likely, these trends may well result in two different interventional laboratory types. One, the diagnostic/traditional interventional type room, will be much like today's laboratory but with greater diagnostic capability. Possibly, these will be designed with a view to greater patient comfort, perhaps with soothing and calming decorations and lighting conducive to an awake, alert patient akin to a contemporary birthing room. Potentially, such awake-patient rooms may include distracting electronic or multimodality features to fully relax and distract the patient with visual or acoustic enhancements. The second type of laboratory may be an alternative surgical suite with fluoroscopy integrated with other large and complex imaging modalities and will be used for sterile procedures that are extensive and more complex. Currently, many institutions are working on ambitious projects and imaginatively configuring "operating rooms of the future," which incorporate a variety of imaging tools, including but not limited to CT, MRI, and PET [22]. As the advantages and drawbacks of incorporating such a variety of imaging equipment are better understood, the pragmatic pairing of selected large imaging tools will be beneficial in the percutaneous, minimally invasive environment. If emergency open surgery is required, these alternative surgical suites will already be equipped and staffed appropriately without needing to move the patient. These alternative surgical suites may be fully perfusion cardiopulmonary bypass capable or configured and optimized for other procedures with an endovascular component such as craniotomies for aneurysm or arteriovenous malformations and will be equipped to meet the necessary open-surgical specifications, such as frequent air exchanges [23]. Rooms of this type are ideally equipped for percutaneous valve procedures, septal occluder placement, and aortic stent graft placement. They are also capable of immediate intra- or post-CABG angiography. These laboratory designs are intended to enhance patient satisfaction, further increasing their competitive advantage and enhancing perceived customer value. Of course, proper utilization would require a change in medical culture, requiring a more complete team approach in which surgeons, cardiologists, and radiologists coordinate their schedules and collaborate in a truly integrated manner. More than merely a cultural shift, it reflects the reality of the fields and interests merging, and traditional distinctions between the various specialties blurring. The cost of such laboratories will likely be significantly higher than current laboratories, as they will be equipped and stocked with novel devices and equipment that is traditionally contained in several separate rooms. Space considerations will be critical, as these laboratories will need to be larger. Storage issues will become more significant. This additional cost will not be transferable to the consumer, or third-party payors, as easily as in the past 2 decades. Scientific evidence will be required to show that the increased expense is justified by improved patient outcomes; moreover, various medical societies will have to work together on behalf of patients to convince the federal government and insurance companies that this is money well spent. Recognition that the "enemy" is not each other but those political forces less interested in providing optimal care than in cutting medical expenditures will have to be the rallying point for organizations of physicians who have not traditionally been politically savvy or economically astute. Radiation shielding design will have to be completely reconsidered, and new approaches developed [24]. Societal expectations include worker safety as well as patient safety. The current paradigm of physicians and staff wearing ergonomically inefficient lead makes their musculoskeletal systems and spinal axes vulnerable to injury, leading to occupational hazards (including time inefficiencies and even early curtailment of careers due to spinal disabilities). This is not an economically feasible employment strategy in a future where even more highly trained operators and technicians are required and difficult to replace. Advances in minimizing the risks of nephrotoxicity, transdermal injury, and infectious transmission to healthcare workers and patients in the endovascular environment will affect the design of such suites. Radiation dosage to operators will be reduced by selecting gantry angles and frame rates that decrease scatter, and shielding will likely be supported by alternative suspension systems. Low-dose fluoroscopy will often be recorded instead of high-dose digital cine runs (fluoroscopy loops), and it is likely that nonionizing imaging techniques will be used to coregister images and to perform desired complementary imaging. As an example, it may not be necessary to use continuous fluoroscopy if a three-dimensional angiogram is stored. Navigation of the vascular tree can be performed through coregistered endovascular ultrasound or radiofrequency tool localization if the necessary coregistration technologies are incorporated in the catheter and wire. Patient radiation dose is already becoming a critical issue as more and more radiologic procedures with high exposures are performed [25]. It is ironic that in spite of advances in multiple technologies in various areas of nonionizing imaging, ionizing radiation is still the core of sophisticated interventional work. Clearly, as multimodal therapies develop and gain increased utilization and as intermittent coregistration with nonionizing or stereotactic methods become a possibility, better understanding will emerge how patients and healthcare workers can be protected from the side effects of visualization and therapeutic technologies. Early work with MR guidance for interventions can be expected to advance. Interventional MRI will prove useful for many procedures and patients. Most interventional laboratories and their physicians currently operate in isolation. Aggregation of information systems and the mandatory consolidation of information into national databases will provide a number of advantages. Quality assurance will demand benchmarking on a national scale. This will be possible with refined IT backbones. It must be accompanied by a clear understanding of how pooled learning and communication should be structured pragmatically. This is a necessary ingredient in the development of comparative effectiveness pathways, and robust, societal-driven outcomes analysis. The National Cardiovascular Data Registry and Society of Thoracic Surgery have pioneered the development of clinical and procedural databases; currently, participation is voluntary in most states. In the future, both government and private insurance will require all laboratories to submit procedural data for quality and outcomes analysis. Reimbursement level may be set accordingly. A mandatory response to suboptimal results will ensure better patient outcomes and appropriate case selection and will be part of dynamic and real-time public reporting. Questions abound regarding the value proposition for many of the procedures that are performed, as physicians explore which metrics need to be used to define quality and to develop accurate appropriateness criteria [26]. In anticipating how the next generation interventional laboratory will function and look, the context within the larger trends facing medicine generally is crucial. Outside agencies will continue to seek to reduce medical expenditures, at times below that requisite to maintain optimal medical care. The best defense against draconian and inappropriate cost cutting is to define what constitutes high quality. It cannot be over emphasized that those who decide what quality is will control the future of medicine. Physicians have in their hands the antidote to the bean counter: the procedural and clinical outcomes of their patients. We cannot allow the next generation to suffer from our inability to collaborate with one another. Only by working together to produce national databases, develop benchmarks, determine the outcome measures of real importance, and create consensus on appropriate utilization of resources, can we control our destiny and the provision of medical care. Therefore, the directors and administrators of the interventional laboratory of the future and its programs must be enthusiastic and fully capable of participating in quality improvement, both locally and nationally. Inventory management is yet another challenge for the multifunctional interventional laboratory of the future. As the laboratory procedure list expands to the full range of peripheral vascular, cardiac structural, complex coronary, interventional neurosurgery, interventional radiology, and interventional oncology cases, the inventory required becomes progressively more costly and requires more storage space. Storage that is bar coded or radiofrequency identification tagged and within easy reach is neither simple nor inexpensive. The laboratory manager and administration will be confronted with conflicting tasks, as the pressures to limit costs increase simultaneously with the need for competitive investments. Well-organized storage space and a sophisticated system for inventory management are necessary to locate equipment when needed and to minimize expiration date-related inventory losses. An integrated inventory management, billing and scheduling system is not only a fundamental operational requirement but may become the central requirement to minimize costs in the efficiency-maximized laboratory of tomorrow. As the laboratory must be prepared to perform many more procedures, its investment in inventory will be substantial. At a time of diminishing reimbursement, it is difficult to conceive how an institution can afford to sink significant capital into equipment with limited shelf life. Flexible purchasing arrangements with industry, including contingency, will be necessary to prevent the expiration of infrequently used disposables from becoming a substantial cost. Several techniques have been proposed to manipulate catheter movement using magnetic or electromagnetic guidance. These capabilities promise to enhance patient safety through improved control, precision and reduced procedure time and improve operator safety by diminishing X-ray exposure. Magnetic systems appear to offer safe and effective navigation but are limited by requiring significant space around the patient, limiting direct access. Moreover, they require substantial additional shielding and specifically designed catheters with a magnet near their tip. Electromechanical guidance is a simpler design, using cables within the catheter to manage tip deflection and position. Such systems promise rapid and direct hand control [27]. A transition to three-dimensional imaging would be a key enabling step in the use of robotic systems [28]. The development of patient-specific organ models may be the first step in the process [29]. However, the incremental costs of development and changes to the procedure room must be justified with significantly better clinical outcomes, and this will be a substantial barrier to their introduction and clinical acceptance. One prediction about the interventional laboratory of the future that is certain is that neither its function nor its design will remain what it is today. Improvements and innovations produced by industry and pioneered by physicians will be stimulated by the needs of our patients. The efficiency and speed of our response will be determined by how well we cooperate in moving forward and how creatively we imagine and construct the future. Have we fully engaged the opportunities for novel growth where our technologies are concerned? Have we forcefully and expediently affirmed or refuted the value of such novel tools and technologies as MRI-based catheter interventions, robotic catheterizations, and evidence-based universal order-entry systems? Certainly, the future will be dynamic, exciting, and multifarious. With the charge for transparency, quality, and safety which faces all of medicine, considerable and necessarily revolutionary change in the future of minimally invasive catheter-based therapies is inevitable. If the thoughtful and methodical quest for improved patient care is accompanied by a quest to create a safe environment for practitioners, then the future indeed is promising. This will require teams of physicians, scientists, regulators, and manufacturers working together with the best interests of patients and staff in mind.
ER  -
TY  - JOUR
TI  - Mechanisms of Augmentation in Proprioceptive Media Art
PY  - 2013
PB  - Queensland University of Technology
SN  - 1441-2616
T2  - M/C Journal
DO  - 10.5204/mcj.744
UR  - https://doi.org/10.5204/mcj.744
DA  - 2013-11-07
AU  - Fedorova, Ksenia
C1  - university of california, davis
LA  - en
KW  - Proprioception
KW  - Representation
KW  - Phenomenon
VL  - 16
IS  - 6
AB  - Introduction In this article, I explore the phenomenon of augmentation by questioning its representational nature and analyzing aesthetic modes of our interrelationship with the environment. How can senses be augmented and how do they serve as mechanisms of enhancing the feeling of presence? Media art practices offer particularly valuable scenarios of activating such mechanisms, as the employment of digital technology allows them to operate on a more subtle level of perception. Given that these practices are continuously evolving, this analysis cannot claim to be a comprehensive one, but rather aims to introduce aspects of the specific relations between augmentation, sense of proprioception, technology, and art. Proprioception is one of the least detectable and trackable human senses because it involves our intuitive sense of positionality, which suggests a subtle equilibrium between a center (our individual bodies) and the periphery (our immediate environments). Yet, as any sense, proprioception implies a communicational chain, a network of signals traveling and exchanging information within the body-mind complex. The technological augmentation of this dynamic process produces an interference in our understanding of the structure and elements, the information sent/received. One way to understand the operations of the senses is to think about them as images that the mind creates for itself. Artistic intervention (usually) builds upon exactly this logic: representation of images generated in mind, supplementing or even supplanting the existing collection of inner images with new, created ones. Yet, in case of proprioception the only means to interfere with and augment these inner images is on bodily level. Hence, the question of communication through images (or representations) should be extended towards a more complex theory of embodied perception. Drawing on phenomenology, cognitive science, and techno-cultural studies, I focus on the potential of biofeedback technologies to challenge and transform our self-perception by conditioning new pathways of apprehension (sometimes by creating mechanisms of direct stimulation of neural activity). I am particularly interested in how the awareness of the self (grounded in the felt relationality of our body parts) is most significantly activated at the moments of disturbance of balance, in situations of perplexity and disorientation. Projects by Marco Donnarumma, Sean Montgomery, and other artists working with biofeedback aesthetically validate and instantiate current research about neuro-plasticity, with technologically mediated sensory augmentation as one catalyst of this process. Augmentation as Representation: Proprioception and Proprioceptive Media Representation has been one of the key ways to comprehend reality. But representation also constitutes a spatial relation of distancing and separation: the spectator encounters an object placed in front of him, external to him. Thus, representation is associated more with an analytical, rather than synthetic, methodology because it implies detachment and division into parts. Both methods involve relation, yet in the case of representation there is a more distinct element of distance between the representing subject and represented object. Representation is always a form of augmentation: it extends our abilities to see the "other", otherwise invisible sides and qualities of the objects of reality. Representation is key to both science and art, yet in case of the latter, what is represented is not a (claimed) "objective" scheme of reality, but rather images of the imaginary, inner reality (even figurative painting always presents a particular optical and psychological perspective, to say nothing about forms of abstract art). There are certain kinds of art (visual arts, music, dance, etc.) that deal with different senses and thus, build their specific representational structures. Proprioception is one of the senses that occupies relatively marginal position in artistic production (which is exactly because of the specificity of its representational nature and because it does not create a sense of an external object. The term "proprioception" comes from Latin propius, or "one's own", "individual", and capio, cepi – "to receive", "to perceive". It implies a sense of one's self felt as a relational unity of parts of the body most vividly discovered in movement and in effort employed in it. The loss of proprioception usually means loss of bodily orientation and a feeling of one's body (Sacks 43-54). On the other hand, in case of additional stimulation and training of this sense (not only via classical cyber-devices, like cyber-helmets, gloves, etc. that set a different optics, but also techniques of different kinds of altered states of mind, e.g. through psychotropics, but also through architecture of virtual space and acoustics) a sense of disorientation that appears at first changes towards some analogue of reactions of enthusiasm, excitement discovery, and emotion of approaching new horizons. What changes is not only perception of external reality, but a sense of one's self: the self is felt as fluid, flexible, with penetrable borders. Proprioception implies initial co-existence of the inner and outer space on the basis of originary difference and individuality/specificity of the occupied position. Yet, because they are related, the "external" and "other" already feels as "one's own", and this is exactly what causes the sense of presence. Among the many possible connections that the body, in its sense of proprioception, is always already ready for, only a certain amount gets activated. The result of proprioception is a special kind of meta-stable internal image. This image may not coincide with the optical, auditory, or haptic image. According to Brian Massumi, proprioception translates the exertions and ease of the body's encounters with objects into a muscular memory of relationality. This is the cumulative memory of skill, habit, posture. At the same time as proprioception folds tactility in, it draws out the subject's reactions to the qualities of the objects it perceives through all five senses, bringing them into the motor realm of externalizable response. (59) This internal image is not mediated by anything, though it depends directly on the relations between the parts. It cannot be grasped because it is by definition fluid and dynamic. The position in one point is replaced here by a position-in-movement (point-in-movement). "Movement is not indexed by position. Rather, the position is born in movement, from the relation of movement towards itself" (Massumi 179). Philosopher of "extended mind" Andy Clark notes that we should distinguish between a real body schema (non-conscious configuration) and a body image (conscious construct) (Clark). It is the former that is important to understand, and yet is the most challenging. Due to its fluidity and self-referentiality, proprioception is not presentable to consciousness (the unstable internal image that it creates resides in consciousness but cannot be grasped and thus re-presented). A feeling/sense, it is not bound by sensible forms that would serve as means of objectification and externalization. As Barbara Montero observes, while the objects of vision and hearing, i.e. the most popular senses involved in the arts, are beyond one's body, sense of proprioception relates directly to the bodily sensation, it does not represent any external objects, but the sensory itself (231). These characteristics of proprioception help to reframe the question of augmentation as mediation: in the case of proprioception, the medium of sensation is the very relational structure of the body itself, irrespective of the "exteroceptive" (tactile) or "interoceptive" (visceral) dimensions of sensibility. The body is understood, then, as the "body without image,” and its proprioceptive effect can then be described as "the sensibility proper to the muscles and ligaments" (Massumi 58). Proprioception in (Media) Art One of the most convincing ways of externalization and (re)presentation of the data of proprioception is through re-production of its structure and its artificial enhancement with the help of technology. This can be achieved in at least two ways: by setting up situations and environments that emphasize self-perspective and awareness of perception, and by presenting measurements of bio-data and inviting into dialogue with them. The first strategy may be connected to disorientation and shifted perspective that are created in immersive virtual environments that make the role of otherwise un-trackable, fluid sense of proprioception actually felt and cognized. These effects are closely related to the nuances of perception of space, for instance, to spatial illusion. Practice of spatial illusion in the arts traces its history as far back as Roman frescos, trompe l’oeil, as well as phantasmagorias, like magic lantern. Geometrically, the system of the 360º image is still the most effective in producing a sense of full immersion—either in spaces from panoramas, Stereopticon, Cinéorama to CAVE (Computer Augmented Virtual Environments), or in devices for an individual spectator’s usage, like a stereoscope, Sensorama and more recent Head Mounted Displays (HMD). All these devices provide a sense of hermetic enclosure and bodily engagement with its scenes (realistic or often fantastical). Their images are frameless and thus immeasurable (lack of the sense of proportion provokes feeling of disorientation), image apparatus and the image itself converge here into an almost inseparable total unity: field of vision is filled, and the medium becomes invisible (Grau 198-202; 248-255). Yet, the constructed image is even more frameless and more peculiarly ‘mental’ in environments created on the basis of objectless or "immaterial" media, like light or sound; or in installations prioritizing haptic sensation and in responsive architectures, i.e. environments that transform physically in reaction to their inhabitants. The examples may include works by Olafur Eliasson that are centered around the issues of conscious perception and employ various optical and other apparata (mirrors, curved surfaces, coloured glass, water systems) to shift the habitual perspective and make one conscious of the subtle changes in the environment depending on one's position in space (there have been instances of spectators in Eliasson's installations falling down after trying to lean against an apparent wall that turned out to be a mere optical construct.). Figure 1: Olafur Eliasson, Take Your Time, 2008. © Olafur Eliasson Studio. In his classic H2OExpo project for Delta Expo in 1997, the Dutch architect Lars Spuybroek experimented with the perception of instability. There is no horizontal surface in the pavilion; floors, composed of interconnected elliptical volumes, transform into walls and walls into ceilings, promoting a sense of fluidity and making people respond by falling, leaning, tilting and "experiencing the vector of one’s own weight, and becoming sensitized to the effects of gravity" (Schwartzman 63). Along the way, specially installed sensors detect the behaviour of the ‘walker’ and send signals to the system to contribute further to the agenda of imbalance and confusion by changing light, image projection, and sound.Figure 2: Lars Spuybroek, H2OExpo, 1994-1997. © NOX/ Lars Spuybroek. Philip Beesley’s Hylozoic Ground (2010) is also a responsive environment filled by a dense organic network of delicate illuminated acrylic tendrils that can extend out to touch the visitor, triggering an uncanny mixture of delight and discomfort. The motif of pulsating movement was inspired by fluctuations in coral reefs and recreated via the system of precise sensors and microprocessors. This reference to an unfamiliar and unpredictable natural environment, which often makes us feel cautious and ultra-attentive, is a reminder of our innate ability of proprioception (a deeply ingrained survival instinct) and its potential for a more nuanced, intimate, emphatic and bodily rooted communication. Figure 3: Philip Beesley, Hylozoic Ground, 2010. © Philip Beesley Architect Inc. Works of this kind stimulate awareness of both the environment and one's own response to it. Inviting participants to actively engage with the space, they evoke reactions of self-reflexivity, i.e. the self becomes the object of its own exploration and (potentially) transformation. Another strategy of revealing the processes of the "body without image" is through representing various kinds of bio-data, bodily affective reactions to certain stimuli. Biosignal monitoring technologies most often employed include EEG (Electroencephalogram), EMG (Electromyogram), GSR (Galvanic Skin Response), ECG (Electrocardiogram), HRV (Heart Rate Variability) and others. Previously available only in medical settings and research labs, many types of sensors (bio and environmental) now become increasingly available (bio-enabled products ranging from cardio watches—an instance of the "quantified self" trend—to brain wave-controlled video games). As the representatives of the DIY makers community put it: "By monitoring some phenomena (biofeedback) you can train yourself to modulate them, possibly improving your emotional state. Biosensing lets you interact more naturally with digital systems, creating cyborg-like extensions of your body that overcome disabilities or provide new abilities. You can also share your bio-signals, if you choose, to participate in new forms of communication" (Montgomery). What is it about these technologies besides understanding more accurately the unconscious and invisible signals? The critical question in relation to biofeedback data is about the adequacy of the transference of the initial signal, about the "new" brought by the medium, as well as the ontological status of the resulting representation. These data are reflections of something real, yet themselves have a different weight, also providing the ground for all sorts of simulative methods and creation of mixed realities. External representations, unlike internal, are often attributed a prosthetic nature that is treated as extensions of existing skills. Besides serving their direct purpose (for instance, maps give detailed picture of a distant location), these extensions provide certain psychological effects, such as disorientation, displacement, a shift in a sense of self and enhancement of the sense of presence. Artistic experiments with bio-data started in the 1960s most famously with employing the method of sonification. Among the pioneers were the composers Alvin Lucier, Richard Teitelbaum, David Rosenblum, Erkki Kurenemi, Pierre Henry, and others. Today's versions of biophysical performance may include not only acoustic, but also visual interpretation, as well as subtle narrative scenarios. An example can be Marco Donnarumma's Hypo Chrysos, a piece that translates visceral strain in sound and moving images. The title refers to the type of a punishing trial in one of the circles of hell in Dante's Divine Comedy: the eternal task of carrying heavy rocks is imitated by the artist-performer, while the audience can feel the bodily tension enhanced by sound and imagery. The state of the inner body is, thus, amplified, or augmented. The sense of proprioception experienced by the performer is translated into media perceivable by others. In this externalized form it can also be shared, i.e. released into a space of inter-subjectivity, where it receives other, collective qualities and is not perceived negatively, in terms of pressure. Figure 4: Marco Donnarumma, Hypo Chrysos, 2011. © Marco Donnarumma. Another example can be an installation Telephone Rewired by the artist-neuroscientist Sean Montgomery. Brainwave signals are measured from each visitor upon the entrance to the installation site. These individual data then become part of the collective archive of the brainwaves of all the participants. In the second room, the viewer is engulfed by pulsing light and sound that mimic endogenous brain waveforms of the previous viewers. As in the experience of Donnarumma's performance, this process encourages tuning in to the inner state of the other and finding resonating states in one's own body. It becomes a tool for self-exploration, self-knowledge, and self-control, as well as for developing skills of collective being, of shared body-mind topologies. Synchronization of mental and bodily states of multiple people serves here a broader and deeper goal of training collaborative and empathic abilities. An immersive experience, it triggers deep embodied neural circuits, reaching towards the most authentic reactions not mediated by conscious procedures and judgment. Figure 5: Sean Montgomery, Telephone Rewired, 2013. © Sean Montgomery. Conclusion The potential of biofeedback as a strategy for art projects is a rich area that artists have only begun to explore. The layer of the imaginary and the fictional (which makes art special and different from, for instance, science) can add a critical dimension to understanding the processes of augmentation and mediation. As the described examples demonstrate, art is an investigative journey that can be engaging, surprising, and awakening towards the more subtle and acute forms of thinking and feeling. This astuteness and percipience are especially needed as media and technologies penetrate and affect our very abilities to apprehend reality. We need new tools to make independent and individual judgment. The sense of proprioception establishes a productive challenge not only for science, but also for the arts, inviting a search for new mechanisms of representing the un-presentable and making shareable and communicable what is, by definition, individual, fluid, and ungraspable. Collaborative cognition emerging from the augmentation of proprioception that is enabled by biofeedback technologies holds distinct promise for exploration of not only subjective, but also inter-subjective states and aesthetic strategies of inducing them. References Beesley, Philip. Hylozoic Ground. 2010. Venice Biennale, Venice. Clark, Andy, and David J. Chalmers. “The Extended Mind.” Analysis 58.1 (1998):7-19. Donnarumma, Marco. Hypo Chrysos: Action Art for Vexed Body and Biophysical Media. 2011. Xth Sense Biosensing Wearable Technology. MADATAC Festival, Madrid. Eliasson, Olafur. Take Your Time, 2008. P.S.1 Contemporary Art Centre; Museum of Modern Art, New York. Grau, Oliver. Virtual Art: From Illusion to Immersion. Cambridge, Mass.: MIT Press, 2003. Massumi, Brian. Parables of the Virtual: Movement, Affect, Sensation. Durham: Duke University Press, 2002. Montero, Barbara. "Proprioception as an Aesthetic Sense." Journal of Aesthetics and Art Criticism 64.2 (2006): 231-242. Montgomery, Sean, and Ira Laefsky. "Biosensing: Track Your Body's Signals and Brain Waves and Use Them to Control Things." Make 26. 1 Oct. 2013 ‹http://www.make-digital.com/make/vol26?pg=104#pg104›. Sacks, Oliver. "The Disembodied Lady". The Man Who Mistook His Wife for a Hat and Other Clinical Tales. Philippines: Summit Books, 1985. Schwartzman, Madeline, See Yourself Sensing. Redefining Human Perception. London: Black Dog Publishing, 2011. Spuybroek, Lars. Waterland. 1994-1997. H2O Expo, Zeeland, NL.
ER  -
TY  - JOUR
TI  - The Influence of the feedback control of the hexapod platform of the SAAM dynamic driving simulator on neuromuscular dynamics of the drivers
PY  - 2012
PB  - Centre National de la Recherche Scientifique
T2  - HAL (Le Centre pour la Communication Scientifique Directe)
DA  - 2012-09-06
AU  - Aykent, Barış
C1  - Laboratoire Electronique, Informatique et Image [UMR6306]
AU  - Paillot, Damien
C1  - Laboratoire Electronique, Informatique et Image [UMR6306]
AU  - Merienne, Frédéric
C1  - Laboratoire Electronique, Informatique et Image [UMR6306]
AU  - Kemeny, Andras
C1  - Laboratoire Electronique, Informatique et Image [UMR6306]
C1  - Technocentre Renault [Guyancourt]
LA  - en
KW  - Driving simulator
KW  - Simulator sickness
KW  - Hexapod
KW  - Motion simulator
KW  - Overtaking
AB  - Multi sensorial cues (visual, auditory, haptic, inertial, vestibular, neuromuscular) [Ang2] play important roles to represent a proper sensation (objectively) and so a perception (subjectively as cognition) in driving simulators. Driving simulator aims at giving the sensation of driving as in a real case. For a similar situation, the driver has to react in the same way as in reality in terms of 'self motion'. To enable this behavior, the driving simulator must enhance the virtual immersion of the subject in the driving situation. The subject has to perceive the motion of his own body in the virtual scene of the virtual car as he will have in a real car. For that reason, restituting the inertial cues on driving simulators is essential to acquire a more proper functioning [Kol20]. Simulation sickness has been one of the main research topics for the driving simulators. It was assessed between dynamic and static simulators [Cur7], [Wat32]). For a braking maneuver, [Sie29] stated that if the motion platform is activated the bias in reaching increased levels of decelerations was reduced strongly comparing to inactivated platform case. However, there has been lack in publications of vehicle-vestibular cue conflict based illness rating approach and its correlation with the neuromuscular dynamics for that kind of research. In order to reduce the simulator sickness, the difference between the accelerations through the visual and the vestibular cues have to be minimized (cost function minimization via model reference adaptive control, in this paper). Because of the fact that, this paper addresses the simulator motion sickness as a correlated function of this deviation for the both cues with the perception questionnaires as well as the EMG analysis results for the subjects who joined in those experiments. Due to the restricted workspace, it is not possible to represent the vehicle dynamics continuously with scale 1 to 1 on the motion platform [Moo22]. Nevertheless, the most desired aim is to minimize the deviation of the sensed accelerations between the represented dynamics as realistic as possible depending on the driving task. The perception of the driving is very difficult to evaluate in that context. This is the reason; the motion sickness is not easy to study as well. This research work has been performed under the dynamic operations of the SAAM driving simulator as an open-loop and a closed-loop controlled tracking of the hexapod platform of the SAAM dynamic driving simulator. It is obvious that inertial restitution addresses a significant role to maintain a developed fidelity of the driver behaviors on diving simulators The dynamic simulators are being used since the mid 1960s (Stewart platform) [Ste1] firstly for the flight simulators, then the use has spread to the automotive applications. The utilization scope diversifies from driver training to research purposes such as; vehicle dynamics control, advanced driving assistance systems (ADAS), motion and simulator sickness, etc. The dynamic driving simulator SAAM (Simulateur Automobile Arts et Metiers) involves a 6 DOF (degree of freedom) motion system. It acts around a RENAULT Twingo 2 cabin with the original control instruments (gas, brake pedals, steering wheel). The visual system is realized by an approximate 150° cylindrical view. Within the cabin for the employment of extensive measuring techniques (XSens motion tracker, and Biopac EMG (electromyography) device [Acq10]) prepared, which have been already used with numerous attempts such as sinus steer test, NATO chicane, etc. The visual accelerations of translations (longitudinal X, lateral Y and vertical Z axes) as well as the visual accelerations of roll and pitch, which correspond to the vehicle dynamics, were taken into account for the control. Then the platform positions, velocities and accelerations were controlled and fed back to minimize the conflict between the vehicle and the platform levels. The research question about this paper explains a comparative study between an open and a closed loop controlled platform in order to determine the spent power by the muscles to maintain the vehicle pursuing among the pylons. For the evaluation and the validation procedure [Kim19], [Wat32], [Rey27], [Kem17], [Che5], [Pic25], [Acq1], the scenario driven on the simulator SAAM with an open and a closed loop controlled platform to describe the impact of the feedback control. Some results from a case study will be illustrated in the scope of this research with real time controls of the platform at a longitudinal velocity of 60 km/h. The results of this study will be discussed also statistically to obtain the distribution of the dynamics behavior for a group of the participants. This research has been undertaken at ENSAM Institut Image, in collaboration with RENAULT.
ER  -
TY  - JOUR
TI  - A Flame in the Game: a quasi-experimental study exploring immersive multimodal Virtual Reality (VR) training, affective states and ecological validity in healthy firefighters (Preprint)
PY  - 2024
PB  - JMIR Publications
SN  - 2291-9279
T2  - JMIR Serious Games
DO  - 10.2196/53683
UR  - https://doi.org/10.2196/53683
DA  - 2024-06-29
AU  - Oliveira, Joana
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal Coimbra PT
C1  - Faculty of Medicine (FMUC), University of Coimbra, Coimbra, Portugal
C1  - Faculty of Medicine (FMUC), University of Coimbra, Coimbra, Portugal Coimbra PT
AU  - Dias, Joana
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal Coimbra PT
AU  - Correia, Rita
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal Coimbra PT
AU  - Pinheiro, Raquel
C1  - Coimbra PT
C1  - National Fire Service School (ENB), Sintra, Portugal
C1  - National Fire Service School (ENB), Sintra, Portugal Sintra PT
AU  - Reis, Vítor
C1  - Center for Informatics and Systems of University of Coimbra (CISUC), Faculty of Science and Technology, University of Coimbra Coimbra PT
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal Coimbra PT
C1  - Coimbra PT
C1  - LE@D, Universidade Aberta, Lisboa, Portugal
C1  - National Fire Service School (ENB), Sintra, Portugal
C1  - National Fire Service School (ENB), Sintra, Portugal Sintra PT
AU  - Sousa, Daniela
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal Coimbra PT
C1  - Faculty of Medicine (FMUC), University of Coimbra, Coimbra, Portugal
C1  - Faculty of Medicine (FMUC), University of Coimbra, Coimbra, Portugal Coimbra PT
AU  - Agostinho, Daniel
C1  - Center for Informatics and Systems of University of Coimbra (CISUC), Faculty of Science and Technology, University of Coimbra Coimbra PT
C1  - Center for Informatics and Systems of University of Coimbra (CISUC), Faculty of Science and Technology, University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal Coimbra PT
C1  - LE@D, Universidade Aberta, Lisboa, Portugal
AU  - Simões, Marco
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal Coimbra PT
C1  - Faculty of Medicine (FMUC), University of Coimbra, Coimbra, Portugal
C1  - Faculty of Medicine (FMUC), University of Coimbra, Coimbra, Portugal Coimbra PT
AU  - Castelo‐Branco, Miguel
C1  - Center for Informatics and Systems of University of Coimbra (CISUC), Faculty of Science and Technology, University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal
C1  - Coimbra Institute for Biomedical Imaging and Translational Research (CIBIT), Institute for Nuclear Sciences Applied to Health (ICNAS), University of Coimbra, Coimbra, Portugal Coimbra PT
C1  - Faculty of Medicine (FMUC), University of Coimbra, Coimbra, Portugal
C1  - Faculty of Medicine (FMUC), University of Coimbra, Coimbra, Portugal Coimbra PT
LA  - en
KW  - Preprint
KW  - Ecological validity
VL  - 12
SP  - e53683
EP  - e53683
AB  - Background Firefighters face stressful life-threatening events requiring fast decision-making. To better prepare for those situations, training is paramount, but errors in real-life training can be harmful. Virtual reality (VR) simulations provide the desired realism while enabling practice in a secure and controlled environment. Firefighters’ affective states are also crucial as they are a higher-risk group. Objective To assess the impact on affective states of 2 simulated immersive experiences in a sample of healthy firefighters (before, during, and after the simulation), we pursued a multivariate approach comprising cognitive performance, situational awareness, depression, anxiety, stress, number of previous adverse events experienced, posttraumatic stress disorder (PTSD) severity, and emotions. The efficacy and ecological validity of an innovative VR haptic system were also tested, exploring its impact on performance. Methods In collaboration with the Portuguese National Fire Service School, we exposed 22 healthy firefighters to 2 immersive scenarios using the FLAIM Trainer VR system (neutral and arousing scenarios) while recording physiological data in a quasi-experimental study. Baseline cognitive performance, depression, anxiety, stress, number of adverse events, and severity of PTSD symptoms were evaluated. Positive and negative affective states were measured before, between, and after each scenario. Situational awareness, sense of presence, ecological validity, engagement, and negative effects resulting from VR immersion were tested. Results Baseline positive affect score was high (mean 32.4, SD 7.2) and increased after the VR tasks (partial η2=0.52; Greenhouse-Geisser F1.82,32.78=19.73; P&lt;.001). Contrarily, mean negative affect score remained low (range 11.0-11.9) throughout the study (partial η2=0.02; Greenhouse-Geisser F2.13,38.4=0.39; P=.69). Participants’ feedback on the VR sense of presence was also positive, reporting a high sense of physical space (mean score 3.9, SD 0.8), ecological validity (mean score 3.8, SD 0.6), and engagement (mean score 3.8, SD 0.6). Engagement was related to the number of previously experienced adverse events (r=0.49; P=.02) and positive affect (after the last VR task; r=0.55; P=.02). Conversely, participants reported few negative effects (mean score 1.7, SD 0.6). The negative effects correlated positively with negative affect (after the last VR task; r=0.53; P=.03); and avoidance (r=0.73; P&lt;.001), a PTSD symptom, controlling for relevant baseline variables. Performance related to situational awareness was positive (mean 46.4, SD 34.5), although no relation was found to metacognitively perceived situational awareness (r=–0.12; P=.59). Conclusions We show that VR is an effective alternative to in-person training as it was considered ecologically valid and engaging while promoting positive emotions, with few negative repercussions. This corroborates the use of VR to test firefighters’ performance and situational awareness. Further research is needed to ascertain that firefighters with PTSD symptomatology are not negatively affected by VR. This study favors the use of VR training and provides new insights on its emotional and cognitive impact on the trainee.
ER  -
TY  - JOUR
TI  - Special Issue: Emerging Technologies and Methods for Early-Stage Product Design and Development
PY  - 2023
PB  - American Society of Mechanical Engineers
SN  - 1050-0472
T2  - Journal of Mechanical Design
DO  - 10.1115/1.4056744
UR  - https://doi.org/10.1115/1.4056744
DA  - 2023-01-23
AU  - Moghaddam, Mohsen
C1  - Department of Mechanical and, Industrial Engineering
C1  - Khoury College of Computer Sciences, Northeastern University, Boston, MA 02115
AU  - Marion, Tucker
C1  - D'Amore McKim School of Business
C1  - Department of Mechanical and Industrial Engineering, Northeastern University, Boston, MA 02115
AU  - Hölttä‐Otto, Katja
C1  - Department of Mechanical Engineering, University of Melbourne, Parkville, VIC 3010, Australia
AU  - Fu, Kate
C1  - Department of Mechanical Engineering, University of Wisconsin–Madison, Madison, WI 53706
AU  - Olechowski, Alison
C1  - Department of Mechanical and Industrial Engineering, University of Toronto, 27 King's College Circle, Toronto, ON M5S, Canada
AU  - McComb, Christopher
C1  - Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA 15213
LA  - en
KW  - Emerging Technologies
VL  - 145
IS  - 4
AB  - The early-stage product design and development (PDD) process fundamentally involves the processing, synthesis, and communication of a large amount of information to make a series of key decisions on design exploration and specification, concept generation and evaluation, and prototyping. Although most current PDD practices depend heavily on human intuition, advances in computing, communication, and human–computer interaction technologies can transform PDD processes by combining the creativity and ingenuity of human designers with the speed and precision of computers. Emerging technologies like artificial intelligence (AI), cloud computing, and extended reality (XR) stand to substantially change the way designers process information and make decisions in the early stages of PDD by enabling new methods such as natural language processing, generative modeling, cloud-based virtual collaboration, and immersive design and prototyping. These new technologies are unlikely to render the human designer obsolete, but rather do change the role that the human designer plays. Thus, it is essential to understand the designer's role as an individual, a team, and a group that forms an organization. The purpose of this special issue is to synthesize the state-of-the-art research on technologies and methods that augment the performance of designers in the front-end of PDD—from understanding user needs to conceptual design, prototyping, and development of systems architecture while also emphasizing the critical need to understand the designer and their role as well.The research articles that comprise this special issue focus primarily on three major early-stage PDD activities that new technologies and methods can potentially transform: (1) design problem exploration, (2) design concept generation, and (3) design concept evaluation. Articles in the first collection gravitate toward AI methods that facilitate the elicitation of user needs and product usage context, exploration and identification of design problems, and specification of design guidelines. The second collection of research articles contributes new AI methods that enable the automated generation of novel design concepts in various forms, such as textual descriptions, images, and 3D shapes, along with a thorough analysis of the resulting changes in the designer's role. The third collection of articles investigates new methods based on AI and XR that aim at automating or facilitating design concept evaluation. While these articles break new ground in augmenting the front-end of PDD through new technologies and methods, designers remain the principal actor in this process. It is, therefore, of paramount importance to explore the evolving role of designers in the PDD process and the nature and necessity of their partnership with technology. This special issue also presents research articles that explore biases, beliefs, attitudes, and intentions, as well as the means and method to facilitate the collection, extraction, and organization of their knowledge to support design. The remainder of this Guest Editorial elaborates on the collections of research articles presented in this special issue.The research articles in this collection of early-stage PDD activities focus on various fundamental problems concerning the specification of the design problem to be solved, including design problem identification and definition, elicitation of user needs and product usage contexts, and specification of design objectives and outcomes.In the article "A Computational Approach to Identifying Engineering Design Problems," Obieke, Milisavljevic-Syed, Silva, and Han present a method based on Markovian models and machine learning to support engineering design problem exploration, a process of identifying or coming up with a new problem or need at the early stage of design. The authors investigate the natural models and phenomena that explain this process, such as rational and garbage can models, and the emerging technologies that can support this process along with the associated challenges. A case study involving 43 international participants from the engineering design communities in academia and industry shows the effectiveness of the proposed method in supporting novice and experienced design engineers in the problem-exploration process.In the article, "A Hybrid Semantic Networks Construction Framework for Engineering Design," Cheligeer, Yang, Bayatpour, Miklin, Dufresne, Lin, Bhuiyan, and Zeng develop a method based on recursive object modeling, Word2Vec technique, and a domain-specific language model to build semantic networks for a project to design aircraft braking systems. The semantic networks are built on the abstracts of scientific papers retrieved from Semantic Scholar API to address the design problem implied in the seed design statement, following an environment analysis from environment-based design methodology. The semantic network proposed in this article can be used for design information retrieval, computer-aided design idea generation, cross-domain communication support system, and designer training.The article "Attribute-Sentiment-Guided Summarization of User Opinions from Online Reviews" by Han, Nanda, and Moghaddam presents a novel computational method for abstractive summarization of user opinions from online reviews guided by specific product attributes and sentiment polarities. The article is motivated by the rapid growth of user-generated reviews, the lack of formal mechanisms to guide the generative process with respect to different categories of product attributes and user sentiments, and the lack of annotated training datasets needed for the supervised training of abstractive summarization models. The authors develop a hierarchical multi-instance attribute-sentiment inference model for assembling a high-quality synthetic dataset, which is utilized to fine-tune a pretrained language model (PLM) for an abstractive summary generation. The proposed method is validated through numerical experiments on a large dataset from three major e-Commerce retail stores for apparel and footwear products.The article "Constructing Product Usage Context Knowledge Graph Using User-Generated Content for User-Driven Customization" by Wang, Liu, and Kara proposes a knowledge graph construction method to identify product usage context from user-generated content for user-driven customization. The authors aim to enable a design paradigm where customers act as co-designers to configure products based on their needs while avoiding designing products incompatible with their environment and needs. The proposed method can convert crowdsourced corner cases into structured usage context knowledge graphs to facilitate the personal usage context prediction, summarization, and reasoning by designers.In the article "Task-Oriented Methodology Combining Human Manual Gestures and Robotic Grasp Stability Analyses: Application to the Specification of Dexterous Robotic Grippers," Escorcia-Hernandez, Grossard, and Gosselin present a task analysis method based on human-centered gestures analysis and object-centered grasp stability analysis to provide guidelines for the design of dexterous robotic grippers. The main design objectives include versatility to perform various tasks, simplicity of manufacturing, and reduced kinematic complexity. The proposed method provides designers with tools that help specify the number of fingers, the number of degrees-of-freedom, and the placement of tactile sensors, along with guidelines for the specification of the actuation system. The authors validate the method by defining technical specifications for designing a multifingered robotic gripper intended to perform the tasks involved in a sterility testing process.The first two articles related to design concept generation help frame the role of designers concerning technology and its potential for integration into the process. With advances in AI and other technologies, this collection of articles is centered on integrating technology into the PDD process to augment the designer's ability to generate concepts via methods that might enhance the novelty, quality, and quantity of concepts that express the needs and requirements of a potential solution. A common thread among these articles is the inclusion of data, be it consumer reviews or inspiration from biological systems, which provide a catalyst for including adjacencies into concept development and related activities. The final two articles in this subtopic give examples and demonstrations of novel technology-driven design concept generation methods.In the article "Generative Design: Reframing the Role of the Designer in Early-Stage Design Process," Saadi and Yang explore how using these generative design tools may impact the design process, designer behavior, and overall outcomes. This qualitative article reports on the results of in-depth interviews with practicing and student designers from different disciplines who use commercial generative design tools, detailing the design processes they followed. This article proposes a provisional process diagram for generative design and its uses in the early-stage design process. The proposed framework and approach can help designers understand when and where new tools, such as generative design, can be best utilized in the early stages of design.In the article "Deep-Learning Methods of Cross-Modal Tasks for Conceptual Design of Product Shapes: A Review," Li, Wang, and Sha conduct a systematic review of the retrieval, generation, and manipulation methods for deep learning of cross-model tasks (DLCMT) that involve three cross-modal types: text-to-3D shape, text-to-sketch, and sketch-to-3D shape. The review identifies 50 articles from 1341 papers in computer graphics, computer vision, and engineering design. The article reviews the state-of-the-art DLCMT methods that can be applied to product shape design and identifies critical challenges. The authors then discuss potential solutions to these challenges and propose research questions that point to future directions of data-driven conceptual design.The next two articles provide examples of how technology can augment the designer's role and tasks. In the article "DDE-GAN: Integrating a Data-Driven Design Evaluator Into Generative Adversarial Networks for Desirable and Diverse Concept Generation," Yuan, Marion, and Moghaddam propose and validate a new GAN-based generative design model with an offline design evaluation function to generate samples that are not only realistic but also diverse and desirable. A multimodal data-driven design evaluation (DDE) model is developed to guide the generative process by automatically predicting user sentiments for the generated samples based on large-scale user reviews of previous designs. The proposed method illustrates how technology can be inserted into the design process to automatically assist the designer in integrating and utilizing customer data to improve the generation of new concepts.In the article, "Biologically Inspired Design Concept Generation Using Generative Pre-Trained Transformers," Zhu, Zhang, and Luo propose a method that integrates bio-inspired design (BID) into the process. This article presents a generative design approach based on the generative PLM to automatically retrieve and map biological analogy and generate BID in the form of natural language. Three design concept generators are identified and fine-tuned from the PLM according to the looseness of the problem space representation. The approach is evaluated and employed in a real-world project of designing light-weighted flying cars during its conceptual design phase. The results illustrate that BID can generate novel designs with good performance.Historically, the evaluation of design concepts has been a largely manual activity based on input from the design team. While Pugh matrices and quality function deployment integrate customer needs with proposed features and specifications into the decision-making process, these evaluation techniques have historically relied on a limited amount of data and have limitations due to the subjectivity and biases of the evaluators. New technologies can potentially integrate more data into the evaluation and selection process, thereby reducing human-related challenges such as bias and requiring high levels of expertise.In the article "Attention-Enhanced Multimodal Learning for Conceptual Design Evaluation," Song, Miller, and Ahmed propose an attention-enhanced multimodal learning-based machine learning model to predict five design metrics: drawing quality, uniqueness, elegance, usefulness, and creativity. The proposed model utilizes knowledge from large external datasets through transfer learning, simultaneously processes text and sketch data from early-phase concepts, and effectively fuses the multimodal information through a mutual cross-attention mechanism. The proposed method highlights the potential benefit of using multimodal representations for design metric assessment.In another article with a similar scope but a significantly different method, entitled "The Influence of Hand Tracking and Haptic Feedback for Virtual Prototype Evaluation in the Product Design Process," Palacios-Ibáñez, Alonso-García, Contero, and Camba report the results of a study where a group of participants evaluated three designs of a product (i.e., umbrella stands) when viewed in a real setting, virtual reality (VR), and VR with passive haptics. Their goal was to observe the influence of visual media in product perception and how the use of a complementary item (i.e., a physical umbrella) for interaction and user design expertise influence product assessment. The article highlights that using VR with passive haptics could be an effective tool for product evaluation, as illustrated by the study of umbrella stands and young consumers.Despite the potentially transformative role of technology in the front-end of PDD, as described earlier, design is still inherently a human activity that relies heavily on the ingenuity and creativity of designers. To better understand how engineering designers and engineering design technologies can work together and complement each other, it is, therefore, necessary to further explore human designers' unique capabilities and limitations in PDD. The last collection of research articles featured in this special issue is centered on the role of designers in PDD, the impact of human traits such as empathy and bias on design outcomes, and the technologies and methods that can foster innovation in design teams and organizations.The article "Error Management Bias in Student Design Teams" by Fillingim, Shapiro, and Fu investigates cognitive bias in design teams with consideration for the intent of error management through the lens of adaptive rationality. The results of a survey-based data collection activity conducted in a graduate-level design course indicate five types of bias in design activities, including bandwagon, availability, status quo, ownership, and hindsight biases. The authors draw conclusions on trends and statistical correlations from survey data and course deliverables. This article highlights the most common forms of bias in design teams and provides directions for developing ways to mitigate such biases.In the article "Not Good Enough? Exploring Relationships Between Novice Designers' Trait Empathy, Their Beliefs, Attitudes, and Intentions Toward Sustainability, and the Self-Evaluated Sustainability of Their Solutions," Prabhu, Alzayed, and Starkey investigate designers' ability to empathize with those affected in a secondary or tertiary capacity and the influence of designers' internal traits, such as beliefs, attitudes, and intentions, on their emphasis on environmental sustainability. Through a human subject experiment involving student designers, the authors compared changes in their trait empathy and their beliefs, attitudes, and intentions toward sustainability before and after a hands-on sustainable design workshop. Results show that participants experienced an increase in their beliefs and intentions toward sustainability and a decrease in personal distress after the workshop. They also reveal that trait empathy significantly predicted the self-evaluated sustainability of solutions on the following dimensions of sustainable design: disposal, recycling, and finding wholesome alternatives. The authors conclude the article by providing future research directions on the influence of designers' differences on their approach to sustainable design.In the article "Embedding Experiential Design Knowledge in Interactive Knowledge Graphs," Wang, Goridkov, Rao, Cui, Grandi, and Goucher-Lambert study the knowledge organization practices of a group of professional designers as they virtually engage with data collected during a teardown of a consumer product to understand knowledge organization during an experiential activity and how it can be transformed into a scalable representation. The authors develop a searchable knowledge graph to represent experiential knowledge and handle complex queries. Two extended examples are used to validate the knowledge graph and uncover insights and patterns from design knowledge. This article is a preliminary step toward creating design knowledge bases that accurately reflect designer behavior and enable effective data-driven support tools for design.In the article "Design-as-a-Service Framework for Enabling Innovations in Small- and Medium-Sized Enterprises," Agarwal, Sorathiya, Vaishnav, Desai, and Mears explore the augmentation of the Design-as-a-Service (DaaS) model into the cloud-based design and manufacturing (CBDM), to connect skilled human resources with enterprises interested in transforming an idea into a product or solution. The proposed model presents an approach for integrating human resources with various CBDM elements and end-users through a service-based model. The authors also discuss the challenges associated with implementing the proposed model and provide directions for enterprises and individuals to adopt the model for rapid and economical product discovery.Lastly, in the article entitled "Prototyping Strategies to Engage Stakeholders During Early Stages of Design: A Study Across Three Design Domains," Rodríguez-Calero, Daly, Burleson, and Sienko aim at identifying patterns in prototyping strategies for engaging stakeholders during the design front-end by conducting semi-structured interviews with a group of design practitioners across three product design domains, including automotive, consumer products, and medical devices. The article is motivated by the lack of studies on prototyping practices that inform problem definition, requirements and specifications development, concept generation, and other front-end design activities. The article reports that the descriptions and examples in the context of prototyping strategies used to engage stakeholders during front-end design can guide the design strategies of both experienced and novice designers.The articles featured in this special issue contribute a wide range of methods enabled by emerging technologies such as AI, cloud computing, and XR to support the front-end of PDD—a process that traditionally depends heavily on human intuition, information processing, and decision-making. The organic emergence of the four collections of articles introduced in this Guest Editorial underscores the role of technology in facilitating activities that involve intensive information processing and decision-making, as well as the necessity of rethinking the roles and capabilities of future designers equipped with these technologies. Yet, this special issue is by no means all-inclusive and should mainly serve as a research agenda for future exploration of new technologies and methods for PDD and their complementary roles in conjunction with designers, design teams, and organizations. There are still limitations on AI systems performing human-like tasks such as latent need generation, creative ideation, and an empathetic understanding of users. The issue of algorithmic bias needs further investigation. Existing generative design models are still limited, expensive to run, and not easily controllable. For concept evaluation, there are still questions surrounding best practices for how best to use automated evaluation to drive the creation of novel solutions. Finally, the role of designers and engineers is ever-changing and, in many cases, evolves in tandem with the emergence of new technology. The future relationship between design practice and the set of technologies featured in this issue is fraught with challenges. It is still unclear how we can best translate this research into truly useful tools and platforms that will augment and improve, but not necessarily replace, the human. The articles presented in this special issue indicate what is possible, but there is a lot more to be explored.We would like to take this opportunity to thank all authors who submitted their original contributions to this special issue and all reviewers for their effort in providing constructive feedback to the authors. We are grateful for the support and guidance of Professor Wei Chen, the Editor-in-Chief of the Journal of Mechanical Design. Special thanks to Amy Suski for her generous assistance throughout this editorial process.
ER  -
TY  - JOUR
TI  - Installing the Game: Gameplay in the Installation &lt;i&gt;T_Visionarium&lt;/i&gt;
PY  - 2009
SN  - 1069-0697
T2  - symplokē
DO  - 10.1353/sym.2009.0021
UR  - https://doi.org/10.1353/sym.2009.0021
DA  - 2009-01-01
AU  - Milton-Smith, Melissa
LA  - en
VL  - 17
IS  - 1-2
SP  - 197
EP  - 203
ER  -
TY  - CHAP
TI  - Audiovisual Industries and Health Care: Overview of Forms of Co-innovation and Convergence
PY  - 2019
T2  - Emerald Publishing Limited eBooks
DO  - 10.1108/978-1-78769-977-920191014
UR  - https://doi.org/10.1108/978-1-78769-977-920191014
DA  - 2019-03-20
AU  - Järvekülg, Madis
LA  - en
SP  - 115
EP  - 120
ER  -
TY  - JOUR
TI  - Will the COVID-19 pandemic be a harbinger of change in dental education
PY  - 2021
PB  - Medknow
SN  - 0973-029X
T2  - Journal of Oral and Maxillofacial Pathology
DO  - 10.4103/0973-029x.325103
UR  - https://doi.org/10.4103/0973-029x.325103
DA  - 2021-05-01
AU  - Sircar, Keya
C1  - Accepted July 29, 2021
C1  - Department of Oral Pathology, Faculty of Dentistry, Jamia Millia Islamia, New Delhi, India E-mail: [email protected]
C1  - Received July 20, 2021
C1  - This is an open access journal, and articles are distributed under the terms of the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 License, which allows others to remix, tweak, and build upon the work non-commercially, as long as appropriate credit is given and the new creations are licensed under the identical terms.
LA  - en
KW  - Pandemic
KW  - 2019-20 coronavirus outbreak
VL  - 25
IS  - 2
SP  - 210
EP  - 212
AB  - Soon after the World Health Organization declared the COVID-19 outbreak a public health emergency of international concern on January 30, 2020, and a pandemic on March 11, 2020, every aspect of life as we knew changed. Education was one of the areas that were quick to try and adapt to the new normal, to maintain continuity in education. Technology was scaled up at every level, as educators and students learned to effectively teach and learn in the virtual mode. Dental colleges, under the guidance of various regulatory authorities and government policies, quickly tried to adapt to the new normal to ensure the learning outcomes for their students as prescribed by Dental Council of India. However, there is a need to consider the impact of these decisions from the student's perspective. Traditionally, the Bachelor of Dental Surgery and Master in Dental Surgery program include didactic teaching, preclinical laboratory courses and clinical skills training. Didactic teaching can easily shift to online mode. Preclinical lab courses typically involve demonstration by the teachers, followed by practice on models, mannequins, etc., along with guided step-by-step assessment by teachers. The course objectives can be achieved by the use of modern digital technology with manikins and virtual reality/augmented reality-based stimulation devices along with haptic technology, but the necessary infrastructure for this digital transition is not yet easily available in most Indian universities and colleges. Clinical skills training in the 3rd year, 4th year, and during internship is perhaps the most essential part of dental education. Close contact between the patient, dental student/intern, and the teacher is an integral part of the teaching–learning process. Adapting this aspect of dental education to pandemic times is the biggest challenge. Research at the undergraduate and postgraduate level is also integral to modern dental education. Clinical research work has been suspended in most countries; however, some limited in vitro studies and literature reviews which could be done on the computer at home has continued.[1] Besides the lockdown restrictions, that closed all educational institutions across India, clinical training of dental students was also impacted by the fact that the SARS-CoV-2 virus is present in the saliva, nasopharyngeal secretions and aerosols in large numbers, and so dental practice which invariably requires the dental surgeon to be in very close proximity with the patient was declared as a high-risk area with respect to COVID-19 transmission.[2] Surveys have shown that students adapted well, and some even prefer online teaching for their theory classes, for the flexibility, it offers in terms of pace of learning and convenience of scheduling.[3] However, most students felt that their clinical training was negatively impacted, with a significant proportion of final-year students not being confident of their clinical skills at the time of graduation and a significant proportion feeling that they would need direct or indirect mentoring and supervision following graduation.[4] In response to this felt need, it should be incumbent to develop mechanisms to allay these anxieties. However, it was interestingly noted that, though students were concerned about their clinical training being negatively impacted, they were not prepared for any extension in the duration of the course, their work hours or even a curtailment of the vacations.[3] The COVID-19 lockdown and resulting restrictions and confinement to homes were a new experience for students and initially "online" education was a new, unique experience. However, it soon gave way to the harsh reality of digital divides, inadequate internet connectivity and the realization on the part of both students and teachers that e-lectures were not a substitute for face-to-face lectures, in which didactic teaching was necessarily accompanied with the development of student–teacher bonds that added an invaluable dimension to the teaching–learning process. One study has shown that there was an improvement in students' academic performance during the COVID-19 confinement.[5] However, most other studies have reported a lack of confidence among graduating dental students in performing clinical procedures independently, without supervision and starting their own dental clinics.[4] It can be stated quite definitively that clinical training in all dental specialties will be adversely affected by the various challenges that have emerged as a consequence to the pandemic. Hattar et al. reported that students were least confident about those clinical specialties, in which they had missed their clinical postings due to the lockdown.[4] As it has been established that COVID-19 spreads through aerosols, dental treatment has been considered "risky" by both patients and dental surgeons alike. Many dental educators have been in favor of indefinitely postponing aerosolizing procedures till the end of the pandemic.[6] Thus, it has become necessary to ensure a safe working environment in dental clinics, both in dental colleges and in private dental clinics. In fact, the pandemic may well be a flexion point that will make it mandatory for all dental clinics to ensure robust infection control measures, even after the pandemic is over. However, studies have shown that routine use of rubber dams, high-volume suction along with personal protective equipment can significantly reduce viral transmission in the dental clinic.[7] Virus infectivity rates are highly dynamic, showing variation from place to place and time to time. Thus, close and continuous cooperation is required between all the concerned people such as faculty, administrators, nurses, assisting staff, and students to actively monitor guidelines and keep updated with the evolving evidence that can guide decision-making in developing the most effective infection control protocols to ensure a safe working environment for all. Studies also indicate that graduating dental students have experienced high stress levels as their clinical training has been negatively impacted by the pandemic.[8] The literature suggests that, even in the pre-COVID-19 times, significant proportion of dental students drink excessively and experiment with drugs.[9] The lockdown and associated "stay at home" restrictions, leading to reduced contact with friends and peers may well push susceptible students toward making poor health choices. There is a need to enhance counseling and other student support systems in our dental colleges. Maintaining good communication with students and involving them in the decision-making process can help to reduce anxiety and equip them to adapt better to the current situation. The current situation can be a "wakeup call" for relooking at dental education in India, which has not undergone any significant change in the last several decades. Inclusion of outreach teaching–learning experiences such as including community dental care, involving private dental practitioners in externship programs as a part of the curriculum can be very useful adjuncts for clinical training, development of communication skills and for building self-confidence in graduating dental students. The academic community has to actively plan for a paradigm shift in dental education by developing modern teaching and assessment methodologies that will ensure that students are able to achieve their clinical competencies and are confident of independent dental practice. The American Dental Education Association took the lead with recommendations for developing teaching modalities on the online platforms and other innovative methods of pedagogy. Regulatory bodies can similarly help to create a community of dental academicians to share ideas and resources to achieve the best learning outcomes for our students.[10] Besides ensuring continuity of academic activities, the teaching community should also recognize the need to augment student support systems such as counseling and mentoring in their institutions. The COVID-19 pandemic may well serve, not as a detriment to education, but a learning experience which will lead to a redefining of dental education. A hybrid or blended program that incorporates clinical training on patients and robust infection control protocols with remote learning using advanced digital technology and artificial intelligence in simulators and skill labs may underpin dental education in the postpandemic world. Such developments may well reduce the time and dependence on the actual number of patients attended to by a dental student, being while still maintaining the highest standards of dental clinical training. It is now incumbent on the dental academic community to be proactive in framing policies and guidelines that will define the beginning of a new era in dental education.
ER  -
TY  - JOUR
TI  - Simulation-based medical education: Using best practices and curriculum mapping to maximize educational benefits in the context of shift toward competency-based medical education
PY  - 2017
PB  - Medknow
SN  - 2321-4848
T2  - Archives of Medicine and Health Sciences
DO  - 10.4103/2321-4848.208217
UR  - https://doi.org/10.4103/2321-4848.208217
DA  - 2017-01-01
AU  - Chacko, Thomas
C1  - Department of Community Medicine, Believers Church Medical College, Thiruvalla, Kerala, India
C1  - Prof. Thomas V. Chacko, Dean Medical Education, Believers Church Medical College, Thiruvalla, Kerala, India. E-mail: [email protected]
LA  - en
KW  - Graduate medical education
VL  - 5
IS  - 1
SP  - 9
EP  - 9
AB  - INTRODUCTION The present curriculum followed in many medical schools is mainly discipline based and knowledge intensive leading to information overload on students with less attention on skills required for the tasks they are expected to perform as health-care professionals. Thus, the graduates produced by this system are not job ready. Hence, medical schools in many countries have moved toward outcome-based curricula focusing the student learning experiences on acquiring competencies and attributes needed for attainment of stated graduate outcomes that would help them to become capable of discharging their job roles and professional activities to meet the health needs of the people. India is also moving toward attaining outcomes expected of Indian Medical Graduate (MCI Vision 2015).[1] It is in this context that the need for simulation-based medical education (SBME) and the role that it plays to achieve the graduate outcome competencies needs to be understood better. In addition, after one is convinced about its need and its role, it is important to know what must be done to ensure and maximize the educational benefits of SBME. WHAT IS SIMULATION-BASED MEDICAL EDUCATION? In SBME, instead of using real patients, we use processes and teaching–learning methods including the use of "Simulated Patients"[2] who are actors who act like a patient and/or use simulators which are devices and tools to replace the actual patient to help mimic a clinical encounter so as to provide a safe learning environment for the learner to do deliberate practice of health-care skills so that it then becomes safe for the patient and for the learner to practice the skills on real patients.[3] Clinical skills laboratories have been established in medical institutions as a facility for SBME. To facilitate SBME, skills laboratories have educational resources such as (1) plastic models for partial task training; (2) mannequin-type simulators (dummy type and high-fidelity type); (3) screen-based virtual-reality simulators; (4) live or inert animals including isolated organs; (5) human cadavers for surgical skills training; and (6) simulated or standardized patients to practice specific skills. There can also be a "full environment simulation" of clinical-or-service-delivery where learners can not only acquire technical skills but also nontechnical skills, such as professional team leadership, team work, communication, situation awareness, decision-making, and awareness of personal limitations.[4] SIMULATION-BASED MEDICAL EDUCATION: ITS PLACE WITHIN THE MBBS CURRICULUM Within the traditional apprentice-based curricular model that most medical schools in India are following, learning and acquisition of Medical Council of India's Graduate Medical Education-listed competencies is possible using a competency-focused curricular approach rather than a pure competency-based medical education model (where it is time independent and one exits the program only by attaining the targeted competency levels). In the competency-focused curricular approach (like what we seem to be moving toward), learning is focused around the identified competencies to be attained within the fixed time of the three phases of MBBS program where milestones to be achieved in the competency progression pathway are mapped out MBBS phase wise with the next milestone in the competency progression process getting addressed in the next phase and then during internship, etc., To make this possible, a further exercise of writing the competencies (which are descriptors of physicians) as Entrustable Professional Activities (EPAs) which are descriptors of professional work activities is needed. In teaching settings, written EPAs can help supervisors to decide when and for what tasks they can entrust trainees to assume clinical responsibilities.[5] This step is needed so that it makes clinical sense to the trainer as well as helps learners get motivated to focus on the acquisition of knowledge required for the skill and do deliberate practice needed to gain mastery on that skill to make the graduate job ready (mastery learning). We need a strategic curricular approach that requires that we ensure learning opportunities for each of the identified competencies. For each of these competencies, students then need to engage in repeated cycles of deliberate practice,[6] receive feedback, and make progress through the stages of unconscious incompetence (incompetent) to conscious incompetence (novice) to conscious competence (competent) and finally to unconscious competence (proficient ~ expert). The "10-year rule of necessary preparation"[7] was recognized as necessary for experts in most domains to attain the highest level of performance by engaging in continuous deliberate practice (and not merely through years of experience alone). Hence, not all EPAs are to be reached to the level of proficiency at the graduate level except the most critical ones (like basic life support) and so they need to be stated as the milestones to be reached along the phases of UG and later internship (mostly reach up to advanced beginner and for some EPAs to competent level), and during residency (from competent to proficient) and progress further during higher PG specialization toward mastery and reach the level of expertise through conscious deliberate practice even after qualifying by engaging in continuing professional development for bridging the gap in the level of competencies needed for professional practice expected at expert level.[8] THE NEED AND ROLE OF SIMULATION-BASED MEDICAL EDUCATION IN MAKING THE INDIAN MEDICAL GRADUATE JOB READY In the competency-focused curriculum transposed within the apprenticeship model of learning experience traditionally available in the institutional teaching–learning clinical environment in the wards and outpatient setting, it is challenged by the inherent shortcoming of the current MBBS curriculum where time for learning is fixed. This is compounded by shortage of appropriate cases for practicing the skills, by the unpredictability that these cases would be available for all students during their posting in the wards or outpatient department, inappropriateness of some cases like those in emergencies to be allowed for deliberate practice and receive immediate feedback and the valid concerns for patient safety. In most of these settings, focused competency-based medical education modality that requires dedicated faculty time to brief, supervise the process of practicing the learning of the correct steps in the right way as well as give immediate feedback on learner performance, score, and document progression is difficult. All the above problems or challenges for competency-based/focused learning make a case for SBME to be a good supplement to the traditional apprentice-based learning system to ensure that none of the required skills are missed out. To overcome the problem of clinical faculty not getting dedicated time for supervising student–patient encounters or deliberate practice sessions in skills laboratories, perhaps up to certain level of milestones at the MBBS graduate level for some EPAs, keeping in mind the large numbers, peer-assisted learning can supplement the process where the actual progression in acquisition of level of competency would need validation by faculty. NEED FOR SIMULATION-BASED MEDICAL EDUCATION TO PREPARE THE DOCTORS FOR LICENSURE EXAMINATIONS AND CREDENTIALING In the present times where concern about uniform standards and capabilities of graduates are being expressed and proposed to be mandatorily tested through national exit examinations and/or being made mandatory for licensure for practice (like in many countries in the West), it makes sense that medical schools must pay attention to ensure that the expected graduate competencies identified and listed as EPA required for carrying out professional tasks as well as leading teams for delivering health care in teams are practiced in simulated conditions and on simulators and internally certified so that the students become more confident to demonstrate the required skills and attributes at the national level testing for licensure as well. MAXIMIZING THE EDUCATIONAL BENEFITS OF SIMULATION-BASED MEDICAL EDUCATION Most of the EPAs which need performance of simple patient care task can be learned within the prevailing apprentice model under supervision using deliberate practice and immediate feedback in the ward and outpatient ambulatory setting, provided separate space and dedicated time are made available and student numbers are small. Simpler intervention procedures need simple simulation models that are available, but they are still costly if realism is to be achieved. Realism is needed for motivation to engage in repeated deliberate practice till competency level is to be reached before allowing them to do the procedure on the real patient in the interest of patient safety. Sophisticated high-fidelity simulation systems are costly and are needed for higher specialty education. Acquiring such costly and advanced systems, however, sometimes takes away the attention and need for providing simpler models in sufficient numbers required for the number of MBBS students who are available during clinical rotations for learning some essential common procedures and this should not happen. However, market forces and "prestige" associated with high-level investments in costly systems of simulation cloud the decision-making about the type of simulation facilities needed. And often after such costly decisions are made, administrators and decision makers feel that owning such "state-of-the-art" facility will take care of all the needs of MBBS students. This leads to gross underutilization of the facilities with money getting diverted to costly high-fidelity ones needed by specialists to the detriment of not making available simple facilities needed in larger numbers for the large number of MBBS students so as to address simple but essential skills including communication skills. Hence, MCI Expert group for undergraduate medical education in its document "Academic Staff Training and Learning Enhancement Strategies for Capacity Building in Medical Education" (2010)[9] recommended that, for adopting the above-mentioned contemporary education technologies, faculty development programs in teacher training, skills training, training for patient simulation center, and e-learning resource center are needed. To avoid burdening the medical colleges administering the MBBS program with costly advanced systems and equipment, it has recommended and classified skills laboratories for various levels of competence and variety of skills for undergraduate, postgraduate, and subspecialty training: Level 1 training facility mandatory for all medical colleges: Basic surgical skills, basic life support skills, procedural skills, normal labor management, and conduct of delivery. Interns should have a mandatory Level 1 certification before they get licensure Level 2 training desired in each medical college or in collaboration with regional centers: Advance life support, basic laparoscopic skills, neonatal and pediatric resuscitation skills Level 3 facilities–to be available in regional skills training centers and above: Microsurgical skills, advanced laparoscopic skills, human patient simulator for anesthesia. So, at the MBBS level, for ensuring all EPAs needed for the graduate to be job ready, curricula must be planned in such a way that all listed competencies are addressed in a systematic process of curriculum mapping [rubric in Table 1] to identify what appropriate learning experiences are needed for each of those competencies with the skill part of the EPA alone requiring deliberate practice sessions within dedicated time slots within the traditional clinical learning settings as well as in facilities where simulated patients, mannequins, and advanced high-fidelity systems each directed to different skills and different levels of expertise needed.Table 1: Curriculum matrix as a tool to plan the learning experiences for acquiring expected competencies and plan optimal use of simulation-based medical educationMAXIMIZING EDUCATIONAL BENEFIT USING MEDICAL SIMULATION TECHNOLOGY Based on critical review of literature on SBME covering the years 1969–2003 and from 2003 to 2009, McGaghie et al.[10] as well as the systematic review on features and uses of high-fidelity medical simulations by Issenberg et al.[11] have led to evidence-based identification and proposal of features and best practices for effective simulation-based medical education. THE 12 FEATURES AND BEST PRACTICES FOR EFFECTIVE SIMULATION-BASED MEDICAL EDUCATION 1. Feedback Knowledge of results of one's performance and feedback on performance that is constructive is the most important feature of SBME that is essential to promote effective learning. Source of feedback could be built in to the simulator, given by the instructor in real time or done as a debriefing by viewing a video of simulation-based educational activity. What is important is that it should be immediate, formative (purpose being to improve), and done as a debriefing. Salas et al., 2008,[12] recommend the best practices in feedback debriefing: "it must be diagnostic, team members must be educated about the art and science of leading team debriefs, focus on a few critical performance issues during the debriefs, support feedback with objective indicators of performance, record conclusions made and goals set during debriefing to document progress for reference during the next debriefing." There is evidence that "educational feedback slows the decay of acquired skills and allows learners to self-assess and monitor their progress toward skill acquisition and maintenance." 2. Repetitive/deliberate practice For professional skill improvement toward expertise, deliberate practice is important.[13] It requires highly motivated learners with good concentration, engagement with a well-defined learning objective or task at an appropriate level of difficulty and requires focused repetitive practice that leads to precise measurements that help in providing objective feedback from teachers or peers or trainees themselves who monitor their progress in learning. Skill repetition in practice sessions gives learners opportunity to correct errors and polish their performance and helps make their skill demonstration effortless and automatic and to reach mastery level and then move to another task. The practice "dose" is to be determined by the learner's needs and not by the instructor's demands. 3. Curriculum integration SBME, being one of the approaches to produce job-ready graduates, should not be an extraordinary or stand-alone activity. It should be built into the learner's routines and required training schedules of educational events and planned curricular learning experiences designed and directed to achieve outcome competencies and grounded in the ways learner performance is evaluated. This is important because SBME can only complement clinical education and cannot be a substitute for training grounded-in patient care in real clinical setting. Since deliberate repetitive practice for acquiring skills is optimally possible in the SBME mode, for specific skills requiring repetitive practice, medical education using simulations must be a required part of the overall curriculum since optional curricular portions do not arouse learner interest. 4. Outcome measurement Measurement of trainee competence progression is important. Learners are more likely to master key skills if outcome benchmarks are defined and appropriate for their training level prior to the simulator exercise. Defining the benchmarks to be reached by a trainee is important to measure the effectiveness of SBME. Besides, observational ratings of trainee progress are also subject to inter-observer biases and so need rater training and calibration. Defining the criteria for correct performance of activities within a professional task helps in reducing inter-rater variability and so also the reliability of self-reports or reports by peers. 5. Simulation fidelity and simulator validity There needs to be a close match between educational goals and simulation tools. Simple task trainers and devices that mimic body parts are enough for procedural skills such as suturing, lumbar puncture, and intubation. Complex clinical events training such as response to simulated hospital "codes" require more advanced systems including life-like full body mannequins. Haptic virtual reality simulators help surgeons and interventionists to acquire skills that are too dangerous to practice on real patients. A high degree of realism or fidelity provides an approximation of complex clinical situations, principles, and tasks and is essential to help learners increase their perceptual skills and to sharpen their responses to critical incidents. Although it is important to note that the desired outcome should be matched with the appropriate degree of fidelity, many competencies can be learned and mastered with relatively low-fidelity simulators. 6. Skill acquisition and maintenance Without further deliberate practice in professional setting, skill acquired through SBME tends to decay post-SBME within 3–12 months depending on the specific skill acquired, the degree of skill learning, and the time elapsed since the last learning encounter. Hence, during the SBME training period, one needs to keep the above variables in mind to determine the duration of SBME the novice or advanced beginner must go through. Helping learners master skills at increasingly difficult levels slows their deterioration of skills over time. 7. Individualized mastery learning The key benefit of competency-based medical education using deliberate practice is to attain mastery of the required professional skill. The goal of mastery learning is for all learners to achieve all objectives at mastery level. Since individuals learn at their own pace, it is important to individualize the learning experiences adapting to individual learning needs. Time taken to reach mastery level may vary from learner to learner. For ensuring that this mastery learning optimally happens, SBME should have the seven complementary features of mastery learning: (1) baseline diagnostic testing; (2) clear learning objectives sequenced as units with increasing difficulty; (3) engage in educational activities that help reach the stated objectives; (4) establishment of minimum passing standard test or checklist scores for each educational unit; (5) formative testing to determine unit completion set at a preset "minimum passing mastery" standard; (6) advancement to the next level unit upon achievement of "at or above mastery" standard; (7) continued practice on an educational unit till mastery standard is achieved. Using high-fidelity medical simulations, it is possible to achieve uniform educational outcomes despite different rates of learner educational progress. 8. Transfer to practice The skills acquired in SBME laboratory settings must translate to real clinical settings. "Simulations capable of sampling from a broad universe of patient demographics, pathologies, and responses to treatment can increase the number and variety of patients that learners encounter. Boosting the variety of simulated patients seen by learners helps to standardize the clinical curriculum across educational sites" and makes the learner more confident and capable to transfer learning to practice. This transfer of learning to practice must be observed and looked for as part of the SBME program evaluation. Deficiencies observed must be factored in to reengineer/redesign the SBME educational learning experience to make the SBME program more effective. 9. Team training Patient care outcomes being influenced by team effort, care delivery teams must practice together using SBME. The eight evidence-based critical principles for effective planning, implementation, and evaluation of team training programs[14] are: (1) identify critical teamwork competencies and use these as a focus for training content; (2) emphasize teamwork over task work, design teamwork to improve team processes; (3) "one size does not fit all," hence let the team-based learning outcomes desired and organizational resources, guide the process; (4) task exposure is not enough and so provide guided, hands-on practice; (5) the power of simulation being a great influencer, ensure training relevance appropriate to transfer environment; (6) feedback matters and so it must be descriptive, timely, and relevant; (7) go beyond learner reaction data to evaluate clinical outcomes, learning, and transfer of behaviors on the job, and (8) reinforce desired teamwork behaviors so as to sustain them through coaching and performance evaluation. 10. High-stakes testing Due to the standardization, fidelity, and reproducibility of SBME, apart from formative assessment following practice sessions to give feedback and improvement, SBME can be used for high-stakes assessment of student for certification that the student or health-care professional has attained the required level of competency (pass–fail decision) to be able to do it without risk to real patients. Such high-stakes assessment of students using SBME demands generation of highly reliable data that permit valid inferences about the competence of the health-care professional, should be acceptable to candidates and practicing professionals in the field with regard to patient safety, and should have systems in place for continuous refinement and quality improvement. 11. Instructor training This is important since the above-mentioned essential features of SBME are important, "SBME is neither easy nor intuitive, and simulation experience alone is not a proxy for simulation instructor effectiveness" and so the instructors need to become aware of these issues and processes through training. Regarding this issue, McGaghie et al.[10] reiterate that "faculty expertise in training with these devices, their motivation to succeed, the local reward system, and institutional support contribute significantly to the success or failure of SBME." 12. Educational and professional context Since SBME is expected to help the learner become job ready, the educational and professional context must be simulated (authentic) as well during the practice sessions. Schuwirth and van der Vleuten[15] second this when they state that "situations in which a candidate's competence is assessed should resemble the situation in which the competence will actually have to be used. SBME that ignores its educational and professional context for teaching, evaluation, or application in clinical practice is misdirected." Furthermore, it must be noted that "high-fidelity medical simulations that capture or represent a wide variety of patient problems or conditions are more effective than simulations having a narrow patient range. This provides more 'contextual experiences' that are critical for gaining problem-solving skills." CONCLUSION There is no doubt about the need for simulation in medical education in the competency-focused outcomes-based curriculum where competencies needed for the outcomes listed to be acquired by the Indian Medical Graduate are to be attained. However, SBME is only a supplement and does not replace the many educational methods and strategies in place in the traditional clinical setting for ensuring graduates become competent. After the learning experience using SBME to develop minimum level of competencies that are entrustable for safe care delivery, students need to further practice under supervision on real patients and service delivery systems in teams to learn to be part of and lead health-care teams in health-care delivery. For the learners, simulation-based learning experiences built into the curriculum provide the ideal opportunity to practice patient care away from the bedside, applying the principles of adult learning and the principles of deliberate practice toward knowledge and skills mastery. Building SBME into the curriculum can be achieved using the tool of curriculum mapping which helps ensure that all expected EPAs needed for the job roles the graduate of the program are identified and addressed. For the patients, having students and residents who have trained with simulation and developing a minimum competency level prior to clinical interaction with them makes them more willing to allow students to perform procedures on them after they have undergone simulation training.[16] For the institutions, pretraining in the simulator or simulated conditions prior to patient encounter addresses patient safety issues and makes them less defensive when faced by attempts by competitors driving the propaganda that "patients are being treated by students." There are various practical constraints and challenges that need to be overcome in implementing simulation training programs such as faculty time constraints, lack of faculty training, high cost of equipment, the high cost of equipment maintenance, and constraints for space needed for educational laboratories. As simulators do not replace good educators, faculty trained in solid educational principles and teaching techniques need to be identified and trained in simulation use and debriefing besides ensuring their availability in terms of some protected time away from their clinical responsibilities. To overcome this SBME faculty-related challenge standing in the way of optimal availability of simulation-based learning for students and residents, institutions must properly reward educators through promotions and compensating them with protected time to teach and do further research and engage in periodic program evaluation in this area so that quality of the simulation-based training program and its effectiveness improves. Institutions must also prioritize simulation in their hospitals as per curricular needs through curriculum mapping using their own curriculum rubric, keeping in mind the facilities and opportunities available in the wards and ambulatory settings and identifying the EPAs that require pretraining on simulators before allowing them to practice on real patients.
ER  -
TY  - JOUR
TI  - Telecommunications and the dialysis patient
PY  - 1999
PB  - Elsevier BV
SN  - 0272-6386
T2  - American Journal of Kidney Diseases
DO  - 10.1016/s0272-6386(99)70100-9
UR  - https://doi.org/10.1016/s0272-6386(99)70100-9
DA  - 1999-07-01
AU  - Winchester, James
LA  - en
VL  - 34
IS  - 1
SP  - xxxvi
EP  - xxxviii
AB  - This article outlines the current status of telemedicine and dialysis, gives an update on developments in telemedicine in general, discusses changes in the Internet that will be important to telemedicine, and points out some of the dangers associated with the Internet. Telemedicine is the remote consultation between physician and patient by means of videoconferencing. It has become commonplace for dialysis patients to communicate with their physicians by telephone and, more recently, email. Using the popular Internet search engines, WebCrawler and HotBot, I triggered 400 and 10,000 “hits,” respectively, with the search term, telemedicine; similarly, in PubMed, I found 1,506 publications, 7 of which were on dialysis. Telemedicine for the care of dialysis patients is being studied and used routinely in several centers throughout the world.1Moncrief JW Telemedicine in the care of the ESRD patient.Adv Renal Replace Ther. 1998; 5: 286-291PubMed Google Scholar Currently, computer-based, multimedia videoconferencing systems with cameras, microphones, and other devices (eg, electronic stethoscopes) are available either in the form of desktop devices or stand-alone units that can be rolled about the dialysis unit to individual treatment stations. Both systems are capable of interfacing with dialysis machines and clinical information systems to achieve a paperless medical record, which includes screen capture of vascular access images, dialysis parameter database, and so on. Most systems use dedicated high-speed leased lines to carry videoconferencing at high bandwidth; however, the changes that are about to occur to the Internet will make telemedicine much more available to the physician in the community. Today's information routing speeds range from 56 Kb/s in the plain-old telephone system (POTS), through multiples of 128 Kb/s with integrated-services digital network (ISDN), through many megabytes per second using asymmetric digital subscriber line (ASDL), to 1.54 to 45 Mb/s with T1 to T3 lines (point-to-point high-bandwidth lines). The high-speed transfer of information is necessary for seamless videoconferencing and to allow rapid transfer of large data files. ISDN, ASDL, and T1 lines are expensive to install and maintain. However, further development of the National Information Infrastructure (Internet) with increased capability is on the horizon. President Clinton, in his 1997 State of the Union address, promised an Internet running 1,000 times its current speed. Those who use the Internet know that at certain times the speed of data transfer is painfully slow; this is caused by its 400% growth per annum (50% of the US population is expected to have Internet access by the year 2000). Data-retrieval speed via POTS is limited by the speed of the modem and by the speed of the backbone that connects computers within an Internet Service Provider (ISP) complex. Sufficient funds are planned to be assigned for Next Generation Internet (NGI; ), the White House initiative linking several government agencies, including the National Library of Medicine, to speed the Internet using the high-speed backbone (very high performance backbone network service) developed by the National Science Foundation. The NGI initially was funded with $85 million and is likely to receive a further $110 million in 1999. The NGI is complementary to and interdependent on the Internet2 (I2; ) project. Both projects are charged to enhance electronic security, particularly necessary for handling medical data. I2 is also government funded, and it links 146 universities, 21 nonprofit organizations, and 16 partners in a collaborative effort to develop GigaPops (1,000 times “points of presence”), or 1,000 times the speed of an ISP. The mission of I2 is to enhance research, teaching, and learning on the high-speed backbone called Qbone. An additional stimulus to improve the Internet was made recently by Vice-President Gore when he announced funding to several government agencies, including the National Institutes of Health, to develop machines and software capable of 40 teraflops (trillion calculations per second) to speed up 21st-century information technology.2Service RF Malakoff D Gore presents plan to spend $366 million.Science. 1999; 283: 613A-614ACrossref Google Scholar The 2,300 miles of Scottish coast must have inspired Jim Winchester, a man from the land of firths and lochs. He is a visionary whose sight can focus narrowly or expand widely. In the accompanying article, he gives us his view of what the practice of nephrology might look like in the coming decades. As an honor medical student at the University of Glasgow, Winchester penned an MD thesis in the use of extracorporeal methods for the treatment of uremic and other poisonings. This was a work that defined his career choice. Trained briefly in general surgery, he proceeded to become an internist and a nephrologist. In the late 1970s, he emigrated to the United States and joined George E. Schreiner at Georgetown University's Division of Nephrology. He rapidly became known in the world of nephrology and began to assume leadership roles at Georgetown and in national and international nephrology circles. Extensive research and publication made him a leader in peritoneal dialysis, hemoperfusion, and other extracorporeal techniques in the treatment of renal insufficiency and poisoning. He has also contributed to the use of ultrasound as an assessment tool of the diseased kidney parenchyma. Winchester has been recognized with numerous honors and awards. He is listed in Who's Who in America and Who's Who in the World, as well as having been chosen as one of the best doctors in America. In 1990, he was made an Alpha Omega Alpha honor medical society member by the Georgetown University chapter. The National Kidney Foundation (NKF) has bestowed on him both the Distinguished Service Award and the President's Award for his extensive service, including a stint on the NKF Board of Directors. He was president of the American Society for Artificial Internal Organs from 1995 to 1996. In addition to being an associate editor and serving on the editorial board of the American Journal of Kidney Diseases from 1987 to 1997, he is the editor of Advances in Renal Replacement Therapy, another NKF publication. Jim Winchester is a leader in the use of informatics in the delivery of health care, particularly nephrology. This is not surprising since one of his passions is patient care and the physician–patient relationship. He is a jogger who is as efficient with a fine oil brush and canvas as he is with a peritoneal dialysis catheter and an abdomen. His accent is now sufficiently Gaelic free to allow his voice to be recognized by a computer assembled . . . possibly in Texas! Slim and fit, he relishes the gourmet meals prepared by his Scottish wife and cherishes the times with his son and daughter.—Manuel Martínez-Maldonado, MD Some problems exist in the development of telemedicine. Reimbursement for telemedicine services recently has received some relief from the Health Care Financing Administration (HCFA). Under the 1997 Balanced Budget Act, Medicare was mandated to make payments for telemedicine consultations (teleconsultations) by January 1, 1999. The HCFA final rule has allowed for payment for certain Current Procedural Terminology (CPT) codes in rural healthcare professional shortage areas (locations are strictly defined throughout the country). In addition, telemedicine consultants will be reimbursed first and, in turn, will act as a conduit for the transfer of 25% of the fees to the presenting physician. There is no payment for telecommunication costs and the providers are strictly defined. Senators Max Baucus (D-MT) and Tom Daschle (D-SD), concerned with rural health care, have introduced legislation to redress some of the flaws in the Medicare reimbursement system for telemedicine. The second issue relates to licensure of the telemedicine consultants. Current requirement demands that a physician be fully licensed in every state in which teleconsultation is performed. Senator Baucus has proposed amending the Balanced Budget Act to allow Health and Human Services to fast-track licensing across state lines by 2003, as well as “to develop uniform, national sets of standards for licensing.” This might lead to central licensure, but it must be remembered that states have financial and other interests in maintaining separate licenses for physicians. Other concerns exist in the area of Internet medical consultants (“cyberdocs”), including the advertising of bogus cures3Larkin M Internet accelerates spread of bogus cancer cure.Lancet. 1999; 353: 331Abstract Full Text Full Text PDF PubMed Scopus (11) Google Scholar and the threats to physicians whose names have been published on the web. Many foresee malpractice suits arising from the Internet. It is recommended that physicians keep printed copies of email patients. A recent Lancet article has discussed the variability of the expertise of Internet consultants (whether gratuitous or fee-for-service sites).4Eysenbach G Diepgen TL Evaluation of cyberdocs.Lancet. 1998; 352: 1526Abstract Full Text Full Text PDF PubMed Scopus (37) Google Scholar Obviously, a distant consultant could give the wrong advice and do harm; because the Internet is free ranging, another country has no jurisdiction in the country where the consultant lives. Similarly, patients can be duped into spending money for worthless “cures.” Just how to monitor this is unclear. Fortunately, watchdog groups have arisen to debunk false claims (eg, ). Are physicians in danger from the web? The answer clearly is yes. Practicing pro-choice physicians, whose names, addresses, and family members' names and schools have been published on the Internet, have believed that they were in danger to the point of wearing bullet-proof vests to work. They went to court and prevailed, winning a large money award and having their names removed from the web. Future nephrologists and all physicians probably will work in collaboration technology through the Internet. This will integrate telemedicine, informatics, and feedback systems using the new science of haptics (touch and force feedback) into virtual reality systems.5Alper J New interface makes virtual world tangible.Science. 1999; 283: 1097-1099Crossref Google Scholar This is not far fetched; researchers have already developed robotic feedback systems and even an artificial hand to manipulate instruments or tissue during surgery or other applications. Informatics and intuitive systems technology already has been used to identify bacterial organisms (through molecular biology) using multiple uniform resource locators (URLs) through the Internet.6Harmsen D Rothganger J Singer C Albert J Frosch M Intuitive hypertext-based molecular identification of microorganisms.Lancet. 1999; 353: 291Abstract Full Text Full Text PDF PubMed Scopus (57) Google Scholar In my view, over the next few years, telemedicine is likely to grow substantially from its current 1% of all consultations in the United States; Internet technology is undoubtedly going to improve; and licensing practitioners for interstate consultations might be slow, but might lead to national licensure. Oversight of care given via the Internet is definitely needed and unless the Medicare payment system for telemedicine is amended, telemedicine growth will be slow. AUTHOR'S NOTE: This article was dictated directly into the computer using speech recognition software (pretty good, but not yet perfect).
ER  -
TY  - JOUR
TI  - Virtual Reality Therapy for the Psychological Well-being of Palliative Care Patients in Hong Kong
PY  - 2022
PB  - Cornell University
T2  - arXiv (Cornell University)
DO  - 10.48550/arxiv.2207.11754
UR  - https://doi.org/10.48550/arxiv.2207.11754
DA  - 2022-01-01
AU  - Eckhoff, Daniel
AU  - Ng, Royce
AU  - Cassinelli, Álvaro
LA  - en
KW  - Reminiscence
KW  - Immersion
KW  - Metaverse
AB  - In this paper we introduce novel Virtual Reality (VR) and Augmented Reality (AR) treatments to improve the psychological well being of patients in palliative care, based on interviews with a clinical psychologist who has successfully implemented VR assisted interventions on palliative care patients in the Hong Kong hospital system. Our VR and AR assisted interventions are adaptations of traditional palliative care therapies which simultaneously facilitate patients communication with family and friends while isolated in hospital due to physical weakness and COVID-19 related restrictions. The first system we propose is a networked, metaverse platform for palliative care patients to create customized virtual environments with therapists, family and friends which function as immersive and collaborative versions of 'life review' and 'reminiscence therapy'. The second proposed system will investigate the use of Mixed Reality telepresence and haptic touch in an AR environment, which will allow palliative care patients to physically feel friends and family in a virtual space, adding to the sense of presence and immersion in that environment.
ER  -
TY  - JOUR
TI  - تقيم أسلوب واداء لعبة الواقع الافتراضي من خلال محاكتها في الحياة الصناعية
PY  - 2008
DA  - 2008-01-01
AU  - دامان, د.داود
LA  - en
VL  - 24
IS  - 234
ER  -
TY  - JOUR
TI  - Rise of Revision Arthroplasties in Indian Subcontinent: An Inadvertent Future
PY  - 2025
PB  - Indian Orthopaedic Research Group
SN  - 2250-0685
T2  - Journal of Orthopaedic Case Reports
DO  - 10.13107/jocr.2025.v15.i05.5532
UR  - https://doi.org/10.13107/jocr.2025.v15.i05.5532
DA  - 2025-01-01
AU  - Aneja, Kunal
C1  - Department of Orthopaedics, Max Super Speciality Hospital, Shalimar Bagh, New Delhi, India.
C1  - Department of Orthopaedics, Naveda Healthcare Centre, New Delhi, India.
AU  - Bajwa, Supreet
C1  - Department of Orthopaedics, Wockhardt Hospitals, Mumbai Central, Mumbai, Maharashtra, India.
AU  - Shyam, Ashok
C1  - Department of Orthopaedics, Sancheti Institute for Orthopaedics and Rehabilitation, Pune, Maharashtra, India.
C1  - Indian Orthopaedic Research Group, Thane, Maharashtra, India.
LA  - en
KW  - Avascular Necrosis
KW  - Implant Failure
VL  - 15
IS  - 5
SP  - 1
EP  - 5
AB  - Introduction In the past two decades, developing countries like India have experienced a surge in joint replacement surgeries, driven by an aging population, rising lifestyle diseases, and increased awareness of arthroplasty’s benefits. However, this growth has led to a rise in revision arthroplasties due to complications such as implant failure, infection, and malalignment, placing a strain on both patients and healthcare systems [1]. A better understanding of causes, preventive strategies, and advancements in implant technology and surgical techniques is crucial to address this issue. Understanding the Rise of Revision Arthroplasties Suboptimal implant survivorship The increasing incidence of revision arthroplasties is largely attributed to the limited longevity of implants. Contributing factors include the use of potentially less durable implants, a younger, more active patient demographic, and a high prevalence of osteoarthritis and avascular necrosis. Globally, implant survivorship typically exceeds 15–20 years, but in India, revisions are often needed within a decade due to wear, aseptic loosening, or mechanical failures [2]. Periprosthetic joint infection (PJI) PJI is among the most challenging and common complications following lower-extremity joint arthroplasty and are a leading cause of revision surgeries [1]. Reported infection rates after primary total knee arthroplasty (TKA) range from 0.51% to 1.55% [3], while for total hip arthroplasty (THA), the incidence is estimated at 0.5–0.7% within the 1st-year post-surgery. Late-onset infections present a cumulative incidence of 0.04–0.06% per prosthesis-year [4]. Alarmingly, studies from India indicate infection rates as high as 87% [1]. Aseptic loosening and wear Aseptic loosening is the leading cause of implant failure, accounting for approximately 55% of hip revisions and 31% of knee revisions [2]. Aseptic loosening is often linked to polyethylene wear, where particulate debris triggers osteoclast-mediated bone resorption, leading to periprosthetic osteolysis and eventual loosening. This issue is particularly pronounced in younger, more active patients, suggesting a rising prevalence in this population [5]. Instability and malalignment Joint instability, resulting from factors such as ligament imbalance, improper component alignment, and surgical errors, is another significant cause of revision surgeries [1]. Malalignment, particularly of the femoral component, has been strongly linked to increased revision rates [6]. Poor positioning can accelerate wear, diminish functionality, and compromise the overall outcome of the procedure. Furthermore, mechanical malalignment that fails to replicate natural joint movement can lead to long-term complications [6]. Patient-related factors The growing trend of joint replacements in younger, more active patients has been associated with increased revision rates. Elevated activity levels in this demographic often result in accelerated wear and degradation of prosthetic components [1]. Whereas, in older adults, increasing comorbidities and associated ailments are the major cause of implant failure or decreased satisfaction rate. Prevention: The Key to Curbing Revision Burden Advanced technologies Recent advancements in surgical technologies aim to improve precision and accuracy in orthopedic procedures. Innovations like patient-specific instrumentation, navigation systems, smart tools, and computer or robotic-assisted surgery enable tailored interventions based on individual anatomy and ligament characteristics. These technologies enhance 3D surgical planning, optimize implant positioning, and improve alignment precision, leading to superior outcomes [7]. Modular operating theaters (OTs) Modular OTs equipped with advanced infection control technologies significantly reduce PJI and post-operative complications. Featuring HEPA filters, laminar airflow systems, and efficient sterilization, these OTs ensure a sterile environment, enhance workflow adaptability, and contribute to better surgical outcomes [8]. Robotic-assisted arthroplasty Robotic systems have revolutionized orthopedic surgeries, by providing unmatched precision and consistency. The introduction of ROBODOC in 1992 marked a pivotal moment in robotic-assisted joint surgeries, improving bone resection accuracy and component alignment while reducing reliance on conventional cutting guides and manual positioning. Since then, robotic-assisted technologies have continuously evolved, with a primary focus on minimizing human error during surgery. Conventional robotic-assisted TKA platforms typically rely on haptic feedback and oscillating saws controlled by surgeons for bone preparation. In contrast, the novel MISSO active robotic system (Meril Healthcare Pvt. Ltd., Vapi, India) represents a significant leap forward with its fully automated approach. This cutting-edge system integrates artificial intelligence and machine learning to enhance both pre-operative planning and intraoperative execution. By utilizing patient-specific computed tomography data, MISSO generates precise 3D bone models and personalized surgical plans tailored to individual anatomical variations [9]. The system’s real-time guidance ensures optimal prosthetic alignment and precise bone cuts, improving surgical accuracy, preserving soft tissues, and reducing the risk of complications. In addition, MISSO’s virtual simulation capability allows surgeons to rehearse procedures on 3D bone models, ensuring sub-millimetric precision during surgery. By automating complex tasks, the system enhances soft tissue management, minimizes collateral damage, and accelerates recovery, contributing to improved long-term patient outcomes. Surgeon training and mentorship Specialized training programs are crucial for equipping surgeons with the skills needed to adopt advanced technologies in orthopedic care. Organizations like Meril Life Sciences and Johnson and Johnson provide comprehensive educational frameworks that include live surgeries, hands-on workshops, cadaveric labs, and virtual reality (VR) simulations [10]. These programs emphasize key aspects such as patient selection, robotic system utilization, and complication management, enhancing surgical precision and decision-making. Mentorship is a cornerstone of these initiatives, with expert surgeons leading case discussions and offering real-time feedback. Virtual mentorship and remote collaborations further enhance accessibility, fostering peer connections and promoting global knowledge-sharing. VR simulations and cadaveric training allow surgeons to practice complex procedures, accelerating their learning curve and building confidence in robotic-assisted surgeries. By combining hands-on training with mentorship and cutting-edge simulations, these programs ensure that surgeons remain proficient, improving surgical outcomes and optimizing the use of innovative technologies. Patient education and engagement Patients may be hesitant to embrace robotic total joint arthroplasty (rTJA), often due to misperceptions about the technology. Common concerns include potential robotic malfunctions causing harm, incorrect procedures, inadequate surgeon training, high costs, and prolonged surgical times. Only half of surveyed patients fully understood the robot’s role in rTJA [11]. Tailored pre-operative counseling can address individual concerns, improve shared decision-making, and identify patients most likely to benefit from rTJA. In addition, factors such as education, income, and age may influence patient understanding and acceptance of such innovations, with marketing campaigns potentially increasing interest and preference for rTJA. Implant innovations: The game changers In revision THA, tapered fluted titanium stems, both Modular and Monoblock, are essential for managing bone loss and restoring hip function. The Wagner Cone Prosthesis (Zimmer Biomet), introduced in the 1980s, was a pivotal innovation but faced limitations like subsidence and dislocation [12]. Modern modular systems, such as the S-ROM Modular Hip System (DePuy Synthes Johnson and Johnson, Warsaw, IN, USA), offer proximal fixation with a porous-coated sleeve and intraoperative adjustability to correct femoral anteversion and leg length discrepancies [13]. The RECLAIM™ (DePuy Synthes Johnson and Johnson, Warsaw, IN, USA) [14] and Restoration® Modular Systems ((Stryker, Kalamazoo, MI USA) [15] provide distal fixation and modular reconstruction for significant femoral bone loss, while the Exeter® V40 Cemented Stem (Stryker, Kalamazoo, MI, USA) [16] ensures long-term durability with its double-tapered design. Innovations like the Latitud MonoMod Stem (Meril Healthcare Pvt. Ltd, India) merge modular flexibility with Monoblock durability to optimize joint stability in complex cases [17]. In revision TKA, modern rotating hinge knee systems, such as the NexGen LCCK (Zimmer Biomet), provide rotational flexibility and joint stabilization in severe ligamentous instability [18, 19]. The TC3® System (DePuy Synthes Johnson and Johnson, Warsaw, IN, USA) [20] and Freedom PCK® System (Meril Healthcare Pvt. Ltd, India) [21] use modular augments and condylar blocks for severe bone loss while balancing flexion laxity and extension stability. The DESTIKNEE® (Meril Healthcare Pvt. Ltd, India) supports high-flexion motion with minimal bone resection, and the Opulent™ Total Knee System (Meril Healthcare Pvt. Ltd, India) features TiNbN-coated components to reduce metal ion release and infection risks [22, 23]. DePuy Synthes’ Attune® Revision Knee System employs an S-curve cam to optimize femoral rollback and patellofemoral tracking [24], while Zimmer Biomet’s LPS-Flex Mobile Bearing Knee accommodates deep flexion (up to 155°) supported by an enhanced cam/spine mechanism, catering to patients with specific physical or cultural needs [25]. Bone deficiency solutions, such as Trabecular Metal Cones (Zimmer Biomet) and Restoration Tritanium Cones (Stryker Kalamazoo, MI, USA), promote osseointegration and address metaphyseal defects [26, 27]. In addition, systems like G7® Acetabular System (Zimmer Biomet) and dual-mobility acetabular cups (Zimmer Biomet, DePuy Synthes) offer enhanced stability and lower dislocation risk in hip revisions, particularly for patients with prior trauma or neuromuscular disorders [28,29]. These innovations collectively increase implant longevity and address complex revision scenarios in both THA and TKA. The road ahead: Balancing cost and accessibility The integration of advanced implants and robotic-assisted technologies is crucial for improving arthroplasty outcomes, yet economic constraints often limit their widespread adoption. To combat this, collaboration among healthcare providers, policymakers, and manufacturers is essential to develop cost-effective solutions. Initiatives such as public-private partnership, subsidies, and targeted investments in training and research can bridge the gap between innovation and affordability. The development of modular implants and accessible robotic platforms, along with streamlined training programs, can further enhance the global reach of advanced arthroplasty care. Conclusion The increasing prevalence of revision surgeries in orthopedics underscores the importance of a comprehensive strategy to optimize primary procedures and minimize failures. Addressing key factors such as component malalignment, bone loss, infection, and implant wear involves adopting a multipronged approach that integrates advanced implant designs, robotic-assisted surgery, and improved perioperative protocols. Standardizing pre-operative planning, improving surgical precision, and fostering research on long-term implant performance are pivotal in achieving durable outcomes. In addition, continuous investment in surgeon education and the development of modular operating systems can further reduce revision rates. By prioritizing innovations, collaboration, and data-driven improvements, the orthopedic community can significantly reduce the burden of revision arthroplasties and improve long-term patient outcome globally.
ER  -
TY  - BOOK
TI  - Virtual Environments 2000: Proceedings of the Eurographics Workshop in Amsterdam, The Netherlands, June 1-2, 2000
PY  - 2000
DA  - 2000-05-19
AU  - Mulder, Jurriaan
AU  - van Liere, Robert
LA  - en
KW  - Workbench
ER  -
TY  - JOUR
TI  - Low-cost VR Collaborative System equipped with Haptic Feedback
PY  - 2019
PB  - Cornell University
T2  - arXiv (Cornell University)
DO  - 10.48550/arxiv.1903.01219
UR  - https://doi.org/10.48550/arxiv.1903.01219
DA  - 2019-01-01
AU  - Benbelkacem, Samir
C1  - CDTA
AU  - Bellarbi, Abdelkader
C1  - CDTA
AU  - Zenati-Henda, Nadia
C1  - CDTA
AU  - Bentaleb, Ahmed
AU  - Bellabaci, Ahmed
AU  - Otmane, Samir
LA  - en
AB  - In this paper, we present a low-cost virtual reality (VR) collaborative system equipped with a haptic feedback sensation system. This system is composed of a Kinect sensor for bodies and gestures detection, a microcontroller and vibrators to simulate outside interactions, and smartphone powered cardboard, all of this are put into a network implemented with Unity 3D game engine. CCS CONCEPTS $\bullet$ Interaction paradigms $\rightarrow$ Virtual reality; Collaborative interaction; $\bullet$ Hardware $\rightarrow$ Sensors and actuators; Wireless devices; KEYWORDS collaborative virtual reality, haptic feedback system.
ER  -
TY  - JOUR
TI  - Low-cost VR Collaborative System equipped with Haptic Feedback
PY  - 2019
DA  - 2019-03-01
AU  - Benbelkacem, Samir
C1  -  CDTA
AU  - Bellarbi, Abdelkader
C1  -  CDTA
AU  - Zenati-Henda, Nadia
C1  -  CDTA
AU  - Bentaleb, Ahmed
C1  - Institute of Electrical and Electronic Engineering (IGEE), Boumerdes, Algiers
AU  - Bellabaci, Ahmed
C1  - Institute of Electrical and Electronic Engineering (IGEE), Boumerdes, Algiers
AU  - Otmane, Samir
C1  - University of Evry, Paris, France
LA  - en
KW  - Game engine
ER  -
TY  - JOUR
TI  - Proceedings of the 18th ACM symposium on Virtual reality software and technology
PY  - 2012
T2  - Virtual Reality Software and Technology
DA  - 2012-12-10
AU  - Green, Mark
C1  - University of Ontario Institute of Technology (Canada)
AU  - Stuerzlinger, Wolfgang
C1  - York University , Toronto Canada
AU  - Latoschik, Marc
C1  - University of Wurzburg (Germany)
AU  - Kapralos, Bill
C1  - University of Ontario Institute of Technology (Canada)
LA  - en
KW  - Presentation (obstetrics)
ER  -
TY  - JOUR
TI  - &lt;title&gt;Comparative study on collaborative interaction in non-immersive and immersive systems&lt;/title&gt;
PY  - 2007
PB  - SPIE
SN  - 0277-786X
T2  - Proceedings of SPIE, the International Society for Optical Engineering/Proceedings of SPIE
DO  - 10.1117/12.733654
UR  - https://doi.org/10.1117/12.733654
DA  - 2007-08-29
AU  - Shahab, Qonita
C1  - Korea Institute of Sci & Tech (South Korea)
AU  - Kwon, Yong-Moo
C1  - Korea Institute of Sci & Tech (South Korea)
AU  - Ko, Heedong
C1  - Korea Institute of Sci & Tech (South Korea)
AU  - Mayangsari, Maria
C1  - Korea Institute of Sci & Tech (South Korea)
AU  - Yamasaki, Shoko
C1  - Oita University, Japan.
AU  - Nishino, Hiroaki
C1  - Oita University, Japan.
LA  - en
ER  -
TY  - JOUR
TI  - Special Issue Commemorating the 25th Anniversary of the ASME CIE Division
PY  - 2005
PB  - ASM International
SN  - 1530-9827
T2  - Journal of Computing and Information Science in Engineering
DO  - 10.1115/1.2031087
UR  - https://doi.org/10.1115/1.2031087
DA  - 2005-08-26
AU  - Shah, Jami
C1  - Engineering of Matter, Transport and Energy, School for (SEMTE)
AU  - Lee, David
LA  - en
VL  - 5
IS  - 3
SP  - 169
EP  - 170
AB  - We are pleased to bring out this special issue of JCISE to provide both a retrospective and a snapshot of key areas in computing and information science as they relate to electro-mechanical product development. We invited some of the leading researchers from areas of current interest to write survey articles about their respective fields. While this issue does not cover all of the areas encompassed by CIE, either from a historical perspective or at the current evolutionary point of the Division, it offers a unique view of what is quintessential to the technical domain of CIE.Over the past 25 years, computers have revolutionized not only all types of products and services, but also the way engineering products are designed and produced. This has created a societal transformation of a magnitude not seen since the industrial revolution. Twenty-five years ago, visionaries such as Ali Seireg, Irwin Berman, L. Eugene Hulbert, T. James Cokonis, Jim Callahan, Terry Shoup, Vijay Tipnis, Ewald Heer, Don Riley, David Dietrich, Steve Rohde, and Gopal Gupta recognized the potential profound impact of computers on the mechanical engineering profession when they created a new Division at the 100th Anniversary mark for ASME.The Computer Engineering Division was founded to provide a forum for mechanical engineers and people from related fields to exchange ideas, advance the technology and its applications to their respective problems, and to keep abreast of the latest developments. Over the past 25 years, the division has grown and evolved to become what is now known as the Computers and Information in Engineering (CIE) Division. By hosting an annual conference since its founding, the papers published in the proceedings of the CIE Conferences provide a road map of the development and maturation of computing systems in mechanical engineering.We have reviewed the proceedings of the CIE Conferences from 1980 up to 2004 in order to identify areas in which the CIE community has been most active. The wide range of research areas and applications published and presented, such as CAD/CAM, robotics, controls, dynamics, thermofluids, FEA, and many others provides an interesting perspective to see how CIE has evolved over the years.At the first conference in 1980, the papers covered the full spectrum of computing platforms, from calculators to mainframes. While many papers during the early years focused on the numerical results generated from programs written to run on the multiplicity of platforms, a large number of authors brought new technologies to bear on harnessing computational capability for providing new insight into engineering problems. These included the application of graphical interfaces and standards as well as concepts developed in computer and information sciences such as knowledge-based systems and computational geometry.Coverage of robot off line planning, geometric pattern recognition algorithms and automated methods for finite element generation were a mainstay of work published throughout the 1980s. The first papers on Expert Systems appeared in 1984, followed by enough papers to fill several sessions in the following year. These simplistic expert systems were directed at very specific problems, such as V-belt design, 4-bar linkages, spur gears, etc. Papers on solid modeling appeared in 1984–1985 also, including a paper on a graphical front end to PADL-2.When solid modeling first became available, many deemed it unusable because of the difficulty of editing models. CIE researchers were at the forefront of technologies that made parametric-based CAD possible, such as associativity and constraint solving, features and part positioning in assemblies. Evidence of this can be found as far back as 1986. Parametric CAD is surveyed by Hoffman in this issue and the challenges faced in developing and using this technology show that there continue to be many unresolved issues in this area.In the mid and late 1980s, Feature Technology went on to become one of the most popular research areas in CIE; this includes design by features, feature recognition and feature-based applications particularly in manufacturing. The article by Corney, Hayes, Sundarajan and Wright looks specifically at the role of features in integrating CAD and CAM and the broader issues of generalized feature classes, feature interaction and process specific feature relations.Towards the end of the 1980s and into the 1990s, people became concerned with scalability, robustness and inter-operability. The influence of standards such as IGES, GKS, PHIGS, STEP, PDES, and many others that were begun in this time frame, echo through the debates of the current day of open standards and open source. Also, there was a trend from focusing on specific applications (point solutions) to more domain independent systems, of which DOMINIC is a good example.In this time period, there was a great deal of activity in data and information issues in engineering. Issues being investigated included PDM (Product Data Management) and data exchange standards for geometry and features. Much of this was motivated by the desire to create concurrent engineering and collaborative design frameworks. Interest in modeling supply chains and LCA (Life Cycle Engineering) began to develop. Two articles in this issue deal with these topics. Rangan, Rhode, Peak, Chada, and Bliznakov give a review of the current state of PLM. Sriram, Fenves, Subrahmaniam and Rachuri discuss a broader vision of product data exchange.The availability of the Internet to the general public in the mid 1990s, opened up many new possibilities for collaboration, services and information exchange. A part of CIE became focused on Internet-based design and commerce. Also, in the late 1990s, virtual reality and haptics made it possible to create completely new immersive CAD/CAE environments.Today we find engineers trying to push computers further upstream in the design process, as well as further downstream. Upstream areas include tasks at conceptual design stage. Functional and behavior models are being developed, as well as ontologies. Design synthesis methods are discussed in the survey article by Cagan, Campbell, Finger and Tomiyama. Another area of current interest is design repositories, methods to store, index, and retrieve design data, including CAD models and design rationale.There is also on-going research in creating a seamless integration between design and analysis through multi-physics simulation and virtual prototyping. The survey article in this issue by John Michopolous describes this area. Another CAE topic, structural optimization, is reviewed by Saitou, Nishiwaki, Izui, and Papalambros.Detailed design has evolved from the “over-the-wall” methods to performing DFM (Design for Manufacturing) and tolerance analysis as early as possible. While the number of people working on GD&T is small, many papers on this topic have appeared all through the years of CIE Conferences. Shen, Ameta, Shah and Davidson compare computer aided tolerance analysis methods currently available commercially.Ever present throughout the 24 years of the Conferences, the CIE community has focused on the effective integration and use of CAD/CAM/CAE in education. Articles in CIE on the use of computers in education began at the first conference in 1980 and have evolved to match the product-centric design methods of today. Rosen, Kinzel and Khosrowjerdi provide a nice survey of how our curriculums have developed over the years.We thank the authors for their contributions to this special issue and wish to congratulate the CIE Division, its Conferences, as well as ASME as each celebrates its own extra special anniversary in 2005.
ER  -
TY  - JOUR
TI  - [Front matter]
PY  - 2014
DO  - 10.1109/have.2014.6954321
UR  - https://doi.org/10.1109/have.2014.6954321
DA  - 2014-10-01
LA  - en
SP  - vii
EP  - xlii
AB  - Since its inauguration in 2002 in Ottawa, Canada, the IEEE International Symposium on Haptic Audio-Visual Environments and Games (HAVE) has been the international forum for all aspects of multimodal haptic audio-visual virtual environment technologies and related haptic applications, including but not limited to: haptic sensors and renderers, hapto-audio-visual systems and applications, Hapto-surgical/medical systems, haptic compression and prediction, multimodal perception and psychophysics, haptic game interfaces, tele-haptics and tele-operation, augmented and virtualized reality, collaborative virtual environments, human-computer interaction in virtual environments, multi-sensor data fusion, object modeling, soft computing techniques, etc.This year, HAVE 2014 is taking place at The University of Texas at Dallas, Texas, on October 10-11, 2014.It is a forum for paper contributions from researchers, practitioners, and developers to explore and disseminate cutting-edge ideas and results, and to exchange techniques, tools, and experiences.We have compiled a diverse and inspiring scientific program with 23 technical papers selected for presentation at the symposium.This year, we introduced a doctoral consortium where PhD students present their ongoing research.
ER  -
TY  - JOUR
TI  - FULL PAPER ONLY: Virtual Reality and Extended Reality for training of operators
PY  - 2024
SN  - 2771-0718
T2  - AHFE international
DO  - 10.54941/ahfe1005686
UR  - https://doi.org/10.54941/ahfe1005686
DA  - 2024-01-01
AU  - Ferraro, Alessandra
AU  - Freda, Daniela
AU  - Pirozzi, Marco
AU  - Palermo, Eduardo
AU  - Di Donato, Luciano
LA  - en
KW  - Immersion
VL  - 159
ER  -
TY  - JOUR
TI  - Advancing Medical Education: Exploring Virtual Dissection Tables and Skill Labs for Innovative Visualisation and Simulation Techniques
PY  - 2025
SN  - 2583-6609
T2  - Central India Journal of Medical Research
DO  - 10.58999/cijmr.v4i01.203
UR  - https://doi.org/10.58999/cijmr.v4i01.203
DA  - 2025-04-18
AU  - Bokil, Prasad
AU  - Relekar, Aparna
AU  - Nandy, Rounok
AU  - Nishanth, R.
AU  - Yadav, Pallavi
AU  - Das, Dillip
LA  - en
VL  - 4
IS  - 01
SP  - 24
EP  - 28
ER  -
TY  - JOUR
TI  - Desarrollo de Aplicaciones de Realidad Virtual y Sistemas Hápticos en Ingeniería, Medicina y Arte.
PY  - 2014
DA  - 2014-01-01
AU  - Medellín-Castillo, Hugo
C1  - Universidad Autónoma de San Luis Potosí
AU  - González, Germánico
AU  - Castañeda, Raquel
AU  - Govea, Eder
AU  - Lim, Theodore
LA  - en
KW  - Instructional simulation
KW  - Virtual world
SP  - 77
EP  - 93
ER  -
TY  - GEN
TI  - Communication Cues in Augmented Remote Collaboration
PY  - 2024
DO  - 10.1002/9781119719830.ch3
UR  - https://doi.org/10.1002/9781119719830.ch3
DA  - 2024-05-24
LA  - en
SP  - 41
EP  - 80
ER  -
TY  - JOUR
TI  - Body Architectures Real time data visualization and responsive immersive environments
PY  - 2019
SN  - 2318-6968
T2  - Blucher Design Proceedings
DO  - 10.5151/proceedings-ecaadesigradi2019_645
UR  - https://doi.org/10.5151/proceedings-ecaadesigradi2019_645
DA  - 2019-12-01
AU  - Diniz, Nancy
C1  - Central Saint Martins, University of the Arts London
AU  - Melendez, Frank
C1  - City College New York
AU  - Boonyapanachoti, Woraya
C1  - Kabaq 3D Technologies
AU  - Morales, Sebastián
C1  - Research Fellow New York University
LA  - en
SP  - 739
EP  - 748
AB  - This project sets up a design framework that promotes augmenting the humanbody's interactions exploring methods for merging and blending the users ofphysical and virtual environments, through the design of wearable devices thatare embedded with sensors and actuators. This allows for haptic and visualfeedback through the use of data that reflects changes in the surrounding physicalenvironment, and visualized in the immersive Virtual Reality (VR) environment.We consider the Body Architectures project to serve as mechanisms foraugmenting the body in relation to the virtual architecture. These wearabledevices serve to bring a hyper-awareness to our senses, as closed-loop cyberneticsystems that utilize `digitized' biometric and environmental data through the useof 3D scanning technologies and cloud point models, virtual reality visualization,sensing technologies, and actuation. The design of Body Architectures relies onhybrid design, transdisciplinary collaborations, to explore new possibilities forwearable body architectures that evolve human-machine-environmentinteractions, and create hyper awareness of the temporal, atmospheric qualitiesthat make up our experience of space, as `sensorial envelopes' (Lally 2014).
ER  -
TY  - JOUR
TI  - https://researchopenworld.com/virtual-reality-based-training-environments-for-orthopedic-surgery/#
PY  - 2018
DO  - 10.31038/srr.2018113
UR  - https://doi.org/10.31038/srr.2018113
DA  - 2018-11-22
AU  - Cecil, J.
C1  - Center for Cyber Physical Systems, Computer Science Department, Oklahoma State University, Stillwater, Oklahoma, USA
AU  - Gupta, Avinash
C1  - Center for Cyber Physical Systems, Computer Science Department, Oklahoma State University, Stillwater, Oklahoma, USA
AU  - Pirela-Cruz, Miguel
C1  - Burrell College of Medicine, New Mexico State University, Las Cruces, New Mexico, USA
LA  - en
VL  - 1
IS  - 1
AB  - In recent years, Virtual Reality based platforms and technologies have come to play a key role in supporting training of medical residents and doctors in medicine including surgery.The focus of this paper is to discuss several platforms including haptic, Virtual Reality, Mixed Reality and distributed collaborative web based cyber training technologies.The design and role of these simulators in the context of two surgical procedures (LISS plating and Condylar plating surgery) is discussed for training application contexts.These surgical procedures are performed to treat the fractures of the femur bone.A comparison of these simulation technologies including emerging low cost platforms are discussed along with an overview of the impact of using such cyber based approaches on medical training.
ER  -
TY  - JOUR
TI  - From medical imaging to virtual reality for archaeology
PY  - 2023
PB  - Cornell University
T2  - arXiv (Cornell University)
DO  - 10.48550/arxiv.2301.11006
UR  - https://doi.org/10.48550/arxiv.2301.11006
DA  - 2023-01-01
AU  - Nicolas, Théophane
C1  - Inrap - Institut national de recherches archéologiques préventives (121 rue d'Alésia
75014 Paris  - France)
C1  - Trajectoires - UMR 8215 (9 rue Malher, 75004 Paris - France)
AU  - Gaugne, Ronan
C1  - Hybrid - 3D interaction with virtual environments using body and mind (Campus de Beaulieu 35042 Rennes cedex - France)
C1  - IRISA - Institut de Recherche en Informatique et Systèmes Aléatoires (Avenue du général Leclerc
Campus de Beaulieu 
35042 RENNES CEDEX - France)
C1  - UR - Université de Rennes (Campus de Beaulieu, 263 avenue Général Leclerc, CS 74205, 35042 RENNES CEDEX - France)
AU  - Arnaldi, Bruno
C1  - Hybrid - 3D interaction with virtual environments using body and mind (Campus de Beaulieu 35042 Rennes cedex - France)
C1  - INSA Rennes - Institut National des Sciences Appliquées - Rennes (20, avenue des Buttes de Coësmes - CS 70839 - 35708 Rennes cedex 7 - France)
C1  - IRISA - Institut de Recherche en Informatique et Systèmes Aléatoires (Avenue du général Leclerc
Campus de Beaulieu 
35042 RENNES CEDEX - France)
AU  - Gouranton, Valérie
C1  - Hybrid - 3D interaction with virtual environments using body and mind (Campus de Beaulieu 35042 Rennes cedex - France)
C1  - INSA Rennes - Institut National des Sciences Appliquées - Rennes (20, avenue des Buttes de Coësmes - CS 70839 - 35708 Rennes cedex 7 - France)
C1  - IRISA - Institut de Recherche en Informatique et Systèmes Aléatoires (Avenue du général Leclerc
Campus de Beaulieu 
35042 RENNES CEDEX - France)
LA  - en
KW  - Modalities
AB  - The IRMA project aims to design innovative methodologies for research in the field of historical and archaeological heritage based on a combination of medical imaging technologies and interactive 3D restitution modalities (virtual reality, augmented reality, haptics, additive manufacturing). These tools are based on recent research results from a collaboration between IRISA, Inrap and the company Image ET and are intended for cultural heritage professionals such as museums, curators, restorers and archaeologists.
ER  -
TY  - JOUR
TI  - Scene Synchronization for Real-Time Interaction in Distributed Mixed Reality and Virtual Reality Environments
PY  - 2018
PB  - Cornell University
T2  - arXiv (Cornell University)
DA  - 2018-12-08
AU  - Hamza-Lup, Felix
C1  - School of Electrical Engineering and Computer Science|University of Central Florida
AU  - Rolland, Jannick
C1  - School of Electrical Engineering and Computer Science & School of Optics-CREOL, University of Central Florida#TAB#
LA  - en
KW  - Interactivity
KW  - Synchronization networks
ER  -
TY  - JOUR
TI  - Scene Synchronization for Real-Time Interaction in Distributed Mixed Reality and Virtual Reality Environments
PY  - 2018
PB  - Cornell University
T2  - arXiv (Cornell University)
DO  - 10.48550/arxiv.1812.03322
UR  - https://doi.org/10.48550/arxiv.1812.03322
DA  - 2018-01-01
AU  - Hamza-Lup, Felix
AU  - Rolland, Jannick
LA  - en
KW  - Interactivity
KW  - Synchronization networks
AB  - Advances in computer networks and rendering systems facilitate the creation of distributed collaborative environments in which the distribution of information at remote locations allows efficient communication. One of the challenges in networked virtual environments is maintaining a consistent view of the shared state in the presence of inevitable network latency and jitter. A consistent view in a shared scene may significantly increase the sense of presence among participants and facilitate their interactivity. The dynamic shared state is directly affected by the frequency of actions applied on the objects in the scene. Mixed Reality (MR) and Virtual Reality (VR) environments contain several types of action producers including human users, a wide range of electronic motion sensors, and haptic devices. In this paper, the authors propose a novel criterion for categorization of distributed MR/VR systems and present an adaptive synchronization algorithm for distributed MR/VR collaborative environments. In spite of significant network latency, results show that for low levels of update frequencies the dynamic shared state can be maintained consistent at multiple remotely located sites.
ER  -
TY  - CHAP
TI  - An Experimental Study on CHVE's Performance Evaluation
PY  - 2012
PB  - IOS Press
SN  - 0926-9630
T2  - Studies in health technology and informatics
DO  - 10.3233/978-1-61499-022-2-328
UR  - https://doi.org/10.3233/978-1-61499-022-2-328
DA  - 2012-01-01
AU  - V.F., Paiva
AU  - S., Machado
AU  - C., Oliveira
LA  - en
ER  -
TY  - JOUR
TI  - Interacción 3D y Realidad Virtual en la Universidad de Málaga. Presentación del grupo 3DI-DIANA
PY  - 2020
DA  - 2020-01-07
AU  - Reyes‐Lecuona, Arcadio
C1  - UNIVERSIDAD DE MÁLAGA
AU  - Molina-Tanco, Luis
C1  - UNIVERSIDAD DE MÁLAGA
AU  - Cuevas-Rodríguez, María
C1  - UNIVERSIDAD DE MÁLAGA
AU  - González-Toledo, Daniel
C1  - UNIVERSIDAD DE MÁLAGA
LA  - es
KW  - Persona
VL  - 1
IS  - 1
SP  - 85
EP  - 88
ER  -
TY  - JOUR
TI  - Proxy Importance Based Haptic Retargeting With Multiple Props in VR
PY  - 2024
PB  - Institute of Electrical and Electronics Engineers
SN  - 1077-2626
T2  - IEEE Transactions on Visualization and Computer Graphics
DO  - 10.1109/tvcg.2024.3392743
UR  - https://doi.org/10.1109/tvcg.2024.3392743
DA  - 2024-01-01
AU  - Liu, Ziming
C1  - Peng Cheng Laboratory, Shenzhen, China
C1  - State Key Laboratory of Virtual Reality Technology and Systems
AU  - Wu, Jian
C1  - Peng Cheng Laboratory, Shenzhen, China
C1  - State Key Laboratory of Virtual Reality Technology and Systems
AU  - Wang, Lili
C1  - Peng Cheng Laboratory, Shenzhen, China
C1  - State Key Laboratory of Virtual Reality Technology and Systems
AU  - Li, Xiangyu
C1  - Peng Cheng Laboratory, Shenzhen, China
C1  - State Key Laboratory of Virtual Reality Technology and Systems
AU  - Im, Sio‐Kei
C1  - Macao Polytechnic University, Macao, China
LA  - en
KW  - Retargeting
KW  - Proxy (statistics)
SP  - 1
EP  - 16
ER  -
TY  - JOUR
TI  - Enhancing Human-Computer Interaction in Augmented Reality (AR) and Virtual Reality (VR) Environments: The Role of Adaptive Interfaces and Haptic Feedback Systems
PY  - 2024
SN  - 2822-6607
T2  - Human computer interaction.
DO  - 10.62802/jfxtjt43
UR  - https://doi.org/10.62802/jfxtjt43
DA  - 2024-11-11
AU  - Tunçel, Kaya
LA  - en
KW  - Immersion
KW  - Stereotaxy
VL  - 8
IS  - 1
SP  - 9
EP  - 9
ER  -
TY  - JOUR
TI  - Foreword: The Next Era of Assessment and Precision Education
PY  - 2023
PB  - Lippincott Williams & Wilkins
SN  - 1040-2446
T2  - Academic Medicine
DO  - 10.1097/acm.0000000000005609
UR  - https://doi.org/10.1097/acm.0000000000005609
DA  - 2023-12-18
AU  - Schumacher, Daniel
AU  - Santen, Sally
AU  - Pugh, Carla
AU  - Burk‐Rafel, Jesse
LA  - en
KW  - Thematic Analysis
VL  - 99
IS  - 4S
SP  - S1
EP  - S6
AB  - This supplement offers a vision for the next era of medical education assessment that centers on why assessment is done, namely, to ensure that learners achieve the learning outcomes that prepare them to provide high-quality, equitable patient care.1 Equitable care is defined as providing care that does not vary in quality because of personal characteristics such as gender, ethnicity, geographic location, and socioeconomic status.2 To achieve these learning outcomes, this supplement proposes an era of assessment that centers around developing and implementing a precision education (PE) system that uses data and technology to transform lifelong learning by improving personalization, efficiency, and learner agency.3 Articles in the supplement explore 3 thematic areas: 1) A vision for assessment and patient care that is personalized, supportive, high-quality, and equitable; 2) Foundations for using data and technology to transform and personalize efficient and effective assessment and lifelong learning; and 3) Examples using data and technology to transform and personalize efficient and effective assessment and learning. Answering the Call of Competency-Based Medical Education Competency-based medical education (CBME) has recently shifted from a preponderance of theoretical discussions with limited meaningful pilots4–6 to multiple large-scale national implementation efforts in several countries and specialties.7,8 At its core, CBME can be defined by 2 concepts: patient-focused and learner-centered.9–11 CBME starts with the end in mind—what do patients and populations need? With the answer to this in hand, CBME defines training outcomes that align with those patient needs and then designs curricula and assessments to ensure those training outcomes are met.10 The curricula and assessments—in fact, the whole of the training programs—should be learner-centered in CBME and place learners in control of their educational process. The environment they are learning in should help them take the next steps in their development, intentionally sequencing competencies and skills over time.9,11 Despite these lofty goals, individuals graduate from training programs with gaps in their basic ability to provide the care that patients need,12–15 resulting in low-quality16,17 and inequitable care.18 There are multiple root causes contributing to this chasm between the current state of medical education and the goals of CBME, including under-resourcing of training programs and use of assessment practices that are not learner-centered and have unwanted variability.19,20 A fundamentally different system of assessment is needed to ensure learners take the assured, successive steps in their development toward providing the care their patients will need. Envisioning the Next Era of Assessment and PE Building on prior work,21 Desai and colleagues advance a conceptual framework for PE that involves applying advanced analytics to multimodal data inputs to generate insights that can then be used to drive precision interventions.3Outcomes are assessed assiduously, gaps are reassessed, and the "cycle" repeats. These cycles can occur at multiple levels22—individuals, teams, programs, or organizations—reflecting contemporary conceptualizations of outcomes assessment and systems thinking.23–25 If PE initially sounds similar to other improvement models, such as the master adaptive learner (MAL) cycle or continuous quality improvement,26,27 that is by design. PE intentionally seeks to build upon these proven frameworks as well as systems science to improve the care learners provide through cycles of inputs, insights, interventions, and outcomes. As the nascent PE framework evolves, it will need continual enhancement and refinement from the medical education community. At the same time, PE also moves medical education in a number of bold new directions described by authors in this supplement, which we explore thematically next. High-quality equitable care through high-quality equitable learner assessment While previous eras of assessment in medical education were defined by how assessment was done, Schumacher and colleagues argue that the next era of assessment must be defined by why assessment is done: to ensure high-quality, equitable patient care.1 We must agree that high-quality care is equitable care—and make this the North Star of PE. Foregrounding health equity across all elements of the PE cycle will require critical reappraisal of systemic racism and harmful bias and inequity that are deeply ingrained in medicine.28 In our view, all inequity is unfair and unjust and must be addressed. Unfortunately, harmful bias and inequity are too often "woven into the fabric"29 of assessment efforts as well.29–32 Thus, high-quality, equitable learner assessment is needed—that is, "all [learners] have fair and impartial opportunities to learn, be evaluated, coached, graded, advanced, graduated, and selected for subsequent opportunities based on their demonstration of achievements that predict future success in the field of medicine, and that neither learning experiences nor assessments are negatively influenced by structural or interpersonal bias related to personal or social characteristics of learners or assessors."33 Marcotte and colleagues note that transparency in assessment development and implementation is an important means to achieve this goal.34 Weaving equity into the fabric of emerging novel assessment efforts will require cocreation with learners, from concept to design and implementation to maintenance.34,35 Likewise, anchoring assessment around patient care requires we engage patients and families, yet only a few efforts have detailed meaningful engagement of patients and families in assessment efforts.36–38 To better understand how equity affects PE systems, we asked all authors contributing papers to this supplement to foreground equity and engage trainees in codevelopment of papers. This was variably achieved, which served as a reminder of ever-present limitations and difficulties likely reflecting structural challenges—underrepresentation in medical education; siloing of colleagues who promote diversity, inclusion, and belonging; and marginalization of trainees from the very work that is for them and about them. As a field, medical education has a long way to go. Rethinking our structural approach to programs of assessment and engaging diverse learners and patients in coproduction will not prevent events where harmful bias, inequity, or lack of fairness arises. An apt example would be a frontline clinician-educator entering narrative comments for clerkship students that use language perpetuating bias or inequity based on gender or race, and these comments getting propagated into students' residency applications. To address this, Thoma and colleagues note how powerful new artificial intelligence (AI) tools are emerging that can prompt assessors in real time when potentially biased language is detected.39 Such approaches must be prioritized and resourced. Scalable precision assessment: high-density, learner-attributable performance data In the PE model, data are the essential currency. Learners and patients own their data, which should cross arbitrary silos of training or clinical care. By establishing ethical principles and enforcing interoperability standards, learner and patient data can flow across the various entities and products that exist in our fragmented medical education ecosystem.3,40 To achieve the precision necessary to drive proactive, targeted interventions that are predictive of high-quality equitable care, the density (quantity) and quality of data we collect about learners must be increased. This prospect is daunting, as existing CBME implementation efforts offer a cautionary tale of assessments resulting in learner harm or burden, rather than learner-centeredness.20,41 However, these cautionary tales further emphasize the need to identify new sources of reliable assessment data that do not rely heavily on human raters, including both "found" and fit-for-purpose data. Most importantly, the data must drive meaningful insights for learners that can be used for feedback and improvement. Kinnear and colleagues detail an instructive analogy: how professional sports (specifically Major League Baseball) went from solely relying on human scouting to using advanced technology for assessing the most granular units of individual performance.42 Pitching performance, for example, once was solely measured through scouting evaluations and game-level outcomes (like win/loss) that were multifactorial. While these measures remain important, innovations in technology have led to sophisticated pitch-level measurements of velocity, movement, spin rate, and the like. The pitcher has complete control over these novel measures (i.e., they are not affected by hitter performance, umpire calls, or ballpark configuration), and they are assessed without human input. This analogy demonstrates a model for assessment in medical training that identifies objective metrics of individual and team performance. Of course, assessing learners in the authentic clinical learning environment is vastly different from a game of baseball, where the rules, environment, and goals are all (largely) static. Nonetheless, baseball's evolution to augment human rater-derived assessments with modern technology to capture much higher density measurements of individual performance is instructive. Emerging performance measures in medical education, such as Resident Sensitive Quality Measures (RSQMs) and TRainee Attributable & Automatable Care Evaluations in Real-time (TRACERs),43–46 take a step in this direction in focusing on measures that have significant attribution to a single learner yet remain meaningful to patient care in their own right. However, even more granular measures are also needed, such as through electronic health record (EHR) metadata, motion capture, and wearable and haptic devices. Obviously, such efforts would need to be done with transparency as well as consent, assent, or ability to opt out in applicable situations. Garibaldi and colleagues describe a multi-institutional effort to use real-time location service badges to quantify residents' time at the bedside, in the workroom, or on rounds.40 Such technologies capture orders of magnitude more data about learners (over 95,000 hours on 43 residents in 1 year), revealing clinically meaningful inter-resident differences.47 Two papers in this supplement describe approaches for using haptics to achieve much more granular assessment of performance during existing standardized clinical tasks, such as an Objective Structured Clinical Examinations (OSCEs) on thyroid or breast palpation.48,49 While the measured forces used to palpate the breast may only be interpreted normatively in isolation, when linked to a meaningful patient outcome (e.g., positive likelihood ratio for detecting a mass), such measurements become powerful and precise tools for performance assessment and timely feedback. These efforts to increase the density and precision of assessment of individual learners are an essential building block for the next era of assessment. Additionally, as Sebok-Syer and colleagues explore, it will be essential to understand and measure interdependent team-based effects.50 Measuring how interdependence shapes learner performance throughout training could be especially impactful in both measuring team performance and identifying critical periods to durably shape learners' future practice patterns, which appear to be driven by interdependence. Stepping out one further "ring" to understand how teams come together to account for program-level outcomes will also require fundamentally different thinking.22 AI: powering analytics to gather insights on big data Emerging high-density assessment data streams bring with them challenges in generating timely insights related to the 6Vs of "big data": Volume, Velocity, Variety, Veracity, Variability, and Value.51 Statistical approaches that account for these increasingly complex and often nested measures with multilevel models have been recently described, as have been approaches for adjusting assessments to control for rater effects.52,53 We view these approaches as analogous to baseball's successful development of analytics that account for team, opponent, and ballpark effects. AI will surely also be essential. Recognizing the breathtaking pace of change in generative AI and other techniques, Turner and colleagues share a vision for how AI can be used for collecting, analyzing, and intervening upon these data streams.54 Issues related to explainability of previously "black box" models are rapidly being addressed, while increased attention to the propagation of bias has led to important principles and guardrails. Thoma and colleagues further explore the promise and perils of applying AI models to "found" data, emphasizing threats related to validity, consent, and unwanted bias.39 Large language models (LLMs), on which technologies like ChatGPT are built, are advancing rapidly. We anticipate LLMs will make sophisticated analyses of previously difficult-to-analyze data types—such as audio and text—commonplace in medical education in the coming years. LLM deployment in the clinical environment will undoubtedly create new data streams that might be used for learner assessment that were previously untenable, such as patient-physician communication patterns from an ambient listening tool.55 Considering how such data can be used to deliver high-quality equitable assessments of our learners and, in turn, ensure our graduates provide high-quality equitable care will be critical. Likewise, new AI tools, such as Segment Anything,56 have transformed computer vision and may eventually augment what an "observable" professional activity is through computer-assisted video analysis.57 Theory-grounded implementation through transdisciplinary collaboration To move beyond isolated innovations in assessment and fully realize a system of precision assessment will require theory-grounded implementation efforts and transdisciplinary collaboration. Drake and colleagues describe several PE interventions and the underlying theories and digital tools that were applied to ensure the implementation efforts were grounded in proven approaches.58 In addition to the theories they review (MAL, transformative learning, and self-determination), others applicable to PE could include cognitive load theory (e.g., personalizing experiences to match an individual learner's cognitive load capacity),59,60 situated cognition theory (e.g., incorporating context into assessment),61 and social learning theory (e.g., understanding how to assess and leverage interprofessional interactions for durable high-quality care patterns).62,63 Likewise, in addition to dashboards and nudge strategy, tools that will advance PE will include digital health devices (e.g., wearables64 and sensors65), adaptive learning platforms, virtual and augmented reality (VR/AR),66,67 gamification,68 and LLM chatbot-based tutors and coaches (e.g., https://hpe-bot.com).69 Garibaldi and colleagues draw upon building blocks for PE to illustrate how applying the PE conceptual framework can elucidate strengths and gaps in PE implementation cycles, whether at the individual or program level.40 Warm and colleagues show that programs need not use AI to achieve true PE; taking a principled approach that provides learners with performance goals related to both assessed performance and improvement over time ensures learners across the performance spectrum remain growth minded.70 Kinnear and colleagues highlight the so-called "Medici effect"71—that transformative innovation often arises from disciplinary intersectionality (i.e., transdisciplinary collaboration) where different ideas and approaches converge.42 Their analogy to player performance assessment in professional sports, though imperfect, is highly instructive and begs the question of whether medical education should be more active in engaging experts in assessment from other fields. The field of haptics has emerged out of engineering, medicine, and the science of touch; similarly, we must leverage the expertise of those doing measurement in other fields. Finally, the Canadian CBME initiative "Competency by Design" has been plagued by challenges related to logistics, workflow disruption, and assessment burnout.20,72–74 Although not explored in depth in this supplement, implementation science has multiple constructs for effecting change at the individual, team, or organization levels,75 such as the Consolidated Framework for Implementation Research (CFIR),76,77 that will be critical to apply in order for PE to move from innovation to widespread implementation. Tackling Threats to the Next Era of Assessment A number of challenges were highlighted by multiple authors in this supplement that threaten the realization of this next era of assessment and PE. The resources—both monetary and human—devoted to health professions education are inadequate. Only 2% of the global health care expenditures go toward health professions education (i.e., medicine, nursing, midwives, public health).10 Paltry funding is unlikely to lead to delivering on the bold visions set forth in this supplement. In the United States, allocating a fraction of federal funding for graduate medical education positions, which currently exceeds $16 billion per year, to medical education innovation and research would be transformational.78 The absence of such funding streams makes the prospect of developing a PE system—replete with complex data inputs, new technologies for data collection, AI analytics, and the like—frankly daunting. Unsurprisingly, existing PE innovations have generally occurred at institutions with more resources, including analytic supports and data scientists. Without concerted effort, this innovation disparity will only widen. Although PE will require front-loaded investment, we truly believe these investments will pay profound dividends to our health care system. As discussed by Richardson and colleagues, an organized approach to this next era of assessment with funding and structures similar to the Human Genome Project or Cancer Moonshot Initiative will be necessary to scale from isolated innovations to widespread implementation of PE.22 Calls to honor medicine's social contract by ensuring the quality of medical graduates are growing louder yet no single entity "owns" the problem. Even more aspirational is the dream of multiple entities partnering together and pooling resources to address the problem. Further complicating these challenges, we believe the changes needed in medical education to realize the vision set forth in this supplement, or any other vision that seeks to better serve patients and learners, must be viewed as an adaptive challenge rather than a technical problem.79,80 A technical problem is one in which the problem and solution are clear, the work will be managed by an expert, and the focus is on expediting a fix. An adaptive challenge, on the other hand, does not present a clear problem or solution. Adaptive challenges can be difficult to identify—and easy to deny. For example, despite the moral imperative to achieve equitable assessments and patient care, these are "wicked" problems characterized by conflicts, uncertainty, dynamic tensions, and susceptibility to contextual influences.33 Solving adaptive (or wicked) challenges requires experimentation and making new discoveries. This work cannot be done by the edict of experts but instead requires concerted investment of stakeholders and resources in addressing the challenges posed by changes in beliefs, roles, relationships, and approaches. Transdisciplinary collaborations, bringing fields such as implementation science, AI, and engineering together with medicine, medical education, and learners and patient communities will be essential. Call to Action Our current system of health professions education is failing to deliver graduates who can consistently deliver high-quality equitable care. The vision for the next era of assessment presented in this supplement requires bold action. As editors of this supplement, we consider the papers presented here a beginning—a call to action to address the gaps in our current system through a new system of PE and assessment. We call on medical school deans, residency and fellowship directors, department chairs, funding agencies, and national regulatory bodies to embrace this vision and invest the necessary resources. Learners, patients, and communities must be engaged as partners. Implementation efforts should draw upon proven frameworks while also recognizing the deep adaptive challenges that lie ahead. Failures will occur but so will profound successes. The trajectory of our learners and the care they provide can be transformed with a commitment to high-quality equitable assessment. What did we miss? Who did we miss? Contact us and join the conversation. We will hold a podcast in spring of 2024 to keep the conversation growing and to build a community of practice. The result will be a future physician workforce empowered to provide the care patients deserve—care that is equitable, patient-centered, and of the highest quality.
ER  -
TY  - JOUR
TI  - Encountered-Type Haptic Display via Tracking Calibrated Robot
PY  - 2023
PB  - Cornell University
T2  - arXiv (Cornell University)
DO  - 10.48550/arxiv.2309.16768
UR  - https://doi.org/10.48550/arxiv.2309.16768
DA  - 2023-01-01
AU  - Xiao, Chenxi
AU  - Tian, Yuan
LA  - en
KW  - Virtual image
AB  - In the past decades, a variety of haptic devices have been developed to facilitate high-fidelity human-computer interaction (HCI) in virtual reality (VR). In particular, passive haptic feedback can create a compelling sensation based on real objects spatially overlapping with their virtual counterparts. However, these approaches require pre-deployment efforts, hindering their democratizing use in practice. We propose the Tracking Calibrated Robot (TCR), a novel and general haptic approach to free developers from deployment efforts, which can be potentially deployed in any scenario. Specifically, we augment the VR with a collaborative robot that renders haptic contact in the real world while the user touches a virtual object in the virtual world. The distance between the user's finger and the robot end-effector is controlled over time. The distance starts to smoothly reduce to zero when the user intends to touch the virtual object. A mock user study tested users' perception of three virtual objects, and the result shows that TCR is effective in terms of conveying discriminative shape information.
ER  -
TY  - JOUR
TI  - Towards Bare-Hand Interaction for Whiteboard Collaboration in Virtual Reality
PY  - 2025
PB  - Association for Computing Machinery
SN  - 2573-0142
T2  - Proceedings of the ACM on Human-Computer Interaction
DO  - 10.1145/3711092
UR  - https://doi.org/10.1145/3711092
DA  - 2025-05-02
AU  - Liu, Guangtian
C1  - State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China
AU  - Su, Haiyun
C1  - State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China
AU  - Wang, Jingyu
C1  - State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China and Pengcheng Laboratory, Beijing, China
AU  - Qi, Qi
C1  - State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China
AU  - Sun, Haifeng
C1  - State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China
AU  - Zhuang, Zirui
C1  - State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China
AU  - Ren, Pengfei
C1  - State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China and E-byte.com, Beijing, China
AU  - Liao, Jianxin
C1  - State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China
LA  - en
KW  - Whiteboard
VL  - 9
IS  - 2
SP  - 1
EP  - 31
ER  -
TY  - JOUR
TI  - Enhancing the user experience for first responders with XR
PY  - 2022
DO  - 10.1117/12.2632506
UR  - https://doi.org/10.1117/12.2632506
DA  - 2022-03-17
AU  - Ledgerwood, Scott
C1  - National Institute of Standards and Technology (United States)
LA  - en
KW  - NIST
SP  - 34
EP  - 34
ER  -
TY  - BOOK
TI  - Graphics Interface 2007 : Montréal, Canada, May 28-30, 2007 : proceedings
PY  - 2007
DA  - 2007-01-01
AU  - Healey, Christopher
AU  - Lank, Edward
LA  - en
KW  - Scientific visualization
KW  - Parallel rendering
KW  - Real-time rendering
ER  -
TY  - JOUR
TI  - A Physics-based Virtual Reality System Design and Evaluation by Simulating Human-Robot Collaboration
PY  - 2022
DO  - 10.36227/techrxiv.18972773
UR  - https://doi.org/10.36227/techrxiv.18972773
DA  - 2022-01-28
AU  - Chowdhury, S.
AU  - Mubarrat, Syed
AU  - Fernandes, Antonio
LA  - en
KW  - Kinesthetic learning
KW  - Physics engine
AB  - Recent advancements in VR technology facilitate tracking real-world objects and users' movements in the virtual environment (VE) and inspire researchers to develop a physics-based haptic system (i.e., real object haptics) instead of computer-generated haptic feedback. However, there is limited research on the efficacy of such VR systems in enhancing operators’ sensorimotor learning for tasks that require high motor and physical demands. Therefore, this study aimed to design and evaluate the efficacy of a physics-based virtual reality (VR) system that provides users realistic cutaneous and kinesthetic haptic feedback. We designed a physics-based VR system, named PhyVirtual, and simulated human-robot collaborative (HRC) sequential pick-and-place lifting tasks in the VE. Participants performed the same tasks in the real environment (RE) with human-human collaboration instead of human-robot collaboration. We used a custom-designed questionnaire, the NASA-TLX, and electromyography activities from biceps, middle and anterior deltoid muscles to determine user experience, workload, and neuromuscular dynamics, respectively. Overall, the majority of responses (&gt;65%) demonstrated that the system is easy-to-use, easy-to-learn, and effective in improving motor skill performance. While compared to tasks performed in the RE, the PhyVirtual system placed significantly lower physical demand (124.90%; p &lt; 0.05) on the user. The electromyography data exhibited similar trends (p &gt; 0.05; r &gt; 0.89) for both environments. These results show that the PhyVirtual system is an effective tool to simulate safe human-robot collaboration commonly seen in many modern warehousing settings. Moreover, it can be used as a viable replacement for live sensorimotor training in a wide range of fields.
ER  -
TY  - CHAP
TI  - Using Animation to Enhance 3D User Interfaces for Multimedia
PY  - 2001
PB  - IGI Global
T2  - IGI Global eBooks
DO  - 10.4018/978-1-930708-00-6.ch011
UR  - https://doi.org/10.4018/978-1-930708-00-6.ch011
DA  - 2001-01-01
AU  - Thomas, Bruce
C1  - University of South Australia, Australia
LA  - en
KW  - Legibility
KW  - Skeletal animation
SP  - 214
EP  - 246
ER  -
TY  - JOUR
TI  - Motion constraints simulation based on MATLAB and haptic interface
PY  - 2009
T2  - 2021 IEEE International Conference on Robotics and Biomimetics (ROBIO)
DO  - 10.1109/robio.2009.5420586
UR  - https://doi.org/10.1109/robio.2009.5420586
DA  - 2009-12-01
AU  - Qi, Lin
C1  - Department of Electronic Engineering at the Chinese University of Hong Kong, Hong Kong SAR, China
AU  - Meng, Max
C1  - Department of Electronic Engineering at the Chinese University of Hong Kong, Hong Kong SAR, China
LA  - en
KW  - Interface (matter)
SP  - 717
EP  - 722
ER  -
TY  - JOUR
TI  - 발목재활을 위한 가상환경 및 햅틱스
PY  - 2003
T2  - 제어·자동화·시스템공학 논문지 = Journal of control, automation and systems engineering
DA  - 2003-08-01
AU  - Ryu, Jeha
AU  - , 송현식
AU  - , 윤정원
AU  - , 최형진
AU  - , 차종은
AU  - , 임길병
AU  - , 나영무
AU  - , 이기석
AU  - , 김현빈
LA  - en
KW  - Interface (matter)
VL  - 9
IS  - 8
SP  - 577
EP  - 584
ER  -
TY  - JOUR
TI  - Creative Reverse Engineering: From remote sensuality to haptic metrology
PY  - 2019
PB  - British Computer Society
SN  - 1477-9358
T2  - Electronic workshops in computing
DO  - 10.14236/ewic/eva2019.7
UR  - https://doi.org/10.14236/ewic/eva2019.7
DA  - 2019-01-01
AU  - Dines, Naomi
C1  - Central Saint Martins University of the Arts London, UK
C1  - University of the Arts London, UK
AU  - Biddulph, Dom
C1  - Central Saint Martins University of the Arts London, UK
C1  - University of the Arts London, UK
LA  - en
KW  - Reverse engineering
AB  - Our on-going experimentation in close-range Photogrammetry has overcome common challenges to generate accurate, high-resolution 3D models using a single DSLR camera and innovative approaches and computer-coded devices. More recent investigations across disciplines sought to bridge the gap between traditional creative skills and modes of visualisation, and what can be made possible through digital means. Working as artists and designers alongside museums and historians, we have developed new photogrammetry equipment and approaches to help overcome the complex fluid geometry, shadowy occlusions and delicate lamina edges of challenging monochromatic garments. The resulting 3D models have allowed the rapid extraction of faithful seams and surfaces direct from the processed ‘mesh’ and into CAD modelling environments for the production of new designs, patterns and production tooling. Current collaborations seek to apply these developments to the capture, visualisation and reverse engineering of iconic garments and museum artefacts, alongside the ‘remote sensing’ of traditional pattern cutters whose eyes, minds and hands are the equivalent of the digital approaches explored in our paper. The second phase sought to unpick some of the familiar structures of object- and asset creation in and for Virtual and Augmented Reality. Experimenting with equipment, methods and processing techniques allowed us to explore the potential of 3D visualisations and readily available tools within Virtual and Augmented Reality for garment design and other forms of object-based creative ideation, sketching and prototyping. In the next stages of our on-going research we explored a more haptic form of CAD-enabled modelling and metrology, aiming to bring these approaches within the reach of a wider range of creative users: enabling artists, designers and makers to move more seamlessly between digital tools and virtual environments, and actual things in real time and space.
ER  -
TY  - JOUR
TI  - Webi Draw: Unleashing Creativity with Handcrafted Air Drawings
PY  - 2024
SN  - 2582-3930
T2  - INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT
DO  - 10.55041/ijsrem29242
UR  - https://doi.org/10.55041/ijsrem29242
DA  - 2024-03-13
AU  - Journal, IJSREM
LA  - en
KW  - Interactive Art
KW  - Digital art
VL  - 08
IS  - 03
SP  - 1
EP  - 11
AB  - Air Canvas emerges as a groundbreaking solution for digital art creation, seamlessly integrating gesture recognition and virtual reality to liberate artists from the constraints of physical tools. Powered by advanced computer vision technology, the system tracks users' hand and foot movements, translating them into invisible strokes on a virtual canvas. With the added dimension of virtual reality headsets, users step into a digital realm where the boundaries between physical and virtual dissolve, providing a unique and immersive creative experience. Key features include instant spot metering, intuitive control over art supplies, and haptic feedback, enhancing the overall artistic journey. Beyond individual expression, Air Canvas fosters collaboration through multi-user support, transcending geographic barriers and democratizing art creation. Accessibility is a priority, with adjustments enabling participation from users with diverse physical abilities. Security measures, including robust encryption, safeguard user data and artwork, ensuring a secure environment for creative exploration. In essence, Air Canvas exemplifies the transformative potential of technology in reshaping artistic processes and offers a glimpse into the future of digital art. Core to Air Canvas is its utilization of computer vision technology, elevating digital art creation by meticulously tracking users' hand movements . Haptic feedback enriches the user experience by adding a tactile dimension to virtual canvas interaction. Multi-user collaboration opens avenues for shared artistic endeavors, unbounded by geographical limitations. Key Words: Air drawing, Interactive Designs, Hand Tracking, Machine Learning, Motion tracking .
ER  -
TY  - JOUR
TI  - Comparing collaborative interaction in different virtual environments
PY  - 2007
PB  - SPIE
SN  - 1818-2259
T2  - SPIE Newsroom
DO  - 10.1117/2.1200711.0922
UR  - https://doi.org/10.1117/2.1200711.0922
DA  - 2007-01-01
AU  - Shahab, Qonita
LA  - en
ER  -
TY  - JOUR
TI  - Evaluating Visual-Spatiotemporal Coregistration of a Physics-based Virtual Reality Haptic Interface
PY  - 2022
DO  - 10.36227/techrxiv.19242951
UR  - https://doi.org/10.36227/techrxiv.19242951
DA  - 2022-03-03
AU  - Chowdhury, S.
AU  - Mubarrat, Syed
AU  - Fernandes, Antonio
AU  - Binkley, Kieran
LA  - en
KW  - Kinesthetic learning
KW  - Interface (matter)
KW  - Motion Capture
AB  - This study aimed to evaluate the visual-spatiotemporal coregistration of the real and virtual objects’ movement dynamics in a low-cost physics-based virtual reality (VR) system that provides real cutaneous and kinesthetic haptic feedback of the objects instead of computer-generated haptic feedback. Twelve healthy participants performed three human-robot collaborative (HRC) sequential pick-and-place lifting tasks while both motion capture and VR systems respectively traced the movement kinematics of the real and virtual objects. We used an iterative closest point algorithm to transform the 3D spatial point clouds of the VR system into the motion capture system. We employed a novel algorithm and principal component analysis to respectively calculate visual and spatiotemporal coregistration precisions between virtual and real objects. Results showed a high correlation (r &gt; 0.96) between real and virtual objects’ movement dynamics and linear and angular coregistration errors of less than 5 cm and 8°, respectively. The trend also revealed a low temporal registration error of &lt;12 ms and was only found along the vertical axis. The visual registration data indicated that the real cutaneous and kinesthetic haptics provided by the physical objects in the virtual environment enhanced proprioception and visuomotor functions of the users.
ER  -
TY  - JOUR
TI  - A Physics-based Virtual Reality System Design and Evaluation by Simulating Human-Robot Collaboration
PY  - 2024
DO  - 10.36227/techrxiv.18972773.v2
UR  - https://doi.org/10.36227/techrxiv.18972773.v2
DA  - 2024-02-22
AU  - Chowdhury, S.
AU  - Mubarrat, Syed
AU  - Fernandes, Antonio
LA  - en
AB  - Recent advancements in VR technology facilitate tracking real-world objects and users’ movements in the virtual environment (VE) and inspire researchers to develop a physics-based haptic system (i.e., real object haptics) instead of computer-generated haptic feedback. However, there is limited research on the efficacy of such VR systems in enhancing operators’ sensorimotor learning for tasks that require high motor and physical demands. Therefore, this study aimed to design and evaluate the efficacy of a physics-based virtual reality (VR) system that provides users realistic cutaneous and kinesthetic haptic feedback. We designed a physics-based VR system, named PhyVirtual, and simulated human-robot collaborative (HRC) sequential pick-and-place lifting tasks in the VE. Participants performed the same tasks in the real environment (RE) with human-human collaboration instead of human-robot collaboration. We used a custom-designed questionnaire, the NASA-TLX, and electromyography activities from biceps, middle and anterior deltoid muscles to determine user experience, workload, and neuromuscular dynamics, respectively. Overall, the majority of responses (&gt;65%) demonstrated that the system is easy-to-use, easy-to-learn, and effective in improving motor skill performance. While compared to tasks performed in the RE, the PhyVirtual system placed significantly lower physical demand (124.90%; p &lt; 0.05) on the user. The electromyography data exhibited similar trends (p &gt; 0.05; r &gt; 0.89) for both environments. These results show that the PhyVirtual system is an effective tool to simulate safe human-robot collaboration commonly seen in many modern warehousing settings. Moreover, it can be used as a viable replacement for live sensorimotor training in a wide range of fields.
ER  -
TY  - JOUR
TI  - Effectiveness of augmented reality telesurgery: Lessons learned from Covid-19 pandemic.
PY  - 2020
DO  - 10.32512//jmr.3.3.2020/28
UR  - https://doi.org/10.32512//jmr.3.3.2020/28
DA  - 2020-11-30
AU  - Aman, Gupta
C1  - Department of Urology, Robotics and kidney Transplant, Fortis Hospital, New Delhi, India
AU  - Sood, Rajeev
C1  - Department of Urology, Robotics and kidney Transplant, Fortis Hospital, New Delhi, India
LA  - en
KW  - Pandemic
KW  - Videoconferencing
AB  - v1, *. Virtual reality (VR) is an artificially simulated environment that permits multiple interactions. Augmented reality (AR) is an interactive experience of a real-world environment where the objects are enhanced by computer-generated perceptual information [1,2]. Enhanced versions of these concepts were being used in several clinical practices. Virtual Interactive Presence (VIP) is a technology by which surgeons located remotely can simultaneously view each other's visual field, allowing them to telecollaborate long distance surgeries [3]. Virtual interactive presence and augmented reality (VIPAR) platform allows a surgeon from a remote location to deliver realtime assistance to a local surgeon using a standard internet connection. Pandemic typically led to a surge in demand for healthcare services overwhelming usually local capabilities. The SARS-Cov-2 outbreak was a big challenge for both patients and health practitioners. Surgical procedures were reserved only to most critical cases. Long lockdown limited patients’ access to different health facilities. Most of the savant societies recommended implementing telemedicine and incorporating telemedicine as part of COVID-19 outbreak response systems [4]. Telemedicine involves not only consultation, radiodiagnosis and clinical follow up but also surgical procedures and surgeon’s assisting guidance. Telemedicine is no longer a futuristic tool. It becomes a need in the present situation where human interaction has been made difficult by the pandemic. The touch sense haptic technology and teledactyl were predicted since 1878. Nowadays it may provide a more realistic and “physical” doctor- patient interaction remotely. Since the first successful tele-laparoscopic cholecystectomy in 2001, telesurgery allowed collaboration between different surgeons located distantly across world. This Tele-collaboration contributed to complex wound repairs in war zones. The same concept was useful in the management of some high-risk procedures such as emergency surgeries in COVID-19 positive patients [5,6]. Telesurgery could revolutionize training concept as well. Real-time access to three‐ dimensional reconstructions in patient imaging and remote interaction with colleagues may provide comprehensive high-quality skills transfer [7]. Before 2020, telesurgery was always an exciting technology but with unclear endpoints. The limited access to tele-guided procedures was mostly explained by the lack of patient’s trust and the high cost. The pandemic outbreak taught us a lot about its safety and effectiveness. Nowadays, health care delivery is feasible anytime in all restricted areas.
ER  -
TY  - JOUR
TI  - Effectiveness of augmented reality telesurgery: Lessons learned from Covid-19 pandemic
PY  - 2020
DO  - 10.32512/jmr.3.3.2020/28
UR  - https://doi.org/10.32512/jmr.3.3.2020/28
DA  - 2020-11-30
LA  - en
KW  - Pandemic
KW  - Videoconferencing
SP  - 28
EP  - 28
ER  -
TY  - JOUR
TI  - HexTouch: Affective Robot Touch for Complementary Interactions to Companion Agents in Virtual Reality
PY  - 2020
DO  - 10.1145/3385956.3422100
UR  - https://doi.org/10.1145/3385956.3422100
DA  - 2020-10-31
AU  - Zhou, Ran
C1  - Parsons School of Design Parsons School of Design, United States
AU  - Wu, Yanzhe
C1  - Parsons School of Design, USA
AU  - Sareen, Harpreet
C1  - Parsons School of Design, United States
LA  - en
KW  - Immersion
KW  - Disgust
VL  - 6
SP  - 1
EP  - 2
ER  -
TY  - CHAP
TI  - Improving Sense-Making for Construction Planning Tasks Using Visual and Haptic Stimuli in Virtual Reality Environments
PY  - 2023
PB  - Firenze University Press
SN  - 2704-5846
T2  - Proceedings e report
DO  - 10.36253/10.36253/979-12-215-0289-3.14
UR  - https://doi.org/10.36253/10.36253/979-12-215-0289-3.14
DA  - 2023-01-01
AU  - Mutis, Iván
C1  - Illinois Institute of Technology, US
AU  - Оберемок, Марина
C1  - Illinois Institute of Technology, US
AU  - Purushotham, Nishanth
C1  - Illinois Institute of Technology, US
LA  - en
SP  - 142
EP  - 154
ER  -
TY  - CHAP
TI  - Haptic vision, acoustic and navigation control in virtual reality game
PY  - 2007
PB  - Penerbit UTHM
T2  - Penerbit UTM eBooks
DA  - 2007-01-01
AU  - Basori, Ahmad
AU  - Bade, Abdullah
AU  - Daman, Daut
AU  - Sunar, Mohd
AU  - Saari, Nadzari
LA  - en
KW  - Joystick
KW  - Interactivity
KW  - Navigation System
ER  -
TY  - RPRT
TI  - Virtual Structural Dynamics, Acoustics and Control
PY  - 2001
DO  - 10.21236/ada395200
UR  - https://doi.org/10.21236/ada395200
DA  - 2001-06-01
AU  - Baz, Amr
LA  - en
KW  - Dynamics
ER  -
TY  - JOUR
TI  - Short paper: design tools, hybridization exploring intuitive interaction
PY  - 2010
T2  - Eurographics
DO  - 10.2312/egve/jvrc10/037-041
UR  - https://doi.org/10.2312/egve/jvrc10/037-041
DA  - 2010-09-27
AU  - Wendrich, Robert
C1  - University of Twente, Enschede, The Netherlands
LA  - en
KW  - Design process
KW  - Interactive Design
KW  - Interaction Design
SP  - 37
EP  - 41
ER  -
TY  - JOUR
TI  - Guest Editors' Introduction: special issue on ACM VRCIA 2006
PY  - 2007
PB  - Wiley
SN  - 1546-4261
T2  - Computer Animation and Virtual Worlds
DO  - 10.1002/cav.177
UR  - https://doi.org/10.1002/cav.177
DA  - 2007-01-01
AU  - Sun, Hanqiu
C1  - The Chinese University of Hong Kong
AU  - Wu, Enhua
C1  - [University of Macau]
AU  - Baciu, George
C1  - The Hong Kong Polytechnic University#TAB#
LA  - en
KW  - George (robot)
VL  - 18
IS  - 3
SP  - i
EP  - ii
AB  - ACM international conference on virtual reality continuum and its applications (VRCIA) is biannually sponsored by ACM SIGGRAPH, and in cooperation with the Eurographics Association, Chinese Society of Image and Graphics, and INI-GraphicsNet.The conference is devoted to the technical aspects and applied areas of virtual reality continuum, covering from the real environment through augmented reality and augmented virtuality to the virtual environment.ACM VRCIA 2006 is aimed to provide a forum for the scientists, researchers, developers, and users in the international VRC community to share experiences, exchange ideas, and disseminate knowledge of this fast-growing multidisciplinary field.Among the forty regular technical papers accepted at the conference, five of them ranked on the top of reviews list by IPC committee are selected and further extended for the special issue of VRCIA 2006.The parallel-culling paper by H. Xiong, H. Peng, A. Qin, and J. Shi addresses efficient parallel occlusion culling on cluster of GPUs systematically.Based on the occlusion-culling algorithm they proposed, different strategies of paralleling the occlusion culling on the GPUs cluster are developed and experimented for the high-resolution tiled display wall.The soft-touch deformations paper by H. Chen, H. Sun, and X. Jin proposes the interactive haptic deformation approach incorporating the dynamic simulation of mass-spring systems and flexible control of free-form deformation in the touch-enabled soft object manipulation.Through the distribution of physical properties, special effects can be intuitively created through the soft-touch interactions, letting the objects move in a dynamic, cartoon-style deforming approach.The ICWall paper by T.v.d.Schaaf, M. Koutek, D.M. Germans, and H.E. Bal describes their alignment/calibration method for the construction of the ICWall stereo tiled display using an automated approach.The alignment error can be reduced by applying sub-pixel accurate localization and modeling of the projector lenses.The large stereo system they developed on tiled display has been used for visualization of medical datasets and immersive VR presentations.The collision-detection paper by S.K. Wong and G. Baciu proposes robust continuous collision detection in the simulation of meshed deformable surfaces.A primitive filter layer is embedded in the pipeline of continuous collision detection to extract the potentially interacting primitive pairs.Interactive rates can be achieved for complex deformable surfaces with large contact regions in a cloth simulation system.The 3D user interfaces paper by M. Green and W.L.
ER  -
TY  - JOUR
TI  - Evaluating Visual-Spatiotemporal Coregistration of a Physics-based Virtual Reality Haptic Interface
PY  - 2024
DO  - 10.36227/techrxiv.19242951.v2
UR  - https://doi.org/10.36227/techrxiv.19242951.v2
DA  - 2024-02-22
AU  - Chowdhury, S.
AU  - Mubarrat, Syed
AU  - Fernandes, Antonio
LA  - en
KW  - Interface (matter)
AB  - This study aimed to evaluate the visual-spatiotemporal co-registration of the real and virtual objects’ movement dynamics in a low-cost physics-based virtual reality (VR) system that provides real cutaneous and kinesthetic haptic feedback of the objects instead of computer-generated haptic feedback. Twelve healthy participants performed three human-robot collaborative (HRC) sequential pick-and-place lifting tasks while both motion capture and VR systems respectively traced the movement kinematics of the real and virtual objects. We used an iterative closest point algorithm to transform the 3D spatial point clouds of the VR system into the motion capture system. We employed a novel algorithm and principal component analysis to respectively calculate visual and spatiotemporal co-registration precisions between virtual and real objects. Results showed a high correlation (r &gt; 0.96) between real and virtual objects’ movement dynamics and linear and angular co-registration errors of less than 5 cm and 8°, respectively. The trend also revealed a low temporal registration error of &lt;12 ms and was only found along the vertical axis. The visual registration data indicated that the real cutaneous and kinesthetic haptics provided by the physical objects in the virtual environment enhanced proprioception and visuomotor functions of the users.
ER  -
TY  - JOUR
TI  - Evolution in Haptic Displays
PY  - 2013
SN  - 0385-4221
T2  - IEEJ Transactions on Electronics Information and Systems
DO  - 10.1541/ieejeiss.133.625
UR  - https://doi.org/10.1541/ieejeiss.133.625
DA  - 2013-01-01
AU  - TAKASAKI, Masaya
C1  - Dept. of Mechanical Eng., Saitama University
LA  - en
KW  - Stereotaxy
KW  - Sensation
VL  - 133
IS  - 3
SP  - 625
EP  - 629
ER  -
TY  - JOUR
TI  - Objective monitoring of attentional states based on collaborative force-position control tasks
PY  - 2019
PB  - Science China Press
SN  - 1674-7267
T2  - Scientia Sinica Informationis
DO  - 10.1360/n112018-00286
UR  - https://doi.org/10.1360/n112018-00286
DA  - 2019-04-01
AU  - Wang, Lijun
C1  - State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing 100083, China
AU  - Wang, Dangxiao
C1  - State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing 100083, China
AU  - Zheng, Yilei
C1  - State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing 100083, China
AU  - Zhang, Yuru
C1  - State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing 100083, China
LA  - en
KW  - Position (finance)
KW  - Attentional control
KW  - Position paper
VL  - 49
IS  - 4
SP  - 422
EP  - 435
AB  - Accurate haptic interaction tasks require intensive activation of attentional resources. Exploring the relation between haptic channel and attention is not only conducive to understanding the interaction mechanism between human perception and cognition but is also important for the design of brain-computer interaction system based on haptic modality. In this paper, we built a virtual reality environment incorporating the multiregion force feedback and immersive visual displays and developed a collaborative force-position control task to monitor the attentional states objectively based on this platform. The force and position control performances of users at four different difficulty levels were used to measure the attentional level and attentional spotlight. The users subjective assessment showed that the task can effectively activate attentional resources. The experimental results showed that the task can be used as an attentional oscilloscope to monitor the changes in the attentional level and target of attentional spotlight with a high temporal resolution, providing a behavioral ground truth for exploring attentional biomarkers.
ER  -
TY  - JOUR
TI  - A Multi-layer Approach for Interactive Path Planning Control
PY  - 2014
T2  - Proceedings of the 15th International Conference on Informatics in Control, Automation and Robotics
DO  - 10.5220/0005055200900101
UR  - https://doi.org/10.5220/0005055200900101
DA  - 2014-01-01
AU  - Cailhol, Simon
C1  - INP-ENIT, France
AU  - Fillatreau, Philippe
C1  - INP-ENIT, France
AU  - Fourquet, Jean-Yves
C1  - INP-ENIT, France
AU  - Zhao, Yingshen
C1  - INP-ENIT, France
LA  - en
KW  - Planner
KW  - Representation
SP  - 90
EP  - 101
AB  - This work considers path-planning processes for manipulation tasks such as assembly, maintenance or disassembly in a Virtual Reality (VR) context. The approach consists in providing a collaborative system associating a user immersed in VR and an automatic path planning process. It is based on semantic, topological and geometric representations of the environment and the planning process is split in two phases: coarse and fine planning. The automatic planner suggests a path to the user and guides him trough a haptic device. The user can escape from the proposed solution if he wants to explore a possible better way. In this case, the interactive system detects the user's intention in real-time and computes a new path starting from the user's guess. Experiments illustrate the different aspects of the approach: multi-representation of the environment, path planning process, user's intent prediction and control sharing.
ER  -
TY  - JOUR
TI  - A multi-layer approach for path planning control in Virtual Reality simulation
PY  - 2014
DA  - 2014-06-18
AU  - Cailhol, Simon
C1  - LGP - Laboratoire Génie de Production (47, avenue d'Azereix BP 1629 65016 Tarbes CEDEX - France)
AU  - Fillatreau, Philippe
C1  - LGP - Laboratoire Génie de Production (47, avenue d'Azereix BP 1629 65016 Tarbes CEDEX - France)
AU  - Fourquet, Jean-Yves
C1  - LGP - Laboratoire Génie de Production (47, avenue d'Azereix BP 1629 65016 Tarbes CEDEX - France)
AU  - Zhao, Yingshen
C1  - LGP - Laboratoire Génie de Production (47, avenue d'Azereix BP 1629 65016 Tarbes CEDEX - France)
LA  - en
KW  - Planner
KW  - Representation
AB  - This work considers path-planning processes for manipulation tasks such as assembly, maintenance or disassembly in a virtual reality (VR) context. The approach consists in providing a collaborative system associating a user immersed in VR and an automatic path planning process. It is based on semantic, topological and geometric representations of the environment and the planning process is split in two phases: coarse and fine planning. The automatic planner suggests a path to the user and guides him trough a haptic device. The user can escape from the proposed solution if he wants to explore a possible better way. In this case, the interactive system detects the user’s intention and computes in real-time a new path starting from the user’s guess. Experiments illustrate the different aspects of the approach: multi-representation of the environment, path planning process, user’s intent prediction and control sharing.
ER  -
TY  - JOUR
TI  - VR-based product development process: opportunities and challenges in the automotive industry
PY  - 2022
DO  - 10.5753/svr_estendido.2022.226711
UR  - https://doi.org/10.5753/svr_estendido.2022.226711
DA  - 2022-10-24
AU  - Winkler, Ingrid
C1  - SENAI CIMATEC
AU  - Murari, Thiago
C1  - SENAI CIMATEC
AU  - Ferreira, Cristiano
C1  - Automotive Engineering Federal University of Santa Catarina Joinville, SC, Brazil
C1  - Human Factors and Lifestyles Ford Motor Company Salvador, BA, Brazil
C1  - Management and Industrial Technology SENAI CIMATEC Salvador, BA, Brazil
AU  - Freitas, Fábio
C1  - Ford Motor Company
LA  - en
KW  - Product engineering
SP  - 41
EP  - 44
AB  - In the product development, the success of a manufacturing strategy is achieved by specifying a manufacturing process that it can be produced with minimal impact. In the automotive industry, to detect late, i.e., already during manufacturing phase, issues on customers preferences on new vehicles, physical ergonomic issues, or problems on usability of a product has a high cost of correction and long the time to launch a new product. Thus, given the complexity of products that are under development, designers must perform a number of procedures to guarantee that the finished product fits customer demands and is accepted by the market. With the emergence of low-cost virtual reality devices, the automotive industry is adopting virtual reality for several engineering processes and support everyday engineering. The patent filings have boomed since 2016, in a technology space that is rapidly evolving, offering opportunities to enter an area while it is still young. Virtual reality benefits the product development process by saving costs and time, closing customers, improving interactions, avoiding prototype transportation, optimizing the assembly line, improving the performance and well-being of the user, mitigating hidden dangers, stimulating novel insights and increasing team collaboration, and feeling of engagement, among others. However, certain constraints must be overcome before the technology’s possibilities can be fully harnessed. The challenges faced by VR-based processes are the lack of realism due to unnatural tactile and visual interactions, latency and registration issues, communication difficulties between teams, unpleasant symptoms, issues on depth, haptic, motion and movement perceptions, cybersecurity, cybersickness, lack of intuitiveness, and partial control over the user’s moving around, among others. While there are still challenges to be addressed until industries can fully benefit from the technology’s potential and these constraints prevent virtual reality from fully replacing conventional automotive product development in the near future, it is a valuable contribution to the process. In this context, this work discusses the opportunities and challenges of virtual reality-based product development process in the automotive industry. A better knowledge on this subject may provide a reference for decision-makers, practitioners and researchers as they continue to develop innovative immersive solutions in the product development in the automotive industry.
ER  -
TY  - CHAP
TI  - Reshaping the Shape of Time: Integrating LLMs and XR for Enhanced Cultural Heritage Representation
PY  - 2023
T2  - United Research Forum eBooks
DO  - 10.51219/urforum.2023.james-hutson
UR  - https://doi.org/10.51219/urforum.2023.james-hutson
DA  - 2023-12-16
AU  - Hutson, James
C1  -  Lindenwood University, Saint Charles, USA
C1  - ARTIFICIAL INTELLIGENCE ARTIFICIAL INTELLIGENCE ARTIFICIAL INTELLIGENCE DATA SCIENCE & ROBOTICS DATA SCIENCE & ROBOTICS DATA SCIENCE & ROBOTICS
C1  - Art History and Visual Culture at Lindenwood University.
LA  - en
KW  - Representation
AB  - This keynote discusses integrating generative AI, NLP, and XR, augmented with multi-sensory feedback like haptics and olfactory virtual reality (OVR).This integration aims to facilitate immersive learning experiences in teaching global cultural heritage, fostering a dialogical interaction between users and diverse cultural narratives.The proposed model highlights the potential of using generative AI to resurrect significant historical personalities and indigenous cultures, often overlooked in mainstream history.This approach challenges traditional postcolonial narratives by offering scaffolded experiences in virtual learning environments (VLEs), enabling deeper engagement with historical events and figures.The chapter also addresses concerns regarding the accuracy of large language models and the ethical implications of potential historical misrepresentations.It emphasizes collaboration with experts to ensure historical veracity and appropriateness, alongside addressing ownership, representation, and cultural appropriation issues.Furthermore, the integration of ecological momentary assessment (EMA) and geomapping wearable devices proposes a nuanced and interactive approach to history, addressing Kubler's The Shape of Time dilemma and offering a new perspective on the spacetime continuum.This research underscores the transformative potential of merging LLMs with immersive technologies, providing captivating educational experiences while conscientiously navigating the delicate balance between authentic historical dialogues and postmodern simulacra.
ER  -
TY  - JOUR
TI  - Shaping the Future of Dentistry: How Digital VR-Haptic Thinkers Are Revolutionizing Education by Thinking Big for Better Future in Oral Care
PY  - 2025
PB  - Georg Thieme Verlag
SN  - 1305-7456
T2  - European Journal of Dentistry
DO  - 10.1055/s-0045-1810611
UR  - https://doi.org/10.1055/s-0045-1810611
DA  - 2025-08-18
AU  - Chau, Reinhard
C1  - Division of Restorative Dental Sciences, Faculty of Dentistry, The University of Hong Kong, Hong Kong, Hong Kong
AU  - Neshka, Manchorova
C1  - Department of Operative Dentistry and Endodontics, Faculty of Dental Medicine, Medical University of Plovdiv, Plovdiv, Bulgaria
AU  - Pantea, Mihaela
C1  - Department of Fixed Prosthodontics and Occlusology, Faculty of Dentistry, "Carol Davila" University of Medicine and Pharmacy, Bucharest, Romania
AU  - Rampf, Sarah
C1  - Department of Conservative Dentistry, Clinic for Oral, Dental and Maxillofacial Diseases, Heidelberg Medical Faculty, Heidelberg University, Heidelberg, Germany
AU  - Liukkonen, Mikko
C1  - Division of Ophthalmology, Institute of Clinical Medicine, School of Medicine, University of Eastern Finland, Kuopio, Finland
AU  - Rice, David
C1  - Department of Oral and Maxillofacial Diseases, Faculty of Medicine, University of Helsinki, Helsinki, Finland
AU  - Morton, David
C1  - Department of Neurobiology, School of Medicine, University of Utah, Salt Lake City, Utah, United States
AU  - Bandiaky, Octave
C1  - Division of Regenerative Medicine and Skeleton, Faculty of Dentistry, University of Nantes, Nantes, France
AU  - Nagasawa, Masako
C1  - Division of Bio-Prosthodontics, Faculty of Dentistry and Graduate School of Medical and Dental Sciences, Niigata University, Niigata, Japan
AU  - Bágyi, Kinga
C1  - Department of Operative Dentistry and Endodontics, Faculty of Dentistry, University of Debrecen, Debrecen, Hungary
AU  - Quinn, Barry
C1  - Department of Restorative Dentistry, School of Dentistry, Faculty of Health and Life Sciences, Institute of Life Course and Medical Sciences, University of Liverpool, Liverpool, United Kingdom
AU  - Carramolino‐Cuéllar, Esther
C1  - Department of Odontology, Faculty of Health Sciences, Universidad Europea de Valencia, Valencia, Spain
AU  - Galan-Gil, S.
C1  - Department of Odontology, Faculty of Health Sciences, Universidad Europea de Valencia, Valencia, Spain
AU  - Flacco, Nicla
C1  - Department of Odontology, Faculty of Health Sciences, Universidad Europea de Valencia, Valencia, Spain
AU  - Pasqualini, Damiano
C1  - Department of Surgical Sciences, Dental School, University of Turin, Turin, Italy
AU  - Shazib, Muhammad
C1  - Department of Dental Medicine, Workman School of Dental Medicine, High Point University, High Point, North Carolina, United States
AU  - Schick, Simona‐Georgiana
C1  - Department of Conservative Dentistry, Clinic for Oral, Dental and Maxillofacial Diseases, Heidelberg Medical Faculty, Heidelberg University, Heidelberg, Germany
AU  - Yarmukhamedov, Bekhzod
C1  - Tashkent State Dental Institute, Tashkent, Uzbekistan
AU  - Ackerman, Kristin
C1  - Department of Dental Medicine, Workman School of Dental Medicine, High Point University, High Point, North Carolina, United States
AU  - Arias‐Herrera, Santiago
C1  - Department of Odontology, Faculty of Health Sciences, Universidad Europea de Valencia, Valencia, Spain
AU  - Palotie, Ulla
C1  - Department of Oral and Maxillofacial Diseases, Faculty of Medicine, University of Helsinki, Helsinki, Finland
AU  - Kada, A.
C1  - Dental Medicine Faculty, Mohammed V. University in Rabat, Rabat, Morocco
AU  - Bouyahyaoui, Nawal
C1  - Dental Medicine Faculty, Mohammed V. University in Rabat, Rabat, Morocco
AU  - Silva, Edgar
C1  - Stomatology Simulation Center, Facultad de Estomatología, Universidad Peruana Cayetano, Heredia, Lima, Peru
AU  - Rėderienė, Gitana
C1  - European Dental Hygienists Federation, Utrecht, Netherlands
AU  - Arrouf, Nisrine
C1  - Dental Medicine Faculty, Mohammed V. University in Rabat, Rabat, Morocco
AU  - Rodríguez‐Hopp, María
C1  - Facultad de Salud y Odontología, Universidad Diego Portales, Santiago, Chile
AU  - Suominen, Anna
C1  - Oral Health Teaching Unit, Kuopio University Hospital, Kuopio, Finland
AU  - Edgar, Heather
C1  - Northern Ireland Medical and Dental Training Agency (NIMDTA), Belfast, Northern Ireland, United Kingdom
AU  - Shanks, Nicola
C1  - Northern Ireland Medical and Dental Training Agency (NIMDTA), Belfast, Northern Ireland, United Kingdom
AU  - Jackson, Amanda
C1  - Northern Ireland Medical and Dental Training Agency (NIMDTA), Belfast, Northern Ireland, United Kingdom
AU  - Hendron, Brid
C1  - Northern Ireland Medical and Dental Training Agency (NIMDTA), Belfast, Northern Ireland, United Kingdom
AU  - Usta, Sıla
C1  - Department of Restorative Dentistry & Endodontics, Gulhane Faculty of Dentistry, University of Health Sciences Ankara, Ankara, Türkiye
AU  - Lingström, Peter
C1  - Department of Cariology, Institute of Odontology, Sahlgrenska Academy, University of Gothenburg, Gothenburg, Sweden
AU  - Örtengren, Ulf
C1  - Department of Cariology, Institute of Odontology, Sahlgrenska Academy, University of Gothenburg, Gothenburg, Sweden
AU  - Maggio, Margrit
C1  - Department of Dental Medicine, Workman School of Dental Medicine, High Point University, High Point, North Carolina, United States
AU  - Sondagar, Niku
C1  - Note Dr Ltd, Covent Garden, London, United Kingdom
AU  - Abuzaid, Maxstein
C1  - Division of Restorative Dental Sciences, Faculty of Dentistry, The University of Hong Kong, Hong Kong, Hong Kong
AU  - Ponto-Wolska, Małgorzata
C1  - Department of Propaedeutics and Dental Prophylaxis, Faculty of Medicine and Dentistry, Warsaw Medical University, Warsaw, Poland
AU  - Lam, Walter
C1  - Division of Restorative Dental Sciences, Faculty of Dentistry, The University of Hong Kong, Hong Kong, Hong Kong
AU  - Regulski, Piotr
C1  - Department of Propaedeutics and Dental Prophylaxis, Faculty of Medicine and Dentistry, Warsaw Medical University, Warsaw, Poland
AU  - Huhtela, Outi
C1  - Institute of Dentistry, School of Medicine, University of Eastern Finland, Kuopio, Finland
AU  - Zadrożny, Łukasz
C1  - Department of Propaedeutics and Dental Prophylaxis, Faculty of Medicine and Dentistry, Warsaw Medical University, Warsaw, Poland
AU  - Pang, MengWei
C1  - Department of Prosthodontics, School of Stomatology, Chongqing Medical University, Chongqing, China
AU  - Bergman, Suzie
C1  - Department of Neurosurgery, Oregon Health and Science University, Multnomah County, Oregon, United States
AU  - Felszeghy, Szabolcs
C1  - Institute of Dentistry, School of Medicine, University of Eastern Finland, Kuopio, Finland
AU  - Bencharit, Sompop
C1  - Department of Dental Medicine, Workman School of Dental Medicine, High Point University, High Point, North Carolina, United States
AU  - Sittoni‐Pino, Maria
C1  - Department of Odontology, Faculty of Health Sciences, Universidad Europea de Valencia, Valencia, Spain
LA  - en
AB  - Integrating digital, virtual reality (VR), and haptic technologies into dental education transforms training by fostering immersive, student-centered environments. These tools bridge theoretical knowledge and clinical practice, enhancing psychomotor skills, reducing anxiety, and enabling standardized assessments in risk-free settings. The Digital, VR, and Haptic Thinkers Network drives global collaboration and innovation. Drawing on insights from a 2025 conference at Queen Mary University of London, this commentary explores advancements, challenges, and future directions for VR-haptic integration in dental curricula. Results from global implementations, including improved manual dexterity and procedural precision, as well as enhanced pulpotomy performance, demonstrate a significant educational benefit. In clinical dentistry, VR-haptic simulators enhance patient outcomes by facilitating precise skill development for procedures in restorative dentistry and endodontics, thereby reducing errors in real-world practice. Combining these technologies with traditional methods is proposed to prepare competent, confident dental professionals while addressing educational disparities. Rigorous validation, strategic curriculum integration, and interdisciplinary collaboration are recommended to maximize impact.
ER  -
TY  - JOUR
TI  - Low Latency Haptic Feedback for Battery Powered HCI for the Tactile Internet
PY  - 2021
DO  - 10.1109/ssi52265.2021.9466961
UR  - https://doi.org/10.1109/ssi52265.2021.9466961
DA  - 2021-04-27
AU  - Kundu, Souvik
C1  - Wireless Sensor Networks, Tyndall National Institute, Cork, Ireland
AU  - O’Flynn, Brendan
C1  - Wireless Sensor Networks, Tyndall National Institute, Cork, Ireland
AU  - Sanchez, J
C1  - Wireless Sensor Networks, Tyndall National Institute, Cork, Ireland
AU  - Walsh, Michael
C1  - Wireless Sensor Networks, Tyndall National Institute, Cork, Ireland
LA  - en
KW  - Teleoperation
KW  - Tactile sensor
SP  - 1
EP  - 4
ER  -
TY  - JOUR
TI  - &lt;title&gt;Teleoperating a compliance task&lt;/title&gt;
PY  - 2002
PB  - SPIE
SN  - 0277-786X
T2  - Proceedings of SPIE, the International Society for Optical Engineering/Proceedings of SPIE
DO  - 10.1117/12.454746
UR  - https://doi.org/10.1117/12.454746
DA  - 2002-02-07
AU  - Kuan, Cheng-Peng
C1  - Industrial Technology Research Institute, Taiwan
AU  - Young, Kuu‐Young
C1  - National Chiao Tung University Taiwan
LA  - en
KW  - Teleoperation
KW  - Telerobotics
KW  - Remote operation
KW  - Human–robot interaction
VL  - 4570
SP  - 60
EP  - 68
ER  -
TY  - JOUR
TI  - Haptic interaction device based on active/passive hybrid actuator
PY  - 2011
DA  - 2011-01-01
AU  - Xiaorui, Zhang
C1  - Technology,Nanjing 210044,China)
LA  - en
KW  - Realization (probability)
ER  -
TY  - JOUR
TI  - Interactive 3-D Software in Aircraft Rescue and Fire Fighting Training
PY  - 2016
PB  - Embry–Riddle Aeronautical University
SN  - 2374-6793
T2  - International Journal of Aviation Aeronautics and Aerospace
DO  - 10.15394/ijaaa.2016.1031
UR  - https://doi.org/10.15394/ijaaa.2016.1031
DA  - 2016-01-01
AU  - Gorman, Mary
C1  - Embry-Riddle Aeronautical Univ.
AU  - Herron, Rita
LA  - en
KW  - Rescue therapy
AB  - As the nexus between aviation, fire science, and emergency management becomes increasingly more complex, technology can be used to augment training and avoid risk while maintaining authenticity with situational reality. In Aircraft Rescue & Fire Fighting (ARFF), the manner in which the learning content is effectively imparted to the student-professional can make all the difference in a successful emergency response. The interactive 3-D software developed exclusively for Dallas/Fort Worth Fire Training Research Center (DFW FTRC) is part of a curriculum designed to educated and train ARFF professionals in life-saving strategies and tactics. Through a 2013 Memorandum of Understanding, the world’s leading aviation and aerospace university, Embry-Riddle Aeronautical University (ERAU), and DFW FTRC have created a unique partnership for the conduct of research to explore emerging issues in the discipline. Researchers from ERAU designed this collaborative study to examine how effectively the DFW FTRC virtual technology software in the classroom translated knowledge and accelerated haptic skill transfer to the hands-on portion of ARFF training at the facility. The qualitative approach integrated classroom observations with key informant interviews to create a single-case study exploratory research strategy. Emergent themes led to a richer understanding of experiential learning, particularly key differences among individual student characteristics and instructional culture that influence student proficiency and attitudes. Most noteworthy were: a larger interest among international over domestic students, age/generational difficulties with new technology, and an apprehension among ARFF professionals to transition from traditional tabletop exercises to virtual reality. Variability also existed within the instructional culture, including inconsistencies of software integration in the classroom, instructor proficiency with the software, and adult and group teaching theories. The study also found that knowledge and accelerated haptic skill transfer were positively associated with the virtual reality software, and that interactive participation and memory reinforcement were supported by the findings. Time required for curriculum development advancing further integration of the software into the training program was a significant administrative and operational challenge. Software recommendations included options that allow scenario-specific applications and variable incident conditions, thus enriching each classroom learning experience. Marketing of this software remains the final task for DFW FTRC, as cost-effective distribution could revolutionize training across public safety. Future research should also evaluate pedagogy to categorize learning constructivism using simulator-based and software-supported education and training. How this may be applied to public safety professions where risk is an inherent part of training is a crucial need in the industry.
ER  -
TY  - JOUR
TI  - Two are not always better than one: Role specialization is an important determinant of collaborative task performance
PY  - 2022
PB  - Cornell University
T2  - arXiv (Cornell University)
DO  - 10.48550/arxiv.2205.06196
UR  - https://doi.org/10.48550/arxiv.2205.06196
DA  - 2022-01-01
AU  - Takai, Asuka
AU  - Fu, Qiushi
AU  - Doibata, Yuzuru
AU  - Lisi, Giuseppe
AU  - Tsuchiya, Toshiki
AU  - Mojtahedi, Keivan
AU  - Yoshioka, Toshinori
AU  - Kawato, Mitsuo
AU  - Morimoto, Jun
AU  - Santello, Marco
LA  - en
KW  - Leverage (statistics)
KW  - Context effect
AB  - Collaboration frequently yields better results in decision making, learning, and haptic interactions than when these actions are performed individually. However, is collaboration always superior to solo actions, or do its benefits depend on whether collaborating individuals have different or the same roles? To answer this question, we asked human subjects to perform virtual-reality collaborative and individual beam transportation tasks. These tasks were simulated in real-time by coupling the motion of a pair of hand-held robotic manipulanda to the virtual beam using virtual spring-dampers. For the task to be considered successful, participants had to complete it within temporal and spatial constraints. While the visual feedback remained the same, the underlying dynamics of the beam were altered to create two distinctive task contexts which were determined by a moving pivot constraint. When the pivot was placed at the center of the beam, two hands contribute to the task with symmetric mechanical leverage (symmetric context). When the pivot was placed at the left side of the beam, two hands contribute to the task with asymmetric mechanical leverage (asymmetric context). Participants performed these task contexts either individually with both hands (solo), or collaboratively by pairing one hand with another one (dyads). We found that dyads in the asymmetric context performed better than solos. In contrast, solos performed the symmetric context better than dyads. Importantly, we found that two hands took different roles in the asymmetric context for both solos and dyads. In contrast, the contribution from each hand was statistically indistinguishable in the symmetric context. Our findings suggest that better performance in dyads than solos is not a general phenomenon, but rather that collaboration yields better performance only when role specialization emerges in dyadic interactions.
ER  -
TY  - JOUR
TI  - New ways of employing TLC in education: Immersive Object-Based Learning and AI Integration for Cultural Heritage Education. The case of the Restart Project
PY  - 2025
SN  - 2631-5602
T2  - Ubiquity Proceedings
DO  - 10.5334/uproc.215
UR  - https://doi.org/10.5334/uproc.215
DA  - 2025-09-03
AU  - Poce, Antonella
AU  - Valente, Mara
AU  - De Medio, Carlo
LA  - en
KW  - Digitization
SP  - 47
EP  - 47
AB  - RESTART - Innovative telecommunication solutions for the enhancement and heritage experience: the totems and the Virtual Museum of the University of Tor Vergata" represents an advanced research initiative that is located at the intersection of technology, culture and education within the recovery funding project RESTART RESearch and innovation on future Telecommunications systems and networks, to make Italy more smART foundation. The main objective is to develop and implement innovative solutions in the field of telecommunications to improve accessibility, enjoyment and enhancement of cultural heritage, with a specific focus on the campus of the University of Tor Vergata. The research activity herewith described represents a use case within Spoke 8 of the RESTART project as it embodies the mission to develop innovative solutions for the experience and enhancement of cultural heritage through the integration of cutting-edge technologies and advanced educational methodologies, realized through two demonstrators, two totem installed in the engineering macro-area. Thanks to the use of augmented reality, virtual reality, and 3D digitization, the project not only promotes inclusive and immersive access to local heritage but also tests and validates replicable models of connection between culture, technology, and society. Through the installation of interactive totems, a dedicated 5G network, and devices such as VR headsets and haptic gloves, the Virtual Museum acts as an innovation laboratory for testing educational approaches like digital Object-Based Learning, which enhance users’ soft skills. Additionally, the totems play a crucial role in disseminating the results of the RESTART project and its scientific products, serving as strategic access points for communication and interaction with digital content, thereby strengthening the social and cultural impact of the initiative. The RESTART project at the University of Rome Tor Vergata herewith presented is an innovative endeavor that employs Object-Based Learning (OBL) and advanced digital solutions to redefine contemporary education. Its primary objective is to nurture essential competences for the 21st century—Creativity, Collaboration, Communication, and Critical Thinking—while emphasizing participant well-being. Central to RESTART is the Tor Vergata Virtual Museum, a fully immersive virtual reality (VR) domain featuring twenty meticulously chosen objects, which guide users through the historical and cultural richness of the local area. The experience is further enhanced by a haptic glove simulating tactile feedback, offering a multisensory approach that fosters deeper engagement and retention. Inclusivity stands at the core of RESTART’s mission. Dedicated workshops ensure that all learners, regardless of physical or cognitive abilities, have equitable access to these cutting-edge educational methods. By harnessing AI-driven personalization, the initiative tailors’ experiences to individual needs, reinforcing an inclusive and adaptable environment. Of particular note is RESTART’s dual commitment to both scholarly success and holistic well-being. By tracking academic metrics alongside indicators of emotional health, the project aims to demonstrate how technologically enriched OBL can heighten engagement, comprehension, and personal satisfaction. In doing so, RESTART paves the way for future models that integrate advanced educational technologies with progressive pedagogies. Ultimately, RESTART represents a significant milestone in the fusion of digital innovations and instructional strategies. By embracing avant-garde solutions and prioritizing inclusivity, this project helps shape the future of teaching and learning, inspiring new generations to value cultural heritage while enhancing their academic and emotional development.
ER  -
TY  - JOUR
TI  - Virtual Reality in Surgical Training
PY  - 1998
DA  - 1998-01-01
AU  - Müller, Wolfgang
AU  - Bockholt, Ulrich
AU  - Voß, Gerrit
LA  - en
KW  - Interface (matter)
KW  - Representation
ER  -
TY  - JOUR
TI  - Augmented Reality Integration in Surgery for Craniosynostoses: Advancing Precision in the Management of Craniofacial Deformities
PY  - 2025
PB  - Multidisciplinary Digital Publishing Institute
SN  - 2077-0383
T2  - Journal of Clinical Medicine
DO  - 10.3390/jcm14124359
UR  - https://doi.org/10.3390/jcm14124359
DA  - 2025-06-19
AU  - Sharma, Divya
C1  - University Hospitals Bristol & Weston, Bristol, BS2 8HW, UK
AU  - Holden, Adam
C1  - University Hospitals Bristol & Weston, Bristol, BS2 8HW, UK
AU  - Nezamivand-Chegini, Soudeh
C1  - Department of Oral & Maxillofacial Surgery, Honorary Clinical Lecturer for University College London, London WC1E 6B5, UK
C1  - University Hospitals Bristol & Weston, Bristol, BS2 8HW, UK
LA  - en
KW  - Craniofacial surgery
KW  - Craniosynostoses
KW  - Surgical Planning
VL  - 14
IS  - 12
SP  - 4359
EP  - 4359
AB  - Craniofacial deformities, particularly craniosynostosis, present significant surgical challenges due to complex anatomy and the need for individualised, high-precision interventions. Augmented reality (AR) has emerged as a promising tool in craniofacial surgery, offering enhanced spatial visualisation, real-time anatomical referencing, and improved surgical accuracy. This review explores the current and emerging applications of AR in preoperative planning, intraoperative navigation, and surgical education within paediatric craniofacial surgery. Through a literature review of peer-reviewed studies, we examine how AR platforms, such as the VOSTARS system and Microsoft HoloLens, facilitate virtual simulations, precise osteotomies, and collaborative remote guidance. Despite demonstrated benefits in feasibility and accuracy, widespread clinical adoption is limited by technical, ergonomic, financial, and training-related challenges. Future directions include the integration of artificial intelligence, haptic feedback, and robotic assistance to further augment surgical precision and training efficacy. AR holds transformative potential for improving outcomes and efficiency in craniofacial deformity correction, warranting continued research and clinical validation.
ER  -
TY  - JOUR
TI  - Using Virtual Reality (VR) in Interior Design Visualization
PY  - 2025
SN  - 2822-6585
T2  - Next generation.
DO  - 10.62802/ex60p006
UR  - https://doi.org/10.62802/ex60p006
DA  - 2025-01-09
AU  - Kavak, Elif
LA  - en
VL  - 8
IS  - 1
SP  - 163
EP  - 163
ER  -
TY  - JOUR
TI  - From Haptic Interfaces to Man-Machine Symbiosis
PY  - 1999
PB  - Queensland University of Technology
SN  - 1441-2616
T2  - M/C Journal
DO  - 10.5204/mcj.1787
UR  - https://doi.org/10.5204/mcj.1787
DA  - 1999-09-01
AU  - Kangas, Sonja
LA  - en
VL  - 2
IS  - 6
AB  - Until the 1980s research into computer technology was developing outside of a context of media culture. Until the 1970s the computer was seen as a highly effective calculator and a tool for the use in government, military and economic life. Its popular image from the 1940s to 1950s was that of a calculator. At that time the computer was a large machine which only white lab-coated engineers could understand. The computer was studied as a technical instrument, not from the viewpoint of the user. The peculiar communication between the user -- engineers at this point -- and the machine was described in caricatures like those in Electric Media (Brown &amp; Marks 100). Many comics handled the issue of understanding. In one cartoon one engineer asks another: "Do you ever feel that it is trying to tell us something?" And in Robert Sherman Townes's novel "Problem of Emmy", the computer (Emmy) acts out of control and prints the words: "WHO AM I WHO AM I WHO AM I?". In these examples the man-machine relationship was taken under consideration, but the attitude towards the relationship was that of a master-tool way. The user was pronouncedly in control and the machine just a passive tool. After the 1980s the image of the computer was turning into that of a playful toy and a game machine, thanks to the game houses' and marketing departments' efforts. Suddenly the player was playing with the computer, and even fairly often got beaten by it. That definitely raises feelings towards the machine! The playing situation was so intensive that the player did not often pay any attention to the interface, and the roles were not so clear anymore. This was a step towards the idea of natural communication between human and machine. Later science fiction influenced depictions of virtual reality, and haptic interfaces mediated the ideas into reality. In this paper I will discuss the man-machine relationship from the viewpoint of interface design. My expertise is in electronic games, and thus I will use examples from the game industry. This paper is a sidetrack of RAID -- Research of Adaptive User Interface Design, which was going on at the University of Lapland, Finland in 1995-1999. The RAID project was about research into adaptive interface design from the viewpoint of media archaeology, electronic games, toys and media art. Early Visions Already in the 1960s, MIT professor J.C.R. Licklider wrote about man-machine symbiosis. He saw that "man machine symbiosis is an expected development in cooperative interaction between men and electronic computers". He believed that it would lead to a new kind of cooperative partnership between man and machine (9). Licklider's visions are important, because the relationship between man and machine was seen generally differently at those days. At the time of the first mainframe computers in the 1940s, man and machine were seen as separate entities from the viewpoint of data processing. The operator put in data to the machine, which processed it by its own language which only the machine and very few engineers could understand. Fear -- a fearful affection -- has affected the development of machines and the idea of man-machine relationships throughout the decades. One reason for this is that the ordinary person had no contact to the computer. That has led to fears that when cooperating with the machine, the user will become enslaved by it, or sucked into it, as in Charlie Chaplin's film Modern Times (1936). The machine captivates its user's body, punishes it and makes its movement impossible at the end. Or the machine will keep the body's freedom, but adapt its functions to work by the automatic rhythm: the human body will be subordinated to the machine or made a part of it. What Is the Interface? In reality there still is a mediator between the user and the machine: the interface. It is a connector -- a boundary surface -- that enables the user to control the machine. There has been no doubt who is in charge of whom, but the public image of the machine is changing from "computer as a tool" to "computer as an entertainment medium". That is also changing the somewhat fearful relationship to the computer, because such applications place the player much more intensively immersed in the game world. The machine as a tool does not lose its meaning but its functionality and usability are being developed towards more entertainment-like attributes. The interface is an environment and a structural system that consists of the physical machine, a virtual programming environment, and the user. The system becomes perfect when all its parts will unite as a functional, interactive whole. Significant thresholds will arise through the hapticity of the interface, on one hand questioning the bodily relationship between user and machine and on the other hand creating new ways of being with the machine. New haptic (wearable computing) and spatial (sensors in a reactive space) interfaces raise the question of man-machine symbiosis from a new perspective. Interfaces in a Game World In games the man-machine relationship is seen with much less emotion than when using medical applications, for example. The strength of electronic games is in the goal-oriented interaction. The passivity of older machines has been replaced by the information platform where the player's actions have an immediate effect in the virtual world. The player is already surrounded by the computer: at home sitting by the computer holding a joystick and in the arcades sometimes sitting inside the computer or even being tied up with the computer (as in gyroscope VR applications). The symbiosis in game environments is essential and simple. During the 1980s and 1990s a lot of different virtual reality gear variants were developed in the "VR boom". Some systems were more or less masked arcade game machines that did not offer any real virtuality. Virtuality was seen as a new way of working with a machine, but most of the applications did not support the idea far enough. Neither did the developers pay attention to interface design nor to new ways of experiencing and feeling pleasure through the machine. At that time the most important thing was to build a plausible "virtual reality system". Under the futuristic cover of the machine there was usually a PC and a joystick or mouse. Usually a system could easily be labelled as a virtual theater, a dome or a cabin, which all refer to entertainment simulators. At the beginning of the 1990s, data glasses and gloves were the most widely used interfaces within the new interaction systems. Later the development turned from haptic interfaces towards more spatial ideas -- from wearable systems to interaction environments. Still there are only few innovative applications available. One good example is Vivid Group's old Mandala VR system which was later in the 1990s developed further to the Holopod system. It has been promoted as the interface of the future and new way of being with the computer. As in the film Modern Times so also with Holopod the player is in a way sucked inside the game world. But this time with the user's consent. Behind the Holopod is Vivid Group's Mandala VGC (Video Gesture Control) technology which they have been developing since 1986. The Mandala VGC system combines real time video images of the player with the game scene. The player in the real world is the protagonist in the game world. So the real world and the game world are united. That makes it possible to sense the real time movement as well as interaction between the platform and the player. Also other manufacturers like American Holoplex has developed similar systems. Their system is called ThunderCam. Like Konami's Dance Dance Revolution, it asks heavy physical involvement in the Street Fighter combat game. Man-Man and Man-Machine Cooperation One of the most important elements in electronic games has been reaction ability. Now the playing is turning closer to a new sport. Different force feedback systems combined with haptic interfaces will create much more diverse examples of action. For example, the Japanese Konami corporation has developed a haptic version of a popular Playstation dance game where karaoke and an electronic version of the Twister game are combined. Besides new man-machine cooperative applications, there are also under development some multi-user environments where the user interacts with the computer-generated world as well as with other players. The Land of Snow and Ice has been under development for about a year now in the University of Lapland, Finland. It is a tourism project that is supposed to be able to create a sensation of the arctic environment throughout the year. Temperature and atmosphere are created with the help of refrigerating equipment. In the space there are virtual theatre and enhanced ski-doo as interfaces. The 3-D software makes the sensation very intense, and a hydraulic platform extends the experience. The Land of Snow and Ice is interesting from the point of view of the man-machine relationship in the way that it brings a new idea to the interface design: the use of everyday objects as interfaces. The machine is "hidden" inside an everyday object and one is interacting and using the machine in a more natural way. For example, the Norwegian media artist Stahl Stenslie has developed "an 'intelligent' couch through which you communicate using your body through tactile and visual stimuli". Besides art works he has also talked about new everyday communication environments, where the table in a café could be a communication tool. One step towards Stenslie's idea has already become reality in Lasipalatsi café in Helsinki, Finland. The tables are good for their primary purpose, but you can also surf the Internet and read your e-mail with them, while drinking your tea. These kind of ideas have also been presented within 'intelligent home' speculations. Intelligent homes have gained acceptance and there are already several intelligent homes in the world. Naturally there will always be opposition, because the surface between man and machine is still a very delicate issue. In spite of this, I see such homogeneous countries as Finland, for example, to be a good testing ground for a further development of new man-machine interaction systems. Pleasure seems to be one of the key words of the future, and with the new technology, one can make everyday routines easier, pleasure more intense and the Internet a part of social communication: within the virtual as well as in real world communities. In brief, I have introduced two ideas: using games as a testing ground, and embedding haptic and spatial interfaces inside everyday objects. It is always difficult to predict the future and there are always at least technology, marketing forces, popular culture and users that will affect what the man-machine relationship of the future will be like. I see games and game interfaces as the new developing ground for a new kind of man-machine relationship. References Barfield, W., and T.A. Furness. Virtual Environments and Advanced Interface Design. New York: Oxford UP, 1995. Brown, Les, and Sema Marks. Electric Media. New York: Hargrove Brace Jovanovich, 1974. Burdea, G., and P. Coiffet. Virtual Reality Technology. New York: John Wiley and Sons, 1994. Greelish, David. "Hictorically Brewed Magazine. A Retrospective." Classic Computing. 1 Sep. 1999 &lt;http://www.classiccomputing.com/mag.php&gt;. Huhtamo, Erkki. "Odottavasta Operaattorista Kärsimättömäksi Käyttäjäksi. Interaktiivisuuden Arkeologiaa." Mediaevoluutiota. Eds. Kari Hintikka and Seppo Kuivakari. Rovaniemi: U of Lapland P, 1997. Jones, Steve, ed. Virtual Culture: Identity and Communication in Cybersociety. Thousand Oaks, Calif.: Sage, 1997. Kuivakari, Seppo, ed. Keholliset Käyttöliittymät. Helsinki: TEKES, 1999. 1 Sep. 1999 &lt;http://media.urova.fi/~raid&gt;. Licklider, J.C.R. "Man-Computer Symbiosis." 1960. 1 Sep. 1999 &lt;http://memex.org/licklider.pdf&gt;. Picard, Rosalind W. Affective Computing. Cambridge, Mass.: MIT P, 1997. "Return of the Luddites". Interview with Kirkpatrick Sale. Wired Magazine June 1995. Stenslie, Stahl. Artworks. 1 Sep. 1999 &lt;http://sirene.nta.no/stahl/&gt;. Citation reference for this article MLA style: Sonja Kangas. "From Haptic Interfaces to Man-Machine Symbiosis." M/C: A Journal of Media and Culture 2.6 (1999). [your date of access] &lt;http://www.uq.edu.au/mc/9909/haptic.php&gt;. Chicago style: Sonja Kangas, "From Haptic Interfaces to Man-Machine Symbiosis," M/C: A Journal of Media and Culture 2, no. 6 (1999), &lt;http://www.uq.edu.au/mc/9909/haptic.php&gt; ([your date of access]). APA style: Sonja Kangas. (1999) From haptic interfaces to man-machine symbiosis. M/C: A Journal of Media and Culture 2(6). &lt;http://www.uq.edu.au/mc/9909/haptic.php&gt; ([your date of access]).
ER  -
TY  - JOUR
TI  - Special Session â??Challenges in Engineering Education within Control Automation
PY  - 2010
SN  - 2626-8493
T2  - International Journal of Online and Biomedical Engineering (iJOE)
DO  - 10.3991/ijoe.v6i1.1202
UR  - https://doi.org/10.3991/ijoe.v6i1.1202
DA  - 2010-01-20
AU  - Papers, Call
LA  - en
VL  - 6
IS  - 1
SP  - 40
EP  - 40
AB  - Special Session "Challenges in EngineeringEducation within Control Automation" within 8th International Symposium on Soft Computing for Industry (ISSCI) This special session aims to open the discussion on challenges in Engineering Education with special scope in Control Automation by providing a forum for sharing approaches, developments and experiences at under and postgraduate levels.The effectiveness of fundamental knowledge needs to guaranty simultaneously the spirit of engineering leadership in society and the lifelong learning capability.The topics include (but are not limited to): -Innovation and creativity in MSc and PhD degrees.-Student projects vs. industrial solutions and collaborations.-Integrating engineering with basic sciences.-Multidisciplinary experiences in Control & Automation engineering -Project based learning: Integrating undergraduate students working in research projects.-Student development of Intelligent Actuation and Sensing.-Mechatronics System for student training.-Human-machine interaction in the training process.-Haptic devices applications for training purposes.-Mixed reality for training purposes in academia or in an industrial environment.-Applications of distance/remote/virtual learning vs. industrial demands.-New eLearning applications in academia and in industry.
ER  -
TY  - JOUR
TI  - Design a socialVR tool for the remote co-design of customized cakes
PY  - 2020
DA  - 2020-01-01
AU  - Mei, Yidan
LA  - en
KW  - Communication design
ER  -
TY  - CHAP
TI  - Using Animation to Enhance 3D User Interfaces for Multimedia
PY  - 2011
PB  - IGI Global
T2  - IGI Global eBooks
DO  - 10.4018/9781930708006.ch011
UR  - https://doi.org/10.4018/9781930708006.ch011
DA  - 2011-01-18
AU  - Thomas, Bruce
C1  - University of South Australia, Australia
LA  - en
ER  -
TY  - JOUR
TI  - Explorative study towards the integration and combination of three technologies into a virtual control system
PY  - 2019
DA  - 2019-01-01
AU  - Spel, Bart
LA  - en
KW  - Component (thermodynamics)
KW  - Teleoperation
KW  - Avatar
ER  -
TY  - GEN
TI  - Reference Architecture of the Tactile Internet
PY  - 2021
DO  - 10.1002/9781119881087.ch2
UR  - https://doi.org/10.1002/9781119881087.ch2
DA  - 2021-12-03
AU  - ahiya, Tara
C1  - Department of Computer Science, University of Paris-Saclay, France
LA  - en
KW  - Teleoperation
SP  - 13
EP  - 20
ER  -
TY  - JOUR
TI  - 13‐2: An Electrotactile‐Centered Cross‐Modal Application for Immersive Virtual Reality
PY  - 2025
PB  - Wiley
SN  - 0097-966X
T2  - SID Symposium Digest of Technical Papers
DO  - 10.1002/sdtp.18737
UR  - https://doi.org/10.1002/sdtp.18737
DA  - 2025-06-01
AU  - Huang, Jing‐Ye
C1  - School of Electronic Science and Engineering Southeast University  Nanjing P.R. China 211189
AU  - Zhang, Kang
C1  - School of Electronic Science and Engineering Southeast University  Nanjing P.R. China 211189
AU  - Gao, Zhengyang
C1  - School of Electronic Science and Engineering Southeast University  Nanjing P.R. China 211189
AU  - Rui, Zebao
C1  - School of Electronic Science and Engineering Southeast University  Nanjing P.R. China 211189
AU  - Zhang, Xiong
C1  - School of Electronic Science and Engineering Southeast University  Nanjing P.R. China 211189
LA  - en
VL  - 56
IS  - S1
SP  - 108
EP  - 111
ER  -
TY  - JOUR
TI  - FOREWORD
PY  - 2018
PB  - Institute of Electronics, Information and Communication Engineers
SN  - 0916-8532
T2  - IEICE Transactions on Information and Systems
DO  - 10.1587/transinf.2016iif0001
UR  - https://doi.org/10.1587/transinf.2016iif0001
DA  - 2018-01-01
AU  - Kunifuji, Susumu
C1  - Japan Advanced Institute of Science and Technology (JAIST)
AU  - THEERAMUNKONG, Thanaruk
C1  - SIIT, Thammasat University
LA  - en
VL  - E101.D
IS  - 4
SP  - 836
EP  - 837
AB  - Welcome to the Special Section on Intelligent Information and Communication Technology and its Applications to Creative Activity Support, the IEICE Transactions on Information and Systems.With wide spread of terminals, sensors, and other mobile devices, together with the primary data gathered and accumulated through them, it is now possible to have accurate predictions of succeeding events and phenomena, and more attention has been paid to the development and employment of the systems and products utilizing those data that contribute to improvements of creative activities in our daily life, business, medical treatment, education, and creation all of which are based on advanced intelligent processing of knowledge and information.This trend has necessitated collaborations and integrations among academic fields including information science, language sciences, and knowledge science, and essential is to let computers learn, construct, and assess adequate models of the reality and its advanced knowledge processing with a high precision at a greater speed.The state of the art of knowledge information and communication that assumes those collaborations and integrations has born new areas and technologies including service science, robotics, artificial intelligence, haptics, sensor networking, mechatronics, and virtual reality, to name a few.Even more collaborations and integrations are further expected, while existing techniques and technologies also wait for radical innovations due to the unprecedented alterations of available data in size and quality.
ER  -
TY  - JOUR
TI  - Game-like virtual reality interfaces as a new paradigm in architecture/engineering/construction design simulation
PY  - 2012
DA  - 2012-10-01
AU  - Rahimian, Farzad
C1  - Architecture
AU  - Ibrahim, Rahinah
C1  - University of Central Lancashire
LA  - en
KW  - Interactivity
KW  - Integrated project delivery
SP  - 115
EP  - 121
ER  -
TY  - JOUR
TI  - Algorithm of position-based dynamics and cutting simulation for soft tissue using tetrahedral mesh
PY  - 2015
PB  - Beijing University of Aeronautics and Astronautics (BUAA)
SN  - 1001-5965
T2  - Beijing Hangkong Hangtian Daxue xuebao
DA  - 2015-01-01
AU  - Junxua, Bai
C1  - School of Computer Science and Engineering,Beijing University of Aeronautics and Astronautics
LA  - en
KW  - Tetrahedron
KW  - Position (finance)
ER  -
TY  - JOUR
TI  - Both-handed 6DOF Manipulation with Force Feedback for Multi-Projection D-vision System
PY  - 2006
PB  - China Aerospace Science and Industry Corporation
SN  - 1006-9348
T2  - Jisuanji fangzhen
DA  - 2006-01-01
AU  - Xue-hui, Liu
C1  - Murayama Jun3
LA  - en
KW  - Machine Vision
ER  -
TY  - BOOK
TI  - Graphics Interface 2006 : Québec, Québec, Canada, June 7-9, 2006 : proceedings
PY  - 2006
DA  - 2006-01-01
AU  - Mann, Stephen
AU  - Gutwin, Carl
LA  - en
KW  - Scientific visualization
KW  - Parallel rendering
KW  - Real-time rendering
ER  -
TY  - JOUR
TI  - Digital twin embodied interactions design: Synchronized and aligned physical sensation in location-based social VR
PY  - 2025
PB  - Frontiers Media
SN  - 2673-4192
T2  - Frontiers in Virtual Reality
DO  - 10.3389/frvir.2025.1499845
UR  - https://doi.org/10.3389/frvir.2025.1499845
DA  - 2025-05-21
AU  - Zhang, Ju
AU  - Ma, Fang
AU  - Pi, Yuke
AU  - Du, Haoyang
AU  - Pan, Xiaoqing
LA  - en
KW  - Sensation
KW  - Sensation Seeking
VL  - 6
AB  - Digital twin technologies have become increasingly relevant in virtual reality, offering precise 1:1 mapping between physical environments and their virtual counterparts. While previous work has focused on object interaction through passive haptics, little attention has been given to how such environments can support social and embodied interactions that feel natural and expressive. In this work, we extend the digital twin paradigm by integrating full-body avatars, hand tracking, and voice-driven facial animation into a location-based VR environment. To explore the interactive potential of this dual-realm environment, we propose three categories of cross-realm embodied interaction: (1) Tangible interaction, exemplified by spatially aligned object manipulation; (2) Social gesture, supported through expressive hand and body movement; and (3) Social touch, including co-located tactile actions such as handshakes and hugs. We developed a prototype system showing all three embodied interactions, supported by passive haptics, precise spatial alignment, and real-time multiplayer synchronization. We also introduced a low-cost, Wi-Fi-based motion tracking prototype to enhance interaction with movable physical elements. We evaluate the system through expert interviews, identifying key themes related to spatial trust, tactile realism, and interpersonal presence. Our findings suggested that precise alignment and embodied social cues significantly enhance immersion and social connectedness. This work contributes towards a replicable framework for designing socially immersive digital twin experiences and opens new directions for location-based VR in collaborative and educational contexts.
ER  -
TY  - JOUR
TI  - Adversity and Turnaround in Medical Education:Development and vision of a framework for a multimodal teaching and learning interaction model (Preprint)
PY  - 2023
DO  - 10.2196/preprints.47503
UR  - https://doi.org/10.2196/preprints.47503
DA  - 2023-03-22
AU  - Ying, Liang
AU  - Cheng, Zhangyu
AU  - Sun, Jiaju
AU  - Chen, Linjunliang
AU  - Ye, Zijun
AU  - Ye, Qing
AU  - Xu, Haichao
AU  - Wu, Xinyu
AU  - Hong, Xiaochang
AU  - Chen, Tongke
LA  - en
KW  - Situational ethics
KW  - Multimodality
ER  -
TY  - JOUR
TI  - Pain Distraction for Children Through VR- or Audio-haptic Soundscapes in Situ
PY  - 2023
DO  - 10.1145/3611659.3617220
UR  - https://doi.org/10.1145/3611659.3617220
DA  - 2023-10-09
AU  - Bordum, Maya
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Engberg, Emil
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Hansen, Peter
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Jensen, Nickolai
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Jægerlund, Martin
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Mouritzen, Jeppe
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Poulsen, Hannibal
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Ravnsborg, Lukas
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Rybak, Celine
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Stappert, Frederik
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Troldahl, Bjørn
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Winther, Julius
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
AU  - Nordahl, Rolf
C1  - Dept. of Architecture, Design and Media Technology, Aalborg University Copenhagen, Denmark
LA  - en
KW  - Soundscape
KW  - Audio visual
SP  - 1
EP  - 3
ER  -
TY  - THES
TI  - Strategic Deployment of Artificial Intelligence-Enhanced Cloudlets for Low-latency Human-to-Machine Applications
PY  - 2020
DA  - 2020-01-01
AU  - Mondal, Sourav
LA  - en
KW  - Cloudlet
KW  - Mobile Cloud Computing
ER  -
TY  - JOUR
TI  - Adversity and Turnaround in Medical Education:Development and vision of a framework for a multimodal teaching and learning interaction model
PY  - 2024
PB  - Research Square (United States)
T2  - Research Square (Research Square)
DO  - 10.21203/rs.3.rs-3994192/v1
UR  - https://doi.org/10.21203/rs.3.rs-3994192/v1
DA  - 2024-04-01
AU  - Ying, Liang
C1  - School of Education, Zhejiang Normal University
AU  - Xu, Haichao
C1  - Renji College, Wenzhou Medical University
AU  - Sun, Jiaju
C1  - School of Laboratory Medicine and Life Science, Wenzhou Medical University
AU  - Chen, Linjunliang
C1  - School of Ophthalmology and Optometry, Eye Hospital, Wenzhou Medical University
AU  - Ye, Zijun
C1  - The First Clinical Medical College, Wenzhou Medical University
AU  - Ye, Qing
C1  - The First Clinical Medical College, Wenzhou Medical University
AU  - Cheng, Zhangyu
C1  - Department of Psychology, Wenzhou Medical University
AU  - Wu, Xinyu
C1  - Renji College, Wenzhou Medical University
AU  - Hong, Xiaochang
C1  - Communist Youth League Committee, Wenzhou Medical University
AU  - Li, Feiming
C1  - School of Education, Zhejiang Normal University
AU  - Chen, Tongke
C1  - Laboratory Animal Center, Wenzhou Medical University
LA  - en
AB  - Abstract Background Post-pandemic era has provided an opportunity for new educational theory as long as the new way to make use of technology. This paper puts forward the architecture of the multimodal teaching interaction model and the prospect of application situations combining the research foundations of technological phenomenology and multimodal theory. Objective This paper aims to clarify a multimodal teaching interaction model perspective, we hope the interactive feedback between medical education subjects can be improved, meet the teaching and learning needs in the post-epidemic era, and promote the development of medical education reform. The focal point is the characteristics, structure, and application of MTIM. Method Using the behavioral education model, situational learning, and human-computer interaction theory as the theoretical framework, we take the medical teaching model as the background, combined with cutting-edge virtual reality, haptic feedback, gesture interaction, and other technologies, rely on the multi-level application architecture such as physical layer and perceptual feedback layer, to successfully build a teaching method of multimodal virtual experience and the overall conceptual framework of learning scenarios. Results This is an innovative conceptual model that focuses on the fundamentals of the overall framework. The characteristics of the model have obvious application advantages in three types of virtual medical education scenarios: "Theoretical knowledge learning", "Operational skill learning" and "Practical experiential learning". And through the characteristics of model immersion, collaboration, dynamic feedback, and other characteristics, the cross-spatial connection between virtual and real is established, which greatly breaks through the limitations of space scenes. Conclusion The multimodal teaching interaction model(MTIM) broadens the application scenarios of teaching, effectively enhances the sense of reality and experience of situational teaching, has great application prospects for promoting the development of medical education reform, and provides some feasible ideas and suggestions for the future development of artificial intelligence in medical education.
ER  -
TY  - JOUR
TI  - Investigating Trainee Perspectives on Virtual Reality Environments: An In-Depth Examination of Immersive Experiences with Haptic Feedback Vibration
PY  - 2024
T2  - 2022 IEEE International Systems Conference (SysCon)
DO  - 10.1109/syscon61195.2024.10553420
UR  - https://doi.org/10.1109/syscon61195.2024.10553420
DA  - 2024-04-15
AU  - Xanthidou, Ourania
C1  - Computer Science, Brunel University London, London, U.K.
AU  - Aburumman, Nadine
C1  - Computer Science, Brunel University London, London, U.K.
AU  - Ben‐Abdallah, Hanêne
C1  - Higher Colleges of Technology,Computer Information Science &#x0026; Applied Media,Dubai,U.A.E.
LA  - en
SP  - 1
EP  - 8
AB  - This research investigates trainee reflections on Virtual Reality Environments (VREs) within educational training centers, aiming to understand their experiences, perceptions, and preferences. The study focuses on the impact of haptic feedback vibrations, examining both their general effects during VRE interactions and the specific influence of adaptable vibration configurations triggered by user errors. A convenience sample of 81 participants/trainees, 41 from the computer science and 40 from the aviation engineering departments of a major higher education institution in the U.A.E., was used to run four variations of the same VRE, with two from each field. Results indicate that participants largely embraced the VRE experience, reporting feelings of contentment, joy, and competence. Haptic feedback, particularly in non-adaptable forms, was acknowledged as enhancing the immersive experience. However, the study suggests that further research is needed to explore the nuanced role of adaptable vibration, especially in more complex interactions. Notably, participants expressed a preference for a blended approach, advocating for both VREs and physical labs in their training. The study acknowledges limitations, such as the predominantly single-user focus, and recommends future research extensions into collaborative VRE settings, more intricate interactions, and potential technical issues in multi-user scenarios. Overall, this research sheds light on the evolving landscape of educational training, emphasizing the importance of understanding trainee perspectives to optimize the integration of VREs in learning environments.
ER  -
TY  - GEN
TI  - The Reality of Virtual Human Connections
PY  - 2025
DO  - 10.1002/9781394278480.ch3
UR  - https://doi.org/10.1002/9781394278480.ch3
DA  - 2025-01-10
AU  - Altvater, Rachel
LA  - en
SP  - 27
EP  - 37
ER  -
TY  - JOUR
TI  - Toward a Frontierless Collaboration in Neurosurgery: A Systematic Review of Remote Augmented and Virtual Reality Technologies
PY  - 2024
PB  - Research Square (United States)
T2  - Research Square (Research Square)
DO  - 10.21203/rs.3.rs-3922557/v2
UR  - https://doi.org/10.21203/rs.3.rs-3922557/v2
DA  - 2024-02-07
AU  - Bocanegra‐Becerra, Jhon
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Sánchez, José
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Castilla-Encinas, Adriam
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Sociedad Científica de San Fernando, Universidad Nacional Mayor de San Marcos, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Ríos-García, Wagner
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Mendieta, Cristian
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Pontificia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Quiroz-Marcelo, Diego
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Alhwaishel, Khaled
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Aguilar-Zegarra, Luis
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - López-González, Miguel
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
LA  - en
KW  - Subspecialty
AB  - <title>Abstract</title> <bold>Introduction</bold> Augmented Reality (AR) and Virtual Reality (VR) technologies have been introduced to Neurosurgery with the goal of improving the experience of human visualization. In recent years, the application of remote AR and VR has opened new horizons for neurosurgical collaboration across diverse domains of education and patient treatment. Herein, we aimed to systematically review the literature about the feasibility of this technology and discuss the technical aspects, current limitations, and future perspectives.<bold>Methods</bold> Following the PRISMA guidelines, four databases (PubMed, Embase, Scopus, and Cochrane Library) were queried for articles discussing the use of remote AR and VR technologies in Neurosurgery. Data were collected in various fields, including surgery type, application type, subspecialty, software and hardware descriptions, haptic device utilization, visualization technology, internet connection, remote site descriptions, technical outcomes, and limitations. Data were summarized as counts and proportions and analyzed using IBM® SPSS® software.<bold>Results</bold> Our search strategy generated 466 records, out of which 9 studies satisfied the inclusion criteria. The majority of AR and VR applications were used in cranial procedures (77.8%), mainly in education (63.6%), followed by telesurgical assistance (18.2%), patient monitoring (9.1%), and surgical planning (9.1%). Local collaborations were established in 55.6% of the studies, while national and international partnerships were formed in 44.4% of the studies. AR was the main visualization technology, and 3G internet connection was predominantly used (27.5%). All studies subjectively reported the utility of remote AR and VR for real-time interaction. The major technical challenges and limitations included audiovisual latency, the requirement for higher-fidelity and resolution image reconstructions, and the level of proficiency of the patient with the software.<bold>Conclusion</bold> The results from this systematic review suggest that AR and VR technologies are dynamically advancing to offer remote collaboration in Neurosurgery. Although still incipient in development and with an imperative need for technical improvement, remote AR and VR hold a frontierless potential for patient monitoring, neurosurgical education, and long-distance surgical assistance.
ER  -
TY  - JOUR
TI  - Toward a Frontierless Collaboration in Neurosurgery: A Systematic Review of Remote Augmented and Virtual Reality Technologies
PY  - 2024
PB  - Research Square (United States)
T2  - Research Square (Research Square)
DO  - 10.21203/rs.3.rs-3922557/v1
UR  - https://doi.org/10.21203/rs.3.rs-3922557/v1
DA  - 2024-02-06
AU  - Bocanegra‐Becerra, Jhon
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Sánchez, José
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Castilla-Encinas, Adriam
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Sociedad Científica de San Fernando, Universidad Nacional Mayor de San Marcos, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Ríos-García, Wagner
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Mendieta, Cristian
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Pontificia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Quiroz-Marcelo, Diego
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Alhwaishel, Khaled
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - Aguilar-Zegarra, Luis
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
AU  - López-González, Miguel
C1  - Department of Neurosurgery, Loma Linda University Medical Center, Loma Linda, California, United States
C1  - Facultad de Medicina Humana, Universidad Nacional San Luis Gonzaga, Ica, Peru
C1  - Mansoura Manchester Program, Faculty of Medicine, Mansoura University, Mansoura, Egypt
C1  - School of Medicine, Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Universidad Mayor Real y Ponti cia de San Francisco Xavier de Chuquisaca, Bolivia
C1  - Universidad Peruana Cayetano Heredia, Lima, Peru
C1  - Vascular Neurosurgery and Skull Base Division, Department of Neurosurgery, Hospital Nacional Dos de Mayo, Lima, Peru
LA  - en
KW  - Subspecialty
AB  - <title>Abstract</title> <bold>Introduction</bold> Augmented Reality (AR) and Virtual Reality (VR) technologies have been introduced to Neurosurgery with the goal of improving the experience of human visualization. In recent years, the application of remote AR and VR has opened new horizons for neurosurgical collaboration across diverse domains of education and patient treatment. Herein, we aimed to systematically review the literature about the feasibility of this technology and discuss the technical aspects, current limitations, and future perspectives.<bold>Methods</bold> Following the PRISMA guidelines, four databases (PubMed, Embase, Scopus, and Cochrane Library) were queried for articles discussing the use of remote AR and VR technologies in Neurosurgery. Data were collected in various fields, including surgery type, application type, subspecialty, software and hardware descriptions, haptic device utilization, visualization technology, internet connection, remote site descriptions, technical outcomes, and limitations. Data were summarized as counts and proportions and analyzed using IBM® SPSS® software.<bold>Results</bold> Our search strategy generated 466 records, out of which 9 studies satisfied the inclusion criteria. The majority of AR and VR applications were used in cranial procedures (77.8%), mainly in education (63.6%), followed by telesurgical assistance (18.2%), patient monitoring (9.1%), and surgical planning (9.1%). Local collaborations were established in 55.6% of the studies, while national and international partnerships were formed in 44.4% of the studies. AR was the main visualization technology, and 3G internet connection was predominantly used (27.5%). All studies subjectively reported the utility of remote AR and VR for real-time interaction. The major technical challenges and limitations included audiovisual latency, the requirement for higher-fidelity and resolution image reconstructions, and the level of proficiency of the patient with the software.<bold>Conclusion</bold> The results from this systematic review suggest that AR and VR technologies are dynamically advancing to offer remote collaboration in Neurosurgery. Although still incipient in development and with an imperative need for technical improvement, remote AR and VR hold a frontierless potential for patient monitoring, neurosurgical education, and long-distance surgical assistance.
ER  -
TY  - JOUR
TI  - Virtual Reality for Learning: Sharing Experiences rather than Resources
PY  - 2003
PB  - British Computer Society
SN  - 1477-9358
T2  - Electronic workshops in computing
DO  - 10.14236/ewic/3lege2003.16
UR  - https://doi.org/10.14236/ewic/3lege2003.16
DA  - 2003-12-01
AU  - Kommers, Piet
C1  - University of Twente, Faculty of Behavioral Sciences, Division of Educational Instrumentation#TAB#
LA  - en
KW  - Work space
KW  - Intuition
KW  - Instructional simulation
AB  - Virtual Reality is becoming a major candidate for embodying immersive learning environments. Whereas in the two preceding decades learning has been conceptualized as situations where students are guided rather than elicited to undertake actions, it is now the right time to explore the other side or the continuum. The tradition of instruction starts from the idea that knowledge and skills need a process of gradual incremental complexity, and thus teaching is the guided tour from initial to finally the execution target performance. At the same time it is a common sense experience that students always build upon earlier experiences and intuition, even if it stems from a slightly different domain.New learning communities rely upon the evidence that learning has both a cognitive, perceptual and social dimension. Virtual Reality allows learning partners to share views, haptics and even allow collaborative experimentation. This workshop will present the more dominant scenarios for Virtual Didactic Laboratories; the needed roles, its mechanisms for self-organisation, diagnostics and final assessment. Demonstrators of VR didactic metaphors will be presented and discussed upon its final implications. The Dime en VRINT projects demonstrate how VR may work out in surgical training. However there are strong indications that the less-advanced 2D shared workspaces have even a more important message here; it is the notion that students need an activity space in order to literally "construct" meanings, concepts and formalities. GRID technologies are not only an answer to the technical needs; they also elicit educational architects to express ideas that went beyond our imagination before. One of them is the challenging idea that learners share spatial models of how they see critical interventions like in medicine, biology and astrophysics; the primitives are objects like human tissues and procedures to be executed. The learning partners will negotiate on best practices seen immediate (visible or tactile) side-effects and thus develop a much more intense apprenticeship than the normal side-looking experience where the expert surgeon just demonstrates his/her best solutions. GRID methodology like proposed collaboratories, and coupled CAVES. The presentation will end up with metaphoric methods to transform educational and training approaches into the arena of GRID-based experiences. Also the projects in the medical domain will be extrapolated into those of engineering, urban planning and art manifestations. Underlying methodology is to map relevant dimensions, scale ontologies for autonomies agents so that learner communities may manifest on self organisation rather than orchestration by the instructor.
ER  -
TY  - JOUR
TI  - Simuladores hápticos con entornos de realidad virtual en educación dental: un diagnóstico de enseñanza preliminar
PY  - 2017
PB  - Servei de Formació Permanent i Innovació Educativa, Universitat de València
SN  - 1989-3477
T2  - tic revista d innovació educativa
DA  - 2017-01-01
AU  - Coro‐Montanet, Gleyvis
AU  - Sánchez, Margarita
AU  - Suárez, Ana
LA  - en
KW  - Trainer
KW  - IBM
IS  - 18
SP  - 14
EP  - 21
ER  -
TY  - JOUR
TI  - Simulateur collaboratif de chirurgie d'instrumentation du rachis scoliotique en réalité virtuelle avec interface haptique logicielle
PY  - 2010
DA  - 2010-08-01
AU  - Côté, Mélissa
LA  - fr
ER  -
TY  - JOUR
TI  - Human-Centered AI integration in nautical architecture: enhancing design processes through emotion recognition and intelligent systems
PY  - 2025
SN  - 2771-0718
T2  - AHFE international
DO  - 10.54941/ahfe1006545
UR  - https://doi.org/10.54941/ahfe1006545
DA  - 2025-01-01
AU  - Pagani, Laura
AU  - Gemelli, Paolo
AU  - Bertirotti, Alessandro
AU  - Zignego, Mario
LA  - en
VL  - 186
ER  -
TY  - CHAP
TI  - The contemporary architectural concept of the coherence of space and time in Andreas Meck's projects
PY  - 2023
PB  - Multidisciplinary Digital Publishing Institute
SN  - 2813-9526
T2  - Time and space
DO  - 10.1201/9781003260554-26
UR  - https://doi.org/10.1201/9781003260554-26
DA  - 2023-10-25
AU  - Serafin, Aleksander
C1  - Institute of Architecture and Urban Planning, Faculty of Civil Engineering, Architecture and Environmental Engineering, Lodz University of Technology, Lodz, Poland
LA  - en
SP  - 183
EP  - 187
AB  - One of the keys to understanding contemporary architecture is the interaction between time and space. A phenomenological solution can be distinguished among the various approaches to this issue. The research subject is two selected completed projects by Andreas Meck (1959-2019) in Munich (Germany). The works of the architect deserve attention not only because of their special artistic qualities but also because of their unique symbolic meaning and timeless character. Meck implemented phenomenology in architectural design in the early stages when Peter Zumthor promoted this trend. Meck's designs correspond to Zumthor's writings. His funeral center in the Riem district, designed in collaboration with Stephan Köppel, was created according to the phenomenological concept 'motion, weight, and substance'. This triad was popularized in the theory of architecture by Thomas Thiis-Evensen in the 1980s. A second later work by Andreas Meck was designed together with Wolfgang Amann, Susanne Frank, Peter Fretschner, Wolfgang Kusterer, and Werner Schad. The cultural and spiritual center at the Nordheide estate presents an even more advanced implementation of phenomenological rules. At first glance, all the buildings are examples of contemporary minimalist architecture, but a more detailed study shows that designs are, in fact, a more advanced and subtle play of the senses. These issues are especially relevant from the point of view of the parallel form development toward virtual reality and haptic architecture.
ER  -
TY  - THES
TI  - Toward spatial impedance estimation for robotic systems
PY  - 2018
DA  - 2018-01-01
AU  - Graziosi, Damiano
LA  - en
KW  - Teleoperation
KW  - Situation Awareness
KW  - Telerobotics
ER  -
TY  - JOUR
TI  - Virtual reality in restorative dentistry: a bibliometric analysis of research trends
PY  - 2025
PB  - Springer Nature
SN  - 2056-807X
T2  - BDJ Open
DO  - 10.1038/s41405-025-00364-2
UR  - https://doi.org/10.1038/s41405-025-00364-2
DA  - 2025-09-02
AU  - Matoug‐Elwerfelli, Manal
C1  - Department of Pre-Clinical Oral Sciences, College of Dental Medicine, QU Health, Qatar University, Doha, Qatar
AU  - Daud, Alaa
C1  - Department of Pre-Clinical Oral Sciences, College of Dental Medicine, QU Health, Qatar University, Doha, Qatar
AU  - Ali, Kamran
C1  - Department of Pre-Clinical Oral Sciences, College of Dental Medicine, QU Health, Qatar University, Doha, Qatar
AU  - Abdou, Ahmed
C1  - Department of Restorative Dentistry, Faculty of Dentistry, Universiti Malaya, Kuala Lumpur, Malaysia
LA  - en
KW  - Restorative Dentistry
KW  - Dental education
KW  - Dental research
VL  - 11
IS  - 1
AB  - Abstract Background Virtual reality (VR) technologies are increasingly being adopted in dental education, particularly in restorative dentistry, due to their capacity to simulate realistic clinical scenarios and enhance student learning. However, despite the growing interest, the overall research landscape in this field remains unclear. This study aimed to conduct a bibliometric analysis to evaluate the most influential research contributions, publication trends, and collaborative patterns related to VR in restorative dentistry. Methods An advanced search of the Web of Science Core Collection (WoS-CC) database was performed on 29th October 2024 using a combination of keywords and Medical Subject Headings (MeSH) terms relevant to VR and restorative dentistry. Only original research and review articles in English were included. Bibliometric parameters such as citation metrics, authorship, institutional affiliations, countries of origin, and keywords were extracted and analyzed using Bibliometrix (R) and VOSviewer software. Results Out of 434 retrieved records, 62 articles met the inclusion criteria. A marked increase in publications was observed after 2019, with the USA, UK, and Netherlands emerging as the leading contributors. The most cited article received 73 citations, focusing on haptic simulators for motor skill acquisition. The Journal of Dental Education , the European Journal of Dental Education , and BMC Medical Education were among the most prolific journals. Despite global contributions, the analysis revealed limited interdisciplinary and international collaboration. Conclusion This bibliometric study highlights the increasing research activity surrounding VR in restorative dentistry and its potential to transform dental education. While considerable progress has been made, further high-quality research and broader collaborative efforts are necessary to address existing gaps and fully harness the capabilities of VR and related immersive technologies in dental education.
ER  -
TY  - JOUR
TI  - 사용자 경험을 위한 인터랙션 공간디자인 표현에 관한 연구
PY  - 2012
T2  - 한국실내디자인학회 논문집
DA  - 2012-08-01
AU  - , 김세영
LA  - en
KW  - Interface (matter)
VL  - 21
IS  - 4
SP  - 48
EP  - 56
ER  -
TY  - JOUR
TI  - 사용자 경험을 위한 인터랙션 공간디자인 표현에 관한 연구 :디지털 미디어를 중심으로
PY  - 2012
T2  - 한국실내디자인학회 논문집
DA  - 2012-08-01
AU  - , 김세영
LA  - en
KW  - Interface (matter)
VL  - 21
IS  - 4
SP  - 48
EP  - 56
ER  -
TY  - JOUR
TI  - Platform Technology for VR Biofeedback Training under Operant Conditioning for Functional Limb Weakness: A Proposal for Co-production of At-Home Solution (REACT2HOME) (Preprint)
PY  - 2025
PB  - JMIR Publications
SN  - 1929-0748
T2  - JMIR Research Protocols
DO  - 10.2196/70620
UR  - https://doi.org/10.2196/70620
DA  - 2025-07-03
AU  - Dutta, Anirban
C1  - Centre for Systems Modelling and Quantitative Biomedicine, University of Birmingham, Birmingham, United Kingdom.
AU  - Das, Abhijit
C1  - Lancashire Teaching Hospitals NHS Foundation Trust, Preston, United Kingdom.
LA  - en
KW  - Operant conditioning
KW  - Biofeedback
VL  - 14
SP  - e70620
EP  - e70620
AB  - Functional neurological disorder (FND), including functional movement disorders (FMDs), arises from disruptions in the perception-action cycle, where maladaptive cognitive learning processes reduce the sense of agency and motor control. FND significantly impacts quality of life, with patients often experiencing physical disability and psychological distress. Extended reality (XR) technologies present a novel therapeutic opportunity by leveraging biofeedback training to target sensory attenuation and amplification mechanisms, aiming to restore motor function and the sense of agency. This study aims to coproduce and evaluate the usability of an XR technology platform for FND rehabilitation, focusing on functional limb weakness. The platform integrates biofeedback training with haptic and visual feedback to support motor relearning and control. We propose to use an experience-based co-design framework to engage patients with FND, caregivers, and health care professionals in collaboratively designing the XR platform. Stakeholders can share their experiences through narrative interviews and co-design workshops, which can identify emotional touchpoints and prioritized patient-centered needs. Insights will be synthesized through qualitative analysis and used to guide the development of system requirements via quality function deployment, ensuring that the platform aligns with user needs. XR training tasks-virtual reality relaxation, XR position feedback, and XR force feedback-will be integrated as needed into a unified therapeutic game experience through 4-week Agile sprints. Usability will be assessed using the System Usability Scale and qualitative feedback, with themes analyzed in NVivo to identify key areas for subsequent improvement. High usability scores (>85) were recorded for the XR position feedback tasks in the predesign study, reflecting excellent usability and participant satisfaction. However, the virtual reality relaxation and XR force feedback tasks exhibited interindividual variability, underscoring the need for personalization. Key themes included customization, comfort, accessibility, and XR technological quality, ensuring that the XR platform effectively addressed diverse patient needs. The predesign study highlighted the potential of XR technology for FMD rehabilitation by integrating biofeedback training into a patient-centered game design framework. Approaches such as experience-based co-design and quality function deployment can support coproduction by systematically addressing usability and accessibility challenges. Brain-based metrics may further strengthen this evaluation. Accordingly, this study will use portable brain imaging to capture dynamic functional connectivity in key brain regions, enabling personalized interventions. Through coproduction and iterative refinement, this study aims to demonstrate the promise of personalized XR gaming technology as a scalable, at-home solution for FMD rehabilitation. In this context, personalization and accessibility are critical for optimizing usability and long-term clinical outcomes, paving the way for at-home implementation within the FND stepped care model. PRR1-10.2196/70620.
ER  -
TY  - THES
TI  - Virtual surgery and orthopaedic surgery : towards training using haptic technology
PY  - 2017
DA  - 2017-07-13
AU  - Hauck, Robert
LA  - en
KW  - Invasive surgery
KW  - Learning curve
KW  - Identification
ER  -
TY  - JOUR
TI  - Control of humanoid robots to realize haptic tasks in collaboration with a human operator
PY  - 2009
PB  - Centre National de la Recherche Scientifique
T2  - HAL (Le Centre pour la Communication Scientifique Directe)
DA  - 2009-12-07
AU  - Evrard, Paul
LA  - en
KW  - Human–robot interaction
AB  - Haptic collaborative tasks are actions performed jointly by several partners, involving direct or indirect physical contact among them. A typical example of such tasks are collaborative manipulation tasks, where the partners apply forces on a same object to impose it a desired motion or bring it to a target location. Human beings learn naturally how to perform such tasks with other human partners, but implementing such behaviors on a robotic platform is challenging. When jointly manipulating an object, the partners no longer act independently, and must negotiate a common plan to perform the task. To avoid conflicts among the partners' intentions, the leader-follower model defines a task leader, who imposes a task plan to the other partners, while the latter act as follower and follow at best the intentions of the leader. This model has often been used in physical Human-Robot Interaction (pHRI). Because robotic systems have limited cognitive capabilities in comparison to human beings, a follower role has generally been assigned to robotic systems to cooperate with human operators. Recently, thanks to the increasing computational power embedded into the robots, more and more initiative has been given to robotic assistants. In some recent works, robots were sometimes even given the possibility to lead human operators. In the context of physical tasks, where the partners are in direct or indirect contact through an object and exchange mechanical energy, we believe that the haptic channel is a favored and fast way for the partners to exchange information about their intentions. Therefore, this thesis will focus on the kinesthetic aspects of collaborative tasks. The long-term aim of the project is to endow humanoid robots with the necessary haptic skills to perform collaborative tasks with a human operator as a partner rather than as a helper. The work presented here proposes solutions towards this direction. In its first part, our contribution is to extend the leader-follower model to continuous, time-varying role distributions among the partners in the context of haptic dyadic collaborative tasks. This model describes the behavior of each partner of the dyad as a variable weighting between the two extreme leader and follower behaviors. Our goal is to abstract the concept of role distribution from the implementation of the underlying controllers, and to describe the behavior of dyads using two independent functions that will shape the behavior of each partner in term of leadership. We exemplify the use of our model in a virtual reality scenario where a human operator manipulates an object in cooperation with a virtual robotic system. We also explore possible strategies to exploit it. The problem we adress is to define how the weighting between both behaviors can be adjusted automatically on a robotic system, depending on various criteria such as constraints of the robot or knowledge from human-human haptic interaction. Simulations and experiments conducted on a humanoid robot are presented to illustrate the proposed solutions. The results show that the extended leader-follower model can be applied to realize collaborative tasks with a human operator while avoiding self-collision. The model also encompasses the specialization phenomenon recently highlighted in human-human collaborative haptic tasks. We then propose to use a programming by demonstration method to teach collaborative skills to a robotic system. This method uses a probabilistic framework to encode the characteristics of the task and reproduce it autonomously. This framework is based on Gaussian Mixture Models and Gaussian Mixture Regression and has been successfully applied to various stand-alone tasks. We remind the main components of this framework and present its application to collaborative lifting tasks between a humanoid robot and a human operator. Our first contribution is the design of the experimental setup, based on a teleoperation system whith kinesthetic feedback which allows the human teacher to demonstrate the task while taking into account the constraints and sensor data of the robotic system. The main contribution, however, is the use of this methodology to attempt to assess the validity of our extended leader-follower model, by highlighting smooth switching behaviors on human partners during collaborative lifting tasks. The experimental data aquired during reproductions of the task is analyzed within this perspective. The second part of this thesis focuses on the control of humanoid robots in the context of pHRI. We examine several paradigms of interaction: interaction between two remote human partners through a tele-presence system, direct interaction between an autonomous humanoid robot and a human operator, and collaborative transportation tasks between a human operator and a humanoid robot. Behind these different paradigms of interaction lies one common problem: the generation of whole-body motion and gait in response to external forces that arise from the haptic interaction with a human operator. This thesis does not aim at tackling the problem of gait generation at the mechanical and control level. We will rather use state-of-the-art algorithms which do not consider external disturbances, and show to what extent they can be used to generate complex and intuitive collaborative behaviors. Our contributions in this part are thus to integrate impedance control and gait generation within an existing control architecture in a generic and flexible way in order to (i) use the resulting controller in various contexts, (ii) demonstrate how the basic principles of impedance control can be implemented on a complex platform biped humanoid robot while exploiting all the capabilities of such platforms and (iii), highlight the limitations of the passivity-based approaches often used in pHRI, and thereby justify further research in the field of pHRI. The work presented in this part has been integrated within a complex demonstrator where the robot walks in a teleoperated manner and performs autonomously a collaborative transportation task with a human operator.
ER  -
TY  - JOUR
TI  - N0d0s_Camaleón: Control de eventos multimediales desde dispositivos móviles multiplataforma*
PY  - 2012
PB  - Universidad de Manizales
SN  - 0123-9678
T2  - Ventana informatica
DO  - 10.30554/ventanainform.27.143.2012
UR  - https://doi.org/10.30554/ventanainform.27.143.2012
DA  - 2012-12-20
AU  - Valencia, Mario
C1  - Universidad de Caldas
AU  - Manrique, Marlon
C1  - Universidad Autónoma de Manizales
AU  - Isaza, Gustavo
C1  - Universidad de Caldas
AU  - Zuluaga, Nelson
C1  - Universidad de Caldas
AU  - Vélez, Víctor
C1  - Universidad de Caldas
LA  - es
IS  - 27
AB  - Resumen En este artículo se presenta el proceso investigativo de las nuevas formas de comprensión de los espacios, el sonido y la imagen, fundamentado en la materialidad dada por el desarrollo tecnológico-digital, que permite trabajar con componentes visuales, sonoros y acústicos en el diseño de objetos, ambientes y/o espacios envolventes, a partir de la construcción de una plataforma de creación multimedia de control en tiempo real , que permite estudiar el modo en que se manipulan los objetos, la imagen y el sonido en ambientes de desarrollo y sistemas de control, que conducen a la implementación de controladores de este tipo en ambientes móviles. Se parte de la construcción de proyectos colaborativos soportados en metodologías de desarrollo tecnológico y análisis teórico que permiten comprender y relacionar temas como la interacción natural, las interfaces físicas, la interacción hombre - computadora (IHC), la realidad virtual, la háptica y el control, las metáforas post-escritorio, la computación ubicua, el diseño emocional y el diseño de interacción. Para el efecto se desarrolló un prototipo, denominado Camaleón, implementado para dispositivos con sistema operativo iOS y Android que se involucra en las aplicaciones de control multimedia, permitiendo a los usuarios interactuar con múltiples dispositivos. Palabras ClavesControl Multimedia, dispositivos móviles, iOS, Android. Abstract This paper aims to present the research process of new understandings of space, sound and image, based on the material provided by the digital-technology development, which allows working with visual components, audio and acoustic design objects, environments and / or surround areas, from building a multimedia creation platform real-time control, which allows the study of how objects are manipulated, the picture and sound settings and systems development control, leading to the implementation of this type drivers in mobile environments. The initial construction of projects supported collaborative technological development methodologies and theoretical analysis that allow understanding and interaction related issues such as natural, physical interfaces, the human - computer (HCI), virtual reality, haptics and control post-desktop metaphors, ubiquitous computing, emotional design and interaction design. For this purpose we developed a prototype, called Camaleón, implemented for devices with IOS and Android operating system that is involved in multimedia control applications, allowing users to interact with multiple devices.KeywordsMedia Control, mobile devices, IOS, Android.
ER  -
TY  - JOUR
TI  - Fantastic Media Fiction: Cognition, Design, Worldbuilding
PY  - 2019
PB  - Technical University of Denmark
T2  - Research Portal Denmark
DA  - 2019-01-01
AU  - Wille, Jakob
C1  - Royal Danish Academy - Architecture, Design, Conservation, Royal Danish Academy - Design, Institute of Visual Design, DK
AU  - Schubart, Rikke
C1  - The University of Southern Denmark, DK
AU  - Ndalianis, Angela
C1  - Swinburne University of Technology, Faculty of Design
AU  - Howell, Amanda
C1  - Griffith University
LA  - en
AB  - “This is pure, limitless magic,” a reviewer wrote about the unusual fantasy film Border (Gräns, 2018), “turning the world we seem to know inside out and giving it an entirely new context” (Carlsen 2018). Border is about Tina, an ugly border guard who can smell guilt on people – an impossible ability. But Tina turns out to be a troll. Not long ago, fantastic fiction was discarded as childish pastime. Today, the fantastic is the most popular genre in the West and East, and generates unusual films like Border as well as blockbuster franchises such as Star Wars and the transmedia superhero universes of DC and Marvel. This panel theorizes the fantastic as a cognitive ability to think the impossible and unreal (Grodal 2009). We ask how to define the transmedia fantastic, how and why it is adaptive, and how and why users – authors, directors, designers, readers, viewers, players – employ its affordances. The panel consists of people from the network “Imagining the Impossible: The Fantastic as Media Entertainment and Play” (2018–2020), with 8 participants from Denmark, and 5 from the UK, US, and Australia. We join media studies with design and production studies, we analyze texts and creative production processes, and we observe and interview users. We use biocultural theory, genre theory, production and design theory, and media ethnography. Our aim is to forge a holistic theory of the fantastic. We define fantastic fiction as stories that break with laws of nature and we use an umbrella definition including all fantastic subgenres. We theorize the fantastic as meta-thinking and as imaginary play. Across our approaches is a view of fiction as play. Play is innate and a constant in every culture (Huizinga 1938). Humans play from birth until old age, and play facilitates vital things like problem solving and to prepare for the unknown (Smith 2019). The panel has three presentations which address areas central in this enterprise of producing a Grand Theory of the fantastic: • cognition, mind, body – thinking beyond the real and possible • design & technology – designing and inventing the fantastic in media • worldbuilding, uses, play – imagining and playing with fantastic worlds Presentation 1: Cognition – Fantastic Bodies and Corporeal Sensations Using Border as point of reference, this presentation addresses the cognitive basis of the fantastic to create corporeal sensations. Grodal argues “the supernatural is interesting precisely because it violates universal common sense” (2009: 103), a “violation” which causes curiosity and a search for explanations. About religion, Pascal Boyer says the phenomenon triggers “the activation of a panoply of systems in the mind . . . [which is] not so much caused as made more likely by the cognitive processes” (2001: 298). This presentation addresses the use of social realism mixed with minimally counterintuitive elements, thus using masks and makeup instead of CGI to design fantastic bodies that stimulate a corporeal sense of a real body. It joins cognitive psychology with media ethnography, using interviews with author Johan Ajvide Lindqvist (Let the Right One In) and director Ali Abbasi. Presentation 2: Technology – Virtual Reality and Entering the Fantastic This paper examines how – or whether – our experience of the fantastic alters in the VR environment. Drawing on neuroscience research, this paper will argue that VR experiences introduce new forms of perception and embodiment that transform what Jonathan Crary called the “observer” (1990). While relying on stereoscopic vision, VR engagement demands what Giuliana Bruno in Atlas of Emotions (2002) refers to as “kinesthetic perception” and haptic visuality. To quote Terry Castle (1995), who writes about phantasmagoria of the C19th), VR games like Lone Echo, Resident Evil 7, Skyrim VR and Paranormal Activity: The Lost Soul trigger an “optical explosion of the senses” that ignite the entire body and, in the process, activate a dialogue between two bodies – the real and the virtual. The question this paper addresses is, what does this mean for our engagement with the fantastic in virtual reality? Presentation 3: The fantastic as Worldbuilding and Play This presentation discusses Story World building as media agnostic content design processes in production design and as user interaction with fantastic worlds. It addresses how the fantastic affords Story World building. Worldbuilding is a) traditionally seen as fictional worlds associated with fantastic genres; b) used as method to create content in any media format like games, serial fiction, television series, trans-media creations; and c) can be used in co-creation to extend existing media stories through less hierarchical and more collaborative processes, for example as with fan’s cosplay or in recent fan protest activism as in The Handmaid’s Tale. This presentation examines worldbuilding as, on the one hand, development method for creating media fiction with digital visualization technologies such as game engines Unity and Unreal and, on the other hand, as user activity in story world extensions such as cosplay, fan-art, and fan-fiction.
ER  -
TY  - JOUR
TI  - Use of Materials Science to Understand Haptic Perception
PY  - 2024
PB  - American Chemical Society
SN  - 2643-6728
T2  - Accounts of Materials Research
DO  - 10.1021/accountsmr.4c00207
UR  - https://doi.org/10.1021/accountsmr.4c00207
DA  - 2024-12-19
AU  - Becerra, Laura
C1  - Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, California 92093, United States
AU  - Root, Nicholas
C1  - Psychology Department, University of Amsterdam, 1018 WT Amsterdam, Netherlands
AU  - Ramji, Robert
C1  - Aiiso Yufeng Li Family Department of Chemical and Nano Engineering, University of California San Diego, La Jolla, California 92093, United States
AU  - Rouw, Romke
C1  - Psychology Department, University of Amsterdam, 1018 WT Amsterdam, Netherlands
AU  - Lipomi, Darren
C1  - Aiiso Yufeng Li Family Department of Chemical and Nano Engineering, University of California San Diego, La Jolla, California 92093, United States
LA  - en
KW  - Haptic perception
ER  -
TY  - JOUR
TI  - Beyond Words
PY  - 2024
PB  - Queensland University of Technology
SN  - 1441-2616
T2  - M/C Journal
DO  - 10.5204/mcj.3033
UR  - https://doi.org/10.5204/mcj.3033
DA  - 2024-04-16
AU  - Chen, Jasmine
C1  - Utah State University
LA  - en
VL  - 27
IS  - 2
AB  - Introduction Despite the expansive and multimodal realm of Chinese Boys’ Love (BL) culture (also known as danmei in Chinese), audio works have been notably absent from scholarly discussions, with the focus predominantly being on novels (e.g. Bai; Zhang). This article aims to fill this gap by delving into the transformative impact of sound on narrative engagement within the Chinese BL culture. Focussing on the audio drama adaptations of Grandmaster of Demonic Cultivation (modao zushi, hereafter Grandmaster), originally a serialised Chinese BL novel, this analysis aims to unravel the meticulously crafted BL fantasy in these auditory renditions. The audio drama format delivers an intimate storytelling experience directly to the listener’s ears. Unlike textual media, audio dramas allow listeners to immerse themselves in narratives during various daily activities, deepening their connection with the content. The audio drama Grandmaster, produced by the renowned Chinese platform MissEvan, has garnered a vast fan base and over 640 million plays across three seasons (the episodes and numbers of plays can be found on MissEvan: Season 1, Season 2, and Season 3). Unlike the serialised Web-drama adaption diluted by censorship regulations, the audio drama retains the utmost BL fidelity to the original novel, highlighting the significant potential of this medium in the Chinese BL culture. BL culture has surged in popularity within China, partly due to the export of Japanese culture and the burgeoning Chinese Internet accessibility (Feng). The BL genre encompasses diverse media forms such as novels, fanfiction, comics, animation, and audio/Web dramas, rooted in shared fantasies of romantic love between men. The growing interest in BL culture reflects a response to societal structures like Confucianism and the oppressive education system, which, due to their restrictedness, inadvertently foster the exploration of alternative narratives and identities within the genre (Kwon). While initially inspired by Japanese subculture, Chinese BL has evolved under diverse global influences, including American and other Asian subcultures (Lavin et al.). Chinese BL narratives delve into themes of identity, sexuality, power dynamics, and societal norms, reflecting a rich blend of modern and traditional Chinese culture (Madill and Zhao). Moreover, the rise of BL fandom has empowered female readers to engage in questions about gendered politics, questions that enable them to turn a voyeuristic gaze upon men (Zhang). The versatility of Chinese BL media reflects not only the evolving nature of the genre but also its enduring appeal and cultural significance within contemporary Chinese society. This article initiates a concise review of audio drama in China and the transformative impact of earphone technology, shifting listening experiences from public to intimate settings. It subsequently explores the intricate interplay between Chinese BL novels and audio dramas, elucidating the unique dynamics involved. The analysis then examines specific scenes from Grandmaster, providing insights into its role in facilitating a mesmerising BL audio fantasy. Grandmaster, originating as an Internet novel, has gained a dedicated following. MissEvan, recognising its potential, secured copyrights and commissioned Triones Penguin Studio for a radio drama adaptation in Mandarin. This full-cast dramatisation involves skilled editors, playwrights, and composers, thereby enriching character portrayals and interactions. The professional teamwork and meticulous oversight at each production stage guaranteed regular updates and high audio quality (Shao). Despite the collaborative nature of teamwork, I argue that the power of sound technology personalises the auditory journey as it creates an immersive experience for individual listeners. My analyses mainly rely on research involving actual listeners, along with examinations of specific content within Grandmaster with an idealised listener in consideration, to elucidate the factors contributing to its auditory allure. This examination contributes to a nuanced understanding of Chinese BL culture and its constitutive relationship to audio. From Public Broadcasting to Intimate Voicing: Audio Drama in China Radio broadcasting in China, with roots dating back to the early twentieth century, initially served as a propaganda instrument for mass mobilisation and communication. Chinese storytelling, rooted in acoustics, emphasises the sensory appeal of sound (Chan). It intertwines oral and written traditions in classical literature, particularly fiction and drama (Børdahl). Local vernaculars commonly feature in oral storytelling traditions, whereas Chinese radio programs adopt Mandarin to foster a cohesive national identity via linguistic uniformity. The Communist Party tactically expanded its audience through a radio reception network, establishing a wired broadcasting infrastructure with over 100 million loudspeakers by the 1970s. This revolutionised politics, everyday life, and perceptions of time and space (Li). The interplay between radio and social change reflected China’s pursuit of modernity, as the Communist Party utilised radio to institute a national communication system and monopolise news production. Radio thus served as a crucial tool for constructing and sustaining revolutionary fervor (Lei; He). Radio dramas, often cross-media adaptations from edited films in the 1970s, contributed to everyday sensory pleasure amidst a totalising revolutionary soundscape (Huang). The growth of radio and loudspeaker infrastructure played diverse roles in the revolution, fostering political communication, labour mobilisation, propaganda, surveillance, and even nurturing the Mao cult, turning radio drama into a potent tool for mass mobilisation and communication (Li). As a result, before the widespread availability of televisions in the 1990s, radio structured Chinese people’s daily activities and served as the primary information medium. Technological advancements in earphones, transitioning from larger wired headphones to smaller wireless earbuds like AirPods, have shifted auditory experiences in China from a collective identity tool used in political propaganda to a medium for individualistic entertainment. This change is marked by the personal nature of headphone usage, which can extend social interactions in and beyond physical dimensions (Grusin). The transition from wired headphones to wireless earbuds implements the interiorisation of one person’s body/voice within another, initiating a profound connection that transcends physical limitations (Stankievech). Since 2018, wireless earbuds have exceeded wired headphones in output value in China (Insight and Info), with the online audio market surging to 22 billion yuan in 2021, a 67.9% increase year-on-year. Audiobooks and audio dramas are the most popular genres, with a predominantly female audience under forty who prefer listening at night after work (iimedia). Among audio dramas, BL works generate the most traffic and revenue in China (Y. Wang). Along with such content, putting wireless earbuds inside the ear intensifies the intimacy of listening, transmitting voices directly into the listener’s head and sitting alongside their thoughts (Weldon). This physical closeness underscores the exclusive bond between the listener and the audio content, redefining oral narratives and transforming public and political audio content into a more personal and intimate medium. The use of wireless earbuds even extends listening beyond mere auditory experience, empowering haptic sensations that create an intimate bond. The acousmatic voice envelops the listener’s ears, establishing a connection even before the message’s content is considered (Madsen and Potts). The ear’s sensitivity prompts consciousness and memory, unlocking the imaginative world (C. Wang 91-94). This sensory engagement surpasses traditional auditory limits, resembling a physical encounter where listeners feel like their body has joined with the body of sound. Dermot Rattigan, discussing radio drama, notes how listeners fill the void with mental visualisations and imagination, entering a state of individual ‘virtual reality’ through aural stimulation (Rattigan 118). Drawing from visual psychology, Shaffer likens the soundscape to a dynamic landscape painting, emphasising the fluidity of auditory experiences (Schafer). Listening becomes a multi-dimensional journey involving the entire body and mind, a compelling tool for reception and connection that transcends reality’s boundaries. The advent of MP3 technologies and the podcasting boom also extends the former spatial and temporal limitations of listening. In contrast to traditional real-time broadcasting, MP3 technologies enable voices to persist indefinitely into the future (Madsen and Potts). This temporal flexibility further builds a private sound sphere for listeners (Euritt). Listeners no longer need to share time and space with others around loudspeakers or radios, so they can freely indulge in their subcultural preferences, such as BL stories, without concern for societal judgment. Many listeners strategically incorporate audio dramas into their daily schedule, choosing moments of solitude such as before sleep or upon waking, where they can detach from the expectations of their physical space and identity roles. This is particularly evident among devoted fans of Chinese BL audio dramas, who carve out personal time for these works and seek a quiet space for focussed engagement (Wang 55). This intentional, focussed engagement differs from the typical mode of everyday radio listening as it serves an expanded, widespread dissemination environment that is also highly intimate (Madsen and Potts). Thus, the convergence of temporal flexibility and immersive technology shapes listener engagement and interaction dynamics. The fusion of intimacy, physical closeness, and temporal flexibility heightens the allure of the voice in programs with erotic undertones, such as BL audio dramas. Euritt introduces the concept of ‘breathing out into you’ to explain queer eroticism in podcasts, emphasising shared breaths and potential haptic exchanges that enhance the sensual dimensions of sound (Euritt 27-53). This wireless, intimately riveting auditory experience transforms the soundscape and reshapes contemporary social interactions. This shift is particularly noteworthy for popular Chinese radio and audio content as they began as a public, propaganda-oriented tool and transitioned into forms as novel as the intimate domain of BL audio dramas. This change underscores the transformative power of sound in shaping interactions, surpassing conventional storytelling boundaries, and ushering in a new era of engaging narratives. The 2.5-Dimensional: Auralising Chinese Boys’ Love Fiction The BL genre emerges as a cultural and social force that can potentially challenge traditional Chinese values. Its focus on male-male love inherently questions societal expectations around gender and sexuality in ways that disrupt Confucian ideology’s emphasis on heterosexual marriage and lineage (Welker). Furthermore, the genre’s similarity to the melodramatic ‘soap opera’ storytelling style resonates with Western ideals of individualism and aligns more with a feminist viewpoint that contrasts with the male-dominant heterosexism often found in traditional Chinese narratives (Mumford). This emphasis on individual desires also implicitly disputes the collectivist and socialist values, as well as the importance of the extended family, traditionally embraced in Chinese cultures. In short, the love, sex, and romance depicted in BL represent a departure from traditional Chinese values, positioning the BL genre as a vehicle for cultural exchange and societal transformation in terms of gender norms. The surge of Internet radio and social media in the 2010s has substantially contributed to the professionalisation and commercialisation of Chinese BL audio dramas. MissEvan, a prominent barrage-audio and live-broadcasting Website, has been crucial to this proliferation (Hu et al.). Before the advent of commercial dubbing, enthusiasts of BL novels voluntarily recorded non-profit Chinese audio dramas and disseminated them online. The popularity of BL novels subsequently prompted their adaptation into animation and television dramas, creating a demand for dubbing services. This demand inaugurated a niche for professional voice actors to hone and showcase their skills. The integration of technology and capital by commercial production teams has markedly elevated the quality of Chinese BL audio dramas. Amidst tightening censorship in 2021, Chinese BL online novels and their television/Web-drama adaptations faced restrictions. Audio drama emerged as a less restrictive medium, which can relatively directly present explicit gay relationships (Hu et al.). Listeners of Chinese BL audio dramas typically read the online novel beforehand, engaging in dual consumption for pleasure in both reading and listening (Wang 58). Their engagement transcends plot comprehension, focussing instead on appreciating sophisticated voice performances. Exploring how audio dramas derived from novels can transcend textual narratives and captivate audiences has become a central focus in the production process, highlighting the flourishing landscape of audio drama. The listening process provides informed listeners with a re-experience, offering multiple sensory and emotional pleasures by translating words into voice and sounds. Unlike film and television dubbing, which requires synchronisation with actors’ lip movements and speech rhythms, dubbing for animation, audio dramas, and games gives greater creative autonomy to voice actors. The thriving market for audio dramas has shaped the Chinese dubbing industry, cultivating a devoted fan base for previously overlooked voice actors. The character voices (CVs, also known as voice actors, or VAs) have emerged as central figures, attracting fans and driving media traffic. In the late 2010s, collaborations between MissEvan and renowned CVs resulted in the adaptation of popular online fiction into paid audio dramas, exemplified by Grandmaster, which aired in 2017 and 2018 (Hu et al.). Fans’ motivation for engaging with BL audio dramas extends beyond intertextual and trans-media entertainment but incorporates an appreciation for their beloved CVs, thereby fostering a culture of support within the burgeoning Chinese BL audio drama market. In the storytelling of aural media, CVs are crucial in bridging the auditor’s BL imagination between the text and the characters as their performances breathe life into characters. CVs fill a gap between two-dimensional works (fiction, comic, and animation) and the three-dimensional real world, forging ‘2.5-dimensional’ content. This term originated in the 1970s-80s to describe anime voice actors, who imbue two-dimensional characters with a sense of existence and generate interrelations between the real, fictional, and cyber worlds (Sugawa-Shimada and Annett). In BL audio dramas, CVs commonly stimulate listeners’ sensations through male moans that facilitate an erotic flow between sound and body, arousing desire through the auditory channel. The incorporation of scenes with sexual innuendo between the male protagonists creates a space for listeners to indulge in these moments with earphones on, enveloped in their own private, eroticised sphere of engagement between fiction and reality. The deliberate pauses, gasps, and panting become the silent dialogue that intertwines inner voices with external narratives, enhancing comprehensive sensory engagement for listeners. Audio Fantasy in Grandmaster of Demonic Cultivation Grandmaster is a seminal Chinese BL novel that blends martial arts, supernatural fantasies, and emotional depth. Set in a richly imagined world where immortal cultivation techniques bestow individuals with extraordinary powers, the story follows protagonists Wei Wuxian’s and Lan Wangji’s intertwined fates. Its captivating narrative and nuanced characters have garnered a global fanbase, solidifying its place as a cornerstone of Chinese BL literature and media. The audio drama Grandmaster faithfully mirrors the novel’s narrative structure, unfolding from the protagonist Wei’s perspective after his reincarnation, weaving memories of his past and present life, including his romantic involvement with Lan. Wei’s establishment of the forbidden Demonic Path leads to his death, but he is reincarnated thirteen years later and reunites with Lan. After his reincarnation, Wei gradually realises Lan’s concealed profound affection and scarification for him. Diverging from the television/Web-drama adaptation, which replaces the romance with platonic ‘bromance’ due to censorship (Lei), the audio drama accentuates the impassioned soundscapes of their relationship. The three-season series, comprising episodes of 30-40 minutes, offers the first three episodes for free, with subsequent content requiring payment (approximately four to six dollars per season). Impressively, the series has driven earnings exceeding $1.5 million (Asia Business Leaders). This success highlights the captivating and profitable potential of audio dramas as a BL storytelling medium. Unlike the original novel, which uses an omniscient narrator, the audio drama advances the plot solely through character dialogue. Consequently, listeners navigate the storyline guided by the rhythm of the CVs’ delivery and the accompanying music. Different from Japanese BL audio dramas that feature as ‘voice porn’ for women (Ishida), Grandmaster subtly implies the romance between Lan and Wei, with the most intimate interactions limited to kisses. Rather than sexually explicit content, the drama focusses on the characters’ affective fulfillment after a prolonged thirteen-year anticipation. For instance, in Season 1, Episode 4, Wei attempts to hide his identity and flee from Lan. When Wei creeps back towards Lan’s bed to steal the pass for exiting Lan’s residence, Lan catches him. Rather than simply saying ‘Get off’ as in the novel, Lan instructs Wei in the audio drama to ‘Get off from my body,’ offering listeners additional physical contact cues (the quotes from the novel and audio drama in this article are translations from Chinese to English). Following Wei’s intentional refusal, the CV Wei Chao, portraying Lan, strategically breathes before his next line, ‘then stay like this for the whole night’. The breath conveys Lan’s deep, restrained affection and evokes the listener’s nuanced emotional resonance. To represent Lan’s affection within his minimal and often monosyllabic lines requires the CV to convey emotions through breaths and intonations, which commonly elicit an autonomous sensory meridian response (ASMR) in listeners. ASMR is a tingling sensation often triggered by soft low-tone spoken or whispered voices (Barratt and Davis). Wei Chao intentionally lowers his voice to interpret how Lan’s sighs encapsulate unspoken sentiments (Wei). In contrast, the CV Lu Zhixing employs a playful and sweet tone in his portrayal of Wei Wuxian. When Lu delivers flirtatious lines, online real-time comments frequently express listeners’ admiration, suggesting that his voice is even more captivating than women’s. The contrasting restraint and playfulness intensify the listener’s empathy for Lan’s unspeakable passion. Thus, Lan’s subtle expressions of his restrained love become the primary attraction for listeners (KikuHonda). The high-quality sound further amplifies the breath sounds, making each of Lan’s ‘hmm’ responses—indifferent, melancholy, or indulgent—a nuanced emotional trigger. Listeners, through their wireless earbuds, engage in the meticulously crafted expressions of Lan within a profoundly personal soundscape. This listening mode is a crucial component of the overall enthralling auditory voyage, augmenting the appreciation of the characters’ subdued emotions. The layered integration of music and sound in Grandmaster constructs a three-dimensional sonic storytelling landscape. Effective soundscapes for storytelling are crafted by multiple dimensions: sound source, temporal progression, simultaneous layers, and spatialisation. Sound editing allows for source selection, with listeners experiencing these dimensions as integrated, not separate or sequential (Stedman et al.). The audio drama Grandmaster distinguishes itself from the novel by using voice flashbacks for narrative enhancement. In Season Three, Episode 12, when Lan’s brother recounts Lan’s sacrifice for Wei, particularly the moment when Lan endured severe punishment to save Wei thirteen years ago, the soundscape instantly transports listeners to that intense scene. Listeners vividly hear the swishing force of the whip and its impact, immersing them in the sounds of Lan’s anguish and unwavering love. This direct auditory impact allows listeners to feel as if they are experiencing the events firsthand, physically sensing the hardships encountered by the protagonists in understanding each other’s affection, intensifying their hard-won love. The musical orchestration and vocal interplay are also pivotal to conveying the story. In the storyline, Wei and Lan showcase proficiency in their respective instruments: Wei with the flute and Lan with the guqin (a seven-string Chinese zither). The tonal features of these instruments—the flute’s melodious brightness and the guqin’s deep lingering resonance—symbolise the protagonists’ distinct personalities, adding ingenious layers to their relationship. In the Guanyin Temple scene (Season Three, Episode 13), as Wei confesses to Lan, the initial background music features the flute, guqin, and rain sounds, foreshadowing the confessional moment with Wei’s worries that Lan will not believe his words. As Wei promises to remember Lan’s every word from now on, the music incorporates the guzheng, a Chinese string instrument with a brighter timbre than guqin. The tremolo technique of guzheng is reminiscent of the characters’ heartstring vibrations. Through auditory cues, the narrative climaxes with Wei’s heartfelt confession of love for Lan. When Wei straightforwardly confesses, ‘I fancy you, I love you, I want you, I cannot leave you. … I do not want anyone but you—it cannot be anyone but you’ (Season Three, Episode 13), his heartfelt words are accompanied by layered sounds, including the duet of the flute and guqin, and the sound of thunder and rain, accelerating the affective climax. Lan echoes Wei’s words, underscored by erhu, thereby showing how this string instrument resembles humans’ sobbing voices through its sliding technique, rendering the touching melody. The heartbeat and rain sound with Lan’s panting highlight the painful loneliness of Lan’s thirteen-year wait. The intricate fusion of musical and vocal elements enables listeners to not only hear but also to feel the mutual affection between the characters, culminating in a sense of delight upon the disclosure of their reciprocal love following numerous adventures. Using earbuds amplifies listeners’ capacity to fully receive auditory details and stereo effects, thereby contributing to the popularity of BL audio dramas that skillfully convey unspoken love through detailed soundscapes. Epilogue The Grandmaster audio dramas provide crafted episodes that fulfill fans’ passionate needs that exceed the novel’s scope. In addition to adapting the novel, the team has conceived original mini-dramas that enrich the character images. Listeners can access additional content such as iconic quotes, ringtones, and ‘lullaby’ episodes recorded by the leading CVs, maximising the captivating power of sound and justifying listeners’ investment. The multi-layered use of sounds and instrumental arrangements effectively constructs a three-dimensional soundscape, reinforcing the audience’s understanding of the story and characters. Unlike television/Web-drama adaptations, the audio drama fully amplifies the tragic elements of the novel, pushing the immersed listener’s imagination past textual limitations. While casting choices and modelling in visual adaptions may disappoint viewers’ expectations at times, the audio drama leverages the power of sound to stimulate listeners’ imaginations, encouraging them to visualise their own specific character images. Skillful orchestration, along with sound effects, breaths, and dialogues in Grandmaster intensifies emotional expression, forming a rich and dimensional soundscape and unlocking new possibilities for audio drama artistic expression for Chinese BL fantasy. Reference Asia Business Leaders. “魔道祖師收益驚人, 中國廣播劇市場逾百億 [The Astonishing Earnings of Grandmaster of Demonic Cultivation, China’s Radio Drama Market Exceeds 10 Billion].” 19 Jan. 2022. &lt;https://www.asiabusinessleaders.com/posts/%E4%B8%AD%E5%9C%8B%E7%B7%9A%E4%B8%8A%E9%9F%B3%E8%A8%8A %E5%B8%82%E5%A0%B4%E9%80%BE%E7%99%BE%E5%84%84&gt;. Bai, Meijiadai. “Regulation of Pornography and Criminalization of BL Readers and Authors in Contemporary China (2010–2019).” Cultural Studies 36.2 (Mar. 2022): 279–301. Barratt, Emma L., and Nick J. Davis. “Autonomous Sensory Meridian Response (ASMR): A Flow-Like Mental State.” PeerJ 3 (Mar. 2015). &lt;https://doi.org/10.7717/peerj.851&gt;. Børdahl, Vibeke. Wu Song Fights the Tiger: The Interaction of Oral and Written Traditions in the Chinese Novel, Drama and Storytelling. NIAS Press, 2013. Chan, Leo Tak-hung. “Text and Talk: Classical Literary Tales in Traditional China and the Context of Casual Oral Storytelling.” Asian Folklore Studies 56.1 (1997): 33–63. Euritt, Alyn. Podcasting as an Intimate Medium. Routledge, 2022. Feng, Jin. “‘Addicted to Beauty’: Consuming and Producing Web-Based Chinese ‘Danmei’ Fiction at Jinjiang.” Modern Chinese Literature and Culture 21.2 (2009): 1–41. Grusin, Richard A. Premediation: Affect and Mediality after 9/11. Palgrave Macmillan, 2010. He, Bixiao. “ ‘Yelling at the Masses’: Making Propaganda Audible in the Communist Revolution.” China Report 58.1 (2022): 28–40. Hu, Tingting, Jing Jin, and Lin Liao. “A Transmedia ‘Third’ Space: The Counterculture of Chinese Boys” Love Audio Dramas.” Asian Studies Review 47.4 (2023): 836–54. Huang, Nicole. “Listening to Films: Politics of the Auditory in 1970s China.” Journal of Chinese Cinemas 7.3 (2013): 187–206. Hunn, Nick. “The Market for Hearable Devices 2016-2020.” Wearable Technologies. 7 Dec. 2016. &lt;https://wt-obk.wearable-technologies.com/2016/12/the-market-for-hearable-devices-2016-2020-and-then-there-were-airpods/&gt;. iimedia. “2021年中国在线音频行业发展及用户行为研究报告 [2021 China Online Audio Industry Development and User Behaviour Research Report].” 21 Nov. 2021. &lt;https://www.iimedia.cn/c400/82048.html&gt;. Insight and Info. “中国无线耳机行业发展现状分析与投资前景研究报告 (2022-2029 年) [Analysis and Investment Prospect Research Report on the Development of China's Wireless Earphone Industry (2022-2029)].” 2022. &lt;https://www.chinabaogao.com/detail/607742.html&gt;. Ishida, Minori. “Sounds and Sighs: 'Voice Porn' for Women.” In Shōjo across Media: Exploring “Girl” Practices in Contemporary Japan, eds. Jaqueline Berndt et al. Springer International, 2019. 283–99. KikuHonda. “[閒聊] 廣播劇魔道祖師 [[Chat] The Audio Drama Grandmaster].” 18 Jan. 2020. &lt;https://www.ptt.cc/bbs/YuanChuang/M.1579362798.A.49D.html&gt;. Kwon, Jungmin. “The Past, Present, and Future of Boys Love (BL) Cultures in East Asia.” In Transnational Convergence of East Asian Pop Culture. Routledge, 2021. Lavin, Maud, et al. Boys’ Love, Cosplay, and Androgynous Idols: Queer Fan Cultures in Mainland China, Hong Kong, and Taiwan. Hong Kong UP, 2017. Lei, Jun. “Taming the Untamed Politics and Gender in BL-Adapted Web Dramas.” In Queer TV China: Televisual and Fannish Imaginaries of Gender, Sexuality, and Chineseness, ed. Jamie J. Zhao. Hong Kong UP, 2023. 105–23. Lei, Wei. Radio and Social Transformation in China. Routledge, 2019. Li, Jie. “Revolutionary Echoes: Radios and Loudspeakers in the Mao Era.” Twentieth-Century China 45.1 (2020): 25–45. Madill, A., and Y. Zhao. “Engagement with Female-Oriented Male-Male Erotica in Mainland China and Hong Kong: Fandom Intensity, Social Outlook, and Region.” Participations: Journal of Audience and Reception Studies 18.1 (May 2021): 111–31. Madsen, Virginia, and John Potts. “Voice-Cast: The Distribution of the Voice via Podcasting.” In VOICE: Vocal Aesthetics in Digital Arts and Media, eds. Norie Neumark et al. MIT P, 2010. Mumford, Russell E. Love and Ideology in the Afternoon: Soap Opera, Women and Television Genre. Indiana UP, 1995. Rattigan, Dermot. Theatre of Sound: Radio and the Dramatic Imagination. Carysfort, 2002. Schafer, R. Murray. The Soundscape. Destiny, 1993. Shao, Maomao. “魔道祖师广播剧播放2000万 [The Audio Drama Grandmaster of Demonic Cultivation Has Been Played 20 Million Times].” JMedia 2018. &lt;https://www.jiemian.com/article/2324030.html&gt;. Stankievech, Charles. “From Stethoscopes to Headphones: An Acoustic Spatialisation of Subjectivity.” Leonardo Music Journal 17 (Dec. 2007): 55–59. Stedman, Kyle D., et al. "Tuning into Soundwriting." Intermezzo, 2020. &lt;http://intermezzo.enculturation.net/14-stedman-et-al/index.html&gt;. Sugawa-Shimada, Akiko, and Sandra Annett. “Introduction.” Mechademia: Second Arc 15.2 (Spring 2023): 1–7. Wang, Chien Hua. “聲音的「腐」能量：宅宅腐眾的跨國bl廣播劇聆聽與妄想 [The Voice Fantasies of Boy’s Love: How Otaku and Fujoshi Listen to and Consume Boy’s Love Audio Drama].” Master's thesis. National Taiwan Normal University, 2021. Wang, Ying. “ ‘耳朵经济’ 时代下猫耳FM广播剧发展策略研究 [Research on the Development Strategy of Maoer FM Radio Drama in the Era of ‘Ear Economy’].” 新闻传播科学 [Journalism and Communications] 11.4 (2023): 847–51. Wei, Chao. Interview. In “Free Talk of the Voice Actors I”, Grandmaster of Demonic Cultivation Season 2. 14 Mar. 2019. &lt;https://www.missevan.com/sound/player?id=1185150&gt;. Weldon, Glen. “It’s All in Your Head: The One-Way Intimacy of Podcast Listening.” NPR, 2 Feb. 2018. &lt;https://www.npr.org/2018/02/02/582105045/its-all-in-your-head-the-one-way-intimacy-of-podcast-listening&gt;. Welker, James, ed. Queer Transfigurations: Boys Love Media in Asia. U of Hawai'i P, 2023. Zhang, Chunyu. “Loving Boys Twice as Much: Chinese Women’s Paradoxical Fandom of ‘Boys’ Love’ Fiction.” Women’s Studies in Communication 39.3 (July 2016): 249–67.
ER  -
TY  - THES
TI  - Enhancing detailed haptic relief for real-time interaction
PY  - 2015
DO  - 10.5821/dissertation-2117-95993
UR  - https://doi.org/10.5821/dissertation-2117-95993
DA  - 2015-11-25
AU  - Theoktisto, Víctor
LA  - ca
KW  - Viewport
KW  - Implementation
AB  - The present document exposes a different approach for haptic rendering, defined as the simulation of force interactions to reproduce the sensation of surface relief in dense models. Current research shows open issues in timely haptic interaction involving large meshes, with several problems affecting performance and fidelity, and without a dominant technique to treat these issues properly. Relying in pure geometric collisions when rendering highly dense mesh models (hundreds of thousands of triangles) sensibly degrades haptic rates due to the sheer number of collisions that must be tracked between the mesh's faces and a haptic probe. Several bottlenecks were identified in order to enhance haptic performance: software architecture and data structures, collision detection, and accurate rendering of surface relief. To account for overall software architecture and data structures, it was derived a complete component framework for transforming standalone VR applications into full-fledged multi-threaded Collaborative Virtual Reality Environments (CVREs), after characterizing existing implementations into a feature-rich superset. Enhancements include: a scalable arbitrated peer-to-peer topology for scene sharing; multi-threaded components for graphics rendering, user interaction and network communications; a collaborative user interface model for session handling; and interchangeable user roles with multi-camera perspectives, avatar awareness and shared annotations. We validate the framework by converting the existing ALICE VR Navigator into a complete CVRE, showing good performance in collaborative manipulation of complex models. To specifically address collision detection computation, we derive a conformal algebra treatment for collisions among points, segments, areas, and volumes, based on collision detection in conformal R{4,1} (5D) space, and implemented in GPU for faster parallel queries. Results show orders of magnitude time reductions in collisions computations, allowing interactive rates. Finally, the main core of the research is the haptic rendering of surface mesostructure in large meshes. Initially, a method for surface haptic rendering was proposed, using image-based Hybrid Rugosity Mesostructures (HRMs) of per-face heightfield displacements and normalmaps layered on top of a simpler mesh, adding greater surface detail than actually present. Haptic perception is achieved modulating the haptic probe's force response using the HRM coat. A usability testbed framework was built to measure experimental performance with a common set tests, meshes and HRMs. Trial results show the goodness of the proposed technique, rendering accurate 3D surface detail at high sampling rates. This local per-face method is extended into a fast global approach for haptic rendering, building a mesostructure-based atlas of depth/normal textures (HyRMA), computed out of surface differences of the same mesh object at two different resolutions: original and simplified. For each triangle in the simplified mesh, an irregular prism is considered defined by the triangle's vertices and their normals. This prism completely covers the original mesh relief over the triangle. Depth distances and surfaces normals within each prism are warped from object volume space to orthogonal tangent space, by means of a novel and fast method for computing barycentric coordinates at the prism, and storing normals and relief in a sorted atlas. Haptic rendering is effected by colliding the probe against the atlas, and effecting a modulated force response at the haptic probe. The method is validated numerically, statistically and perceptually in user testing controlled trials, achieving accurate haptic sensation of large meshes' fine features at interactive rendering rates, with some minute loss of mesostructure detail. En aquesta tesi es presenta un novedós enfocament per a la percepció hàptica del relleu de models virtuals complexes mitjançant la simulació de les forces d'interacció entre la superfície i un element de contacte. La proposta contribueix a l'estat de l'art de la recerca en aquesta àrea incrementant l'eficiència i la fidelitat de la interacció hàptica amb grans malles de triangles. La detecció de col·lisions amb malles denses (centenars de milers de triangles) limita la velocitat de resposta hàptica degut al gran nombre d'avaluacions d'intersecció cara-dispositiu hàptic que s'han de realitzar. Es van identificar diferents alternatives per a incrementar el rendiment hàptic: arquitectures de software i estructures de dades específiques, algorismes de detecció de col·lisions i reproducció hàptica de relleu superficial. En aquesta tesi es presenten contribucions en alguns d'aquests aspectes. S'ha proposat una estructura completa de components per a transformar aplicacions de Realitat Virtual en Ambients Col·laboratius de Realitat Virtual (CRVEs) multithread en xarxa. L'arquitectura proposada inclou: una topologia escalable punt a punt per a compartir escenes; components multithread per a visualització gràfica, interacció amb usuaris i comunicació en xarxa; un model d'interfície d'usuari col·laboratiu per a la gestió de sessions; i rols intercanviables de l'usuari amb perspectives de múltiples càmeres, presència d'avatars i anotacions compartides. L'estructura s'ha validat convertint el navegador ALICE en un CVRE completament funcional, mostrant un bon rendiment en la manipulació col·laborativa de models complexes. Per a incrementar l'eficiència del càlcul de col·lisions, s'ha proposat un algorisme que treballa en un espai conforme R{4,1} (5D) que permet detectar col·lisions entre punts, segments, triangles i volums. Aquest algorisme s'ha implementat en GPU per obtenir una execució paral·lela més ràpida. Els resultats mostren reduccions en el temps de càlcul de col·lisions permetent interactivitat. Per a la percepció hàptica de malles complexes que modelen objectes rugosos, s'han proposat diferents algorismes i estructures de dades. Les denominades Mesoestructures Híbrides de Rugositat (HRM) permeten substituir els detalls geomètrics d'una cara (rugositats) per dues textures: de normals i d'alçades. La percepció hàptica s'aconsegueix modulant la força de resposta entre el dispositiu hàptic i la HRM. Els tests per avaluar experimentalment l'eficiència del càlcul de col·lisions i la percepció hàptica utilitzant HRM respecte a modelar les rugositats amb geometria, van mostrar que la tècnica proposada va ser encertada, permetent percebre detalls 3D correctes a altes tases de mostreig. El mètode es va estendre per a representar rugositats d'objectes. Es proposa substituir l'objecte per un model simplificat i un atles de mesoestructures en el que s'usen textures de normals i de relleus (HyRMA). Aquest atles s'obté a partir de la diferència en el detall de la superfície entre dos malles del mateix objecte: l'original i la simplificada. A partir d'un triangle de la malla simplificada es construeix un prisma, definit pels vèrtexs del triangle i les seves normals, que engloba el relleu de la malla original sobre el triangle. Les alçades i normals dins del prisma es transformen des de l'espai de volum a l'espai ortogonal tangent, amb mètode novedós i eficient que calcula les coordenades baricèntriques relatives al prisma, per a guardar el mapa de textures transformat en un atles ordenat. La percepció hàptica s'assoleix detectant les col·lisions entre el dispositiu hàptic i l'atles, i modulant la força de resposta d'acord al resultat de la col·lisió. El mètode s'ha validat numèricament, estadística i perceptual en tests amb usuaris, aconseguint una correcta i interactiva sensació tàctil dels objectes simulats mitjançant la mesoestructura de les malles En esta tesis se presenta un enfoque novedoso para la percepción háptica del relieve de modelos virtuales complejos mediante la simulación de las fuerzas de interacción entre la superficie y un elemento de contacto. La propuesta contribuye al estado del arte de investigación en este área incrementando la eficiencia y fidelidad de interacción háptica con grandes mallas de triángulos. La detección de colisiones con mallas geométricas densas (cientos de miles de triángulos) limita la velocidad de respuesta háptica debido al elevado número de evaluaciones de intersección cara-dispositivo háptico que deben realizarse. Se identificaron diferentes alternativas para incrementar el rendimiento háptico: arquitecturas de software y estructuras de datos específicas, algoritmos de detección de colisiones y reproducción háptica de relieve superficial. En esta tesis se presentan contribuciones en algunos de estos aspectos. Se ha propuesto una estructura completa de componentes para transformar aplicaciones aisladas de Realidad Virtual en Ambientes Colaborativos de Realidad Virtual (CRVEs) multithread en red. La arquitectura propuesta incluye: una topología escalable punto a punto para compartir escenas; componentes multithread para visualización gráfica, interacción con usuarios y comunicación en red; un modelo de interfaz de usuario colaborativo para la gestión de sesiones; y roles intercambiables del usuario con perspectivas de múltiples cámaras, presencia de avatares y anotaciones compartidas. La estructura se ha validado convirtiendo el navegador ALICE en un CVRE completamente funcional, mostrando un buen rendimiento en la manipulación colaborativa de modelos complejos. Para incrementar la eficiencia del cálculo de colisiones, se ha propuesto un algoritmo que trabaja en un espacio conforme R4,1 (5D) que permite detectar colisiones entre puntos, segmentos, triángulos y volúmenes. Este algoritmo se ha implementado en GPU a efectos de obtener una ejecución paralelamás rápida. Los resultadosmuestran reducciones en el tiempo de cálculo de colisiones permitiendo respuesta interactiva. Para la percepción háptica de mallas complejas que modelan objetos rugosos, se han propuesto diferentes algoritmos y estructuras de datos. Las denominadasMesoestructuras Híbridas de Rugosidad (HRM) permiten substituir los detalles geométricos de una cara (rugosidades) por una textura de normales y otra de alturas. La percepción háptica se consigue modulando la fuerza de respuesta entre el dispositivo háptico y la HRM. Los tests realizados para evaluar experimentalmente la eficiencia del cálculo de colisiones y la percepción háptica utilizando HRM respecto a modelar las rugosidades con geometría, mostraron que la técnica propuesta fue acertada, permitiendo percibir detalles 3D correctos a altas tasas de muestreo. Este método anterior es extendido a un procedimiento global para representar rugosidades de objetos. Para hacerlo se propone sustituir el objeto por un modelo simplificado y un atlas de mesostructuras usando texturas de normales y relieves (HyRMA). Este atlas se obtiene de la diferencia en detalle de superficie entre dos mallas del mismo objeto: la original y la simplificada. A partir de un triángulo de la malla simplificada se construye un prisma definido por los vértices del triángulo a lo largo de sus normales, que engloba completamente el relieve de la malla original sobre este triángulo. Las alturas y normales dentro de cada prisma se transforman del espacio de volumen al espacio ortoganal tangente, usando un método novedoso y eficiente que calcula las coordenadas baricéntricas relativas a cada prisma para guardar el mapa de texturas transformado en un atlas ordenado. La percepción háptica se consigue detectando directamente las colisiones entre el dispositivo háptico y el atlas, y modulando la fuerza de respuesta de acuerdo al resultado de la colisión. El procedmiento se ha validado numérica, estadística y perceptualmente en ensayos con usuarios, consiguiendo a tasas interactivas la correcta sensación táctil de los objetos simulados mediante la mesoestructura de las mallas, con alguna pérdida muy puntual de detalle
ER  -
TY  - JOUR
TI  - Scientific Collaboratories: Evaluating their Potential
PY  - 2002
PB  - Association for Information Science and Technology
SN  - 0095-4403
T2  - Bulletin of the American Society for Information Science and Technology
DO  - 10.1002/bult.255
UR  - https://doi.org/10.1002/bult.255
DA  - 2002-08-01
AU  - Sonnenwald, Diane
C1  - University of North Carolina at Chapel Hill
AU  - Whitton, Mary
C1  - University of North Carolina at Chapel Hill
AU  - Maglaughlin, Kelly
C1  - University of North Carolina at Chapel Hill
LA  - en
KW  - Collaboratory
KW  - Scientific Communication
VL  - 28
IS  - 6
SP  - 12
EP  - 15
AB  - Scientific collaboratories have the potential to be centers "without walls, in which researchers can perform their research without regard to physical location – interacting with colleagues, accessing instrumentation, sharing data and computational resources, and accessing information in digital libraries" [Wulf, W.A. (1993). The collaboratory opportunity. Science, 261, 854-855]. A number of scientific collaboratories have been developed, and a comprehensive discussion of these collaboratories can be found in Finholt, T. (2002). Collaboratories, In B. Kronin (Ed.) Annual Review of Information Science and Technology. Washington, DC: American Society for Information Science and Technology. However, the evaluation of scientific collaboratories has lagged behind their development. So few evaluations of scientific collaboratories exist that fundamental questions regarding their potential have yet to be answered: Can distributed scientific research produce high quality results? Do the capabilities afforded by collaboratories outweigh their disadvantages from scientists' perspectives? How does the scientific process change in the context of a collaboratory? The answers to these questions are not obvious. Previous research in computer-supported cooperative work [e.g., Olson, G.M. & Olson, J.S. (2000). Distance matters. Human-Computer Interaction, 15 (2-3), 139-178] and theory of language [Clark, H. (1996). Using Language. Cambridge, UK: Cambridge University Press] would predict that working remotely would lack the richness of collocation and face-to-face interaction such as multiple and redundant communication channels, implicit cues and spatial co-references, which are difficult to support via computer-mediated communications. This lack of richness is thought to impair performance because it is more difficult to establish the common ground that enables individuals to understand the meaning of each other's utterances. The collaboratory system we evaluated provides distributed, collaborative access to a specialized scientific instrument called a nanoManipulator (nM). The single-user nM provides haptic and 3D visualization interfaces to a local (co-located) atomic force microscope (AFM), providing a natural scientist with the ability to interact directly with physical samples ranging in size from DNA to single cells. The nM and its uses are described in Guthold, M., Falvo, M.R., Matthews, W.G., Paulson, S., Washburn, S., Erie, D.A., Superfine, R., Brooks, Jr., F.P., & Taylor, III, R.M.(2000). Controlled Manipulation of Molecular Samples with the nanoManipulator. IEEE/ASME Transactions on Mechatronics, 5(2), 189-198. The collaboratory version of the nM was designed based on results of an ethnographic study from which we developed an understanding of the scientific research process, current collaborative work practices, the role of an nM as a scientific instrument and scientists' expectations regarding technology to support scientific collaborations [Sonnenwald, D.H., Bergquist, R., Maglaughlin, K.L., Kupstas-Soo, E. & Whitton, M.C. (2001). Designing to support collaborative scientific research across distances: The nanoManipulator example, In E. Churchill, D. Snowdon, &A. Munro, (Eds.), Collaborative Virtual Environments (pp. 202-224). London: Springer Verlag]. One PC is equipped with a Sensable Devices Phantom force-feedback device. This PC and its associated software provide haptic and 3D visualization interfaces to a local or remote atomic force microscope (AFM) and support collaborative manipulation and exploration of scientific data. Scientists can dynamically switch between working together in shared mode and working independently in private mode. In shared mode, remote, that is, non-collocated, collaborators view and analyze the same (scientific) data. Mutual awareness is supported via multiple pointers, each showing the focus of attention and interaction state for one collaborator. Collaborators can perform almost all operations synchronously. Because of the risk of damage to an AFM, control of the microscope tip is explicitly passed between collaborators. In private mode, each collaborator can independently analyze the same or different data from stream files previously generated. When switching back to private from shared mode, collaborators return to the exact data they were previously using. Another PC supports shared application functionality and video conferencing (via Microsoft NetMeeting) and an electronic writing/drawing tablet. This PC allows collaborators to work together synchronously using a variety of domain-specific and off-the-shelf applications, including specialized data analysis, word processing and whiteboard applications. Video conferencing is supported by two cameras. One camera is mounted on a gooseneck stand so it can be pointed at the scientist's hands, sketches or other physical artifacts scientists may use during experiments; the other is positioned to capture a head and shoulders view of the user. Collaborators have software control of which camera view is broadcast from their site. A wireless telephone headset and speakerphone connected to a commercial telephone network provides high quality audio communications for collaborators. The experimental evaluation study was a repeated-measures, or within-subjects, controlled experiment comparing working face-to-face and working remotely with the order of conditions counterbalanced. Twenty pairs of study participants (upper level undergraduate natural science students) conducted two realistic scientific research activities each requiring two to three hours to complete. Ten pairs of study participants worked face-to-face first and, on a different day, worked remotely (in different locations.) Another 10 pairs worked remotely first and, on a different day, face-to-face. When face-to-face, the participants shared a single collaboratory system; when collaborating remotely, each location was equipped with its own complete collaboratory system. The scientific research activities completed by the participants were designed in collaboration with natural scientists. The tasks were actual activities the scientists completed and documented during the course of their investigations. To complete the tasks the participants had to engage in the following activities typical of scientific research: operate the scientific equipment properly; capture and record data in their (electronic) notebooks; perform analysis using scientific data analysis software applications and include the results of that analysis in their notebooks; draw conclusions, create hypotheses and support those hypotheses based on their data and analysis; and prepare a formal report of their work. We collected a variety of quantitative and qualitative evaluation data, including task performance measures to compare the quality of scientific work produced in the two collaboration conditions, and post-interviews to gain, from participants' perspectives, a more in-depth understanding of the scientific process in both conditions. Task performance was measured through graded lab reports. The information participants were asked to provide in the reports mirrored the information found in the scientists' lab notes created when they conducted their original research. Each pair of study participants collaboratively created a lab report under each condition, generating a total of 40 lab reports; 20 created working remotely and 20 created working face-to-face. The lab reports were graded blindly; the graders had no knowledge of the report authors or under which condition the report was created. To further our understanding of participants' perceptions of the system, we conducted semi-structured interviews with each participant after each task. Study participants were asked what they thought about their experience, including the most satisfying and dissatisfying aspects of their experience. In addition, we inquired about work patterns that emerged during the experience, and the impact technology may have had on their interactions with their collaborator. After completing their second task, participants were also asked to compare working face-to-face and working remotely. To better learn each participant's perspective, participants were interviewed individually, for a total of 80 interviews, each lasting from 30 to 60 minutes. Task Performance: Analysis of Graded Lab Reports. The average lab report scores for the first task session were identical (70/100) for both the face-to-face and remote condition. Previous research would predict that scores from a remote first session would be lower because the remote session would lack the richness of collocation and face-to-face interaction, including multiple and redundant communication channels, implicit cues and spatial co-references, that are difficult to support via computer-mediated communications. This lack of richness is often thought to impair performance. Perhaps technical features such as seeing your partner's pointer and functions, optimized shared control of scientific instrumentation and applications, improved video that provides multiple views and high quality audio communications may be "good enough" for scientific tasks focusing on collecting, analyzing and interpreting data. The data further suggest that collaborating first remotely may have a positive effect. Using a multivariate analysis of variance (MANOVA) test, the differences in scores for the face-to-face and remote conditions were not statistically significant. However, when order is taken into account, participants who collaborated remotely first scored significantly higher on the second task than did those who collaborated face-to-face first. There was no statistically significant difference between face-to-face and remote lab scores for participants who collaborated face-to-face first. In general, the literature suggests that participants would learn more about the system, science and each other when collaborating face-to-face and that this knowledge helps increase their current and future performance. Our performance data suggest collaborating first remotely does not negatively impact current performance, and may positively impact future performance for scientific tasks such as data collection, analysis and interpretation. We looked to our interview data for explanations of this result. Participants' Perceptions of the Scientific Process: Post-Interview Analysis. As expected, participants reported disadvantages to collaborating remotely. However, participants also reported that some of these disadvantages are not significant in scientific work contexts and that coping strategies, or work-arounds, can reduce the impact of other disadvantages. Furthermore, participants reported that remote collaboration provided several relative advantages compared with face-to-face collaboration (see Table 1). Similar to previous studies [e.g., Olson, G.M. & Olson, J.S. (2000). Distance matters. Human-Computer Interaction, 15 (2-3), 139-178], study participants reported remote collaboration was less personal than face-to-face collaboration. When comparing working face-to-face and remotely, participants reported collaborating face-to-face was more personal and it was easier to express themselves. However, participants also reported that lacking this type of interaction when working remotely did not seem to have a negative impact on their work. The impersonal nature of remote collaboration increased their productivity and facilitated collaborative intellectual contributions. As participants explained: If we were. . . working side by side, we might tell more stories or something like that. . . . [However] if you're trying to get something done, sometimes the stories and stuff can get in your way. I think that being in separate rooms helps a little bit because it's more impersonal. . . [You] just throw stuff back and forth more easily. Participants also reported that when working remotely they received fewer implicit cues about what their partners were doing and thinking. The study participants explained that without these cues, it may be difficult to follow social interaction norms and assist your collaborators: [when collaborating face to face] it was a lot easier to ask questions of each other. . . since you have a feeling [about] when to interrupt them . . . if you're in the same room . . . you'll wait [to ask a question] until the other person is not doing as much or not doing something very specific. It is hard to get the context of any question that's asked because you're not paying attention to what the other person is doing because they're in a little [video-conferencing] screen. To compensate for this lack of cues, several participants reported they needed to talk more frequently and descriptively when collaborating remotely. Participants reported Even though we were in separate rooms, it kind of seemed like there was more interaction compared to being face-to-face, which seems kind of strange. . . . It just seemed more interaction was expected. . . . Maybe needed. We had a really good interaction [when collaborating remotely]. . . . You're conscious that you're not together and you can't see [some things, and] so you think more about [interacting. For example, you think] 'I need to let this person know that I'm about to do this' or 'this is what I'm seeing and I'm trying to let you know so, and you're like doing the same to me.' Thus to compensate for the absence of implicit cues in the remote condition participants provided explicit cues for their partner. When working remotely, it appears that individuals recognize they do not have a common shared physical reality and subsequently may not have a shared cognitive reality. However, humans are intrinsically motivated to develop a shared reality [Schutz, A., & Luckmann, T. (1983). The Structures of the Life-World, Vol. I. Evanston, IL: Northwestern University Press]. Subsequently, study participants developed a strategy, providing explicit cues to their partners, to develop a shared reality. These explicit cues, or joint actions, typically contribute to faster and more accurate formation of common ground and mutual understanding [Clark, H. (1996). Using Language. Cambridge, UK: Cambridge University Press]. In addition to receiving fewer cues from a partner, participants also reported that some physical tasks are more difficult when collaborating remotely. These tasks include drawing, e.g., creating sketches of scientific structures and manipulating mathematical equations, and sharing control of applications within NetMeeting. Some of these problems may be remedied with advances in technology, such as shared applications that support multiple pointers and concurrent floor control. Participants explained [when collaborating face to face] you could draw more easily, communicate diagrams more easily, and you could look at the other person and see their level of understanding more easily. The thing that frustrated me the most [collaborating remotely] was the shared applications [NetMeeting] . . . you could see the other person doing things but you couldn't do anything [simultaneously]. Although technology made some tasks more difficult, study participants also reported that the collaboratory system provides some advantages over collaborating face-to-face. These advantages include the ability to easily explore the scientific instrument and data and their own ideas both independently and collaboratively, having identical views of the data visualization, and working simultaneously with the data visualization. I liked that we were separate. I think it gave a whole new twist on the interactions, and if one of us got snagged up with something the other could independently work and get it done rather than both of us being bogged down by having to work on it simultaneously. Sometimes when you're working side by side with somebody, you have to deal with 'Well, you're looking at [the data] from a different angle than I am, and so you're seeing a different perspective there.' Now [working remotely] we could both of us be straight on, having the exact same perspective from where we're sitting. It made it easier. [My partner] could be changing the light focusing somewhere, while I could be zooming or moving [the plane] around. And that was really helpful because you're thinking, 'OK, as soon as I'm done moving the light I want to go ahead and shift [the plane] . . . [to be able to] say to [my partner], 'Why don't you [shift the plane] while I'm shining the light,' was really cool. It was really helpful. The participants in this study experienced disadvantages attributed to remote collaboration that have been previously reported in the literature. However, the study participants also reported that some disadvantages had minimal impact on their scientific work, and they used coping strategies to compensate for disadvantages. In addition, they perceived remote collaboration to provide some advantages relative to face-to-face collaboration. These findings corroborate our findings regarding task performance. The results illustrate the potential of collaboratories, allowing individuals who do not have specialized, state-of-the-art scientific instruments locally to access scientific instruments remotely and conduct scientific experiments in collaboration with other students, faculty and staff at institutions that have the instruments. When collaborating first remotely, study participants were able to use the technology and conduct science as well as or better than if they were face-to-face. Working face-to-face before working remotely did not produce the anticipated positive impact on the scientific process or outcomes. These conclusions are supported by the similarity in lab report grades for the first task session and statistically significant higher lab report grades for pairs who first worked remotely, as well as interview data that illustrate that the technology provides unique advantages and, although the technology has disadvantages, many individuals can develop coping strategies to reduce the impact of these disadvantages. The evaluation data combine to illustrate the potential of the collaboratory system for adoption by scientists and how this technology mediates collaborative scientific work processes without negatively impacting scientific data collection and analysis task outcomes. However, the tasks used in the study do not encompass the entire life cycle of the scientific process. For example, problem formulation, research design and research dissemination were not included in the tasks. Furthermore, the tasks in the first and second sessions differed. Although designed to be similar in complexity, additional investigation may uncover aspects of the tasks that are inherently impacted by an interaction condition. Future work includes a longitudinal field study to investigate whether the results reported here hold for professional scientific contexts. In the field study, the technology will be provided to scientists who have expressed an interest in conducting scientific investigations using the system. We plan to investigate the similarities and differences between scientists' and study participants' perceptions and use of the technology to further our understanding of the impact of collaboratories on the scientific process and outcomes. Our thanks to the study participants; to students who helped run the experiment sessions and assisted in data analysis; to the team who built the nM, including Frederick P. Brooks, Jr., Martin Guthold, Aron Helser, Tom Hudson, Richard Superfine and Russell M. Taylor II. The development of the nM and this work have been funded by the NIH National Center for Research Resources, NCRR 5-P41-RR02170. The nanoManipulator project is part of the Computer Graphics for Molecular Studies and Microscopy Research Resource at the University of North Carolina at Chapel Hill.
ER  -
TY  - JOUR
TI  - 從秀場到展場：台灣美術館中的時尚藝術展覽探討（2002-2008）
PY  - 2010
T2  - 國立臺北教育大學藝術與造型設計學系學位論文
DO  - 10.6344/ntue.2010.00092
UR  - https://doi.org/10.6344/ntue.2010.00092
DA  - 2010-01-01
AU  - , 王琳筠
LA  - en
KW  - Nothing
KW  - Modern art
SP  - 1
EP  - 97
ER  -
TY  - JOUR
TI  - Special Issue: Highlights From ASME Computers and Information in Engineering (CIE) 2017
PY  - 2018
PB  - ASM International
SN  - 1530-9827
T2  - Journal of Computing and Information Science in Engineering
DO  - 10.1115/1.4040307
UR  - https://doi.org/10.1115/1.4040307
DA  - 2018-06-12
AU  - Panchal, Jitesh
C1  - Associate Editor, JCISE, School of Mechanical Engineering, Purdue University, West Lafayette, IN 47907
LA  - en
KW  - Multiphysics
VL  - 18
IS  - 3
ER  -
TY  - JOUR
TI  - Limited access to museum and prosection models: how 3D scanning and 3D printing can help
PY  - 2019
PB  - Wiley
SN  - 0892-6638
T2  - The FASEB Journal
DO  - 10.1096/fasebj.2019.33.1_supplement.444.8
UR  - https://doi.org/10.1096/fasebj.2019.33.1_supplement.444.8
DA  - 2019-04-01
AU  - Venne, Gabriel
C1  - Anatomy and Cell Biology, McGill University, Montreal, QC, Canada
AU  - Medvedev, Rachel
C1  - School of Physical and Occupational Therapy, McGill University, Montreal, QC, Canada
LA  - en
KW  - 3D Scanning
KW  - 3d printed
KW  - 3d model
KW  - 3D modeling
VL  - 33
IS  - S1
ER  -
TY  - JOUR
TI  - Interactive Intelligent Systems and Haptic Interfaces
PY  - 2022
PB  - Wiley
SN  - 2640-4567
T2  - Advanced Intelligent Systems
DO  - 10.1002/aisy.202100172
UR  - https://doi.org/10.1002/aisy.202100172
DA  - 2022-02-01
AU  - Ozioko, Oliver
C1  - Bendable Electronics and Sensing Technologies (BEST) Group James Watt School of Engineering, University of Glasgow, Glasgow, G12 8QQ UK
AU  - Nathan, Arokia
C1  - Darwin College, University of Cambridge, Cambridge, CB3 9EU UK
AU  - Dahiya, Ravinder
C1  - Bendable Electronics and Sensing Technologies (BEST) Group James Watt School of Engineering, University of Glasgow, Glasgow, G12 8QQ UK
LA  - en
VL  - 4
IS  - 2
AB  - Haptics, which involve human touch sensing and tactile feedback, play a crucial role in the physical interactions of humans with their environment. Touch sensing constitutes the most intuitive and natural way for humans to interact with the digital world, and human–machine interfaces (HMIs) are at the core of these interactions. Over the past decade, the advances in HMIs have revolutionised areas such as robotics, healthcare, assistive technologies, autonomous vehicles, and augmented/virtual reality (AR/VR). More so, the remarkable progress in related underpinning technologies such as 5G/6G communication, internet of things, tactile internet, neurocomputing and machine learning provides a clear prospect towards the realisation of the envisioned smart society. As efforts towards these technologies continue to rise, more intelligent systems and various methods of human interaction with these systems will also continue to evolve. Apart from the conventional physical touch interaction, humans are now able to interact with 2D objects which are displayed as 3D objects via mid-air displays. In addition to different perception modalities in humans, tactile feedback plays a significant role for an efficient bidirectional interaction with the environment and enriches the user experience. Today, HMIs which can provide both tactile sensing and feedback have also been explored. Overall, the quality of the user experience while interacting with these systems, largely depends on the intuitive nature of the HMI in use, and their ability to provide easy to understand information. Over the years, both wearable and non-wearable HMIs have significantly evolved and effectively adapted for use in various intelligent systems such as those for human-robot interaction, human-in vehicle interaction, assistive technology, and VR/AR. One of the several challenges in HMIs technologies are issues such as bulky size, lack of intuitiveness, and high control precision, especially for monitoring the human motions or transmitting complex commands. However, novel wearable technologies are gradually revolutionizing our life by integrating the flexible sensors onto our body for a more intuitive and accurate detection of physical command through our body. More so, the burgeoning field of material sciences has increasingly enabled the fabrication of novel stretchable and even implantable devices to sense or stimulate the human activities during various interactions scenarios. With this, future intelligent systems are envisioned to be more intuitive and interactive. To develop a highly intuitive and intelligent interactive system, it is highly advantageous and encouraged to consider existing HMI technologies, tactile sensors, materials, computational techniques, soft actuators as well as advances in haptic interfaces suitable for the realization of such systems. To showcase the recent advances in this rapidly growing field, we have organised this special issue of Advanced Intelligent Systems focusing on “Interactive Intelligent Systems and Haptic Interfaces”. It covers various existing intelligent systems, HMIs, sensors, soft actuators, materials, and computational techniques, for applications in robotics, autonomous vehicles, and smart flexible/wearable electronics. The following paragraphs, summarizes the key contributions to this special issue. Christou et al. (article number 2000126) realised an interactive 3D touch surface using frustrated total internal reflection and four-sided pyramidal pseudo-holographic projection. This pseudo-holographic display allows gesture-based control and smooth touch interaction through facile and inexpensive hardware and open-source software tools. In another related work, Christou et al. (article number 2100090) also presented an air-based haptic feedback device, named “Aerohaptics”, which has the capability to deliver mid-air tactile feedback while the user is interacting within a custom-made pseudo-holographic display. The haptic feedback provided by this device has a controllable intensity and is capable of being directed on to specific location of the user hand during interaction with a virtual object. The reported device is quite simple and cost-effective as it does not require any wearable peripheral. Buhl et al. (article number 2100037), presented a technique for customising the tactile and visual perception of organic light emitting diodes. This provides opportunities for the realization of transparent and flexible devices for application in various objects such as clothing, windows etc. for tactile and visual interaction. To achieve this, the authors utilized a polymer coating to customize the tactile and visual perception capabilities of an OLED substrate. This has the potential to enable the adjustment of haptic and optical characteristic of devices without altering their OLED spectral emission characteristics. Shuo et al. (2100074), presented a comprehensive review on tactile and visual perception which provides the fundamentals, insights, and working mechanisms of tactile and visual sensing, as well as their various applications. Recently, hand gesture recognition has attracted huge interest, as an approach for human-machine interaction, and flexible strain sensor is rapidly being explored as a means of measuring the finger motion for accurate hand gesture recognition. Si et al. (article number 2100046) presented a review on flexible strain sensor for hand gesture applications. This review is timely and provides detailed progress on the materials, structures, and operation mechanisms of various flexible strain sensor for hand gesture recognition. While this work focuses specifically on the in-depth review of strain sensors for hand recognition, Ozioko et al. (article number 2100091) presented another review on smart tactile gloves for haptic interaction, communication and rehabilitation, including smart gloves where strain sensors have been utilized for hand gesture recognition. This is also a timely review considering that wearable devices are rapidly finding their way into our lives, and glove-based HMIs have attracted considerable interest in recent years. These gloves are worn on the hand, and hand gesture is one of the most intuitive ways for human to interact. The paper also discussed the possibility and prospects of tapping into the multi-functional capabilities of electronic skin (e-skin) for the realisation of glove-based HMIs for a more intuitive and richer user interaction experience. Further, the huge potential of integrating sensing and actuation for bidirectional haptic interaction for applications such as robotics, healthcare, sensorial augmentation for non-disabled and tactile internet etc. were also discussed. Marius et al., in their work (2100045), provided a framework for designing and evaluating gesture interaction in the low-dimensional space. Further, soft actuators are increasing becoming attractive for application in interactive human machine interfaces due to their soft and conformal nature. Karipoth et al. (article number 2100092), presented a bio-inspired inchworm and earthworm like soft robot with intrinsic strain sensing capability. Apart from the huge advantage of adding sensing to soft robots for realization of a more intelligent system, the strain sensor presented in this work, (with a high stretchability of up to 900%), could also be adopted for use in hand gesture recognition where it will measure hand movements during interactions. Additionally, Chen et al. (article number 2100075) presented a comprehensive review on low-voltage soft actuators for interactive human interfaces. Low-voltage soft electrical actuators presents advantages such as good safety, low power consumption, small system size. To provide the progress in this field, this review covers three typical classes of electrical actuators, namely electrochemical, electrothermal, and other electrical characteristics. Additionally, the advantages, working principle, device configuration/design, materials selection, including the challenges and solutions were presented. Another review by Ankit et al. (article number 2100061) covers soft actuator materials for electrically driven haptic interfaces. This review summarises the advancement in material for electrically driven soft actuators. It further provided a detailed analysis of the different strategies for improving the electromechanical performance of existing material, and approaches for synthesizing novel materials for such actuators. The paper concluded by reflecting on the challenges in the field and the prospects of this material for future applications Armleder et al. (article number 2100047), presented a control architecture that can support the deployment of large-scale robot skin in a human–robot collaboration scenario. The authors showed how whole-body tactile feedback can extend the capabilities of robots during dynamic interactions by providing information about multiple contacts across the robot's surface. From the obtained results, this paper concludes that multi-modal tactile information enables robust force control while still simultaneously responding to user's interactions. Taisuke et al. in his work (2100038), provided a potential solution to the tradeoff during physical human-robot interaction using bipedal walking control. In addition to the advances in human–computer interaction, there has been a recent interest in human–vehicle interaction (HVI) which takes place inside the vehicle. This is owing to the rapidly growing interest in autonomous vehicles. To present the recent progress in this field, Murali et al. (article number 2100122) presented a review on intelligent in-vehicle interaction technologies. This timely article systematically summarized the technologies that are being used or developed to perceive user's intentions for natural and intuitive in-vehicle interaction. Further, it discussed the inherent challenges, potential solutions, and future research direction in this area. We hope that this special issue focusing on Interactive Intelligent Systems and Haptic Interfaces will bring knowledge, insight, and inspiration to readers. We look forward to the rapid growth of the massive developmental efforts in this field which will lead us right into the envisioned smart society. Finally, we appreciate all the authors for their valuable contributions, and very thankful to the editorial team of Advanced Intelligent Systems for their support and the opportunity to organize this special issue. Oliver Ozioko is currently a lecturer in Electrical and Electronic Engineering at the University of Derby. He obtained his PhD from the University of Glasgow where he also worked as a postdoctoral researcher at Bendable Electronic and Sensing Technologies (BEST). His current research interest includes tactile sensors, haptic interaction, electronic skin, smart 3D printed objects as well as self-powered wearable and portable systems. Arokia Nathan is a Bye-Fellow and a Tutor with Darwin College, University of Cambridge. He is a leading pioneer in the development and application of thin-film transistor technologies to flexible electronics, display, and sensor systems. He has over 600 publications, including four books, and more than 110 patents and four spin-off companies. He is a recipient of the 2020 IEEE EDS J. J. Ebers Award. He is Fellow of IEEE. Ravinder Dahiya is Professor of Electronics and Nanoengineering in the University of Glasgow, U.K. He is the leader of Bendable Electronics and Sensing Technologies (BEST) research group. He has authored over 400 research articles, 8 books, and 15 submitted/granted patents and disclosures. He is the President of IEEE Sensors Council and Founding Editor-in-Chief of IEEE Journal on Flexible Electronics (J-FLEX). He has received several awards, including 11 best paper awards as author/co-author in International Conferences and Journals. He is Fellow of IEEE.
ER  -
TY  - JOUR
TI  - Exploring Immersive Multimodal Virtual Reality Training, Affective States, and Ecological Validity in Healthy Firefighters: Quasi-Experimental Study (Preprint)
PY  - 2023
DO  - 10.2196/preprints.53683
UR  - https://doi.org/10.2196/preprints.53683
DA  - 2023-10-15
AU  - Oliveira, Joana
AU  - Dias, Joana
AU  - Correia, Rita
AU  - Pinheiro, Raquel
AU  - Reis, Vítor
AU  - Sousa, Daniela
AU  - Agostinho, Daniel
AU  - Simões, Marco
AU  - Castelo‐Branco, Miguel
LA  - en
KW  - Preprint
KW  - Ecological validity
ER  -
TY  - JOUR
TI  - Editorial
PY  - 2007
PB  - ASM International
SN  - 1530-9827
T2  - Journal of Computing and Information Science in Engineering
DO  - 10.1115/1.2815940
UR  - https://doi.org/10.1115/1.2815940
DA  - 2007-11-29
AU  - Shah, Jami
LA  - en
VL  - 7
IS  - 4
SP  - 293
EP  - 294
AB  - As we complete the seventh year of publication, I am writing this editorial to report to you the state of JCISE.JCISE began publication at the start of the new millennium. It was created by ASME CIE Division to provide a forum for publishing high quality archival research at the intersection of engineering and computer science. The journal was established by the effort of many people, particularly Yong Se Kim, Simon Szykman, David Rosen and David Lee. Significant milestones in the evolution of JCISE include the co-operative arrangement with ACM (Association for Computing Machinery) from 2001–2004, inclusion of JCISE in SCI index in 2004 and joint sponsorship of ASME Design Engineering Division in 2006.What kinds of papers are published in JCISE? Of the almost 300 papers published in JCISE in the past seven years, Geometric modeling, including solid modeling, constraint solving, parametrics, features, assembly modeling and surface modeling account for about 30% of all papers. Computational metrology, tolerance modeling and analysis, CMM and inspection planning continue to present many challenges, as evidenced by the large number of papers appearing in JCISE, just under 20%. The next large group is from Computer aided Manufacturing, including CAPP, process simulation and plan optimization. Machining seems to still be the main focus of such research, followed by injection molding and solid free form fabrication. In recent years, a few papers have appeared on subjects related to micro-fabrication. In addition to computational techniques, JCISE also focuses on Information Science applied to engineering, as indicated by the title of our journal. Papers on engineering information management, data models, ontologies and data exchange have been another big part of JCISE. Recent IT trends appear to be in the direction of developing integration frameworks and collaborative environments.Other areas represented in JCISE issues are Virtual Reality and Immersive Environments, Simulation (mostly meshing), Optimization, and AI and Knowledge based Systems. One surprise has been the fewer than expected number of submissions in Artificial Intelligence and Knowledge based Systems (AI/KBS). Perhaps this area is not as popular in engineering as it once was, or maybe the papers are going to journals narrowly focused on those topics.JCISE has published many special issues to introduce the journal to new communities or to highlight emerging technologies. JCISE special issues have included the following topics: Meshing, Reverse Engineering, Collaborative Engineering, Computational Metrology, Engineering Information Management, and Computer aided Conceptual Design (CACD). The issue on CACD led us to the realization that some areas are in very early stages of development and not yet ready to produce archival papers. In the coming year we plan to publish two special issues: one on Engineering Informatics and the other on Haptics in Immersive Environments. Review of papers in these areas is already underway.In addition to full length research articles, we also publish papers in the Application Track. These represent innovations in software or data technology that have mechanical design or simulation implications. The archival value of such publications is in the innovation part of the system design and not necessarily in the theory. Industry pilot projects or prototype implementation are also appropriate for such briefs.For the first four years of JCISE, ACM was a joint sponsor with ASME. As part of this cooperation, we published one special issue each year composed of the best papers from the ACM Solid Modeling conference. All papers had to go through an additional review process to ensure that they met Transaction level quality. One difficulty with this arrangement was that some of the best papers forwarded to us did not fit well into our scope. We focus strictly on mechanical and electro-mechanical product development but the ACM conference has a much broader scope and includes geometric computing technologies for all kinds of applications, such as video games, medicine, geology, etc. When the ACM Solid Modeling conference was combined with IEEE Surface Modeling conference we ran into new problems related to copyright ownership. After producing four wonderful issues from best papers presented at ACM conferences, this tradition was discontinued by mutual agreement.In 2004 ISI accepted JCISE into its citation index. It requires three years of data collection to compute Impact Factors. Just a few months ago ISI released Impact Factors for JCISE for the first time. The good news is that our IF of 0.531 puts us in the top one-third of our peers. The bad news is that IF is not a good measure of quality or impact but many people are using this number for various purposes. Whether I agree with such uses or not, I am forced to pay attention to this “measure” and think about ways to continually improve our score.Unlike other journals in our field, JCISE is published by a non-profit, professional society. The ASME's Transaction label is reserved for archival scholarly journals of highest quality. To ensure quality, all Transactions operate under strict guidelines set by ASME's Publication Committee. This includes a multi-layered paper review system, formal processes for review and appointment of Editors and Associate Editors, term limits and central oversight. In addition, JCISE is governed by an Advisory Board with representatives from sponsoring and co-sponsoring Divisions of ASME. JCISE also provides full transparency of its review process through its web-based paper management system, eLane. Authors can view every detail related to their paper at any time; they can see how many reviewers have been assigned, when each downloaded the paper, when each submitted the review and the recommendation made by the Associate Editor. Once the reviews are submitted they cannot be edited or deleted and must be shared in their entirety with the authors. The only information kept confidential is the identity of the reviewers. Few journals provide this level of access to authors. We are also proud of our industry leading average review times and submission-to-publication time. Our acceptance rates are comparable to those of other ASME Transactions.The most important people for building and maintaining the quality of JCISE are our Associate Editors. I would like to take this opportunity to acknowledge the key role they play and to thank them for their dedicated service to our community. I have included a profile of our current Associate Editors in this issue. I would also like to recognize the distinguished group of people who serve on our Advisory Board. Their profiles are also included in this issue. Last but not least, I would like to thank all our reviewers for their time and effort in evaluating JCISE papers. Realizing the demands on our reviewer's time, we limit the total number of review cycles to just two. After that a final accept/reject decision must be made. This is a departure from other ASME journals.I would be very happy to receive comments, suggestions, feedback from our readers so as to make continuous improvements to the JCISE.
ER  -
TY  - GEN
TI  - Index
PY  - 2017
PB  - Emerald Publishing Limited
SN  - 1479-3636
T2  - International perspectives on inclusive education
DO  - 10.1108/s1479-363620170000011020
UR  - https://doi.org/10.1108/s1479-363620170000011020
DA  - 2017-07-07
SP  - 267
EP  - 272
ER  -
TY  - JOUR
TI  - Curiosity
PY  - 2018
PB  - Lippincott Williams & Wilkins
SN  - 0148-396X
T2  - Neurosurgery
DO  - 10.1093/neuros/nyy292
UR  - https://doi.org/10.1093/neuros/nyy292
DA  - 2018-06-05
AU  - Cohen, Alan
C1  - Alan R. Cohen, MD, Johns Hopkins Hospital, Pediatric Neurosurgery, 600 N Wolfe Street, Phipps 556, Baltimore, MD 21287. E-mail: [email protected]
C1  - Department of Pediatric Neurosurgery, Johns Hopkins Hospital, Baltimore, Maryland
C1  - Online date: August 13, 2018
LA  - en
KW  - Curiosity
VL  - 65
IS  - CN_suppl_1
SP  - 37
EP  - 48
AB  - This is a selfie taken by the Curiosity Rover on the surface of the planet Mars (Figure 1). The rover landed in the Mars Gale Crater Aug 5, 2012, less than 1.5 miles from its touchdown target after a journey of more than 350 million miles over 8.5 mo. Remarkably, within weeks, Curiosity rolled through an ancient streambed where water once flowed. It is still roving on Mars 5 yr later.FIGURE 1: Curiosity Rover on Mars. Photo by NASA, public domain.The Curiosity I’d like to talk about today has to do with the burgeoning field of Minimally Invasive Neurosurgery (Figure 2). I’d like to share with you some of the lessons I’ve learned working in that arena over the past 30 yr.FIGURE 2: Endoscopic resection of colloid cyst.Albert Szent–Györgyi was a biochemist who won the Nobel Prize for Physiology or Medicine in 1937 (Figure 3). He said something profound that applies to everyone in the audience: “Discovery consists of seeing what everybody has seen, and thinking what nobody has thought.”FIGURE 3: Albert Szent–Györgyi. CC BY-3.0, from FOTO: FORTEPAN/Semmelweis Egyetem Levéltára.The field of endoscopy dates back to at least the fourth century BC, when Hippocrates used a bamboo speculum to inspect the rectum and remove condylomata. But the godfather of endoscopy is Philipp Bozzini, of Mainz, Germany. In 1806 Bozzini developed the “Lichtleiter”, or Light Carrier, an aluminum endoscope consisting of a wax candle in a cradle, a set of reflective mirrors and a series of tubes that could be fitted at the other end to examine body cavities, which he did on cadavers. However, due to rampant internecine rivalry in 19th century Europe, when he presented his device to the faculty of the University of Vienna, he was roundly ridiculed and criticized for his “inappropriate curiosity” and his “magic lantern” was rejected. Bozzini died 3 yr later at the age of 36, and the field of endoscopy was set back for 50 yr (Figure 4).FIGURE 4: A, Philpp Bozzini. Portrait of Philipp Bozzini, 1773-1809. http://history.uroweb.org/biographies/bozzini-philipp/. Used with permission from the European Association of Urology and its European Museum of Urology. B, Bozzini's Lichtleiter. Image courtesy of the Archives of the American College of Surgeons. https://www.facs.org/about-acs/archives/pasthighlights/bozzinihighlight.Arthur Schopenhauer, the 19th century philosopher said, “All truth passes through 3 stages. First, it is ridiculed. Second, it is violently opposed. Third, it is accepted as being self-evident.” Schopenhauer's words certainly apply to the work of Bozzini, and many other investigators who have come after him. Another landmark advance in endoscopy came from Adolph Kussmaul of Freiburg, Germany in 1868 when he became the first to perform gastroscopy to examine the esophagus and fundus of the stomach, using a rigid tube with mirrors and a gasoline-powered lamp. The challenge was that most people cannot voluntarily release the cricopharyngeal muscle, so Kussmaul did the first procedure in a sword swallower. He actually brought sword swallowers with him on tour to demonstrate his new technique, and as a result he was honored by induction into the Sword Swallowers Hall of Fame (Figure 5).FIGURE 5: Sword swallower. From Hopkins, Albert (1897) Magic; stage illusions and scientific diversions, including trick photography, London: Sampson Low, Marston and Company, p. 158. Public Domain.Endoscopy has made advances in virtually every medical and surgical subspecialty, in man or beast, in which there is an air or fluid-filled cavity. It is surprising, then, that the field of neuroendoscopy began relatively late, as the cerebral ventricles are deep-seated, difficult to access, and filled with clear fluid. Neuroendoscopy began as an effort to diagnose and treat hydrocephalus, a once and sometimes still fatal disease. The first neuroendoscopic procedure was performed in 1910 by Victor Lespinasse, a Urologist from Chicago. He used a cystoscope to fulgurate the choroid plexus in 2 infants with hydrocephalus. One child died on the operating room table, the other lived for 5 yr and the work was never published, it appeared only as a footnote in a textbook, Neurological Surgery, by Loyal Davis, in 1936, who incidentally was Nancy Reagan's stepfather. Lespinasse was talented, but eccentric (Figure 6). He called the procedure “an intern's stunt” and abandoned the field. In 1922, he performed a famous operation on Harold Fowler McCormick, who was 50 yr old, and VP of International Harvester. He was the son of Cyrus McCormick, The Reaper King, and was married to Edith Rockefeller, daughter of John D. Rockefeller, the President of Standard Oil. On the right, the Chicago Tribune shows McCormick both before and after the secret operation.FIGURE 6: Victor Darwin Lespinasse. Reprinted from World Neurosurgery, 79(2), Decq P, Schroeder HWS, Fritsch M, Cappabianca P, A History of Ventricular Neuroendoscopy, S14.e1-S14.e6, 2013, with permission from Elsevier.McCormick was divorcing his wife and running off to Europe with the Polish opera singer, Ganna Walska (Figure 7). Impressed by the virility of his elderly father in law, McCormick submitted to an operation of testicular transplantation by Lespinasse (this was well before the era of Viagra). The secret operation was performed for an exorbitant fee of $50 000. The reason for such a fee is that it was said that the donor was a local blacksmith, who was amply remunerated for his donation. The Chicago Tribune and New York Times were replete with articles about denials and lawsuits. The local society clubs in Chicago shared the verse, adapted from Longfellow: “Under the spreading chestnut tree, the village smithy stands; The smith a gloomy man is he, McCormick has his glands.”FIGURE 7: Ganna Walska. PD-US, no known restrictions on publication.The same year, 1922, Walter Dandy of Johns Hopkins, used a Kelley cystoscope to inspect the lateral ventricles and avulse the choroid plexus in 2 infants with hydrocephalus, describing the outcome as only partially successful. He coined the term, “ventriculoscope.” The following year, in 1923, W. Jason Mixter, working at the MGH, performed the first successful endoscopic third ventriculostomy (ETV), fenestrating the floor of the third ventricle in a 9-mo-old infant with aqueductal stenosis (Figure 8). He published his operation in the Boston Medical and Surgical Journal, the forerunner of the New England Journal of Medicine.FIGURE 8: William Jason Mixter. Image printed with permission of Massachusetts General Hospital, Archives and Special Collections.ETV became the standard treatment for hydrocephalus, but the early instruments were poor and the morbidity and mortality rates were high, and ETV gradually fell out of favor, particularly in 1951 when Frank Nulsen and Eugene Spitz introduced ventricular shunting. Then the instruments got better and ETV was re-introduced by Gerard Guiot of Paris in 1962. Guiot placed an endoscope into one lateral ventricle and a spatula in the other to fenestrate the third ventricular floor in cases of aqueductal stenosis. In 1973 Takanori Fukushima, working in Tokyo, used a “ventriculofiberscope” to biopsy tumors of the lateral and third ventricles. In 1975, Huw Griffith of Bristol, England, used a rigid ventriculoscope with a solid rod lens system to treat hydrocephalus in children (Figure 9).FIGURE 9: Huw Griffith. From Maurice-Williams RS, Cummins B. Huw Griffith 1930–1993, British Journal of Neurosurgery, 7(6), 1993, reprinted with permission of Taylor & Francis Ltd, http://www.tandfonline.com.I became interested in the field about 30 yr ago, and began collaborating with the brilliant surgeon, Axel Perneckszky, of Mainz, Germany. Perneckzky coined the term keyhole surgery, and I searched far and wide for a picture of an old-fashioned keyhole, and finally found this one at a meeting in Wiesbaden, Germany. As luck would have it, the keyhole was on the door to the Men's Room, and someone opened the door and came out as I was snapping the photo. And I can tell you, that if something like that ever happens to you, don’t even bother trying to explain what you’re doing—there's nothing you can say that will make it better. We have rigid endoscopes with solid rod lens technology. And we have flexible endoscopes, that can be steered to look around corners. I tend to use the rigid lens system more often because I prefer the superior optics. I call the procedure, Nintendo Neurosurgery, because the image is projected through a camera onto a TV monitor. We learned early on to place the TV in front of the surgical team so we would not have to strain our necks. I began using ventriculoscopy to fenestrate loculated cysts in cases of complex hydrocephalus and to fenestrate the septum pellucidum for trapped lateral ventricles (Figure 10). Carl Heilman and I used a “saline torch”, a poor man's laser, developed by Kim Manwaring, to perform the fenestrations. Middle fossa arachnoid cysts lend themselves nicely to endoscopic fenestration, because they are large and filled with clear fluid (Figure 11). The cysts can be fenestrated to the basal cisterns. However, I prefer to do these fenestrations using a mini craniotomy because it enables me to have better control and make larger fenestrations.FIGURE 10: A, Endoscopic fenestration of septum pellucidum. B, Closer view.FIGURE 11: Left middle fossa arachnoid cyst.Suprasellar arachnoid cysts, which can obstruct the foramina of Monro and cause symptomatic hydrocephalus, are ideally suited for endoscopic fenestration (Figure 12). Through a single burr hole, one can perform a ventriculocystostomy, fenestrating the cyst into the ventricle, as well as a cystocisternostomy, fenestrating the cyst into the basal cisterns, obliterating the slit valve mechanism that may be responsible for enlargement of these cysts.FIGURE 12: Large suprasellar arachnoid cyst.I became interested in endoscopic third ventriculostomy as a rejuvenation of Mixter's operation from 1923, now that the instruments are better. The procedure is ideally suited for acquired noncommunicating hydrocephalus, for example, aqueductal stenosis, as fenestration of the thinned tuber cinereum at the third ventricular floor permits the operator to short circuit CSF into the basal cisterns, bypassing the obstruction downstream (Figure 13).FIGURE 13: Endoscopic third ventriculostomy.ETV entails poking a hole in the third ventricular floor and dilating it with a balloon catheter. Once the fenestration is created one has a clear view of the basilar artery in the interpeduncular cistern. The fenestration is made under direct endoscopic visualization anterior to the mammillary bodies, away from the underlying basilar artery. When I started doing ETV, there was a move to use tiny diameter fiberscopes, in the hope of minimizing trauma to the brain. The problem, though, was that the optics were so poor it was difficult to do anything therapeutic. So I started using higher resolution rod lenses through a sheath with working channels and the anatomy immediately became clearer. Figure 14 showsa view of the right foramen of Monro. One can clearly identify the periforaminal structures and third ventricular floor. A balloon catheter is passed through the third ventricular floor. The balloon is inflated to create the fenestration. And that's the entire procedure (Figure 14).FIGURE 14: A, Right foramen of Monro. B, Fogarty balloon catheter. C, Enlarging the fenestration. D, Fenestration in third ventricular floors.We published a series of 100 consecutive cases of ETV with an overall success rate of 75%, with no deaths. The single most powerful prognostic factor was inferior bowing of the third ventricular floor. If the floor was bowed down on the preop MRI, the overall success rate was 79%. ETV is effective in treating hydrocephalus associated with pineal tumors, permitting CSF sampling and tumor biopsy in the same sitting. The approach to the anterior third ventricular floor through the foramen of Monro for ETV is usually just in front of the coronal suture, while the approach to the posteriorly situated pineal tumor is fairly more anterior. We developed a “split the difference” technique that permits both procedures to be performed through a single burr hole. For tumors that will require open microsurgical resection, this can be carried out electively with the hydrocephalus controlled. Neuroendoscopy is not difficult, but it is different, and the success of procedures is often dependent on attention to subtleties or nuances of judgment and technique. For ETV, it is essential to plan the trajectory, and the sagittal MRI is helpful for choosing the site of the burr hole. As Yogi Berra said, “Baseball is 90% mental, the other half is physical.” The same holds true for neuroendoscopy—most of the effort is in the planning. Because ETV is a midline operation, it is helpful to move the burr hole more medial than the standard mid-pupillary line. When necessary, image guidance can be useful for planning the trajectory (Figure 15).FIGURE 15: A, Frameless stereotactic navigation. B, Frameless stereotactic navigation.The anatomy is fairly constant, but one only sees a small amount of it at any given time, and it can be easy to get lost. It is prudent to practice the procedure before performing it live (Figure 16). We have worked to develop novel teaching techniques, collaborating with computer scientists to create a virtual reality simulator. The virtual reality simulators combine visual images rendered from MR scans with haptic (tactile) feedback.FIGURE 16: Minimally invasive neurosurgery laboratory.Recently, when I was at Boston Children's Hospital, I worked with a group of simulation engineers, neuroradiologists, and special effects technologists from Hollywood, Fractured FX, using 3-dimensional printing to create ultrarealistic physical models rendered from MR images so that trainees can practice minimally invasive techniques in a pulsating brain in which CSF is flowing and blood vessels are beating (Figure 17).FIGURE 17: 3D model of endoscopic third ventriculostomy. Cover of Journal of Neurosurgery: Pediatrics, July 2017, reprinted with permission of JNSPG.As technology has improved, indications for neuroendsocopy have increased. Colloid cysts of the third ventricle can obstruct the foramina of Monro causing symptomatic hydrocephalus. Conventional treatment entails craniotomy and microsurgical resection. This avascular tumor sitting in a lake of CSF lends itself nicely to an endoscopic approach. We began using an endoscopic approach to resect colloid cysts in the early 1990s, employing a YAG laser to open the capsule and microinstruments to resect the cyst. The success of surgery depends upon having adequate visualization of the mass in the foramen of Monro. Unlike ETV, where we move the burr hole more medially, for colloid cysts we move the burr hole more anteriorly and laterally. Here, the operator has a nice face-on view of the lesion obstructing the foramen. Endoscopic resection can be highly effective in selected patients (Figure 18).FIGURE 18: Endoscopic resection of colloid cyst. Reprinted from Neurosurgical Operative Atlas, 1993, Alan R. Cohen, with permission of the American Association of Neurological SurgeonsAnother novel approach to these cysts is neuroendoport surgery. A slightly larger tube permits the surgeon to use better instruments and bimanual technique. Here's a large colloid cyst that we removed using a neuroendoport technique. Here's the resection performed using an endoport. The hypothalamic hamartoma can cause gelastic seizures that can be medically intractable. This 9-yr-old boy had been misdiagnosed for years because the small lesion was not recognized. The endoscopic approach can be tricky because of the small size of the ventricles, so frameless navigation is helpful. The endoscope is guided through the foramen of Monro and the subependymal hamartoma is resected. Removing that small lesion had a dramatic effect on that youngster because it eliminated his seizures. The endoscope can be used in conjunction with the microscope to perform synchronous surgery for selected cases (Figure 19). For example, some large cystic and solid adamantinomatous suprasellar craniopharyngiomas in children cause hydrocephalus and are also adherent to neurovascular structures at the skull base. The ventriculoscope can empty the cystic component from above to make the microsurgical resection from below easier. We and others have used this technique of burr hole ventriculoscopy in combination with skull base microsurgery to facilitate resection of some of the tougher tumors.FIGURE 19: Synchronous microsurgery and endoscopy. Reprinted with permission. Copyright © 2010, © 2010 S. Karger AG, BaselIn the lab, we have developed some minimally invasive epilepsy procedures, including endoscopic hemispherotomy for medically intractable epilepsy. The procedure, anatomic hemispherectomy, is one of the most invasive operations ever developed. Over time the operation has been modified to a less invasive hemispherotomy. We went a step further and developed a technique of endoscopic transventricular hemispherotomy, and in a cadaveric model, we were able to disconnect the entire hemisphere using only 2 burr holes (Figure 20).FIGURE 20: Endoscopic hemispherotomy. Cover of Journal of Neurosurgery: Pediatrics, December 2010, reprinted with permission of JNSPG.Endoscopic endonasal surgery is effective n approaching parasellar lesions. Here is a transnasal removal of a craniopharyngioma under endoscopic guidance (Figure 21).FIGURE 21: A, Craniopharyngioma, Preop MRI. B, Postop MRI.Endoscope-assisted microsurgery enables the operator to expand the field of vision and look around blind corners. The endoscope can be a useful adjunct to the microscope for tumors at the skull base, such as intracranial epidermoids, which can weave around basal cisterns and have hidden components. In one case, we used the endoscope to facilitate total resection of an epidermoid tumor within the substance of the brainstem at the pontomedullary junction. The endoscope can be used in conjunction with the microscope to help identify hidden remnants of vestibular schwannomas and clival chordomas. In vascular neurosurgery, the endoscope can sometimes be helpful for inspecting the position of an aneurysm clip to ensure there are no perforators being occluded. For endoscope-assisted microsurgery to be useful, your operating room needs to be familiar with setting up the equipment. Otherwise, it is too laborious and time-consuming to be of practical value. Endoscopic neurosurgery is a burgeoning field that is still evolving. The 18th century German philosopher, Johann Wolfgang von Goethe, said, “Man sieht nur was man Weiss.” “One sees only what one knows.” In this tour of the evolution of neuroendoscopy, we one can appreciate that advances in the field came when investigators looked farther than they were able to see. Disclosure The author has no personal, financial, or institutional interest in any of the drugs, materials, or devices described in this article.
ER  -
TY  - JOUR
TI  - 10th Anniversary Special Issue: From Fringe to Mainstream—We Have Come a Long Way
PY  - 2011
PB  - ASM International
SN  - 1530-9827
T2  - Journal of Computing and Information Science in Engineering
DO  - 10.1115/1.3599040
UR  - https://doi.org/10.1115/1.3599040
DA  - 2011-06-01
AU  - Shah, Jami
C1  - Engineering of Matter, Transport and Energy, School for (SEMTE)
LA  - en
KW  - Mainstream
VL  - 11
IS  - 2
AB  - At the start of my Ph.D. in 1980, I caught a glimpse, purely by chance, of the emerging field of computer-aided design (CAD). It intrigued and fascinated me to such an extent that I ended up scrapping my original plans, switching schools and changing my research area. Even though my new school, Ohio State, was one of only a handful of schools with computing facilities dedicated to CAD, I ran into stiff resistance when I expressed my desire to get a Ph.D. in CAD. I was told that CAD was hardly an intellectually challenging field worthy of a Ph.D. dissertation. I was directed to consider mainstream mechanical engineering areas, such as solid mechanics, vibrations, kinematics, and dynamics. The closest I could get to CAD was to do my dissertation in FEA, which allowed me to do at least part of my work in computing and visualization.When I began my academic career at Arizona State, I thought I was finally free to pursue my true love. But I soon realized that we were still a fringe group; faculty in traditional fields, such as thermofluids and solid mechanics, took a dim view of computational research. The proposed thesis plan for my first graduate student (Expert System for Conceptual Synthesis of Frame Structures) was rejected by the Graduate Chair, who remarked “This is not mechanical engineering.” He viewed it as purely a computer program without any regard for the fact that we needed to explicate, structure, and represent experiential knowledge for structural synthesis not found in any textbook on the subject.Of course, I was not alone in facing this predicament. Fortunately, for misfits like us there was an ASME Division that welcomed us. Originally named the Computer Engineering Division (CED), and later known as Computer &amp; Information Engineering (CIE) Division, it was approved in 1979 and began operating in 1980. Unlike academia, industry was well aware of the potential of computing and information technologies to revolutionize product design and manufacturing. Visionaries from computer industry (CDC, IBM, DEC, Applicon), an infant software industry (SDRC, CV, Swanson), and a variety of OEMs (GM, GE, McDonnell-Douglas) led a grassroots effort to convince ASME of the importance of mechanical engineers active participation in these evolving areas through the creation of a new Division. The first CED newsletter in 1981 boldly heralds “…the dawn of an era that is certain to be dominated by computer technology. All projections indicate that mechanical engineers, more than any other professional group, will be more involved in the utilization of this (computer) technology.” They saw MEs playing as important a role in the IT revolution as their far predecessors had in the industrial revolution—a prediction that was to come true.Prof. Ali Seirig was appointed the first Chair of CED. I am in awe of the progress this new Division made in just the first two years. Twenty-four technical committees were set up and an annual conference was initiated in 1981. This conference was unique in that it was associated with an exhibition of the latest hardware and software from leading vendors. This element was critical in keeping the ASME community well informed about the current state of engineering computing. It is, therefore, not surprising to see that this Division was heavily industry dominated—21 out of 24 Technical Committee Chairs were from industry. Sadly, today industry participation in CIE has sagged. Did CIE change because industry participation diminished, or did industry reduce its participation because CIE became less relevant to their needs? We can only speculate about the reasons.CED soon became the fastest growing Division within ASME. The CED/CIE conference and exhibition attracted participants from a wide range of areas, not just CAD/CAM and FEA but kinematics, robotics, heat transfer, and fluid mechanics. This diverse community only had one thing in common, the application of computational methods to problems in their respective fields. As traditional conferences and journals gradually came around to seeing computational methods as valuable contributions in their own fields, they became more accepting of papers of this nature. Thus began the return of computational researchers back to their own discipline communities, shrinking the size of CIE conferences. Finally, in 1994, the CIE conference was colocated with Design Engineering Technical Conferences (DETC).The founders of CED debated the type of journal they needed to have. They felt that given the rapid evolution of computing technologies, an archival journal like an ASME Transactions was not appropriate. At the same time, they wanted their journal to be more technical than a trade magazine. They ended up creating a “hybrid” quarterly publication called CIME (Computers in Mechanical Engineering), with Ali Seirig as its editor. This magazine was produced in full color and was very informative about the latest developments in engineering software. In the words of the editor, CIME was “user-oriented” not “research oriented.” Unfortunately, this philosophy did not command much respect in academia and eventually CIME was merged into ASME’s monthly magazine Mechanical Engineering.And so it came to be that unlike all other ASME conferences and Divisions, CIE did not have any associated journal. Over the years, CIE leaders made several attempts at getting a Transactions journal approved, but to no avail. Reasons for rejection ranged from “computing technologies have no archival value” to the failure to sustain CIME magazine.In 2000, a small group of CIE Division “activists” decided to make another push for a journal. Yong Se Kim, David Lee, Simon Szykman, and David Rosen were the principals in this effort. They came up with a strategy based on lessons from past failures. That included building alliances with three other Divisions (Design, Manufacturing, and Systems &amp; Controls), and demonstrating that an editorial board could be formed with well known researchers who had extensive publication records. I became aware of this effort when I received a call out of the blue, asking me the intriguing question “How would you like to be the Chief Editor of an ASME Transactions?” Of course, the very next sentence brought me down to earth quickly “…the problem is that the journal doesn’t yet exist – will you help us get it approved by ASME?” Thus began my involvement with this journal. We put together an impressive editorial board that included two NAE members and research leaders in each of our targeted areas. Phil Divitero, ASME Director of Publications, immediately saw the marketing potential of this journal, and became a key ally. Bahram Ravani, DED Chair, gave valuable advice on writing our proposal to ASME. Art Erdman, himself a CIE pioneer, happened to be the Chair of ASME Publication Committee, which had authority of approving new journals, which gave us a much needed sympathetic ear on the committee to make our case. In a café in Chicago, before our presentation, we brainstormed various names for the journal and settled on Journal of Computing &amp; Information Science in Engineering (JCISE). The journal was approved and began publishing in the first year of the new millennium, 2001. The CIE Division finally had an archival journal of its own with three cosponsoring Divisions. In 2005, after much lobbying and deliberation, the Design Engineering Division became an equal partner with CIE—an important step in going mainstream.From the very beginning we decided to focus sharply on computational methods for mechanical product development. This set us apart from journals from private publishers that accepted everything and anything related to computing—from gaming to geology, from biology to every branch of engineering. We did not want to dilute our journal with such a wide and general scope. We stipulated that every paper submitted to JCISE must demonstrate applications of its techniques to mechanical design, mechanical analysis, product manufacturing, or quality assurance. Through several iterations we settled on eight major categories to include within the scope of our journal: solid modeling (including parametrics), computational geometry (including reverse engineering), computational metrology (including CMM and tolerance modeling), haptics and virtual reality, engineering informatics, simulation (including FEA, meshing, and optimization), AI/Knowledge based systems, and computer aided manufacturing. Given the practical nature of our field, we also decided to publish papers along two tracks: Research and Application. The latter has subcategories of Software Reviews, Technology Reviews, Tech Notes, and Industry Pilot Projects. The idea was to keep the journal relevant to industry as well as academia. We instituted a three-level rigorous review process for appointment of Associate Editors. We owe it to the founding editorial board for setting sound policies that resulted in quick recognition of JCISE as an archival publication of high quality. That group consisted of Paul Wright, David Rosen, Nick Patrikalakis, Deba Dutta, Susan Urban, Martti Mantyla, Dana Nau, S. Jayaram, Pradeep Khosla, Harry Cheng, and Ravi Rangan. Since we see ourselves as being at the intersection of computer science and mechanical engineering, it was appropriate to have about half of the AEs from each field, and we managed to do so.ACM (Association for Computing Machinery) approached us in 2001 to become an official cosponsor—an offer we gladly accepted in order to strengthen the linkage with our computer science colleagues. From 2001 to 2004, we published a special issue annually drawn from the best papers of the ACM Solid Modeling conferences. Unfortunately, this conference series became too broad, and it was difficult to accommodate their best papers in JCISE without violating our objective of serving the engineering community; this annual tradition of ACM special issues had to be discontinued.ISI included JCISE in its data collection in 2004; after 3 years of this process, the first Impact Factors for JCISE became available in 2007 (for the 2004–2006 period). With respect to ISI Impact Factors, JCISE ranks in the top third of all ASME Transactions; it is better than many long established journals in CAD/CAM and AI areas. Our Impact Factor has continued to improve each year. How meaningful are such statistics in gauging the quality of a journal is debatable. More meaningful metrics are in the offing and we hope they will supplant bean counters of today.When we opened shop in 2000, ASME did not have any web based tool for paper submission and review management. Being the journal focused on computing and information science, we refused to conduct paper reviews the old fashioned way and began developing eLane. With the help of one of our associate editors, Susan Urban, a database expert, and one of her brilliant students, Anish Shah (no relation), we designed and implemented eLane over a period of 3 years. For the past 10 years, we have hosted, maintained, and continuously improved eLane to support not only JCISE but also other journals, such as Research in Engineering Design, and CIE, DTM, and NSF Grantees conferences. eLane blazed a new trail and guided ASME to develop its own “Journal Tool.” Data security and confidentiality is a critical issue in online systems. I am particularly indebted to one of our founding associate editors, Simon Szykman, who provided valuable advice on security aspects of the system by constantly trying to enter the system through unintended holes. It is no surprise that Simon went on to become the first Director of the Cyber-Security group at US Department of Homeland Security and is now the CIO of the Department of Commerce.With Bahram Ravani taking over as the new chief editor of JCISE, we have begun the process of gradually migrating from eLane to ASME’s Journal Tool. Although the Journal Tool still lacks some functionality available in eLane, the reasons for migration are that this will provide greater visibility to JCISE through ASME websites, set JCISE at par with other Transactions, make it easier to transfer papers between ASME journals and, most importantly, have 24/7 support from ASME’s IT professionals.My tenure as chief editor is ending as it started, with a special issue providing snapshots of each of the technology areas within our scope. In both cases, I put together a wish list of papers and expert groups to co-author the state of art reviews. I had hoped to have every area covered, but some papers did not materialize this time around. Nevertheless, this special issue will be a good reference for most, if not all of the areas JCISE covers. For V1 N1, I invited each of our founding Associate Editors to write state-of-the-art surveys of their fields in collaboration with other experts in their respective areas. This special issue contains survey papers not only in some well-established CIE areas but also in a few emerging fields.Computational methods and information technologies related to engineering product development have come a long way. CAD, CAM, FEA, CFD, VR, Reverse Engineering, Computational Metrology, Optimization, and many other simulation techniques are now pervasive in industry. Even traditional fields, such as thermal science, fluid mechanics, and solid mechanics, have embraced numerical methods and computer visualization. What started on the fringes is now the mainstream. We owe it to the founders of the CED/CIE Division who saw this potential more than 30 years ago. Let us recognize Ali Seireg (Wisconsin), J. Callahan (McDonnell Douglas), V. Tipnis, T. Shoup (Santa Clara), D. Dietrich (Swanson), L. Hulbert (Battelle), E. Heer (NASA), S. Rhode (GM), R. Fulton (Georgia Tech), J.Cokonis (GE), R. Arvikar (Bell Labs), J. Lemon (SDRC), D. Riley (U. Minnesota), and R. Raghavan (Foster Wheeler).A high quality archival journal is extremely important to any research community. A conference alone cannot be sufficient. Conferences, at least in engineering, serve the purpose of quick dissemination of work in progress. Having an archival journal aids the maturation of a research community. Not all conference papers are suitable for archival in a journal. An additional complication in computing and IT is the rapid rate of development and consequent obsolescence of ideas and methods. What then should we archive? There certainly are many techniques in our field that have withstood the test of time. B-Rep solid models, B-splines, and NURBS, regularized Boolean algorithms, Attributed Adjacency Graph based feature recognition, and bipartite graphs for constraint solving are but a few examples. But most research is incremental, and it is important to archive snapshots of major milestones in each area. NURBS did not just come about suddenly. There were B-splines, rational B-splines before the idea of nonuniform knot spacing.JCISE associate editors serve 3 year terms, renewable for an additional 3. In addition to the founding group of AEs, I want to take this opportunity to thank all our current and past AEs. They are the ones that do the bulk of the work and get the credit for maintaining our high quality. I am very grateful to the following individuals: J. Michopoulos, K. Saitou, A. Goel, I. Grosse, K. Law, X. Qian, J. Oliver, S. McMains, S. Gao, A. Fischer, J. Vandenbrande, C. Geiger, Y. Kitamura, C. McMahon, A. Joneja, S. K. Gupta, R. Crawford, K. Lee, J. Corney, N. Dorighi, L. Joskowicz, and S. Callahan.I am sure that our new chief editor, Bahram Ravani, will take JCISE to new heights. My very best wishes to JCISE readers, authors, and reviewers. For me, this has been a labor of love.
ER  -
