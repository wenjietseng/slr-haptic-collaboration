"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Exploring Remote Collaborative Tasks: The Impact of Avatar Representation on Dyadic Haptic Interactions in Shared Virtual Environments","G. Sasaki; H. Igarashi","Department of Electrical and Electronic System Engineering, Graduate School of Advanced Science and Technology, Tokyo Denki University, Tokyo, Japan; Department of Electrical and Electronic System Engineering, Tokyo Denki University, Tokyo, Japan",IEEE Transactions on Visualization and Computer Graphics,"4 Sep 2025","2025","31","10","8846","8858","This study is the first to explore the interplay between haptic interaction and avatar representation in Shared Virtual Environments (SVEs). Specifically, how these factors shape users’ sense of social presence during dyadic collaborations, while assessing potential effects on task performance. In a series of experiments, participants performed the collaborative task with haptic interaction under four avatar representation conditions: avatars of both participant and partner were displayed, only the participant’s avatar was displayed, only the partner’s avatar was displayed, and no avatars were displayed. The study finds that avatar representation, especially of the partner, significantly enhances the perception of social presence, which haptic interaction alone does not fully achieve. However, neither the presence nor the type of avatar representation impacts the task performance or participants’ force effort of the task, suggesting that haptic interaction provides sufficient interaction cues for the execution of the task. These results underscore the significance of integrating both visual and haptic modalities to optimize remote collaboration experiences in virtual environments, ensuring effective communication and a strong sense of social presence.","1941-0506","","10.1109/TVCG.2025.3580546","Research Institute for Science and Technology, Tokyo Denki University(grant numbers:Q23D-07,Q24D-01); Japan and JSPS KAKENHI(grant numbers:22H01455); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039141","HCI;avatar representation;haptic interaction;haptic communication;remote collaboration;virtual human;social interaction;collaborative virtual environments;shared virtual environments","Avatars;Haptic interfaces;Collaboration;Visualization;Virtual environments;User experience;Force;Communication channels;Psychology;Tracking","Humans;Male;Female;Virtual Reality;Young Adult;Computer Graphics;User-Computer Interface;Adult;Cooperative Behavior;Task Performance and Analysis;Interpersonal Relations;Touch;Avatar","","","72","CCBY","17 Jun 2025","","","IEEE","IEEE Journals"
"Decentralized H2 optimal control of haptic interfaces for a shared virtual environment","M. Kristalny; J. H. Cho","Faculty of Mechanical Engineering, Technion-IIT, Haifa, Israel; Automatic Control LTH, Lund University, Lund, Sweden",52nd IEEE Conference on Decision and Control,"10 Mar 2014","2013","","","5204","5209","Decentralized control of haptic interface devices for a shared virtual environment over delayed communication is considered. We show that allowing indirect communication between the interface devices via the virtual environment site may greatly facilitate controller synthesis and analysis by rendering the problem quadratically invariant. In particular, this allows us to find an insightful structure possessed by all stabilizing controllers within the proposed architecture and to show that this structure offers stability of the system regardless the delay length. We show also that within the proposed control architecture, the global H2 optimization can be reduced to a number of uncoupled model matching problems with multiplicative delays.","0191-2216","978-1-4673-5717-3","10.1109/CDC.2013.6760707","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6760707","","Virtual environments;Delays;Haptic interfaces;Optimization;Stability analysis;Dynamics;Numerical stability","","2","","25","IEEE","10 Mar 2014","","","IEEE","IEEE Conferences"
"Toward Volume-Based Haptic Collaborative Virtual Environment with Realistic Sensation","T. Tanaka; S. Yamaguchi; L. Jooho; N. Shimada; H. T. Tanaka","Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan; Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan; Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan; Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan; Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan",2008 Second International Symposium on Universal Communication,"22 Dec 2008","2008","","","268","273","In this paper, we propose a volume-based realistic communication system called Haptic Communication that allows participants to interact in real-time with others at remote locations on the network in haptic perception (sense of touch) of soft objects in virtual environments. To provide sense of touch at remote locations in real-time we construct the system as follows. At first virtual soft objects are represented by adaptive volume model in the PCs at the remote locations. Next, from the parameters of positions and forces at contacting points transmitted via network, at each PC the reflection force of the soft object is calculated rapidly and accurately. Eventually, as a result the haptic and visual information are rendered by means of a haptic device PHANToM and a volume graphic software at the PCs. We investigated the efficiency of our system via experiments on a simulation of needle insertion with high force feedback rates at remote locations on a WAN between Ritsumeikan University, Biwako Kusatsu Campus and Osaka University, Toyonaka Campus. The experiment results show that the delay due to network traffic is negligible.","","978-0-7695-3433-6","10.1109/ISUC.2008.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4724472","Realistic-Communication;Telexistence;Haptics;Volume Model;Adaptive-Grid","Haptic interfaces;Collaboration;Virtual environment;Real time systems;Personal communication networks;Reflection;Rendering (computer graphics);Imaging phantoms;Graphics;Needles","","","","13","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"Tandem Canoeing over the Internet using Haptic Feedback","J. Tang; C. Carignan; P. Olsson","Imaging Science and Information Systems Center, George town University, Washington D.C., DC, USA; Imaging Science and Information Systems Center, George town University, Washington D.C., DC, USA; Department of Electrical Engineering, Royal Institute of Technology, Stockholm, Sweden",2006 14th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems,"8 May 2006","2006","","","281","285","A cooperative tandem canoeing task with haptic feedback is developed for internet application. A pair of InMotion2 robots provide stroke commands to the boat and force feedback to the operators while a flat screen panel displays the virtual environment to the participants. OpenInventor is used to generate the graphical environment while a realistic dynamics engine runs concurrently on an RT Linux box. Experimental results are presented for racing a straightline canoe course, and future work involving new input devices and virtual environments are discussed.","2324-7355","1-4244-0226-3","10.1109/HAPTIC.2006.1627130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1627130","cooperative manipulation;haptic feedback;time delay","Internet;Haptic interfaces;Virtual environment;Graphics;Force feedback;Robots;Robotic assembly;Linux;Virtual reality;Intersymbol interference","","","","15","IEEE","8 May 2006","","","IEEE","IEEE Conferences"
"Influences of haptic communication on a shared manual task","A. Chellali; C. Dumas; I. Milleville-Pennel",NA; NA; NA,Interacting with Computers,"18 Jan 2018","2011","23","4","317","328","With the advent of new haptic feedback devices, researchers are giving serious consideration to the incorporation of haptic communication in collaborative virtual environments. For instance, haptic interactions based tools can be used for medical and related education whereby students can train in minimal invasive surgery using virtual reality before approaching human subjects. To design virtual environments that support haptic communication, a deeper understanding of humans′ haptic interactions is required. In this paper, human′s haptic collaboration is investigated. A collaborative virtual environment was designed to support performing a shared manual task. To evaluate this system, 60 medical students participated to an experimental study. Participants were asked to perform in dyads a needle insertion task after a training period. Results show that compared to conventional training methods, a visual-haptic training improves user′s collaborative performance. In addition, we found that haptic interaction influences the partners′ verbal communication when sharing haptic information. This indicates that the haptic communication training changes the nature of the users′ mental representations. Finally, we found that haptic interactions increased the sense of copresence in the virtual environment: haptic communication facilitates users′ collaboration in a shared manual task within a shared virtual environment. Design implications for including haptic communication in virtual environments are outlined.","1873-7951","","10.1016/j.intcom.2011.05.002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8147065","Haptic communication;Common ground;Collaborative virtual environments;User-centred design;HCI","","","6","","","","18 Jan 2018","","","OUP","OUP Journals"
"The use of a proximity agent in a collaborative virtual environment with 6 degrees-of-freedom voxel-based haptic rendering","A. Prior; K. Haines","School of Computer Science and Software Engineering, University of Western Australia, Australia; School of Computer Science and Software Engineering, University of Western Australia, Australia",First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. World Haptics Conference,"4 Apr 2005","2005","","","631","632","The extension of software designed primarily for a single-user haptic environment to a multi-user collaborative environment presents challenges on several fronts. This paper discusses the use of a proximity agent to overcome problems associated with the time allowances for collision detection and subsequent force/torque generation between pairs of dynamic objects in a voxel-based collaborative haptic environment.","","0-7695-2310-2","10.1109/WHC.2005.137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1407035","","Collaboration;Virtual environment;Haptic interfaces;Object detection;Testing;Torque;Collaborative software;Computer science;Software engineering;Software design","","3","","2","IEEE","4 Apr 2005","","","IEEE","IEEE Conferences"
"An efficient hybrid multicast transport protocol for collaborative virtual environment with networked haptic","A. Boukerche; H. Maamar","PARADISE Research Laboratory, SITE, University of Ottawa, Canada; PARADISE Research Laboratory, SITE, University of Ottawa, Canada",2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006),"15 Jan 2007","2006","","","78","83","In recent years, we have witnessed a growing interest in synchronous collaboration based class of applications. Several techniques for collaborative virtual environments CVE, haptic, audio and visual environments C-HAVE were designed. However several challenging issues remain to be resolved before CVE and C-HAVE become a common place. In this paper, we focus upon applications that are based on closely coupled and highly synchronized haptic tasks that require a high- level of coordination among the participants. Four main protocols were designed to resolve the synchronization issues in such environments: the synchronous collaboration transport protocol (SCTP), the selective reliable transmission protocol (SRTP), the reliable multicast transport protocol (RMTP) and the scalable reliable multicast (SRM). While these four protocols have shown good performance for CVE and C-HAVE class of applications, none of these protocols was able to meet all the of the basic CVE requirement i.e., scalability, reliability, synchronization and minimum delays. In this paper, we present a hybrid protocol that is able to satisfy all the CVE and C-HAVE requirements and discuss its implementation","","1-4244-0760-5","10.1109/HAVE.2006.283778","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4062554","","Multicast protocols;Transport protocols;Collaboration;Virtual environment;Haptic interfaces;Decision support systems;Virtual reality","","1","","20","IEEE","15 Jan 2007","","","IEEE","IEEE Conferences"
"Haptic Designation Tool to Improve Working Strategy in Collaborative Virtual Environment","A. Girard; M. Ammi","INRIA, Rennes; Univ. Paris Sud/LIMSI-CNRS","2015 IEEE International Conference on Systems, Man, and Cybernetics","14 Jan 2016","2015","","","1321","1328","Coordinating team's work in a 3D Collaborative Virtual Environments is a real challenge. The communication constraints in such environments reduces the understanding between the partner's and thus complicates the team's coordintation. In order to facilitate the coordination, this paper proposes a hap tic tool for the designation of targets. This tool was experimented in a context of collaborative molecular design where one user designates tasks and coordinates the actions of two operators. The experimental results show an improvement of the working efficiency of the group and a better sharing of the activity between partners. Moreover, we observe that the hap tic guidance enables an accurate selection of targets which leads to an improvement of performance during the deformation process.","","978-1-4799-8697-2","10.1109/SMC.2015.235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379367","Collaborative Virtual Environment;Haptic communication;Collaborative tools;Molecular modeling;team working","Haptic interfaces;Collaboration;Three-dimensional displays;Virtual environments;Computers;Force;Software","","","","17","IEEE","14 Jan 2016","","","IEEE","IEEE Conferences"
"Passive shared virtual environment for distributed haptic cooperation","R. Rakhsha; D. Constantinescu","Mechanical Engineering Department, University of Victoria, BC, Canada; Mechanical Engineering Department, University of Victoria, BC, Canada",2014 IEEE Haptics Symposium (HAPTICS),"20 Mar 2014","2014","","","221","226","For distributed haptic cooperation systems, this paper develops a framework for virtual environments such that the design of the coordinating controllers is decoupled from the network topology and the communication issues. The discrete-time n-port passivity of the shared virtual object (SVO) is presented when n SVO copies are distributed on an undirected and connected communication topology with unreliable data transmission. Wave nodes as passive network elements can be implemented on multilateral wave-based communication architecture to passively distribute power across the network. In this note, the wave node scheme introduced in [16] is employed to construct a passive wave-based network architecture in order to passively interconnect multiple discrete-time port-Hamiltonian local SVO copies alongside their coordinating controllers. The performance analysis shows that the proposed network architecture: (i) possesses n-port passivity over a network with time-varying delay and packet-loss; (ii) is lossless when subjected to communications with no time delay; and (iii) offers less dissipation comparing to the network structures built based on the node scheme proposed in [18]. Simulations in which a VO is shared among four peers across a network with constant and varying time-delay validate the analysis.","2324-7355","978-1-4799-3131-6","10.1109/HAPTICS.2014.6775458","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6775458","Haptic cooperation;Port-Hamiltonian systems;Passive shared virtual object;Wave-based communication","Peer-to-peer computing;Delays;Haptic interfaces;Ports (Computers);PD control;Communication channels;Communication networks","","5","","29","IEEE","20 Mar 2014","","","IEEE","IEEE Conferences"
"A Peer-to-Peer Collaborative Virtual Environment for E-Commerce","M. Khoury; X. Shen; S. Shirmohammadi","Distributed Collaborative Virtual Environment Research Laboratory (DISCOVER), School of Information Technology and Engineering (SITE), University of Ottawa, Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory (DISCOVER), School of Information Technology and Engineering (SITE), University of Ottawa, Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory (DISCOVER), School of Information Technology and Engineering (SITE), University of Ottawa, Ottawa, Canada",2007 Canadian Conference on Electrical and Computer Engineering,"30 Jul 2007","2007","","","828","831","The current e-commerce systems consist of a catalogue which online customers browse through, trying to emulate the real-life shopping experience. These customers, most of the times, are exposed to the product specifications in addition to some pictures and sometimes, animations. They do not undergo the same experience they would in reality: people often shop in groups and share opinions among each other and with product experts about items they browse before committing to purchase. All the pre-purchase experience is heavily undermined in the current electronic shopping emulation, potentially leading to reduced purchasing. However, this experience can be enhanced through Collaborative Virtual Environments (CVE). In this paper, we present a web-based e-commerce system where customers can collaboratively experience shopping with their online friends in real-time, and share the interaction with three dimensional virtual models of the items they are considering to buy available in the virtual shop. The system considers accessibility, a concern for any e-commerce application trying to attract as many customers as possible, and hence uses Macromedia Shockwave at the client side: a widely deployed free player. This differentiates our system from similar VR-based e-commerce systems that require VRML plug-ins or other nonstandard software at the client side. Another characteristic of the proposed system is its unique approach to supporting scalability. Realizing that collaborative shopping might lead to an increase in the number of shoppers browsing products simultaneously, scalability is an inevitable issue to deal with. We propose a peer-to-peer (P2P) architecture, where all peers provide resources and contribute in handling the scalability problem. The paper therefore focuses on two aspects: collaborative virtual environments in an e-commerce environment, and the application of peer-to-peer networking to such systems. Proof of concept and performance evaluations are also presented.","0840-7789","1-4244-1020-7","10.1109/CCECE.2007.212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4232871","","Peer to peer computing;Virtual environment;Scalability;Internet;Online Communities/Technical Collaboration;Business;Emulation;Social factors;Marketing and sales;Information technology","","3","","13","IEEE","30 Jul 2007","","","IEEE","IEEE Conferences"
"Cooperative control with haptic visualization in shared virtual environments","I. Goncharenko; M. Svinin; S. Matsumoto; Y. Masui; Y. Kanou; S. Hosoe","3D, Inc., Yokohama, Kanagawa, Japan; Bio-Mimetic Control Research Center, Nagoya, Japan; 3D, Inc., Yokohama, Kanagawa, Japan; Department of Electronic-Mechanical Engineering, Faculty of Engineering, University of Nagoya, Japan; 3D, Inc., Yokohama, Kanagawa, Japan; Bio-Mimetic Control Research Center, Nagoya, Japan","Proceedings. Eighth International Conference on Information Visualisation, 2004. IV 2004.","9 Aug 2004","2004","","","533","538","A distributed PHANToM-based system for collaborative haptic visualization of a VR crank is presented. Physical IDOF crank model providing realistic kinaesthetic sensations of inertia and viscosity is described. Theoretical and experimental kinematic trajectory patterns are compared for the case of cooperative two-arm human movements. Nonvisual visualization applications of the system are discussed.","1093-9547","0-7695-2177-0","10.1109/IV.2004.1320196","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1320196","","Haptic interfaces;Visualization;Virtual reality;Communication system control;Collaboration;Viscosity;Humans;Computer displays;Virtual environment;Imaging phantoms","","12","","13","IEEE","9 Aug 2004","","","IEEE","IEEE Conferences"
"A Study of Communication Modalities in a Virtual Collaborative Task","J. Wang; A. Chellali; C. G. L. Cao","Department of Biomedical, Industrial, & Human Factors Engineering, Wright State University, Dayton, OH, USA; Department of Surgery, Cambridge Health Alliance, Cambridge, MA, USA; Department of Biomedical, Industrial, & Human Factors Engineering, Wright State University, Dayton, OH, USA","2013 IEEE International Conference on Systems, Man, and Cybernetics","27 Jan 2014","2013","","","542","546","This paper examined the relative effectiveness of three communication modalities in a collaborative virtual environment. Communication modalities of verbal only (V), haptic only (H), and both (HV), were used in a 2D pointing task. A total of 36 participants were paired into 18 dyads. In each dyad, there was a supervisor and an acting agent. The supervisor used one of the three modalities to guide the acting agent to reach the target location. The time to task completion and the trajectory were recorded and analyzed. The results indicate that subjects using verbal only and haptic+verbal communication performed equally well in the collaborative pointing task. Subjects using haptic only communication spent more time and had longer path lengths than verbal only and haptic+verbal communication. Nevertheless, all three modalities were effective in communicating in a virtual collaborative task.","1062-922X","978-1-4799-0652-9","10.1109/SMC.2013.98","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6721851","haptic communication;communication modality;collaborative virtual environment;pointing task;human computer interaction","Haptic interfaces;Collaboration;Virtual environments;Monitoring;Mice;Human factors;Trajectory","","6","","10","IEEE","27 Jan 2014","","","IEEE","IEEE Conferences"
"fARFEEL: Providing Haptic Sensation of Touched Objects Using Visuo-Haptic Feedback","N. Tanabe; Y. Sato; K. Morita; M. Inagaki; Y. Fujino; P. Punpongsanon; H. Matsukura; D. Iwai; K. Sato","Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University; Graduate School of Engineering Science, Osaka University",2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),"15 Aug 2019","2019","","","1355","1356","We present fARFEEL, a remote communication system that provides visuo-haptic feedback allows a local user to feel touching distant objects. The system allows the local and remote users to communicate by using the projected virtual hand (VH) for the agency of his/her own hands. The necessary haptic information is provided to the non-manipulating hand of the local user that does not bother the manipulation of the projected VH. We also introduce the possible visual stimulus that could potentially provide the sense of the body ownership over the projected VH.","2642-5254","978-1-7281-1377-7","10.1109/VR.2019.8798195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798195","Virtual hand illusion;Spatial augmented reality;Visuo-haptic;Haptic feedback;Extended body interface","Haptic interfaces;Cameras;Visualization;Three-dimensional displays;Shape;Conferences;Strain","","8","","5","IEEE","15 Aug 2019","","","IEEE","IEEE Conferences"
"Design and assessment of haptic interfaces: An essay on proactive haptic articulation","V. A. de Jesus Oliveira","Universidade Federal do Rio Grande do Sul, Porto Alegre, RS, BR",2017 IEEE Virtual Reality (VR),"6 Apr 2017","2017","","","409","410","We looked up to elements present in speech articulation to introduce the proactive haptic articulation as a novel approach for intercommunication. The ability to use a haptic interface as a tool for implicit communication can supplement communication and support near and remote collaborative tasks in virtual and physical environments. In addition, the proactive articulation can be applied during the design process, including the user in the construction of more dynamic and optimized vibrotactile vocabularies. In this proposal, we discuss the thesis of the haptic proactive communication and our method to assess and implement it. Our goal is to understand the phenomena related to the proactive articulation of haptic signals and its use for communication and for the design of optimized tactile vocabularies.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892350","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892350","H.5.1 [Human computer interaction (HCI)]: Interaction devices — Haptic devices","Haptic interfaces;Vocabulary;Context;Collaboration;Three-dimensional displays;Speech;Proposals","","","","13","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"Multiple-contact representation for the real-time volume haptic rendering of a non-rigid object","Sang-Youn Kim; Jinah Park; Dong-Soo Kwon","Telerobotics & Control Laboratory, Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Computer Graphics & Visualization Laboratory, School of Engineering, ICU, South Korea; Telerobotics & Control Laboratory, Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, South Korea","12th International Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2004. HAPTICS '04. Proceedings.","19 Apr 2004","2004","","","242","249","This paper presents a fast haptic rendering method providing the sense of touch from a virtual volumetric non-rigid object when a human operator interacts with the object at multiple points. Previously, we have proposed a fast volume haptic rendering method based on the shape-retaining chain linked model (or the S-chain model) that can handle the deformation of a volumetric non-rigid object and its haptic feedback in real time. One of the key differences between the S-chain model and a traditional FEM or mass-spring model is that the computation of the deformation and its reflected force is performed at a local level. When there are more than one interaction points with the object, it is necessary to consider a modeling framework that can handle human operator's all inputs together. In this paper, we propose a modeling framework in which forces generated at interaction points are vectorially summed to deal with the multiple contact points. Our experiments demonstrate that our proposed method is suitable for the real-time volume haptic rendering of a volumetric non-rigid object with multiple-contact points.","","0-7695-2112-6","10.1109/HAPTIC.2004.1287202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1287202","","Haptic interfaces;Humans;Rendering (computer graphics);Computational modeling;Deformable models;Minimally invasive surgery;Laboratories;Feedback;Telerobotics;Mechanical engineering","","","","15","IEEE","19 Apr 2004","","","IEEE","IEEE Conferences"
"A distributed latency-aware architecture for massively multi-user virtual environments","B. Hariri; S. Ratti; S. Shirmohammadi; M. R. Pakravan","Distributed Collaborative Virtual Environment Research Laboratory, University of Ottawa, Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory, University of Ottawa, Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory, University of Ottawa, Ottawa, Canada; Department of Electrical Engineering, Sharif University of Technology, Tehran, Iran",2008 IEEE International Workshop on Haptic Audio visual Environments and Games,"21 Nov 2008","2008","","","53","58","Massively multi-user virtual environments (MMVE) incorporate computer graphics, sound and haptics to simulate the experience of real-time interaction among multiple users in a shared three-dimensional virtual world. Such applications therefore deal with the distribution of updates among their users to provide them with a common sense of time and place while interacting in the virtual environment. This paper introduces a new distributed architecture for message exchange in MMVE applications. We propose the use of Hilbert space filling curve, due to its good locality preserving characteristics, as a mechanism for indexing users' three dimensional locations to a one dimension. We also propose our novel routing strategy based on this architecture, which is executed among the points that are mapped over the Hilbert curve. Such hierarchical routing requires only few entries in the routing tables while it is guaranteed to converge in few steps. The routing procedure is based on guiding the packets to their destinations through traversing the Hilbert curve in tree format. A three dimensional Hilbert curve of order K can be described with a tree of K levels. In making a forwarding decision, a node finds the best neighbour that moves the message closer to its destination over this tree. This avoids the complexity of locating the points over the Hilbert curve as the mapping is actually performed throughout the routing process. The performance evaluation results show that the propose architecture can efficiently handle update exchange among MMVE users.","","978-1-4244-2668-3","10.1109/HAVE.2008.4685298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4685298","Massively multi-user Virtual environment;Hilbert curve;Multi-dimensional indexing;Latency-aware routing","Virtual environment;Routing;Computer architecture;Computer graphics;Haptic interfaces;Computational modeling;Computer simulation;Application software;Hilbert space;Filling","","1","","9","IEEE","21 Nov 2008","","","IEEE","IEEE Conferences"
"Performance and co-presence in heterogeneous haptic collaboration","M. McLaughlin; G. Sukhatme; Wei Peng; Weirong Zhu; J. Parks","Integrated Media Systems Center, University of Southern California, USA; Integrated Media Systems Center, University of Southern California, USA; Integrated Media Systems Center, University of Southern California, USA; Integrated Media Systems Center, University of Southern California, USA; Integrated Media Systems Center, University of Southern California, USA","11th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2003. HAPTICS 2003. Proceedings.","2 Apr 2003","2003","","","285","291","Based on a distributed architecture for real-time collection and broadcast of haptic information to multiple participants, heterogeneous haptic devices (the PHANToM and the CyberGrasp) were used in an experiment to test the performance accuracy and sense of presence of participants engaged in a task involving mutual touch. In the experiment, the hands of CyberGrasp users were modeled for the computer to which the PHANToM was connected PHANToM users were requested to touch the virtual hands of CyberGrasp users to transmit randomly ordered letters of the alphabet using a pre-set coding system. Performance accuracy achieved by a small sample of participants was less than optimal in the strict sense: accurate detection of intended location and frequency of touch combined ranged from .27 to .42. However, participants accurately defected the intended location of touch in 92% of the cases. Accuracy may be positively related to pairwise sense of co-presence and negatively related to mean force, force variability, and task completion time.","","0-7695-1890-7","10.1109/HAPTIC.2003.1191297","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191297","","Haptic interfaces;Collaboration;Imaging phantoms;Fingers;Collaborative work;Wrist;Image segmentation;Delay;Jacobian matrices;Nonhomogeneous media","","11","","15","IEEE","2 Apr 2003","","","IEEE","IEEE Conferences"
"A 3D Annotation Interface Using the DIVINE Visual Display","K. Osman; F. Malric; S. Shirmohammadi","Distributed Collaborative Virtual Environment Research Laboratory (DISCOVER Lab), School of Information Technology and Engineering, University of Ottawa, Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory (DISCOVER Lab), School of Information Technology and Engineering, University of Ottawa, Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory (DISCOVER Lab), School of Information Technology and Engineering, University of Ottawa, Ottawa, Canada",2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006),"15 Jan 2007","2006","","","5","9","While systems such as CAVEs have been experimented with and used for a number of years, their deployment has been slow mainly due to their expense and space requirements. As such, researchers have been moving towards smaller and cheaper immersive systems. In this paper, we introduce an immersive interface for manipulating 3D objects using the DIVINE system","","1-4244-0760-5","10.1109/HAVE.2006.283798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4062539","","Three dimensional displays;Computer displays;Space technology;Computer graphics;Rendering (computer graphics);Application software;Virtual environment;Humans;Computer interfaces;Hardware","","2","","10","IEEE","15 Jan 2007","","","IEEE","IEEE Conferences"
"An immersive collaborative virtual environment of a university campus for performing virtual campus evacuation drills and tours for campus safety","S. Sharma; S. P. Rajeev; P. Devearux","Department of Computer Science, Bowie State University, Bowie, MD, USA; Department of Computer Science, Bowie State University, Bowie, MD, USA; Department of Computer Science, Bowie State University, Bowie, MD, USA",2015 International Conference on Collaboration Technologies and Systems (CTS),"20 Aug 2015","2015","","","84","89","The use of a collaborative virtual reality environment for training and virtual tours has been increasingly recognized an as alternative to traditional reallife tours for university campuses. Our proposed application shows an immersive collaborative virtual reality environment for performing virtual online campus tours and evacuation drills using Oculus Rift head mounted displays. The immersive collaborative virtual reality environment also offers a unique way for training in emergencies for campus safety. The participant can enter the collaborative virtual reality environment setup on the cloud and participate in the evacuation drill or a tour which leads to considerable cost advantages over large scale real life exercises. This paper presents an experimental design approach to gather data on human behavior and emergency response in a university campus environment among a set of players in an immersive virtual reality environment. We present three ways for controlling crowd behavior: by defining rules for computer simulated agents, by providing controls to the users to navigate in the VR environment as autonomous agents, and by providing controls to the users with a keyboard/ joystick along with an immersive VR head set in real time. Our contribution lies in our approach to combine these three methods of behavior in order to perform virtual evacuation drills and virtual tours in a multi-user virtual reality environment for a university campus. Results from this study can be used to measure the effectiveness of current safety, security, and evacuation procedure for campus safety.","","978-1-4673-7648-8","10.1109/CTS.2015.7210404","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7210404","virtual reality;behavior simulation;evacuation;collaborative virtual environment","Solid modeling;Computational modeling;Virtual reality;Computers;Three-dimensional displays;Buildings;Servers","","13","","24","IEEE","20 Aug 2015","","","IEEE","IEEE Conferences"
"Experimental Internet Haptic Collaboration using Virtual Coupling Schemes","G. Sankaranarayanan; B. Hannaford","Department of Electrical Engineering, University of Washington, Seattle, WA, USA; Department of Electrical Engineering, University of Washington, Seattle, WA, USA",2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems,"31 Mar 2008","2008","","","259","266","In this paper we present the results from several global-scale haptic collaboration experiments that were performed using the Internet. These experiments consist of three virtual coupling schemes proposed to maintain position coherency in a networked haptic virtual environment (NHVE). We compared two of our virtual coupling schemes—which represent a peer-to-peer architecture—to the third—with a client-server architecture. We set up a packet reflector network at our collaborator servers (Italy, Canada and North Carolina, USA) to perform the experiments with subjects located within the same laboratory. Our largest one-way latency was in the order of 200 ms for the packet reflector situated in Italy. The virtual coupling parameters were chosen so that it resulted in stable operation for all the delay values that were tested. User datagram protocol (UDP) was used for haptic data communication because of the high transmission rate requirement for NHVEs. There were three experiments carried out in total: two of them at the packet transmission rate of 1000 Hz with a change in the virtual coupling parameters in scheme 2, and the third one, which tested the three virtual coupling schemes at two fixed transmission rates of 500 Hz and 100 Hz. Locally, the haptic update rate was maintained at 1000 Hz during all the experiments. Our results demonstrate that the peer-to-peer virtual coupling schemes can be used for maintaining position coherency in a NHVE. We also show that the position error and the force rendered to the users increase with the reduction in the packet transmission rate. Given that these experiments were performed through the actual Internet, this work proves valuable for global-scale stable haptic collaboration using the Internet.","2324-7355","978-1-4244-2005-6","10.1109/HAPTICS.2008.4479954","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4479954","Haptic Virtual Environments;Collaborative Haptic Virtual Environments;Networked Haptic Virtual Environments;Collaborative Haptics;Multi-user Haptics;Networked Applications;Multi-rate Haptics;Human Factors;H.5.2 [Information Interfaces and Presentation]: User Interfaces-Haptic I/O;I.3.2 [Computer Graphics]: Graphics Systems-Distributed/network graphics","Internet;Haptic interfaces;Collaboration;Couplings;Peer to peer computing;Delay;Testing;Virtual environment;Network servers;Laboratories","","27","","23","IEEE","31 Mar 2008","","","IEEE","IEEE Conferences"
"A Survey on Haptics: Communication, Sensing and Feedback","M. Emami; A. Bayat; R. Tafazolli; A. Quddus","Institute for Communication Systems, Home of 5G & 6G Innovation Centres, University of Surrey, Guildford, U.K.; Institute for Communication Systems, Home of 5G & 6G Innovation Centres, University of Surrey, Guildford, U.K.; Institute for Communication Systems, Home of 5G & 6G Innovation Centres, University of Surrey, Guildford, U.K.; Institute for Communication Systems, Home of 5G & 6G Innovation Centres, University of Surrey, Guildford, U.K.",IEEE Communications Surveys & Tutorials,"12 Jun 2025","2025","27","3","2006","2050","Haptic communications represent a vast area of research focused on integrating the sense of touch into digital sensory experiences. Achieving effective haptic communication requires meticulous design and implementation of all subsystems. As implied by the term, the two primary subsystems are haptic and communication. Haptic refers to replicating the touch sensation in various applications such as augmented reality, virtual reality and teleoperation, and communication involves optimising network structures to transmit and receive haptic information alongside other sensory data. In this survey paper, we discuss both haptic interfaces and network requirements simultaneously. For haptic interfaces, we comprehensively explore the mechanisms of touch perception, haptic sensing, and haptic feedback. We delve into haptic sensing by examining state-of-the-art sensors and approaches to capture data related to touch, such as pressure, force, and motion, and translate these physical interactions into digital data that a haptic system can interpret and respond to. Subsequently, we discuss various methods of achieving haptic feedback, including different mechanical actuators and electrical stimulation. We also investigate the incorporation of artificial intelligence in this field, proposing new areas where it could enhance system performance. Additionally, we address open challenges and future research directions, covering critical issues related to privacy, data transmission, cybersickness, performance and wearability of haptic interface, integrated systems, power supply and evaluation of these devices. Through this interdisciplinary approach, which merges haptic feedback, haptic sensing, and communication, our paper aims to inspire further research and development, ultimately advancing technology and enhancing haptic experiences.","1553-877X","","10.1109/COMST.2024.3444051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10637258","Haptic communications;haptic interfaces;haptic feedback;haptic sensing;artificial intelligence;human-computer interaction;tactile displays;virtual reality;teleoperation;tactile Internet;Internet of senses","Haptic interfaces;Surveys;Sensors;Wearable devices;Visualization;Reviews;Temperature sensors","","25","","282","CCBY","14 Aug 2024","","","IEEE","IEEE Journals"
"Leveraging motion estimation for data reduction in 3D tele-immersive systems","C. W. Leong; B. Hariri; S. Shirmohammadi; N. D. Georganas","Distributed Collaborative Virtual Environment Research Laboratory, University of Ottawa, Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory, University of Ottawa, Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory, University of Ottawa, Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory, University of Ottawa, Ottawa, Canada",2010 IEEE International Symposium on Haptic Audio Visual Environments and Games,"9 Nov 2010","2010","","","1","6","A 3D tele-immersive system makes use of various technologies including imaging, multimedia, networking and telecommunication. This article discusses the design issues that should be considered in the networking parts of such systems and provides effective solutions to reduce the required communication bandwidth of an interactive session. The proposed technique is based on the use of motion estimation in order to reduce the redundancy of the transmitted data thus saving communication bandwidth.","","978-1-4244-6509-5","10.1109/HAVE.2010.5623966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5623966","Virtual Reality;Teh-immersive systems;Teh-presence","Motion estimation;Cameras;Shape;Three dimensional displays;Kalman filters;Measurement uncertainty;Bandwidth","","","","22","IEEE","9 Nov 2010","","","IEEE","IEEE Conferences"
"Augmentation of check in/out model for remote collaboration with Mixed Reality","G. Kamei; T. Matsuyama; K. -i. Okada","Keio University, Japan; Keio University, Japan; Japan Science and Technology Agency, Keio University, Japan",2010 IEEE International Symposium on Mixed and Augmented Reality,"22 Nov 2010","2010","","","243","244","This paper proposes augmentation of check in/out model for remote collaboration with Mixed Reality (MR). We add a 3D shared and private space into the real workspace by MR technology, and augment the check in/out model to remote collaboration. By our proposal, user can intuitively receive remote partner's work via virtual objects in the shared space and stop sharing information about an object by just moving the object into the private space if the user doesn't want to share it. We implement a system which achieves our proposal and evaluate it.","","978-1-4244-9346-3","10.1109/ISMAR.2010.5643588","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5643588","Remote Collaboration;Mixed Reality;Check In/Out Model","Collaboration;Three dimensional displays;Space technology;Solid modeling;Virtual reality;Aerospace electronics;Brushes","","1","","5","IEEE","22 Nov 2010","","","IEEE","IEEE Conferences"
"Symmetric Model of Remote Collaborative MR Using Tangible Replicas","S. Yamamoto; H. Tamaki; Y. Okajima; K. Okada; Y. Bannai","Keio University, Japan; Keio University, Japan; Keio University, Japan; Canon, Inc., Japan; Keio University, Japan",2008 IEEE Virtual Reality Conference,"4 Apr 2008","2008","","","71","74","Research into collaborative mixed reality (MR) or augmented reality has recently been active. Previous studies showed that MR was preferred for collocated collaboration while immersive virtual reality was preferred for remote collaboration. The main reason for this preference is that the physical object in remote space cannot be handled directly. However, MR using tangible objects is still attractive for remote collaborative systems, because MR enables seamless interaction with real objects enhanced by virtual information with the sense of touch. Here we introduce ""tangible replicas""(dual objects that have the same shape, size, and surface), and propose a symmetrical model for remote collaborative MR. The result of experiments shows that pointing and drawing functions on the tangible replica work well despite limited shared information.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480753","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480753","Mixed Reality;remote collaboration;collaborative interaction;usability","Collaboration;Virtual reality;Collaborative work;Feedback;Virtual environment;Haptic interfaces;Biological system modeling;Environmental factors;Augmented reality;Displays","","5","","18","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"A haptic virtual environment for industrial training","M. Hosseini; F. Malric; N. D. Georganas","School of Information Technology and Engineering, University of Ottawa, Ottawa, Canada; School of Information Technology and Engineering, University of Ottawa, Ottawa, Canada; School of Information Technology and Engineering, University of Ottawa, Ottawa, Canada",IEEE International Workshop HAVE Haptic Virtual Environments and Their,"6 Jan 2003","2002","","","25","30","This paper presents a haptic virtual environment application for industrial training. A choice of haptic devices. (PHANTOM and CyberForce/CyberGrasp) is used to perform a training exercise with the possibility of sharing virtual scene states with remote users to allow collaboration and remote observation. Furthermore, the application employs video textured avatars to improve face-to-face communication, a novel area of interest management mechanism to reduce network bandwidth usage, standard encoding of state updates for compatibility and is used in conjunction with various projection technologies such as a head mounted display, CAVE configuration or regular PC monitor. The paper serves to underline the various components needed for the development of a haptic virtual environment and our experiences in doing so.","","0-7803-7635-8","10.1109/HAVE.2002.1106909","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106909","","Haptic interfaces;Virtual environment;Industrial training;Imaging phantoms;Management training;Layout;Collaboration;Video sharing;Avatars;Project management","","7","3","16","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"A prediction algorithm for haptic collaboration","A. Boukerche; S. Shirmohammadi; A. Hossain","PARADISE Research Laboratory, University of Ottawa, Canada, Ottawa, Canada; Distributed Collaborative Virtual Environments Research Laboratory School of Information Technology and Engineering, University of Ottawa, Canada, Ottawa, Canada; PARADISE Research Laboratory, University of Ottawa, Canada, Ottawa, Canada",IEEE International Workshop on Haptic Audio Visual Environments and their Applications,"12 Dec 2005","2005","","","5 pp.","","The incorporation of haptic interfaces into collaborative virtual environments suffers from setbacks due to some inherent technical problem when the users are geographically distributed. The main causes of such discrepancies are network delay, lack of view of individual participants' activities (awareness), and haptic feedback. Although some strategies exist for dealing with those concerns, they don't adequately address realism, causality, and the sense of co-presence in collaborative virtual environments during closely-coupled haptic tasks. We propose an approach based on prediction to compensate the limitations and to visualize the whole scenario for the users in order to help them cope with existing drawbacks intuitively. We introduce a predictor which can determine lost-update messages to improvise the current state, guess the current network delay, and anticipate remote user's interaction strategy and virtual object's position/orientation based on the history.","","0-7803-9376-7","10.1109/HAVE.2005.1545670","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1545670","","Prediction algorithms;Haptic interfaces;Jitter;Virtual environment;Online Communities/Technical Collaboration;Industrial training;Delay effects;Space shuttles;Information technology;Feedback","","4","","22","IEEE","12 Dec 2005","","","IEEE","IEEE Conferences"
"A novel haptic training method through skill decomposition","L. Liu; G. Liu; Y. Zhang","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Haidian District, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Haidian District, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Haidian District, Beijing, China",2013 World Haptics Conference (WHC),"7 Oct 2013","2013","","","621","625","Skill training with haptic guidance is more efficient than traditional ways which are visual and/or auditory guidance only. There have been several haptic training methods presented in previous studies. But how to exert effective guidance force is still a difficulty. This paper proposed a novel training method through skill decomposition. We decompose the task skill into several basic skill components. During training, the novices are controlling one component and are guided by expert in the other ones. Skill components are trained individually in this way. When a novice without cooperation with expert can finish the task very well just like the expert does, he/she acquires a skill component. We set up a 2-DOF control training experiment to compare the novel haptic training method with visual only training and traditional force guidance training. Skill for the training task is decomposed into controlling each DOF. The preliminary experimental result shows that the novices' short-term skill improvement using the novel haptic training method is better than that using the virtual fixture guidance training and visual training.","","978-1-4799-0088-6","10.1109/WHC.2013.6548480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6548480","Skill training;haptic guidance","Training;Haptic interfaces;Force;Visualization;Target tracking;Fixtures;Virtual environments","","1","","20","IEEE","7 Oct 2013","","","IEEE","IEEE Conferences"
"Enhancing Telecooperation Through Haptic Twin for Internet of Robotic Things: Implementation and Challenges","M. Huang; R. Feng; L. Zou; R. Li; J. Xie","School of Future Technology, South China University of Technology, Guangzhou, China; School of Future Technology, South China University of Technology, Guangzhou, China; Department of Broadband Communication, Pengcheng Laboratory, Shenzhen, China; Department of Broadband Communication, Pengcheng Laboratory, Shenzhen, China; School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China",IEEE Internet of Things Journal,"8 Oct 2024","2024","11","20","32440","32453","The Internet of Robotic Things (IoRT) serves as a bridge for the progress of upcoming immersive interaction technologies like XR, holographic communications, and the metaverse, enabling smooth interaction between the tangible and virtual domains. It enriches the capabilities of sensors and controllers in both domains, enabling precise mapping and control. Moreover, immersive interaction technologies enhance IoRT by offering superior visualization and user experiences. Here, we propose a haptic-twin-enhanced telecooperation system (HTTS) delving into tactile interaction technology for IoRT, unveiling a telecooperation-enhanced haptic twin technology. Our goal is to construct haptic gloves devices and its haptic twin entity that are centered on virtual collaborations (i.e., virtual handshakes and collaborative tasks), deploying an experimental system for the acquisition, processing, transmission, reconstruction and interaction of multisensory data over wireless networks. We simulate and demonstrate the perception of touch, friction, and virtual gravity using the proposed haptic twin-based experimental testbed. Compared to commercial product, namely, HTC Vive Controller, our approach achieves a more reliable and precise construction improvement of haptic twin entity that is based on our implemented haptic gloves in terms of simulated human hand posture, ensuring consistent haptic feedback in virtual control and collaboration. This offers a more user-friendly and immersive experience with adaptive haptic effects, paving the way for novel telecooperation applications in the future IoRT.","2327-4662","","10.1109/JIOT.2024.3424936","Major Key Project of PCL; Basic and Applied Basic Research Foundation of Guangdong Province(grant numbers:2022A1515220053); National Natural Science Foundation of China(grant numbers:62201244,52375493); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10589920","Haptic interface;haptic signal reconstruction;haptic twin;telecooperation;virtual collaboration","Haptic interfaces;Collaboration;Digital twins;Visualization;Real-time systems;Thumb;Testing","","4","","56","IEEE","9 Jul 2024","","","IEEE","IEEE Journals"
"Networked Haptic Cooperation Using Remote Dynamic Proxies","Z. Li; D. Constantinescu","Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada; Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada",2009 Second International Conferences on Advances in Computer-Human Interactions,"13 Feb 2009","2009","","","243","248","Networked haptic cooperation entails direct interaction among users as well as joint manipulation of virtual objects. To increase the realism of both types of interactions, this paper introduces remote dynamic proxies. Remote dynamic proxies are second order dynamic representations of users at the remote peer sites. They are generated according to dynamics laws and are controlled by the user whom they represent through a virtual coupler. Hence, they move in a physically intuitive manner and do not suffer from position discontinuities due to network packet transmission limitations. The remote dynamic proxies are integrated into a distributed control architecture for networked haptic cooperation. An experimental comparison of the new controller to two recently proposed controllers demonstrates smoother rendering of contact between users, as well as stable cooperation for larger network delays.","","978-1-4244-3351-3","10.1109/ACHI.2009.9","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4782521","networked haptic cooperation;haptic rendering;remote dynamic proxies","Haptic interfaces;Distributed control;Delay effects;Force control;Centralized control;Computer networks;Mechanical engineering;Surgery;Virtual environment;Stability","","8","","16","IEEE","13 Feb 2009","","","IEEE","IEEE Conferences"
"Virtual reality simulator for scoliosis surgery training: Transatlantic collaborative tests","M. Cote; J. -A. Boulay; B. Ozell; H. Labelle; C. -E. Aubin","Department of Computer Engineering, Ecole polytechnique, Montreal, QUE, Canada; Department of Computer Engineering, Ecole polytechnique, Montreal, QUE, Canada; Department of Computer Engineering, Ecole polytechnique, Montreal, QUE, Canada; Research Center, Sainte-Justine University Hospital Center, Montreal, QUE, Canada; Department of Computer Engineering, Ecole polytechnique, Montreal, QUE, Canada",2008 IEEE International Workshop on Haptic Audio visual Environments and Games,"21 Nov 2008","2008","","","1","6","Scoliosis is a complex deformation of the spine requiring, in severe cases, a highly delicate and invasive surgical instrumentation operation to correct the spinal deformities. Available traditional tools for surgical training have major drawbacks for which virtual reality (VR) technologies and computer simulation can offer solutions. In this paper, we introduce a surgical simulator integrating a complex patient-specific biomechanical model into a VR immersive environment in a collaborative context, the first of its kind for scoliosis surgery training. We present the results for the fully collaborative AVE (audio visual environment) aspects of the simulator. Haptic forces are computed in the biomechanical model, but not yet available as a haptic feedback because of the high forces and torques characteristic of scoliosis surgery, requiring the use of a specifically designed haptic device (in progress). Transatlantic collaborative tests showed that, with our simulator, users on different continents can train collaboratively for scoliosis surgery and visualise the forces and the resulting correction. With the eventual addition of haptic devices, they will also be able to feel the forces remotely.","","978-1-4244-2668-3","10.1109/HAVE.2008.4685289","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4685289","collaborative virtual environment;haptic feedback;immersive environment;scoliosis;surgical training","Virtual reality;Surgery;Collaboration;Testing;Computational modeling;Haptic interfaces;Context modeling;Spine;Surgical instruments;Computer simulation","","9","","30","IEEE","21 Nov 2008","","","IEEE","IEEE Conferences"
"Comparison of tracker-based to tracker-less haptic device calibration","B. Knoerlein; M. Harders","Virtual Reality in Medicine Group, Computer Vision Laboratory, ETH Zurich, Switzerland; Virtual Reality in Medicine Group, Computer Vision Laboratory, ETH Zurich, Switzerland",2011 IEEE World Haptics Conference,"11 Jul 2011","2011","","","119","124","In our current work we explore the feasibility of using visuo-haptic augmented reality techniques for training and remote collaboration. Accurate calibration of system components is a key factor in this context. In this paper we deal with the calibration of the kinematic parameters of the haptic device. We compare a previously developed technique using an external optical tracker to a new approach not relying on additional devices. Simulated and real experiments are carried out to investigate the performance of the new technique. As will be shown, both methods yield reasonable results with average errors in the workspace below 2mm. It is found that the trackerless technique is an acceptable alternative to using a tracker for calibration, with only slightly reduced accuracy. It is straightforward to apply and allows to improve rendering fidelity.","","978-1-4577-0298-3","10.1109/WHC.2011.5945472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5945472","","Calibration;Haptic interfaces;Kinematics;Optimization;Accuracy;Joints;Phantoms","","5","","14","IEEE","11 Jul 2011","","","IEEE","IEEE Conferences"
"The effects of visual information about self-movement on grasp forces when receiving objects in an augmented environment","A. H. Mason; C. L. MacKenzie","School of Kinesiology, Simon Fraser University, Burnaby, BC, Canada; School of Kinesiology, Simon Fraser University, Burnaby, BC, Canada",Proceedings 10th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. HAPTICS 2002,"7 Aug 2002","2002","","","105","112","This work explored how the presence of visual information about self-movement affected grasp forces when receiving an object from a partner. Twelve subjects either reached to grasp or grasped without reaching objects that were passed by a partner or rested on a table surface. Visual feedback about self-movement was available for half the trials and was removed for the other half. Results indicated that a graphic representation of self-movement significantly decreased transfer time when objects were passed between subjects. Results also indicated decreased time to peak grip force and peak grip force rate by the receiver with this visual feedback. These results suggest that grip force production on objects acquired from another person benefit from a crude graphical representation of the finger pads. Furthermore, these results suggest that sources of sensory feedback cannot be studied in isolation. Instead we must consider how feedback modalities are integrated for successful interaction. Implications for the design of virtual environments and integrated feedback devices are discussed.","","0-7695-1489-8","10.1109/HAPTIC.2002.998947","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=998947","","Electrical capacitance tomography;Force feedback;Haptic interfaces;Humans;Virtual environment;Production;Read only memory;Computer graphics;Tellurium;RAKE receivers","","2","","21","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Supporting Collaborative Interaction with Real Time Force Feedback in Distributed Haptic Virtual Environments over IP Networks","K. M. Yap","School of Computer Technology, Sunway University College, Petaling Jaya, Selangor Darul Ehsan, Malaysia",2010 Fourth International Conference on Genetic and Evolutionary Computing,"17 Feb 2011","2010","","","497","500","This paper presents an investigation into a new peer-to-peer network architecture for real time tele-haptic operation in distributed virtual environments (DVEs). A novel force collaboration and position synchronization algorithm is developed in order to support networked haptic interactions. Network impairments such as time delay, jitter and packet loss each have different (and severe) impacts on remote haptic collaborations. The new peer-to-peer architecture is able to support haptic interactions over IP networks. Experiments have been conducted to show the performance of this architecture in comparison with the currently available two algorithms that compensate for delay (TiDeC™), and position (dead reckoning) are examined. Experiments have been conducted to investigate the threshold levels of QoS required for networked haptic collaboration. Findings of the study are presented in this paper with recommendations for a set of network QoS parameter values that support haptic collaboration over IP networks.","","978-1-4244-8891-9","10.1109/ICGEC.2010.130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5715478","distributed virtual environment;haptic collabroation;multi-sensory traffic;QoS;peer-to-peer","Force;Haptic interfaces;Collaboration;Virtual environment;Synchronization;Delay;Jitter","","1","","19","IEEE","17 Feb 2011","","","IEEE","IEEE Conferences"
"Research on virtual assembly technology based on haptic senses","J. Chen; Y. Yuan; J. Yang","Department of Six, Air Force Airborne Academy, Guilin, China; Department of Training, Air Force Airborne Academy, Guilin, China; Department of Six, Air Force Airborne Academy, Guilin, China",2015 10th International Conference on Computer Science & Education (ICCSE),"10 Sep 2015","2015","","","725","728","This paper presents the research and implementation methods of virtual assembly based on a new haptic senses in the training system. According to the Leap Motion related technologies, we design several gestures and hand shape to achieve 3d interaction associated with virtual assembly. We propose the model of parts classification method includes four kinds of definition in order to simplify the assembly steps, on the basis of this give the method of parts coding to realize assembly sequence operation. The effectiveness of the proposed method is verified by a training example of the device model on virtual assembly training system.","","978-1-4799-6600-4","10.1109/ICCSE.2015.7250340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7250340","Virtual Assembly;Haptic Senses;Leap Motion;Gesture","Assembly;Haptic interfaces;Training;Solid modeling;Thumb;Tracking","","","","12","IEEE","10 Sep 2015","","","IEEE","IEEE Conferences"
"A Cloth Design System Using Haptic Device and Its Collaborative Environment","K. Miyahara; Y. Okada; K. Niijima","Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan",2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006),"15 Jan 2007","2006","","","48","53","This paper proposes a cloth design system that provides intuitive operations, e.g., sewing, cutting and fitting a cloth in a virtual 3D space through direct manipulations using a force-feedback device. This cloth design system also provides a collaborative environment that allows two users to design a common cloth collaboratively in a virtual 3D space through the Internet. A lot of cloth simulation algorithms and systems have been proposed and existed so far. However, there is no cloth design system that supports a force-feedback device and provides a networked-collaborative environment. So, the authors developed such a cloth design system. This paper describes what kinds of intuitive operations are implemented, how the collaborative environment is designed, and quantitative performances of the system to clarify its usefulness","","1-4244-0760-5","10.1109/HAVE.2006.283789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4062548","","Haptic interfaces;Collaboration;Collaborative work;Virtual reality;Internet;Imaging phantoms;Hardware;Character generation;Animation;Real time systems","","9","","21","IEEE","15 Jan 2007","","","IEEE","IEEE Conferences"
"Remote dynamic proxies for wave-based peer-to-peer haptic interaction","Zhi Li; D. Constantinescu","Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada; Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada",World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems,"3 Apr 2009","2009","","","553","558","This paper introduces a distributed haptic control architecture that can render direct interaction between users in addition to cooperative manipulation of virtual objects. The proposed architecture integrates remote dynamic proxies and peer-to-peer wave-based communications. Remote dynamic proxies are avatars of users at peer sites with motion governed by second order dynamics laws. They render physically-based motion of the distant users in the presence of update discontinuities caused by packet transmission limitations. They also enable users to touch their far away peers directly. The remote dynamic proxies are integrated with peer-to-peer wave-based communications by using wave variable controllers to connect the distributed copies of the shared virtual object, and to connect the users to their remote dynamic proxies. The proposed distributed control architecture is compared via experiments to peer-to-peer haptic cooperation with wave variable time delay compensation. The results illustrate that remote dynamic proxies with wave-based communications: (1) improve position coherency between the distributed copies of the shared virtual object; (2) render mass more faithfully in the presence of network delay; and (3) permit users to interact with each other directly in addition to enabling them to cooperatively manipulate the shared virtual object.","","978-1-4244-3858-7","10.1109/WHC.2009.4810799","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4810799","H.5.2 [Information Interfaces and Presentation]: User Interfaces—Haptic I/O;B.4.2 [Input/Output and Data Communications]: Input/Output Devices—Channels and controllers C.2.1 [Computer-Communication Networks]: Network Architecture and Design—Network communications","Peer to peer computing;Haptic interfaces;Communication system control;Distributed control;Propagation delay;Manipulator dynamics;Virtual environment;Mechanical engineering;Avatars;Delay effects","","3","","19","IEEE","3 Apr 2009","","","IEEE","IEEE Conferences"
"Design and implementation of a collaborative virtual haptic surgical training system","B. Chebbi; D. Lazaroff; F. Bogsany; P. X. Liu; Liya Ni; M. Rossi","School of Advanced Technology, Algonquin College, Ottawa, ONT, Canada; School of Advanced Technology, Algonquin College, Ottawa, ONT, Canada; School of Advanced Technology, Algonquin College, Ottawa, ONT, Canada; Department of Systems & Computer Engineering, Carleton University, Ottawa, ONT, Canada; Handshake VR, Waterloo, ONT, Canada; Handshake VR, Waterloo, ONT, Canada","IEEE International Conference Mechatronics and Automation, 2005","8 May 2006","2005","1","","315","320 Vol. 1","The high level design of a hapto-visual telementoring virtual environment consisting of two networked stations allowing two users to collaborate within the learning environment is outlined. The physical implementation and the operation of the system are described. This system is designed to be used for remote surgical training. It would allow surgeons to remotely train students in a networked hapto-visual virtual environment to perform simple tasks. Moreover, the system provides a platform for studying many aspects of collaborative virtual environment (CVE) systems and their applications.","2152-744X","0-7803-9044-X","10.1109/ICMA.2005.1626566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1626566","","Collaboration;Haptic interfaces;Surgery;Virtual environment;Virtual reality;Graphics;Communication system control;Application software;Internet;Web server","","39","","13","IEEE","8 May 2006","","","IEEE","IEEE Conferences"
"Comparison of power- and wave-based control of remote dynamic proxies for networked haptic cooperation","Zhi Li; D. Constantinescu","Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada; Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada",2009 International Conference on Mechatronics and Automation,"18 Sep 2009","2009","","","66","71","This paper investigates through experiments the performance of two recent control architectures for networked haptic cooperation [10], [11]. The two architectures can render direct haptic interaction between networked users in addition to cooperative manipulation of virtual objects. This is because both architectures employ remote dynamic proxies to represent users at their networked peer sites. The remote dynamic proxies have second order dynamics and are controlled by the distant user whom they represent via virtual coupling (i.e., power-based) control or via wave-based control. The remote dynamic proxies render smooth motion of their respective user in the presence of update discontinuities caused by limited network transmission rates and by network delays. The experimental comparison investigates the performance of cooperative manipulation and of direct user-to-user contact for various constant network delays. The results illustrate that: (1) both power-based and wave-based control of remote dynamic proxies can maintain high position coherency between the distributed copies of the shared virtual object; (2) wave-based control of remote dynamic proxies renders the inertia of the shared virtual object and of the remote dynamic proxies more realistically than virtual coupling control; and (3) wave-based control of remote dynamic proxies maintains the networked haptic cooperation stable for longer constant network delays.","2152-744X","978-1-4244-2692-8","10.1109/ICMA.2009.5246503","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5246503","Networked haptic cooperation;remote dynamic proxy","Haptic interfaces;Kinematics;Avatars;Mechanical engineering;Propagation delay;Application software;Surgery;Peer to peer computing;Mechatronics;Automation","","1","","19","IEEE","18 Sep 2009","","","IEEE","IEEE Conferences"
"KnuckleGuide: Mid-Air Haptic Guidance System Targeting Dorsal Hand Using Airborne Ultrasound","Q. Zhu; X. Yao; R. Sun; K. Hara; Y. Jiao","The Future Laboratory, Tsinghua University, Beijing, China; The Future Laboratory, Tsinghua University, Beijing, China; The Future Laboratory, Tsinghua University, Beijing, China; School of Computing and Information Systems Singapore Management University, Singapore, Singapore; The Future Laboratory, Tsinghua University, Beijing, China",2025 IEEE World Haptics Conference (WHC),"21 Aug 2025","2025","","","214","227","Ultrasound-based mid-air haptic guidance has gained significant attention as a contact-free solution for conveying direction information at a minimal distraction with high flexibility and robust environmental adaptability, particularly valuable when other modalities are limited or unavailable. Current research predominantly targets the palmar side of the hand, which becomes inaccessible for perceiving ultrasound-based haptic cues during critical interaction moments such as surface exploration or object gripping. This paper presents KnuckleGuide, a mid-air ultrasonic haptic navigation system focused at the dorsum hand while leaving the palmar side free for physical exploration. We propose two ultrasonic guidance strategies: a four-direction strategy (left, right, up, down) and an eight-direction strategy (including diagonals) and evaluate them through a user study with 16 participants performing surface navigation tasks. The effectiveness of the system was validated in three experiments, underscoring the feasibility of dorsum-targeted mid-air haptics for guiding surface exploration, offering new possibilities in assistive technologies and eye-free navigation.","2835-9534","979-8-3315-3353-3","10.1109/WHC64065.2025.11123318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11123318","ultrasound;mid-air haptics;navigation assistance;haptic exploration","Hands;Vibrations;Ultrasonic imaging;Accuracy;Navigation;Virtual environments;Focusing;Acoustics;Haptic interfaces;Testing","","","","44","IEEE","21 Aug 2025","","","IEEE","IEEE Conferences"
"An experimental study of supporting collaborative haptic interaction in distributed virtual environments over wireless networks","K. M. Yap; H. A. A. Ai-Rawi; T. -H. Lee","Sunway University, Petaling Jaya, Selangor, Malaysia; Sunway University Bandar Sunway, Petaling Jaya, Selangor, Malaysia; National Taichung University, Taichung, Taiwan",IET International Conference on Wireless Communications and Applications (ICWCA 2012),"15 Jul 2013","2012","","","1","6","This paper presents an experimental investigation into a new peer-to-peer wireless network architecture for real time telehaptic operation in distributed virtual environments (DVEs). The new peer-to-peer architecture is able to support haptic interactions over different wireless network architecture. Experiments have been conducted to show the performance of different wireless architecture, i. e. wireless-B/G/N. Experiments have also been conducted to investigate the performance of this architecture. Findings of the study are presented in this paper and it shows the challenges in conducting haptic collaboration over wireless IP networks. This is especially true when the wireless hops increase. The wireless channel condition varies over time due to such factors as channel characteristics, the PHY scheme selected, time-varying interference, and channel width for the particular wireless architecture.","","978-1-84919-550-8","10.1049/cp.2012.2089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6552432","distributed virtual environment;haptic;multisensory traffic;peer-to-peer;wireless haptic","","","","","","","15 Jul 2013","","","IET","IET Conferences"
"Toward Real-time Volume-based Haptic Communication with Realistic Sensation","S. Yamaguchi; T. Tanaka; H. Q. H. Viet; Y. Takama; Y. Tsujino; H. T. Tanaka","Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan; Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan; Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan; Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan; Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan; Computer Vision Laboratory, Ritsumeikan University, Kusatsu, Japan",17th International Conference on Artificial Reality and Telexistence (ICAT 2007),"2 Jan 2008","2007","","","135","142","A volume-based realistic communication system called Haptic Communication is described. The system allows participants to interact in real time with others at remote locations on the network using haptic perception (sense of touch) of soft objects in virtual environments. We constructed the system so that it provides a sense of touch at remote locations in real time. First, an adaptive volume model represents virtual soft objects in PCs at remote locations. Next, the reflection force of the soft object is calculated rapidly and accurately from the parameters of positions and forces at contacting points transmitted via network at each PC. Eventually, the haptic and visual information are rendered by a haptic device (PHANToM) and a volume graphic software in the PCs. We investigated the efficiency of our system via experiments on a simulation of needle insertion with high force feedback rates at two remote locations on a WAN between Ritsumeikan University, Biwako Kusatsu Campus and Shiga Medical University. The experiment results show that the delay due to network traffic is negligible.","","0-7695-3056-7","10.1109/ICAT.2007.47","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4414626","","Haptic interfaces;Real time systems;Personal communication networks;Virtual environment;Reflection;Rendering (computer graphics);Imaging phantoms;Graphics;Medical simulation;Needles","","1","","13","IEEE","2 Jan 2008","","","IEEE","IEEE Conferences"
"Presence in Shared Virtual Environments and Virtual Togetherness","N. Durlach; M. Slater","Research Laboratory of Electronics Massachusetts Institute of Technology Cambridge, MA 02139, durlach@cbgrle.mit.edu; University College London",Presence,"19 May 2014","2000","9","2","214","217","This Forum article discusses the relationships among people, their avatars, and their virtual environment workstations in a shared virtual environment. It introduces the notion of togetherness, the sense of people being together in a shared space, which is the counterpart for shared VEs to the presence of an individual in a VE. The role of tactual communication is emphasized as being fundamental to togetherness.","1054-7460","","10.1162/105474600566736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6788099","","","","18","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"XML-based representation of haptic information","Jilin Zhou; Xiaojun Shen; I. Shakra; A. El Saddik; N. D. Georganas","Distributed and Collaborative Virtual Environments Research Laboratory (DISCOVER), School of Information Technology and Engineering, University of Ottawa, Canada, Canada; Distributed and Collaborative Virtual Environments Research Laboratory (DISCOVER), School of Information Technology and Engineering, University of Ottawa, Canada, Canada; Distributed and Collaborative Virtual Environments Research Laboratory (DISCOVER), School of Information Technology and Engineering, University of Ottawa, Canada, Canada; Distributed and Collaborative Virtual Environments Research Laboratory (DISCOVER), School of Information Technology and Engineering, University of Ottawa, Canada, Canada; Distributed and Collaborative Virtual Environments Research Laboratory (DISCOVER), School of Information Technology and Engineering, University of Ottawa, Canada, Canada",IEEE International Workshop on Haptic Audio Visual Environments and their Applications,"12 Dec 2005","2005","","","5 pp.","","The ongoing research on haptics has produced excellent results that have paved the way to a whole new field of multimedia. Creating the sense of ""touch"", along with all its derivatives is very appealing indeed. Whether it is in gaming, tele-surgery simulations, rehabilitation, entertainment, or in the realm of military applications, concerned users seem to have obtained an acquired taste of this haptic world. However, the lack of haptic information representation formats is an impediment to the development of haptic applications. We propose a novel approach to represent haptic information. Six basic categories are defined to describe the haptic application model with an explanation on why these categories and their parameters need to be defined.","","0-7803-9376-7","10.1109/HAVE.2005.1545663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1545663","","Haptic interfaces;Application software;Collaboration;Virtual environment;Humans;Information technology;Computational modeling;Military computing;Surgery;Electronic mail","","4","1","32","IEEE","12 Dec 2005","","","IEEE","IEEE Conferences"
"A Scheme for Haptic Data Transmission Under Various Network Conditions","Y. You; M. Y. Sung; K. Jun","Department of Computer Science & Engineering, Department of Multimedia Systems Engineering, University of Incheon, Incheon, South Korea; Department of Computer Science & Engineering, Department of Multimedia Systems Engineering, University of Incheon, Incheon, South Korea; Department of Computer Science & Engineering, Department of Multimedia Systems Engineering, University of Incheon, Incheon, South Korea",2007 IEEE International Conference on Multimedia and Expo,"8 Aug 2007","2007","","","2238","2241","Haptic Collaboration Virtual Environment (HCVE) is an enhanced virtual reality space that supports sense of touch, which is called ""haptic"". In HCVE, remote users connected over networks are able to collaborate by sharing touching experiences in addition to well-established audio and visual interfaces. The success of HCVE largely depends on timely transmission of haptic data despite time-varying network conditions such as delay, loss, and jitter. However, the fact that the data generation frequency of haptic interface devices is extremely high, e.g. 1 KHz, makes the realization of successful HCVE more challenging. For seamless haptic data communication even under adverse network conditions, we propose a linear prediction algorithm and a buffering scheme. The prediction algorithm, which is basically extrapolation, is to mitigate the negative effects of network delay, loss and jitter, and the buffering scheme is to help synchronization of haptic interaction between remote users. We build an experimental test bed for the evaluation of our proposed schemes, and as the results of analyzing quantitative measurement results, conclude that those are effective in improving the quality of haptic experiences.","1945-788X","1-4244-1016-9","10.1109/ICME.2007.4285131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4285131","","Haptic interfaces;Data communication;Collaboration;Jitter;Prediction algorithms;Virtual environment;Virtual reality;Propagation losses;Frequency;Extrapolation","","2","","9","IEEE","8 Aug 2007","","","IEEE","IEEE Conferences"
"Experimental performance evaluation of a haptic training simulation system","B. Khademian; K. Hashtrudi-Zaad","Department of Electrical and Computer Engineering, Queen's University, Kingston, ONT, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ONT, Canada",2009 IEEE/RSJ International Conference on Intelligent Robots and Systems,"15 Dec 2009","2009","","","1247","1252","In this paper the performance of a dual-user haptic simulation system with a proposed shared control architecture is experimentally evaluated for a specific trajectory following task under different operating conditions. The multilateral control architecture developed for training purposes, allows interaction between both users, the trainee and the trainer, as well as between the users and the virtual slave robot in a shared environment. The performance of the architecture is evaluated experimentally in terms of the effect of environment point of view, environment mushiness, and the existence of virtual fixtures. The performance is measured against task completion time, the path following accuracy and energy exchange by the trainer and the trainee.","2153-0866","978-1-4244-3803-7","10.1109/IROS.2009.5354183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5354183","","Haptic interfaces;Robots;Feedback;Collaboration;Fixtures;Energy measurement;Time measurement;Force measurement;Humans;Virtual environment","","10","","11","IEEE","15 Dec 2009","","","IEEE","IEEE Conferences"
"Influence of Local Lag on Reaction Force in Networked Virtual Environment with Haptic Sense","K. Z. Win; Y. Ishibashi; K. H. Win","Faculty of Computer Science, University of Computer Studies, Yangon, Yangon, Myanmar; Graduate School of Engineering, Nagoya Institute of Technology, Nagoya, Japan; Faculty of Computer Systems and Technologies, University of Computer Studies, Yangon, Yangon, Myanmar",2024 IEEE Conference on Computer Applications (ICCA),"22 May 2024","2024","","","1","6","This paper investigates the influence of local lag on the reaction forces in a networked virtual maze system incorporating haptic feedback by experiment. In the experiment, participants move a box from the starting position to the target point by using Raising method with haptic device. We measure the average operation time and the average of average reaction force for three different moving velocities and three distinct local lags. Experimental results reveal that as the moving velocity increases and the local lag becomes higher, the two measures become larger. Thus, we illustrate that there exists a strong relationship among the average operation time, the average of average reaction force, moving velocity, and local lag, through multiple regression analysis.","","979-8-3503-5362-4","10.1109/ICCA62361.2024.10533043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10533043","Local Lag Control;Reaction Force Control;Haptic Sense;Networked Maze System;Virtual Environment;Raising Method;Force Feedback","Force measurement;Force;Virtual environments;Computer applications;Particle measurements;Control systems;Time measurement","","","","23","IEEE","22 May 2024","","","IEEE","IEEE Conferences"
"Social Touch Technology: A Survey of Haptic Technology for Social Touch","G. Huisman","Human Media Interaction Group, University of Twente, Enschede, NB, the Netherlands",IEEE Transactions on Haptics,"15 Sep 2017","2017","10","3","391","408","This survey provides an overview of work on haptic technology for social touch. Social touch has been studied extensively in psychology and neuroscience. With the development of new technologies, it is now possible to engage in social touch at a distance or engage in social touch with artificial social agents. Social touch research has inspired research into technology mediated social touch, and this line of research has found effects similar to actual social touch. The importance of haptic stimulus qualities, multimodal cues, and contextual factors in technology mediated social touch is discussed. This survey is concluded by reflecting on the current state of research into social touch technology, and providing suggestions for future research and applications.","2329-4051","","10.1109/TOH.2017.2650221","Dutch national program COMMIT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7811300","Haptics and haptic interfaces;social touch;affective touch;medaited social touch;simulated social touch","Haptic interfaces;Skin;Neurophysiology;Manipulators;Psychology;Visualization;Bonding","Affect;Electrical Equipment and Supplies;Humans;Interpersonal Relations;Social Perception;Touch Perception;User-Computer Interface","167","","219","IEEE","9 Jan 2017","","","IEEE","IEEE Journals"
"Performance Issues in Collaborative Haptic Training","B. Khademian; K. Hashtrudi-Zaad","Department of Electrical and Computer Engineering, Queen's University, Kingston, ONT, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ONT, Canada",Proceedings 2007 IEEE International Conference on Robotics and Automation,"21 May 2007","2007","","","3257","3262","This paper proposes a new multilateral position-position shared control architecture for dual-user haptic training. The proposed controller allows interaction between both users, the trainee and the trainer, as well as between the users and the virtual slave robot and environment. It also allows for the adjustment of the dominance of the trainer over the trainee in interaction with the virtual slave and environment through a dominance factor parameter. The issue of transparency in such collaborative haptic simulation system has been discussed. A performance index has also been defined to quantify the users' skill for a specific task under study. This metric is used to identify the maximum allowable dominance of the trainee over the trainer. Haptic simulation experiments have been carried out with two planar twin pantograph haptic devices and a simulated pantograph as the slave robot.","1050-4729","1-4244-0601-3","10.1109/ROBOT.2007.363975","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4209593","","Collaboration;Haptic interfaces;Robots;Impedance;Performance analysis;Virtual environment;Automatic control;Collaborative work;Control systems;Feedback","","22","","9","IEEE","21 May 2007","","","IEEE","IEEE Conferences"
"Peer-to-peer control architecture for multiuser haptic collaboration over undirected delayed packet-switching network","D. Lee; K. Huang","Department of Mechanical, Aerospace & Biomedical Engineering, University of Tennessee, Knoxville, TN, USA; Department of Mechanical, Aerospace & Biomedical Engineering, University of Tennessee, Knoxville, TN, USA",2010 IEEE International Conference on Robotics and Automation,"15 Jul 2010","2010","","","1333","1338","We propose a novel peer-to-peer distributed control architecture for shared haptic collaboration among remotely-located users over undirected packet-switching network (e.g. Internet) with inter-user communication delay. The proposed architecture is distributed, in that each user simulates and interacts with its own local copy of the shared virtual environment. Spring connection among the local copies and local damping are used, which, together, under a certain condition, achieve configuration synchronization among the local copies while enforcing discrete-time passivity of the total peer-to-peer architecture, thereby, rendering the architecture portable/scalable for any (passive) users/devices and ensuring its interaction stability be user/device-invariant. The issue of optimizing communication network is also addressed with some relevant experimental results.","1050-4729","978-1-4244-5038-1","10.1109/ROBOT.2010.5509578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5509578","","Peer to peer computing;Haptic interfaces;Collaboration;Communication system control;Distributed control;Internet;Delay;Virtual environment;Springs;Damping","","8","","20","IEEE","15 Jul 2010","","","IEEE","IEEE Conferences"
"Haptic Human Computer Interaction","T. Nikolaos; V. Georgios; K. Georgios","Dept. of Business Administration, University Of Western Macedonia, Grevena, Greece; Dept. of Business Administration, University Of Western Macedonia, Grevena, Greece; Dept. of Business Administration, University Of Western Macedonia, Grevena, Greece",2023 6th World Symposium on Communication Engineering (WSCE),"25 Dec 2023","2023","","","21","27","Human-Computer Interaction (HCI) is a multidisciplinary field that focuses on the design, evaluation, and implementation of interactive computer systems for human use. It encompasses the study of how people interact with computers, the design of user interfaces, and the development of technologies that facilitate effective communication between humans and machines. HCI is a dynamic field that evolves alongside advancements in technology and user expectations. It draws from various disciplines, including computer science, psychology, design, sociology, and anthropology, to create human-centered computing experiences. HCI also addresses the importance of designing inclusive interfaces that can be used by individuals with disabilities. Haptic Human-Computer Interaction (HHCI) refers to the use of touch and force feedback technologies to enable interaction between humans and computers. It focuses on providing users with tactile and kinesthetic sensations that enhance the overall user experience and facilitate communication between users and digital systems. When we lose sight, either because of a visual impairment, or simply by traveling in an environment where the visual sense is impaired, we become aware of the sense of touch. Today, at a technological level, several devices and applications, based on the sense of touch, have been developed, that enable people with visual disabilities to interact with them in order to improve their daily activity. This paper attempts a report on the most usable haptic devices and applications in recent years, as well as how they have affected various areas of users' daily lives.","2835-3404","979-8-3503-3950-5","10.1109/WSCE59557.2023.10365961","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10365961","Tactile Internet;Haptic Interfaces;Virtual reality;Augmented reality;Tactile feedback;Virtual Interaction;Haptic perception;Haptic display;Force Feedback;Virtual shapes;Tele-haptics;Algorithm;Depth images","Human computer interaction;Performance evaluation;Visualization;Solid modeling;Visual impairment;Virtual environments;Data transfer","","","","35","IEEE","25 Dec 2023","","","IEEE","IEEE Conferences"
"The Effect of Multisensory Pseudo-Haptic Feedback on Perception of Virtual Weight","J. Kim; S. Kim; J. Lee","Graduate School of Culture Technology, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Graduate School of Culture Technology, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea; Graduate School of Culture Technology, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, South Korea",IEEE Access,"19 Jan 2022","2022","10","","5129","5140","Providing realistic haptic feedback of virtual objects is critical for immersive VR experience, and there have been many approaches to simulate haptic properties. Most of them, however, are limited to a narrow modulation range of simulated perception. To overcome this limitation, the current paper examines the effect of multisensory pseudo-haptic feedback that combines control-to-display (C/D) ratio manipulation and electrical muscle stimulation (EMS) on simulated weight perception. In two experiments, we independently manipulated the C/D ratio and EMS status and observed the effects on the absolute and difference thresholds of simulated weight perception. From the absolute thresholds results, we specify the effective range of C/D ratio that can successfully induce weight perception and show that the range can be more than twice widened by multisensory pseudo-haptic feedback. Furthermore, we demonstrate that the sensitivity to weight difference increases as the standard C/D ratio decreases from the difference thresholds results, which provides practical design guidelines for assigning multiple levels of weight to virtual objects. This study contributes to understanding the psychological effects of multisensory pseudo-haptic feedback on simulated weight perception in virtual reality.","2169-3536","","10.1109/ACCESS.2022.3140438","Korea Advanced Institute of Science and Technology (KAIST)(grant numbers:G04180005); National Research Foundation of Korea (NRF); Ministry of Science and ICT (MSIT)(grant numbers:NRF-2021R1F1A1056524); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9669918","Pseudo-haptic feedback;virtual reality;weight simulation;electrical muscle stimulation;multisensory integration;proprioception","Visualization;Haptic interfaces;Modulation;Muscles;Sensitivity;Design methodology;Virtual reality","","28","","56","CCBY","5 Jan 2022","","","IEEE","IEEE Journals"
"Streaming 3D shape deformations in collaborative virtual environment","Z. Tang; G. Rong; X. Guo; B. Prabhakaran","Computer Science Department, University of Texas, Dallas, USA; Computer Science Department, University of Texas, Dallas, USA; Computer Science Department, University of Texas, Dallas, USA; Computer Science Department, University of Texas, Dallas",2010 IEEE Virtual Reality Conference (VR),"8 Apr 2010","2010","","","183","186","Collaborative virtual environment has been limited on static or rigid 3D models, due to the difficulties of real-time streaming of large amounts of data that is required to describe motions of 3D deformable models. Streaming shape deformations of complex 3D models arising from a remote user's manipulations is a challenging task. In this paper, we present a framework based on spectral transformation that encodes surface deformations in a frequency format to successfully meet the challenge, and demonstrate its use in a distributed virtual environment. Our research contributions through this framework include: i) we reduce the data size to be streamed for surface deformations since we stream only the transformed spectral coefficients and not the deformed model; ii) we propose a mapping method to allow models with multi-resolutions to have the same deformations simultaneously; iii) our streaming strategy can tolerate loss without the need for special handling of packet loss. Our system guarantees real-time transmission of shape deformations and ensures the smooth motions of 3D models. Moreover, we achieve very effective performance over real Internet conditions as well as a local LAN. Experimental results show that we get low distortion and small delays even when surface deformations of large and complicated 3D models are streamed over lossy networks.","2375-5334","978-1-4244-6238-4","10.1109/VR.2010.5444793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444793","Collaborative Interaction;Distributed Virtual Reality;3D Shape Deformation","Shape;Collaboration;Virtual environment;Deformable models;High performance computing;Computer networks;Multiresolution analysis;Simultaneous localization and mapping;Spatial resolution;Internet","","6","","15","IEEE","8 Apr 2010","","","IEEE","IEEE Conferences"
"A novel approach for addressing extensibility issue in collaborative virtual environment","Choo Tian Fook; Lin Qingping; Zhang Liang","Information Communication Institute of Singapore, School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore; Information Communication Institute of Singapore, School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore; Information Communication Institute of Singapore, School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore",Proceedings. 2003 International Conference on Cyberworlds,"8 Jan 2004","2003","","","78","84","In order to achieve entity evolvement, enrich socialization of virtual community and optimize computer processing in the collaborative virtual environment (CVE), efficient collaborative interaction management (CIM) is a key to handle these issues. In this paper, we focus on functional extensibility in CVE, and give the solution by using the conceptual idea of our proposed CIM approach, called task-oriented interaction management. This approach has four important components, which are scene interaction manager, virtual entity interaction manager, interaction task agent, and scene role & rules. They have certain capabilities, like data distribution, load-balance, tasks migration, ownership transfer, entities' states consistency maintenance, database persistency management and etc. The motivation of this research is to develop an extensible and evolving CVE with extensible functionalities for creating large-scale collaborative interaction experience to users in a large-scale interconnected 3D virtual environment. Details of the conceptual framework of the task-oriented interaction management will be presented in this paper.","","0-7695-1922-9","10.1109/CYBER.2003.1253438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1253438","","Collaboration;Virtual environment;Virtual reality;Computer integrated manufacturing;Layout;Large-scale systems;Graphics;Collaborative work;Environmental management;Technology management","","3","","16","IEEE","8 Jan 2004","","","IEEE","IEEE Conferences"
"Networked Haptic Virtual Environments Supporting Ultra High Resolution Display","S. Son; V. Ramachandra; J. Kim","Department of Information and Communications, Gwangju Institute of Science and Technology, Gwangju, South Korea; Department of Information and Communications, Gwangju Institute of Science and Technology, Gwangju, South Korea; Department of Information and Communications, Gwangju Institute of Science and Technology, Gwangju, South Korea",2009 11th IEEE International Conference on High Performance Computing and Communications,"17 Jul 2009","2009","","","579","584","With HPC (high performance computing) and scientific computing, it has been possible to produce a large amount of data. To easily analyze those data and collaborate on it, visualization in terms of ultra high resolution is desired. However, in order to combine a HPC system with a high resolution display system, high system resource is required. This paper shows an example of a system combining both a haptic system requiring high speed computing and a ultra high resolution display system. Thus, in this paper, we realize a networked haptic virtual environment system over ultra high resolution tiled display. With a networked haptic virtual environment supporting ultra high resolution display, users can feel sense of touch with haptic device and see visuals in ultra high resolution manner with network tiled display when users collaborate in shared virtual environment together. In addition, in this paper, a frame rate control scheme, making the networked haptic virtual environment system over ultra high resolution display stable, is proposed.","","978-1-4244-4600-1","10.1109/HPCC.2009.92","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5167047","haptic display;virtual environments;visualization system;tiled display;QoE","Haptic interfaces;Virtual environment;Computer displays;Virtual reality;Resource management;High performance computing;Collaboration;Control systems;Auditory displays;Scientific computing","","","","14","IEEE","17 Jul 2009","","","IEEE","IEEE Conferences"
"Improvement of collaborative selection in 3D complex environments","A. Girard; M. Ammi; J. Simard; M. Auvray","CNRS/LIMSI, University Paris Sud 11, France; CNRS/LIMSI, University Paris Sud 11, France; CNRS/LIMSI, University Paris Sud 11, France; CNRS/LIMSI, University Paris Sud 11, France",2012 IEEE Haptics Symposium (HAPTICS),"16 Apr 2012","2012","","","281","288","Closely coupled interactions in 3D Collaborative Virtual Environments present a new challenge for the design of Computer-Human Interfaces. Among emerging issues, the collaborative selection of artifact presents several constraints since it requires a good understanding of the workspace of the partner and a good coordination between their actions. However, existing Collaborative Virtual Environments inhibit some mechanisms of communication and interpersonal awareness processes, and this limits the efficiency of such collaborative tasks. To go beyond these constraints, we propose in this article a metaphor for the collaborative selection of 3D artifacts. The proposed approach exploits the haptic channel through a gestural guidance strategy. Once the target is selected by one partner, the second partner is attracted through a suitable force model toward the target. An experimental study was carried out in the context of molecular design, investigating different working strategies. The results show that the proposed metaphor significantly improves the efficiency of the group during the deformation of molecular structures. Moreover, the proposed approach provides a suitable learning support for beginners and enables the more experienced user to implicitly convey and explain some features of the molecular structures.","2324-7355","978-1-4673-0809-0","10.1109/HAPTIC.2012.6183803","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6183803","","Collaboration;Haptic interfaces;Three dimensional displays;Force;Visualization;Computers;Vectors","","2","","15","IEEE","16 Apr 2012","","","IEEE","IEEE Conferences"
"Group Haptic Collaboration: Evaluation of Teamwork Behavior during VR Four-Person Rowing Task","B. Tian; Y. Zheng; Z. Zhuang; H. Luo; Y. Zhang; D. Wang","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; School of Electromechanical Engineering, Beijing Information Science and Technology University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China",IEEE Transactions on Haptics,"19 Sep 2024","2024","17","3","384","395","The assessment of multi-person group collaboration has garnered increasing attention in recent years. However, it remains uncertain whether haptic information can be effectively utilized to measure teamwork behavior. This study seeks to evaluate teamwork competency within four-person groups and differentiate the contributions of individual members through a haptic collaborative task. To achieve this, we propose a paradigm in which four crews collaboratively manipulate a simulated boat to row along a target curve in a shared haptic-enabled virtual environment. We define eight features related to boat trajectory and synchronization among the four crews' paddling movements, which serve as indicators of teamwork competency. These features are then integrated into a comprehensive feature, and its correlation with self-reported teamwork competency is analyzed. The results demonstrate a strong positive correlation (r>0.8) between the comprehensive feature and teamwork competency. Additionally, we extract two kinesthetic features that represent the paddling movement preferences of each crew member, enabling us to distinguish their contributions within the group. These two features of the crews with the highest and the lowest contribution in each group were significantly different. This work demonstrates the feasibility of kinesthetic features in evaluating teamwork behavior during multi-person haptic collaboration tasks.","2329-4051","","10.1109/TOH.2023.3346683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10373120","Group haptic collaboration;teamwork behavior;kinesthetic feature;teamwork competency;members' contri- bution;four-person rowing;paddling movement","Haptic interfaces;Teamwork;Boats;Behavioral sciences;Feature extraction;Behavioral sciences;Kinematics;Federated learning;Collaboration","Humans;Cooperative Behavior;Male;Female;Touch Perception;Virtual Reality;Adult;Young Adult;Group Processes;Kinesthesis;Task Performance and Analysis;Water Sports;User-Computer Interface;Touch","","","51","IEEE","25 Dec 2023","","","IEEE","IEEE Journals"
"5G-TSN FlexTac: Experience A New Touch","S. Senk; T. Scheinert; H. K. Nazari; H. -H. Liu; G. T. Nguyen; F. H. P. Fitzek","Deutsche Telekom Chair of Communication Networks, TU Dresden, Germany; Deutsche Telekom Chair of Communication Networks, TU Dresden, Germany; Deutsche Telekom Chair of Communication Networks, TU Dresden, Germany; Deutsche Telekom Chair of Communication Networks, TU Dresden, Germany; Haptic Communication Systems, TU Dresden, Germany; Haptic Communication Systems, TU Dresden, Germany",IEEE INFOCOM 2024 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS),"13 Aug 2024","2024","","","1","3","The Tactile Internet (TI) is a revolutionary communication platform that enables perceived real-time interaction between humans and machines, such as in remote surgery. However, realizing TI is a complex challenge in wireless networks like the 5G and beyond 5G mobile communication systems. 5G-TSN is an approach adopting the determinism of Time-Sensitive Networking (TSN) into 5G systems. This demo presents 5G-TSN FlexTac, a 5G and TSN combination, to achieve ultra-low latency for real-time tactile experiences. The demo showcases its effectiveness in providing immersive haptic interactions, opening avenues for virtual reality and remote surgery applications. The user can experience the Tactile Internet with haptic feedback through a cyber-physical input device. Furthermore, the user can understand the need for traffic prioritization by investigating the effects of different QoS settings in the 5G-TSN FlexTac testbed.","2833-0587","979-8-3503-8447-5","10.1109/INFOCOMWKSHPS61880.2024.10620809","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10620809","5G and beyond 5G;Time-Sensitive Networking;Tactile Internet;Testbed;Haptic Communication Systems","Tactile Internet;5G mobile communication;Wireless networks;Conferences;Surgery;Input devices;Virtual reality","","1","","5","IEEE","13 Aug 2024","","","IEEE","IEEE Conferences"
"Remote collaboration across heterogeneous large interactive spaces","C. Fleury; N. Férey; J. -M. Vézien; P. Bourdot","Université Paris-Sud & CNRS (LRI), Inria Orsay, France; VENISE group, CNRS-LIMSI, Orsay, France; VENISE group, CNRS-LIMSI, Orsay, France; VENISE group, CNRS-LIMSI, Orsay, France",2015 IEEE Second VR International Workshop on Collaborative Virtual Environments (3DCVE),"13 Jul 2015","2015","","","9","10","Immersive virtual reality systems or high resolution wall-sized displays become more common for analyzing the increasing among of data from science, industry, business and society. These large interactive spaces are powerful tools to enable remote users to work together on shared data. However, we cannot imagine that remote collaboration in such systems becomes wide-spread if it requires that all users have the exact same physical devices, and we need to make remote collaboration across different systems possible. The asymmetric interaction capabilities of each user are also an interesting opportunity to develop new collaboration strategies. In this short position paper, we present our past work about collaborative virtual environments and, in particular, how to represent the physical environments of each user in a virtual environment. We also introduce an on-going project which aims to support remote collaborative interaction across heterogeneous large interactive spaces.","","978-1-4799-1840-9","10.1109/3DCVE.2015.7153591","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153591","","Collaboration;Three-dimensional displays;Virtual environments;Solid modeling;Data visualization;Data analysis","","7","","8","IEEE","13 Jul 2015","","","IEEE","IEEE Conferences"
"A real-time GPU-based coupled fluid-structure simulation with haptic interaction","J. Zhang; S. Yuasa; S. Fukuma; S. -I. Mori","Dept. of Information Science, University of Fukui, Fukui, JAPAN; Dept. of Information Science, University of Fukui, Fukui, JAPAN; Dept. of Information Science, University of Fukui, Fukui, JAPAN; Dept. of Information Science, University of Fukui, Fukui, JAPAN",2016 IEEE/ACIS 15th International Conference on Computer and Information Science (ICIS),"25 Aug 2016","2016","","","1","6","Time series scientific simulation on supercomputers generates huge amounts of data at each time step. In the big data era, these data become impossible to be stored anymore, so simultaneous analysis of these data is strongly demanded. In order to realize such an on-the-fly intuitive analysis of simulation, this paper showcases a multimodal visualization and steering system with visual and haptic interfaces for a real-time GPU-based coupled fluid-structure simulation. Since the nature of touching sense of human beings requires extremely fast and continuous refreshing to form authentic feeling, parallel techniques were utilized to speed up haptic updating to around one millisecond. A middle-layer interface for a haptic device was developed to realize the ease of use of this device. Furthermore, a model of palpation was proposed to allow users to touch, push and sense the dynamic fluid motion inside a deformable tube.","","978-1-5090-0806-3","10.1109/ICIS.2016.7550842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7550842","Interactive Real-time Simulation;GPU-based;Haptic Device;Parallel Processing;GPGPU;Streaming Data Analysis","Haptic interfaces;Force;Computational modeling;Fluids;Real-time systems;Analytical models;Graphics processing units","","6","","16","IEEE","25 Aug 2016","","","IEEE","IEEE Conferences"
"Kinesthetic haptics integration into large-scale virtual environments","U. Kunzler; C. Runde","Bern University of Applied Sciences, Bern, Switzerland; Fraunhofer IPA, Stuttgart, Germany",First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. World Haptics Conference,"4 Apr 2005","2005","","","551","556","In this paper we investigate the hardware and software challenges to integrate kinesthetic haptic force feedback into large-scale (i.e. human-sized or larger) virtual environments (VE). Based on a literature survey of current haptic interface technologies, we introduce a qualitative schema for the evaluation of large-scale haptic immersion of various haptic display types suitable to be used within such large VEs. The other focus of our research concentrates on the elaboration of a distributed software architecture for an adaptable and extendable framework for VE haptics integration. In particular we describe a specific haptics-server prototype implementation integrated into a three wall passive stereo CAVE system currently being built at the Fraunhofer IPA institute in Stuttgart.","","0-7695-2310-2","10.1109/WHC.2005.84","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1407006","","Haptic interfaces;Large scale integration;Virtual environment;Hardware;Force feedback;Large-scale systems;Displays;Software architecture;Software prototyping;Prototypes","","9","","27","IEEE","4 Apr 2005","","","IEEE","IEEE Conferences"
"Proactive haptic articulation for intercommunication in collaborative virtual environments","V. A. de Jesus Oliveira; L. Nedel; A. Maciel","Universidade Federal do Rio Grande do Sul (UFRGS) - Instituto de Informática (INF), Porto Alegre, RS, Brazil; Universidade Federal do Rio Grande do Sul (UFRGS) - Instituto de Informática (INF), Porto Alegre, RS, Brazil; Universidade Federal do Rio Grande do Sul (UFRGS) - Instituto de Informática (INF), Porto Alegre, RS, Brazil",2016 IEEE Symposium on 3D User Interfaces (3DUI),"28 Apr 2016","2016","","","91","94","In this paper, we look upon elements present in speech articulation to introduce proactive haptic articulation as a novel approach for communication in Collaborative Virtual Environments. We defend the hypothesis that elements present in natural language, when added to the design of the vibrotactile vocabulary, should provide an expressive medium for intercommunication. Moreover, the ability to render tactile cues to a teammate should encourage users to extrapolate a given vocabulary while using it. We implemented a collaborative puzzle task to observe the use of such vocabulary. Results show that participants autonomously adapted it to attend their communication needs during the assembly.","","978-1-5090-0842-1","10.1109/3DUI.2016.7460036","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7460036","H.5.1 [Information Interface and Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces & Presentation]: User Interfaces — Haptic I/O","Vocabulary;Collaboration;Virtual environments;Vibrations;Data gloves;Speech","","4","","10","IEEE","28 Apr 2016","","","IEEE","IEEE Conferences"
"A basic study of a pillow-shaped haptic device using a pneumatic actuator","Satoshi Iwaki; Satoshi Ueki; Y. Nakamura; M. Motegi; K. Ogawa; K. Shimokura","Hiroshima City University, Japan; Gifu University, Japan; NTT, Japan; NTT, Japan; Keio University, Japan; ATR, Japan",2008 5th International Symposium on Mechatronics and Its Applications,"14 Oct 2008","2008","","","1","5","As a new haptic device for daily use, a pillow-shaped haptic device using a pneumatic actuator, the Air-pillow telephone, is proposed. The Air-pillow telephone allows an intimate couple at a distance to mutually share the partner’s sense of touch and presence, which cannot be easily conveyed by conventional communication media: text, voice, still image and video. We have developed a prototype system with an air bag driven by a piston-cylinder mechanism. The user’s head motion affects the air pressure of the air bag and then its signal is bilaterally transmitted in real time via internet to actuate the partner’s air pillow. Inside the pillow’s subtle motion, the user can find the existence of the partner’s haptic language. This paper describes the Air-pillow telephone concept and application as well as implementation of the prototype system, modeling and control design. For the user’s sense of touch control method, we propose two control modes: the seesaw mode and the synchronous mode. The validity of the proposed idea was confirmed with successful simulation and experimental results under the TCP/IP network environment.","","978-1-4244-2033-9","10.1109/ISMA.2008.4648859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4648859","","Safety devices;Automotive components;Prototypes;Pistons;Telephone sets;Head;Haptic interfaces;Magnetic heads;Robots;Mathematical models","","4","","16","IEEE","14 Oct 2008","","","IEEE","IEEE Conferences"
"Packet-loss-resilient perception-based haptic data reduction and transmission using ACK packets","J. Qin; K. -S. Choi; R. Xu; W. -M. Pang; P. -A. Heng","Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, China; School of Nursing, Hong Kong Polytechnic University, Hong Kong, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Department of Computer Science, Caritas Institute of Higher Education, Hong Kong, China; Department of Computer Science and Engineering, Chinese University of Hong Kong, Hong Kong, China",2012 IEEE 11th International Conference on Signal Processing,"4 Apr 2013","2012","2","","1165","1170","Numerous studies have shown that haptic interaction plays a key role in enriching the sense of immersion and copresence of distributed users in collaborative virtual environments (CVEs). However, to ensure high-fidelity haptic interaction in CVEs, a high packet rate is required, resulting in considerable increase in overall traffic over the network. While perceptual deadband approach for haptic signals can successfully reduce high packet rates, this method is vulnerable to packet loss because the losing of single perceivable update packet results in a succession of wrong predictions. In this paper, we improve the perceptual deadband model by incorporating a packet loss resilient scheme using acknowledgement (ACK) packets. In case that an ACK packet is not returned to the sender within a trigger time, the sender will send an additional haptic data packet to the receiver to offset the effect caused by packet loss. By carefully selecting trigger time, buffer length and acknowledge time, the proposed scheme can be applied in a network environment with variable packet loss rates. The ACK-packets-based scheme is experimented by using different packet loss rates and lengthes of burst loss. Experimental results show that the proposed scheme can maintain stable and robust haptic interaction in terms of both objective and subjective measurements in a lossy network environment, and meanwhile perform well in haptic data reduction.","2164-523X","978-1-4673-2197-6","10.1109/ICoSP.2012.6491784","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6491784","Haptic data reduction and transmission;perceptual deadband;collaborative virtual environments","","","2","","19","IEEE","4 Apr 2013","","","IEEE","IEEE Conferences"
"A heterogeneous scalable architecture for collaborative haptics environments","Xiaojun Shen; F. Bogsanyi; Liya Ni; N. D. Georganas","Distributed and Collaborative Virtual Environments Research Laboratory (DISCOVER) School of Information Technology and Engineering, University of Ottawa, Canada; Algonquin College, Ottawa, ONT, Canada; Handshake Interactive Technologies, Inc., Canada; Distributed and Collaborative Virtual Environments Research Laboratory (DISCOVER) School of Information Technology and Engineering, University of Ottawa, Canada","The 2nd IEEE Internatioal Workshop on Haptic, Audio and Visual Environments and Their Applications, 2003. HAVE 2003. Proceedings.","10 Nov 2003","2003","","","113","118","The purpose of this research effort is to design a generic architecture for collaborative haptic, audio, visual environments (C-HAVE). We aim to develop a heterogeneous scalable architecture for large collaborative haptics environments where a number of potential users participate with different kinds of haptic devices. This paper begins with a brief overview of C-HAVE and then proceeds to describe a generic architecture that is implemented over HLA/RTI (High Level Architecture/Run Time Infrastructure), an IEEE standard for distributed simulations and modeling. A potential electronic commerce application over C-HAVE is discussed.","","0-7803-8108-4","10.1109/HAVE.2003.1244735","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1244735","","Collaboration;Haptic interfaces;Virtual environment;Virtual reality;Electronic commerce;Collaborative work;Delay;Erbium;Information technology;Educational institutions","","14","2","20","IEEE","10 Nov 2003","","","IEEE","IEEE Conferences"
"A cataract tele-surgery training application in a hapto-visual collaborative environment running over the CANARIE photonic network","N. R. El-Far; S. Nourian; Jilin Zhou; A. Hamam; Xiaojun Shen; N. D. Georganas","Distributed & Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada, Ottawa, ONT, Canada; Distributed & Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada, Ottawa, ONT, Canada; Distributed & Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada, Ottawa, ONT, Canada; Distributed & Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada, Ottawa, ONT, Canada; Distributed & Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada, Ottawa, ONT, Canada; Distributed & Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada, Ottawa, ONT, Canada",IEEE International Workshop on Haptic Audio Visual Environments and their Applications,"12 Dec 2005","2005","","","4 pp.","","We discuss our efforts in developing a hapto-visual application that medical students can use to gain valuable experience in performing eye cataract surgery on a human. Our application supports three scenarios: an instructor and a trainee in geographically distant locations interacting in real-time having the instructor tele-mentor the trainee using haptic devices at both ends; a trainee learning the surgical procedure by means of perceptual cues (e.g. projective lighting); and finally, a trainee performing the surgery without any guidance. Collaboration and remote interaction is done over the CANARIE CA*net4 photonic network. Organizationally, project development responsibilities are split into four functional components: the GUI, the graphic rendering, the haptic rendering (which includes collision detection and collision response by means of a physics engine), and networking. In this paper, we discuss our work on the four components, comment on the challenges we are facing and expect to face, and also discuss remaining work.","","0-7803-9376-7","10.1109/HAVE.2005.1545647","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1545647","","Collaboration;Surgery;Haptic interfaces;Rendering (computer graphics);Performance gain;Humans;Graphical user interfaces;Graphics;Physics;Engines","","11","","13","IEEE","12 Dec 2005","","","IEEE","IEEE Conferences"
"Virtual Coupling Schemes for Position Coherency in Networked Haptic Environments","G. Sankaranarayanan; B. Hannaford","Biorobotics Laboratory, Department of Electrical Engineering, University of Washington, Seattle, WA, USA; Biorobotics Laboratory, Department of Electrical Engineering, University of Washington, Seattle, WA, USA","The First IEEE/RAS-EMBS International Conference on Biomedical Robotics and Biomechatronics, 2006. BioRob 2006.","5 Jul 2006","2006","","","853","858","In networked haptic environments, multiple users remotely collaborate sharing the same virtual space. Such environments are used in surgical simulation training, maintenance task training, etc. Maintaining position coherency between the copies of the virtual object in these environments is necessary to achieve consistency in collaboration, especially in the presence of time delays between users. Client-server architecture is widely used to maintain position coherency in networked haptic environments. Such methods introduce a round trip delay for each user and also the collaboration depends on the client's ability to maintain communication with the server. In peer-to-peer architecture where the information from each user is multicasted to all other users, time delay is reduced to half compared to client-server based methods. It is also the most difficult method for maintaining position coherency. Of the three virtual coupling schemes introduced to maintain position coherency in this paper, two utilize a peer-to-peer architecture. The performance of the schemes using peer-to-peer architecture for constant time delays was compared to the virtual coupling scheme representing the client-server method. Experimental results demonstrate that one of the virtual coupling schemes has a comparable performance to the server-based method","2155-1782","1-4244-0040-6","10.1109/BIOROB.2006.1639197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1639197","","Intelligent networks;Haptic interfaces;Delay effects;Peer to peer computing;Collaboration;Virtual environment;Surgery;Network servers;IP networks;Humans","","23","","18","IEEE","5 Jul 2006","","","IEEE","IEEE Conferences"
"Speaking Haptics: Proactive haptic articulation for intercommunication in virtual environments","V. A. de Jesus Oliveira; L. Nedel; A. Maciel","Universidade Federal do Rio Grande do Sul (UFRGS) - Instituto de Informática (INF), Porto Alegre, RS, Brazil; Universidade Federal do Rio Grande do Sul (UFRGS) - Instituto de Informática (INF), Porto Alegre, RS, Brazil; Universidade Federal do Rio Grande do Sul (UFRGS) - Instituto de Informática (INF), Porto Alegre, RS, Brazil",2016 IEEE Virtual Reality (VR),"7 Jul 2016","2016","","","251","252","Communication is crucial in collaborative tasks. Multimodal strategies are commonly applied to complement, reinforce and disam-biguate information exchange. However, although multimodal communication is commonplace in Collaborative Virtual Environments, the proactive use of touch for intercommunication is surprisingly neglected regardless its importance for communication. In this paper, we look up to elements present in speech articulation to introduce the proactive haptic articulation as a novel approach for communication in CVEs. We defend the hypothesis that elements present in natural language, when added to the design of the vibro-tactile vocabulary, should provide an expressive medium for intercommunication. Moreover, we hypothesize that the ability to render tactile cues to a teammate will encourage users to adapt a given vocabulary spontaneously during its use. We implemented a case study around a collaborative puzzle task to demonstrate the use of such vocabulary. Results show that the proactive haptic articulation provided a way for participants to autonomously and dynamically adapt the provided tactile vocabulary to attend their communication needs during the task.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504748","H.5.1 [Information Interface and Presentation]: Multimedia Information Systems — Artificial, augmented, and virtual realities;H.5.2 [Information Interfaces & Presentation]: User Interfaces — Haptic I/O","Vocabulary;Haptic interfaces;Collaboration;Virtual environments;Electronic mail;Actuators","","1","","8","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"Discrimination of Virtual Environments Under Visual and Haptic Rendering Delays","I. Lee; S. Choi","Department of Computer Science and Engineering, Haptics and Virtual Reality Laboratory, South Korea; Department of Computer Science and Engineering, Haptics and Virtual Reality Laboratory, South Korea",2007 Frontiers in the Convergence of Bioscience and Information Technologies,"16 May 2008","2007","","","554","562","Many virtual reality systems have a distributed structure for certain purposes such as more computational power, tele-presence, collaboration, and portability. However, network delays are inevitable in the distributed structure and often make sensory information delivered behind time to the user. In the literature, the effect of network delays on the quality of virtual environments has been considered mostly with respect to task performances. In this paper, we pay attention to whether perceptual artifacts caused by network delays are perceptible by the user, which is a more stringent criterion than the degradation of task performance. We examined minimum perceptible visual and/or haptic rendering delays by measuring their discrimination thresholds between normal and delayed virtual environments with and without a task, and report the results in this paper. We also provide a simple guideline for determining whether some active delay compensation algorithms are required in a distributed virtual reality system by comparing representative network delays to the measured discrimination thresholds.","","978-0-7695-2999-8","10.1109/FBIT.2007.124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4524165","","Virtual environment;Haptic interfaces;Delay effects;Virtual reality;Computer networks;Distributed computing;Collaboration;Degradation;Error analysis;Information technology","","2","","13","IEEE","16 May 2008","","","IEEE","IEEE Conferences"
"The clutch: two-handed mobile multi-touch 3D object translation and manipulation","A. A. N. Shirehjini; M. Chegini; S. Shirmohammadi","Computer Engineering Department, Sharif University of Technology, Iran; Computer Engineering Department, Sharif University of Technology, Iran; Distributed and Collaborative Virtual Environment Research (DISCOVER) Lab, University of Ottawa, Canada","2015 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE)","21 Dec 2015","2015","","","1","5","Nowadays, handheld devices such as smartphones provide users with multi-touch input screens. Displaying interactive and touch-enabled 3D environments in such handheld devices has become popular in different applications like games or virtual reality. Technologies such as Web3D and WebGL have made the creation and display of 3D environments in mobile devices easier than ever. However, object manipulation techniques are not as well developed. For example, moving an object within the 3D environment or other similar object-specific manipulations are neither intuitive nor easy to perform. Current manipulation techniques like Gizmo that are successful in systems that use mouse and keyboard are not designed for and do not work well for multi-touch handheld devices. In this paper, we present a novel technique to perform object manipulation in 6DOF in multi-touch screens. Our performance evaluations show that our technique compared to existing techniques such as Gizmo improves task completion time by 63% while increasing task precision by 52%.","","978-1-4673-9175-7","10.1109/HAVE.2015.7359446","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359446","multi-touch 3D manipulation;mobile 3D environments;mobile 3D object translation","Three-dimensional displays;Mobile communication;Smart phones;Cameras;Handheld computers;Performance evaluation;Games","","1","","12","IEEE","21 Dec 2015","","","IEEE","IEEE Conferences"
"Novel shared control architectures for enhanced users' interaction in haptic training simulation systems","B. Khademian; K. Hashtrudi-Zaad","Department of Electrical and Computer Engineering, Queen''s University, Kingston, ONT, Canada; Department of Electrical and Computer Engineering, Queen''s University, Kingston, ONT, Canada",2009 IEEE/RSJ International Conference on Intelligent Robots and Systems,"15 Dec 2009","2009","","","886","892","This paper proposes two new multilateral shared control architectures for dual-user haptic training systems. Similar to the architecture previously proposed in, the controllers allow interaction between both users, the trainee and the trainer, as well as between the users and the virtual slave robot and environment. However, the newly proposed architectures provide increased maneuverability and enhanced sense of environment to the users. The kinesthetic performance of the proposed control architectures are analyzed under different operating conditions. Furthermore, the architectures are implemented on a dual-user haptic simulation testbed for user study experiments to investigate the effectiveness of the proposed architectures in terms of sense of environment, maneuverability, and guidance.","2153-0866","978-1-4244-3803-7","10.1109/IROS.2009.5354158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5354158","","Haptic interfaces;Robots;Master-slave;Control systems;Force control;Iron;Collaboration;Computer architecture;Performance analysis;Surgery","","8","","9","IEEE","15 Dec 2009","","","IEEE","IEEE Conferences"
"Supporting haptic collaboration across networked peers with real time force feedback in distributed virtual environments","K. M. Yap; A. Marshall; W. Yu","Virtual Engineering Centre, School of Electronics, Electrical Engineering & Computer Science, Queen's University Belfast, Belfast, UK; Virtual Engineering Centre, School of Electronics, Electrical Engineering & Computer Science, Queen's University Belfast, Belfast, UK; Virtual Engineering Centre, School of Electronics, Electrical Engineering & Computer Science, Queen's University Belfast, Belfast, UK",2007 IEEE International Conference on Telecommunications and Malaysia International Conference on Communications,"8 Feb 2008","2007","","","494","499","In this paper, we design and implement a new peer- to-peer network architecture for real time tele-haptic operation in distributed virtual environments (DVEs). We have also developed a novel force collaboration and position synchronization algorithm in order to support networked haptic interactions. In order to interact successfully in DVE with haptic devices, haptic applications require a stringent Quality of Service (QoS) service from the network. Impairments such as time delay, jitter and packet loss each have different (and severe) impacts on remote haptic collaborations. The new peer-to-peer architecture is able to support haptic interactions across time-varying networked peers. Experiments have been conducted to investigate the levels of QoS required for networked haptic collaboration. We also examine whether existing compensation algorithms can be used to enhance the performance of the system. The performance of two algorithms that compensate for delay (TiDeCtrade), and position (dead reckoning) are examined. Findings of the study, together with a set of network QoS parameter values obtained for supporting haptic collaboration over IP networks, are presented.","","978-1-4244-1093-4","10.1109/ICTMICC.2007.4448687","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4448687","Distributed virtual environments;haptic collaboration;network QoS;peer-to-peer networking","Haptic interfaces;Collaboration;Force feedback;Virtual environment;Quality of service;Delay effects;Jitter;Peer to peer computing;Dead reckoning;IP networks","","3","","19","IEEE","8 Feb 2008","","","IEEE","IEEE Conferences"
"Group Work About Geometrical Concepts Among Blind and Sighted Pupils Using Haptic Interfaces","E. -L. Sallnas; J. Moll; K. Severinson-Eklundh","Human-Computer Interaction Group School of Computer Science and Communication Royal Institute of Technology, Sweden; Human-Computer Interaction Group School of Computer Science and Communication Royal Institute of Technology, Sweden; Human-Computer Interaction Group School of Computer Science and Communication Royal Institute of Technology, Sweden",Second Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems (WHC'07),"2 Apr 2007","2007","","","330","335","In the study presented in this paper two haptic and visual prototypes for learning about geometrical concepts in group work in primary school have been designed and evaluated. The aim was for the prototypes to support collaborative learning between sighted and visually impaired pupils. The first prototype was a 3D environment, that supported learning of spatial geometry. The second prototype was a flattened 3D environment that supported learning to distinguish between angles. The two prototypes were evaluated in four schools with small groups of pupils - two sighted and one visually impaired. The results showed that the support for the visually impaired user was good and that cooperation and learning are satisfactorily supported. However, a number of interesting problems were also discovered that need to be investigated further. A promising result was that the power of the touch-based haptic interface for supporting visually impaired people was made clear","","0-7695-2738-8","10.1109/WHC.2007.61","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4145196","","Haptic interfaces;Educational institutions;Prototypes;Collaborative work;Feedback;Psychology;Virtual environment;Laboratories;Collaboration;Computer science","","19","","13","IEEE","2 Apr 2007","","","IEEE","IEEE Conferences"
"On supporting collaborative haptic interactions with physically-based 3D deformations","Z. Tang; Y. Yang; X. Guo; B. Prabhakaran","Department of Computer Science, University of Texas, Dallas, Richardson, TX, USA; Department of Computer Science, University of Texas, Dallas, Richardson, TX, USA; Department of Computer Science, University of Texas, Dallas, Richardson, TX, USA; Department of Computer Science, University of Texas, Dallas, Richardson, TX, USA",2010 IEEE International Symposium on Haptic Audio Visual Environments and Games,"9 Nov 2010","2010","","","1","6","Haptic-enabled collaborative systems have long been limited to 3D rigid models only, primarily due to slow force calculations, long-time deformable simulations and large communication loads. In this paper, we propose a novel system to support real-time sharing of haptic feedbacks and deformable simulations of physically-based 3D models in a distributed virtual environment. Particularly, adopting a spectral method, we can effectively complete force calculation and deformable simulation based on user manipulations so as to achieve real-time streaming with low network loads. In addition, we explain how our system works under two different collaborative network architectures, and analyze them separately. The experimental results confirm the validity of our approach and prove its effectiveness. Our research has a wide range of applications in such fields as education (e.g., distributed, virtual class rooms) and entertainment (e.g., gaming).","","978-1-4244-6509-5","10.1109/HAVE.2010.5623988","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5623988","haptics;collaborative virtual environments;3D deformation;interaction","Deformable models;Computational modeling;Solid modeling;Force;Three dimensional displays;Haptic interfaces;Computer architecture","","1","1","13","IEEE","9 Nov 2010","","","IEEE","IEEE Conferences"
"Fully Immersive Web-Based Collaborative Virtual Environment for Upper Limb Rehabilitation Purposes","M. Hudák; B. Sobota; Š. Korečko; M. Sivý","Department of Computers and Informatics, Faculty of Electrical Engineering and Informatics, Technical University of Košice, Slovak Republic; Department of Computers and Informatics, Faculty of Electrical Engineering and Informatics, Technical University of Košice, Slovak Republic; Department of Computers and Informatics, Faculty of Electrical Engineering and Informatics, Technical University of Košice, Slovak Republic; Department of Computers and Informatics, Faculty of Electrical Engineering and Informatics, Technical University of Košice, Slovak Republic",2020 18th International Conference on Emerging eLearning Technologies and Applications (ICETA),"22 Mar 2021","2020","","","194","199","Web-based collaborative virtual reality is emerging as platform-independent technology that permits developers to produce fully immersive and interactive virtual environments accessible through web-browsers. The use of collaborative virtual environments can be helpful in situations when therapists and patients are unable to meet personally. This work introduces an extension of the LIRKIS G-CVE system with web-based interfaces for remote management of the upper limb rehabilitation process. Concerning the quality and safety of web technologies., we consider distant virtual training to be efficient for ordinary people.","","978-1-6654-2226-0","10.1109/ICETA51985.2020.9379239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9379239","","Training;Virtual environments;Collaboration;Rapid prototyping;Real-time systems;Safety;Testing","","","","30","IEEE","22 Mar 2021","","","IEEE","IEEE Conferences"
"Mentor-Guided Learning in Immersive Virtual Environments: The Impact of Visual and Haptic Feedback on Skill Acquisition","F. Lebrun; C. Simon; A. Boukezzi; S. Otmane; A. Chellali","IBISC Lab, Université Evry Paris-Saclay, France; IBISC Lab, Université Evry Paris-Saclay, France; IBISC, Algerian Higher National School of Computer Science, France; IBISC Lab, Université Evry Paris-Saclay, France; IBISC Lab, Université Evry Paris-Saclay, France",IEEE Transactions on Visualization and Computer Graphics,"25 Apr 2025","2025","31","5","3547","3557","In the early stages of learning a technical skill, trainees require guidance from a mentor through augmented feedback to develop higher expertise. However, the impact of such feedback and the different modalities used to communicate it remain underexplored in immersive virtual environments (IVE). This paper presents a study in which 27 participants were divided into three groups to learn a tool manipulation trajectory in an IVE. Two experimental groups received guidance from an expert using visual and/or haptic augmented feedback, while the control group received no feedback. The results indicate that both experimental groups showed significantly greater improvement in tool trajectory performance than the control group from pre- to post-test, with no significant differences between them. Analysis of their learning curves revealed similar performance improvements in tool trajectory across trials, outperforming the control group. Additionally, the visual-haptic feedback condition was linked to lower task load in three out of six dimensions of the NASA-TLX and a higher perceived interdependence with the expert's actions. These findings suggest that augmented feedback from an expert enhances the learning of tool manipulation skills. Although adding haptic feedback did not lead to better learning outcomes compared to visual feedback alone, it did enhance the overall user experience. These results offer valuable insights for designing IVEs that support mentor-trainee interactions through augmented feedback.","1941-0506","","10.1109/TVCG.2025.3549547","Agence Nationale de la Recherche(grant numbers:ANR-20-CE33-0010 Show-me); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10918861","Multimodal interactions;Augmented feedback;Mentorship;Remote collaboration;Immersive learning","Visualization;Haptic interfaces;Motors;Collaboration;Training;Hands;Virtual environments;Trajectory;Timing;Visual communication","Humans;Female;Male;Virtual Reality;Adult;Young Adult;Computer Graphics;Learning;Mentors;Feedback, Sensory;User-Computer Interface","","","77","IEEE","10 Mar 2025","","","IEEE","IEEE Journals"
"Geometrically Consistent Projection-Based Tabletop Sharing for Remote Collaboration","D. Iwai; R. Matsukage; S. Aoyama; T. Kikukawa; K. Sato","Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Japan",IEEE Access,"2 Mar 2018","2018","6","","6293","6302","Projection-based tabletop sharing (PBTS) systems allow a local user to share a pointing gesture or a handwritten note on a tabletop document with a remote user who places the same document on a tabletop by projecting the upper limb image of the local user onto the remote document and tabletop. A vertical display is used to share an image of the upper body, including the face of the remote user. However, in previous systems, the spatial layouts of the shared documents must be identical on both tabletops, and the projected upper limb is not extended from the upper body image of the remote user. This paper proposes a PBTS system to address such geometric consistency issues to improve remote collaboration. First, we propose to maintain the geometric consistency of a pointing gesture and handwritten note between each pair of the shared documents rather than between the entire tabletops. This allows users to freely change the document layouts on both tabletops. Second, we propose to overlay the upper limb image such that it is extended from the vertical display, where the upper body image is shown. This is achieved by rotating the upper limb image around the fingertip that performs the pointing gestures or around the tip of the pen used to write notes. We constructed a prototype to determine if the proposed system resolves the geometric consistency issues. Then, we evaluated how accurately a user can convey a pointing position to a distant partner when the document layouts differ between the remote tabletops. Finally, we evaluated how the user experience, particularly the social presence, is improved by the proposed geometrically consistent upper limb direction.","2169-3536","","10.1109/ACCESS.2017.2781699","JSPS KAKENHI(grant numbers:JP16H02859); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8172039","Spatial augmented reality;remote collaboration;tabletop sharing;projection mapping","Layout;Collaboration;Cameras;Robustness;Feature extraction;Servers;Face","","22","","34","OAPA","11 Dec 2017","","","IEEE","IEEE Journals"
"Semantic Communication for Capacity-aware Remote Collaboration","T. Amano; S. M. Kala; T. Mizumoto; H. Yamaguchi","Graduate School of Information Science and Technology, Osaka University, Suita, Japan; Graduate School of Information Science and Technology, Osaka University, Suita, Japan; Graduate School of Information Science and Technology, Osaka University, Suita, Japan; Graduate School of Information Science and Technology, Osaka University, Suita, Japan","2022 18th International Conference on Wireless and Mobile Computing, Networking and Communications (WiMob)","15 Nov 2022","2022","","","381","386","The global spread of coronavirus has sparked a considerable interest in technologies that facilitate seamless communication between users which are physically or spatially distant. Using current remote collaboration systems that utilize 3D sensing with LiDAR and depth cameras, point cloud streaming, and MR/VR devices, distant users can communicate with each other as if they did in person. However, these systems may violate users' privacy since they can share information of their entire personal space with other users. In addition, although various point cloud compression methods have been proposed, remote transmission of 3D scenes still requires significant bandwidth. This paper proposes a 3D spatial data sharing system based on the paradigm of “semantic communication”, i.e., controlling communication in the units of semantic objects. Our system understands the semantics of the scene and leverages point cloud streaming, thereby enabling users to assert fine-grained control over their privacy. Further, the system adaptively controls the size of the data frame based on network capacity and scene context. The experimental results show that the network delay can be reduced by 96%. We have also tested our system in a commercial 4G network, showing that 3-D spatial sharing with point clouds over severe networks is possible.","2160-4894","978-1-6654-6975-3","10.1109/WiMob55322.2022.9941595","NICT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9941595","Remote Collaboration;Semantic Communication;Point Cloud;MR/VR","Point cloud compression;Privacy;Wireless sensor networks;Three-dimensional displays;Semantics;Collaboration;Computer architecture","","4","","17","IEEE","15 Nov 2022","","","IEEE","IEEE Conferences"
"Haptic Rendering of Volumetric Data for Cranial Implant Modeling","Zhuming Ai; R. Evenhouse; M. Rasmussen","VRMedlab, Department of Biomedical and Health Information Sciences, University of Illinois, Chicago, Chicago, IL, USA; VRMedlab, Department of Biomedical and Health Information Sciences, University of Illinois, Chicago, Chicago, IL, USA; VRMedlab, Department of Biomedical and Health Information Sciences, University of Illinois, Chicago, Chicago, IL, USA",2005 IEEE Engineering in Medicine and Biology 27th Annual Conference,"10 Apr 2006","2005","","","5124","5127","A force feedback algorithm for cranial implant design is presented in this paper. The algorithm is applied directly on volumetric data. It is a proxy-based algorithm, and a spherical proxy is used to accurately calculate the force between the sculpting tool and the skull. Based on this algorithm a cranial implant modeling system is implemented, and an implant for a simulated defect is designed","1558-4615","0-7803-8741-4","10.1109/IEMBS.2005.1615630","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1615630","","Haptic interfaces;Cranial;Implants;Skull;Force feedback;Algorithm design and analysis;Stereolithography;Computational modeling;Injuries;Diseases","","1","","17","IEEE","10 Apr 2006","","","IEEE","IEEE Conferences"
"Quality of service issues for distributed virtual environments with haptic interfaces","A. Marshall; K. M. Yap; W. Yu","School of Electronics, Electrical Engineering & Computer Science, Queen's University Belfast, U.K.; School of Electronics, Electrical Engineering & Computer Science, Queen's University Belfast, U.K.; School of Electronics, Electrical Engineering & Computer Science, Queen's University Belfast, U.K.",2008 IEEE 10th Workshop on Multimedia Signal Processing,"5 Nov 2008","2008","","","40","45","Currently all interactions that occur between ourselves and communications networks involve only two senses (aural and visual). Moreover all these networks, including the Internet, have been designed to carry application information pertaining to these two senses (e.g. telephony, video, graphics, and text). It is clear that by introducing into networks the ability to carry information relating to other senses opens up an enormous potential for new and improved applications. However it is also clear that the network service needed to support other senses such as touch (haptics) will be significantly different from that which currently exists. The effective transmission of the sense of touch (haptics) presents a significant challenge to the current Internet architecture. Haptic information originates from a different human sense; therefore the quality of service (QoS) required to support this type of traffic is significantly different from that used to support conventional real-time traffic such as voice or video. To date there has been no specific provision of QoS parameters for haptic interaction, and each type of network impairment has different (and severe) impacts on the userpsilas haptic experience. This paper describes some of the issues and challenges that are presented whenever remote haptic interactions with virtual environments are considered, and identifies a number of techniques, in the network and in the end applications, that can be used to improve performance of such systems.","","978-1-4244-2294-4","10.1109/MMSP.2008.4665046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4665046","","Haptic interfaces;Delay;Jitter;Virtual environment;Quality of service;Force;Collaboration","","10","","24","IEEE","5 Nov 2008","","","IEEE","IEEE Conferences"
"Multi-rate Control Architectures for Dextrous Haptic Rendering in Cooperative Virtual Environments","M. Fotoohi; S. Sirouspour; D. Capson","Department of Electrical and Computer Engineering, McMaster University, Hamilton, ONT, Canada; Department of Electrical and Computer Engineering, McMaster University, Hamilton, ONT, Canada; Department of Electrical and Computer Engineering, McMaster University, Hamilton, ONT, Canada",Proceedings of the 45th IEEE Conference on Decision and Control,"7 May 2007","2006","","","4478","4483","This paper is concerned with haptic simulation in multi-user virtual environments in which the users can haptically interact in a shared virtual world from separate workstations over an Ethernet local-area network (LAN). High-fidelity haptic rendering requires a minimum control update rate of 1000Hz which is beyond the capability of popular network protocols such as the UDP and TCP/IP. Consequently, a multi-rate control strategy is adopted in which local force-feedback loops are executed at higher rates than data packet transmission between the user workstations. Two control architectures, i.e. centralized and distributed, are presented and their stability margins are compared. Two methods for mathematical modelling and analysis of the proposed multi-rate haptic control systems are examined. Analytical and experimental results demonstrate that the distributed control architecture is superior to the centralized controller from performance and stability perspectives. This is confirmed through experiments with a dual-user dual-finger haptic rendering platform","0191-2216","1-4244-0171-2","10.1109/CDC.2006.377163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4177717","Haptic Interfce Control;Cooperative Haptics;Collaborative Haptics;Multi-user Haptics;Collaborative Virtual Environments;Multi-rate Systems","Haptic interfaces;Virtual environment;Workstations;Local area networks;Force control;Centralized control;Ethernet networks;Protocols;TCPIP;Stability","","2","","18","IEEE","7 May 2007","","","IEEE","IEEE Conferences"
"RoboHapalytics: A Robot Assisted Haptic Controller for Immersive Analytics","S. Dai; J. Smiley; T. Dwyer; B. Ens; L. Besancon","Monash University, Australia; Monash University, Australia; Monash University, Australia; Monash University, Australia; Linköping University, Sweden",IEEE Transactions on Visualization and Computer Graphics,"16 Dec 2022","2023","29","1","451","461","Immersive environments offer new possibilities for exploring three-dimensional volumetric or abstract data. However, typical mid-air interaction offers little guidance to the user in interacting with the resulting visuals. Previous work has explored the use of haptic controls to give users tangible affordances for interacting with the data, but these controls have either: been limited in their range and resolution; were spatially fixed; or required users to manually align them with the data space. We explore the use of a robot arm with hand tracking to align tangible controls under the user's fingers as they reach out to interact with data affordances. We begin with a study evaluating the effectiveness of a robot-extended slider control compared to a large fixed physical slider and a purely virtual mid-air slider. We find that the robot slider has similar accuracy to the physical slider but is significantly more accurate than mid-air interaction. Further, the robot slider can be arbitrarily reoriented, opening up many new possibilities for tangible haptic interaction with immersive visualisations. We demonstrate these possibilities through three use-cases: selection in a time-series chart; interactive slicing of CT scans; and finally exploration of a scatter plot depicting time-varying socio-economic data.","1941-0506","","10.1109/TVCG.2022.3209433","Australian Research Council's Discovery Projects funding scheme(grant numbers:DP180100755); Knut and Alice Wallenberg Foundation(grant numbers:KAW 2019.0024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9903598","Haptic Feedback;Human Centred Interaction;Robotic Arm","Robots;Haptic interfaces;Robot kinematics;Manipulators;Data visualization;Three-dimensional displays;Affordances","","5","","76","IEEE","26 Sep 2022","","","IEEE","IEEE Journals"
"Co-actuated table creating a sense of co-presence in shared virtual environments","S. Wesugi; Y. Miwa","Graduate School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; Waseda University, Shinjuku, Tokyo, Japan","IEEE International Conference on Systems, Man and Cybernetics","29 Jan 2003","2002","2","","606","611","","1062-922X","0-7803-7437-1","10.1109/ICSMC.2002.1173481","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1173481","","Space technology;Virtual environment;Collaborative work;Internet;Buildings;Prototypes;Avatars;Augmented reality;Microcomputers;Spatial resolution","","","","12","IEEE","29 Jan 2003","","","IEEE","IEEE Conferences"
"Putting Haptics into the Ambience","K. E. MacLean","Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Haptics,"28 Aug 2009","2009","2","3","123","135","In an attentionally overloaded world, relief will come only from interfaces between humans and computation that are able to provide information in the background of our sensory and cognitive processes. Haptic displays may have a special role to play in this emerging movement toward ambient interfaces, because the touch sense is well suited to present many types of information in a way that treads lightly on our mental resources. This paper offers an introduction to the notion of ambient information display, and explores why and how the haptic channel could contribute. It begins with a discussion of the attentional problems posed by contemporary interface technology, and a broad overview of ambient interfaces themselves: their purpose, specification, features, and some general examples. Sense is made of the haptic ambient design space through a morphology of the functionality and social configurations exhibited by existing and envisioned examples. Finally, reflections on design principles and challenges for ambient haptic interfaces are aimed at inspiring, shaping, and informing future development in this area.","2329-4051","","10.1109/TOH.2009.33","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5184837","Haptic I/O;human computer interaction (HCI);human information processing;ambient interfaces.","Haptic interfaces;Displays;Space technology;Human computer interaction;Cellular phones;Writing;Computer interfaces;Morphology;Optical reflection;Information processing","","49","","100","IEEE","31 Jul 2009","","","IEEE","IEEE Journals"
"Effect of Packet Loss on Collaborative Haptic Interactions in Networked Virtual Environments: An Experimental Study","J. Qin; K. Choi; R. Xu; W. Pang; P. Heng","Shenzhen Institute of Advanced Technology, Chinese Academy of Science; Centre for Integrative Digital Health, School of Nursing, The Hong Kong Polytechnic University; Shenzhen Institute of Advanced Technology, Chinese Academy of Science; Department of Computer Science, Caritas Institute of Higher Education; Department of Computer Science and Engineering, The Chinese University of Hong Kong",Presence,"19 May 2014","2013","22","1","36","53","It has been widely demonstrated that haptic interaction can enrich the sense of copresence of distributed users and improve their performance in collaborative virtual environments (CVEs). However, the influence of network traffic on haptic collaboration, particularly packet loss in haptic data streams, is still largely unknown. In order to investigate this effect, we designed and conducted a series of experiments on a simulated lossy network. First, a single-user interactive task was designed to estimate the just- noticeable packet loss threshold in terms of the length of burst loss (LBL). Second, a CVE was developed in which two users are required to work together on a goal-directed task through haptic collaboration. Experiments were performed to evaluate the users' task performance at different packet loss rates and their perception using subjective measurements. Finally, the effect of packet loss combined with network latency was investigated. The findings are: (1) the threshold LBL value for haptic discontinuity to become noticeable is 60.18 ms; (2) haptic collaboration performance is sensitive to packet loss rate; and (3) while the combined effect of packet loss and communication delay adversely affects collaborative haptic interactions, the influence due to packet loss rate is dominant when the delay is below a certain threshold. These results can serve as a guiding reference for the design and development of virtual telepresence systems with rich haptic collaborations.","1054-7460","","10.1162/PRES_a_00132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6797288","","","","3","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Control Synthesis and ISS Stability Analysis of a Dual-User Haptic Training System Based on S-Shaped Function","M. Motaharifar; H. D. Taghirad; K. Hashtrudi-Zaad; S. F. Mohammadi","Advanced Robotics and Automated Systems, Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Advanced Robotics and Automated Systems, Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada; Translational Ophthalmology Research Center, Farabi Eye Hospital, Tehran University of Medical Sciences, Tehran, Iran",IEEE/ASME Transactions on Mechatronics,"14 Aug 2019","2019","24","4","1553","1564","The controller design and stability analysis of a dual user training haptic system is studied. Most of the previously proposed control methodologies for this system have not simultaneously considered special requirements of surgery training and stability analysis of the nonlinear closed-loop system which is the objective of this paper. In the proposed training approach, the trainee is allowed to freely experience the task and be corrected as needed, while the trainer maintains the task dominance. A special S-shaped function is suggested to generate the corrective force according to the magnitude of motion error between the trainer and the trainee. The closed-loop stability of the system is analyzed considering the nonlinearity of the system components using the Input-to-State Stability approach. Simulation and experimental results show the effectiveness of the proposed approach.","1941-014X","","10.1109/TMECH.2019.2917448","National Institute for Medical Research Development(grant numbers:942314); K. N. Toosi University of Technology Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8717693","Dual user;haptics;Input-to-State Stability (ISS) analysis;S-shaped function;surgery training","Haptic interfaces;Training;Stability analysis;Force;Surgery;Task analysis;Symmetric matrices","","21","","26","IEEE","17 May 2019","","","IEEE","IEEE Journals"
"Control of Dual-User Haptic Training System With Online Authority Adjustment: An Observer-Based Adaptive Robust Scheme","M. Motaharifar; H. D. Taghirad; K. Hashtrudi-Zaad; S. F. Mohammadi","Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Advanced Robotics and Automated Systems (ARAS), Industrial Control Center of Excellence, Faculty of Electrical Engineering, K. N. Toosi University of Technology, Tehran, Iran; Department of Electrical and Computer Engineering, BioRobotics Research Laboratory, Queen’s University, Kingston, ON, Canada; Translational Ophthalmology Research Center, Farabi Eye Hospital, Tehran University of Medical Sciences, Tehran, Iran",IEEE Transactions on Control Systems Technology,"8 Oct 2020","2020","28","6","2404","2415","The design problem for the control a dual-user haptic surgical training system is studied in this article. The system allows the trainee to perform the task on a virtual environment, while the trainer is able to interfere in the operation and correct probable mistakes made by the trainee. The proposed methodology allows the trainer to transfer the task authority to or from the trainee in real time. The robust adaptive nature of the controller ensures position tracking. The stability of the closed-loop system is analyzed using the input-to-output stability approach and the small-gain theorem. Simulation and experimental results are presented to validate the effectiveness of the proposed control scheme.","1558-0865","","10.1109/TCST.2019.2946943","National Institute for Medical Research Development (NIMAD)(grant numbers:942314); Tehran University of Medical Sciences, Tehran, Iran(grant numbers:35949-43-01-97); K. N. Toosi University of Technology, Tehran, Iran Research Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8886365","Dual-user haptics;robust adaptive control;stability;surgical training;task dominance","Haptic interfaces;Task analysis;Training;Stability analysis;Force;Robots;Surgery","","12","","22","IEEE","30 Oct 2019","","","IEEE","IEEE Journals"
"Virtual coupling design for stability and transparency of multi-device haptic systems with delays","G. Bianchini; D. Prattichizzo","Dipartimento di Inceqneria dell'Informazione e Scienze Matematiche, Università di Siena, Italy; Advanced Robotics Department, Istituto Italiano di Tecnologia, Genova, Italy",2013 World Haptics Conference (WHC),"7 Oct 2013","2013","","","223","228","This paper deals with haptic systems involving multiple human operators and devices with computational and communication delays. A method is proposed for the design of stabilizing controllers which also guarantee transparency, i.e., controllers are designed to mitigate the impact of delays and of the controllers themselves on the realism of the tactile interaction. The proposed approach exploits an extension of a previously developed passivity-based framework for stabilization combined with a special loop shaping-like technique. The design procedure involves the solution of a sequence of Linear Matrix Inequality (LMI) optimization problems.","","978-1-4799-0088-6","10.1109/WHC.2013.6548412","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6548412","","Haptic interfaces;Delays;Virtual environments;Couplings;Symmetric matrices;Stability criteria","","3","","21","IEEE","7 Oct 2013","","","IEEE","IEEE Conferences"
"Effects of Packet Loss and Latency on the Temporal Discrimination of Visual-Haptic Events","Z. Shi; H. Zou; M. Rank; L. Chen; S. Hirche; H. J. Muller","Allgemeine und Experimentelle Psychologie, Ludwig-Maximilians University of Munich, Munich, Germany; Allgemeine und Experimentelle Psychologie, Graduate School of Systemic Neurosciences, Ludwig-Maximilians University of Munich, Munich, Germany; Information-Oriented Control, Institute of Automatic Control Engineering, Technische Universität München, Munich, Germany; Allgemeine und Experimentelle Psychologie, Ludwig-Maximilians University of Munich, Munich, Germany; Information-Oriented Control, Institute of Automatic Control Engineering, Technische Universität München, Munich, Germany; Allgemeine und Experimentelle Psychologie, Ludwig-Maximilians University of Munich, Munich, Germany",IEEE Transactions on Haptics,"25 Mar 2010","2010","3","1","28","36","Temporal discontinuities and delay caused by packet loss or communication latency often occur in multimodal telepresence systems. It is known that such artifacts can influence the feeling of presence [1]. However, it is largely unknown how the packet loss and communication latency affect the temporal perception of multisensory events. In this article, we simulated random packet dropouts and communication latency in the visual modality and investigated the effects on the temporal discrimination of visual-haptic collisions. Our results demonstrated that the synchronous perception of crossmodal events was very sensitive to the packet loss rate. The packet loss caused the impression of time delay and influenced the perception of the subsequent events. The perceived time of the visual event increased linearly, and the temporal discrimination deteriorated, with increasing packet loss rate. The perceived time was also influenced by the communication delay, which caused time to be slightly overestimated.","2329-4051","","10.1109/TOH.2009.45","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5306068","Visual-haptic temporal perception;packet loss;psychophysics;perception.","Humans;Delay effects;Psychology;Propagation losses;Teleoperators;Automatic control;Quality of service;Games;Orbital robotics;Haptic interfaces","","34","","32","IEEE","30 Oct 2009","","","IEEE","IEEE Journals"
"Haptic perception of multi-joint hypertonia during simulated patient-therapist physical tele-interaction","D. Piovesan; A. Melendez-Calderon; F. A. Mussa-Ivaldi","Sensory Motor Performance Program, Rehabilitation Institute of Chicago, Illinois, U.S.A; Sensory Motor Performance Program, Rehabilitation Institute of Chicago, Illinois, U.S.A; Sensory Motor Performance Program, Rehabilitation Institute of Chicago, Illinois, U.S.A",2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"26 Sep 2013","2013","","","4143","4147","A potential solution to provide individualized physical therapy in remote areas is tele-interaction via robotic devices. To maintain stability during tele-interaction, transmission delay-compensation algorithms bound the impedance between the patient and the therapist. This can compromise the haptic perception of the patient being assessed, which can in turn lead to a bad diagnosis or intervention. We investigated how the perception of the severity of hypertonia (a common condition after neurological disorders) varied by modifying the connection impedance on a physical simulator. We found that assessing hypetonia using a low impedance connection may result in an overestimation of mild impairments.","1558-4615","978-1-4577-0216-7","10.1109/EMBC.2013.6610457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6610457","hypertonia;haptic perception;tele-rehabilitation","Muscles;Haptic interfaces;Joints;Robots;Force;Elbow;Impedance","Adult;Computer Simulation;Humans;Joints;Muscle Hypertonia;Patient Simulation;Physical Therapy Modalities;Telemetry;Touch Perception","4","","32","IEEE","26 Sep 2013","","","IEEE","IEEE Conferences"
"Accessibility and scalability in collaborative eCommerce environments","M. Khoury; S. Shirmohammadi","Distributed Collaborative Virtual Environment Research Laboratory (DISCOVER), School of Information Technology and Engineering (SITE), University of Ottawa, Canada; Distributed Collaborative Virtual Environment Research Laboratory (DISCOVER), School of Information Technology and Engineering (SITE), University of Ottawa, Canada",2007 2nd International Conference on Digital Information Management,"31 Jan 2008","2007","2","","738","743","The Much advancement has lately occurred in eCommerce systems’ interfaces. Product specifications listings combined with pictures is no longer considered the benchmark for eCommerce interfaces. Albeit commercial websites haven’t ventured in these developments, academic research has tried, through this progression, to mimic the real-life shopping experience. Shopping in real-life is a social experience with other components attached to it: customers consult with experts and shop in groups benefiting from others’ opinions. These aspects, when lacking, can lead to reduction in sales. In this paper, we build on a collaborative eCommerce system. The system adopts concepts from virtual environments, allowing customers to interact with three-dimensional models of the items of interests in the virtual shop, as well as share those items with other customers or ask for expert opinions, in real-time. Our system addresses accessibility, by using Macromedia Shockwave, a widely deployed player, and therefore avoids the need of unusual plug-ins, such as VRML viewers. The system also addresses scalability, by using a peer-to-peer communications architecture to support a number of geographically dispersed users on the Internet simultaneously.","","978-1-4244-1475-8","10.1109/ICDIM.2007.4444312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4444312","","Scalability;Collaboration;Electronic commerce;Virtual environment;Internet;Marketing and sales;Peer to peer computing;Information technology;Real time systems;Web sites","","3","","13","IEEE","31 Jan 2008","","","IEEE","IEEE Conferences"
"Haptic media synchronization using time adjustment algorithm for noncollaborative telehaptics","O. Wongwirat; S. Ohara","Graduate School of Engineering, Tokai University, Hiratsuka, Kanagawa, Japan; Graduate School of Engineering, Tokai University, Hiratsuka, Kanagawa, Japan","IEEE International Conference on Mechatronics, 2005. ICM '05.","14 Nov 2005","2005","","","555","561","Haptic applications in noncollaborative telehaptics include remote surgery and remote manipulation that use a haptic device as a robot arm in master/slave manner. The problem of haptic applications in the noncollaborative telehaptics comes from a delay variation on networks. The delay variation causes in change of an update sequence interval of haptic media at a remote haptic process. Thereby, it results in operational instability of the remote haptic device that appears in the form of jolting and buzzing of haptic display. This paper introduces a method of synchronization to solve an interval fluctuation of the update haptic sequence resulting from the delay variation. The control mechanism of our synchronization employs a buffer to compensate the delay and uses the time adjustment algorithm to solve the interval fluctuation for smoothing the haptic display. The model of noncollaborative telehaptics applications and the derivation of synchronization control mechanism are detailed in the paper. Performance measurement of the synchronization is investigated by simulations under the regional network delay and the delay variations resulting from light, moderate, and high traffic conditions. The optimum buffer criteria under each traffic condition are also verified in the simulation. The results express that the operational stability of remote haptic device can be achieved by the proposed synchronization when the optimum buffer criteria are chosen as specified on each traffic condition.","","0-7803-8998-0","10.1109/ICMECH.2005.1529318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1529318","","Haptic interfaces;Traffic control;Displays;Fluctuations;Communication system traffic control;Surgery;Robots;Master-slave;Delay effects;Smoothing methods","","2","","21","IEEE","14 Nov 2005","","","IEEE","IEEE Conferences"
"Game Engine Based Application for Neurorehabilitation in Collaborative Virtual Reality","Š. Korečko; P. Nehila; B. Sobota","Department of Computers and Informatics, Faculty of Electrical Engineering and Informatics, Technical University of Košice, Košice, Slovak Republic; Department of Computers and Informatics, Faculty of Electrical Engineering and Informatics, Technical University of Košice, Košice, Slovak Republic; Department of Computers and Informatics, Faculty of Electrical Engineering and Informatics, Technical University of Košice, Košice, Slovak Republic",2023 21st International Conference on Emerging eLearning Technologies and Applications (ICETA),"12 Dec 2023","2023","","","313","317","Virtual reality is used for a wide range of applications nowadays. It can also be used for medical purposes, for example in the process of therapy and rehabilitation of patients. The advantage of applying virtual reality to the rehabilitation process is the possibility of creating interesting and immersive virtual environments and scenarios. Based on an analysis of the technology’s potential uses and current solution, we have created an application in Unity game engine that will allow patients and therapists to collaborate in a shared virtual environment. The application includes several simple scenarios that can be expanded and combined into more complex, engaging sequences in the future, as well as interface to communicate with external environments to assess the patient’s actions via electroencephalography.","","979-8-3503-7069-0","10.1109/ICETA61311.2023.10344065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10344065","Collaborative virtual environment;Neurorehabilitation;virtual reality;Unity game engine;EEG","Headphones;Electronic learning;Collaboration;Virtual environments;Medical treatment;Games;Immersive experience","","2","","14","IEEE","12 Dec 2023","","","IEEE","IEEE Conferences"
"Distributed Architecture for Remote Collaborative Modification of Parametric CAD Data","Y. Okuya; N. Ladeveze; O. Gladin; C. Fleury; P. Bourdot","VENISE group, LIMSI/CNRS, Universite Paris-Saclay, Orsay, France; VENISE group, LIMSI/CNRS, Universite Paris-Saclay, Orsay, France; LRI, Univ. Paris-Sud, CNRS, Inria, Universite Paris-Saclay, Orsay, France; LRI, Univ. Paris-Sud, CNRS, Inria, Universite Paris-Saclay, Orsay, France; VENISE group, LIMSI/CNRS, Universite Paris-Saclay, Orsay, France",2018 IEEE Fourth VR International Workshop on Collaborative Virtual Environments (3DCVE),"7 Feb 2019","2018","","","1","4","Companies are now using Virtual Reality (VR) for collaborative design reviews on digital mock-ups. These meetings often involve remote collaborators due to current trends towards decentralization of work organization. While lots of previous works proposed distributed architectures for implementing Collaborative Virtual Environments (CVE), modifying native CAD parts in such environments is challenging. There are two main difficulties: (i) how to directly modify native CAD data (i.e. data used internally in CAD software) from the virtual environment, and (ii) how to manage collaborative modifications of such data by remote users. Most common VR-CAD applications require data conversions before the VR session and post-modifications of original CAD data afterwards. Only a few VR applications allow direct modifications of native CAD data, but they do not support remote collaboration. In this paper, we propose a distributed architecture allowing collaborative modifications of native CAD data from remote and heterogeneous platforms. Technically, a VR-CAD server embedding a CAD engine is included in our architecture to load and modify native CAD data according to remote requests. A proof of concept uses our architecture to connect a wall-sized display and a CAVE-like system.","","978-1-5386-5132-2","10.1109/3DCVE.2018.8637112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8637112","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Collaborative and social computing;Computer supported cooperative work","Collaboration;Servers;Virtual environments;Engines;Software;Couplings;Distributed databases","","8","","10","IEEE","7 Feb 2019","","","IEEE","IEEE Conferences"
"An MR Remote Collaborative Platform Based on 3D CAD Models for Training in Industry","P. Wang; X. Bai; M. Billinghurst; S. Zhang; D. Han; H. Lv; W. He; Y. Yan; X. Zhang; H. Min","Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China; Cyber-Physical Interaction Laboratory, Northwestern Polytechnical University, Xi'an, China",2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"9 Jan 2020","2019","","","91","92","In this paper, we describe a new Mixed Reality (MR) remote collaborative platform making use of 3D CAD models for training in the manufacturing industry. It enables a remote expert in Virtual Reality (VR) to train a local worker in a physical assembly task. For the local site, we use Spatial Augmented Reality (SAR) to enable the local worker see virtual cues without wearing any AR devices, leaving their user hands free to easily manipulate the physical parts. For the remote expert, we construct a 3D virtual environment using virtual replicas of the physical parts. We also report on the results of a usability study of the prototype.","","978-1-7281-4765-9","10.1109/ISMAR-Adjunct.2019.00038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951982","Remote collaboration;3D CAD models;training in the industry;Augmented Reality;Mixed reality","Three-dimensional displays;Training;Collaboration;Solid modeling;Task analysis;Virtual reality;Usability","","21","","6","IEEE","9 Jan 2020","","","IEEE","IEEE Conferences"
"Effects of visual and haptic latency on touchscreen interaction: A case study using painting task","J. R. Kim; R. H. Osgouei; S. Choi","Next Generation Visual Computing Laboratory, Electronics and Telecommunications Research Institute (ETRI), Daejeon, Republic of Korea; Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), Pohang, Gyeongbuk, Republic of Korea; Department of Computer Science and Engineering, Pohang University of Science and Technology (POSTECH), Pohang, Gyeongbuk, Republic of Korea",2017 IEEE World Haptics Conference (WHC),"27 Jul 2017","2017","","","159","164","This paper reports a user study on the effects of latency in visual and haptic feedback on touchscreen interaction for a painting task. Our work was motivated by recently emerging multimodal use of touchscreens and electrostatic friction displays with high-quality 3D graphics. We designed and implemented a painting application on a touchscreen that enabled users to paint a 3D sculpture with their finger pad while perceiving haptic feedback through electrovibration. Software-induced latency was varied from 0 to 120 ms for both visual and haptic feedback. Participants' task was to paint on the 3D sculpture as quickly and accurately as possible. For performance assessment, we measured task completion time and execution error. We also obtained subjective responses to four questions (easiness, responsiveness, pleasantness, and the sense of control) related to user experiences. Experiment results indicated that visual latency is critical for both task completion time and task execution error whereas haptic latency is for task execution error, but not for task completion time. Both latencies affected the subjective responses, but visual latency had more apparent effects.","","978-1-5090-1425-5","10.1109/WHC.2017.7989894","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7989894","","Haptic interfaces;Visualization;Three-dimensional displays;Painting;Friction;Electrostatics;Time measurement","","6","","27","IEEE","27 Jul 2017","","","IEEE","IEEE Conferences"
"Haptic-Based Serious Games","X. Hou; O. Sourina; S. Klimenko","Fraunhofer IDM@NTU Nanyang Technological University, Singapore; Fraunhofer IDM@NTU Nanyang Technological University, Singapore; Moscow Institute of Physics and Technology, Russia",2014 International Conference on Cyberworlds,"15 Dec 2014","2014","","","39","46","Recently, new interactive devices such as hap tic devices became available for game development. 6DOF hap tic devices give the user an opportunity ""to feel"" the simulated virtual environment in the way similar to the real world. Hap tic-based interaction can add a new dimension to ""serious games"" development. The user can ""feel"" objects surfaces and complex objects interaction forces in a 3D virtual environment. In this paper, we propose two hap tic-based serious games. In the first ""T Puzzle"" game, the user can ""feel"" the weight of objects, rotate and move the 3D puzzle pieces in the virtual world. This game can be used to improve the user's spatial abilities. In the second ""Mol Docking"" game, the player can feel interaction forces between molecular systems and learn the process of molecular docking in collaborative virtual environment.","","978-1-4799-4677-8","10.1109/CW.2014.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6980741","haptics;serious games;multimodal interaction","Games;Haptic interfaces;Force;Rendering (computer graphics);Torque;Virtual environments;Shape","","8","","29","IEEE","15 Dec 2014","","","IEEE","IEEE Conferences"
"Foundations of Transparency in Tactile Information Design","K. E. MacLean","Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Haptics,"2 Dec 2008","2008","1","2","84","95","This paper places contemporary literature on the topic of unimodal, single-site display of information using complex tactile signals in the context of progress towards the achievement of transparent communication - placing minimal load on the user's attentional resources. We discuss recent evidence that more is possible with purely haptic display than is commonly believed, as well as procedural developments that support systematic design of transparent tactile information display; and we frame the advances required to realize significant benefits with the technology we have now. Examples used and objectives thus identified focus on establishing effective information representations, and outlining efficient tools and processes for perceptually guiding icon design. Our discussion is inspired by Weiser's vision of calm technology based on locatedness and seamless movement between center and periphery, and it is organized along the lines of potential utility, form and learning.","2329-4051","","10.1109/TOH.2008.20","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4674348","Human information processing;Haptic I/O;Input devices and strategies;User-centered design;Human information processing;Haptic I/O;Input devices and strategies;User-centered design","Displays;Haptic interfaces;Information representation;Humans;Space technology;Signal design;Context;Information processing;User centered design;Resists","","68","1","61","IEEE","17 Nov 2008","","","IEEE","IEEE Journals"
"Haptic Relocation of Virtual Finger Forces via Pneumatic Wrist-Worn Haptic Devices","J. E. Palmer; B. B. Vuong; Z. Zhakypov; Y. Qin; L. Tilton; A. M. Okamura","Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA",2024 IEEE Haptics Symposium (HAPTICS),"10 May 2024","2024","","","315","320","Relocation of finger interaction forces in a virtual environment is enabled using soft, 3D-printed, pneumatic wrist-worn haptic devices called Hoxels, which display up to 20 N of force normal to the skin. Due to off-board pumps and flexible pneumatic transmission lines, the worn mass of a pair of Hoxels is only 75 grams. We performed a user study in which participants grasped and moved a cube in a virtual environment, with virtual interaction forces displayed to the wrist. Dual-tactor and single-tactor relocated haptic feedback reduced grasp forces compared no haptic feedback. This lays the foundation for multi-degree-of-freedom feedback to the wrist, leaving the fingers unencumbered for mixed reality applications.","2324-7355","979-8-3503-4511-7","10.1109/HAPTICS59260.2024.10520855","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10520855","","Wrist;Performance evaluation;Power transmission lines;Fingers;Force;Virtual environments;Mixed reality","","2","","17","IEEE","10 May 2024","","","IEEE","IEEE Conferences"
"A breeze enhances presence in a virtual environment","S. Noel; S. Dumoulin; T. Whalen; M. Ward; J. A. Stewart; E. Lee","Communications Research Centre, Canada; Communications Research Centre, Canada; Communications Research Centre, Canada; Communications Research Centre, Canada; Communications Research Centre, Canada; St. Mary's University","The 3rd IEEE International Workshop on Haptic, Audio and Visual Environments and Their Applications","14 Feb 2005","2004","","","63","68","Typically virtual environments are created with visual and auditory stimuli. Less often, haptic stimulation is included as well, usually in the form of force-feedback and tactile manipulators. Another possible source of haptic stimulation is moving air. In order to generate a breeze in a virtual environment, we created a breeze cannon from readily-available components. We compared four conditions: no breeze, self-generated breeze, object-generated breeze and nature-generated breeze. Participants reported feeling more immersed in the virtual environment when the breeze was caused by their own movement. Anecdotal results also suggest that moving air may help decrease simulator sickness.","","0-7803-8817-8","10.1109/HAVE.2004.1391883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1391883","","Haptic interfaces;Virtual environment;Wire;Force feedback;Psychology;Displays;Muscles;Tendons;Skin;Teleoperators","","5","","20","IEEE","14 Feb 2005","","","IEEE","IEEE Conferences"
"Perception of Delay in Haptic Telepresence Systems","M. Rank; Z. Shi; S. Hirche","Institute of Automatic Control Engineering Technische Universität München D-80290 Munich, Germany; Department of Psychology Ludwig-Maximilians-Universität München D-80802 Munich, Germany; Institute of Automatic Control Engineering Technische Universität München D-80290 Munich, Germany",Presence,"19 May 2014","2010","19","5","389","399","Time delay is recognized as an important issue in haptic telepresence systems as it is inherent to long-distance data transmission. What factors influence haptic delay perception in a time-delayed environment are, however, largely unknown. In this article, we examine the impact of manual movement frequency and amplitude in a sinusoidal exploratory movement as well as the stiffness of the haptic environment on the detection threshold for delay in haptic feedback. The results suggest that the detection of delay in force feedback depends on the movement frequency and amplitude, while variation of the absolute feedback force level does not influence the detection threshold. A model based on the exploration movement is proposed and guidelines for system design with respect to the time delay in haptic feedback are provided.","1054-7460","","10.1162/pres_a_00021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6797542","","","","9","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"A Peer-to-peer Architecture for Collaborative Haptic Assembly","R. Iglesias; S. Casado; T. Gutierrez; A. Garcia-Alonso; K. M. Yap; W. Yu; A. Marshall","Labein-Tecnalia, Derio Bizkaia, Spain; Labein-Tecnalia, Derio Bizkaia, Spain; Labein-Tecnalia, Derio Bizkaia, Spain; University of Basque Country (UPV-EHU), Spain; School of Electrical & Electronic Eng, Queen''s University Belfast, Belfast, UK; School of Electrical & Electronic Eng, Queen''s University Belfast, Belfast, UK; School of Electrical & Electronic Eng, Queen''s University Belfast, Belfast, UK",2006 Tenth IEEE International Symposium on Distributed Simulation and Real-Time Applications,"11 Dec 2006","2006","","","25","34","Virtual environments using haptic devices have proved useful for assembly/disassembly simulation of mechanical components. To date most haptic virtual environments are stand-alone. Collaborative haptic virtual environments (CHVEs) are distributed across a number of users via a network, such as the Internet. These present new challenges to the designer, such as consistency of the virtual environments, user-user haptic interaction, and scalability. The system described in this paper considers the CHVEs to be distributed over a packet-switched network such as the Internet. It gives priority to the validation of interactions between objects grasped by users; guarantees consistency across different users' virtual environments. The paper explains the components used and the consistency-maintenance scheme that guarantees the consistency of the virtual scene in the remote nodes. Consistency and force feedback results are also discussed. Results presented show the system maintains a consistent and satisfactory response when network incurs delay or packet jitter","1550-6525","0-7695-2697-7","10.1109/DS-RT.2006.3","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4020784","","Peer to peer computing;Collaboration;Haptic interfaces;Assembly;Virtual environment;IP networks;Scalability;Layout;Force feedback;Jitter","","14","","30","IEEE","11 Dec 2006","","","IEEE","IEEE Conferences"
"Assessment of Environmental Effects on Collaborative Haptic Guidance","B. Khademian; J. Apkarian; K. Hashtrudi-Zaad","Department of of Electrical and Computer Engineering, Queen's University Kingston, ON Canada; Quanser Consulting Inc., Edward S. Rogers Sr. Department of Electrical and Computer Engineering, University of Toronto, Toronto, ON Canada; Department of of Electrical and Computer Engineering, Queen's University Kingston, ON Canada",Presence,"19 May 2014","2011","20","3","191","206","This paper investigates the effect of environmental factors on user performance in a dual-user haptic guidance system. The system under study allows for interaction between both users, the trainee and the trainer, to collaboratively perform a common task in a shared virtual environment. User studies are carried out to experimentally evaluate the users' performance while following square and circular trajectories with two viewpoints of the environment (top view and front view), while the virtual manipulator tool moves in free motion or against forbidden-region virtual fixtures. The performance is measured and statistically evaluated against task completion time, tracking accuracy, and user energy exchange. The studies revealed that changing the environment geometry from a square to a circle results in reduced task completion time and tracking error. Changing the environment viewpoint from top to front decreases the task completion time in both geometries. Forbidden-region virtual fixtures increase energy exchange by both users and decrease task completion time while compromising the tracking performance in the square-following task. However, when visual feedback is removed in the presence of the fixtures, the square tracking performance improves. The results also indicate a strong relationship between user dominance and tracking error only when the experiment is time-limited.","1054-7460","","10.1162/PRES_a_00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6797683","","","","4","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Using collaborative haptics in remote surgical training","C. Gunn; M. Hutchins; D. Stevenson; M. Adcock; P. Youngblood","CSIRO, ICT Centre, Australia; CSIRO, ICT Centre, Australia; CSIRO, ICT Centre, Australia; CSIRO, ICT Centre, Australia; Stanford University School of Medicine, USA",First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. World Haptics Conference,"4 Apr 2005","2005","","","481","482","We describe the design and trial of a remotely conducted surgical master class, using a haptic virtual environment. The instructor was located in the United States and the class was in Australia. The responses of the audience and participants are presented.","","0-7695-2310-2","10.1109/WHC.2005.141","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1406977","","Collaboration;Haptic interfaces;Surgery;Ducts;Australia;Delay;Virtual environment;Physics;Imaging phantoms;Bladder","","33","","4","IEEE","4 Apr 2005","","","IEEE","IEEE Conferences"
"The role of haptics in immersive telecommunication environments","M. Reiner","Technion-Israel Institute of Technology, Haifa, Israel",IEEE Transactions on Circuits and Systems for Video Technology,"15 Mar 2004","2004","14","3","392","401","This paper explores the role of haptics in immersive telecommunication applications and analyzes the contribution of haptics to the sense of presence in a variety of applications. Based on the concept of embodied presence, a new construct, resonance between the human cognitive-body system and the streaming sensory information from the environment, is suggested to be a principal factor in ""presence."" Resonance is defined as the level of mutual synergy between sensory information and action, relative to the physical environment. It occurs when the sensory flow supports action. Since the human haptic system is unique in that it both perceives sensations from the environment and acts on the environment, it has a central role in resonance and in presence. Haptics in the natural world supports efficient bodily action and, in a tacit way, supports development of higher reasoning skills. This requires resonance and embodied presence. The current visual-haptic gap between levels of technological development creates a bottleneck in developing fully tele-immersive applications.","1558-2205","","10.1109/TCSVT.2004.823399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1273548","","Haptic interfaces;Resonance;Humans;Teleconferencing;TV;Displays;Equations;Cognition;Force sensors;Actuators","","50","2","95","IEEE","15 Mar 2004","","","IEEE","IEEE Journals"
"How Do Novice Hapticians Design? A Case Study in Creating Haptic Learning Environments","H. Seifi; M. Chun; C. Gallacher; O. Schneider; K. E. MacLean","Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Haply Robotics Co., Montreal, Quebec, Canada; University of Waterloo, Waterloo, NO, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Haptics,"25 Dec 2020","2020","13","4","791","805","Access to haptic technology is on the rise, in smartphones, virtual reality gear, and open-source education kits. However, engineers and interaction designers are often inexperienced in designing with haptics, and rarely have tools and guidelines for creating multisensory experiences. To examine the impact of this deficit, we supplied a haptic design kit, custom software, and technical support to nine teams (25 students) for an innovation challenge at a major haptics conference. Teams (predominantly undergraduate engineers with little haptics, interaction design, or education training) designed and built haptic environments to support learning of science topics. Qualitative analysis of surveys, interviews, team blogs, and expert assessments of teams’ final demonstrations exposed three themes in these design efforts. 1) Novice teams tended to ignore many of ten design choices that experts navigate, such as explicitly choosing whether haptic and graphic feedback should reinforce versus complement one other. 2) Their design activities differed in timing and inclusion from the ten activities observed in expert process. 3) We identified three success strategies in how teams devised useful and engaging interactions and interpretable multimodal experiences, and communicated about their designs. We compare novice and expert design needs and highlight where future haptic design tools and theory need to support novice practice and training.","2329-4051","","10.1109/TOH.2020.2968903","National Science Foundation; Natural Sciences and Engineering Research Council of Canada; Institute for Computing, Information and Cognitive Systems; UBC Designing for People (DFP) Research Cluster; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967162","haptic design;multisensory interaction;novice designer;haptician;API;education","Haptic interfaces;Tools;Hardware;Education;Guidelines;Software;Design tools","Clinical Competence;Feedback;Humans;Learning;Virtual Reality","29","","71","IEEE","23 Jan 2020","","","IEEE","IEEE Journals"
"Sharing and bridging information in a collaborative virtual environment: Application to ergonomics","C. Pontonnier; T. Duval; G. Dumont","IRISA/INRIA, Ecoles de Saint-Cyr Coëtquidan, Rennes, France; IRISA/INRIA, Université de Rennes 1, Rennes, France; IRISA/INRIA, ENS Rennes, Rennes, France",2013 IEEE 4th International Conference on Cognitive Infocommunications (CogInfoCom),"23 Jan 2014","2013","","","121","126","The current paper aims at presenting a collaborative virtual environment usable to conduct ergonomic design sessions, involving the worker, ergonomists and engineers. The paper focuses particularly on the representation of the ergonomic evaluation and the interaction between an ergonomist and the main user (worker). An ergonomic evaluation of the postures is presented. An interaction architecture between the main user and an ergonomist based on the combination of animation modes of two linked manikins is also proposed. Preliminary results and future developments of the CVE (e.g. additional ergonomic evaluation tools, graphical enhancement, interaction enhancement,...) are then presented.","","978-1-4799-1546-0","10.1109/CogInfoCom.2013.6719226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6719226","","Ergonomics;Joints;Collaboration;Virtual environments;Tracking;Motion segmentation;Three-dimensional displays","","5","","29","IEEE","23 Jan 2014","","","IEEE","IEEE Conferences"
"Implementation and evaluation of decorators for delayed live streaming video on remote control system","Shinichi Hamasaki; Takahiro Yakoh","Department of System Design Engineering, Keio University, Yokohama, Japan; Department of System Design Engineering, Keio University, Yokohama, Japan",2008 6th IEEE International Conference on Industrial Informatics,"3 Sep 2008","2008","","","1220","1225","A remote control system is one of the applications of com munication. An user at a local side requires feedback information from a remote side to operate. In general, visual information and haptic information are used. However, it is impossible to synchronize local side and remote side perfectly because of communication delay and processing time. When the delay becomes long, the operability of remote control system becomes worse. To overcome this difficulty, this article proposed to introduce visual decorators, which are mainly researched in the field of virtual reality, in remote control system. The proposed decorators superimposed real-time remote side information on delayed remote video playout. A position decorator indicated the position of remote robot, and a force decorator indicated the force of the robot. Experimental results showed two decorators improve the operability of the remote control system over network with delay. This results confirmed the effectiveness of proposed decorators for remote control system with delayed video playout.","2378-363X","978-1-4244-2170-1","10.1109/INDIN.2008.4618288","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4618288","","Delays;Haptic interfaces;Visualization;Force;Remote control;Rails;Videos;Motors;Robots;Communication systems","","6","","8","IEEE","3 Sep 2008","","","IEEE","IEEE Conferences"
"Haptic virtual environment performance over IP networks: a case study","Rima Tfaily Souayed; D. Gaiti; G. Pujolle; Wai Yu; Qiang Gu; A. Marshall","Université de Technologie de Troyes, Troyes, France; Université de Technologie de Troyes, Troyes, France; Université Pierre et Marie Curie, Paris, France; School of Electric. & Electro. Engineering, Queen's University Belfast, Belfast, UK; School of Electric. & Electro. Engineering, Queen's University Belfast, Belfast, UK; School of Electric. & Electro. Engineering, Queen's University Belfast, Belfast, UK",Proceedings Seventh IEEE International Symposium on Distributed Simulation and Real-Time Applications,"3 Nov 2003","2003","","","181","189","This paper reports on the quality of service (QoS) requirements and the performance of virtual environment (VE) applications deployed in IP networks. We are interested specifically in systems that support communication with end-user through force feedback devices known as haptic interfaces. Little is known about networked haptic interfaces in VE. Our goal is to understand such application QoS requirements as well as the effect of other traffic when they co-exist in the same network. In this paper, we compare the peer-to-peer model with the client-server model. Our motivation is to deploy distributed haptic VE applications (DHVE) over a network connecting two departments of Queen's University of Belfast. This deployment will be used for educational purposes and for implementing further research in this area, and will be evaluated by end-users; hence, the essential realization of network-based DHVE under realistic network conditions. A set of experiments was conducted to achieve this aim and their results are presented in this paper.","1530-1990","0-7695-2036-7","10.1109/DISRTA.2003.1243014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1243014","","Haptic interfaces;Virtual environment;IP networks;Computer aided software engineering;Force feedback;Quality of service;Collaboration;Frequency;Telecommunication traffic;Traffic control","","8","","21","IEEE","3 Nov 2003","","","IEEE","IEEE Conferences"
"The evaluation of delay jitter for haptics collaboration over the Internet","K. Hikichi; H. Morino; I. Arimoto; K. Sezaki; Y. Yasuda","Graduate School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; Graduate School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; Institute of Industrial Science, University of Tokyo, Meguro, Tokyo, Japan; Center for Spatial Information Science, University of Tokyo, Meguro, Tokyo, Japan; Graduate School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan","Global Telecommunications Conference, 2002. GLOBECOM '02. IEEE","26 Mar 2003","2002","2","","1492","1496 vol.2","What we are concerned with in this paper is a shared virtual environment (SVE) on a non-dedicated network like the Internet. Especially, we address haptics on an SVE for the new generation of network applications. The goal of our research Is to build an SVE system in which multiple participants can collaborate using haptics feedback, even though the participants are located around the world. One of the problems for this system is network impairment, and we have examined the effect of constant network delay and packet loss on the haptics collaboration system. In this paper we examine and evaluate the effect of delay jitter on the system when using media synchronization and dead reckoning.","","0-7803-7632-3","10.1109/GLOCOM.2002.1188447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1188447","","Jitter;Haptic interfaces;Collaboration;Internet;Delay effects;Quality of service;Feedback;Streaming media;Sections;Dead reckoning","","41","3","14","IEEE","26 Mar 2003","","","IEEE","IEEE Conferences"
"Hapto-audio-visual environments for collaborative training of ophthalmic surgery over optical network","P. Boulanger; G. Wu; W. F. Bischof; X. D. Yang","Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada",2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006),"15 Jan 2007","2006","","","21","26","This paper presents the results of a two-year project to develop a shared hapto-visual-audio-virtual environment (HAVE) with advanced multi-point video conferencing, new display and interface technologies, and distributed latency-compensated haptic technologies for collaborative medical research and training in ophthalmology. One of the goals of this project is to create collaborative training environment, in which residents can remotely learn, in real-time, cataract operations from real operations performed by teaching surgeons. The assumption of this work is that a trainee surgeon can learn the complex hand-eye coordination necessary for becoming a good ophthalmic surgeon by feeling and seeing every move the expert surgeon makes, through a complex haptic, auditory, and visual playback interface. Experimental results are presented","","1-4244-0760-5","10.1109/HAVE.2006.283801","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4062542","","Collaboration;Surgery;Optical fiber networks;Surges;Lenses;Haptic interfaces;Tellurium;Videoconference;Displays;Anesthesia","","14","","20","IEEE","15 Jan 2007","","","IEEE","IEEE Conferences"
"Immersed remotely: Evaluating the use of Head Mounted Devices for remote collaboration in robotic telepresence","S. Kratz; F. Rabelo Ferriera","FX Palo Alto Laboratory, Palo Alto, CA, USA; Fred Rabelo Ferreira is with Columbia University, New York, NY, USA",2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),"17 Nov 2016","2016","","","638","645","Mobile Telepresence Robots (MTR) are an emerging technology that extend the functionality of telepresence systems by adding mobility. MTRs nowadays, however, rely on stationary imaging systems such as a single narrow-view camera for vision, which can lead to higher operator error rates due to view-related deficiencies in situational awareness. We therefore developed an improved imaging and viewing platform that allows immersive telepresence using a Head Mounted Device (HMD) with head-tracked mono and stereoscopic video. Using a remote collaboration task to ground our research, we examine the effectiveness head-tracked HMD systems in comparison to a baseline monitor-based system. We performed a user study where participants were divided into three groups: fixed camera monitor-based baseline condition (without HMD), HMD with head-tracked 2D camera and HMD with head-tracked stereo camera. Results showed the use of HMD reduces task error rates and improves perceived collaborative success and quality of view, compared to the baseline condition. No major difference was found, however, between stereo and 2D camera conditions for participants wearing an HMD.","1944-9437","978-1-5090-3929-6","10.1109/ROMAN.2016.7745185","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745185","","Cameras;Robot vision systems;Resists;Collaboration;Navigation;Head","","17","","42","IEEE","17 Nov 2016","","","IEEE","IEEE Conferences"
"Architecture and Evaluation of Tele-Haptic Environments","Xiaojun Shen; Jilin Zhou; A. El Saddik; N. D. Georganas","Distributed and Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada; Distributed and Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada; Distributed and Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada; Distributed and Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Canada",Eighth IEEE International Symposium on Distributed Simulation and Real-Time Applications,"13 Dec 2004","2004","","","53","60","A collaborative, haptic, audio and visual environment (C-HAVE) consists of a network of nodes. Each node in the C-HAVE world contributes to the shared environment with some virtual objects. These can be static, e.g., a sculpture or the ground, or dynamic, e.g., an object that can be virtually manipulated. We aim at developing a heterogeneous scalable architecture for large collaborative haptics environments where a number of potential users participate with different kinds of haptic devices. The main objective of the presented research is the development of three prototypes to demonstrate quantitatively the effects of adding haptics to a task. The experimental results reveal the effects of the different implementations on the performance and time delay of a particular task through objective measurement results.","1550-6525","0-7695-2232-7","10.1109/DS-RT.2004.8","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1364579","","Haptic interfaces;Collaboration;Virtual environment;Information technology;Manipulator dynamics;Feedback;Electronic mail;Prototypes;Delay effects;Particle measurements","","24","","21","IEEE","13 Dec 2004","","","IEEE","IEEE Conferences"
"Delay compensation in Shared Haptic Virtual Environments","C. Schuwerk; R. Chaudhari; E. Steinbach","Institute for Media Technology, Technische Universität München; Technische Universitat Munchen, Munchen, Bayern, DE; Institute for Media Technology, Technische Universität München",2014 IEEE Haptics Symposium (HAPTICS),"20 Mar 2014","2014","","","371","377","Shared Haptic Virtual Environments (SHVEs) are often realized using a client-server architecture. At the server, a physics simulation engine calculates the object states based on the position information received from the clients. At the clients, the object state information, received from the server, is used to update the local copy of the virtual environment. Forces displayed to the user through a haptic device are computed locally at the client based on the interactions with the objects. Communication delay leads to delayed object state updates and increased interaction forces rendered at the clients. Users perceive this as increased object weight. In this paper, we systematically analyze the loss of transparency caused by communication delay and propose a novel adaptive force rendering scheme to compensate for it. The proposed scheme reduces the objects' stiffness at the clients, based on delay, device velocity and motion constraints of the objects, only if necessary to achieve perceptual transparency. Simulations and subjective evaluations show that the effect of increased weight of objects is successfully compensated for the tested delay range of up to 150 ms. At the same time, if the object is unmovable, the perception of interaction with a rigid object is preserved.","2324-7355","978-1-4799-3131-6","10.1109/HAPTICS.2014.6775484","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6775484","","Delays;Force;Haptic interfaces;Servers;Engines;Probes","","3","","17","IEEE","20 Mar 2014","","","IEEE","IEEE Conferences"
"Evaluating Visual-Spatiotemporal Co-Registration of a Physics-Based Virtual Reality Haptic Interface","S. T. Mubarrat; S. K. Chowdhury; A. S. Fernandes","Department of Industrial Engineering, Texas Tech University, Lubbock, TX, USA; Department of Industrial Engineering, Texas Tech University, Lubbock, TX, USA; Department of Industrial Engineering, Texas Tech University, Lubbock, TX, USA",IEEE Access,"25 Apr 2024","2024","12","","57017","57032","This study aimed to evaluate the visual-spatiotemporal co-registration of the real and virtual objects’ movement dynamics by designing a low-cost, physics-based virtual reality (VR) system that provides actual cutaneous and kinesthetic haptic feedback of an object instead of using computer-generated haptic feedback. Twelve healthy participants performed three human-robot collaborative (HRC) sequential pick-and-place lifting tasks while both motion capture and VR systems, respectively, traced the movement of the real and virtual objects simultaneously. We used an iterative closest point algorithm to transform and align the 3D coordinates of VR point clouds with the 3D coordinates of the motion capture system. We introduced a new method to calculate and analyze the precision of visual and spatiotemporal co-registration between virtual and real objects. Results showed a high correlation ( $r >$  0.96) between real and virtual objects’ movement dynamics and linear and angular co-registration errors of less than 5 cm and 8°, respectively. The trend also revealed a low temporal registration error of < 12 ms and was only found along the vertical axis. The visual registration data indicated that using real objects to provide cutaneous and kinesthetic haptics in the VR setting enhanced the users’ overall proprioception and visuomotor functions.","2169-3536","","10.1109/ACCESS.2024.3391186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10505290","Co-registration;haptics technology;high-fidelity;human-robot collaboration;virtual reality;accuracy","Haptic interfaces;Visualization;Task analysis;Tracking;Motion capture;Virtual environments;Spatiotemporal phenomena;Human-robot interaction;Virtual reality","","1","","75","CCBYNCND","19 Apr 2024","","","IEEE","IEEE Journals"
"The Proactive Desk: A New Haptic Display System for a Digital Desk Using a 2-DOF Linear Induction Motor","H. Noma; S. Yoshida; Y. Yanagida; N. Tetsutani","ATR Media Information Science Laboratories, Kyoto, Japan, noma@atr.jp; ATR Media Information Science Laboratories, Kyoto, Japan, shun@atr.jp; ATR Media Information Science Laboratories, Kyoto, Japan, yanagida@atr.jp; ATR Media Information Science Laboratories, Kyoto, Japan, tetsutani@atr.jp",Presence,"19 May 2014","2004","13","2","146","163","The Proactive Desk is a new digital desk with haptic feedback. The concept of a digital desk was proposed by Wellner in 1991 for the first time. A typical digital desk enables a user to seamlessly handle both digital and physical objects on the desk with a common GUI standard. The user, however, handles them as virtual GUI objects. Our Proactive Desk allows the user to handle both digital and physical objects on a digital desk with a realistic feeling. In the Proactive Desk, two linear induction motors are equipped to generate an omnidirectional translational force on the user's hand or on a physical object on the desk without any mechanical links or wires, thereby preserving the advantages of the digital desk. In this article, we first discuss applications of a digital desk with haptic feedback; then we mention the design and structure of the first trial Proactive Desk, and its performance.","1054-7460","","10.1162/1054746041382438","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6789031","","","","6","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Transatlantic Touch: A Study of Haptic Collaboration over Long Distance","J. Kim; H. Kim; B. K. Tay; M. Muniyandi; M. A. Srinivasan; J. Jordan; J. Mortensen; M. Oliveira; M. Slater","The Touch Lab, Department of Mechanical Engineering and The Research Laboratory of Electronics, Massachusetts Institute of Technology, Cambridge, MA; The Touch Lab, Department of Mechanical Engineering and The Research Laboratory of Electronics, Massachusetts Institute of Technology, Cambridge, MA; The Touch Lab, Department of Mechanical Engineering and The Research Laboratory of Electronics, Massachusetts Institute of Technology, Cambridge, MA; The Touch Lab, Department of Mechanical Engineering and The Research Laboratory of Electronics, Massachusetts Institute of Technology, Cambridge, MA; The Touch Lab, Department of Mechanical Engineering and The Research Laboratory of Electronics, Massachusetts Institute of Technology, Cambridge, MA; Department of Computer Science, University College London, London; Department of Computer Science, University College London, London; Department of Computer Science, University College London, London; Department of Computer Science, University College London, London",Presence,"19 May 2014","2004","13","3","328","337","The extent to which the addition of haptic communication between human users in a shared virtual environment (SVE) contributes to the shared experience of the users has not received much attention in the literature. In this paper we describe a demonstration of and an experimental study on haptic interaction between two users over a network of significant physical distance and a number of network hops. A number of techniques to mitigate instability of the haptic interactions induced by network latency are presented. An experiment to evaluate the use of haptics in a collaborative situation mediated by a networked virtual environment is examined. The experimental subjects were to cooperate in lifting a virtual box together under one of four conditions in a between-groups design. Questionnaires were used to report the ease with which they could perform the task and the subjective levels of presence and copresence experienced. This extends earlier work by the authors to consider the possibility of haptic collaboration under real network conditions with a number of improvements. Using the technology described in this paper, transatlantic touch was successfully demonstrated between the Touch Lab at Massachusetts Institute of Technology, USA and Virtual Environments and Computer Graphics (VECG) lab at University College London (UCL), UK in 2002. It was also presented at the Internet II demonstration meeting in 2002 between University of Southern California and the Massachusetts Institute of Technology.","1054-7460","","10.1162/1054746041422370","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6788847","","","","46","1","","","19 May 2014","","","MIT Press","MIT Press Journals"
"A Performance Evaluation of a Hybrid Multicast Transport Protocol for a Distributed Collaborative Virtual Simulation of a Brain Tumor Tele-Surgery Class of Applications","A. Boukerche; H. Maamar; A. Hossain","PARADISE Research Laboratory, University of Ottawa, Canada; PARADISE Research Laboratory, University of Ottawa, Canada; PARADISE Research Laboratory, University of Ottawa",2007 12th IEEE Symposium on Computers and Communications,"12 Nov 2007","2007","","","975","980","Haptic interfaces have been designed for brain surgery simulation may prove to be especially useful for training surgeons to conduct minimally invasive procedures and remote surgery using tele-operators. However, it well known that collaborative, haptic, audio and visual environments (C-HAVE) suffer from setbacks due to network delay, scalability, reliability and synchronization problem when the users are geographically distributed. In this paper, we focus upon a Brain Tumor Tele-Surgery application that is based on closely coupled and highly synchronized haptic tasks that require a high-level of coordination among the participants. We considered four main protocols: the synchronous collaboration transport protocol (SCTP), the selective reliable transmission protocol (SRTP), the reliable multicast transport protocol (RMTP) and the scalable reliable multicast (SRM) and presented a hybrid protocol that is able to satisfy all the CVE and C-HAVE requirements and discuss its implementation using brain tumor tele-surgery application as a case study.","1530-1346","978-1-4244-1520-5","10.1109/ISCC.2007.4381516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4381516","","Multicast protocols;Transport protocols;Collaboration;Brain modeling;Neoplasms;Haptic interfaces;Minimally invasive surgery;Delay;Industrial training;Scalability","","5","","6","IEEE","12 Nov 2007","","","IEEE","IEEE Conferences"
"A meta user interface for interaction with mixed reality environments","A. Mostafazadeh; A. A. N. Shirehjini; S. Daraei; N. Khojasteh; S. Shirmohammadi","Department of Computer Engineering, Sharif University of Technology, Tehran, Iran; Department of Computer Engineering, Sharif University of Technology, Tehran, Iran; Department of Computer Engineering, Sharif University of Technology, Tehran, Iran; Department of Computer Engineering, Sharif University of Technology, Tehran, Iran; Distributed and Collaborative Virtual Environment Research Laboratory, University of Ottawa, Ottawa, Canada","2015 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE)","21 Dec 2015","2015","","","1","6","The aim of this paper is the design and development of a novel user interface to interact with a meta system. Our focus is rather on interacting with Ambient Intelligence as a whole, which would for example enable users to influence the overall behaviors and attributes of dynamic device compositions. We call such interfaces Meta User Interfaces. The design details of a proposed user interface as well as a cognitive walkthrough evaluation are presented in this paper.","","978-1-4673-9175-7","10.1109/HAVE.2015.7359449","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7359449","","User interfaces;Ambient intelligence;Automation;Intelligent systems;Interviews;Home appliances","","1","","26","IEEE","21 Dec 2015","","","IEEE","IEEE Conferences"
"Remote collaboration using a tele-presence mobile projector robot tele-operated by a smartphone","J. -g. Ahn; G. J. Kim","Digital Experience Laboratory, Korea University, Seoul, Korea; Digital Experience Laboratory, Korea University, Seoul, Korea",2016 IEEE/SICE International Symposium on System Integration (SII),"9 Feb 2017","2016","","","236","241","In this paper, we present SPRinT (Smart Phone/Pad and Robot for Tele-operation and Tele-presence), a tele-presence robot for HRI controlled by a smart phone. It uses the projection display as a main communication channel between the local and remote users and we describe the interaction model for such an HRI scenario. We focus on the interaction model and interplay among the robot controlling (local) user, tele-presence robot, and the counterpart person in the remote environment the local user attempting to interact with using the projection display. We outline the technical and interface requirements for understanding the target remote space, and initiating and setting up such an information exchange for the local user (and partly for the remote).","2474-2325","978-1-5090-3329-4","10.1109/SII.2016.7844004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7844004","","Cameras;Robot vision systems;Aerospace electronics;Smart phones","","4","","30","IEEE","9 Feb 2017","","","IEEE","IEEE Conferences"
"""Personal Practically Panoramic"" Multimodal Interfaces","K. Kanno; N. Fernando; A. Bolhassan; S. Narita; M. Cohen","Spatial Media Group, University of Aizu, Fukushima, Japan; Spatial Media Group, University of Aizu, Fukushima, Japan; Spatial Media Group, University of Aizu, Fukushima, Japan; Spatial Media Group, University of Aizu, Fukushima, Japan; Spatial Media Group, University of Aizu, Fukushima, Japan",IEEE Virtual Reality Conference (VR 2006),"7 Aug 2006","2006","","","322","322","We have developed second-generation prototypes of the Internet Chair, a novel internet appliance. The first generation explored using the chair as an input device; ¡°S chaire,¡± the prototype employed here, is a pivot (swivel, rotating) chair deployed as an output device, a rotary motion-platform information appliance, dynamically aligning haptic display with wireless visual displays and spatial audio in rotation-invariant virtual spaces. As a haptic output modality, chairs with servomotors render kinesthetic and proprioceptive cues, twisting under networked control, to direct the attention of a seated subject orienting seated users like a ¡°dark ride¡± amusement park attraction or under active user control, local or distributed. Using its audio display modality, ¡°nearphones¡± embedded in the seat headrest, the system can present unencumbered binaural sound with soundscape stabilization for multichannel sound image localization. In groupware situations like teleconferencing, chat spaces, or multiplayer gaming, such orientation is also synchronized with panoramic or turnoramic displays or twisting iconic representations of the users, avatars in virtual spaces, enabling social situation awareness. The S chaire, manifesting as personal LBE (location-based entertainment), can be used in both stand-alone and networked applications.We have developed several clients that exploit such ¡°practically panoramic¡± capability, including simulators, games, and 360¢ª browsers, providing sensory-integrated multimodal applications, variously including stereographic or mobile features.","2375-5334","1-4244-0224-7","10.1109/VR.2006.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1667685","reality/virtuality;haptic interface;information furniture;locationbased;entertainment (LBE);motion platform;networked appliance;soundscape stabilization.","Auditory displays;Internet;Home appliances;Haptic interfaces;Prototypes;Virtual prototyping;Servomotors;Distributed control;Collaborative software;Collaborative work","","1","","7","IEEE","7 Aug 2006","","","IEEE","IEEE Conferences"
"Designing a Vibrotactile Head-Mounted Display for Spatial Awareness in 3D Spaces","V. A. de Jesus Oliveira; L. Brayda; L. Nedel; A. Maciel","Instituto de Informática, Universidade Federal do Rio Grande do Sul - UFRGS, Porto Alegre, Brazil; Department of Robotics, Brain and Cognitive Science, Fondazione Istituto Italiano di Tecnologia - IIT, Genoa, Italy; Instituto de Informática, Universidade Federal do Rio Grande do Sul-UFRGS; Instituto de Informática, Universidade Federal do Rio Grande do Sul-UFRGS",IEEE Transactions on Visualization and Computer Graphics,"14 Mar 2017","2017","23","4","1409","1417","Due to the perceptual characteristics of the head, vibrotactile Head-mounted Displays are built with low actuator density. Therefore, vibrotactile guidance is mostly assessed by pointing towards objects in the azimuthal plane. When it comes to multisensory interaction in 3D environments, it is also important to convey information about objects in the elevation plane. In this paper, we design and assess a haptic guidance technique for 3D environments. First, we explore the modulation of vibration frequency to indicate the position of objects in the elevation plane. Then, we assessed a vibrotactile HMD made to render the position of objects in a 3D space around the subject by varying both stimulus loci and vibration frequency. Results have shown that frequencies modulated with a quadratic growth function allowed a more accurate, precise, and faster target localization in an active head pointing task. The technique presented high usability and a strong learning effect for a haptic search across different scenarios in an immersive VR setup.","1941-0506","","10.1109/TVCG.2017.2657238","CAPES; CNPq-Brazil(grant numbers:305071/2012-2); Ligurian PARFAS(grant numbers:CUP G35C13001360001); EUFP7 grant BLINDPAD(grant numbers:611621); CNPq-Brazil(grant numbers:305071/2012-2); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829406","Vibrotactile head-mounted display;haptic interaction;spatial awereness;3D environments","Three-dimensional displays;Frequency modulation;Vibrations;Azimuthal plane;Haptic interfaces;Visualization;Skin","","74","","39","IEEE","23 Jan 2017","","","IEEE","IEEE Journals"
"Evaluation Patterns of Tele-Haptics","X. Shen; J. Zhou; N. D. Georganas","Distributed and Collaborative Virtual Environments Research Laboratory DISCOVER, School of Information Technology and Engineering SITE, University of Ottawa, Canada; Distributed and Collaborative Virtual Environments Research Laboratory DISCOVER, School of Information Technology and Engineering SITE, University of Ottawa, Canada; Distributed and Collaborative Virtual Environments Research Laboratory DISCOVER, School of Information Technology and Engineering SITE, University of Ottawa, Canada",2006 Canadian Conference on Electrical and Computer Engineering,"15 Jan 2007","2006","","","1542","1545","Multimedia and information technology are reaching limits in terms of what can be done in multimedia applications with only sight and sound. The next critical step is to bring the sense of ""touch"" over network connections, which is commonly known as tele-haptics. In this paper, we present methodologies for performing usability evaluation of tele-haptics system. The overall performance of a tele-haptics system relies on two aspects: the mechanical characteristics of the haptic device used and system architecture","0840-7789","1-4244-0038-4","10.1109/CCECE.2006.277764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4054712","","Haptic interfaces;Humans;Collaboration;Virtual environment;Temperature sensors;Feedback;Context modeling;Delay effects;Stability;Information technology","","2","","6","IEEE","15 Jan 2007","","","IEEE","IEEE Conferences"
"Separate DOF control and mutual guidance in networked haptic collaboration maze game: Design and evaluation","Lingzhi Liu; Guanyang Liu; Yuru Zhang; Weidong Guo; Keke Lu; Moyuan Zhou","State Key Laboratory of Virtual Reality Technology and Systems, Robotics Institute, Beihang University, China; State Key Laboratory of Virtual Reality Technology and Systems, Robotics Institute, Beihang University, China; State Key Laboratory of Virtual Reality Technology and Systems, Robotics Institute, Beihang University, China; Beihang University, Beijing, CN; Beihang University, Beijing, CN; Beihang University, Beijing, CN",2011 IEEE International Conference on Robotics and Automation,"18 Aug 2011","2011","","","913","918","In this paper we study on haptic collaboration in a maze game over computer network. Two players located at separated places operate each haptic device to collaboratively finish the game task. Herein, a new collaboration mode of manipulation separate DOF control is proposed for the first time. Separate DOF control here means each player controls one DOF of an object or a task independently in collaborative virtual environment. Mutual guidance is also proposed which provides guidance force to each player. We setup an experiment to evaluate its efforts on cooperation performance and co-presence. Twelve participants did the experiment. The results revealed that this collaboration mode is effective. Ten of the twelve participants believed that they performed well in the experiment and thought the collaboration way was very interesting. The presented results motivated a new haptic collaboration mode in the fields of game design, education and cooperative assembly.","1050-4729","978-1-61284-385-8","10.1109/ICRA.2011.5979832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5979832","","Collaboration;Games;Force;Phantoms;Graphics;Force feedback","","4","","20","IEEE","18 Aug 2011","","","IEEE","IEEE Conferences"
"How to improve group performances on colocated synchronous manipulation tasks?","J. Simard; A. Girard; A. Mayeur; M. Ammi","CNRS-LIMSI, University Paris-Sud, Orsay, France; CNRS-LIMSI, University Paris-Sud, Orsay, France; CNRS-LIMSI, Orsay, France; CNRS-LIMSI, University Paris-Sud, Orsay, France",2012 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2012) Proceedings,"6 Dec 2012","2012","","","13","18","Collaborative Virtual Environments provide new working methods to associate several users on the same problem through different space and time configurations (synchronous/ asynchronous, distant/colocated). This new approach enables the simultaneous management of complex environments with several constraints for a more robust and efficient process. Previous studies investigate various features of synchronous Collaborative Virtual Environment but they mainly focus on configurations involving mainly 2 users. This paper presents an experimental study which investigates the collaborative work for more users. We propose to compare 2 users with 4 users to perform a closely coupled molecular deformation task. The results show that groups of 4 participants are more efficient than pairs, even more if they plan their actions during a brainstorming step. An important outcome of this study shows that the role of a leader improve the coordination between the participants and limit the conflicting communication.","","978-1-4673-1567-8","10.1109/HAVE.2012.6374435","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374435","","Collaboration;Force;Haptic interfaces;Planning;Atmospheric measurements;Particle measurements;Electronic mail","","1","","17","IEEE","6 Dec 2012","","","IEEE","IEEE Conferences"
"Guest Editorial: Special Issue on Haptics, Virtual, and Augmented Reality","G. C. Burdea; M. C. Lin; W. Ribarsky; B. Watson","Electrical and Computer Engineering Department, Rutgers University, Piscataway, NJ, USA; Computer Science Department, North Carolina State University, Chapel Hill, NC, USA; Charlotte Visualization Center, University of North Carolina, Charlotte, Charlotte, NC, USA; Department of Computer Science, Northwestern University, Evanston, IL, USA",IEEE Transactions on Visualization and Computer Graphics,"26 Sep 2005","2005","11","6","611","613","Guest Editorial: Special Issue on Haptics, Virtual, and Augmented Reality","1941-0506","","10.1109/TVCG.2005.102","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512012","","Haptic interfaces;Augmented reality;Avatars;Virtual environment;Application software;Graphics;Cameras;Displays;Robot vision systems;Anthropomorphism","Computer Simulation;Computer Systems;Data Display;Environment;Humans;Imaging, Three-Dimensional;Models, Theoretical;Online Systems;Touch;User-Computer Interface","15","","","IEEE","26 Sep 2005","","","IEEE","IEEE Journals"
"Passivity-based position consensus of multiple mechanical integrators with communication delay","K. Huang; D. Lee","Department of Mechanical, Aerospace & Biomedical Engineering, University of Tennessee, Knoxville, TN, USA; Department of Mechanical, Aerospace & Biomedical Engineering, University of Tennessee, Knoxville, TN, USA",Proceedings of the 2010 American Control Conference,"29 Jul 2010","2010","","","836","841","We present a consensus framework for multiple variable-rate heterogeneous mechanical integrators (i.e. multidimensional integrators with mass, damping and spring matrices) on undirected graph with constant, yet, non-uniform communication delay. By connecting multiple mechanical integrators via (discrete-time) spring connections over delayed links with some damping injection, our proposed framework not only achieves position consensus, but also enforces closed-loop discrete-time passivity. Moreover, it allows arbitrary control gains regardless of integration steps, if there is no delay. Simulation result is also given to support the theory.","2378-5861","978-1-4244-7427-1","10.1109/ACC.2010.5530740","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5530740","","Delay;Damping;Springs;Haptic interfaces;Communication system control;Joining processes;Humans;Virtual environment;Graph theory;Mechanical variables control","","3","","21","","29 Jul 2010","","","IEEE","IEEE Conferences"
"Auditory decorator of complex sounds for teleoperation systems","H. Kuramata; T. Yakoh","Department of System Design Engineering, Keio University, Japan; Department of System Design Engineering, Keio University, Japan",2011 9th IEEE International Conference on Industrial Informatics,"6 Oct 2011","2011","","","227","232","Communication delay in network is inevitable issue and it causes discomfort in manipulation of teleoperation systems. One of the solutions for this problem is decorator. Decorator is a technique to decrease the discomfort by modifying visual or auditory feedback based on the other information, which is transmitted with shorter delay, to its operator. In the former study, the artificial modification improves the usability of teleoperation. In this paper, we proposed an auditory decorator composed of complex sounds. Complex sounds have an ability to express multidimensional information. Therefore, with the complex sound, various information can be included in auditory information. We chose chord sounds and sign sounds as complex sounds and implemented the auditory decorator. From result of the user study to evaluate the proposed decorator, the proposed decorator is more effective to improve the usability of teleoperation system than the conventional one.","2378-363X","978-1-4577-0434-5","10.1109/INDIN.2011.6034878","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6034878","","Visualization;Delay;Rails;Haptic interfaces;Usability;Interviews;Force","","","","8","IEEE","6 Oct 2011","","","IEEE","IEEE Conferences"
"Immerstar, a still evolving 25 years old VR research facility","R. Gaugne","CNRS, IRISA, Univ Rennes, Inria",2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"24 Apr 2025","2025","","","181","184","The two platforms Immersia and Immermove offer an immersive collaborative space called ImmerStar, intended for the scientific and industrial community, for international research projects. Immersia is a 3D virtual reality platform which, thanks to its exceptional dimensions, offers an environment for experimentation, particularly in the context of real-time and multi-modal interaction (vision, sound, haptics, brain-computer interface) between humans and virtual models. Immermove is a technological platform dedicated to motion capture, extended by a virtual reality space. It enables the precise capture of rapid movements (sports for example) or of a group of people, in order to study human behavior such as crowd-movement or sport gestures. This paper presents the history of the evolution of these two joint platforms, an overview of their technical specifications, associated research projects and perspective of evolutions.","","979-8-3315-1484-6","10.1109/VRW66409.2025.00045","Equipex; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972772","Virtual reality;haptics;motion capture","Geometry;Solid modeling;Three-dimensional displays;Virtual reality;Motion capture;Real-time systems;Haptic interfaces;Teamwork;History;Sports","","","","14","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"Impact of Multimodal Instructions for Tool Manipulation Skills on Performance and User Experience in an Immersive Environment","C. Simon; M. Boukli-Hacene; F. Lebrun; S. Otmane; A. Chellali",IBISC Lab Univ Evry Paris Saclay; IBISC Lab Univ Evry Paris Saclay; IBISC Lab Univ Evry Paris Saclay; IBISC Lab Univ Evry Paris Saclay; IBISC Lab Univ Evry Paris Saclay,2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR),"15 Apr 2024","2024","","","670","680","With the mentoring model, a mentee can learn technical skills under the supervision of more experienced peers who demonstrate their knowledge through several communication modalities. Supporting the mentoring model within shared immersive training simulators holds promise in enhancing mentor-mentee interactions and learning outcomes in a safe environment. However, efficient communication within these spaces remains an open issue. This work presents a user study that explores the combination of communication modalities (verbal-visual, verbal-haptic, visual-haptic, and verbal-visual-haptic) to convey instructions to learners on the amplitude of movements to perform during a tool-handling task in an immersive environment. The study aims to examine the impact of the four modality combinations on performance (speed and accuracy of movement replication), mental workload, and participants’ user experience. The results show that participants achieved higher accuracy with the visual-haptic and verbal-visual-haptic conditions. Moreover, they performed the movements faster, and their movement trajectories were closer to the reference trajectories in the visual-haptic condition. Finally, the most preferred verbal-visual-haptic combination enhanced the users’ sense of presence, co-presence, social presence, and learning experience. No impact on the mental workload was observed. These results suggest that combining haptic and visual modalities is the best suited for enhancing learners’ performance. Adding the verbal modality can also improve the user experience in the immersive learning environment. These findings contribute to improving the design of immersive collaborative systems and pave the way for exploring novel avenues of research into the efficacy of multimodal communication for enhancing the mentoring-based acquisition of technical skills in VR. These tools hold promise for diverse applications, including medical simulation.","2642-5254","979-8-3503-7402-5","10.1109/VR58804.2024.00087","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494100","Multimodal interactions;Mentorship;Remote collaboration;Immersive learning;Human-centered computing Virtual reality;Human-centered computing User studies;Human-centered computing Collaborative interaction","Training;Visualization;Three-dimensional displays;Collaboration;User interfaces;Motors;User experience","","4","","58","IEEE","15 Apr 2024","","","IEEE","IEEE Conferences"
"Replicating Human-Human Physical Interaction","K. B. Reed; J. Patton; M. Peshkin","Laboratory for Intelligent Mechanical Systems, Northwestern University, Evanston, IL, USA; Mechanical Engineering, Northwestern, Rehabilitation Institute of Chicago, Chicago, IL, USA; Laboratory for Intelligent Mechanical Systems, Northwestern University, Evanston, IL, USA",Proceedings 2007 IEEE International Conference on Robotics and Automation,"21 May 2007","2007","","","3615","3620","Machines might physically interact with humans more smoothly if we better understood the subtlety of human-human physical interaction. We recently reported that two people working cooperatively on a physical task will quickly negotiate an emergent strategy: typically subjects formed a temporal specialization such that one member commands the early parts of motion and the other the late parts. In our study, we replaced one of the humans with a robot programmed to perform one of the typical human specialized roles. We expected the remaining human to adopt the complementary specialized role. Subjects did believe that they were interacting with another human but did not adopt a specialized behavior as subjects would when physically working with another human; our negative result suggests a very subtle negotiation takes place in human-human physical interaction.","1050-4729","1-4244-0601-3","10.1109/ROBOT.2007.364032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4209650","","Haptic interfaces;Force feedback;Human robot interaction;Virtual environment;Force control;Intelligent systems;Mechanical systems;Position control;Error correction;Robotics and automation","","25","","21","IEEE","21 May 2007","","","IEEE","IEEE Conferences"
"Field of view deficiency-based dominance distribution for collaborative teleoperation","B. Gromov; G. Ivanova; J. -H. Ryu","Biorobotics Laboratory, Korea University of Technology and Education, Cheonan, South Korea; Biorobotics Laboratory, Korea University of Technology and Education, Cheonan, South Korea; Biorobotics Laboratory, Korea University of Technology and Education, Cheonan, South Korea","2012 12th International Conference on Control, Automation and Systems","31 Dec 2012","2012","","","1990","1993","This paper intoduces a preliminary study on a new control decomposition criterion for collaborative teleoperation systems - field of view deficiency. This criterion represents the amount of visual information available to operators. As a tool for such decomposition we introduce a dominance distribution matrix - a more flexible approach to dominance distribution than a well-known scalar dominance factor concept. We introduce collaborative teleoperation architecture, based on field of view deficiency criterion and apply it to experimental dual-master/single-slave teleoperation system. Experimental study demonstrates the effectiveness of the proposed approaches.","","978-89-93215-04-5","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6393177","Teleoperation;collaborative control;dominance distribution;field of view deficiency;multiple-master single-slave;haptic interface","Cameras;Collaboration;Robots;Vectors;Visualization;Force;Haptic interfaces","","2","","7","","31 Dec 2012","","","IEEE","IEEE Conferences"
"A network architecture supporting consistent rich behavior in collaborative interactive applications","J. Marsh; M. Glencross; S. Pettifer; R. Hubbold","School of Computer Science, University of Manchester, Institute of Science and Technology, Manchester, UK; School of Computer Science, University of Manchester, Institute of Science and Technology, Manchester, UK; School of Computer Science, University of Manchester, Institute of Science and Technology, Manchester, UK; School of Computer Science, University of Manchester, Institute of Science and Technology, Manchester, UK",IEEE Transactions on Visualization and Computer Graphics,"20 Mar 2006","2006","12","3","405","416","Network architectures for collaborative virtual reality have traditionally been dominated by client-server and peer-to-peer approaches, with peer-to-peer strategies typically being favored where minimizing latency is a priority and client-server where consistency is key. With increasingly sophisticated behavior models and the demand for better support for haptics, we argue that neither approach provides sufficient support for these scenarios nor, thus, a hybrid architecture is required. We discuss the relative performance of different distribution strategies in the face of real network conditions and illustrate the problems they face. Finally, we present an architecture that successfully meets many of these challenges and demonstrate its use in a distributed virtual prototyping application which supports simultaneous collaboration for assembly, maintenance, and training applications utilizing haptics","1941-0506","","10.1109/TVCG.2006.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1608027","Virtual reality;network architecture and design;haptic I/O;computer-supported collaborative work;computer-supported cooperative work;simulation;modeling;and visualization;client/server;distributed applications;computer-aided design.","Intelligent networks;Collaboration;Haptic interfaces;Application software;Delay;Virtual prototyping;Collaborative work;Virtual reality;Peer to peer computing;Computer architecture","Communication;Computer Communication Networks;Computer Graphics;Cooperative Behavior;Signal Processing, Computer-Assisted;User-Computer Interface","56","","50","IEEE","20 Mar 2006","","","IEEE","IEEE Journals"
"Dual Purpose Multi-User Semi-Immersive Hapto-Acoustic Virtual Environment","T. Adriaansen","ICT Centre, CSIRO, Epping, NSW, Australia",Digital Image Computing: Techniques and Applications (DICTA'05),"16 Oct 2006","2005","","","21","21","Our hapto-acoustic virtual environment we call the ""haptic-workbench"" [1], has remained unchanged since 1994. Recent changes in available projector hardware technology now means that the system can be modified to address some inherent limitations in terms of user participation. In addition, the proposed changes are now more viable, whereas only six months ago such modifications were prohibitively expensive or not possible. Up to now the system has used active stereo for 3D graphics visualization but this implementation limits effective participation to one person. The new dual purpose environment is a more versatile system which may be used in one of two ways; a) single user mode or b) large volume display mode where many users can simultaneously participate. The semi-immersive attributes of the former haptic-workbench are retained in single user mode and when in large volume display mode the system allows multiple user involvement and interaction. The new dual purpose multi-user environment removes some of the restrictions which effectively limit interaction to one person operating in a narrow viewing space, is not limited to rooms needing special seating or lighting and addresses the increasing need for a sense of presence and interaction with many persons simultaneously. Groups of up to 30 can now experience the collaborative virtual environment (CVE) [2] rather than single user at a time and when networked allows the system to be used for educational interaction in a classroom setting with the possibility of similar numbers at each end. Methodology and some traps and pitfalls are discussed in terms of differing technologies used in generating the real time 3D stereo models and the realisation of the new system is given.","","0-7695-2467-2","10.1109/DICTA.2005.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1587623","","Virtual environment;Real time systems;Collaboration;Australia;Graphics;Displays;Information technology;Art;Haptic interfaces;Virtual reality","","","","9","IEEE","16 Oct 2006","","","IEEE","IEEE Conferences"
"Subjective and Objective Analyses of Collaboration and Co-Presence in a Virtual Reality Remote Environment","A. Bayro; Y. Ghasemi; H. Jeong",University of Illinois at Chicago; University of Illinois at Chicago; University of Illinois at Chicago,2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"20 Apr 2022","2022","","","485","487","Remote collaboration in virtual reality has gained attention and proved to be a viable solution for providing effective collaboration environments for physically distant collaborators. This study compares head-mounted display (HMD)- and computer-based remote collaboration solutions that allow users to interact with each other through immersive environments. Analyzing remote collaboration in immersive environments requires understanding group interactions and personal experiences. For this purpose, a 3D object assembly task was performed by 10 participants using self-reported surveys and physiological measures to investigate the effectiveness of collaboration from the users' perspective. The results showed that the HMD-based remote collaboration in a virtual reality environment increased the sense of co-presence among the users.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00108","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757558","Virtual environment;virtual reality;co-presence;remote collaboration;physiology;Human-centered computing [Human computer interaction (HCI)]: Interaction paradigms-Mixed/augmented reality;Human-centered computing [Human computer interaction (HCI)]: Interaction paradigms-Collaborative interaction;Human-centered computing [Collaborative and social Computing]: Collaborative and social computing theory;concept and paradigms-Computer supported cooperative work","Social computing;Three-dimensional displays;Head-mounted displays;Conferences;Collaboration;Virtual reality;Resists","","23","","15","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Enhancing Virtual Material Perception with Vibrotactile and Visual Cues","A. Tang; M. Billinghurst; S. Rosset; I. Anderson","Biomimetic Lab, Auckland Bioengineering Institute; Empathic Computing Lab, Auckland Bioengineering Institute; Biomimetic Lab, Auckland Bioengineering Institute; Biomimetic Lab, Auckland Bioengineering Institute",2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"1 May 2023","2023","","","1011","1012","The ability to feel is crucial for a more realistic Virtual Reality (VR) experience. This research demo presents a way to enhance the VR experience through the use of a lightweight glove that provides vibrotactile feedback, allowing the user to feel the stiffness of virtual objects of different materials. The glove uses dielectric elastomer sensors and piezoelectric vibrotactile actuators, and is able to accurately convey the sensation of compressing various real-world objects through vibrotactile and visual cues. This demonstration presents a novel combination of visual information and vibrotactile feedback that has been shown to significantly improve a user's engagement with a VR environment","","979-8-3503-4839-2","10.1109/VRW58643.2023.00351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108678","Haptics feedback;haptic glove;vibrotactile feedback;haptic rendering;stiffness perception;visuo haptic illusion","Visualization;Actuators;Three-dimensional displays;Conferences;Virtual reality;User interfaces;Rendering (computer graphics)","","","","8","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Automatic face recognition system architecture for collaborative virtual environments","A. Adler","School of Information Technology and Engineering, University of Ottawa, Ottawa, Canada",IEEE International Workshop HAVE Haptic Virtual Environments and Their,"6 Jan 2003","2002","","","1","6","In a collaborative virtual environment (CVE) participants are represented by icons called avatars. In order to correctly assign these avatars, participants must be identified as they enter, leave and navigate within the CVE. We present an approach and systems architecture for the use of automatic face recognition (AFR) to accomplish the task of participant identification. The requirements for AFR within a CVE are discussed and distinguished from those for general applications of AFR. A face recognition server has been developed to implement these requirements, and is described. The system is implemented in a Java Server Pages environment, using Java Native Interface to interact with individual face recognition algorithms, and interacts with other CVE components using messages in the SOAP protocol format.","","0-7803-7635-8","10.1109/HAVE.2002.1106905","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1106905","","Face recognition;Collaboration;Biometrics;Avatars;Virtual environment;Appropriate technology;Navigation;Java;Speech analysis;Information technology","","5","13","20","IEEE","6 Jan 2003","","","IEEE","IEEE Conferences"
"Joint manipulation management in collaborative virtual environments","Xiaojun Shen; N. D. Georganas","Distributed and Collaborative Virtual Environments Research Laboratory DISCOVERSchool of Information Technology and Engineering, University of Ottawa, Canada; Distributed and Collaborative Virtual Environments Research Laboratory DISCOVERSchool of Information Technology and Engineering, University of Ottawa, Canada","The 2nd IEEE Internatioal Workshop on Haptic, Audio and Visual Environments and Their Applications, 2003. HAVE 2003. Proceedings.","10 Nov 2003","2003","","","95","99","Some international standards have been developed that are very likely to make a major impact on CVE (Collaborative Virtual Environment) technology: the Distributed Interactive Simulation (DIS) (IEEE Standard 1278.1) and the High Level Architecture (HLA) (IEEE Standard 1516). Deriving from military-purpose simulations, DIS and HLA, however, have limitations on building large-scale general-purpose CVE applications. For instance, HLA object-attribute based ownership management only allows joint manipulation in a constraint-based solution. The purpose of this research effort is to realize joint manipulation management in CVE. This paper begins with a discussion of interaction requests and interaction model and proceeds to describe three generic approaches for joint manipulation management: Constraint-based, Synchronized and Non Synchronized.","","0-7803-8108-4","10.1109/HAVE.2003.1244732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1244732","","Environmental management;Virtual environment;Standards development;International collaboration;Information technology;Electronic mail;Buildings;Large-scale systems;Computer networks;Control systems","","3","","10","IEEE","10 Nov 2003","","","IEEE","IEEE Conferences"
"Combating Latency in Haptic Collaborative Virtual Environments","C. Gunn; M. Hutchins; M. Adcock","Virtual Environments Laboratory, CSIRO, Canberra 2601 Australia; Virtual Environments Laboratory, CSIRO, Canberra 2601 Australia; Virtual Environments Laboratory, CSIRO, Canberra 2601 Australia",Presence,"19 May 2014","2005","14","3","313","328","Haptic (force) feedback is increasingly being used in surgical-training simulators. The addition of “touch” is important extra information that can add another dimension to the realism of the experience. Progress in networking these systems together over long distances has been held back, principally because the latency of the network can induce severe instability in any dynamic objects in the scene. This paper describes techniques allowing long-distance sharing of haptic-enabled, dynamic scenes. At the CSIRO Virtual Environments Laboratory, we have successfully used this system to connect a prototype of a surgical-simulation application between participants on opposite sides of the world in Sweden and Australia, over a standard Internet connection spanning 3 continents and 2 oceans. The users were able to simultaneously manipulate pliable objects in a shared workspace, as well as guide each other's “hands” (and shake hands!) over 22,000 km (13620 miles) of Internet connection. The main obstacle to overcome was the latency-induced instability in the system, caused by the delays and jitter inherent in the network. Our system involved a combination of an event-collection mechanism, a network event-forwarding mechanism and a “pseudophysics” mechanism. We found that the resulting behavior of the interconnected body organs, under simultaneous-user manipulation, was sufficiently convincing to be considered for training surgical procedures.","1054-7460","","10.1162/105474605323384663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6790843","","","","8","1","","","19 May 2014","","","MIT Press","MIT Press Journals"
"AlloHaptic: Robot-Mediated Haptic Collaboration for Learning Linear Functions","H. Khodr; S. Kianzad; W. Johal; A. Kothiyal; B. Bruno; P. Dillenbourg","Computer Human Interaction in Learning and Instruction Laboratory (CHILI), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland; Department of Computer Science, University of British Columbia; Computer Human Interaction in Learning and Instruction Laboratory (CHILI), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland; Computer Human Interaction in Learning and Instruction Laboratory (CHILI), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland; Computer Human Interaction in Learning and Instruction Laboratory (CHILI), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland; Computer Human Interaction in Learning and Instruction Laboratory (CHILI), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland",2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),"14 Oct 2020","2020","","","27","34","Collaborative learning appears in a joint intellectual efforts of individuals to understand an object of knowledge collectively. In their search for understanding the problems, meanings, and solutions, learners employ different multi-modal strategies. In this work, we explore the role of force feedback in learners interaction with tangible hand-held robots. We designed a collaborative learning environment to provide embodied intuitions on linear mathematical functions combined with graphical representations and ran a first study involving 24 participants. Our analysis shows a positive learning gain for our learning activity. Moreover, to explore the link between different types of force feedback and learners’ collaboration, we designed a focus group study with 12 participants. Our results suggest that the haptic communication channel affects the collaboration dynamic differently according to the nature of the learning task. We finish by proposing design insights for future exploration of haptic in collaborative learning.","1944-9437","978-1-7281-6075-7","10.1109/RO-MAN47096.2020.9223563","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9223563","","Visualization;Robot kinematics;Force feedback;Collaboration;Communication channels;Collaborative work;Search problems","","5","","41","IEEE","14 Oct 2020","","","IEEE","IEEE Conferences"
"Dual-Driver Networked Fire Truck Simulator with Multimodal Display including Force Feedback Steering and Rotating Motion Platform","T. Nagai; M. Cohen; Y. Moriguchi; Y. Murakami","Spatial Media Group, University of Aizu, Fukushima, Japan; Spatial Media Group, University of Aizu, Fukushima, Japan; Spatial Media Group, University of Aizu, Fukushima, Japan; Spatial Media Group, University of Aizu, Fukushima, Japan",16th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE 2007),"26 Dec 2007","2007","","","424","430","We describe the integration of two pairs of force displays-- a force-feedback wheel (FFBW) and the S c haire (`Share Chair'), a rotary motion platform-- in a dual- driver networked driving simulator which navigates through virtual space using CVE ( collaborative virtual environment) groupware. We developed a double-driver (long ladder-style) fire-truck simulation with a tiller (rear steering), driven via an integrated pair of networked driving simulator stations. Such a dual-driver system is useful to turn narrow corners rapidly and smoothly in case of (simulated) emergencies. Its FFB steering wheels display simple collision force to both drivers separately when the vehicle collides with walls or other vehicles. The technique of feeding back the effect employs programs using C++ and DirectInput, escaping to an execution file called Force- Manager from the driving simulator, which is implemented with Java3D. Effect patterns are changed by arguments to ForceManager. The S c haire is rotated with a servo- motor, the rotation angle controlled via internet through the CVE. A demonstration video is posted at http: //sonic.u-aizu.ac.jp/spatial-media/ Videos/DualDrivingSimulator.mov . Keywords: dual-driver networked driving simulator, force feedback, haptic interface, rotary motion platform.","1524-4547","978-0-7695-2879-3","10.1109/WETICE.2007.4407202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4407202","","Fires;Displays;Force feedback;Wheels;Vehicle driving;Navigation;Collaboration;Virtual environment;Collaborative software;Collaborative work","","3","1","12","IEEE","26 Dec 2007","","","IEEE","IEEE Conferences"
"Dual-User Teleoperation Systems: New Multilateral Shared Control Architecture and Kinesthetic Performance Measures","B. Khademian; K. Hashtrudi-Zaad","Department of Electrical and Computer Engineering, Queen's University, Kingston, ONT, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ONT, Canada",IEEE/ASME Transactions on Mechatronics,"17 Aug 2012","2012","17","5","895","906","This paper proposes a novel six-channel multilateral shared control architecture for dual-user teleoperation systems. The proposed controller allows interaction between two users as well as the slave and environment through a dominance factor. The dominance factor adjusts the authority of the users over the slave robot and environment. The proposed controller is implemented on a haptic simulation test bed consisting of two planar twin pantograph haptic devices and a simulated pantograph as the slave robot. To analyze the kinesthetic performance of the proposed multilateral shared controller, a number of performance measures are extended or proposed. These measures are evaluated analytically and experimentally for various types of environments, users’ grasps, and levels of dominance of the users over the task.","1941-014X","","10.1109/TMECH.2011.2141673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5772008","Dual-user teleoperation;kinesthetic performance measures;multilateral control;transparency","Impedance;Robots;Force;Haptic interfaces;Teleoperators","","86","","33","IEEE","23 May 2011","","","IEEE","IEEE Journals"
"Real-time Interactions and Synchronization of Voxel-based Collaborative Virtual Environments","E. Acosta; A. Liu","National Capital Area Medical Simulation Center, Uniformed Services University, USA; National Capital Area Medical Simulation Center, Uniformed Services University, USA",2007 IEEE Symposium on 3D User Interfaces,"10 Apr 2007","2007","","","","","Collaborative virtual environments (C-VE) facilitate team-oriented training on virtual reality-based surgical simulators. Many C-VEs replicate the VE on each user's machine to allow for real-time interactions. However, this solution does not work well when modifying voxel-based C-VEs because large and frequent volumetric updates make it difficult to synchronize the C-VE. This paper describes a hybrid depth-buffered image (DBI) and geometry-based rendering method created to simulate visual interactions between local virtual bone cutting tools and remotely maintained volumetric bone material for a craniotomy simulator. For real-time interactions, users only store a DBI of the volumetric C-VE and composite it with rendered images of surgical tools. Additionally, we describe methods to combat network bandwidth/latency to remotely simulate haptic and bone drilling interactions between users' tools and the volumetric VE. For haptic feedback, a multi-rate solution (Cavusoglu and Tendick, 2000) allows users to construct a local approximation of the volumetric C-VE to compute new forces. Only 2D DBI updates are required to synchronize different users when the bone changes due to drilling. Our approach provides an improved performance over a replicated VE that uses 3D model-based updates","","1-4244-0907-1","10.1109/3DUI.2007.340785","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4142856","","Collaboration;Virtual environment;Capacitance-voltage characteristics;Bones;Collaborative work;Surgery;Rendering (computer graphics);Solid modeling;Haptic interfaces;Drilling","","3","4","26","IEEE","10 Apr 2007","","","IEEE","IEEE Conferences"
"Collada-Based File Format for Various Attributes of Realistic Objects in Networked VR Applications Supporting Various Peripherals","K. Miyahara; Y. Okada","Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, JAPAN; Graduate School of Information Science and Electrical Engineering, Kyushu University, Fukuoka, JAPAN",Journal of Mobile Multimedia,"8 Jul 2025","2010","6","2","128","144","This paper proposes an extended COLLADA-based file format to represent various attributes of realistic objects used in Virtual Reality (VR) applications that support various peripherals. VR applications provide the user with virtual objects represented as 3D CG. To provide realistic virtual objects in VR applications, the developer of the VR application has to define many attributes of the corresponding real objects besides their 3D geometry and material data in his/her program or in instance definition files of the virtual objects. In this paper, the authors propose the use of a COLLADA file format for such instance definition of virtual objects because it is a XML based 3D model data format and can be easily extended to additionally include various attributes of the virtual objects. This paper introduces the proposed COLLADA-based file format that mainly supports four types of attributes. Those are for haptic parameters of soft objects represented by the spring model used for a haptic device like Phantom, sound data for generating a sound when the user touches a 3D object, text data used as annotations for explaining corresponding objects helpful in simulation/training systems and smell information of objects used for smell generator devices to enhance immersive feeling in VR applications. This paper also clarifies the usefulness of the proposed COLLADA-based file format by showing its examples of actual networked VR applications, and the authors also mention its adaptability to mobile 3D graphics applications by showing one mobile 3D graphics application.","1550-4654","","JMM/JMM.2010.11074379","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11074379","Virtual reality;immersive environments;Phantom;COLLADA;touch interface device","Solid modeling;Three-dimensional displays;Phantoms;Surgery;Prototypes;Virtual reality;Data models;Real-time systems;Haptic interfaces;Springs","","","","21","","8 Jul 2025","","","River Publishers","River Publishers Journals"
"A Novel Method for Supporting Massively Multi-user Virtual Environments","D. T. Ahmed; S. Shirmohammadi; J. C. De Oliveira","Distributed & Collaborative Virtual Environments Research Laboratory (DISCOVER Lab), University of Ottawa, Ottawa, Ontario, Canada; Distributed & Collaborative Virtual Environments Research Laboratory (DISCOVER Lab), University of Ottawa, Ottawa, Ontario, Canada; Computer Science Department, National Laboratory for Scientific Computing, Petrópolis, Brazil",2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006),"15 Jan 2007","2006","","","72","77","In collaborative distributed virtual environment people interact with each other to shard their states. In this paper we present massively multi-user virtual simulation architecture - MMVISA. The framework partitions the simulation platform into multiple regions to properly organize the decorative entities and to efficiently manage their association. The coordinator, the leader of a zone, manages local communications in multicast fashion but this multicast functionality is shifted from the network layer to the application layer to get the benefit of the scalability and easy deployability. Considering the behavior of the entities, coordinator opens multiple multicast channels to reduce structural reformation events among the entities. On the other hand, coordinators themselves form a top level mesh hierarchy to manage the area of interest. A mathematical model is given to determine the best node in the best zone with a given interest vector. This gives a provision to a node to import all the interesting messages when needed and makes it easy to be virtually there","","1-4244-0760-5","10.1109/HAVE.2006.283807","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4062553","","Virtual environment;Peer to peer computing;Scalability;Virtual reality;Conferences;Haptic interfaces;Application software;Collaborative work;International collaboration;Information technology","","4","","16","IEEE","15 Jan 2007","","","IEEE","IEEE Conferences"
"SensARy Substitution: Augmented Reality Techniques to Enhance Force Perception in Touchless Robot Control","T. Mielke; F. Heinrich; C. Hansen","Faculty of Computer Science, University of Magdeburg, Germany; Faculty of Computer Science, University of Magdeburg, Germany; Faculty of Computer Science, University of Magdeburg, Germany",IEEE Transactions on Visualization and Computer Graphics,"25 Apr 2025","2025","31","5","3235","3244","The lack of haptic feedback in touchless human-robot interaction is critical in applications such as robotic ultrasound, where force perception is crucial to ensure image quality. Augmented reality (AR) is a promising tool to address this limitation by providing sensory substitution through visual or vibrotactile feedback. The implementation of visual force feedback requires consideration not only of feedback design but also of positioning. Therefore, we implemented two different visualization types at three different positions and investigated the effects of vibrotactile feedback on these approaches. Furthermore, we examined the effects of multimodal feedback compared to visual or vibrotactile output alone. Our results indicate that sensory substitution eases the interaction in contrast to a feedback-less baseline condition, with the presence of visual support reducing average force errors and being subjectively preferred by the participants. However, the more feedback was provided, the longer users needed to complete their tasks. Regarding visualization design, a 2D bar visualization reduced force errors compared to a 3D arrow concept. Additionally, the visualizations being displayed directly on the ultrasound screen were subjectively preferred. With findings regarding feedback modality and visualization design our work represents an important step toward sensory substitution for touchless human-robot interaction.","1941-0506","","10.1109/TVCG.2025.3549856","Bundesministerium für Bildung und Forschung; Research Campus STIMULATE(grant numbers:13GW0473A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10926846","Augmented Reality;Sensory Substitution;Force Perception;Human-Robot Interaction;Robotic Ultrasound","Force;Visualization;Robot sensing systems;Robots;Ultrasonic imaging;Bars;Force feedback;Probes;Human-robot interaction;Image color analysis","Humans;Robotics;Augmented Reality;Male;Female;Adult;Computer Graphics;Young Adult;Feedback, Sensory;Haptic Interfaces;User-Computer Interface;Touch","","","53","CCBY","14 Mar 2025","","","IEEE","IEEE Journals"
"QoS Provisioning: Key Drivers and Enablers Toward the Tactile Internet in Beyond 5G Era","M. Z. Islam; R. Ali; A. Haider; H. S. Kim","Department of Intelligent Mechatronics Engineering, Sejong University, Seoul, Republic of Korea; Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Spain; Department of Intelligent Mechatronics Engineering, Sejong University, Seoul, Republic of Korea; Department of Intelligent Mechatronics Engineering, Sejong University, Seoul, Republic of Korea",IEEE Access,"19 Aug 2022","2022","10","","85720","85754","The Tactile Internet has become a revolution for Internet technology, greatly improving the transmission of skill sets (audio, video, text, and haptics) over communication channels compared with traditional triple-play data (audio, video, text). It is a strong candidate to support next-generation delay-sensitive and loss-intolerant smart applications. However, stringent requirements for the Tactile Internet, including ultra-low latency, ultra-high reliability, high availability, and ultra-security, present critical challenges to ensure Quality of Service (QoS). Consequently, several approaches have been proposed to meet these QoS requirements. This article reviews QoS provisioning approaches for the Tactile Internet. First, we present key concepts for the fifth-generation and beyond technologies, Tactile Internet, and haptic communication. Second, we discuss the Tactile Internet use cases along with strict QoS requirements. Third, we classify existing solutions, including haptic codecs, control system designs, hybrid schemes, and intelligent prediction models; provide in-depth discussion regarding these approaches to improve QoS for the Tactile Internet applications; and investigate strengths and weaknesses for each proposed solution. Finally, we present open research challenges and discuss potential future research avenues to realize the Tactile Internet services.","2169-3536","","10.1109/ACCESS.2022.3197900","Institute of Information and Communications Technology Planning and Evaluation (IITP) Grant by the Korean Government through the Ministry of Science and ICT (MSIT)(grant numbers:2022-0-00331); National Research Foundation of Korea (NRF); Korean Government through MSIT(grant numbers:2022R1F1A1063662); Strengthening Research and Development Capability Program of Sejong University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9853511","5G/B5G;Tactile Internet;IoT;URLLC;teleoperations;machine learning;codecs;prediction control","Tactile Internet;5G mobile communication;Quality of service;Reliability;Ultra reliable low latency communication;Standards;Prediction algorithms;Machine learning;Predictive models;Teleoperators","","10","","254","CCBY","10 Aug 2022","","","IEEE","IEEE Journals"
"Exploring Stereoscopic Multi-user Interaction with Individual Views","V. Küszter; G. Brunnett; D. Pietschmann","Faculty of Computer Science, Technische Universität Chemnitz, Chemnitz, Germany; Faculty of Computer Science, Technische Universität Chemnitz, Chemnitz, Germany; Faculty of Computer Science, Technische Universität Chemnitz, Chemnitz, Germany",2014 International Conference on Cyberworlds,"15 Dec 2014","2014","","","101","106","When users are interacting in a collaborative virtual environment it can neither be guaranteed that every user has the same input device nor that they have access to the same information. Our research aims at understanding the effects of such asymmetries on the user embodiment in cooperative multi-user environments. In order to do this, a generic interaction application is needed, which can be altered quickly to generate differences in information distribution and interaction possibilities. In this paper we therefore present the development of such a prototyping platform for cooperative interaction between two users in a stereoscpoic cooperative virtual world. A flexible software framework enables us to quickly generate physics-based puzzles for the users to solve together. To change the information a user gets, we are incorporating ""special views"" for each person. To diversify interaction fidelity, an easily expandable array of input devices is supported, e.g. Mouse/Keyboard, Novint Falcon, Razer Hydra, ART Flight stick, etc. Those devices can provide additional information to a user, like hap tic feedback, but they can also restrain a user by providing less degrees of freedom. Additionally, they can be used to compare different interaction metaphors, like handover, object possession, or picking behavior.","","978-1-4799-4677-8","10.1109/CW.2014.22","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6980749","virtual reality;multi-user;interaction;stereoscopy","Games;Mice;Stereo image processing;Haptic interfaces;Software;Keyboards;Three-dimensional displays","","3","","20","IEEE","15 Dec 2014","","","IEEE","IEEE Conferences"
"Visual and force feedback time-delays change telepresence: Quantitative evidence from crossmodal congruecy task","A. Sengül; F. Rivest; M. van Elk; O. Blanke; H. Bleuler","Laboratory of Cognitive Neuroscience Brain Mind Institute, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland; Robotic Systems Laboratory (LSRO), Ecole Poly technique Fédérale de Lausanne (EPFL), Lausanne, Switzerland; Laboratory of Cognitive Neuroscience Brain Mind Institute, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland; Laboratory of Cognitive Neuroscience Brain Mind Institute, Ecole Polytechnique Fédérale de Lausanne (EPFL), Switzerland; Robotic Systems Laboratory (LSRO), Ecole Poly technique Fédérale de Lausanne (EPFL), Lausanne, Switzerland",2013 World Haptics Conference (WHC),"7 Oct 2013","2013","","","577","582","In the field of surgical robotics, it is difficult to find objective assessment techniques for evaluating telepresence. In this study we try to merge the concepts from cognitive neuroscience more specifically from the field of tool incorporation (embodiment) into surgical robotics in order to assess quantitatively the affect of delayed feedback on the telepresence. Hence, this study investigates the relationship between tool-incorporation (in this case the haptic device of the surgical console) and the decrease of performance due to time delays. A cognitive neuroscience method called the crossmodal congruency effect (CCE) is used to measure the level of tool incorporation and thus indirectly the level of telepresence while performing a simulated surgical-like task. The result of this study shows that user telepresence level and performance measures decrease with increasing delayed visual and haptic feedback.","","978-1-4799-0088-6","10.1109/WHC.2013.6548472","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6548472","Telepresence;haptic feedback;delay;crossmodal congruency effect;tool use;tool incorporation","Delays;Visualization;Robots;Thumb;Surgery;Force feedback","","7","","24","IEEE","7 Oct 2013","","","IEEE","IEEE Conferences"
"The Two-User Seating Buck: Enabling Face-to-Face Discussions of Novel Car Interface Concepts","H. Salzmann; B. Froehlich","Volkswagen AG Wolfsburg, Germany; Bauhaus Universitat Weimar, Germany",2008 IEEE Virtual Reality Conference,"4 Apr 2008","2008","","","75","82","The automotive industry uses physical seating bucks, which are minimal mockups of a car interior, to assess various aspects of the planned interior early in the development process. In a virtual seating buck, users wear a head-mounted display (HMD) which overlays a virtual car interior on a physical seating buck. We have developed a two-user virtual seating buck system, which allows two users to take the role of the driver and co-driver respectively. Both users wear tracked head-mounted displays and see the virtual car interior from the respective view points enabling them to properly interact with the interface elements of a car. We use this system for the development, test and evaluation of novel human-machine interface concepts for future car models. We provide each user with an avatar, since the two co-located users need to see each others' actions. Our evaluation of different head and hand models for representing the two users indicate that the user representations and motions should be as realistic as possible even though the focus is on testing interface elements operated by the users' fingers. The participants of our study also expressed that they clearly prefer the two-user seating buck over a single-user system since it directly supports the face-to-face discussions of features and problems of a newly developed interface.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480754","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480754","mixed reality;multi-user systems;collaborative virtual environment;human-machine interfaces;co-location;I.3.1 [Computer Graphics]: Hardware Architecture-Three-dimensional displays;I.3.6 [Computer Graphics]: Methodology and Techniques-Ergonomics;I.3.6 [Computer Graphics]: Methodology and Techniques-Interaction techniques;I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Virtual reality","Man machine systems;Avatars;Computer graphics;Testing;Virtual reality;Fingers;Automotive engineering;Displays;Virtual environment;Hardware","","16","8","19","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"Design of a Desktop Virtual Reality-Based Collaborative Activities Simulator (ViRCAS) to Support Teamwork in Workplace Settings for Autistic Adults","A. Z. Amat; D. Adiani; M. Tauseef; M. Breen; S. Hunt; A. R. Swanson; A. S. Weitlauf; Z. E. Warren; N. Sarkar","Department of Electrical and Computer Engineering, Vanderbilt University, Nashville, TN, USA; Department of Computer Science, Vanderbilt University, Nashville, TN, USA; Department of Electrical and Computer Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Treatment and Research Institute for Autism Spectrum Disorders, Nashville, TN, USA; Department of Pediatrics, Vanderbilt University Medical Center, Nashville, TN, USA; Department of Pediatrics, Vanderbilt University Medical Center, Nashville, TN, USA; Department of Mechanical Engineering, Department of Electrical and Computer Engineering, Department of Computer Science, Vanderbilt University, Nashville, TN, USA",IEEE Transactions on Neural Systems and Rehabilitation Engineering,"5 May 2023","2023","31","","2184","2194","Autistic adults possess many skills sought by employers, but may be at a disadvantage in the workplace if social-communication differences negatively impact teamwork. We present a novel collaborative virtual reality (VR)-based activities simulator, called ViRCAS, that allows autistic and neurotypical adults to work together in a shared virtual space, offering the chance to practice teamwork and assess progress. ViRCAS has three main contributions: 1) a new collaborative teamwork skills practice platform; 2) a stakeholder-driven collaborative task set with embedded collaboration strategies; and 3) a framework for multimodal data analysis to assess skills. Our feasibility study with 12 participant pairs showed preliminary acceptance of ViRCAS, a positive impact of the collaborative tasks on supported teamwork skills practice for autistic and neurotypical individuals, and promising potential to quantitatively assess collaboration through multimodal data analysis. The current work paves the way for longitudinal studies that will assess whether the collaborative teamwork skill practice that ViRCAS provides also contributes towards improved task performance.","1558-0210","","10.1109/TNSRE.2023.3271139","NSF(grant numbers:1936970,2033413); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10109859","Intelligent system;virtual reality;collaborative virtual environment;human computer interaction;autism;teamwork","Task analysis;Teamwork;Employment;Behavioral sciences;Virtual environments;Training;Stakeholders","Humans;Adult;Autistic Disorder;Virtual Reality;Communication;Workplace","13","","64","CCBY","27 Apr 2023","","","IEEE","IEEE Journals"
"Collaborative Virtual Assembly Environment for Product Design","S. Sharma; S. -T. Bodempudi; M. Arrolla; A. Upadhyay","Department of Computer Science, Bowie State University, Bowie, MD, USA; Department of Computer Science, Bowie State University, Bowie, MD, USA; Department of Computer Science, Bowie State University, Bowie, MD, USA; Equiskill Insights, Banglore, INDIA",2019 International Conference on Computational Science and Computational Intelligence (CSCI),"20 Apr 2020","2019","","","606","611","Collaborative virtual assembly environment is a vital computer-aided design tool in product design and can be used as a learning and training tool. It helps in supporting complex product design by enabling designers to collaborate and communicate with other designers involved in the product design. This paper proposes a collaborative virtual assembly environment built in two phases for the immersive and non-immersive environments. Phase one was developed in Unity 3D using Virtual Reality Toolkit (VRTK) and Steam VR. Whereas, phase two was built using Vizard and Vizible. This work aims to allow scientists and engineers to discuss the concept design in a real-time VR environment so that they can interact with the objects and review their work before it is deployed. This paper proposes the system architecture and describes the design and implementation of a collaborative virtual assembly environment. The outcome of this work is to be able to resolve communication and interaction problems that arise during the concept-design phase.","","978-1-7281-5584-5","10.1109/CSCI49370.2019.00114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9071219","virtual reality, assembly system, collaborative virtual environment, computer-aided design, collaborative concept design","Collaboration;Three-dimensional displays;Solid modeling;Training;Virtual environments;Real-time systems","","5","","25","IEEE","20 Apr 2020","","","IEEE","IEEE Conferences"
"Haptics for Product Design and Manufacturing Simulation","P. Xia","School of Computer Science and Engineering, 693 Xiongchu Avenue, Wuhan, Hubei, P. R. China",IEEE Transactions on Haptics,"15 Sep 2016","2016","9","3","358","375","Product design and manufacturing simulation is a promising research and application area for haptics. By benefiting from its natural human-computer interaction and realistic force/torque feedback, haptics can change the traditional design and manufacturing approaches which are mainly based on physical mock-ups or CAD (Computer Aided Design) modes. This paper provides a detailed and comprehensive survey of haptics for product design and manufacturing simulation in the past 10 years, mainly from 2004-2014, including haptics for product design and shape modelling, haptics for machining simulation, and haptics for virtual assembly and maintenance simulation. The new haptic devices and rendering algorithms involved in this area are introduced, the major research efforts and the typical systems are discussed, and the new ideas and research progresses are investigated. Then, conclusions and future trends are summarized.","2329-4051","","10.1109/TOH.2016.2554551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7452616","Haptics;manufacture simulation;product design;machining;assembly;maintenance;survey","Haptic interfaces;Force;Product design;Manufacturing;Solid modeling;Computational modeling;Impedance","Algorithms;Computer-Aided Design;Feedback;Humans;Touch;User-Computer Interface","30","","111","IEEE","14 Apr 2016","","","IEEE","IEEE Journals"
"Gaze Augmented Hand-Based Kinesthetic Interaction: What You See is What You Feel","Z. Li; D. Akkil; R. Raisamo","Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland",IEEE Transactions on Haptics,"18 Jun 2019","2019","12","2","114","127","Kinesthetic interaction between the user and the computer mainly utilizes the hand-based input with force-feedback devices. There are two major shortcomings in hand-based kinesthetic interaction: physical fatigue associated with continuous hand movements and the limited workspace of current force-feedback devices for accurately exploring a large environment. To address these shortcomings, we developed two interaction techniques that use eye gaze as an additional input modality: HandGazeTouch and GazeTouch. Hand GazeTouch combines eye gaze and hand motion as the input for kinesthetic interaction, i.e., it uses eye gaze to point and hand motion to touch. GazeTouch replaces all hand motions in touch behavior with eye gaze, i.e., it uses eye gaze to point and gaze dwell time to trigger the touch. In both interaction techniques, the user feels the haptic feedback through the force-feedback device. The gaze-based techniques were evaluated in a softness discrimination experiment by comparing them to the traditional kinesthetic interface, HandTouch, which only uses the hand-based input. The results indicate that the HandGazeTouch technique is not only as accurate, natural, and pleasant as the traditional interface but also more efficient.","2329-4051","","10.1109/TOH.2019.2896027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8632737","Kinesthetic interaction;gaze tracking;hand-eye coordination;force-feedback device;workspace;fatigue.","Fatigue;Task analysis;Haptic interfaces;Hip;Force;Performance evaluation;Safety","Adult;Biomechanical Phenomena;Eye Movements;Female;Hand;Humans;Kinesthesis;Male;Psychomotor Performance;Touch Perception;User-Computer Interface;Young Adult","6","","52","IEEE","1 Feb 2019","","","IEEE","IEEE Journals"
"Collaborative virtual training using force feedback devices","M. A. F. Rodrigues; R. R. C. Chaves; W. B. Silva","Mestrado em Informática Aplicada Centro de Ciências Tecnológicas, Universidade de Fortaleza (UNIFOR), Fortaleza, Ceara, Brazil; Mestrado em Informática Aplicada Centro de Ciências Tecnológicas, Universidade de Fortaleza (UNIFOR), Fortaleza, Ceara, Brazil; Bacharelado em Informática Centro de Ciências Tecnológicas, Universidade de Fortaleza (UNIFOR), Fortaleza, Ceara, Brazil",Proceedings. 17th Brazilian Symposium on Computer Graphics and Image Processing,"8 Nov 2004","2004","","","332","339","Force feedback plays an important role in collaborative virtual reality environments, mainly for programmers of haptic visualization tools. Whereas a great deal of work has gone into graphical displays over the past years, little has changed on the input side. One of the problems that has slowed down development in this area is the difficulty of integrating the visualization of a scene, the interaction of the user with the scene, the feeling for the user to be immersed inside the scene, and finally, the input devices. We describe the architecture we have designed, implemented and tested for a collaborative virtual training using force feedback devices. In particular, it provides device independence and easy extensibility through a compartmentalized and multilayered model. We also present examples of how force feedback joysticks can be integrated into training exercises using our prototype.","1530-1834","0-7695-2227-0","10.1109/SIBGRA.2004.1352978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1352978","","Collaboration;Force feedback;Layout;Collaborative work;Visualization;Collaborative tools;Virtual reality;Programming profession;Haptic interfaces;Displays","","6","","25","IEEE","8 Nov 2004","","","IEEE","IEEE Conferences"
"Challenges for real time long distance holoportation to enable human bond communication","A. Manolova; N. Neshov; K. Tonchev; P. Koleva; V. Poulkov","Faculty of Telecommunications, Technical University - Sofia, Sofia, Bulgaria; Faculty of Telecommunications, Technical University - Sofia, Sofia, Bulgaria; Faculty of Telecommunications, Technical University - Sofia, Sofia, Bulgaria; Faculty of Telecommunications, Technical University - Sofia, Sofia, Bulgaria; Faculty of Telecommunications, Technical University - Sofia, Sofia, Bulgaria",2019 42nd International Conference on Telecommunications and Signal Processing (TSP),"25 Jul 2019","2019","","","529","534","Nowadays, the way people see the world and interact between each other is changing; new technologies are paving the way of innovative solutions for communication between humans. The recent research work on relevant topics and the rapid development of powerful hardware and software implementations allow for building of new communications pathways for lifelike interaction between people in different locations called human bond communication. One very new technology may offer the practical application of human bond communication is holoportation, but it also presents a lot of challenges in terms of digital data gathering and transmission. By combining appropriate technics, we propose an approach for holoportation combined with haptic technology between same controlled environments. We present a conceptual model of holoportation architecture for real time communication based on highly accurate 3D modelling of the human face and body, recognition and prediction of human actions and facial expressions to achieve realistic communications. Designed this way the proposed conceptual model of the holoportation system addresses the challenges from the information transmission aspect where real time constraints and narrowband channels are imposed, while big amounts of data, such as 3D body models of humans need to be transmitted.","","978-1-7281-1864-2","10.1109/TSP.2019.8769053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769053","holoportation;immersive telepresence;human bond communication;mixed reality;prediction of human actions and facial expressions;haptics","Real-time systems;Three-dimensional displays;Telepresence;Haptic interfaces;Solid modeling;Sensors;Data models","","2","","23","IEEE","25 Jul 2019","","","IEEE","IEEE Conferences"
"Using a rendering engine to support the development of immersive virtual reality applications","S. R. dos Santos; J. C. de Oliveira; L. M. Fraga; P. R. Trenhago; S. M. Malfatti","Departamento deInformatica e Matematica Aplicada, Universidade Federal do Rio Grande do Norte, Natal, Brazil; Laboratorio Nacional de Computacao Cientifica, Petropolis, Brazil; Laboratorio Nacional de Computacao Cientifica, Petropolis, Brazil; Laboratorio Nacional de Computacao Cientifica, Petropolis, Brazil; Laboratorio Nacional de Computacao Cientifica, Petropolis, Brazil","2008 IEEE Conference on Virtual Environments, Human-Computer Interfaces and Measurement Systems","8 Aug 2008","2008","","","74","79","This work presents the features of a flexible realtime 3D graphics engine aimed at the development of multimedia applications and collaborative virtual environments. The engine, called EnCIMA (Engine for Collaborative and Immersive Multimedia Applications), enables a quick development process of applications by providing a high level interface, which has been implemented using the C++ object-oriented programming paradigm. Important characteristics of the engine are the integration of several real time graphics techniques needed by visualization applications; access to network connection management to support collaboration; 3D sound capability; the support to various specialized interaction equipments such as 3D mice, haptic devices, 3D motion trackers, data-gloves, joypads, force feedback joysticks, and; the capacity to have rendering computation and Physics simulation assigned to GPUs and PPUs, respectively. The engine also enables the developer to choose how the scene should be rendered to, i.e. using standard display devices, stereoscopy, or even several simultaneous projection for spatially immersive displays. As part of the evaluation process, we have compared the performance of EnCIMA to a game engine and two scene graph toolkits, through the use of a testbed application.","1944-9410","978-1-4244-1927-2","10.1109/VECIMS.2008.4592756","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4592756","Virtual reality engine;immersive application;real time rendering;collaborative virtual reality","Engines;Three dimensional displays;Graphics;Collaboration;Solid modeling;Games;Haptic interfaces","","2","1","13","IEEE","8 Aug 2008","","","IEEE","IEEE Conferences"
"Application of robotic mechanisms to simulation of the international space station","E. Freund; J. Rossmann; C. Turner","Institute of Robotics Research, Dortmund, Germany; Institute of Robotics Research, Dortmund, Germany; Institute of Robotics Research, Dortmund, Germany",Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453),"3 Dec 2003","2003","4","","3047","3052 vol.3","In 2004, the European COLUMBUS Module is to be attached to the International Space Station. On the way to the successful planning, deployment and operation of the module, computer generated and animated models are being used to optimize performance. Under contract of the German Space Agency DLR, it has become IRF's task to provide a Projective Virtual Reality System to provide a virtual world built after the planned layout of the COLUMBUS module enabling astronauts and scientists to practice operational procedures and the handling of experiments. The possibility for distributed multiuser access to the virtual lab and the visualization of real-world experiment data comprise the key features of the system. Through the ability to share the virtual world, cooperative operations can be practiced easily and trainers and trainees can work together more effectively in the shared virtual environment. The ability to visualize real-world data will be used to introduce measured experimental data into the virtual world online in order to allow realistic interaction with the science reference model hardware: The user's actions in the virtual world are translated into corresponding changes of the inputs of the science reference model hardware; the measured data is then in turn fed back into the virtual world. In order to provide astronauts and scientists with an even more complete insight into various aspects of COLUMBUS and the ISS, the simulation of the COLUMBUS module is currently being extended to include the entire International Space Station. This paper describes the background and the developed features which allow the creation of a virtual world that provides users with the feel of being on board the ISS.","","0-7803-7860-1","10.1109/IROS.2003.1249624","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1249624","","Orbital robotics;International Space Station;Data visualization;Extraterrestrial measurements;Hardware;Application software;Computational modeling;Animation;Contracts;Virtual reality","","2","","8","IEEE","3 Dec 2003","","","IEEE","IEEE Conferences"
"Non-Contact Thermo-Visual Augmentation by IR-RGB Projection","D. Iwai; M. Aoki; K. Sato",Graduate School of Engineering Science; Graduate School of Engineering Science; Graduate School of Engineering Science,IEEE Transactions on Visualization and Computer Graphics,"26 Feb 2019","2019","25","4","1707","1716","This paper presents an approach for non-contact haptic augmentation with spatial augmented reality (SAR). We construct a thermo-visual projection system by combining a standard RGB projector and a fabricated infrared (IR) projector. The primary contribution of this paper is that we conduct thorough psychophysical experiments to investigate a design guideline for spatiotemporal projection patterns for both RGB and IR projectors to render a warm object with high presence. We develop application systems to evaluate the validity of the proposed system and design guideline. The evaluation results demonstrate that the proposed system can render warm objects with significantly higher presence than a standard SAR system.","1941-0506","","10.1109/TVCG.2018.2820121","JSPS KAKENHI(grant numbers:JP15H05925); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8327511","Spatial augmented reality;projection mapping;IR projector;cross modal;non-contact haptic feedback","Visualization;Haptic interfaces;Skin;Mirrors;Spatial resolution;Temperature measurement;Heating systems","","11","","34","IEEE","28 Mar 2018","","","IEEE","IEEE Journals"
"Immersive Multiplayer VR: Unreal Engine’s Strengths, Limitations, and Future Prospects","S. Berrezueta-Guzman; S. Wagner","Chair of Software Engineering, Technical University of Munich, Heilbronn, Germany; Chair of Software Engineering, Technical University of Munich, Heilbronn, Germany",IEEE Access,"20 May 2025","2025","13","","85597","85612","Virtual Reality (VR) has revolutionized digital interactions, particularly in multiplayer games, where players engage in immersive experiences that foster social connectivity and collaboration. Unreal Engine is at the core of this evolution, a powerful development platform known for its advanced networking tools, VR-specific capabilities, and seamless cross-platform support. Unreal Engine’s cross-platform support also ensures accessibility and scalability across diverse devices. This paper analyzes Unreal Engine’s role in advancing multiplayer VR development, focusing on its ability to create immersive environments that enhance user engagement and social interaction. We examined key features such as real-time networking for seamless communication, detailed avatar customization, and realistic environmental rendering, all contributing to an enhanced sense of presence. Beyond its technical features, this research identifies key challenges in multiplayer VR gaming, including latency, scalability, and ethical concerns related to inclusivity and user privacy. We propose future directions to address these issues, such as integrating artificial intelligence (AI), enhancing haptic feedback, and optimizing large-scale VR projects. By bridging these gaps, Unreal Engine can strengthen its role as a pioneering platform for social interaction, education, and collaboration in virtual spaces. This study also evaluates Unreal Engine’s effectiveness in facilitating social interaction and compares its capabilities with alternative platforms. The findings highlight best practices for VR game developers and provide recommendations to enhance user engagement and accessibility, ensuring that multiplayer VR continues to evolve as a transformative medium.","2169-3536","","10.1109/ACCESS.2025.3570166","TUM Campus Heilbronn Incentive Fund 2024 of the Technical University of Munich, TUM Campus Heilbronn; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11004002","AI-driven VR interactions;avatar customization;cross-platform VR development;haptic feedback in VR;immersive environments;literature review;multiplayer virtual reality (VR);real-time VR communication;scalability in multiplayer VR;social interaction in VR;unreal engine","Avatars;Engines;Collaboration;Scalability;Systematic literature review;Real-time systems;Focusing;Haptic interfaces;Games;Ethics","","2","","121","CCBY","14 May 2025","","","IEEE","IEEE Journals"
"Real-Time Medical Training in Virtual Reality over 5G Open RAN: A Performance Study","V. Ravihansa; C. Sandeepa; O. Vasilapostolos; F. McAuliffe; E. Mangina; M. Liyanage","School of Computer Science, University College, Dublin, Ireland; School of Computer Science, University College, Dublin, Ireland; Quanta & Qualia, Athens, Greece; UCD Perinatal Research Centre, University College Dublin, National Maternity Hospital, Dublin, Ireland; School of Computer Science, University College, Dublin, Ireland; School of Computer Science, University College, Dublin, Ireland",2025 IEEE 50th Conference on Local Computer Networks (LCN),"15 Sep 2025","2025","","","1","7","The convergence of immersive technologies and next-generation communication networks offers new potential for advancing surgical training. This paper presents the Magos Bakri Balloon Placement Training (MBBPT) system, a Virtual Reality (VR) simulation platform integrated with haptic feedback and 5th Generation (5G) Open Radio Access Network (O-RAN) connectivity. The system enables realistic and interactive medical training, leveraging submillimeter-precision hand tracking and kinesthetic feedback from Magos gloves. To evaluate the feasibility and performance of network-assisted VR training, MBBPT was tested across a disaggregated O-RAN-based private 5G testbed at University College Dublin (UCD), a standalone private 5G testbed at Patras, and a cross-site setup linking both. The setup assessed Key Performance Indicators (KPIs) and Key Value Indicators (KVIs) to show the system supports responsive, multiuser VR interactions across geographically distributed sites, with consistent performance. These findings highlight the role of 5G O-RAN as an enabler for scalable, collaborative, high-fidelity immersive medical education.","2832-1421","979-8-3315-3703-6","10.1109/LCN65610.2025.11146288","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11146288","Virtual Reality;5G O-RAN;network performance evaluation;haptic feedback;medical training","Training;5G mobile communication;Key performance indicator;Surgery;Open RAN;Virtual reality;Real-time systems;Haptic interfaces;Systems support;Next generation networking","","","","15","IEEE","15 Sep 2025","","","IEEE","IEEE Conferences"
"Haptic Feedback Relocation from the Fingertips to the Wrist for Two-Finger Manipulation in Virtual Reality","J. E. Palmer; M. Sarac; A. A. Garza; A. M. Okamura","Department of Mechanical Engineering, Stanford University, CA, USA; Department of Mechatronics Engineering, Kadir Has University, Istanbul, Turkey; Department of Mechanical Engineering, Stanford University, CA, USA; Department of Mechanical Engineering, Stanford University, CA, USA",2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"26 Dec 2022","2022","","","628","633","Relocation of haptic feedback from the fingertips to the wrist has been considered as a way to enable haptic interaction with mixed reality virtual environments while leaving the fingers free for other tasks. We present a pair of wrist-worn tactile haptic devices and a virtual environment to study how various mappings between fingers and tactors affect task performance. The haptic feedback rendered to the wrist reflects the interaction forces occurring between a virtual object and virtual avatars controlled by the index finger and thumb. We performed a user study comparing four different finger-to-tactor haptic feedback mappings and one no-feedback condition as a control. We evaluated users' ability to perform a simple pick-and-place task via the metrics of task completion time, path length of the fingers and virtual cube, and magnitudes of normal and shear forces at the fingertips. We found that multiple mappings were effective, and there was a greater impact when visual cues were limited. We discuss the limitations of our approach and describe next steps toward multi-degree-of-freedom haptic rendering for wrist-worn devices to improve task performance in virtual environments.","2153-0866","978-1-6654-7927-1","10.1109/IROS47612.2022.9981392","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9981392","","Wrist;Performance evaluation;Visualization;Thumb;Virtual environments;Mixed reality;Rendering (computer graphics)","","12","","15","IEEE","26 Dec 2022","","","IEEE","IEEE Conferences"
"The wobbly table: Increased social presence via subtle incidental movement of a real-virtual table","M. Lee; K. Kim; S. Daher; A. Raij; R. Schubert; J. Bailenson; G. Welch",University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida; University of Central Florida and UNC-Chapel Hill; Stanford University; University of Central Florida,2016 IEEE Virtual Reality (VR),"7 Jul 2016","2016","","","11","17","While performing everyday interactions, we often incidentally touch and move objects in subtle ways. These objects are not necessarily directly related to the task at hand, and the movement of an object might even be entirely unintentional. If another person is touching the object at the same time, the movement can transfer through the object and be experienced — however subtly — by the other person. For example, when one person hands a drink to another, at some point both individuals will be touching the glass, and consequently exerting small (often unnoticed) forces on the other person. Despite the frequency of such subtle incidental movements of shared objects in everyday interactions, few have examined how these movements affect human-virtual human (VH) interaction. We ran an experiment to assess how presence and social presence are affected when a person experiences subtle, incidental movement through a shared real-virtual object. We constructed a real-virtual room with a table that spanned the boundary between the real and virtual environments. The participant was seated on the real side of the table, which visually extended into the virtual world via a projection screen, and the VH was seated on the virtual side of the table. The two interacted by playing a game of “Twenty Questions,” where one player asked the other a series of 20 yes/no questions to deduce what object the other player was thinking about. During the game, the “wobbly” group of subjects experienced subtle incidental movements of the real-virtual table: the entire real-virtual table tilted slightly away/toward the subject when the virtual/real human leaned on it. The control group also played the same game, except the table did not wobble. Results indicate that the wobbly group had higher presence and social presence with the virtual human in general, with statistically significant increases in presence, co-presence, and attentional allocation. We present the experiment and results, and discuss some potential implications for virtual human systems and some potential future studies.","2375-5334","978-1-5090-0836-0","10.1109/VR.2016.7504683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7504683","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, Augmented and Virtual Realities;J.4 [Computer Applications]: Social and Behavioral Sciences — Psychology","Electronic mail;Measurement by laser beam;Virtual environments;Games;Training;Haptic interfaces;Force","","40","","42","IEEE","7 Jul 2016","","","IEEE","IEEE Conferences"
"A DASH-Based Adaptive Multiple Sensorial Content Delivery Solution for Improved User Quality of Experience","L. Zou; T. Bi; G. -M. Muntean","Peng Cheng Laboratory, PCL Research Center of Networks and Communications, Southern University of Science and Technology, Shenzhen, China; Performance Engineering Laboratory, School of Electronic Engineering, Dublin City University, Dublin 9, Ireland; Performance Engineering Laboratory, School of Electronic Engineering, Dublin City University, Dublin 9, Ireland",IEEE Access,"16 Jul 2019","2019","7","","89172","89187","Increasing number of researchers are focusing on the emerging communication technologies which enrich user perceived quality of experience by involving vision, auditory, tactile, olfaction, gustatory, and other senses. However, there are multiple challenges related to using multiple sensorial media (i.e., mulsemedia), including synchronization with the traditional multimedia content and delivery over diverse network environments. This paper proposes MulseDASH, a novel multiple sensorial media content delivery solutions based on the Dynamic Adaptive Streaming over HTTP standard (DASH). MulseDASH is described and evaluated in a real test-bed in terms of the effectiveness of its adaptive streaming and synchronization mechanisms. The extensive testing involving both network emulation and subjective assessment experiments shows how MulseDASH performs an excellent real-time streaming adjustment to match network conditions and improves user quality of experience.","2169-3536","","10.1109/ACCESS.2019.2926207","European Union’s Horizon 2020 Research and Innovation programme(grant numbers:688503); China Postdoctoral Science Foundation(grant numbers:2017M622777); PCL Future Regional Network Facilities for Large-scale Experiments and Applications(grant numbers:PCL2018KP001); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8752224","Mulsemedia;MPEG DASH;quality of experience","Media;Streaming media;Haptic interfaces;Quality of experience;Robot sensing systems;Actuators;Force","","22","","59","CCBY","1 Jul 2019","","","IEEE","IEEE Journals"
"Digital Transformation in Nursing Education: A Systematic Review on Computer-Aided Nursing Education Pedagogies, Recent Advancements and Outlook on the Post-COVID-19 Era","N. K. Dicheva; I. U. Rehman; A. Anwar; M. M. Nasralla; L. Husamaldin; S. Aleshaiker","School of Computing and Engineering, University of West London, London, U.K; School of Computing and Engineering, University of West London, London, U.K; School of Computing and Engineering, University of West London, London, U.K; Smart Systems Engineering Laboratory, Prince Sultan University, Riyadh, Saudi Arabia; School of Computing and Engineering, University of West London, London, U.K; School of Computing and Engineering, University of West London, London, U.K",IEEE Access,"7 Dec 2023","2023","11","","135659","135695","The COVID-19 pandemic has transformed nursing education worldwide. Due to the globally applied restrictions of interpersonal interactions, many educational institutions transitioned from traditional to computer-aided nursing education pedagogies. However, an obligatory change, this digital transformation in nursing education, has been deemed promising by students and academics, yet raising concerns about the effectiveness of innovative nursing pedagogies. Hence, this systematic literature review aims to investigate the state of the art of computer-aided nursing pedagogies in the post-COVID-19 era and provide recommendations for further research investigation. Specifically, it utilises a mixed methods approach to examine (1) the evolution of computer-aided nursing pedagogies before and after COVID-19; (2) their effectiveness against traditional methods in terms of knowledge, skills acquisition and self-efficiency; and (3) nursing students’ experiences and opinions when exposed to computer-aided nursing education pedagogies. For this purpose, several databases (PubMed, MEDLINE, CINAHL Complete, Academic Search Elite, IEEE, ACM, Scopus, ERIC and Cochrane Library (Controlled trial requests) were searched, initially retrieving 802 articles published between 2013-2023. After removing duplicates, exclusion criteria and assessment for eligibility, the number of articles assessed for eligibility was reduced to 78 conducted in 20 different countries. The articles comprised quantitative research (n=37), including Randomised Control Trials (n=14) and Quasi-experimental studies (n=23), and qualitative research (n=41) including observational studies (n=14), mixed-methods methodological design (n=15), pilot studies (n=7) and conference papers (n=5). Moreover, this SLR utilised the Joanna Briggs Institute (JBI) methodological approach for conducting a mixed-methods systematic review (MMSR) and provided a narrative synthesis of all studies. The results of this mixed-methods SLR suggested that the post-COVID-19 era has enabled the implementation of a variety of computerised systems in nursing education, including desktop-based systems, mobile applications, Virtual Reality, Augmented Reality, Mixed Reality and holograms, haptics, Artificial Intelligence-enabled chatbots and systems, smart glasses and multimodal systems. The authors found that these computer-aided nursing education pedagogies were superior to traditional nursing pedagogies regarding acquiring knowledge, skills, and self-efficiency. However, the generalisability of the above findings should be interpreted with caution due to variations in sample size and effect size established via Hedges’ g calculations among the 35 quantitative articles. Nevertheless, nursing students’ experiences and opinions were encouragingly positive. Further research is needed to incorporate more realistic and memorable scenarios and examine the effects of computer-aided nursing educational pedagogies on long-term knowledge gains and the effective learning domain.","2169-3536","","10.1109/ACCESS.2023.3337669","U.K.—Saudi Challenge Fund from the British Council’s Going Global Partnerships Programme; “Intelli-Student—A Cutting-Edge Computer-Aided Learning Platform to Augment Online Teaching and Learning Pedagogies: A U.K.—Saudi Partnership Project,’’; U.K.—Saudi Challenge Fund from the British Council’s Going Global Partnerships Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10332192","Nursing;education;computer aided systems;student satisfaction;knowledge gains;COVID-19;digital transformation","Medical services;Education;COVID-19;Haptic interfaces;Pandemics;Systematics;Bibliographies;Computer aided analysis","","12","","146","CCBYNCND","28 Nov 2023","","","IEEE","IEEE Journals"
"A distributed collaborative simulation environment for orthopedic surgical training","J. Cecil; A. Gupta; P. Ramanathan; M. Pirela-Cruz","Center for Cyber Physical Systems, Computer Science Oklahoma State University, Stillwater, Ok; Center for Cyber Physical Systems, Computer Science Oklahoma State University, Stillwater, Ok; Electrical and Computer Engineering, University of Wisconsin-Madison; Orthopedic Surgery, Paul Foster School of Medicine, El Paso, TX",2017 Annual IEEE International Systems Conference (SysCon),"29 May 2017","2017","","","1","8","The use of Virtual Reality (VR) simulators has increased rapidly in the field of medical surgery for training purposes. In this paper, the design and development of a Virtual Surgical Environment (VSE) for training residents in an orthopaedic surgical process called Less Invasive Stabilization System (LISS) surgery is discussed; LISS plating surgery is a process used to address fractures of the femur bone. The development of such virtual environments for educational and training purposes will accelerate and supplement existing training approaches enabling medical residents to be better prepared to serve the surgical needs of the general public. One of the important aspects of the VSE is that it is a network based simulator. Our approach explores the potential of emerging Next Generation Internet frameworks and technologies to support such distributed interaction contexts. A discussion of the validation activities is also presented, which highlights the effectiveness of the VSE for teaching medical residents and students.","2472-9647","978-1-5090-4623-2","10.1109/SYSCON.2017.7934721","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7934721","virtual reality;orthopaedic simulator;LISS plating","Surgery;Training;Solid modeling;Haptic interfaces;Plating;Software","","11","","40","IEEE","29 May 2017","","","IEEE","IEEE Conferences"
"Tactical Training Using Augmented Reality/Virtual Reality and Haptics","S. Vashisht","Department of Computer Science and Engineering, Chitkara University Institute of Engineering and Technology, Chitkara University, Punjab, India",2024 4th International Conference on Technological Advancements in Computational Sciences (ICTACS),"21 Jan 2025","2024","","","646","651","This study investigates the effects of these immersive technologies on military personnel's training efficacy, efficiency, and safety. Virtual reality (VR) immerses users in artificial surroundings, augmented reality (AR) superimposes digital data on the actual world, and haptics adds tactile input to improve realism. These technologies work together to create training simulations that are incredibly realistic, adaptable, and closely mimic real-world situations. Examples of these scenarios include military operations, emergency response protocols, and technical maintenance jobs. This research emphasizes the advantages of AR, VR, and haptics in military training, including higher information retention, improved skill learning, and enhanced preparation for operational difficulties. It does this by doing a thorough assessment of the available literature and case studies. By eliminating the need for live exercises and giving students practical experience in authentic settings, these immersive technologies provide a secure and affordable substitute for conventional training approaches. Furthermore, employees stationed in remote or inaccessible regions may receive training nearly anytime, anywhere, thanks to the scalability and mobility of AR and VR devices. In the future, this field of study will focus on developing increasingly complex simulation environments and on utilizing advances in machine learning and artificial intelligence to build intelligent and adaptable training systems. Furthermore, haptics, AR, and VR are being widely used by allied agencies and military groups, which has great potential for collaborative training platforms and more equitable access to excellent training materials. Incorporating immersive technology into tactical and technical training signifies a fundamental change in military readiness and education, with far-reaching effects on the 21st-century armed forces' efficacy and adaptability.","","979-8-3503-8749-0","10.1109/ICTACS62700.2024.10840957","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10840957","Immersive technologies;Augmented Reality;Virtual Reality;Mixed Reality;Training;Defense","Training;Solid modeling;Adaptation models;Technological innovation;Protocols;Scalability;Haptic interfaces;Personnel;Augmented reality;Smart phones","","","","15","IEEE","21 Jan 2025","","","IEEE","IEEE Conferences"
"Zone Based Messaging in Collaborative Virtual Environments","D. T. Ahmed; S. Shirmohammadi; I. Kazem","Distributed & Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Ottawa, ONT, Canada; Distributed & Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Ottawa, ONT, Canada; Distributed & Collaborative Virtual Environments Research Laboratory, School of Information Technology and Engineering, University of Ottawa, Ottawa, ONT, Canada",2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006),"15 Jan 2007","2006","","","165","170","Massively multi-user simulation requires synchronous communication among the parties. In this paper, we present a multiuser collaboration architecture that divides the virtual world in multiple adjacent hexagonal regions in order to properly organize the entities and efficiently manage their liaison. An especial node, named hybrid node, be in charge of each hexagonal region and constructs a data distribution tree at the application layer rather at the network layer. While constructing the data distribution pathways among the end-hosts, protocol focuses to reflect the physical topology onto the overlay network to enhance the system performance. To control the excessive message overhead, necessary messages of a foreign region are only imported when needed to a particular region through a hybrid node. Dynamic adjustment of cheek-in and check-out marks reduces frequent connections and disconnections between a hybrid and an ordinary node, and provides resilience to the system. The effectiveness of this collaboration architecture is tested through the implementation","","1-4244-0760-5","10.1109/HAVE.2006.283794","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4062535","","Virtual environment;Delay;Collaborative tools;Computer architecture;Collaborative software;Internet;Collaborative work;International collaboration;Peer to peer computing;Management training","","10","","12","IEEE","15 Jan 2007","","","IEEE","IEEE Conferences"
"Control system for the Schaire Internet chair","U. C. Duminduwardena; M. Cohen","Spatial Media Group, University of Aizuwakamatsu, Fukushima, Japan; Spatial Media Group, University of Aizuwakamatsu, Fukushima, Japan","The Fourth International Conference onComputer and Information Technology, 2004. CIT '04.","30 Nov 2004","2004","","","215","220","We have developed second-generation prototypes of the Internet chair, a novel Internet appliance. The first generation explored using the chair as an input device; ""Schaire"", the prototype described here, is a pivot (swivel, rotating) chair deployed as an output device, a rotary motion platform information appliance. Its haptic display modality is yaw, dynamically synchronized with wireless visual displays and spatial audio in a rotation-invariant virtual space. In groupware situations, like teleconferencing, chat spaces, or multiplayer gaming, such orientation is also used to twist iconic representations of a seated user, avatars in a virtual world, enabling social situation awareness. Using its audio display modality, ""nearphones"" embedded in the seat headrest, the system can present unencumbered binaural sound with soundscape stabilization for multichannel sound image localization. As a haptic output modality, chairs with servomotors render kinesthetic and proprioceptive cues, twisting under networked control, to direct the attention of a seated users like a ""dark ride"" amusement park attraction or under active user control, local and/or distributed. The Schaire, manifesting as personal LBE (location-based entertainment) can be used in both stand-alone and networked applications.","","0-7695-2216-5","10.1109/CIT.2004.1357199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1357199","","Control systems;Internet;Auditory displays;Prototypes;Home appliances;Haptic interfaces;Collaborative software;Collaborative work;Teleconferencing;Avatars","","3","1","12","IEEE","30 Nov 2004","","","IEEE","IEEE Conferences"
"An application-layer multicasting protocol for distributed collaboration","S. Shirmohammadi; A. Diabi; P. Lacombe","Distributed Collaborative Virtual Environments Research Lab, University of Ottawa, Canada, Ottawa, Canada; Distributed Collaborative Virtual Environments Research Lab, University of Ottawa, Canada, Ottawa, Canada; Distributed Collaborative Virtual Environments Research Lab, University of Ottawa, Canada, Ottawa, Canada",IEEE International Workshop on Haptic Audio Visual Environments and their Applications,"12 Dec 2005","2005","","","4 pp.","","Although IP multicast can be used to support message transmission among participants in massively large virtual environments, it is typically not available on the Internet. Alternatively, researches have in recent years proposed the use of application layer multicasting techniques (ALM), either using proxies or purely depending on end systems, to allow scalable message passing among peers in a large group of users on the Internet. We propose a hybrid application-layer multicast framework that uses both proxies and end-systems to provide scalable and timely-reliable communication among the participants of a distributed virtual environment over the Internet. Our filed trials using a simulation application shows that the framework performs satisfactorily over the Internet.","","0-7803-9376-7","10.1109/HAVE.2005.1545667","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1545667","","Multicast protocols;Collaboration;Internet;Virtual environment;Delay;Military standards;Routing;Message passing;Disaster management;Telecommunication traffic","","1","","11","IEEE","12 Dec 2005","","","IEEE","IEEE Conferences"
"Collaborative Networked Virtual Surgical Simulators (CNVSS) Implementing Hybrid Client–Server Architecture: Factors Affecting Collaborative Performance","C. Diaz; H. Trefftz; L. Quintero; D. A. Acosta; S. Srivastava",Grupo de Investigación I+D+I en TIC Universidad EAFIT; Grupo de Investigación I+D+I en TIC Universidad EAFIT; Grupo de Investigación de Modelado Matemático Universidad EAFIT; Grupo de Investigación DDP Universidad EAFIT; Department of Surgery Stanford University,Presence,"13 Mar 2015","2014","23","4","393","409","Currently, surgical skills teaching in medical schools and hospitals is changing, requiring the development of new tools to focus on (i) the importance of the mentor’s role, (ii) teamwork skills training, and (iii) remote training support. Collaborative Networked Virtual Surgical Simulators (CNVSS) allow collaborative training of surgical procedures where remotely located users with different surgical roles can take part in the training session. To provide successful training involving good collaborative performance, CNVSS should guarantee synchronicity in time of the surgical scene viewed by each user and a quick response time which are affected by factors such as users’ machine capabilities and network conditions. To the best of our knowledge, the impact of these factors on the performance of CNVSS implementing hybrid client–server architecture has not been evaluated. In this paper the development of a CNVSS implementing a hybrid client–server architecture and two statistical designs of experiments (DOE) is described by using (i) a fractional factorial DOE and (ii) a central composite DOE, to determine the most influential factors and how these factors affect the collaboration in a CNVSS. From the results obtained, it was concluded that packet loss, bandwidth, and delay have a larger effect on the consistency of the shared virtual environment, whereas bandwidth, server machine capabilities, and delay and interaction between factors bandwidth and packet loss have a larger effect on the time difference and number of errors of the collaborative task.","1054-7460","","10.1162/PRES_a_00208","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7060813","","","","2","","","","13 Mar 2015","","","MIT Press","MIT Press Journals"
"Investigating the application of virtual environment technology for use in the petroleum exploration industry","K. V. Nesbitt; R. J. Gallimore; B. J. Orenstein","Dept. of Comput. Sci., Newcastle Univ., NSW, Australia; Sofhwrc Engirleerirlg Architect, BHP Information Technology, Newcastle, Australia; Softwre Engineer, Agents Pty Limited, Sydney, Australia",Proceedings 23rd Australasian Computer Science Conference. ACSC 2000 (Cat. No.PR00518),"6 Aug 2002","2000","","","181","188","Although the concepts of virtual environments or virtual reality have been researched for many years, the industrial application of these concepts is a relatively recent event in the evolution of the human-computer interface. This paper outlines an investigation by a commercial research organization (BHP Research) into the applications of this technology. The major domain under investigation was that of petroleum exploration. The focus of the research was two-fold, namely, the use of virtual environments to enable multi-sensory interpretation of data and the ability of virtual environments to enhance collaboration amongst work teams. Appraisal was conducted by trialing the applications amongst a wide user base. While it is not possible to divulge in full the recommendations that resulted from this work, a number of observations are made about the use of this technology for petroleum exploration. Furthermore, various general implications for the use of this technology are discussed.","","0-7695-0518-X","10.1109/ACSC.2000.824400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=824400","","Virtual environment;Industrial training;Computational modeling;Marine technology;Medical simulation;Biomedical imaging;Prototypes;Testing;Petroleum industry;Psychology","","1","","15","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Oasis: Procedurally Generated Social Virtual Spaces from 3D Scanned Real Spaces","M. Sra; S. Garrido-Jurado; P. Maes","Media Lab, Massachusetts Institute of Technology, Cambridge, MA; Computing and Numerical Analysis Department, University of Córdoba, Córdoba, Spain; Media Lab, Massachusetts Institute of Technology, Cambridge, MA",IEEE Transactions on Visualization and Computer Graphics,"26 Oct 2018","2018","24","12","3174","3187","We present Oasis, a novel system for automatically generating immersive and interactive virtual reality environments for single and multiuser experiences. Oasis enables real-walking in the generated virtual environment by capturing indoor scenes in 3D and mapping walkable areas. It makes use of available depth information for recognizing objects in the real environment which are paired with virtual counterparts to leverage the physicality of the real world, for a more immersive virtual experience. Oasis allows co-located and remotely located users to interact seamlessly and walk naturally in a shared virtual environment. Experiencing virtual reality with currently available devices can be cumbersome due to presence of objects and furniture which need to be removed every time the user wishes to use VR. Our approach is new, in that it allows casual users to easily create virtual reality environments in any indoor space without rearranging furniture or requiring specialized equipment, skill or training. We demonstrate our approach to overlay a virtual environment over an existing physical space through fully working single and multiuser systems implemented on a Tango tablet device.","1941-0506","","10.1109/TVCG.2017.2762691","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8067498","Virtual reality;procedural generation;multiuser interaction","Three-dimensional displays;Haptic interfaces;Legged locomotion;Tracking;Object detection;Virtual environments","","35","","36","IEEE","13 Oct 2017","","","IEEE","IEEE Journals"
"Predictive force display for tele-handling/machining system","M. Mitsuishi; T. Hori; T. Nagao","Department of Engineering Synthesis, Faculty of Engineering, University of Tokyo, Bunkyo, Tokyo, Japan; Department of Engineering Synthesis, Faculty of Engineering, University of Tokyo, Bunkyo, Tokyo, Japan; Department of Engineering Synthesis, Faculty of Engineering, University of Tokyo, Bunkyo, Tokyo, Japan",Proceedings of 1993 2nd IEEE International Workshop on Robot and Human Communication,"6 Aug 2002","1993","","","160","164","With the development of virtual reality, tele-existence and remote collaboration technologies, it has become possible for a human being to operate a machine and handle objects in worlds that are in remote locations, vastly different in scale from the human world, or in which the governing physical laws are different from those in the normal human world. To develop such a system, it is necessary to create an environment in which an operator feels as if he/she were in the world where the remote machine actually exists by transmitting a readily perceivable impression of that world. In this paper, the authors use the machining center in the remote machine site for a telehandling/machining system and propose a method of predictive force display for telemachining. Specifically, a force smoothing method and the method of identification of the working environment for predictive force display are proposed.<>","","0-7803-1407-7","10.1109/ROMAN.1993.367729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=367729","","Displays;Machining;Humans;Robots;Manipulators;Force feedback;Manufacturing;Smoothing methods;Delay effects;Force control","","1","","17","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Jamming in MR: Towards Real-Time Music Collaboration in Mixed Reality","R. Schlagowski; K. Gupta; S. Mertes; M. Billinghurst; S. Metzner; E. André","HCAI-Lab, University of Augsburg; Empathic Computing Lab, University of Auckland; HCAI-Lab, University of Augsburg; Empathic Computing Lab, University of Auckland; LMZ, University of Augsburg; HCAI-Lab, University of Augsburg",2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"20 Apr 2022","2022","","","854","855","Recent pandemic-related contact restrictions have made it difficult for musicians to meet in person to make music. As a result, there has been an increased demand for applications that enable remote and real-time music collaboration. One desirable goal here is to give musicians a sense of social presence, to make them feel that they are “on site” with their musical partners. We conducted a focus group study to investigate the impact of remote jamming on users' affect. Further, we gathered user requirements for a Mixed Reality system that enables real-time jamming and developed a prototype based on these findings.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00278","Bundesministerium für Bildung und Forschung (BMBF, Ministry of Education and Research)(grant numbers:01UO1820A); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757686","Mixed Reality;Remote Collaboration;Music;Human-centered computing;Visualization;Visualization design and evaluation methods","Three-dimensional displays;Conferences;Music;Mixed reality;Collaboration;Prototypes;Virtual reality","","3","","4","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"A Shared Haptic Virtual Environment for Dental Surgical Skill Training","M. Kaluschke; M. S. Yin; P. Haddawy; N. Srimaneekarn; P. Saikaew; G. Zachmann","Computer Graphics and Virtual Reality, University of Bremen; Faculty of ICT, Mahidol University; Faculty of ICT, Mahidol University; Faculty of Dentistry, Mahidol University; Faculty of Dentistry, Mahidol University; Computer Graphics and Virtual Reality, University of Bremen",2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"6 May 2021","2021","","","347","352","Online learning has become an effective approach to reach students who may not be able to travel to university campuses for various reasons. Its use has also dramatically increased during the current COVID-19 pandemic with social distancing and lockdown requirements. But online education has thus far been primarily limited to teaching of knowledge and cognitive skills. There is yet almost no use of online education for teaching of physical clinical skills.In this paper, we present a shared haptic virtual environment for dental surgical skill training. The system provides the teacher and student with a shared environment containing a virtual dental station with patient, a dental drill controlled by a haptic device, and a drillable tooth. It also provides automated scoring of procedure outcomes. We discuss a number of optimizations used in order to provide the high-fidelity simulation and real-time performance needed for training of high-precision clinical skills. Since tactile, in particular kinaesthetic, sense is essential in carrying out many dental procedures, an important question is how to best teach this in a virtual environment. In order to support exploring this, our system includes three modes for transmitting haptic sensations from the user performing the procedure to the user observing.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00069","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419258","Applied computing;Education;Interactive learning environments Applied computing—Education;Collaborative learning Applied computing;Distance learning Human-centered computing;Collaborative and social computing;Human-centered computing;Visualization;Visualization techniques;Computing methodologies;Modeling and simulation","Training;Solid modeling;Three-dimensional displays;Conferences;Virtual environments;Surgery;Teeth","","9","","28","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"Design of a master-slave rehabilitation system using self-tuning fuzzy PI controller","S. Guo; S. Zhang; Z. Song; M. Pang","Department of Intelligent Mechanical Systems Engineering, Kagawa University, Takamatsu, Japan; Graduate School of Engineering, Kagawa University, Takamatsu, Japan; Department of Intelligent Mechanical Systems Engineering, Kagawa University, Takamatsu, Japan; Graduate School of Engineering, Kagawa University, Takamatsu, Japan",2012 IEEE International Conference on Mechatronics and Automation,"27 Aug 2012","2012","","","2088","2092","Many robotic devices have been developed for stroke patients to recover their upper limb motor function. Among them, master-slave type rehabilitation systems provide surveillance of the therapist to the patient who is performing home-rehabilitation. In this study, we proposed a wearable and light exoskeleton device for upper limb rehabilitation and designed a master-slave rehabilitation system using the exoskeleton device as slave device and a haptic device (Phantom Premium) as master device. To convey therapist's experience to patients using this system, the slave device is driven to track the motion of the master device manipulated by the therapist. In order to improve the tracking efficacy of traditional PI control, a self-tuning fuzzy PI control was proposed. Results of simulation indicated the proposed control method is more effective than the traditional PI control, particularly in tracking accuracy and response speed.","2152-744X","978-1-4673-1278-3","10.1109/ICMA.2012.6285665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6285665","Master-Slave system;Self-Tuning Fuzzy PI control;Matlab/Simulink","Pi control;Exoskeletons;Master-slave;Elbow;Tracking;Phantoms;Robots","","6","","17","IEEE","27 Aug 2012","","","IEEE","IEEE Conferences"
"Virtual Reality In Education: Promise And Reality","R. B. Loftin; F. P. Brooks; C. Dede","University of Houston, USA; University of North Carolina, Chapel Hill, USA; George Mason University, USA",Proceedings. IEEE 1998 Virtual Reality Annual International Symposium (Cat. No.98CB36180),"6 Aug 2002","1998","","","208","208","","","0-8186-8362-7","10.1109/VRAIS.1998.658491","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=658491","","Virtual reality;Educational technology;Virtual environment;Cognitive science;Costs;Haptic interfaces;Feedback;Humans;Pattern recognition;Data visualization","","2","9","","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"From 3d bimanual toward distant collaborative interaction techniques: an awareness issue","M. L. Chénéchal; B. Arnaldi; T. Duval; V. Gouranton; J. Royan","NA; Beijing Aerospace Automatic Institute of Control, Beijing, China; Beijing Aerospace Automatic Institute of Control, Beijing, China; Institute for Microelectronics, TU Vienna, Vienna, Austria; NA",2014 International Workshop on Collaborative Virtual Environments (3DCVE),"27 Jul 2015","2014","","","1","8","This paper aims to raise the question : ”How much 3D bimanual interaction techniques can be useful to the design of collaborative interaction techniques in the field of Collaborative Virtual Environment (CVE)?”. Indeed, CVE involve the use of complex interaction techniques based on specific collaborative metaphors. The design of these metaphors may be a difficult task because it has to deal with collaborative issues that came from sparse research areas (Human-Computer Interfaces, Human-Human Interactions, Networking, Physiology and Social Psychology). Metaphors for bimanual interactions have been developed for a while essentially because it is a widely spread area of interest for common tasks. Bimanual interactions involve the use of both hands of the user in a collaborative way in order to achieve a goal with better performances compared to uni-manual interactions thanks to a natural skill that is proprioception. This collaborative aspect could certainly be a helpful entry point in the design of efficient collaborative interaction techniques extended from improved bimanual metaphors. However, the proprioceptive sense cannot be considered in the same way, and additional features must be proposed to be able to collaborate efficiently. Thus, awareness is a key to let CVE be usable and the availability of collaborative feedbacks is essential to extend bimanual interactions toward collaborative ones. In this paper, we based our study on existing work on bimanual and collaborative interaction techniques trying to draw similarities between them. We emphasize common points between both fields that could be useful to better design both metaphors and awareness in CVE.","","978-1-4799-5217-5","10.1109/3DCVE.2014.7160929","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160929","","Collaboration;Three-dimensional displays;Context;Human computer interaction;Haptic interfaces;Physiology;Virtual environments","","1","","52","IEEE","27 Jul 2015","","","IEEE","IEEE Conferences"
"Performance evaluation of a novel telerehabilitation system for the elbow joint training","S. Zhang; S. Guo","Graduate School of Engineering, Kagawa University; Department of Intelligent Mechanical Systems Engineering, Kagawa University, Takamatsu, Kagawa, JP",2015 IEEE International Conference on Mechatronics and Automation (ICMA),"3 Sep 2015","2015","","","420","424","Except the network latency which limits the development of telerehabilitation systems for home-based rehabilitation, the loss of real contact feeling should also be addressed. In this paper, a novel telerehabilitation system is developed to recover the lost contact feeling. The system incorporates a human upper limb-like device (master device) for therapists' use and an exoskeleton device (slave device) for patients' use. The training process of passive training with the proposed system is introduced in this paper. On the patients' side, a force sensor was used to detect the interaction force between the forearm and exoskeleton device. The interaction force can be reflected to therapists with master device which was designed with the SEA-based structure. The closed-loop interaction control method was used, thus the force feedback can be controlled by adjusting the deflection of elastic elements. The performance that the master device can generate variable impedances is evaluated. Moreover, motion tracking performance during passive trainings was tested under local network environment. The passive training is suitable for patients with severe impairments and poor motor function.","2152-744X","978-1-4799-7098-8","10.1109/ICMA.2015.7237522","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237522","Telerehabilitation;Force feedback;Series Elastic Actuator;Exoskeleton device;Passive training","Exoskeletons;Training;Force;Robots;Impedance;Performance evaluation;Force sensors","","4","","25","IEEE","3 Sep 2015","","","IEEE","IEEE Conferences"
"Assembly Modelling Through Constraint-based Manipulations in A Virtual Reality Environment","Y. Zhong; B. Shirinzadeh; W. Ma; H. C. Liaw","Robotics & Mechatronics Research Laboratory, Monash University, VIC, Australia; Robotics & Mechatronics Research Laboratory, Monash University, VIC, Australia; Department of Manufacturing Engineering and Engineering Management, City University of Hong Kong, Hong Kong, China; Robotics & Mechatronics Research Laboratory, Monash University, VIC, Australia",TENCON 2005 - 2005 IEEE Region 10 Conference,"5 Feb 2007","2005","","","1","6","With today's virtual reality (VR) systems, it is difficult to create precise assembly models through 3D interactions due to hardware limitations. In this paper, an efficient approach is presented for intuitive and precise assembly modeling in a VR environment. Assembly modelling is performed by precise constraint-based 3D direct manipulations in an intuitive manner. Constraint-based manipulations are accompanied with automatic constraint recognition and precise constraint satisfaction, and are realized by allowable motions for precise 3D interactions in the VR environment. Some special constraint-based assembly operations are constructed for assembly modelling in the VR environment. A method for recognizing the pairs of mating features between assembly components is presented. This method integrates 3D direct manipulations with a feature mating knowledge base and makes the process of recognizing a pair of mating features intuitive. A concept of offset solid is also presented for determining assembly components. A prototype system has been developed for assembly modelling through precise constraint-based manipulations in an intuitive manner in the VR environment.","2159-3450","0-7803-9311-2","10.1109/TENCON.2005.301317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4085117","","Virtual reality;Assembly systems;Robotic assembly;Solids;Virtual environment;Hardware;Prototypes;Design automation;Mechatronics;Virtual manufacturing","","2","","18","IEEE","5 Feb 2007","","","IEEE","IEEE Conferences"
"Virtual Human-Machine Interaction Force Algorithm in Astronaut Virtual Training","L. Lingjie; W. Lan; C. Ying; Z. Lixun; X. Feng","College of Mechanical and Electrical Engineering, Harbin Engineering University, Harbin, HLJ, PRC; College of Mechanical and Electrical Engineering, Harbin Engineering University, Harbin, HLJ, PRC; College of Mechanical and Electrical Engineering, Harbin Engineering University, Harbin, HLJ, PRC; College of Mechanical and Electrical Engineering, Harbin Engineering University, Harbin, HLJ, PRC; College of Mechanical and Electrical Engineering, Harbin Engineering University, Harbin, HLJ, PRC","2022 12th International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)","17 Oct 2022","2022","","","1299","1304","In the astronauts' collaborative virtual training, it is necessary to map the astronauts' keyboard and mouse operations to the input force, that is, the virtual human-machine interaction force. This paper establishes a virtual force sensor, by analyzing the working principle of the real force sensor. Next, a robot simulation model and the physical engine are integrated into the virtual force sensor, its stability is analyzed and it is further optimized. The ultimate goal is to obtain virtual human-machine interaction force through a virtual force sensor. In collaborative training, the human-machine interaction forces of multiple astronauts can be coupled with each other, through the physical engine, as well as influence each other. The simulation results show that, the solution result of the virtual human-machine interaction force is similar to the real one, while it can be better applied to the astronaut collaborative virtual training.","2642-6633","978-1-6654-7267-8","10.1109/CYBER55403.2022.9907056","National Natural Science Foundation of China(grant numbers:61773007); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9907056","","Human computer interaction;Training;Analytical models;Simulation;Force;Collaboration;Robot sensing systems","","1","","10","IEEE","17 Oct 2022","","","IEEE","IEEE Conferences"
"Virtual impedance based remote tele-collaboration with time delay","Nak Young Chong; T. Kotoku; K. Ohba; K. Komoriya; N. Matsuhira; K. Taniel","Robotics Department, Mechanical Engineering Laboratory, Tsukuba, Japan; Robotics Department, Mechanical Engineering Laboratory, Tsukuba, Japan; Robotics Department, Mechanical Engineering Laboratory, Tsukuba, Japan; Robotics Department, Mechanical Engineering Laboratory, Tsukuba, Japan; R & D Center, Mechanical Systems Laboratory, Toshiba Corporation, Kawasaki, Japan; NA",8th IEEE International Workshop on Robot and Human Interaction. RO-MAN '99 (Cat. No.99TH8483),"6 Aug 2002","1999","","","267","272","A collision-free coordinated control scheme is discussed for multi-operator-multi-robot (MOMR) teleoperation through a network with communication time delay. Collaboration tasks have rapidly emerged in many possible applications such as the plant maintenance, construction, and surgery, because multi-robot collaboration would have a significant advantage over a single robot in such cases. However, the effect of time-delay would pose a more difficult problem to MOMR teleoperation systems and seriously affect their performance. In this work, the virtual impedance based coordinated control method is proposed to cope with collision arising from the communication delay in the MOMR teleoperation system. We impose a variable impedance on the master hand and change the impedance according to the distance between two slave arms in the local predictor simulator. When a possible collision is expected during the task, a high impedance is set to master hand and signals the operator to stop or to change her master command. This adjustable impedance of the master hand safely guides an operator through unexpected collisions in time-delayed MOMR teleoperation. To verify the validity of the proposed scheme, an experimental setup is built and a block arrangement task is performed by two slave arms based on simulation models.","","0-7803-5841-4","10.1109/ROMAN.1999.900351","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=900351","","Impedance;Delay effects;Communication system control;Arm;Collaboration;Surgery;Collaborative work;Robot kinematics;Control systems;Master-slave","","1","","15","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Autonomous agents in collaborative virtual environments","S. Noll; C. Paul; R. Peters; N. Schiffner","Fraunhofer-Institute of Computer Graphics, Darmstadt, Germany; Fraunhofer-Institute of Computer Graphics, Darmstadt, Germany; Fraunhofer-Institute of Computer Graphics, Darmstadt, Germany; Fraunhofer-Institute of Computer Graphics, Darmstadt, Germany",Proceedings. IEEE 8th International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WET ICE'99),"6 Aug 2002","1999","","","208","215","Our world is now entering an age where the current understanding of telecommunications and graphics computing will be constantly challenged. The universal advancement of graphics technology, new business models, and the continuing upgrade of global infrastructure are transforming the solitary, platform-centric 3D computing model. With the availability of global information highways intercontinental collaboration using 3D graphics will become part of our daily work routine. The research efforts have been concentrated on determining how the distributed workplace can be transformed into a shared virtual environment. Interaction among people and processes in this virtual world has to be provided and improved. To enhance the usability and functionality of our collaborative virtual environment we integrated software agents into it. These agents support the user as well as the designer and the interaction with objects in the virtual world. We describe the basic needs for combining agents and virtual worlds as well as techniques to enhance VR environments.","1080-1383","0-7695-0365-9","10.1109/ENABL.1999.805203","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=805203","","Autonomous agents;Virtual environment;Graphics;Telecommunication computing;Collaborative work;Road transportation;International collaboration;Employment;Usability;Collaborative software","","1","1","10","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Authoring multimedia objects in collaborative ambient intelligent virtual environment","A. El Saddik; M. A. Rahman; M. A. Hossain","Multimedia Communications Research Laboratory, School of Information Technology and Engineering (SITE), University of Ottawa, Canada, Canada; Multimedia Communications Research Laboratory, School of Information Technology and Engineering (SITE), University of Ottawa, Canada, Canada; Multimedia Communications Research Laboratory, School of Information Technology and Engineering (SITE), University of Ottawa, Canada, Canada",IEEE International Workshop on Haptic Audio Visual Environments and their Applications,"12 Dec 2005","2005","","","6 pp.","","Authoring multimedia objects may be challenging when done in a collaborative ambient intelligent (AmI) environment where both the authors and the objects are geographically distributed. In our earlier work, we created a tool called LORNAV that allows an author to visualize different multimedia objects in a 3D virtual environment and to aggregate those objects and represent them in a SMIL 2.0 format. We introduce a collaborative authoring environment that uses LORNAV's visualization and authoring services and enables multiple authors to create aggregated objects in real time based on ambient information. The overall authoring process is also enhanced with the addition of moderation and multipoint-to-multipoint audio/video conferencing services. The collaborative AmI environment is based on a JXTA peer-to-peer (P2P) network.","","0-7803-9376-7","10.1109/HAVE.2005.1545671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1545671","","Collaboration;Ambient intelligence;Virtual environment;Collaborative work;Multimedia communication;Visualization;Aggregates;Videoconference;Peer to peer computing;Information technology","","4","","15","IEEE","12 Dec 2005","","","IEEE","IEEE Conferences"
"The roles of haptic-ostensive referring expressions in cooperative, task-based human-robot dialogue","M. E. Foster; E. G. Bard; M. Guhe; R. L. Hill; J. Oberlander; A. Knoll","Informatik VI: Robotics and Embedded Systems, Technische Universität München, Germany; Human Communication Research Centre, University of Edinburgh, UK; Human Communication Research Centre, University of Edinburgh, UK; Human Communication Research Centre, University of Edinburgh, UK; Human Communication Research Centre, University of Edinburgh, UK; Informatik VI: Robotics and Embedded Systems, Technische Universität München, Germany",2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI),"26 Jul 2012","2008","","","295","302","Generating referring expressions is a task that has received a great deal of attention in the natural-language generation community, with an increasing amount of recent effort targeted at the generation of multimodal referring expressions. However, most implemented systems tend to assume very little shared knowledge between the speaker and the hearer, and therefore must generate fully-elaborated linguistic references. Some systems do include a representation of the physical context or the dialogue context; however, other sources of contextual information are not normally used. Also, the generated references normally consist only of language and, possibly, deictic pointing gestures. When referring to objects in the context of a task-based interaction involving jointly manipulating objects, a much richer notion of context is available, which permits a wider range of referring options. In particular, when conversational partners cooperate on a mutual task in a shared environment, objects can be made accessible simply by manipulating them as part of the task. We demonstrate that such expressions are common in a corpus of human-human dialogues based on constructing virtual objects, and then describe how this type of reference can be incorporated into the output of a humanoid robot that engages in similar joint construction dialogues with a human partner.","2167-2148","978-1-60558-017-3","10.1145/1349822.1349861","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249449","Multimodal dialogue;referring expressions","Pragmatics;Context;Robot kinematics;Humans;Joints;Color","","1","","20","","26 Jul 2012","","","IEEE","IEEE Conferences"
"Managing collaboration in the nanoManipulator","T. C. Hudson; A. T. Helser; D. H. Sonnenwald; M. C. Whitton","North Carolina State University, USA; 3rdTech, Inc., USA; North Carolina State University, Chapel Hill, USA; North Carolina State University, Chapel Hill, USA","IEEE Virtual Reality, 2003. Proceedings.","2 Apr 2003","2003","","","180","187","We designed, developed, deployed, and evaluated the Collaborative nanoManipulator (CnM), a system supporting remote collaboration between users of the nanoManipulator interface to atomic force microscopes. To be accepted by users, the shared nanoManipulator application had to have the same high level of interactivity as the single user system and the application had to support a user's ability to interleave working privately and working collaboratively. The paper describes the entire collaboration system, but focuses on the shared nanoManipulator application. Based on our experience developing the CnM, we present: a method of analyzing applications to characterize the requirements for sharing data between collaborating sites, examples of data structures that support collaboration, and guidelines for selecting appropriate synchronization and concurrency control schemes.","1087-8270","0-7695-1882-6","10.1109/VR.2003.1191137","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191137","","Collaboration;Collaborative work;Application software;Virtual environment;Concurrency control;Control systems;Collaborative software;Microscopy;Identity-based encryption;Guidelines","","5","1","23","IEEE","2 Apr 2003","","","IEEE","IEEE Conferences"
"A Survey on Remote Assistance and Training in Mixed Reality Environments","C. G. Fidalgo; Y. Yan; H. Cho; M. Sousa; D. Lindlbauer; J. Jorge","INESC-ID, Instituto Superior Técnico, University of Lisbon and Carnegie Mellon University, United States; Carnegie Mellon University, United States; Carnegie Mellon University, United States; University of Toronto, Canada; Carnegie Mellon University, United States; INESC-ID and Instituto Superior Técnico, University of Lisbon, Portugal",IEEE Transactions on Visualization and Computer Graphics,"29 Mar 2023","2023","29","5","2291","2303","The recent pandemic, war, and oil crises have caused many to reconsider their need to travel for education, training, and meetings. Providing assistance and training remotely has thus gained importance for many applications, from industrial maintenance to surgical telemonitoring. Current solutions such as video conferencing platforms lack essential communication cues such as spatial referencing, which negatively impacts both time completion and task performance. Mixed Reality (MR) offers opportunities to improve remote assistance and training, as it opens the way to increased spatial clarity and large interaction space. We contribute a survey of remote assistance and training in MR environments through a systematic literature review to provide a deeper understanding of current approaches, benefits and challenges. We analyze 62 articles and contextualize our findings along a taxonomy based on degree of collaboration, perspective sharing, MR space symmetry, time, input and output modality, visual display, and application domain. We identify the main gaps and opportunities in this research area, such as exploring collaboration scenarios beyond one-expert-to-one-trainee, enabling users to move across the reality-virtuality spectrum during a task, or exploring advanced interaction techniques that resort to hand or eye tracking. Our survey informs and helps researchers in different domains, including maintenance, medicine, engineering, or education, build and evaluate novel MR approaches to remote training and assistance. All supplemental materials are available at https://augmented-perception.org/publications/2023-training-survey.html.","1941-0506","","10.1109/TVCG.2023.3247081","Portuguese Foundation for Science and Technology(grant numbers:UIDB/50021/2020); Carnegie Mellon/Portugal Program fellowship(grant numbers:SFRH/BD/151465/2021); UNESCO Chair on AI&XR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049704","Mixed Reality;Virtual Reality;Augmented Reality;Extended Reality;Remote;Collaboration;Training;Assistance","Training;Virtual reality;Collaboration;Mixed reality;Task analysis;Maintenance engineering;Visualization","","37","","98","IEEE","22 Feb 2023","","","IEEE","IEEE Journals"
"Tele-Board Prototyper - Distributed 3D Modeling in a Web-Based Real-Time Collaboration System","M. Wenzel; A. Klinger; C. Meinel","Hasso Plattner Institute Potsdam, Potsdam, Germany; Hasso Plattner Institute Potsdam, Potsdam, Germany; Hasso Plattner Institute Potsdam, Potsdam, Germany",2016 International Conference on Collaboration Technologies and Systems (CTS),"6 Mar 2017","2016","","","446","453","Prototypes help people to externalize their ideas and are a basic element for gathering feedback on an early product design. Prototyping is oftentimes a team-based method traditionally involving physical and analog tools. At the same time, collaboration among geographically dispersed team members becomes more and more standard practice for companies and research teams. Therefore, a growing need arises for collaborative prototyping environments. We present a standards compliant, web browser-based real-time remote 3D modeling system. We utilize cross-platform WebGL rendering API for hardware accelerated visualization of 3D models. Synchronization relies on WebSocket-based message interchange over a centralized Node.js real-time collaboration server. In a first co-located user test, participants were able to rebuild physical prototypes without having prior knowledge of the system. This way, the provided system design and its implementation can serve as a basis for visual real-time collaboration systems available across a multitude of hardware devices.","","978-1-5090-2300-4","10.1109/CTS.2016.0084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7871022","remote collaboration;prototyping;3.0;real-time;JavaScript;WebGl","Three-dimensional displays;Solid modeling;Collaboration;Real-time systems;Browsers;Prototypes;Synchronization","","3","","29","IEEE","6 Mar 2017","","","IEEE","IEEE Conferences"
"A Comparison Study Understanding the Impact of Mixed Reality Collaboration on Sense of Co-Presence","J. Yin; W. Zheng; Y. Wang; X. Tong; Y. Yan","University of Rochester Tsinghua University; Duke Kunshan University; Tsinghua University; Hong Kong University of Science and Technology, Guangzhou; University of Rochester",2025 IEEE Conference Virtual Reality and 3D User Interfaces (VR),"28 Mar 2025","2025","","","580","590","Sense of co-presence refers to the perceived closeness and interaction between participants in a collaborative context, which critically impacts the collaboration experience and task performance. With the emergence of Mixed Reality (MR) technologies, we would like to investigate the effect of MR immersive collaboration environment on promoting co-presence in a remote setting by comparing it with non-MR methods, such as video conferencing. We conduct a comparison study, where we invited 14 dyads of participants to collaborate on block assembly tasks with video conferencing, MR system, and in a physically co-located scenario. Each participant of a dyad was assigned either a local worker to assemble the blocks or a remote helper to give the instructions. Results show that MR system can create comparable sense of co-presence with co-located situation, and allow users to interact more naturally with both the environment and each other. The adoption of mixed reality enhances collaboration and task performance by reducing reliance on verbal communication and favoring action-based interactions through gestures and direct manipulation of virtual objects.","2642-5254","979-8-3315-3645-9","10.1109/VR59515.2025.00081","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10937421","Index Terms: Remote Collaboration;Co-presence;Mixed Reality","Three-dimensional displays;Collaboration;Mixed reality;Virtual reality;User interfaces;Indexes;Assembly;Videoconferences","","","","81","IEEE","28 Mar 2025","","","IEEE","IEEE Conferences"
"A Review of Bilateral Teleoperation Control Strategies with Soft Environment","Y. Deng; Y. Tang; B. Yang; W. Zheng; S. Liu; C. Liu","School of Automation, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Automation, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Automation, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Automation, University of Electronic Science and Technology of China, Chengdu, P. R. China; School of Automation, University of Electronic Science and Technology of China, Chengdu, P. R. China; Department of Robotics, Lirmm, University of Montpellier-Cnrs, Montpellier, France",2021 6th IEEE International Conference on Advanced Robotics and Mechatronics (ICARM),"15 Sep 2021","2021","","","459","464","In the past two decades, bilateral teleoperation with haptic feedback has attracted great research and application interests in both robotics and other areas. Initially triggered by the need to handle dangerous and remote distance tasks such as nuclear materials manipulation and space exploration, bilateral teleoperation has found its way into other applications as a result of development of control theory, robotic technology (both hardware and software) and latest breakthrough in artificial intelligence and machine learning. Consequently, bilateral teleoperation is found facing new challenges brought by these new applications. One major and obvious change is the working environment for the slave manipulator: different from rigid or solid contact environments which are reasonably assumed in early applications in industrial, nuclear and aerospace applications, the slave environment is now more complex and often the objects in contact are much softer in term of stiffness and can not be described by simple elastic model if good teleoperation performance (accurate and transparent) is expected. In this paper, the research of bilateral teleoperation system considering soft environment in recent 20 years has been surveyed for the first time in literature, to the knowledge of the authors. Following the difference in real applications, in this review the definition of soft environment covers linear elastic environment with much lower stiffness than conventional industrial environment and nonlinear complex soft environment with/out time-varying characteristics. Accordingly, the surveyed control strategies and structures in recent literature to improve the stability and accuracy of bilateral teleoperation with soft environment are classified and explained. Finally, the main applications, current challenges and future perspectives of bilateral teleoperation with soft environment are discussed.","","978-1-6654-3909-1","10.1109/ICARM52023.2021.9536056","Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9536056","Bilateral teleoperation;soft environment;passivity;transparency","Solid modeling;Mechatronics;Machine learning;Solids;Stability analysis;Software;Hardware","","22","","53","IEEE","15 Sep 2021","","","IEEE","IEEE Conferences"
"Scene Synchronization for Real-Time Interaction in Distributed Mixed Reality and Virtual Reality Environments","F. G. Hamza-Lup; J. P. Rolland","School of Electrical Engineering and Computer Science, University of Central Florida, fhamza@cs.ucf.edu; School of Electrical Engineering and Computer Science & School of Optics-CREOL, University of Central Florida, jannick@odalab.ucf.edu",Presence,"19 May 2014","2004","13","3","315","327","Advances in computer networks and rendering systems facilitate the creation of distributed collaborative environments in which the distribution of information at remote locations allows efficient communication. One of the challenges in networked virtual environments is maintaining a consistent view of the shared state in the presence of inevitable network latency and jitter. A consistent view in a shared scene may significantly increase the sense of presence among participants and facilitate their interactivity. The dynamic shared state is directly affected by the frequency of actions applied on the objects in the scene. Mixed Reality (MR) and Virtual Reality (VR) environments contain several types of action producers including human users, a wide range of electronic motion sensors, and haptic devices. In this paper, we propose a novel criterion for categorization of distributed MR/VR systems and present an adaptive synchronization algorithm for distributed MR/VR collaborative environments. In spite of significant network latency, results show that for low levels of update frequencies the dynamic shared state can be kept consistent at multiple remotely located sites.","1054-7460","","10.1162/1054746041422343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6789042","","","","2","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Tactile-ViewGCN: Learning Shape Descriptor from Tactile Data using Graph Convolutional Network","S. Vs; M. Sharma","Department of Physics, IIT Madras, Chennai, India; Department of Computer Science and Engineering, Thapar Institute of Engineering and Technology, Punjab, India","2025 7th International Conference on Signal Processing, Computing and Control (ISPCC)","24 Jun 2025","2025","","","657","662","For humans, the sense of touch has always been crucial for precise and efficient manipulation of objects in diverse environments. However, until recently, relatively few studies have fully explored haptic feedback. In this work, we propose a novel approach that surpasses existing methods in creating shape descriptors for object classification using multiple tactile signals collected from a specialized glove. Our technique addresses the key challenge of aggregating features from multiple tactile images by considering tactile object recognition as a 3D shape recognition from multi-view problems. To do so, we introduce Tactile-ViewGCN, which hierarchically integrates tactile features and accounts for their interrelationships through a Graph Convolutional Network. When evaluated on the MIT STAG dataset, our model achieves an accuracy of 81.82%, illustrating its effectiveness in processing tactile data for object classification.","2643-8615","979-8-3315-3893-4","10.1109/ISPCC66872.2025.11039550","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11039550","Tactile object classification;Graph neural network","Three-dimensional displays;Image recognition;Accuracy;Measurement units;Shape;Graph convolutional networks;Inertial navigation;Signal processing;Data models;Object recognition","","","","18","IEEE","24 Jun 2025","","","IEEE","IEEE Conferences"
"Study of communication modalities for teaching distance information","F. Fastelli; C. Simon; A. Ricca; A. Chellali","IBISC Lab, Univ Evry, Université Paris Saclay; IBISC Lab, Univ Evry, Université Paris Saclay; Arts et Metiers Institute of Technology, LISPEN, UBFC; IBISC Lab, Univ Evry, Université Paris Saclay",2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"20 Apr 2022","2022","","","706","707","We present an exploratory study to compare the haptic, visual, and verbal modalities for communicating distance information in a shared virtual environment. The results show that the visual modality decreased the distance estimation error while the haptic modality decreased the completion time. The verbal modality increased the sense of copresence but was the least preferred modality. These results suggest that a combination of modalities could improve communication of distance information to a partner. These findings can contribute to improving the design of collaborative VR systems and open new research perspectives on studying the effectiveness of multimodal interaction.","","978-1-6654-8402-2","10.1109/VRW55335.2022.00204","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9757496","Human-centered computing—Interaction Techniques;Human-centered computing—Virtual Reality","Visualization;Estimation error;Three-dimensional displays;Conferences;Education;Collaboration;Virtual environments","","","","6","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Providing a Wide Field of View for Effective Interaction in Desktop Tangible Augmented Reality","S. Jeon; G. J. Kim","Department of Computer Science and Engineering, Haptics and Virtual Reality Laboratory, Republic of Korea; Department of Computer Science and Engineering, Korea University, Republic of Korea",2008 IEEE Virtual Reality Conference,"4 Apr 2008","2008","","","3","10","This paper proposes to generate and provide wide field of view (FOV) augmented reality (AR) imagery by mosaicing images from smaller fields of moving views in ""desktop"" tangible AR (DTAR) environments. AR systems usually offer a limited FOV into the interaction space, constrained by the FOV of the camera and/or the display, which causes serious usability problems especially when the interaction space is large and many tangible props/markers are used. This problem is more apparent in DTAR environments in which an upright frontal display is used, instead of a head mounted display. This can be solved partly by placing the camera at a relatively far location or by using multiple cameras and increasing the working FOV. However, as for the former solution, the large distance between the interaction space and the fixed camera decreases the tracking and recognition reliability of the tangible markers, and the latter solution introduces significant additional set-up, cost, and computational load. Thus, we propose to use a mosaiced image to provide wide FOV AR imagery. We experimentally compare our solution, i.e. to offer the entire view of the interaction space at once, to other nominal AR set-ups. The experimental results show that, despite some amounts of visual artifacts due to the imperfect mosaicing, the proposed solution can improve task performance and usability for a typical DTAR system. Our findings should contribute to making AR systems more practical and usable for the mass.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480743","Mosaicing;Augmented Reality;Desktop AR;Usability;Interaction Space;H.5.1 [INFORMATION INTERFACES AND PRESENTATION]: Multimedia Information Systems-Artificial;augmented;and virtual realities","Augmented reality;Cameras;Virtual reality;Usability;Head;Computer displays;Switches;Computer science;Haptic interfaces;Computational efficiency","","9","","27","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"Collaborative Strategies for the Search of 3-D Targets in Molecular Environments","J. Simard; M. Ammi; M. Auvray","French National Center for Scientific Research-Laboratory for Mechanics and Engineering Sciences, University of Paris-Sud, Orsay, France; French National Center for Scientific Research-Laboratory for Mechanics and Engineering Sciences, University of Paris-Sud, Orsay, France; French National Center for Scientific Research-Laboratory for Mechanics and Engineering Sciences, University of Paris-Sud, Orsay, France","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)","21 Dec 2012","2012","42","6","1555","1565","Collaborative virtual environments introduce new working methods allowing for the association of several experts in the same problem-solving process. These new platforms have the potential to improve the processing of complex environments with large amounts of data and require different skills. This paper proposes the study of a synchronous and colocated approach for molecular design tasks. More precisely, this study focuses on the collaborative search of targets during the molecular deformation process. The aim of this paper is to highlight the different working strategies that emerge according to different tasks and humans factors. Based on these working strategies, we propose to investigate the contribution of collaborative configurations of work according to different efficiency criteria such as the completion time, verbal communication, and manipulation distance. Finally, this study will highlight some issues related to conflict of actions, concurrent access, awareness, and communication processes.","1558-2442","","10.1109/TSMCC.2012.2206805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392445","Human computer interaction;systems, man, and cybernetics;user interfaces","Collaboration;Virtual environments;Solid modeling;Haptic interfaces;Complexity theory;Computational modeling","","2","","40","IEEE","21 Dec 2012","","","IEEE","IEEE Journals"
"A Systematic Review of Multilateral Teleoperation Systems","M. Shahbazi; S. F. Atashzar; R. V. Patel","Western University, London, ON, CA; Western University, London, ON, CA; Western University, London, ON, CA",IEEE Transactions on Haptics,"16 Sep 2018","2018","11","3","338","356","While conventional bilateral Single-Master/Single-Slave (SM/SS) teleoperation systems have received considerable attention during the past several decades, multilateral teleoperation is only recently being studied. Unlike an SM/SS system, which consists of one master-slave set, multilateral teleoperation frameworks involve a minimum of three agents in order to remotely perform a task. This paper presents an overview of multilateral teleoperation systems and classifies the existing state-of-the-art architectures based on topologies, applications, and closed-loop stability analysis. For each category, the review discusses control strategies used for various architectures as well as control challenges (e.g., closed-loop instability as a result of a delay in the communication network) for each methodology.","2329-4051","","10.1109/TOH.2018.2818134","Canadian Institutes of Health Research (CIHR); Natural Sciences and Engineering Research Council (NSERC) of Canada; Collaborative Health Research Projects (CHRP)(grant numbers:#316170); AGE-WELL Network of Centres of Excellence(grant numbers:AW CRP 2015-WP5.3); NSERC Discovery(grant numbers:#RGPIN1345); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8322220","Cooperative teleoperation;multilateral telerobotics;multi-master/multi-slave telerobotics;trilateral teleoperation","Task analysis;Delays;Robot kinematics;Topology;Collaboration;Computer architecture","","97","","107","IEEE","22 Mar 2018","","","IEEE","IEEE Journals"
"A Small-Gain Approach for Nonpassive Bilateral Telerobotic Rehabilitation: Stability Analysis and Controller Synthesis","S. F. Atashzar; I. G. Polushin; R. V. Patel","Canadian Surgical Technologies and Advanced Robotics, London, ON, Canada; Canadian Surgical Technologies and Advanced Robotics, London, ON, Canada; Canadian Surgical Technologies and Advanced Robotics, London, ON, Canada",IEEE Transactions on Robotics,"19 May 2017","2017","33","1","49","66","In this paper, the design of a novel bilateral telerobotic architecture for rehabilitation purposes is proposed and the related feasibility, stability, and control challenges are studied. The objective is to incorporate the supervision of a local/remote human physiotherapist into haptics-enabled rehabilitation systems and allow the therapist to provide nonpassive nonlinear assistive/resistive forces in response to the patient's movements. This can address a challenge of conventional software-based rehabilitation systems, i.e., limited capability in adjusting the therapy. To guarantee human-robot interaction safety, a new design framework and a stabilizing controller are developed based on the small-gain approach. System stability and transparency are analyzed in the presence of the nonpassive, nonlinear, and nonautonomous behavior of the terminals (the therapist and the patient) and time-varying delays for the case of remote and cloud-based therapy. Several practical considerations have been taken into account to match the clinical needs and minimize the implementation cost. Simulation studies, practical implementation, and experimental evaluations are presented.","1941-0468","","10.1109/TRO.2016.2623336","Collaborative Health Research Projects(grant numbers:316170); AGE-WELL Network of Centres of Excellencey(grant numbers:2015-WP5.3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7778241","Haptics;physical human–robot interaction;rehabilitation robotics;stability;telerobotics","Telerobotics;Medical treatment;Delays;Stability criteria;Safety","","50","","36","IEEE","8 Dec 2016","","","IEEE","IEEE Journals"
"The Metaverse: Survey, Trends, Novel Pipeline Ecosystem & Future Directions","H. Sami; A. Hammoud; M. Arafeh; M. Wazzeh; S. Arisdakessian; M. Chahoud; O. Wehbi; M. Ajaj; A. Mourad; H. Otrok; O. Abdel Wahab; R. Mizouni; J. Bentahar; C. Talhi; Z. Dziong; E. Damiani; M. Guizani","Department of CSM, Artificial Intelligence and Cyber Systems Research Center, Lebanese American University, Beirut, Lebanon; Department of CSM, Artificial Intelligence and Cyber Systems Research Center, Lebanese American University, Beirut, Lebanon; Department of CSM, Artificial Intelligence and Cyber Systems Research Center, Lebanese American University, Beirut, Lebanon; Department of CSM, Artificial Intelligence and Cyber Systems Research Center, Lebanese American University, Beirut, Lebanon; Department of CSM, Artificial Intelligence and Cyber Systems Research Center, Lebanese American University, Beirut, Lebanon; Department of CSM, Artificial Intelligence and Cyber Systems Research Center, Lebanese American University, Beirut, Lebanon; Department of CSM, Artificial Intelligence and Cyber Systems Research Center, Lebanese American University, Beirut, Lebanon; Department of CSM, Artificial Intelligence and Cyber Systems Research Center, Lebanese American University, Beirut, Lebanon; Department of CSM, Artificial Intelligence and Cyber Systems Research Center, Lebanese American University, Beirut, Lebanon; Department of CS, Center of Cyber-Physical Systems, Khalifa University, Abu Dhabi, UAE; Department of Computer and Software Engineering, Polytechnique Montréal, Montreal, QC, Canada; Department of CS, Center of Cyber-Physical Systems, Khalifa University, Abu Dhabi, UAE; Concordia Institute for Information Systems Engineering, Concordia University, Montreal, QC, Canada; Department of Software and IT Engineering, École de Technologie Supérieure, Montreal, QC, Canada; Department of Electrical Engineering, École de Technologie Supérieure, Montreal, QC, Canada; Department of CS, Center of Cyber-Physical Systems, Khalifa University, Abu Dhabi, UAE; Department of ML, Mohamed Bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE",IEEE Communications Surveys & Tutorials,"21 Nov 2024","2024","26","4","2914","2960","The Metaverse offers a second world beyond reality, where boundaries are non-existent, and possibilities are endless through engagement and immersive experiences using the virtual reality (VR) technology. Many disciplines can benefit from the advancement of the Metaverse when accurately developed, including the fields of technology, gaming, education, art & culture, socialization, commerce, and businesses. Nevertheless, developing the Metaverse environment to its full potential is an ambiguous task that needs proper guidance and directions. Existing surveys on the Metaverse focus only on a specific aspect and discipline of the Metaverse and lack a holistic view of the entire process. Moreover, most surveys refrain from providing detailed guidance about the development process of the metaverse, including its impact on technologies, businesses, existing challenges, and potential research directions due to their lack of a macro and micro perception of such a topic. To this end, a more holistic, multi-disciplinary, in-depth, and academic and industry-oriented review is required to provide a thorough study of the Metaverse development pipeline and fill the gap in existing Metaverse surveys. To address these issues, we present in this survey a novel multi-layered pipeline ecosystem composed of (1) the Metaverse computing, networking, communications and hardware infrastructure, (2) environment digitization, and (3) user interactions. For every layer, we discuss the components that detail the steps of its development. Also, for each of these components, we examine the impact of a set of enabling technologies and empowering domains (e.g., Artificial Intelligence, Security & Privacy, Blockchain, Business, Ethics, and Social) on its advancement. In addition, we explain the importance of these technologies to support decentralization, interoperability, user experiences, interactions, and monetization. Our presented study highlights the existing challenges for each component, followed by research directions and potential solutions. To the best of our knowledge, this survey is the most comprehensive and allows users, scholars, and entrepreneurs to get an in-depth understanding of the Metaverse ecosystem to find their opportunities and potentials for contribution.","1553-877X","","10.1109/COMST.2024.3392642","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10507201","Metaverse;augmented reality;virtual reality;mixed reality;AI;networking;communications;edge computing;security;privacy;blockchain;digital twins;avatars;rendering;3D modeling;user-to-user and user-to-business interactions","Metaverse;Surveys;Pipelines;Ecosystems;Business;Artificial intelligence;Blockchains","","26","","248","IEEE","23 Apr 2024","","","IEEE","IEEE Journals"
"Virtual Training via Vibrotactile Arrays","A. Bloomfield; N. I. Badler","Department of Computer Science, The University of Virginia, 151 Engineer's Way, Charlottesville, VA 22904; Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA 19104",Presence,"19 May 2014","2008","17","2","103","120","What is often missing from many virtual worlds and training simulations is a physical sense of the confinement and constraint of the virtual environment. We present a method for providing localized cutaneous vibratory feedback to the user's right arm. We created a sleeve of tactors linked to a real-time human model; the tactors activate to apply sensation to the corresponding body area. The hypothesis is that vibrotactile feedback to body areas provides the wearer sufficient guidance to assume correct body configurations and ascertain the existence and physical realism of access paths. We present the results of human subject experiments that study both explicit and implicit training of skills using vibrotactile arrays. Implicitly, collision awareness is achieved by activating the appropriate tactor when a body part collides with the scene; thus, the user will attempt to correct his or her body configuration. Explicitly, we use the tactors to guide the body into the proper configuration. The results of human subject experiments clearly show that the use of full arm vibrotactile feedback improves performance over purely visual feedback for navigating the virtual environment, as well as allowing easy acquisition of new skills. These results validate the empirical performance of this concept.","1054-7460","","10.1162/pres.17.2.103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6797328","","","","25","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Wearable Augmented Reality: Research Trends and Future Directions from Three Major Venues","T. T. Minh Tran; S. Brown; O. Weidlich; M. Billinghurst; C. Parker","University of Sydney, Australia; Contxtual, Australia; Contxtual, Australia; University of South Australia, Australia; University of Sydney, Australia",IEEE Transactions on Visualization and Computer Graphics,"2 Nov 2023","2023","29","11","4782","4793","Wearable Augmented Reality (AR) has attracted considerable attention in recent years, as evidenced by the growing number of research publications and industry investments. With swift advancements and a multitude of interdisciplinary research areas within wearable AR, a comprehensive review is crucial for integrating the current state of the field. In this paper, we present a review of 389 research papers on wearable AR, published between 2018 and 2022 in three major venues: ISMAR, TVCG, and CHI. Drawing inspiration from previous works by Zhou et al. and Kim et al., which summarized AR research at ISMAR over the past two decades (1998–2017), we categorize the papers into different topics and identify prevailing trends. One notable finding is that wearable AR research is increasingly geared towards enabling broader consumer adoption. From our analysis, we highlight key observations related to potential future research areas essential for capitalizing on this trend and achieving widespread adoption. These include addressing challenges in Display, Tracking, Interaction, and Applications, and exploring emerging frontiers in Ethics, Accessibility, Avatar and Embodiment, and Intelligent Virtual Agents.","1941-0506","","10.1109/TVCG.2023.3320231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10269051","Augmented reality;mixed reality;head-mounted displays;survey;trends","Market research;Headphones;Ethics;Augmented reality;Rendering (computer graphics);Calibration;Biomedical monitoring","","22","","126","IEEE","2 Oct 2023","","","IEEE","IEEE Journals"
"A rule-based interactive behavioral animation system for humanoids","H. Noser; D. Thalmann","Multimedia Laboratory, University of Zurich, Switzerland; Computer Graphics Laboratory, Swiss Federal Institute of Technology, Lausanne, Switzerland",IEEE Transactions on Visualization and Computer Graphics,"6 Aug 2002","1999","5","4","281","307","We present a versatile, behavioral, and rule-based animation system that includes autonomous humanoid actors whose behavior is based on synthetic sensors that are used for perceiving the virtual environment. We combine the following in a consistent approach: L-systems, a behavioral production rule system; a particle system; an acoustic environment model, including a speech recognition module; a virtual life network; and a humanoid library. Together, these systems create a real-time-structured virtual environment that both high-level autonomous humanoids and interactive users can easily share.","1941-0506","","10.1109/2945.817347","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=817347","","Animation;Virtual environment;Acoustic sensors;Production systems;Sensor systems;Humans;Computer vision;Autonomous agents;Computer graphics;Power system modeling","","21","","36","IEEE","6 Aug 2002","","","IEEE","IEEE Journals"
"Tangi: Tangible Proxies For Embodied Object Exploration And Manipulation In Virtual Reality","M. Feick; S. Bateman; A. Tang; A. Miede; N. Marquardt","University College London, London, UK; University of New Brunswick, Fredericton, Canada; University of Toronto, Toronto, Canada; htw saar, Saarbruecken, Germany; University College London, London, UK",2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"14 Dec 2020","2020","","","195","206","Exploring and manipulating complex virtual objects is challenging due to limitations of conventional controllers and free-hand interaction techniques. We present the TanGi toolkit which enables novices to rapidly build physical proxy objects using Composable Shape Primitives. TanGi also provides Manipulators allowing users to build objects including movable parts, making them suitable for rich object exploration and manipulation in VR. With a set of different use cases and applications we show the capabilities of the TanGi toolkit and evaluate its use. In a study with 16 participants, we demonstrate that novices can quickly build physical proxy objects using the Composable Shape Primitives and explore how different levels of object embodiment affect virtual object exploration. In a second study with 12 participants we evaluate TanGi's Manipulators and investigate the effectiveness of embodied interaction. Findings from this study show that TanGi's proxies outperform traditional controllers and were generally favored by participants.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284771","Virtual Reality;Tangible Interfaces;VR Object Exploration and Manipulation;Tangible Proxy Objects","Shape;Manipulators;Augmented reality","","19","","66","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"Dynamic interactions in physically realistic collaborative virtual environments","P. Jorissen; M. Wijnants; M. Lamotte","Expertise Centre for Digital Media, Hasselt University, Belgium; Expertise Centre for Digital Media, Hasselt University, Belgium; Expertise Centre for Digital Media, Hasselt University, Belgium",IEEE Transactions on Visualization and Computer Graphics,"26 Sep 2005","2005","11","6","649","660","This work describes our efforts in creating a general object interaction framework for dynamic collaborative virtual environments. Furthermore, we increase the realism of the interactive world by using a rigid body simulator to calculate all actor and object movements. The main idea behind our interactive platform is to construct a virtual world using only objects that contain their own interaction information. As a result, the object interactions are application independent and only a single scheme is required to handle all interactions in the virtual world. In order to have more dynamic interactions, we also created a new and efficient way for human users to dynamically interact within virtual worlds through their avatar. In particular, we show how inverse kinematics can be used to increase the interaction possibilities and realism in collaborative virtual environments. This results in a higher feeling of presence for connected users and allows for easy, on-the-fly creation of new interactions. For the distribution of both the interactive objects and the dynamic avatar interactions, we keep the network load as low as possible. To demonstrate the effectiveness of our techniques, we incorporate them into an existing CVE framework.","1941-0506","","10.1109/TVCG.2005.100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1512016","Index Terms- Artificial;augmented;and virtual realities;computer-supported cooperative work;synchronous interaction;animation;simulation.","Collaboration;Animation;Virtual environment;Collaborative work;Avatars;Computational modeling;Computer simulation;Application software;Humans;Kinematics","Computer Simulation;Computer Systems;Cybernetics;Data Display;Environment;Humans;Imaging, Three-Dimensional;Man-Machine Systems;Models, Biological;Online Systems;Touch;User-Computer Interface","15","10","39","IEEE","26 Sep 2005","","","IEEE","IEEE Journals"
"A new passivity-based control technique for safe patient-robot interaction in haptics-enabled rehabilitation systems","S. F. Atashzar; M. Shahbazi; M. Tavakoli; R. V. Patel","Western University, London, ON, CA; Western University, London, ON, CA; University of Alberta, Edmonton, AB, CA; Western University, London, ON, CA",2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"17 Dec 2015","2015","","","4556","4561","In this paper, a new passivity-based technique is proposed to analyze and guarantee the stability of haptics-enabled telerobotic rehabilitation systems where there is a possibility of having more sources of non-passivity than communication delays. In practice, the difficulty of therapeutic exercises should be tuned taking into account the stage of physical disability. However, tuning the difficulty and intensity should not violate the stability of patient-robot interaction. This usually puts conservative prefixed limits on the allowable exercise intensity. In this paper, patient-robot interaction safety is studied in the context of Strong Passivity Theory (SPT). Our goal is to ultimately relax the limitation on the allowable robotic therapies while preserving system stability. The proposed stabilizing scheme does not try to make the entire non-passive component passive. This allows the therapist to have freedom in injecting energy into the system for assistive therapies while ensuring safe patient-robot interaction. In this paper, the case of telerobotic rehabilitation is considered. Experimental implementation and evaluation are presented to support the proposed theory.","","978-1-4799-9994-1","10.1109/IROS.2015.7354025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7354025","","Medical treatment;Stability analysis;Telerobotics;Communication channels;Force;Safety","","13","","","IEEE","17 Dec 2015","","","IEEE","IEEE Conferences"
"Analog Twin Framework for Human and AI Supervisory Control and Teleoperation of Robots","N. Tahir; R. Parasuraman","Heterogeneous Robotics Research Lab, School of Computing, University of Georgia, Athens, GA, USA; Heterogeneous Robotics Research Lab, School of Computing, University of Georgia, Athens, GA, USA","IEEE Transactions on Systems, Man, and Cybernetics: Systems","14 Apr 2023","2023","53","5","2616","2628","Resource-constrained mobile robots that lack the capability to be completely autonomous can rely on a human or artificial intelligence (AI) supervisor acting at a remote site (e.g., control station or cloud) for their control. Such a supervised autonomy or cloud-based control of a robot poses high networking and computing capabilities requirements at both sites, which are not easy to achieve. This article introduces and analyzes a new analog twin (AT) framework by synchronizing mobility between two mobile robots, where one robot acts as an AT to the other robot. We devise a novel priority-based supervised bilateral teleoperation strategy for goal navigation tasks to validate the proposed framework. The practical implementation of a supervised control strategy on this framework entails a mobile robot system divided into a Master–Client scheme over a communication channel where the Client robot resides on the site of operation guided by the Master robot through an agent (human or AI) from a remote location. The Master robot controls the Client robot with its autonomous navigation algorithm, which reacts to the predictive force received from the Client robot. We analyze the proposed strategy in terms of network performance (throughput and delay), task performance (tracking error and goal reach accuracy), and computing efficiency (memory and CPU utilization). Extensive simulations and real-world experiments demonstrate the method’s novelty, flexibility, and versatility in realizing reactive planning applications with remote computational offloading capabilities compared to conventional offloading schemes.","2168-2232","","10.1109/TSMC.2022.3216206","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9938430","Analog twin (AT);cloud robotics;mobile robots;networked systems;supervised control;teleoperation","Robots;Mobile robots;Task analysis;Navigation;Cloud computing;Robot kinematics;Service robots","","12","","46","IEEE","3 Nov 2022","","","IEEE","IEEE Journals"
"Experiences with Multi-modal Collaborative Virtual Laboratory (MMCVL)","K. Desai; U. H. H. Belmonte; R. Jin; B. Prabhakaran; P. Diehl; V. A. Ramirez; V. Johnson; M. Gans","The University of Texas at Dallas, Richardson, TX, USA; The University of Texas at Dallas, Richardson, TX, USA; The University of Texas at Dallas, Richardson, TX, USA; The University of Texas at Dallas, Richardson, TX, USA; Universidad de Guanajuato, Guanajuato, Gto, Mexico; Universidad de Guanajuato, Guanajuato, Gto, Mexico; Eastfield College, Mesquite, TX, USA; Eastfield College, Mesquite, TX, USA",2017 IEEE Third International Conference on Multimedia Big Data (BigMM),"3 Jul 2017","2017","","","376","383","Training through Multi-modal Collaborative Virtual Laboratory (MMCVL) aims at developing or improving skills of students without the need of them being physically present. MMCVL addresses the problems faced by the current education system such as lack of resources and safe use of expensive laboratory equipment. It also provides a means for easy collaboration between students and teachers from different universities and schools. Multimedia data in terms of 3D mesh, skeleton, audio and virtual object physics interaction are incorporated in MMCVL to provide a 3D Tele-Immersion environment. The system uses low-cost RGB-D cameras such as Microsoft Kinect V2 to capture and generate 3D model of the person by extracting him/her from the entire captured data and immersing it in different interactive virtual environments. Different lab environments can be virtually created to provide for and replace the real laboratories. Object interactions allow for users to interact with the virtual objects present in the scene similar to real lab setup. Recording module of the toolkit allows future reference for training and testing of the student. The system also facilitates virtual feedback by giving the correct measurements, video demonstrations as well as audio communication with the collaborating teacher. Two different Chemistry experiments were performed to evaluate the user experience and usability aspects of MMCVL. Results obtained from the user study analysis prove the system to be fun and realistic, and at the same time engaging and motivating for learning laboratory experiments.","","978-1-5090-6549-3","10.1109/BigMM.2017.62","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7966775","Virtual training;Mixed/Augmented reality;Interactive learning environments;3D Tele-Immersion","Three-dimensional displays;Collaboration;Cameras;Skeleton;Chemistry;Training","","12","","24","IEEE","3 Jul 2017","","","IEEE","IEEE Conferences"
"A Survey on Edge Enabled Metaverse: Applications, Technological Innovations, and Prospective Trajectories Within the Industry","A. Patra; A. Pandey; V. Hassija; V. Chamola; R. P. Mishra","School of Computer Engineering, KIIT, Bhubaneshwar, India; School of Computer Engineering, KIIT, Bhubaneshwar, India; School of Computer Engineering, KIIT, Bhubaneshwar, India; Department of Electrical and Electronics Engineering, BITS Pilani, Pilani Campus, Pilani, India; Department of Mechanical Engineering, BITS Pilani, Pilani Campus, Pilani, India",IEEE Access,"17 Sep 2024","2024","12","","125125","125144","As the Metaverse promises to revolutionize human interaction and digital life, the role of edge computing emerges as a critical enabler. This paper presents a comprehensive survey of edge-enabled Metaverse applications, technological innovations, challenges, solutions, and future trajectories within the industry. We dissect the landscape of Metaverse applications across various sectors, analyzing how edge computing empowers real-time, immersive experiences. We delve into the cutting-edge advancements in decentralized computing infrastructure, edge networking, and artificial intelligence shaping the Metaverse, highlighting their potential to overcome latency, bandwidth, and privacy challenges. Additionally, we explore enabling technologies such as 5G and IoT, which facilitate seamless connectivity and data processing. We also address significant challenges, including the need for scalable and resilient infrastructure, data security concerns, and the integration of diverse technologies, proposing viable solutions like enhanced edge AI algorithms and robust cybersecurity frameworks. Finally, we chart prospective trajectories for edge-enabled Metaverse development, identifying key trends and potential disruptive forces that will shape the industry’s future. Our survey aims to serve as a definitive resource for researchers, developers, and industry leaders by providing a holistic understanding of edge computing’s pivotal role in realizing the boundless potential of the Metaverse.","2169-3536","","10.1109/ACCESS.2024.3452184","BITS-Pilani, Pilani Campus; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10659848","Metaverse;edge computing;edge-enabled metaverse;industrial metaverse;blockchain integration;Internet of Things;artificial intelligence;machine learning;augmented reality;virtual reality;mixed reality;decentralized;digitalization;latency","Metaverse;Blockchains;Surveys;Computer architecture;Mixed reality;Internet of Things;Edge AI;Edge computing;Artificial intelligence;Augmented reality;Virtual reality;Digital systems","","10","","127","CCBYNCND","30 Aug 2024","","","IEEE","IEEE Journals"
"Kicking in Virtual Reality: The Influence of Foot Visibility on the Shooting Experience and Accuracy","M. Bonfert; S. Lemke; R. Porzel; R. Malaka","Digital Media Lab, University of Bremen, Germany; Digital Media Lab, University of Bremen, Germany; Digital Media Lab, University of Bremen, Germany; Digital Media Lab, University of Bremen, Germany",2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),"20 Apr 2022","2022","","","711","718","When playing sports in virtual reality foot interaction is crucial for many disciplines. We investigated how the visibility of the foot influences penalty shooting in soccer. In a between-group experiment, we asked 28 players to hit eight targets with a virtual ball. We measured the performance, task load, presence, ball control, and body ownership of inexperienced to advanced soccer players. In one condition, the players saw a visual representation of their tracked foot which improved the accuracy of the shots significantly. Players with invisible foot needed 58% more attempts. Further, with foot visibility the self-reported body ownership was higher.","2642-5254","978-1-6654-9617-9","10.1109/VR51125.2022.00092","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9756749","Human-centered computing—Virtual reality;Human-centered computing—Empirical studies in HCI","Human computer interaction;Visualization;Three-dimensional displays;Target tracking;Sensitivity;Conferences;Virtual reality","","9","","41","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Competitive Multi-robot Teleoperation","Jingtai Liu; Lei Sun; Tao Chen; Xingbo Huang; Chunying Zhao","Institute of Robotics and Automatic Information System-IRAIS, Nankai University, Tianjin, China; Institute of Robotics and Automatic Information System-IRAIS, Nankai University, Tianjin, China; Institute of Robotics and Automatic Information System-IRAIS, Nankai University, Tianjin, China; Institute of Robotics and Automatic Information System-IRAIS, Nankai University, Tianjin, China; Institute of Robotics and Automatic Information System-IRAIS, Nankai University, Tianjin, China",Proceedings of the 2005 IEEE International Conference on Robotics and Automation,"10 Jan 2006","2005","","","75","80","This paper proposes a novel kind of multi-operator multi-robot(MOMR) teleoperation systems - the competitive teleoperation system. Compared with the conventional collaborated MOMR teleoperation system, features and properties of the competitive teleoperation system are presented. Futhermore, major concerns of research and development for this kind of systems are discussed subsequently. Finally, telegame, a kind of Internet-based competitive teleoperation systems, is built as the prototype to support the future research on this aspect and some experimental results are presented to support the discussion.","1050-4729","0-7803-8914-X","10.1109/ROBOT.2005.1570099","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1570099","Telerobotics;multiple-operator-multiple-robot (MOMR) teleoperation;competitive teleoperation;telegame","Collaborative work;Robot kinematics;Mobile robots;Internet;Control systems;Research and development;Application software;Force measurement;Online Communities/Technical Collaboration;Sun","","5","","19","IEEE","10 Jan 2006","","","IEEE","IEEE Conferences"
"Future Industrial Networks: Requirements, Challenges, Research and Standardization Needs","M. Carugi; Z. Lou","Huawei Technologies European Research Center, France; Huawei Technologies European Research Center, Germany",2021 ITU Kaleidoscope: Connecting Physical and Virtual Worlds (ITU K),"6 Jan 2022","2021","","","1","9","Digital transformation is affecting most industries. A large spectrum of applications is expected to be deployed in future industrial networks, with emerging industrial applications that include smart grid, flexible manufacturing, remote mining and others. The support of these applications by the underlying network infrastructures raises critical network challenges: demands for large-scale deterministic networking, increased network security, reliability and privacy support, as well as flexible addressing and routing capabilities, requiring fundamental advances in terms of networking technologies, with consequent needs of further network research and standardization efforts. This paper aims to provide an overview of critical network challenges to be addressed in order to satisfy requirements of future industrial network applications. Networking technology areas whose advances are fundamental in order to address the identified challenges are introduced. Requirements for network research and standardization are highlighted.","","978-92-61-33881-7","10.23919/ITUK53220.2021.9662091","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9662091","Flexible addressing;industrial applications;industrial networks;intrinsic security;privacy;semantic routing;time determinism","Privacy;Scalability;Stability criteria;Standardization;Power system stability;Routing;ITU","","2","","30","","6 Jan 2022","","","IEEE","IEEE Conferences"
"On extending collaboration in virtual reality environments","V. Theoktisto; M. Fairen","Departament de Llenguatges i Sistemes Informàtics, Universitat Politecnica de Catalunya, Barcelona, Spain; Departament de Llenguatges i Sistemes Informàtics, Universitat Politecnica de Catalunya, Barcelona, Spain",Proceedings. 17th Brazilian Symposium on Computer Graphics and Image Processing,"8 Nov 2004","2004","","","324","331","We characterize the feature superset of collaborative virtual reality environments (CVRE) out of existing implementations, and derive a novel component framework for transforming standalone VR tools into fully fledged multi-threaded collaborative environments. The contributions of our approach rely on cost-effective techniques for loading graphics rendering, user interaction and network communications software components into separate threads, with a top thread for session collaboration. The framework recasts VR tools under a scalable peer-to-peer topology for scene sharing, callback hooks for event broadcasting and multicamera perspectives of avatar interaction. We validate the framework by applying it to our own ALICE VR Navigator. Experimental results show the good performance of our approach in the collaborative inspection of complex models.","1530-1834","0-7695-2227-0","10.1109/SIBGRA.2004.1352977","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1352977","","Collaboration;Virtual reality;Collaborative tools;Collaborative software;Yarn;Graphics;Rendering (computer graphics);Peer to peer computing;Network topology;Layout","","1","","24","IEEE","8 Nov 2004","","","IEEE","IEEE Conferences"
"Immersive virtual reality for pain distraction methodologies and barriers","S. Sridevi","Anna University, Chennai, India",2012 Fourth International Conference on Advanced Computing (ICoAC),"24 Jan 2013","2012","","","1","7","A novel method for managing and treating physical and psychological pain is the need of the hour. Although cybertherapy is at its development stage, a great potential can be reaped when it is moulded in the right way. Clinical virtual reality is found to be a promising way of distracting the patients from sensing the pain during medical procedures, physical rehabilitation or post-traumatic stress. There exists no single pain management methodology that is good for everyone, or even the majority of people. Research findings prove that pain has many causes and courses, and can impact individuals in a multitude of ways including the behavioral, physiological, emotional, psychological, social and spiritual levels. Though distraction through audio visual aids has a significant effect in decreasing the intensity of pain signals in the brain, the analgesic efficacy has to be well researched and improved. The perception of pain varies with factors such as age, ethnicity, sex and genetics. Increased nervousness of patients in virtual world, patients' confidentiality, subjectivity in effectiveness on individuals, array of pains to be handled with a single virtual platform and cost are the major barriers to be tackled. This paper discusses ways of providing such generic, acceptable and proven methods of cybertherapy. Such virtually painless world shall be greatly achieved only with close cooperation between technologists and medical experts.","2377-6927","978-1-4673-5584-1","10.1109/ICoAC.2012.6416835","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6416835","virtual reality;cybertherapy;pain management;distraction technique","Pain;Medical treatment;Virtual reality;Neurons;Wounds;Visualization;Logic gates","","1","","11","IEEE","24 Jan 2013","","","IEEE","IEEE Conferences"
"Techniques for using VRChat to Replace On-site Experiments","T. Teo; K. Sakurada; M. Fukuoka; M. Sugimoto",Keio University; Keio University; Keio University; Keio University,2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"15 Dec 2022","2022","","","249","253","In this paper, we present a technique to conduct on-site laboratory experiments using VRChat, a social Virtual Reality platform. COVID-19 pandemic has created challenges and restrictions on re-searchers in running experiments for Human-Computer Interaction research. Hence, universities and institutions set guidelines for social distancing and encourage people to work from home. Therefore, participants are harder to recruit for experiments that run in a physical laboratory. Our technique uses VRChat as a substitution for running on-site experiments despite social restrictions. We exploit features in VRChat to enable researchers to run experiments with domestically recruited participants. Furthermore, we propose a hassle-free method to retrieve study data. This paper also discusses and offers design considerations to run an on-site experiment using VRChat over a homemade system.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974342","Human-centered computing;Laboratory experiments","Human computer interaction;COVID-19;Pandemics;Human factors;Social factors;Augmented reality;Guidelines","","1","","15","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Modeling Prehension for Physical Collaboration in Virtual Environments","P. J. Grabowski; D. N. Rutherford; A. H. Mason","Department of Kinesiology, University of Wisconsin-Madison, Madison, Wisconsin 53706; Department of Kinesiology, University of Wisconsin-Madison, Madison, Wisconsin 53706; Department of Kinesiology, University of Wisconsin-Madison, Madison, Wisconsin 53706",Presence,"19 May 2014","2011","20","6","577","590","The modeling of human movement is vital for a complete understanding of complex human–computer interaction. As three-dimensional collaborative tangible user interfaces (TUIs) evolve, research is needed to understand how people physically interact with each other within a virtual environment. Previous study of physical collaboration in virtual environments has utilized Fitts' law to model gross upper-extremity movement in a passing task. However, no study has modeled passing tasks that require precision grasp with the human hand, an important feature of human–computer interaction in TUIs. The purpose of this study was to evaluate the validity of Fitts' law in modeling movement time for a precision passing task in a 3D TUI, and to assess the coordination between passer and receiver using kinematic parameters. In this experiment, 12 participants (six male, mean age 22.6 years) performed a prehensile passing task within a desktop virtual environment. Results detail the kinematic events required to achieve the necessary temporal and spatial coordination specific to the passing task. Further, results indicate that Fitts' model does not adequately explain movement time for this task (R 2 = .51). This finding challenges the external validity of previous results. We argue that the task-specific complexity of human neuromotor control should be considered when using predictive models in 3D TUI design.","1054-7460","","10.1162/PRES_a_00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6797748","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Coordination of Intelligent Mobile Robots for Human-Agent-Robot Teamwork in 6G","A. Ebrahimzadeh; M. Maier; R. H. Glitho","CIISE, Concordia University, Montréal, Canada; Optical Zeitgeist Laboratory, INRS, Montréal, Canada; CIISE, Concordia University, Montréal, Canada",2024 IEEE Future Networks World Forum (FNWF),"12 Jun 2025","2024","","","553","559","Now that 5G mobile networks are rolled out, early studies have started to speculate about 6G and its key driving applications. These studies demonstrate that 6G will sit at the crossroads of communications, computation, intelligentization, and robotization. In 6G, it is expected that the nature of mobile devices will change significantly and intelligent mobile robots will play a more profound role. In this paper, after identifying the key driving technologies of 6G, we shed some light on the role of the Tactile Internet in the 6G era and give insights into how and to what extent we may reduce task completion time in a human-agent-robot teamwork scenario while paying particular attention to the decomposability of physical tasks.","2770-7679","979-8-3503-7949-5","10.1109/FNWF63303.2024.11028825","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11028825","6G;FiWi enhanced HetNets;Intelligent mobile robots;Tactile Internet;Task decomposition","6G mobile communication;Tactile Internet;Robot kinematics;Benchmark testing;Mobile handsets;Teamwork;Mobile robots;Resource management;Object recognition;Intelligent robots","","","","20","IEEE","12 Jun 2025","","","IEEE","IEEE Conferences"
"I Feel You: Impact of Shared Body Sensations on Social Interactions in Virtual Reality","Y. Tao; J. Egelman; J. N. Bailenson",Stanford University; University of Colorado Boulder; Stanford University,2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"28 Nov 2024","2024","","","1097","1106","While one’s facial expression and voice can be easily broadcasted from one to many via digital media, the sense of touch is limited to direct interactions. What happens if such body sensations can be shared across individuals, in which one feels a touch while watching someone else being touched? In this work, we investigated the impact of such shared body sensations on social interactions in virtual reality (VR). Building upon previous research that used psychophysics methods, our work explores the practical implications of shared body sensations in Social VR, which enables interactions beyond what’s physically possible. We conducted a withingroup user study ($\mathrm{n}=32$) in which participants observed conversations between two virtual agents and shared touch with one of the agents, as shown in Figure 1. Our results showed that even experiencing shared touch sensations several times during a conversation can affect social perception and behavior. Participants reported a stronger body illusion and empathy towards the virtual agent they shared touch with and stood closer to them. These results occurred both with and without a virtual mirror that made participants’ selfavatars more salient. The findings from this study introduce a new technique to enhance social connectedness in VR, and we discuss its applications in various contexts, such as asynchronous communication and collaboration.","2473-0726","979-8-3315-1647-5","10.1109/ISMAR62088.2024.00126","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765457","Index Terms: Social Touch;Haptics;Virtual Reality","Asynchronous communication;Buildings;Collaboration;Oral communication;Media;Mirrors;Indexes;Augmented reality","","","","84","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"An IEC-based Virtual Environment Authoring System for High School Education","H. Nishino; S. Yamabiraki; T. Sueyoshi; T. Mukai; T. Kagawa; K. Yoshida; K. Utsumiya","Department of Computer Science and Intellegent Systms, Oita University, Oita, Japan; Department of Computer Science and Intellegent Systms, Oita University, Oita, Japan; Department of Computer Science and Intellegent Systms, Oita University, Oita, Japan; Tsurusaki Technical High School, Oita, Japan; Department of Computer Science and Intellegent Systms, Oita University, Oita, Japan; Information Processing Center, Oita University, Oita, Japan; Department of Computer Science and Intellegent Systms, Oita University, Oita, Japan","2006 IEEE International Conference on Systems, Man and Cybernetics","16 Jul 2007","2006","1","","203","208","We show software tools to intuitively create a virtual environment (VE) system based on a soft computing technique. The proposed tools use Interactive Evolutionary Computation (IEC) to easily perform 3D authoring tasks such as creating aesthetically pleasing 3D computer graphics (3DCG) models, adding realistic touch sensations to the models, and configuring an effective VE system. Because the tools require no special knowledge and programming skills of users except for sensitivity, we apply the tools to high school IT education. The high school students can make virtual contents by rating the candidate 3DCG models generated and displayed by the system. Then the system evolves the models based on the rates. In this paper, we describe two IEC-based tools for designing the 3DCG model and adding the touch sensation. An ongoing experiment letting the high school students to make a collaborative VE by using the proposed tools is also mentioned.","1062-922X","1-4244-0099-6","10.1109/ICSMC.2006.384383","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4273830","","Virtual environment;Authoring systems;Educational institutions;Computer science education;Software tools;Evolutionary computation;IEC;Computer graphics;Programming profession;Educational programs","","","","14","IEEE","16 Jul 2007","","","IEEE","IEEE Conferences"
"Collaborative Networked Virtual Surgical Simulators (CNVSS): Factors Affecting Collaborative Performance","C. Diaz; H. Trefftz; L. Quintero; D. A. Acosta; S. Srivastava",Grupo de Investigación I+D+I en TIC Virtual Reality Lab Universidad EAFIT; Grupo de Investigación I+D+I en TIC Virtual Reality Lab Universidad EAFIT; Grupo de Investigación Modelado Matemático Universidad EAFIT; Grupo de Investigación DDP Universidad EAFIT; Department of Surgery Stanford University,Presence,"19 May 2014","2013","22","1","54","66","Stand-alone and networked surgical simulators based on virtual reality have been proposed as a means to train surgeons in specific surgical skills with or without expert guidance and supervision. However, a surgical operation usually involves a group of medical practitioners who cooperate as team members. To this end, CNVSS have been proposed for the collaborative training of surgical procedures in which users with different surgical roles can take part in the training session. To be successful, these simulators should guarantee synchronicity, which requires (1) consistent viewing of the surgical scene and (2) a quick response time. These two variables are affected by factors such as users' machine capabilities and network conditions. As far as we know, the impact of these factors on the performance of CNVSS has not been evaluated. In this paper, we describe the development of CNVSS and a statistical factorial design of experiments (DOE) to determine the most important factors affecting collaboration in CNVSS. From the results obtained, it was concluded that delay, jitter, packet loss percentage, and processor speed have a major impact on collaboration in CNVSS.","1054-7460","","10.1162/PRES_a_00133","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6797712","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Exploring the Effect of Virtual Reality with Haptics on Educational Research: A Meta-analysis From 2010 to 2020","X. Zhai; Y. Sun; M. Wang; F. Asmi; W. Cai; X. Chu","College of Education, Zhejiang University, Hangzhou, China; School of electronic and Information Engineering, Anhui Jianzhu University, Hefei, China; Learning Design and Technology, San Diego State University, San Diego, USA; Department of Science and Technology Communication, University of Science and Technology of China, Hefei, China; School of public affairs, University of Science and Technology of China, Hefei, China; College of Education, Zhejiang University, Hangzhou, China",2022 8th International Conference of the Immersive Learning Research Network (iLRN),"11 Jul 2022","2022","","","1","7","Virtual reality (VR) not only expands the learning field and enriches the learning experience, but also provides an effective presentation for scarce educational resources. However, because VR mainly depends on image processing technology, its application in the field of education mostly stays at the level of knowledge observation, and many challenges are gradually exposed, such as untimely interaction and weak sense of existence. In recent years, haptics has gradually become the development frontier of human-computer interaction, breaking through the limitation of single visual stimulation of VR to a great extent. Some researchers began to explore the teaching mode of VR with haptics, in order to mobilize learners’ multi-sensory stimulus responses such as hearing, touch, force and movement, and enhance learners’ on-the-spot experience and flow experience. In order to deeply explore the effectiveness of VR with haptics in teaching and explore the regulatory variables affecting this teaching method, 1646 academic papers published from 2010 to 2020 were screened based on WOS and Scopus databases. After meta-analysis of 50 selected research data, it is found that: (1) from the perspective of overall effect, VR with haptics can significantly improve learners’ learning performance and efficiency; (2) Through the analysis of the effects of three regulatory variables, it is found that VR with touch has a positive impact on learning performance; VR with haptics has a positive impact on learning efficiency, especially for learners who have no previous learning experience and take practical skills as their learning goal for a long time. This discovery provides an important data reference for building an effective “virtual reality with haptics” teaching scene.","","978-1-7348995-3-5","10.23919/iLRN55037.2022.9815893","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9815893","VR;Haptics;learning performance;learning efficiency","Human computer interaction;Visualization;Databases;Image processing;Education;Force;Buildings","","","","31","","11 Jul 2022","","","IEEE","IEEE Conferences"
"User Experience Optimization in Immersive Technologies: Techniques, Challenges, and Opportunities","K. G; A. P","Department of Computer Applications, Periyar Maniammai Institute of Science and Technology, Periyar Maniammai Institute of Science and Technology, Thanjavur, India; Department of Computer Applications, Periyar Maniammai Institute of Science and Technology, Periyar Maniammai Institute of Science and Technology, Thanjavur, India",2025 International Conference on Intelligent Computing and Control Systems (ICICCS),"12 May 2025","2025","","","908","917","Immersive technologies, including Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR), have transformed the way users interact with digital content across various sectors such as entertainment, education, healthcare, and business. However, optimizing user experience (UX) within these environments remains a significant challenge due to the complex interplay of immersion, usability, and sensory engagement. This review explores key techniques, challenges, and future opportunities for improving UX in immersive technologies. The paper examines essential components of UX, including immersion, presence, interaction models, and sensory feedback, highlighting their role in delivering seamless experiences. Techniques for optimization, such as adaptive interfaces, latency reduction, ergonomic design, and multi-modal feedback integration, are reviewed to understand how they enhance user satisfaction and reduce discomfort.Several challenges, including hardware limitations, motion sickness, user fatigue, and accessibility, are discussed, emphasizing the need for more inclusive and user-friendly design solutions. The review also explores content creation barriers and difficulties in scaling immersive experiences. Finally, the paper outlines future opportunities, focusing on AI-driven personalization, biometric feedback for adaptive environments, enhanced cross-platform integration, and advancements in collaborative immersive experiences. These emerging trends offer promising solutions to overcome current limitations and push the boundaries of UX in immersive technologies. This review aims to provide a comprehensive understanding of the state-of-the-art in UX optimization and identify key areas for future research and innovation.","","979-8-3315-1208-8","10.1109/ICICCS65191.2025.10985157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10985157","Immersive Technologies;AI-Driven Experiences;Dynamic User Interfaces;Continuous Feedback Loops;Adaptive Interfaces","Technological innovation;Reviews;Education;Collaboration;Mixed reality;Medical services;Motion sickness;Fatigue;User experience;Optimization","","","","61","IEEE","12 May 2025","","","IEEE","IEEE Conferences"
"Using a 6 Degrees of Freedom Virtual Reality Input Device With An Augmented Reality Headset In A Collaborative Environment","A. S. Williams; F. R. Ortega",Colorado State University; Colorado State University,2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"6 May 2021","2021","","","205","209","Augmented reality headsets have become increasingly consumer-available. Often gesture and speech are the main input modalities provided by these headsets. For some tasks, users may need a more precise input method. Tracked controllers can be added by using image tracking; however, this is not always the most accurate solution. This work outlines how to use off-the-shelf products to create a collaborative cross-device mixed reality experience. In that experience, the positionally tracked inputs from one headset can be used by another headset that may not natively support them.","","978-1-6654-4057-8","10.1109/VRW52623.2021.00045","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9419324","Human-centered computing;Human computer interaction (HCI);Interaction devices;Haptic devices;Pointing devices;Interaction paradigms;Collaborative interaction;Mixed / augmented reality;Virtual reality","Headphones;Three-dimensional displays;Conferences;Collaboration;Mixed reality;Input devices;User interfaces","","1","","14","IEEE","6 May 2021","","","IEEE","IEEE Conferences"
"A collaboration support technique by integrating a shared virtual reality and a shared augmented reality","K. Kiyokawa; H. Takemura; N. Yokoya","Multimedia Communications Section, MPT, Communications Research Laboratories, Koganei, Tokyo, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara, Japan","IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)","6 Aug 2002","1999","6","","48","53 vol.6","Proposes seamless view-mode switching, a novel technique for supporting spatial collaboration that integrates a shared virtual environment (SVE) and a shared augmented environment (SAE) in a natural way. The technique uses two view modes: a see-through mode and a blind mode, corresponding to an SAE and an SVE, respectively. In the initial state, the view mode is the see-through one. Whenever a user changes his/her location or scaling factor by using a 3D widget, the view mode is automatically switched to the blind one. In this mode, a computer-graphics human body (avatar), which includes a head and two arms, is displayed in place of a real partner. When a user chooses the see-through mode by using the widget, the position, orientation and scaling factor are gradually changed to those of the partner, and the view mode is switched back to the see-through one. In addition to this seamless view-mode switching, we also employ two techniques for collaboration support. First, the system optionally draws a line from the center of the partner's eyes in his/her viewing direction to enhance face direction information. Second, the system employs two methods for precise calibration: a look-up table-based mechanism for correcting the distorted magnetic field, and a Kalman filter for compensating the computational delay. Owing to these techniques, users of our system can smoothly perform spatial collaboration.","1062-922X","0-7803-5731-0","10.1109/ICSMC.1999.816444","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=816444","","Collaboration;Virtual environment;Computer displays;Humans;Avatars;Magnetic heads;Arm;Eyes;Calibration;Magnetic fields","","41","","10","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Effects of network characteristics on task performance in a desktop CVE system","Ling Chen","College of Computer Science, University of Zhejiang, Hangzhou, China",19th International Conference on Advanced Information Networking and Applications (AINA'05) Volume 1 (AINA papers),"25 Apr 2005","2005","1","","821","826 vol.1","The influences of network characteristics on the task performance in a desktop collaborative virtual environment (CVE) system were studied. In the experiment, two participants worked together to accomplish a collaborative task and a network emulator was utilized to simulate real network characteristics. The task used in the experiment was designed to be highly interactive and had rigid requirements on network characteristics (e.g. latency and packet loss). The objective performance and subjective assessment were recorded and analyzed quantitatively as a function of network latency and packet loss rate. The experiment results show that network latency has no distinct effect on task performance when network latency is less than 200 ms and lightly affect task performance when network latency is between 200 and 600 ms; packet loss has no effect on task performance when there are 40 state update messages received per second and lightly affect task performance when there are between 15 and 40 state update messages received per second.","2332-5658","0-7695-2249-1","10.1109/AINA.2005.171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1423590","","Intelligent networks;Delay;Performance loss;Collaborative work;Virtual environment;Collaboration;Navigation;Filtering algorithms;Educational institutions;Computer science","","5","","12","IEEE","25 Apr 2005","","","IEEE","IEEE Conferences"
"Collaborative virtual environments for ergonomics: embedding the design engineer role in the loop","C. Pontonnier; T. Duval; G. Dumont","IRISA, France Ecoles de Saint-Cyr Coetquidan, Rennes, Guer, France; IRISA, France Universite de Rennes, Rennes, France; IRISA, Rennes, Bruz, France",2014 International Workshop on Collaborative Virtual Environments (3DCVE),"27 Jul 2015","2014","","","1","5","The aim of this paper is to define the role and duties of a design engineer involved in a collaborative ergonomic design session supported by a 3D collaborative virtual environment. For example, such a session can be used to adapt the manual task an operator must achieve in the context of an industrial assembly line. We first present the interest of such collaborative sessions. Then we present a related work explaining the need of proper 3DCVE and metaphors to obtain efficient collaborative ergonomic design sessions. Then, after a short definition of the role of the engineer in such sessions, we propose a use case highlighting the type of metaphor such engineers need to have to be efficient in such a framework. Discussion and future works ends the paper.","","978-1-4799-5217-5","10.1109/3DCVE.2014.7160930","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7160930","","Ergonomics;Collaboration;Workstations;Virtual environments;Assembly;Three-dimensional displays;Solid modeling","","3","","22","IEEE","27 Jul 2015","","","IEEE","IEEE Conferences"
"A knowledge model to read 3D annotations on a virtual mock-up for collaborative design","S. Aubry; I. Thouvenin; D. Lenne; J. Olive","UMR CNRS 6599 Heudiasyc Laboratory, University of Technology of Compiégne, France; UMR CNRS 6599 Heudiasyc Laboratory, University of Technology of Compiégne, France; UMR CNRS 6599 Heudiasyc Laboratory, University of Technology of Compiégne, France; UMR CNRS 6599 Heudiasyc Laboratory, University of Technology of Compiégne, France",2007 11th International Conference on Computer Supported Cooperative Work in Design,"30 Jul 2007","2007","","","669","674","This article describes the concept of knowledge integration in a 3D collaborative virtual environment. This concept characterizes collaborative design in terms of two models introduced in this article -an annotation model with a semantic metadata notion - and a knowledge model to capitalize and to manage annotations - MATRICS environment. We briefly describe this approach. Then we present the results of an empirical study in which subjects performed annotation tasks with the support of an ontology visualization 2D tool and through the navigation in the 3D annotations. This study shows that the knowledge model improves the quality of the understanding of design projects.","","1-4244-0962-4","10.1109/CSCWD.2007.4281516","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4281516","Collaborative Design;Knowledge Representation;3D Annotations;Virtual Reality","Collaborative work;Virtual environment;Virtual reality;Knowledge management;Process design;International collaboration;Knowledge representation;Data visualization;Environmental management;Ontologies","","3","","24","IEEE","30 Jul 2007","","","IEEE","IEEE Conferences"
"Study on effects of network characteristics on cooperation performance in a desktop CVE system","Chen Ling; Chen Gen-Cai; Chen Hong; Xu Xiao-Lei; Chen Chun","College of Computer Science and Technology, University of Zhejiang, Hangzhou, China; College of Computer Science and Technology, University of Zhejiang, Hangzhou, China; College of Computer Science and Technology, University of Zhejiang, Hangzhou, China; College of Computer Science and Technology, University of Zhejiang, Hangzhou, China; College of Computer Science and Technology, University of Zhejiang, Hangzhou, China",8th International Conference on Computer Supported Cooperative Work in Design,"8 Nov 2004","2004","1","","121","126 Vol.1","The influences of network characteristics (e.g. latency, packet loss) on the task performance in desktop collaborative virtual environment (CVE) systems were studied. In the experiment, two remote partners worked together to manipulate shared virtual objects over a network, and a network emulator was utilized to simulate the real network. The task in the experiment was to minimize the time to transfer a frame through a rod with no collisions. The performance of human subjects was measured and analyzed quantitatively as a function of network latency and packet loss rate. The experiment results show that the delay had little effect on the task performance while the network latency was less than 200 ms and it was acceptable while the network latency was less than 500 ms; the packet loss had no effect on the task performance while there were 20 state update messages received and it was acceptable while there were more than 10 state update messages received.","","0-7803-7941-1","10.1109/CACWD.2004.1349000","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1349000","","Intelligent networks;Performance loss;Collaboration;Industrial training;Virtual environment;Delay effects;Navigation;Educational institutions;Computer science;Collaborative work","","1","","11","IEEE","8 Nov 2004","","","IEEE","IEEE Conferences"
"Cybermedicine - what is possible, and is it useful?","N. W. John","School of Informatics, University of Wales, Bangor, UK",2005 International Conference on Cyberworlds (CW'05),"6 Feb 2006","2005","","","2 pp.","13","The medical domain provides excellent opportunities for the application of computer graphics, visualization, and virtual environments, with the potential to help improve healthcare and bring benefits to patients. Possible applications include anatomical educational tools; patient education; diagnostic aids; virtual endoscopy; planning aids; guidance aids; skills training; and computer augmented reality. This talk provides a comprehensive overview of the state-of-the-art in this exciting field, including examples from research projects and commercially available products. The term cybermedicine was discussed and used to categorise those medical applications that can be delivered via the World Wide Web, preferably in the context of a collaborative virtual environment. The issues for effective cybermedicine was highlighted, and we will look ahead to future developments","","0-7695-2378-1","10.1109/CW.2005.34","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1587511","","Application software;Virtual environment;Medical services;Medical diagnostic imaging;Computer graphics;Visualization;Computer science education;Educational products;Endoscopes;Augmented reality","","","","3","IEEE","6 Feb 2006","","","IEEE","IEEE Conferences"
"Effects of Communication Mode on Social Presence, Virtual Presence, and Performance in Collaborative Virtual Environments","E. Sallnäs","Interaction and Presentation Laboratory, Royal Institute of Technology, Stockholm, Sweden evalotta@nada.kth.se",Presence,"19 May 2014","2005","14","4","434","449","How does communication mode affect people's experience of social presence, presence, and performance, and how does it affect their actual collaboration in a virtual environment? In a first experiment, subjects communicated by text-chat, audio conference, or video conference in a desktop collaborative virtual environment (CVE). Both perceived social presence and presence were shown to be lower in the text-chat condition than in the audio- and video-conference conditions. People spent a longer time performing a decision-making task together, spoke fewer words in total, and also spoke fewer words per second in the text-chat environment. Finally, more words per second were spoken in the audio-conference than in the video-conference condition. In a second experiment, collaboration in a CVE audio- and a CVE video condition was compared to collaboration in a Web audio-conference and a Web video-conference condition. Results showed that presence was rated higher in the two video than in the two audio conditions and especially in the Web video condition. People spent more time in the video than in the audio conditions and more words per second were spoken in the Web than in the CVE conditions. In conclusion, it was found that both the communication media used and the environment in which collaboration takes place (CVE or Web) make a difference for how subjects experience interaction and for their communication behavior.","1054-7460","","10.1162/105474605774785253","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6790666","","","","9","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Supporting Artefact Awareness in Partially-Replicated Workspaces","E. Poh; A. Tang; J. S. Lee; Z. Shengdong","NUS-HCI Lab, School of Computing, National University of Singapore; School of Computing and Information Systems, Singapore Management University; Centre for Immersification, Infocomm Technology Cluster, Singapore Institute of Technology; NUS-HCI Lab, School of Computing, National University of Singapore",2023 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"4 Dec 2023","2023","","","55","59","Using Cross Reality (CR) approaches for remote collaboration will often result in partially-replicated workspaces. Here, workspace artefacts are not equally accessible—i.e. a physical artefact may only be manipulated by one collaborator—and in general, the artefacts become desynchronised over time. In this paper, we introduce a framework for artefact awareness that can help collaborators maintain an understanding of each others’ manipulations with workspace artefacts. We illustrate our design explorations through sketches, and outline how we aim to study the effectiveness and utility of artefact awareness in cross reality remote collaboration. In our work, we expect to show that effectively supporting artefact awareness will help make cross-reality remote collaboration smoother.","2771-1110","979-8-3503-2891-2","10.1109/ISMAR-Adjunct60411.2023.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10322229","Human-centered computing Collaborative and social computing theory;concepts and paradigms;H;uman-centered computing Computer supported cooperative work;Human-centered computing Computer supported cooperative work;Human-centered computing Interaction design","Human computer interaction;Social computing;Collaboration;X reality","","","","22","IEEE","4 Dec 2023","","","IEEE","IEEE Conferences"
"Multi-user Interaction in Collaborative Augmented Reality for Urban Simulation","A. W. Ismail; M. S. Sunar","Department of Computer Graphic and Multimedia, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia; Department of Computer Graphic and Multimedia, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia",2009 Second International Conference on Machine Vision,"15 Jan 2010","2009","","","309","314","Augmented reality (AR) environment allows user or multi-user to interact with 2D and 3D data. AR simply can provide a collaborative interactive AR environment for urban simulation, where users can interact naturally and intuitively. AR collaboration approach can be effectively used to develop different interfaces for face-to-face and remote collaboration. This is because AR provides seamless interaction between real and virtual environments, the ability to enhance reality, the presence of spatial cues for face-to-face and remote collaboration, support of a tangible interface metaphor, the ability to transition smoothly between reality and virtuality. In addition, the collaborative AR makes multi-user in urban simulation to share simultaneously a real world and virtual world. The fusion between real and virtual world, existed in AR environment by see-through HMDs, achieves higher interactivity as a key features of collaborative AR. In real-time, precise registration between both worlds and multi-user are crucial for the collaborations. Collaborative AR approach allows multi-user to simultaneously share a real world surrounding them and a virtual world. Common problems in AR environment will be discussed and major issues in collaborative AR will be explained details in this survey. The features of collaboration in AR environment are will be identified and the requirements of collaborative AR will be defined. This paper will give an overview on collaborative AR environment for multi-user in urban studies and planning. The work will also cover numerous systems of collaborative AR environments for multi-user.","","978-1-4244-5645-1","10.1109/ICMV.2009.40","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5381135","","Collaboration;Augmented reality;Collaborative work;Urban planning;Computational modeling;Collaborative tools;Virtual reality;Displays;Process design;Humans","","2","1","28","IEEE","15 Jan 2010","","","IEEE","IEEE Conferences"
"A User Study on Sharing Physiological Cues in VR Assembly Tasks","P. Sasikumar; R. Hajika; K. Gupta; T. S. Gunasekaran; Y. S. Pai; H. Bai; S. Nanayakkara; M. Billinghurst",National University of Singapore; The University of Auckland; The University of Auckland; The University of Auckland; The University of Auckland; The University of Auckland; National University of Singapore; The University of Auckland,2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR),"15 Apr 2024","2024","","","765","773","In collaborative settings where multiple individuals are tasked with completing a shared goal, understanding one’s partner’s emotional state could be crucial for achieving a successful outcome. This is particularly relevant in remote collaboration contexts, where physical distance can impede understanding, empathy, and mutual comprehension between partners. In this paper, we demonstrate representing emotional patterns from physiological data in a shared Virtual Reality (VR) environment, and explore how it impacted communication styles. A user study investigated the potential effects of this emotional representation in fostering empathetic communication during remote collaboration. The study’s findings revealed that although there was minimal variance in the workload associated with observing physiological cues, participants generally preferred monitoring their partner’s attentional state. However, with the assembly task chosen, most participants only directed a minimal proportion of their attention toward the physiological cues displayed by their partner, and were frequently uncertain of how to interpret and use the information obtained. We also discuss limitations of the research and opportunities for future work.","2642-5254","979-8-3503-7402-5","10.1109/VR58804.2024.00096","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494102","AR Assembly;Physiological sensing;Collaborative VR;Adaptive VR;Emotion Adaptive VR","Measurement;Three-dimensional displays;Collaboration;Virtual reality;User interfaces;Physiology;Biomedical monitoring","","2","","65","IEEE","15 Apr 2024","","","IEEE","IEEE Conferences"
"Collaborative teleoperation design requirements and development issues","M. K. Habib","GMD-Japan Research Laboratory, Kitakyushu, Japan","2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies","6 Aug 2002","2000","1","","19","27 vol.1","This paper introduces a collaborative teleoperation concept to deal with task complexity, the high cost needed to enhance quality and safety, and the distribution of resources in terms of time, space and functionality. The new concept is supported by the use of shared virtual environment enhanced by reality to facilitate interaction, decision making, collaborative control, monitoring, discussion, document sharing, and other activities while interacting and manipulating real facilities jointly or individually. This concept uses the Internet and Web as a platform and location independent environment to enable geographically dispersed teams that may compose of human members, and intelligent and autonomous machines. The dispersed team can perform collaboratively shared and individual tasks at specific single or distributed locations as if they were all interacting with each other in the same physical place. In addition, this paper introduces the functional and design requirements along with the development and research issues for having an efficient collaborative teleoperation.","","0-7803-6456-2","10.1109/IECON.2000.973120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=973120","","Collaboration;Humans;Decision making;Internet;Laboratories;Buildings;Problem-solving;Cost function;Safety;Virtual environment","","1","","32","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Hand-in-Hand: A Communication-Enhancement Collaborative Virtual Reality System for Promoting Social Interaction in Children With Autism Spectrum Disorders","H. Zhao; A. R. Swanson; A. S. Weitlauf; Z. E. Warren; N. Sarkar","Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, USA; Treatment and Research Institute for Autism Spectrum Disorders, Vanderbilt Kennedy Center, Nashville, TN, USA; Treatment and Research Institute for Autism Spectrum Disorders, Vanderbilt Kennedy Center, Nashville, TN, USA; Treatment and Research Institute for Autism Spectrum Disorders, Vanderbilt Kennedy Center, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA",IEEE Transactions on Human-Machine Systems,"14 Mar 2018","2018","48","2","136","148","Children with autism spectrum disorders (ASD) often exhibit impairments in communication and social interaction, and thus face various social challenges in collaborative activities. Given the cost of ASD intervention and lack of access to trained clinicians, technology-assisted ASD intervention has gained momentum in recent years. In this paper, we present a novel collaborative virtual environment (CVE)-based social interaction platform for ASD intervention. The development of CVE technology for ASD intervention may lead to the creation of a novel low-cost intervention environment that will foster collaboration with peers and provide flexibility in communication. The presented Communication-Enhancement CVE system, hand-in-hand, allows two children to play a series of interactive games in a virtual reality environment by using simple hand gestures to collaboratively move virtual objects that are tracked in real time via cameras. Furthermore, these games are designed to promote natural communication and cooperation between the users via the presented Communication-Enhancement mode that allows users to share information and discuss game strategies using gaze and voice-based communication. The results of a feasibility study with 12 children with ASD and 12 typically developing peers show that this system was well accepted by both the children with and without ASD, improved their cooperation in game play, and demonstrated the potential for fostering their communication and collaboration skills.","2168-2305","","10.1109/THMS.2018.2791562","National Institutes of Health(grant numbers:1R01MH091102-01A1,1R21MH111548-01); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267303","Autism intervention;collaborative virtual reality (VR) system;communication and social interaction","Games;Collaboration;Autism;Virtual reality;Tracking;Real-time systems;Training","","74","","47","IEEE","23 Jan 2018","","","IEEE","IEEE Journals"
"Using Virtual Reality to Support Acting in Motion Capture with Differently Scaled Characters","R. K. Kammerlander; A. Pereira; S. Alexanderson","Division of Speech Music and Hearing, KTH Royal Institute of Technology; Division of Speech Music and Hearing, KTH Royal Institute of Technology; Division of Speech Music and Hearing, KTH Royal Institute of Technology",2021 IEEE Virtual Reality and 3D User Interfaces (VR),"10 May 2021","2021","","","402","410","Motion capture is a well-established technology for capturing actors' movements and performances within the entertainment industry. Many actors, however, witness the poor acting conditions associated with such recordings. Instead of detailed sets, costumes and props, they are forced to play in empty spaces wearing tight suits. Often, their co-actors will be imaginary, replaced by placeholder props, or they would be out of scale with their virtual counterparts. These problems do not only affect acting, they also cause an abundance of laborious post-processing clean-up work. To solve these challenges, we propose using a combination of virtual reality and motion capture technology to bring differently proportioned virtual characters into a shared collaborative virtual environment. A within-subjects user study with trained actors showed that our proposed platform enhances their feelings of body ownership and immersion. This in turn changed actors' performances which narrowed the gap between virtual performances and final intended animations.","2642-5254","978-1-6654-1838-6","10.1109/VR50410.2021.00063","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417778","Collaborative virtual production;acting;motion capture;body ownership;presence","Three-dimensional displays;Interactive systems;Collaboration;Virtual environments;Production;User interfaces;Tools","","17","","42","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"A virtual reality learning environment providing access to digital museums","N. Kladias; T. Pantazidis; M. Avagianos","Integrated Information Systems, Athens, Greece; Integrated Information Systems, Athens, Greece; Integrated Information Systems, Athens, Greece",Proceedings 1998 MultiMedia Modeling. MMM'98 (Cat. No.98EX200),"6 Aug 2002","1998","","","193","202","VR-LEARNERS (Virtual Learning Environment for Network of Advanced Multimedia Resource Centers, Museums and Schools) is a European project that aims at developing an educational application based on collaborative virtual environment (CVE) technology and providing access to digital exhibits of European museums. The project was initiated in January 1998 and the paper presents an overview of the project objectives, the technical approach, findings of the user requirement research activity as well as the design specification approach.","","0-8186-8911-0","10.1109/MULMM.1998.723002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=723002","","Virtual reality;Virtual environment;Computer networks;Collaboration;Distributed computing;Psychology;Visualization;Information systems;Multimedia systems;Educational technology","","2","","15","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Managing Collaboration in the nanoManipulator","T. C. Hudson; A. T. Helser; D. H. Sonnenwald; M. C. Whitton","University of North Carolina at Wilmington; 3rdTech, Inc.; Göteborg University and University College of Borås, Sweden; University of North Carolina at Chapel Hill",Presence,"19 May 2014","2004","13","2","193","210","We designed, developed, deployed, and evaluated the Collaborative nanoManipulator (CnM), a distributed, collaborative virtual environment system supporting remote scientific collaboration between users of the nanoManipulator interface to atomic force microscopes. This paper describes the entire collaboration system, but focuses on the shared nanoManipulator (nM) application. To be readily accepted by users, the shared nM application had to have the same high level of interactivity as the single-user system and include all the functions of the single-user system. In addition the application had to support a user's ability to interleave working privately and working collaboratively. Based on our experience developing the CnM, we present: a method of analyzing applications to characterize the concurrency requirements for sharing data between collaborating sites, examples of data structures that support distributed collaboration and interleaved private and collaborative work, and guidelines for selecting appropriate synchronization and concurrency control schemes.","1054-7460","","10.1162/1054746041382447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6788713","","","","1","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"A Collaborative Virtual Reality Environment for Molecular Biology","J. Lee; P. Quy; J. -I. Kim; L. -W. Kang; A. Seo; H. Kim","Department of Advanced Technology Fusion, Konkuk University, Seoul, South Korea; Department of Advanced Technology Fusion, Konkuk University, Seoul, South Korea; Department of Advanced Technology Fusion, Konkuk University, Seoul, South Korea; Department of Advanced Technology Fusion, Konkuk University, Seoul, South Korea; Department of Computer Science & Engineering, Konkuk University, Seoul, South Korea; Internet and Multimedia Engineering, Konkuk University, Seoul, South Korea",2009 International Symposium on Ubiquitous Virtual Reality,"4 Sep 2009","2009","","","68","71","A collaborative virtual reality environment (CRVE) can be used in molecular biology because it can provide users with virtual experiences of three dimensional molecular models in cyberspaces. Therefore, we developed a remote collaboration system for molecular docking and crystallography using virtual reality techniques. The collaborative works of molecular docking were successfully exercised. We also conducted visualization and manipulation of three dimensional biomolecular models and supported discussions of remote participants for crystallography using the collaborative system.","","978-1-4244-4437-3","10.1109/ISUVR.2009.14","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232258","Collaborative Virtual Reality;Molecular Simulation;Virtual Reality Applications","Virtual reality;Collaborative work;Computational modeling;Collaborative tools;Visualization;Biological system modeling;Application software;International collaboration;Internet;Crystallography","","7","","10","IEEE","4 Sep 2009","","","IEEE","IEEE Conferences"
"Collaborative Augmented Reality Approach for Multi-user Interaction in Urban Simulation","A. W. Ismail; M. S. Sunar","Department of Computer Graphic and Multimedia, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia; Department of Computer Graphic and Multimedia, Universiti Teknologi Malaysia, Skudai, Johor, Malaysia",2009 International Conference on Information and Multimedia Technology,"15 Jan 2010","2009","","","19","23","Augmented reality (AR) environment allows user or multi-user to interact with 2D and 3D data. AR simply can provide a collaborative interactive AR environment for urban simulation, where users can interact naturally and intuitively. AR collaboration approach can be effectively used to develop face to face interfaces. This is because AR provides seamless interaction between real and virtual environments, the ability to enhance reality, the presence of spatial cues for face-to-face and remote collaboration, support of a tangible interface metaphor, the ability to transition smoothly between reality and virtuality. The fusion between real and virtual world, existed in AR environment, achieves higher interactivity as a key features of collaborative AR. Collaborative AR approach allows multi-user to simultaneously share a real world surrounding them and a virtual world. The features of collaboration in AR environment will be identified. The key for the proposed technique of precise registration between both worlds and multi-user are emphasized for the collaborations using AR environment. Common problems in AR environment and issues in collaborative AR will be discussed. This paper will give an overview for collaborative AR framework employed in urban simulation and the multi-user interaction on how to share these virtual spaces with other users in collaboration. The work will also cover numerous systems in different cases of collaborative AR environments for multiuser interaction.","","978-0-7695-3922-5","10.1109/ICIMT.2009.68","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5381253","Augmented Reality;Multi-User Interaction;Collaborative;Urban Simulation","Augmented reality;Collaborative work;Collaborative tools;Multimedia systems;Urban planning;International collaboration;Computational modeling;Computer graphics;Computer science;Information systems","","2","2","28","IEEE","15 Jan 2010","","","IEEE","IEEE Conferences"
"Remote Co-Creation of Upper Limb Prostheses: Insights from a Feasibility Study","L. Jabban; J. Male; N. Hadjigeorgiou; N. Y. Bailey; B. Ainsworth; B. Metcalfe","Electronic and Electrical Engineering, University of Bath, Bath, UK; Electronic and Electrical Engineering, University of Bath, Bath, UK; Department of Engineering, King’s College London, London, UK; Department of Engineering, King’s College London, London, UK; Department of Psychology, University of Southampton, Southampton, UK; Electronic and Electrical Engineering, University of Bath, Bath, UK",2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),"17 Dec 2024","2024","","","1","4","Upper-limb prostheses aim to replicate hand functionality for those with limb differences, but often fail user expectations due to multiple factors, including lack of sensory feedback, crucial for recognising contact and force application. In developing a user-centred device, researchers often face a barrier in obtaining suitable user input, due to the limited feedback interviews and lab activities can yield. Therefore, this study assessed the feasibility of remote co-creation in developing upper limb prostheses with sensory feedback, employing a user-centric Internet of Things approach. The project yielded insights into user preferences and needs in terms of sensory feedback, along with insights on the technical and communication challenges of such an approach. Results show that while remote co-creation has potential in enhancing prosthesis functionality and user satisfaction, there are significant hurdles to overcome. The limited participation and technical complexities encountered highlight the need for more robust systems and processes to facilitate effective remote collaboration. This study serves as a preliminary exploration in a promising but challenging field.","2694-0604","979-8-3503-7149-9","10.1109/EMBC53108.2024.10782004","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10782004","Sensory Feedback;Co-creation;Upper-limb prostheses;IoT","Face recognition;Force;Collaboration;Complexity theory;Reliability;Internet of Things;Interviews;Engineering in medicine and biology;Prosthetics","Artificial Limbs;Humans;Feasibility Studies;Upper Extremity;Prosthesis Design;Feedback, Sensory;Male","","","7","IEEE","17 Dec 2024","","","IEEE","IEEE Conferences"
"LEM-an approach for real time physically based soft tissue simulation","I. F. Costa; R. Balaniuk","SHARP GRAVIRINRIA, INRIA, France; NA",Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),"9 Jul 2003","2001","3","","2337","2343 vol.3","This paper presents LEM (long elements method), a new method for physically based simulation of deformable objects, suitable for real time animation and virtual environment interaction. The approach implements a static solution for elastic global deformations of objects filled with fluid based on the Pascal's principle and volume conservation. The volumes are discretised in long elements, defining meshes one order of magnitude smaller than tetrahedral or cubic meshes. The physics of the objects are modeled using bulk variables: pressure, density, volume and stress. No pre-calculations or condensations are needed. The approach is particularly interesting for soft tissue real time simulation and for graphic and haptic rendering.","1050-4729","0-7803-6576-3","10.1109/ROBOT.2001.932971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=932971","","Biological tissues;Deformable models;Computational modeling;Virtual reality;Power engineering computing;Surgery;Shape control;Animation;Physics;Stress","","27","1","13","IEEE","9 Jul 2003","","","IEEE","IEEE Conferences"
"Comparing Visual Representations of Collaborative Map Interfaces for Immersive Virtual Environments","A. Santos-Torres; T. Zarraonandia; P. Díaz; I. Aedo","Computer Science and Engineering Department, Interactive Systems Group (DEILAB), Universidad Carlos III de Madrid, Madrid, Spain; Computer Science and Engineering Department, Interactive Systems Group (DEILAB), Universidad Carlos III de Madrid, Madrid, Spain; Computer Science and Engineering Department, Interactive Systems Group (DEILAB), Universidad Carlos III de Madrid, Madrid, Spain; Computer Science and Engineering Department, Interactive Systems Group (DEILAB), Universidad Carlos III de Madrid, Madrid, Spain",IEEE Access,"30 May 2022","2022","10","","55136","55150","Virtual reality offers unique benefits to support remote collaboration. However, the way of representing the scenario and interacting within the team can influence the effectiveness of a collaborative task. In this context, this research explores the benefits and limitations of two different visual representations of the collaboration space, shared experience and shared workspace, in the specific case of map-based collaboration. Shared experience aims at reproducing face-to-face collaboration in a realistic way whilst shared workspace translates to the virtual world the functionalities of 2D collaborative spaces. The goal is to understand whether sophisticated interfaces with realistic avatars are necessary, or if simpler solutions might be enough to support efficient collaboration. We performed a user study ( $n=24$ , 12 pairs) through a collaborative task with two roles in a emergency crisis intervention scenario that typically uses map-based interfaces. Despite that a shared experience scenario might provide a better personal experience to the user in terms of realism, our study provides insights that suggest that a shared workspace could be a more effective way to represent the scenario and improve the collaboration.","2169-3536","","10.1109/ACCESS.2022.3176949","Spanish State Research Agency (Agencia Estatal de Investigación - AEI)(grant numbers:Sense2makeSense PID2019-109388GB-I00,CrossColab PGC2018-101884-B-I100); Madrid Government (Comunidad de Madrid -Spain) under the Multiannual Agreement with UC3M in the line of Excellence of University Professors(grant numbers:EPUC3M17); context of the V PRICIT (Regional Programme of Research and Technological Innovation); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9779762","Immersive map interfaces;collaboration;social presence;workspace awareness;virtual reality","Collaboration;Visualization;Task analysis;Virtual environments;Three-dimensional displays;Avatars;Behavioral sciences","","6","","51","CCBY","23 May 2022","","","IEEE","IEEE Journals"
"Exploring Extended Reality (XR) in the Workplace - Applications, Challenges: Survey","K. T; M. V. Devi; S. SenthilPandi; M. Tharun","Department of CSE, Rajalakshmi Engineering College, Chennai, India; Department of CSE, Rajalakshmi Engineering College, Chennai, India; Department of CSE, Rajalakshmi Engineering College, Chennai, India; Department of CSE, Rajalakshmi Engineering College, Chennai, India","2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)","3 Jan 2024","2023","","","1","5","In ordinary work life, extended reality (XR), which here collectively refers to virtual, augmented, and mixed (VR, AR, MR) reality, is becoming more prevalent. This essay offers a thorough analysis of academic works on XR that show modifications to the way labour is actually organized. We examine XR research's theoretical and methodological foundations as well as its application areas. The PRISMA statement was followed during the evaluation procedure. The primary application domains of XR were design, remote collaboration, and training. By modifying the perception of space, XR made it possible to overcome constraints imposed by time and space, safety, and resources. It is still rather uncommon to do research on XR applications in real-world workplace contexts, and it mostly focuses on three areas: teamwork, knowledge transfer evaluation, and working procedures. The most prevalent application of XR was virtual reality, albeit the hardware used varies depending on the situation. Collaboration, work habits, and knowledge transfer evaluation were the four XR research areas we defined, which roughly mirrored the application domains. Only a few recent studies used unique methods of data collection, such as videotaping participants' movement in virtual reality, in the articles we evaluated. We could not identify any XR-specific procedures in the articles we reviewed. For the time being, XR still has a lot of potential rather than definite general advantages in the workplace.","","979-8-3503-0570-8","10.1109/RMKMATE59243.2023.10369447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10369447","XR;AR;VR;Work Place Challenges","Wireless communication;Training;Surveys;Extended reality;Employment;Teamwork;Time factors","","5","","35","IEEE","3 Jan 2024","","","IEEE","IEEE Conferences"
"Understanding the Quality of User Experience in Telepresence Systems From an Information Theory Perspective","R. Wang; K. Liu; Z. Dang; X. Wang; F. Dang; Y. Sun; Y. Tong; H. Zhao; Y. Liu","Global Innovation Exchange, Tsinghua University, Beijing, China; Global Innovation Exchange, Tsinghua University, Beijing, China; Computer Science Department, University of California at Los Angeles, Los Angeles, CA, USA; Global Innovation Exchange, Tsinghua University, Beijing, China; Global Innovation Exchange, Tsinghua University, Beijing, China; Global Innovation Exchange, Tsinghua University, Beijing, China; Global Innovation Exchange, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Global Innovation Exchange, Tsinghua University, Beijing, China",IEEE Transactions on Consumer Electronics,"18 Aug 2025","2025","71","2","6499","6510","Efforts to enhance the user experience (UX) of telepresence edge systems in various application scenarios have been significant. However, existing approaches tend to focus on specific aspects, leaving us with a fragmented understanding of UX quality. We address this gap by examining Video Conference Systems (VCSs) for remote collaboration, using an Information Theory Perspective as a lens. We introduce a novel model to quantify the multimodality information users receive while engaged in mobile office environments, enabling an evaluation of existing VCSs. Our approach transforms the assessment of UX quality into the measurement of a set of information channels. Based on this insight, we identify new prospects and meaningful guidelines for future multimedia telepresence edge systems, and try to induce a new prototype design under cost restriction. To demonstrate the validity of our method, we implement the prototype which seamlessly integrates visual, audio, and olfactory dimension information. Extensive experiments and user studies validate the effectiveness and practicality of our approach.","1558-4127","","10.1109/TCE.2024.3352240","National Science and Technology Major Project(grant numbers:2022ZD0114903); National Natural Science Foundation of China (NSFC)(grant numbers:62202263); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10387998","Telepresence edge system;model analysis;user experience quality","Telepresence;Information theory;Robots;Prototypes;Three-dimensional displays;Collaboration;Visualization","","2","","53","IEEE","10 Jan 2024","","","IEEE","IEEE Journals"
"Industrial Automation using VR and AI","R. A. Sinha; N. Munjal; A. Lakra; R. Kaur; B. Mehndiratta; A. Kumar","Dept. of Computer Science, (Specialization in Block Chain Technology), Chandigarh University, Mohali, India; Dept. of Computer Science, (Specialization in Block Chain Technology), Chandigarh University, Mohali, India; Dept. of Computer Science, (Specialization in Block Chain Technology), Chandigarh University, Mohali, India; Dept. of Computer Science, (Specialization in Block Chain Technology), Chandigarh University, Mohali, India; Dept. of Computer Science, (Specialization in Block Chain Technology), Chandigarh University, Mohali, India; Deptt. of Mechanical Engineering, Chandigarh University, Mohali, India",2023 World Conference on Communication & Computing (WCONF),"4 Sep 2023","2023","","","1","6","Automation anywhere, is the process of using technology to perform certain tasks or processes that could otherwise be done or performed by humans. Automation is leading to transformation of various processes and industries, and the combination of AI and VR in automation has opened new possibilities and paths for businesses and organizations to optimize their operations. Machine learning (ML) algorithms can process and work on vast amounts of data and generate valuable insights that can help us perform certain tasks and inform decision-making algorithms about it. VR which is another evolving technology can enhance the experience of the user and facilitate remote collaboration. This paper depicts about Artificial Intelligence (AI), Machine Learning (ML), Virtual Reality (VR) and Automation in industries, and it also tries to demonstrate the audience about how these mechanisms are related to each other and how they can be more effective when they work together and can give competitive and industrial advantage. The aim of this review paper is to explore the latest research and developments in automation, virtual reality, and artificial intelligence, with a particular focus on their applications in various industries and their implications for society as a whole.","","979-8-3503-1120-4","10.1109/WCONF58270.2023.10235059","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10235059","Automation Industry;Artificial Intelligence;Virtual Reality;Machine Learning;Industry 4.0","Industries;Technological innovation;Ethics;Automation;Machine learning algorithms;Virtual reality;Machine learning","","","","51","IEEE","4 Sep 2023","","","IEEE","IEEE Conferences"
"Addressing 3D Digital Twin in Xr Remote Fab Lab Over Sliced 5G Networks","K. Komatsu; A. Pauanne; T. Hänninen; J. Kela; T. Rantakokko; E. Piri; J. Prokkola; P. Marques; T. Alves; J. Haapola; A. Pouttu","Centre for Wireless Communications, University of Oulu, Oulu, Finland; Centre for Wireless Communications, University of Oulu, Oulu, Finland; Centre for Wireless Communications, University of Oulu, Oulu, Finland; Finwe Ltd., Oulu, Finland; Finwe Ltd., Oulu, Finland; Kaitotek Oy, Oulu, Finland; Kaitotek Oy, Oulu, Finland; Allbesmart Lda, Castelo Branco, Portugal; Allbesmart Lda, Castelo Branco, Portugal; Centre for Wireless Communications, University of Oulu, Oulu, Finland; Centre for Wireless Communications, University of Oulu, Oulu, Finland",2025 Joint European Conference on Networks and Communications & 6G Summit (EuCNC/6G Summit),"26 Jun 2025","2025","","","506","511","This paper presents a pioneering approach to developing remote Fabrication Laboratory (Fab Lab) using extended reality (XR) and 3D digital twins, enabled by cutting-edge advancements in private 5G networks. These XR Fab Labs enable multi-user remote collaboration and real-time control of R&D and manufacturing processes. Taking advantage of 3D digital twins and XR technologies, users can interact, review, and manipulate 3D models in a virtual space. The integration of ultra-reliable low-latency communication (URLLC) and network slicing within an Open Radio Access Network (O-RAN)-based private 5 G framework provides robust low-latency connectivity. An operational demonstration compared eMBB and URLLC slices under congestion, while a user Quality of Experience (QoE) survey revealed high usability and minimal perceived latency. This approach confirms the feasibility of integrating XR-based digital twins with 5 G slicing capability for remote design and manufacturing in cyber-physical spaces.","2575-4912","979-8-3503-9180-0","10.1109/EuCNC/6GSummit63408.2025.11036986","European Union's Horizon Europe research and innovation programme(grant numbers:101096838); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11036986","5G;Slicing;URLLC;eMBB;3D Digital Twin;XR;Cyber-Physical Systems;Edge Computing;QoS/QoE;Network Performance","Three-dimensional displays;5G mobile communication;Collaboration;Quality of service;Open RAN;Ultra reliable low latency communication;Aerospace electronics;Real-time systems;Digital twins;Quality of experience","","","","19","IEEE","26 Jun 2025","","","IEEE","IEEE Conferences"
"RemoteTouch: Enhancing Immersive 3D Video Communication with Hand Touch","Y. Zhang; Z. Li; S. Xu; C. Li; J. Yang; X. Tong; B. Guo","Microsoft Research Asia; Microsoft Research Asia, Zhejiang University; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia",2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR),"1 May 2023","2023","","","1","10","Recent research advance has significantly improved the visual real-ism of immersive 3D video communication. In this work we present a method to further enhance this immersive experience by adding the hand touch capability (“remote hand clapping”). In our system, each meeting participant sits in front of a large screen with haptic feedback. The local participant can reach his hand out to the screen and perform hand clapping with the remote participant as if the two participants were only separated by a virtual glass. A key challenge in emulating the remote hand touch is the realistic rendering of the participant's hand and arm as the hand touches the screen. When the hand is very close to the screen, the RGBD data required for realistic rendering is no longer available. To tackle this challenge, we present a dual representation of the user's hand. Our dual representation not only preserves the high-quality rendering usually found in recent image-based rendering systems but also allows the hand to reach to the screen. This is possible because the dual representation includes both an image-based model and a 3D geometry-based model, with the latter driven by a hand skeleton tracked by a side view camera. In addition, the dual representation provides a distance-based fusion of the image-based and 3D geometry-based models as the hand moves closer to the screen. The result is that the image-based and 3D geometry-based models mutually enhance each other, leading to realistic and seamless rendering. Our experiments demonstrate that our method provides consistent hand contact experience between remote users and improves the immersive experience of 3D video communication.","2642-5254","979-8-3503-4815-6","10.1109/VR55154.2023.00016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108425","Human-centered computing-Collaborative and social computing;Computing methodologies-Computer graphics-Graphics systems and interfaces-Virtual reality","Solid modeling;Visualization;Three-dimensional displays;Tracking;Immersive experience;Glass;User interfaces","","6","","85","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Exploring the Frontiers of User Experience Design: VR, AR, and the Future of Interaction","B. Hari Chandana; N. Shaik; P. Chitralingappa","Department of CSE, Srinivasa Ramanujan Institute of Technology, Anantapur; Department of CSE, Srinivasa Ramanujan Institute of Technology, Anantapur; Department of CSE, Srinivasa Ramanujan Institute of Technology, Anantapur",2023 International Conference on Computer Science and Emerging Technologies (CSET),"19 Dec 2023","2023","","","1","6","This paper explores the field of user experience (UX) design for virtual reality (VR) and augmented reality (AR) applications. VR and AR technologies have gained significant attention in recent years, offering immersive and interactive experiences across various domains such as gaming, training, visualization, healthcare, and education. Effective UX design is crucial in maximizing the potential of these technologies and creating engaging and meaningful experiences for users. The paper begins by defining VR and AR, highlighting their distinctions and current adoption rates. It then delves into the implications of VR and AR on UX design, emphasizing key principles such as immersion, spatial awareness, interaction, comfort, and realism. The challenges faced in UX design for VR and AR, including motion sickness, field of view limitations, cognitive load, physical constraints, and technical limitations, are also discussed. Best practices for UX design in VR and AR applications are presented, including a user-centered design approach, iterative prototyping, intuitive interactions, effective wayfinding, and the integration of physical and digital elements. The paper showcases successful case studies in gaming, industrial training, architectural visualization, healthcare, and education to illustrate the effective implementation of UX design principles in real-world applications. Future trends and emerging technologies in the field are explored, such as extended reality (XR), natural language processing, haptic feedback, social VR, and ethical considerations. The importance of UX design in VR and AR is emphasized, highlighting its role in creating Immersive, intuitive, and enjoyable experiences. In conclusion, this paper emphasizes the significance of UX design in VR and AR applications and provides insights into the principles, challenges, best practices, case studies, and future outlook of UX design in this evolving field. By following user-centered design principles, staying informed about emerging technologies, and prioritizing ethical considerations, UX designers can shape the future of VR and AR experiences and unlock their full potential in various domains.","","979-8-3503-4173-7","10.1109/CSET58993.2023.10346724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10346724","Virtual Reality (VR);Augmented Reality (AR);User Experience (UX);Extended Reality (XR);Mixed Reality (MR)","Visualization;Ethics;Shape;User centered design;Medical services;Motion sickness;User experience","","5","","15","IEEE","19 Dec 2023","","","IEEE","IEEE Conferences"
"Variable Impedance Control for Safety and Usability in Telemanipulation","S. A. Schwarz; U. Thomas","Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, SN, Germany; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, SN, Germany",2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),"26 Dec 2022","2022","","","6177","6182","In recent years, haptic telemanipulation has been introduced to control robots remotely with an input device that generates force feedback. Compliant control strategies are needed to ensure safe interaction between humans and robots. Accurate and precise manipulation requires a stiff setup of the impedance parameters, while safety demands for low stiffness. This paper proposes an impedance-based control approach that combines stiff manipulation with a safety mechanism that adapts compliance when required. We introduce three system modes: operation, safety and recovery mode. If the external forces exceed a defined force threshold, the system switches to the compliant safety mode. A user input triggers the recovery process that increases the stiffness back to its nominal value. This paper suggests an energy tank, which limits the change of stiffness to ensure stability during recovering phase. We validate the functionality of this approach using a real telemanipulation setup and show that the suggested tank enables recovery even from large displacements.","2153-0866","978-1-6654-7927-1","10.1109/IROS47612.2022.9982118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9982118","","Delay effects;Force;Input devices;Robot sensing systems;Safety;Behavioral sciences;Impedance","","5","","18","IEEE","26 Dec 2022","","","IEEE","IEEE Conferences"
"Integrating Communication with Interaction: Computer Vision Challenges for Interactive and Intelligent Environments","J. R. Cooperstock","Centre for Intelligent Machines, McGill University, Montreal, QUE, Canada",Computer Vision for Interactive and Intelligent Environment (CVIIE'05),"24 Apr 2006","2005","","","151","161","Interactive, Intelligent Environments involve a convergence of various research themes, including high-fidelity visualization, communication, gestural expression, and virtualized reality systems. Recent advances in real-time acquisition, transmission, and rendering of multimodal data (e.g. audio, video, haptic) allow for the synthesis of significantly improved perceptual representations of a virtual or real (e.g. remote) environment than were previously possible. Furthermore, increased computational power permits the synthesis of a rich responsive media space that responds to a large number of participants engaged in a complex, expressive activity. Unfortunately, current systems tend to concentrate almost exclusively on one aspect or the other, supporting the representation and interaction with a virtual world, or supporting distributed human communication, but never both. The ideal interactive intelligent environment is one that permits effective distributed human-human communication among large numbers of participants at multiple locations, simultaneously with data visualization capabilities and interaction with dynamic, synthetic objects. A significant challenge for the next generation of such environments is to develop the necessary physical infrastructures and software architectures that combine these capabilities appropriately.","","0-7695-2524-5","10.1109/CVIIE.2005.10","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1623777","","Computer vision;Humans;Machine intelligence;Data visualization;Video sharing;Space technology;Computer displays;Data gloves;Wrist;Particle filters","","","1","24","IEEE","24 Apr 2006","","","IEEE","IEEE Conferences"
"A Survey on Metaverse: Fundamentals, Security, and Privacy","Y. Wang; Z. Su; N. Zhang; R. Xing; D. Liu; T. H. Luan; X. Shen","School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; Department of Electrical and Computer Engineering, University of Windsor, Windsor, Canada; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada; School of Cyber Science and Engineering, Xi’an Jiaotong University, Xi’an, China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada",IEEE Communications Surveys & Tutorials,"23 Feb 2023","2023","25","1","319","352","Metaverse, as an evolving paradigm of the next-generation Internet, aims to build a fully immersive, hyper spatiotemporal, and self-sustaining virtual shared space for humans to play, work, and socialize. Driven by recent advances in emerging technologies such as extended reality, artificial intelligence, and blockchain, metaverse is stepping from science fiction to an upcoming reality. However, severe privacy invasions and security breaches (inherited from underlying technologies or emerged in the new digital ecology) of metaverse can impede its wide deployment. At the same time, a series of fundamental challenges (e.g., scalability and interoperability) can arise in metaverse security provisioning owing to the intrinsic characteristics of metaverse, such as immersive realism, hyper spatiotemporality, sustainability, and heterogeneity. In this paper, we present a comprehensive survey of the fundamentals, security, and privacy of metaverse. Specifically, we first investigate a novel distributed metaverse architecture and its key characteristics with ternary-world interactions. Then, we discuss the security and privacy threats, present the critical challenges of metaverse systems, and review the state-of-the-art countermeasures. Finally, we draw open research directions for building future metaverse systems.","1553-877X","","10.1109/COMST.2022.3202047","NSFC(grant numbers:U20A20175,U1808207); Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9880528","Metaverse;security;privacy;distributed virtual worlds;extended reality;artificial intelligence;blockchain","Metaverse;Security;Privacy;Artificial intelligence;Blockchains;Spatiotemporal phenomena;Scalability","","807","","177","IEEE","7 Sep 2022","","","IEEE","IEEE Journals"
"Trends in augmented reality tracking, interaction and display: A review of ten years of ISMAR","Feng Zhou; H. B. -L. Duh; M. Billinghurst","Center for Human Factors and Ergonomics, Nanyang Technological University, Singapore; Department of Electrical and Computer Engineering, Interactive and Digital Media Institute, National University of Singapore, Singapore; HIT Laboratory NZ, University of Canterbury, New Zealand",2008 7th IEEE/ACM International Symposium on Mixed and Augmented Reality,"3 Oct 2008","2008","","","193","202","Although Augmented Reality technology was first developed over forty years ago, there has been little survey work giving an overview of recent research in the field. This paper reviews the ten-year development of the work presented at the ISMAR conference and its predecessors with a particular focus on tracking, interaction and display research. It provides a roadmap for future augmented reality research which will be of great value to this relatively young field, and also for helping researchers decide which topics should be explored when they are beginning their own studies in the area.","","978-1-4244-2840-3","10.1109/ISMAR.2008.4637362","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4637362","H5.1. [Information System]: Multimedia information systems—Artificial, augmented, and virtual realities;Augmented reality;tracking;interaction;calibration and registration;AR application;AR display","Solid modeling;Tracking;Computational modeling;Visualization;Collaboration;Three dimensional displays;Sensors","","429","21","97","IEEE","3 Oct 2008","","","IEEE","IEEE Conferences"
"Revisiting Trends in Augmented Reality Research: A Review of the 2nd Decade of ISMAR (2008–2017)","K. Kim; M. Billinghurst; G. Bruder; H. B. -L. Duh; G. F. Welch",University of Central Florida; University of South Australia; University of Central Florida; La Trobe University; University of Central Florida,IEEE Transactions on Visualization and Computer Graphics,"29 Oct 2018","2018","24","11","2947","2962","In 2008, Zhou et al. presented a survey paper summarizing the previous ten years of ISMAR publications, which provided invaluable insights into the research challenges and trends associated with that time period. Ten years later, we review the research that has been presented at ISMAR conferences since the survey of Zhou et al., at a time when both academia and the AR industry are enjoying dramatic technological changes. Here we consider the research results and trends of the last decade of ISMAR by carefully reviewing the ISMAR publications from the period of 2008-2017, in the context of the first ten years. The numbers of papers for different research topics and their impacts by citations were analyzed while reviewing them-which reveals that there is a sharp increase in AR evaluation and rendering research. Based on this review we offer some observations related to potential future research areas or trends, which could be helpful to AR researchers and industry members looking ahead.","1941-0506","","10.1109/TVCG.2018.2868591","ONR(grant numbers:N00014-17-1-2927); NSF(grant numbers:1564065); Florida Hospital; South Australia Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8456568","Augmented reality;mixed reality;survey;trends","Market research;Rendering (computer graphics);Calibration;Augmented reality;Industries;Sensors;Indexes","","273","","153","IEEE","6 Sep 2018","","","IEEE","IEEE Journals"
"A Review of Recent Advances in Automated Guided Vehicle Technologies: Integration Challenges and Research Areas for 5G-Based Smart Manufacturing Applications","E. A. Oyekanlu; A. C. Smith; W. P. Thomas; G. Mulroy; D. Hitesh; M. Ramsey; D. J. Kuhn; J. D. Mcghinnis; S. C. Buonavita; N. A. Looper; M. Ng; A. Ng’oma; W. Liu; P. G. Mcbride; M. G. Shultz; C. Cerasi; D. Sun","MT&E, Corning Inc., Painted Post, NY, USA; Verizon Wireless, Baskin Ridge, NJ, USA; Corning Optical Communications LLC, Hickory, NC, USA; MT&E, Corning Inc., Painted Post, NY, USA; Verizon Wireless, Baskin Ridge, NJ, USA; Verizon Wireless, Baskin Ridge, NJ, USA; MT&E, Corning Inc., Painted Post, NY, USA; Corning Optical Communications LLC, Hickory, NC, USA; Verizon Wireless, Baskin Ridge, NJ, USA; MT&E, Corning Inc., Painted Post, NY, USA; Verizon Wireless, Baskin Ridge, NJ, USA; MT&E, Corning Inc., Painted Post, NY, USA; Verizon Wireless, Baskin Ridge, NJ, USA; MT&E, Corning Inc., Painted Post, NY, USA; MT&E, Corning Inc., Painted Post, NY, USA; Verizon Wireless, Baskin Ridge, NJ, USA; Verizon Wireless, Baskin Ridge, NJ, USA",IEEE Access,"16 Nov 2020","2020","8","","202312","202353","In industrial environments, over several decades, Automated Guided Vehicles (AGVs) and Autonomous Mobile Robots (AMRs) have served to improve efficiencies of intralogistics and material handling tasks. However, for system integrators, the choice and effective deployment of improved, suitable and reliable communication and control technologies for these unmanned vehicles remains a very challenging task. Specifics of communication for AGVs and AMRs imposes stringent performance requirements on latency and reliability of communication links which many existing wireless technologies struggle to satisfy. In this paper, a review of latest AGVs and AMRs research results in the past decade is presented. The review encompasses results from different past and present research domains of AGVs. In addition, performance requirements of communication networks in terms of their latencies and reliabilities when they are deployed for AGVs and AMRs coordination, control and fleet management in smart manufacturing environments are discussed. Integration challenges and limitations of present state-of-the-art AGV and AMR technologies when those technologies are used for facilitating AGV-based smart manufacturing and factory of the future applications are also thoroughly discussed. The paper also present a thorough discussion of areas in need of further research regarding the application of 5G networks for AGVs and AMRs fleet management in smart manufacturing environments. In addition, novel integration ideas by which tactile Internet, 5G network slicing and virtual reality applications can be used to facilitate AGV and AMR based factory of the future (FoF) and smart manufacturing applications were motivated.","2169-3536","","10.1109/ACCESS.2020.3035729","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9247159","Intelligent factory;factory of the future;5G;smart manufacturing;industry 4.0;autonomous industrial equipment;AGV;AMR;tactile Internet;virtual reality;lean manufacturing","Tactile Internet;5G mobile communication;Virtual reality;Production facilities;Reliability;Task analysis;Smart manufacturing","","200","","329","CCBY","3 Nov 2020","","","IEEE","IEEE Journals"
"Face to face collaborative AR on mobile phones","A. Henrysson; M. Billinghurst; M. Ollila","NVIS, Linköping University, Sweden; HIT Lab, University of Canterbury, New Zealand; NVIS, Linköping University, Sweden",Fourth IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR'05),"5 Dec 2005","2005","","","80","89","Mobile phones are an ideal platform for augmented reality. We describe how they also can be used to support face to face collaborative AR applications. We have created a custom port of the ARToolKit library to the Symbian mobile phone operating system and then developed a sample collaborative AR game based on this. We describe the game in detail and user feedback from people who have played it. We also provide general design guidelines that could be useful for others who are developing mobile phone collaborative AR applications.","","0-7695-2459-1","10.1109/ISMAR.2005.32","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1544667","","Collaboration;Mobile handsets;Collaborative work;Application software;Collaborative software;Augmented reality;Guidelines;Libraries;User interfaces;Operating systems","","142","15","34","IEEE","5 Dec 2005","","","IEEE","IEEE Conferences"
"Collaborative Work in Augmented Reality: A Survey","M. Sereno; X. Wang; L. Besançon; M. J. McGuffin; T. Isenberg","CNRS, Inria, LRI, Université Paris-Saclay, Saint-Aubin, France; CNRS, Inria, LRI, Université Paris-Saclay, Saint-Aubin, France; Linköping University, Linköping, Sweden; École de Technologie Supérieure, Montreal, QC, Canada; CNRS, Inria, LRI, Université Paris-Saclay, Saint-Aubin, France",IEEE Transactions on Visualization and Computer Graphics,"2 May 2022","2022","28","6","2530","2549","In Augmented Reality (AR), users perceive virtual content anchored in the real world. It is used in medicine, education, games, navigation, maintenance, product design, and visualization, in both single-user and multi-user scenarios. Multi-user AR has received limited attention from researchers, even though AR has been in development for more than two decades. We present the state of existing work at the intersection of AR and Computer-Supported Collaborative Work (AR-CSCW), by combining a systematic survey approach with an exploratory, opportunistic literature search. We categorize 65 papers along the dimensions of space, time, role symmetry (whether the roles of users are symmetric), technology symmetry (whether the hardware platforms of users are symmetric), and output and input modalities. We derive design considerations for collaborative AR environments, and identify under-explored research topics. These include the use of heterogeneous hardware considerations and 3D data exploration research areas. This survey is useful for newcomers to the field, readers interested in an overview of CSCW in AR applications, and domain experts seeking up-to-date information.","1941-0506","","10.1109/TVCG.2020.3032761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234650","Introductory and survey;computer-supported cooperative work;virtual and augmented reality;immersive analytics","Collaboration;Augmented reality;Collaborative work;Visualization;Hardware;Three-dimensional displays","Augmented Reality;Computer Graphics;Research Design","128","","179","IEEE","21 Oct 2020","","","IEEE","IEEE Journals"
"AI and 6G Into the Metaverse: Fundamentals, Challenges and Future Research Trends","M. Zawish; F. A. Dharejo; S. A. Khowaja; S. Raza; S. Davy; K. Dev; P. Bellavista","Walton Institute for Information and Communication Systems Science, South East Technological University, Waterford, Ireland; Department of Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Faculty of Engineering and Technology, University of Sindh, Jamshoro, Pakistan; Department of Electronic Engineering, Quaid-e-Awam University of Engineering, Science and Technology, Larkana, Pakistan; Centre for Sustainable Digital Technologies, Technological University Dublin, Dublin, Ireland; Department of Computer Science, Munster Technological University, Cork, Ireland; Department of Computer Science and Engineering, University of Bologna, Bologna, Italy",IEEE Open Journal of the Communications Society,"29 Jan 2024","2024","5","","730","778","Since Facebook was renamed Meta, a lot of attention, debate, and exploration have intensified about what the Metaverse is, how it works, and the possible ways to exploit it. It is anticipated that Metaverse will be a continuum of rapidly emerging technologies, usecases, capabilities, and experiences that will make it up for the next evolution of the Internet. Several researchers have already surveyed the literature on artificial intelligence (AI) and wireless communications in realizing the Metaverse. However, due to the rapid emergence and continuous evolution of technologies, there is a need for a comprehensive and in-depth survey of the role of AI, 6G, and the nexus of both in realizing the immersive experiences of Metaverse. Therefore, in this survey, we first introduce the background and ongoing progress in augmented reality (AR), virtual reality (VR), mixed reality (MR) and spatial computing, followed by the technical aspects of AI and 6G. Then, we survey the role of AI in the Metaverse by reviewing the state-of-the-art in deep learning, computer vision, and Edge AI to extract the requirements of 6G in Metaverse. Next, we investigate the promising services of B5G/6G towards Metaverse, followed by identifying the role of AI in 6G networks and 6G networks for AI in support of Metaverse applications, and the need for sustainability in Metaverse. Finally, we enlist the existing and potential applications, usecases, and projects to highlight the importance of progress in the Metaverse. Moreover, in order to provide potential research directions to researchers, we underline the challenges, research gaps, and lessons learned identified from the literature review of the aforementioned technologies.","2644-125X","","10.1109/OJCOMS.2024.3349465","Science Foundation Ireland(grant numbers:21/FFP-A/9174); Science Foundation Ireland and the Department of Agriculture, Food and Marine on behalf of the Government of Ireland VistaMilk Research Centre(grant numbers:16/RC/3835); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10415393","Metaverse;5G;6G;AI;cloud and edge computing;AR/VR/XR;spatial computing","6G mobile communication;Surveys;Wireless communication;Computer vision;Telepresence;Metaverse;Artificial intelligence","","97","","307","CCBYNCND","29 Jan 2024","","","IEEE","IEEE Journals"
"Is there a reality in Industrial Augmented Reality?","P. Fite-Georgel","University of North Carolina, Chapel Hill, USA",2011 10th IEEE International Symposium on Mixed and Augmented Reality,"5 Mar 2012","2011","","","201","210","In the spirit of the seminal article by Brooks [12] that surveys the field of Virtual Reality to evaluate its level of applicability, we study the readiness of Industrial Augmented Reality (IAR). We have been hearing about IAR since Mizell and Caudell [14] first gave a name to AR, but how many applications broke out of the lab to be used by non-developers? In reviewing the literature, we note the amazing progress made in display technology, rendering and tracking. Given these improvements, one might expect AR-based industrial products to flourish. Unfortunately, this is still not the case. In this paper, we provide a comprehensive and up-to-date survey of industrial AR applications. We organize the different applications of IAR over the life-cycle of products, in order to draw some parallels between the different proposed concepts and offer a clear taxonomy for future applications. We also propose and apply a rubric to evaluate existing IAR systems in order to highlight reasons for success and offer guidelines in the hope that it will help IAR become “really real”.","","978-1-4577-2185-4","10.1109/ISMAR.2011.6092387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6162889","","Solid modeling;Welding;Design automation;Maintenance engineering;Production facilities;Assembly;Three dimensional displays","","90","89","75","IEEE","5 Mar 2012","","","IEEE","IEEE Conferences"
"Empowering 6G Communication Systems With Digital Twin Technology: A Comprehensive Survey","N. P. Kuruvatti; M. A. Habibi; S. Partani; B. Han; A. Fellan; H. D. Schotten","Department of Electrical and Computer Engineering, Division of Wireless Communications and Radio Navigation, Technische Universität Kaiserslautern, Kaiserslautern, Germany; Department of Electrical and Computer Engineering, Division of Wireless Communications and Radio Navigation, Technische Universität Kaiserslautern, Kaiserslautern, Germany; Department of Electrical and Computer Engineering, Division of Wireless Communications and Radio Navigation, Technische Universität Kaiserslautern, Kaiserslautern, Germany; Department of Electrical and Computer Engineering, Division of Wireless Communications and Radio Navigation, Technische Universität Kaiserslautern, Kaiserslautern, Germany; Department of Electrical and Computer Engineering, Division of Wireless Communications and Radio Navigation, Technische Universität Kaiserslautern, Kaiserslautern, Germany; Department of Electrical and Computer Engineering, Division of Wireless Communications and Radio Navigation, Technische Universität Kaiserslautern, Kaiserslautern, Germany",IEEE Access,"28 Oct 2022","2022","10","","112158","112186","The global roll-out phase of the fifth-generation of mobile communication systems is currently underway. The industry and academia have already begun research on potential sixth-generation (6G) communication systems. The 6G communication system is anticipated to provide network connectivity for an extensive range of use cases in a variety of emerging vertical industries. Consequently, a new set of challenging requirements and more stringent key performance indicators have to be considered, a novel architecture has to be designed, and unique enabling technologies shall be developed in order to fulfill the technical, regulatory, and business demands of the communication service customers. These requirements place enormous pressure on the players in the telecommunications industry, including network operators, service providers, hardware suppliers, standards development organizations (SDOs), and regulatory authorities aimed at developing, standardizing, and regulating an energy-efficient, cost-effective, performing, and sustainable 6G communication ecosystem. One area of focus for 6G communication systems is the digital twin (DT) technology, which is a well-defined set of tools designed to create virtual representations of physical objects that serve as their digital counterparts. This article explores the applicability of the DT technology in the context of 6G communication systems by viewing it as a promising tool to make research, development, operation, and optimization of the next-generation communication systems highly efficient. The major contribution of this article is fivefold. Firstly, we provide critical analysis of the state-of-the-art literature in the field of DT technology in order to capture its essence in several application areas since its inception. Secondly, we conduct a comprehensive survey of the research concerning the deployment of DT technology in 6G communication systems. Thirdly, we discuss potential use cases and key areas of applications (along with detailed examples) of 6G communication systems that can benefit from DT technology. Fourthly, we present an overview of the activities of several SDOs that are active in the field of DT technology. Finally, we identify several open research challenges and future directions that need to be addressed before the end-to-end deployment of DT technology in 6G communication systems.","2169-3536","","10.1109/ACCESS.2022.3215493","European Union’s Horizon 2020 Research and Innovation Program through the Project Hexa-X(grant numbers:101015956); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9923927","5G;beyond 5G;6G;automation;communication systems;digital twinning;digital twin network;digital twin technology;intelligence;physical twin","6G mobile communication;Communication systems;Industries;5G mobile communication;Digital twins;Mobile communication;Communication networks","","90","","130","CCBY","19 Oct 2022","","","IEEE","IEEE Journals"
"Being an Avatar “for Real”: A Survey on Virtual Embodiment in Augmented Reality","A. Genay; A. Lécuyer; M. Hachet","Inria, Bordeaux, France; Inria, Rennes, France; Inria, Bordeaux, France",IEEE Transactions on Visualization and Computer Graphics,"26 Oct 2022","2022","28","12","5071","5090","Virtual self-avatars have been increasingly used in Augmented Reality (AR) where one can see virtual content embedded into physical space. However, little is known about the perception of self-avatars in such a context. The possibility that their embodiment could be achieved in a similar way as in Virtual Reality opens the door to numerous applications in education, communication, entertainment, or the medical field. This article aims to review the literature covering the embodiment of virtual self-avatars in AR. Our goal is (i) to guide readers through the different options and challenges linked to the implementation of AR embodiment systems, (ii) to provide a better understanding of AR embodiment perception by classifying the existing knowledge, and (iii) to offer insight on future research topics and trends for AR and avatar research. To do so, we introduce a taxonomy of virtual embodiment experiences by defining a “body avatarization” continuum. The presented knowledge suggests that the sense of embodiment evolves in the same way in AR as in other settings, but this possibility has yet to be fully investigated. We suggest that, whilst it is yet to be well understood, the embodiment of avatars has a promising future in AR and conclude by discussing possible directions for research.","1941-0506","","10.1109/TVCG.2021.3099290","Institut national de recherche en informatique et en automatique (INRIA); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9495125","Augmented reality;avatar;sense of embodiment;psychology;social and behavioral sciences","Avatars;Psychology;Visualization;Behavioral sciences;Taxonomy;Augmented reality;Virtual environments","Augmented Reality;User-Computer Interface;Computer Graphics;Virtual Reality;Surveys and Questionnaires","85","","171","IEEE","26 Jul 2021","","","IEEE","IEEE Journals"
"Virtual-Reality Interpromotion Technology for Metaverse: A Survey","D. Wu; Z. Yang; P. Zhang; R. Wang; B. Yang; X. Ma","School of Communication and Information Engineering, Advanced Network and Intelligent Connection Technology Key Laboratory of Chongqing Education Commission of China, Chongqing, China; School of Cyber Security and Information Law, Chongqing University of Posts and Telecommunications, Chongqing, China; School of Communication and Information Engineering, Advanced Network and Intelligent Connection Technology Key Laboratory of Chongqing Education Commission of China, Chongqing, China; School of Communication and Information Engineering, Advanced Network and Intelligent Connection Technology Key Laboratory of Chongqing Education Commission of China, Chongqing, China; School of Communication and Information Engineering, Advanced Network and Intelligent Connection Technology Key Laboratory of Chongqing Education Commission of China, Chongqing, China; School of Artificial Intelligence, Chongqing University of Arts and Sciences, Chongqing, China",IEEE Internet of Things Journal,"6 Sep 2023","2023","10","18","15788","15809","The metaverse aims to build an immersive virtual reality world to support the daily life, work, and recreation of people. In this survey, the status quo of the metaverse is investigated, and the technical framework of the metaverse is introduced from three aspects: 1) the generation of virtual worlds; 2) the connection of virtual and real objects; and 3) the transmission of data. Specifically, this survey first discusses the development and challenges of the related technologies for virtual world generation methods from three aspects: 1) the 3-D world generation; 2) immersive human–computer interaction experience; and 3) ecosystem. Second, we investigate the status quo of extended reality (XR), motion capture, and brain–computer interface technologies and evaluate the potential and research directions of these entrance technologies for the metaverse. Finally, network and data transmission technologies for the metaverse are reviewed from the Internet of Things (IoT), 5G/6G wireless, and edge computing aspects, the demand side of the metaverse in virtual-reality interpromotion, big data processing, and low-latency networking is discussed, and promising research hotspots are identified.","2327-4662","","10.1109/JIOT.2023.3265848","National Natural Science Foundation of China(grant numbers:61901071,U20A20157); Science and Natural Science Foundation of Chongqing, China(grant numbers:cstc2020jcyj-zdxmX0024); University Innovation Research Group of Chongqing(grant numbers:CXQT20017); Program for Innovation Team Building at Institutions of Higher Education in Chongqing(grant numbers:CXTDX201601020); Key Science and Technology Research Program of Chongqing Municipal Education Commission, China(grant numbers:KJZD-K202101305); Natural Science Foundation of Chongqing, China(grant numbers:cstc2021jcyjmsxmX0495); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10098667","Artificial intelligence (AI);brain-computer interactions;edge computing;extended reality (XR);Internet of Things (IoT);metaverse","Metaverse;Three-dimensional displays;Rendering (computer graphics);Solid modeling;Collision avoidance;Feature extraction;Behavioral sciences","","85","","180","IEEE","10 Apr 2023","","","IEEE","IEEE Journals"
"MeBot: A robotic platform for socially embodied telepresence","S. O. Adalgeirsson; C. Breazeal","MIT Media Laboratory, Cambridge, MA, USA; MIT Media Laboratory, Cambridge, MA, USA",2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI),"22 Apr 2010","2010","","","15","22","Telepresence refers to a set of technologies that allow users to feel present at a distant location; telerobotics is a subfield of telepresence. This paper presents the design and evaluation of a telepresence robot which allows for social expression. Our hypothesis is that a telerobot that communicates more than simply audio or video but also expressive gestures, body pose and proxemics, will allow for a more engaging and enjoyable interaction. An iterative design process of the MeBot platform is described in detail, as well as the design of supporting systems and various control interfaces. We conducted a human subject study where the effects of expressivity were measured. Our results show that a socially expressive robot was found to be more engaging and likable than a static one. It was also found that expressiveness contributes to more psychological involvement and better cooperation.","2167-2148","978-1-4244-4892-0","10.1109/HRI.2010.5453272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453272","Human robot interaction;telepresence;robotmediated communication;embodied videoconferencing","Human robot interaction;Orbital robotics;Teleconferencing;Cognitive robotics;Laboratories;Telerobotics;Psychology;Process design;Control systems;Surveillance","","82","3","20","IEEE","22 Apr 2010","","","IEEE","IEEE Conferences"
"Advancing Education Through Extended Reality and Internet of Everything Enabled Metaverses: Applications, Challenges, and Open Issues","S. K. Jagatheesaperumal; K. Ahmad; A. Al-Fuqaha; J. Qadir","Department of Electronics and Communication Engineering, Mepco Schlenk Engineering College, Sivakasi, India; Department of Computer Science, Munster Technological University, Cork, Ireland; Information and Computing Technology Division, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Department of Computer Science and Engineering, College of Engineering, Qatar University, Doha, Qatar",IEEE Transactions on Learning Technologies,"28 Feb 2024","2024","17","","1120","1139","Metaverse has evolved as one of the popular research agenda that let users learn, socialize, and collaborate in a networked 3-D immersive virtual world. Due to the rich multimedia streaming capability and immersive user experience with high-speed communication, the metaverse is an ideal model for education, training, and skill development tasks. To facilitate research in this area, we provide a comprehensive review of the various educational use cases and explore how enabling technologies, such as extended reality and the Internet of Everything will play a major role in educational services in future metaverses. Then, we provide an overview of metaverse-based educational applications focusing on education, training, and skill development and analyze the technologies they are built upon. We identify common research problems and future research directions in the domain. This article also identifies core ethical considerations of metaverse for education and potential pitfalls. We believe this survey can fully demonstrate the versatility of metaverse-driven education, which could serve as a potential guideline for the researchers.","1939-1382","","10.1109/TLT.2024.3358859","Qatar University High Impact Internal(grant numbers:QUHI-CENG23/24-127); Qatar National Library; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10415252","Artificial intelligence (AI);education;extended reality (XR);metaverse","Metaverse;X reality;Education;Extended reality;Surveys;Real-time systems;Internet of Things","","79","","191","CCBY","26 Jan 2024","","","IEEE","IEEE Journals"
"CollaboVR: A Reconfigurable Framework for Creative Collaboration in Virtual Reality","Z. He; R. Du; K. Perlin",New York University; Google; New York University,2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"14 Dec 2020","2020","","","542","554","Writing or sketching on whiteboards is an essential part of collaborative discussions in business meetings, reading groups, design sessions, and interviews. However, prior work in collaborative virtual reality (VR) systems has rarely explored the design space of multi-user layouts and interaction modes with virtual whiteboards. In this paper, we present CollaboVR, a reconfigurable framework for both co-located and geographically dispersed multi-user communication in VR. Our system unleashes users’ creativity by sharing freehand drawings, converting 2D sketches into 3D models, and generating procedural animations in real-time. To minimize the computational expense for VR clients, we leverage a cloud architecture in which the computational expensive application (Chalktalk) is hosted directly on the servers, with results being simultaneously streamed to clients. We have explored three custom layouts – integrated, mirrored, and projective – to reduce visual clutter, increase eye contact, or adapt different use cases. To evaluate CollaboVR, we conducted a within-subject user study with 12 participants. Our findings reveal that users appreciate the custom configurations and real-time interactions provided by CollaboVR. We have open sourced CollaboVR at https://github.com/snowymo/CollaboVR to facilitate future research and development of natural user interfaces and real-time collaborative systems in virtual and augmented reality.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00082","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284659","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Human-centered computing;Collaborative and social computing;Collaborative and social computing systems and tools","Visualization;Layout;Collaboration;Writing;Real-time systems;Space exploration;Augmented reality","","69","","90","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"A Conceptual Model and Taxonomy for Collaborative Augmented Reality","B. Marques; S. Silva; J. Alves; T. Araújo; P. Dias; B. S. Santos","IEETA, DETI, University of Aveiro, Aveiro, Portugal; IEETA, DETI, University of Aveiro, Aveiro, Portugal; IEETA, DETI, University of Aveiro, Aveiro, Portugal; PPGCC, Federal University of Pará, Belém, Brasil; IEETA, DETI, University of Aveiro, Aveiro, Portugal; IEETA, DETI, University of Aveiro, Aveiro, Portugal",IEEE Transactions on Visualization and Computer Graphics,"26 Oct 2022","2022","28","12","5113","5133","To support the nuances of collaborative work, many researchers have been exploring the field of Augmented Reality (AR), aiming to assist in co-located or remote scenarios. Solutions using AR allow taking advantage from seamless integration of virtual objects and real-world objects, thus providing collaborators with a shared understanding or common ground environment. However, most of the research efforts, so far, have been devoted to experiment with technology and mature methods to support its design and development. Therefore, it is now time to understand where the field stands and how well can it address collaborative work with AR, to better characterize and evaluate the collaboration process. In this article, we perform an analysis of the different dimensions that should be taken into account when analysing the contributions of AR to the collaborative work effort. Then, we bring these dimensions forward into a conceptual framework and propose an extended human-centered taxonomy for the categorization of the main features of Collaborative AR. Our goal is to foster harmonization of perspectives for the field, which may help create a common ground for systematization and discussion. We hope to influence and improve how research in this field is reported by providing a structured list of the defining characteristics. Finally, some examples of the use of the taxonomy are presented to show how it can serve to gather information for characterizing AR-supported collaborative work, and illustrate its potential as the grounds to elicit further studies.","1941-0506","","10.1109/TVCG.2021.3101545","Foundation for Science and Technology; Institute of Electronics and Informatics Engineering of Aveiro; FCT(grant numbers:UID/CEC/00127/2019); Portugal2020; Competitiveness and Internationalization Operational Program; European Regional Development Fund(grant numbers:CENTRO-01-0145-FEDER-000010); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9506837","Collaboration;augmented reality;conceptual model;taxonomy;human-centered;systematization","Collaboration;Taxonomy;Collaborative work;Augmented reality;Visualization;Augmented reality;Three-dimensional displays;Human computer interaction","Humans;Augmented Reality;Computer Graphics","64","","120","IEEE","4 Aug 2021","","","IEEE","IEEE Journals"
"A Survey of Full-Body Motion Reconstruction in Immersive Virtual Reality Applications","P. Caserman; A. Garcia-Agundez; S. Göbel","Multimedia Communications Lab, Technische Universität Darmstadt, Darmstadt, Germany; Multimedia Communications Lab, Technische Universität Darmstadt, Darmstadt, Germany; Multimedia Communications Lab, Technische Universität Darmstadt, Darmstadt, Germany",IEEE Transactions on Visualization and Computer Graphics,"1 Sep 2020","2020","26","10","3089","3108","Due to recent advances in virtual reality (VR) technology, the development of immersive VR applications that track body motions and visualize a full-body avatar is attracting increasing research interest. This paper reviews related research to gather and to critically analyze recent improvements regarding the potential of full-body motion reconstruction in VR applications. We conducted a systematic literature search, matching VR and full-body tracking related keywords on IEEE Xplore, PubMed, ACM, and Scopus. Fifty-three publications were included and assigned in three groups: studies using markerless and marker-based motion tracking systems as well as systems using inertial measurement units. All analyzed research publications track the motions of the user wearing a head-mounted display and visualize a full-body avatar. The analysis confirmed that a full-body avatar can enhance the sense of embodiment and can improve the immersion within the VR. The results indicated that the Kinect device is still the most frequently used sensor (27 out of 53). Furthermore, there is a trend to track the movements of multiple users simultaneously. Many studies that enable multiplayer mode in VR use marker-based systems (7 out of 17) because they are much more robust and can accurately track full-body movements of multiple users in real-time.","1941-0506","","10.1109/TVCG.2019.2912607","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695841","Virtual reality;full-body tracking;motion reconstruction;markerless motion capture;marker-based motion capture;inertial measurement units;full-body avatar","Tracking;Avatars;Real-time systems;Resists;Games;Cameras;Robot sensing systems","","55","","73","IEEE","23 Apr 2019","","","IEEE","IEEE Journals"
"Metaverse Communications, Networking, Security, and Applications: Research Issues, State-of-the-Art, and Future Directions","M. Ali; F. Naeem; G. Kaddoum; E. Hossain","Electrical Engineering Department, ETS, University of Quebec, Montreal, QC, Canada; Electrical Engineering Department, ETS, University of Quebec, Montreal, QC, Canada; Electrical Engineering Department, ETS, University of Quebec, Montreal, QC, Canada; Department of Computer and Electrical Engineering, University of Manitoba, Winnipeg, MB, Canada",IEEE Communications Surveys & Tutorials,"22 May 2024","2024","26","2","1238","1278","Metaverse is an evolving orchestrator of the next-generation Internet architecture that produces an immersive and self-adapting virtual world in which humans perform activities similar to those in the real world, such as playing sports, doing work, and socializing. It is becoming a reality and is driven by ever-evolving advanced technologies such as extended reality, artificial intelligence, and blockchain. In this context, Metaverse will play an essential role in developing smart cities, which becomes more evident in the post-COVID-19-pandemic metropolitan setting. However, the new paradigm imposes new challenges, such as developing novel privacy and security threats that can emerge in the digital Metaverse ecosystem. Moreover, it requires the convergence of several media types with the capability to quickly process massive amounts of data to keep the residents safe and well-informed, which can raise issues related to scalability and interoperability. In light of this, this research study aims to review the literature on the state of the art of integrating the Metaverse architecture concepts in smart cities. First, this paper presents the theoretical architecture of Metaverse and discusses international companies’ interest in this emerging technology. It also examines the notion of Metaverse relevant to virtual reality, identifies the prevalent threats, and determines the importance of communication infrastructure in information gathering for efficient Metaverse operation. Next, the notion of blockchain technologies is discussed regarding privacy preservation and how it can provide tamper-proof content sharing among Metaverse users. Finally, the application of distributed Metaverse for social good is highlighted. Most importantly, the paper explores the reflections of this cutting-edge technology on the smart city, talks about the role and impact of the Metaverse in the production of urban policies, and eventually identifies the research gaps and the future research directions in this domain.","1553-877X","","10.1109/COMST.2023.3347172","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10373900","Metaverse;smart city;networking;security;blockchain","Metaverse;Smart cities;Tutorials;Surveys;Avatars;Artificial intelligence;X reality","","54","","257","IEEE","25 Dec 2023","","","IEEE","IEEE Journals"
"Virtual Co-Embodiment: Evaluation of the Sense of Agency While Sharing the Control of a Virtual Body Among Two Individuals","R. Fribourg; N. Ogawa; L. Hoyet; F. Argelaguet; T. Narumi; M. Hirose; A. Lécuyer","Inria, Univ Rennes, CNRS, IRISA, Rennes, France; University of Tokyo, Tokyo, Japan; Inria, Univ Rennes, CNRS, IRISA, Rennes, France; Inria, Univ Rennes, CNRS, IRISA, Rennes, France; University of Tokyo, Tokyo, Japan; University of Tokyo, Tokyo, Japan; Inria, Univ Rennes, CNRS, IRISA, Rennes, France",IEEE Transactions on Visualization and Computer Graphics,"1 Sep 2021","2021","27","10","4023","4038","In this article, we introduce a concept called “virtual co-embodiment”, which enables a user to share their virtual avatar with another entity (e.g., another user, robot, or autonomous agent). We describe a proof-of-concept in which two users can be immersed from a first-person perspective in a virtual environment and can have complementary levels of control (total, partial, or none) over a shared avatar. In addition, we conducted an experiment to investigate the influence of users’ level of control over the shared avatar and prior knowledge of their actions on the users’ sense of agency and motor actions. The results showed that participants are good at estimating their real level of control but significantly overestimate their sense of agency when they can anticipate the motion of the avatar. Moreover, participants performed similar body motions regardless of their real control over the avatar. The results also revealed that the internal dimension of the locus of control, which is a personality trait, is negatively correlated with the user’s perceived level of control. The combined results unfold a new range of applications in the fields of virtual-reality-based training and collaborative teleoperation, where users would be able to share their virtual body.","1941-0506","","10.1109/TVCG.2020.2999197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105074","Virtual embodiment;sense of agency;avatars;virtual reality;user experimentation","Avatars;Atmospheric measurements;Particle measurements;Robots;Training;Task analysis;Collaboration","Computer Graphics;Humans;Male;Psychomotor Performance;Self Concept;Virtual Reality","49","","75","IEEE","1 Jun 2020","","","IEEE","IEEE Journals"
"Collaborative Educational Environments Incorporating Mixed Reality Technologies: A Systematic Mapping Study","A. A. Ali; G. A. Dafoulas; J. C. Augusto","Department of Computer Science, Middlesex University, London, U.K; Department of Computer Science, Middlesex University, London, U.K; Department of Computer Science, Middlesex University, London, U.K",IEEE Transactions on Learning Technologies,"17 Sep 2019","2019","12","3","321","332","In this paper, we report findings from a systematic mapping study, conducted to review the existing literature on collaborative educational environments incorporating mixed reality technologies. There is increasing interest in mixed reality technologies in education, especially with the introduction of new over head mounted displays (OHMDs), such as HoloLens, Oculus Rift, and HTC Vive. with the consideration of areas, such as education, dynamic technology, and complex environments, a research area is identified. We carried out an extensive review of the literature from 2007 to 2017 and conducted an analysis of the works on mixed reality technologies and its subcategories applied to collaborative education environments. Results highlighted the lack of research across the mixed reality spectrum, especially in the augmented virtuality subcategory, as well as technical limitations such as response time in the development of mixed reality technologies for collaborative environments. Furthermore, the difficulty of teaching professionals to replicate mixed reality experiments in real environments, due to the technical skills required, was identified. The main contribution of this paper is the discussion of the current works with visualization of the present state of the area, which is aimed to encourage educators to develop mixed reality artefacts and conduct further research to support collaborative educational environments.","1939-1382","","10.1109/TLT.2019.2926727","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765378","Computer supported collaborative learning;collaborative environments;mixed reality;virtual reality augmented reality;augmented virtuality;systematic mapping.","Collaboration;Collaborative work;Education;Systematics;Augmented virtuality;Augmented reality","","47","","62","IEEE","17 Jul 2019","","","IEEE","IEEE Journals"
"Multimodal Multi-User Mixed Reality Human–Robot Interface for Remote Operations in Hazardous Environments","K. A. Szczurek; R. M. Prades; E. Matheson; J. Rodriguez-Nogueira; M. D. Castro","European Organization for Nuclear Research (CERN), Geneva, Switzerland; Department of Computer Science and Engineering, Jaume I University of Castellon, Castelló de la Plana, Spain; European Organization for Nuclear Research (CERN), Geneva, Switzerland; European Organization for Nuclear Research (CERN), Geneva, Switzerland; European Organization for Nuclear Research (CERN), Geneva, Switzerland",IEEE Access,"24 Feb 2023","2023","11","","17305","17333","In hazardous environments, where conditions present risks for humans, the maintenance and interventions are often done with teleoperated remote systems or mobile robotic manipulators to avoid human exposure to dangers. The increasing need for safe and efficient teleoperation requires advanced environmental awareness and collision avoidance. The up-to-date screen-based 2D or 3D interfaces do not fully allow the operator to immerse in the controlled scenario. This problem can be addressed with the emerging Mixed Reality (MR) technologies with Head-Mounted Devices (HMDs) that offer stereoscopic immersion and interaction with virtual objects. Such human-robot interfaces have not yet been demonstrated in telerobotic interventions in particle physics accelerators. Moreover, the operations often require a few experts to collaborate, which increases the system complexity and requires sharing an Augmented Reality (AR) workspace. The multi-user mobile telerobotics in hazardous environments with shared control in the AR has not yet been approached in the state-of-the-art. In this work, the developed MR human-robot interface using the AR HMD is presented. The interface adapts to the constrained wireless networks in particle accelerator facilities and provides reliable high-precision interaction and specialized visualization. The multimodal operation uses hands, eyes and user motion tracking, and voice recognition for control, as well as offers video, 3D point cloud and audio feedback from the robot. Multiple experts can collaborate in the AR workspace locally or remotely, and share or monitor the robot’s control. Ten operators tested the interface in intervention scenarios in the European Organization for Nuclear Research (CERN) with complete network characterization and measurements to conclude if operational requirements were met and if the network architecture could support single and multi-user communication load. The interface system has proved to be operationally ready at the Technical Readiness Level (TRL) 8 and was validated through successful demonstration in single and multi-user missions. Some system limitations and further work areas were identified, such as optimizing the network architecture for multi-user scenarios or high-level interface actions applying automatic interaction strategies depending on network conditions.","2169-3536","","10.1109/ACCESS.2023.3245833","CERN; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10045681","Augmented Reality;facility maintenance;hand tracking;hazardous environment;human–robot interaction;mixed reality;mobile robotic manipulator;mobile network;multi-user;safe operations;point cloud;spatial perception;telerobotics;voice control","Mobile robots;Collision avoidance;Robot sensing systems;Augmented reality;Three-dimensional displays;Collaboration;Human factors;Safety;Telerobotics","","42","","68","CCBY","15 Feb 2023","","","IEEE","IEEE Journals"
"High-Quality Visualization for Geographically Distributed 3-D Teleimmersive Applications","R. Vasudevan; G. Kurillo; E. Lobaton; T. Bernardin; O. Kreylos; R. Bajcsy; K. Nahrstedt","Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA; Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA; Institute for Data Analysis and Visualization, University of California Davis, Davis, CA, USA; Institute for Data Analysis and Visualization, University of California Davis, Davis, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, CA, USA; Department of Computer Science, University of Illinois, Urbana-Champaign, Urbana, IL, USA",IEEE Transactions on Multimedia,"16 May 2011","2011","13","3","573","584","The growing popularity of 3-D movies has led to the rapid development of numerous affordable consumer 3-D displays. In contrast, the development of technology to generate 3-D content has lagged behind considerably. In spite of significant improvements to the quality of imaging devices, the accuracy of the algorithms that generate 3-D data, and the hardware available to render such data, the algorithms available to calibrate, reconstruct, and then visualize such data remain difficult to use, extremely noise sensitive, and unreasonably slow. In this paper, we present a multi-camera system that creates a highly accurate (on the order of a centimeter), 3-D reconstruction of an environment in real-time (under 30 ms) that allows for remote interaction between users. This paper focuses on addressing the aforementioned deficiencies by describing algorithms to calibrate, reconstruct, and render objects in the system. We demonstrate the accuracy and speed of our results on a variety of benchmarks and data collected from our own system.","1941-0077","","10.1109/TMM.2011.2123871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5727958","Human-computer interaction;real-time;stereo reconstruction;virtual reality;visualization;3-D teleimmersion;3-D video","Cameras;Three dimensional displays;Calibration;Image reconstruction;Pixel;Real time systems;Matrix decomposition","","39","1","34","IEEE","10 Mar 2011","","","IEEE","IEEE Journals"
"Quantifying the Effects of Working in VR for One Week","V. Biener; S. Kalamkar; N. Nouri; E. Ofek; M. Pahud; J. J. Dudley; J. Hu; P. O. Kristensson; M. Weerasinghe; K. Č. Pucihar; M. Kljun; S. Streuber; J. Grubert","Coburg University of Applied Sciences and Arts, Germany; Coburg University of Applied Sciences and Arts, Germany; Coburg University of Applied Sciences and Arts, Germany; Microsoft Research, United States; Microsoft Research, United States; University of Cambridge, United Kingdom; University of Cambridge, United Kingdom; University of Cambridge, United Kingdom; University of Primorska, Slovenia; University of Primorska, Slovenia; University of Primorska, Slovenia; Coburg University of Applied Sciences and Arts, Germany; Coburg University of Applied Sciences and Arts, Germany",IEEE Transactions on Visualization and Computer Graphics,"21 Oct 2022","2022","28","11","3810","3820","Virtual Reality (VR) provides new possibilities for modern knowledge work. However, the potential advantages of virtual work environments can only be used if it is feasible to work in them for an extended period of time. Until now, there are limited studies of long-term effects when working in VR. This paper addresses the need for understanding such long-term effects. Specifically, we report on a comparative study $i$, in which participants were working in VR for an entire week—for five days, eight hours each day—as well as in a baseline physical desktop environment. This study aims to quantify the effects of exchanging a desktop-based work environment with a VR-based environment. Hence, during this study, we do not present the participants with the best possible VR system but rather a setup delivering a comparable experience to working in the physical desktop environment. The study reveals that, as expected, VR results in significantly worse ratings across most measures. Among other results, we found concerning levels of simulator sickness, below average usability ratings and two participants dropped out on the first day using VR, due to migraine, nausea and anxiety. Nevertheless, there is some indication that participants gradually overcame negative first impressions and initial discomfort. Overall, this study helps lay the groundwork for subsequent research, by clearly highlighting current shortcomings and identifying opportunities for improving the experience of working in VR.","1941-0506","","10.1109/TVCG.2022.3203103","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9872089","virtual reality;long-term;knowledge work;user study","Task analysis;Keyboards;Visualization;Monitoring;Layout;Virtual environments;Usability","Humans;Computer Graphics;Virtual Reality;User-Computer Interface","38","","61","IEEE","31 Aug 2022","","","IEEE","IEEE Journals"
"Effects of Unaugmented Periphery and Vibrotactile Feedback on Proxemics with Virtual Humans in AR","M. Lee; G. Bruder; T. Höllerer; G. Welch","University of Central Florida; University of Central Florida; University of California, Santa Barbara; University of Central Florida",IEEE Transactions on Visualization and Computer Graphics,"13 Mar 2018","2018","24","4","1525","1534","In this paper, we investigate factors and issues related to human locomotion behavior and proxemics in the presence of a real or virtual human in augmented reality (AR). First, we discuss a unique issue with current-state optical see-through head-mounted displays, namely the mismatch between a small augmented visual field and a large unaugmented periphery, and its potential impact on locomotion behavior in close proximity of virtual content. We discuss a potential simple solution based on restricting the field of view to the central region, and we present the results of a controlled human-subject study. The study results show objective benefits for this approach in producing behaviors that more closely match those that occur when seeing a real human, but also some drawbacks in overall acceptance of the restricted field of view. Second, we discuss the limited multimodal feedback provided by virtual humans in AR, present a potential improvement based on vibrotactile feedback induced via the floor to compensate for the limited augmented visual field, and report results showing that benefits of such vibrations are less visible in objective locomotion behavior than in subjective estimates of co-presence. Third, we investigate and document significant differences in the effects that real and virtual humans have on locomotion behavior in AR with respect to clearance distances, walking speed, and head motions. We discuss potential explanations for these effects related to social expectations, and analyze effects of different types of behaviors including idle standing, jumping, and walking that such real or virtual humans may exhibit in the presence of an observer.","1941-0506","","10.1109/TVCG.2018.2794074","Office of Naval Research(grant numbers:N00014-14-1-0248,N00014-12-1-1003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8302409","Augmented reality;virtual humans;locomotion;proxemics;vibrotactile feedback;field of view","Visualization;Legged locomotion;Collision avoidance;Optical feedback;Task analysis;Vibrations","Adult;Feedback;Female;Head Movements;Humans;Male;Middle Aged;Touch;User-Computer Interface;Vibration;Virtual Reality;Visual Fields;Walking;Young Adult","38","","51","IEEE","23 Feb 2018","","","IEEE","IEEE Journals"
"Intelligent transportation system for accident prevention and detection","D. Selvathi; P. Pavithra; T. Preethi","Department of ECE, Mepco Schlenk Engineering College, Sivakasi, Tamilnadu; Department of ECE, Mepco Schlenk Engineering College, Sivakasi, Tamilnadu; Department of ECE, Mepco Schlenk Engineering College, Sivakasi, Tamilnadu",2017 International Conference on Intelligent Computing and Control Systems (ICICCS),"11 Jan 2018","2017","","","442","446","In a developing nation like India, with advancement in the transportation technology and rise in the total number of vehicles, road accidents increases rapidly. This advancement in technology also increased the traffic hazards. Two wheelers accounts for 25% of total road crash death. Hence the ratio of road accidents that take place frequently increases causing immense loss of life due to poor emergency facilities. Main causes behind these road accidents are lack of training institutes, unskilled drivers, poor road conditions, use of cell phone during driving, consuming alcohol while driving, over loading and poor governmental plans in this regard. Plenty of solutions have been applied to prevent these road accidents, like designing stringent rules and regulations. But most of them failed to prevent accidents. This paper provides an intelligent system for two wheeler accident prevention and detection for human life safety. The prevention part involves, Smart Helmet, which automatically checks whether the person is wearing the helmet and has non-alcoholic breath while driving. The relay does not ON the engine if these two conditions are not satisfied. The microcontroller controls the function of relay and thus the ignition. The system also enables detection of an accident at any place and reports about the accident to predefined numbers with GSM module. The Microcontroller continuously records all the parameters of automobile for prevention and detection of accident.","","978-1-5386-2745-7","10.1109/ICCONS.2017.8250761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8250761","Accident detection;Smart helmet;Alcohol detection;microcontroller;GSM","Road accidents;Relays;Microcontrollers;Switches;Radio frequency;Accelerometers","","36","","12","IEEE","11 Jan 2018","","","IEEE","IEEE Conferences"
"The Metaverse in Engineering Management: Overview, Opportunities, Challenges, and Future Research Agenda","K. -B. Ooi; G. W. -H. Tan; M. Al-Emran; M. A. Al-Sharafi; I. Arpaci; A. A. Zaidan; V. -H. Lee; L. -W. Wong; M. Deveci; M. Iranmanesh","UCSI Graduate Business School, UCSI University, Cheras, Malaysia; UCSI Graduate Business School, UCSI University, Cheras, Malaysia; Faculty of Engineering & IT, The British University in Dubai, Dubai, United Arab Emirates; Institute of Informatics and Computing in Energy, Universiti Tenaga Nasional, Kajang, Malaysia; Faculty of Engineering and Natural Sciences, Bandirma Onyedi Eylul University, Balıkesir, Turkey; SP Jain School of Global Management, Lidcombe, NSW, Australia; Faculty of Business and Finance, Universiti Tunku Abdul Rahman, Kampar, Malaysia; School of Computing and Data Science, Xiamen University Malaysia, Sepang, Malaysia; Department of Industrial Engineering, Turkish Naval Academy, National Defence University, Tuzla, Turkey; School of Business and Law, Edith Cowan University, Joondalup, WA, Australia",IEEE Transactions on Engineering Management,"7 Aug 2024","2024","71","","13882","13889","The metaverse is widely regarded as “the evolution of the Internet,” with the potential to provide opportunities for various stakeholders. In addition to enhancing productivity among employees and creating new business models and revenue streams, it can increase the competitiveness of organizations. However, like any disruptive technology, it poses significant challenges, such as data privacy, security, and ethics. This study acknowledges the growing significance of the metaverse and provides valuable insights into five key areas from the viewpoint of engineering management: supply chain management, logistics management, decision-making, technology management, and knowledge management. Drawing on the contributions of ten experts from various disciplinary backgrounds, each area has an overview, opportunities, challenges, and research agenda. By combining these diverse perspectives through a multidisciplinary approach, this study makes significant contributions to both the academic and practical communities, particularly in the field of engineering management, including the management of technology and innovation. The insights presented can also be utilized to shape policies and drive social and economic progress in the emerging era of the metaverse.","1558-0040","","10.1109/TEM.2023.3307562","UCSI University(grant numbers:T2S-2023/003); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10242236","Decision-making;knowledge management (KM);logistics management (LM);metaverse;supply chain management;technology management","Metaverse;Industries;Digital twins;Supply chains;Monitoring;Companies;Smart manufacturing","","36","","26","IEEE","6 Sep 2023","","","IEEE","IEEE Journals"
"Dynamic Composite Data Physicalization Using Wheeled Micro-Robots","M. Le Goc; C. Perin; S. Follmer; J. -D. Fekete; P. Dragicevic","Stanford University, Stanford, CA, US; University of Victoria, Victoria, BC, CA; Stanford University, Stanford, CA, US; Inria, Le Chesnay, ÃŽle-de-France, FR; Inria, Le Chesnay, ÃŽle-de-France, FR",IEEE Transactions on Visualization and Computer Graphics,"7 Dec 2018","2019","25","1","737","747","This paper introduces dynamic composite physicalizations, a new class of physical visualizations that use collections of self-propelled objects to represent data. Dynamic composite physicalizations can be used both to give physical form to well-known interactive visualization techniques, and to explore new visualizations and interaction paradigms. We first propose a design space characterizing composite physicalizations based on previous work in the fields of Information Visualization and Human Computer Interaction. We illustrate dynamic composite physicalizations in two scenarios demonstrating potential benefits for collaboration and decision making, as well as new opportunities for physical interaction. We then describe our implementation using wheeled micro-robots capable of locating themselves and sensing user input, before discussing limitations and opportunities for future work.","1941-0506","","10.1109/TVCG.2018.2865159","Hasso Plattner Design Thinking Research Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8440836","information visualization;data physicalization;tangible user interfaces","Data visualization;Visualization;Two dimensional displays;Collaboration;Animation;Shape;Human computer interaction","","34","","92","IEEE","20 Aug 2018","","","IEEE","IEEE Journals"
"Integration of Hybrid Networks, AI, Ultra Massive-MIMO, THz Frequency, and FBMC Modulation Toward 6G Requirements: A Review","N. A. Alhaj; M. F. Jamlos; S. A. Manap; S. Abdelsalam; A. A. Bakhit; R. Mamat; M. A. Jamlos; M. S. M. Gismalla; M. Hamdan","Faculty of Electrical and Electronics Engineering Technology, Universiti Malaysia Pahang, Pekan, Malaysia; Faculty of Electrical and Electronics Engineering Technology, Universiti Malaysia Pahang, Pekan, Malaysia; Faculty of Electrical and Electronics Engineering Technology, Universiti Malaysia Pahang, Pekan, Malaysia; Department of Information Technology, University of Khartoum, Khartoum, Sudan; Faculty of Electrical and Electronics Engineering Technology, Universiti Malaysia Pahang, Pekan, Malaysia; Centre for Automotive Engineering Centre, Universiti Malaysia Pahang, Pekan, Malaysia; Faculty of Electronic Engineering Technology, Universiti Malaysia Perlis, Arau, Malaysia; Center for Communication Systems and Sensing, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia; Interdisciplinary Research Center for Intelligent Secure Systems, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia",IEEE Access,"3 Jan 2024","2024","12","","483","513","The fifth-generation (5G) wireless communications have been deployed in many countries with the following features: wireless networks at 20 Gbps as peak data rate, a latency of 1-ms, reliability of 99.999%, maximum mobility of 500 km/h, a bandwidth of 1-GHz, and a capacity of 106 up to Mbps/m2. Nonetheless, the rapid growth of applications, such as extended/virtual reality (XR/VR), online gaming, telemedicine, cloud computing, smart cities, the Internet of Everything (IoE), and others, demand lower latency, higher data rates, ubiquitous coverage, and better reliability. These higher requirements are the main problems that have challenged 5G while concurrently encouraging researchers and practitioners to introduce viable solutions. In this review paper, the sixth-generation (6G) technology could solve the 5G limitations, achieve higher requirements, and support future applications. The integration of multiple access techniques, terahertz (THz), visible light communications (VLC), ultra-massive multiple-input multiple-output ( $\mu {\mathrm{ m}}$ -MIMO), hybrid networks, cell-free massive MIMO, and artificial intelligence (AI)/machine learning (ML) have been proposed for 6G. The main contributions of this paper are a comprehensive review of the 6G vision, KPIs (key performance indicators), and advanced potential technologies proposed with operation principles. Besides, this paper reviewed multiple access and modulation techniques, concentrating on Filter-Bank Multicarrier (FBMC) as a potential technology for 6G. This paper ends by discussing potential applications with challenges and lessons identified from prior studies to pave the path for future research.","2169-3536","","10.1109/ACCESS.2023.3345453","Malaysian Ministry of Higher Education through the MTUN Matching(grant numbers:RDU212802,UIC211503); Universiti Malaysia Pahang Al-Sultan Abdullah(grant numbers:UIC191205); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10368007","6G;multicarrier modulation technique;terahertz communication;ultra-massive multi-input multi-output;visible light communication","6G mobile communication;5G mobile communication;Artificial intelligence;Modulation;Wireless communication;Visible light communication;Surveys","","33","","273","CCBYNCND","21 Dec 2023","","","IEEE","IEEE Journals"
"Toward Trustworthy Metaverse: Advancements and Challenges","J. R. Jim; M. T. Hosain; M. F. Mridha; M. M. Kabir; J. Shin","Advanced Machine Intelligence Research Laboratory (AMIRL), Dhaka, Bangladesh; Department of Computer Science and Engineering, American International University-Bangladesh, Dhaka, Bangladesh; Department of Computer Science and Engineering, American International University-Bangladesh, Dhaka, Bangladesh; Superior Polytechnic School, University of Girona, Girona, Spain; School of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan",IEEE Access,"31 Oct 2023","2023","11","","118318","118347","The Metaverse, a transformative digital realm, holds immense promise for reshaping industries and human interactions while potentially addressing global challenges and democratizing opportunities. However, it also introduces a spectrum of complexities that demand careful navigation. To establish trustworthiness within the Metaverse ecosystem, gaining a deep understanding of its applications, challenges, and existing solutions is imperative. In this comprehensive survey, we first delve into Metaverse applications, drawing insights from existing literature. Subsequently, we explore the diverse challenges the Metaverse presents, analyzing them through the lens of existing research. We then scrutinize the overall trustworthiness of the Metaverse environment and investigate existing solutions to previously identified challenges through a thorough review and analysis of pertinent literature. Lastly, we discussed future research directions aimed at fostering a trustworthy Metaverse environment. This comprehensive review can provide an overview of the Metaverse, its application domains, challenges, existing solutions and research directions for many multidisciplinary studies.","2169-3536","","10.1109/ACCESS.2023.3326258","Competitive Research Fund of The University of Aizu, Japan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10288438","Metaverse;Blockchain;data privacy;edge computing;adaptive artificial intelligence","Metaverse;Surveys;Virtual reality;Security;Ecosystems;Training;Three-dimensional displays;Blockchains;Edge computing;Artificial intelligence","","33","","226","CCBYNCND","20 Oct 2023","","","IEEE","IEEE Journals"
"VirCA NET: A case study for collaboration in shared virtual space","P. Galambos; C. Weidig; P. Baranyi; J. C. Aurich; B. Hamann; O. Kreylos","Computer and Automation Research Institute, Hungarian Academy of Sciences, Budapest, Hungary; Institute for Manufacturing Technology and Production Systems, University of Kaiserslautern, Germany; Computer and Automation Research Institute, Hungarian Academy of Sciences, Budapest, Hungary; Institute for Manufacturing Technology and Production Systems, University of Kaiserslautern, Germany; Institute for Data Analysis and Visualization (IDAV), University of California, Davis, USA; Institute for Data Analysis and Visualization (IDAV), University of California, Davis, USA",2012 IEEE 3rd International Conference on Cognitive Infocommunications (CogInfoCom),"28 Jan 2013","2012","","","273","277","To take up the challenge of global distributed companies, Manufacturing Engineering has to be accomplished in a worldwide collaborative way. Design and development of production processes and their execution are nowadays spread all over the world. To ensure quality standards and to create synergies between spatially distributed entities, distance collaboration tools must be provided to allow cooperation even over large distances. The Virtual Reality (VR) is thereby offering beneficial capabilities to exchange current planning stages, identify problems and solve them cooperatively. This paper introduces a new approach for distance collaboration, which enables users to work in a joint virtual space, nearly as if they were working together in the same place. Therefore two full-immersive CAVE-like systems are interconnected using the VirCA (Virtual Collaboration Arena) platform. The paper describes the requirements of Mechanical Engineers towards distance collaboration tools and the technical challenges solved with the enhanced VirCA framework. This working prototype is one premier application in the field of VR-enhanced spatially distributed collaboration. A typical use case scenario is provided to highlight the interaction and cooperation capabilities offered by VirCA NET.","","978-1-4673-5188-1","10.1109/CogInfoCom.2012.6421993","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6421993","3D Internet;Virtual reality;Augmented reality;Collaboration platform;Factory layout design;Digital factory","Collaboration;Planning;Robots;Production facilities;Manufacturing;Virtual reality;Production systems","","33","","24","IEEE","28 Jan 2013","","","IEEE","IEEE Conferences"
"Multisensory Metaverse-6G: A New Paradigm of Commerce and Education","M. H. ALSAMH; A. Hawbani; S. Kumar; S. Hamood Alsamhi","Department of Accounting, Faculty of Administrative Science, IBB University, Ibb, Yemen; School of Computer Science, Shenyang Aerospace University, Shenyang, China; Department of CSE, IIIT Naya Raipur, Atal Nagar-Nava Raipur, Chhattisgarh, India; Insight Centre for Data Analytics, University of Galway, Galway, Ireland",IEEE Access,"31 May 2024","2024","12","","75657","75677","Multisensory Metaverse applications ignite a revolution across industries, captivating audiences with immersive experiences. With the impending release of 6G technology, the stage is set for an extraordinary advancement toward an even higher level of engagement and immersion. This paper examines how combining multimodal Metaverse apps with 6G technology might change the game, with an emphasis on business and education. We examine how multisensory Metaverse-6G signifies and reshapes a paradigm change in digital connection and immersion in light of the impending advent of 6G networks, distinguished by ultra-high-speed connectivity, low latency, and immense interconnectedness. We investigate how immersive Metaverse experiences improve virtual purchasing, targeted marketing campaigns, and customer engagement from a business perspective. Within the field of education, we investigate how Metaverse technology might transform conventional pedagogical techniques through interactive learning, skill development, and distant collaboration. We aim to build a more connected, immersive, and inclusive digital world by imagining a day when multimodal Metaverse-6G experiences drive innovation across commerce and education. We foresee a future where Metaverse-6G convergence transforms communication and cooperation, and we also highlight future research areas and potential developments. By embracing innovation and tackling challenges, we can fully utilize this convergence to build a more inclusive, immersive, and networked digital future.","2169-3536","","10.1109/ACCESS.2024.3392838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10506898","Multisensory;metaverse;extended reality;6G;immersive communication;holographic communication;metaverse-6G immersive experiences;connectivity;interaction;commerce;education","Metaverse;6G mobile communication;Surveys;Computer architecture;Collaboration;Technological innovation;Biological system modeling;Multisensory integration;Immersive experience;Education;Commerce and trade","","31","","107","CCBYNCND","23 Apr 2024","","","IEEE","IEEE Journals"
"Collaborative Virtual Reality for Laparoscopic Liver Surgery Training","V. Chheang; P. Saalfeld; T. Huber; F. Huettl; W. Kneist; B. Preim; C. Hansen","Faculty of Computer Science Otto-von-Guericke University, Magdeburg, Germany; Faculty of Computer Science Otto-von-Guericke University, Magdeburg, Germany; University Medicine of the Johannes Gutenberg-University, Mainz, Germany; University Medicine of the Johannes Gutenberg-University, Mainz, Germany; University Medicine of the Johannes Gutenberg-University, Mainz, Germany; Faculty of Computer Science Otto-von-Guericke University, Magdeburg, Germany; Faculty of Computer Science Otto-von-Guericke University, Magdeburg, Germany",2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR),"27 Dec 2019","2019","","","1","17","Virtual reality (VR) has been used in many medical training systems for surgical procedures. However, the current systems are limited due to inadequate interactions, restricted possibilities of patient data visualization, and collaboration. We propose a collaborative VR system for laparoscopic liver surgical planning and simulation. Medical image data is used for model visualization and manipulation. Additionally, laparoscopic surgical joysticks are used to provide an opportunity for a camera assistant to cooperate with an experienced surgeon in VR. Continuous clinical feedback led us to optimize the visualization, synchronization, and interactions of the system. Laparoscopic surgeons were positive about the systems' usefulness, usability, and system performance. Additionally, limitations and potential for further development are discussed.","","978-1-7281-5604-0","10.1109/AIVR46125.2019.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8942324","Collaborative virtual reality;liver surgery;surgical training;laparoscopic procedures;human computer interaction;medical visualization","Surgery;Training;Collaboration;Liver;Solid modeling;Laparoscopes;Data models","","30","","40","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"Resource-Constrained EXtended Reality Operated With Digital Twin in Industrial Internet of Things","H. M. Kamdjou; D. Baudry; V. Havard; S. Ouchani","CESI LINEACT, Paris, France; CESI LINEACT, Paris, France; CESI LINEACT, Paris, France; CESI LINEACT, Paris, France",IEEE Open Journal of the Communications Society,"6 Feb 2024","2024","5","","928","950","EXtended Reality (XR) alongside the Digital Twin (DT) in Industrial Internet of Things (IIoT) emerges as a promising next-generation technology. Its diverse applications hod the potential to revolutionize multiple facets of Industry 4.0 and serve as a cornerstone for the rise of Industry 5.0. However, current systems are still not effective in providing a high-quality experience for users due to various factors, one of which is their limited resources for processing and transmitting complex data and big data. To overcome these challenges, this paper presents an in-depth analysis of performance optimization techniques for resource-constrained Augmented Reality (AR) and/or Virtual Reality (VR) environments operating with DT, with a specific focus on Quality of Service (QoS), Quality of Experience (QoE), Edge-Cloud architectures and future research directions. Furthermore, this study delves into the intricate complex trade-off relationships involving optimization factors, including system quality, information quality, and QoE. In addition, it also explores potential solutions based on powerful emerging technological tools, including data compression, blockchain, cloud computing, quantum computing, Artificial Intelligence (AI) / Machine Learning (ML), and cybersecurity in the Cyber-Physical Systems (CPS). The insights provided in this comprehensive survey can inspire and guide researchers and industrial practitioners in optimizing performance for XR with DT applications in resource-constrained Smart Manufacturing System (SMS).","2644-125X","","10.1109/OJCOMS.2024.3356508","CESI LINEACT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10409546","Augmented reality;digital twin;EXtended Reality;IIoT;optimization;resource-constrained;virtual reality;visualization","Surveys;X reality;Industrial Internet of Things;Optimization;Digital twins;Quality of experience;Quality of service","","30","","100","CCBYNCND","19 Jan 2024","","","IEEE","IEEE Journals"
"Bridging multiple user interface dimensions with augmented reality","D. Schmalstieg; A. Fuhrmann; G. Hesina","University of Technology, Vienna, Austria; Research Center for Virtual Reality and Visualization, Vienna, Austria; University of Technology, Vienna, Austria",Proceedings IEEE and ACM International Symposium on Augmented Reality (ISAR 2000),"6 Aug 2002","2000","","","20","29","Studierstube is an experimental user interface system which uses collaborative augmented reality to incorporate true 3D interaction into a productivity environment. This concept is extended to bridge multiple user interface dimensions by including multiple users, multiple host platforms, multiple display types, multiple concurrent applications and a multi-context (i.e. 3D document) interface into a heterogeneous distributed environment. With this architecture, we can explore the user interface design space between pure augmented reality and the popular ubiquitous computing paradigm. We report on our design philosophy, which is centered around the notion of contexts and locales, as well as the underlying software and hardware architecture. Contexts encapsulate a live application together with 3D (visual) and other data, while locales are used to organize geometric reference systems. By separating geometric relationships (locales) from semantic relationships (contexts), we achieve a great amount of flexibility in the configuration of displays. To illustrate our claims, we present several applications, including a cinematographic design tool which showcases many features of our system.","","0-7695-0846-4","10.1109/ISAR.2000.880919","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=880919","","User interfaces;Augmented reality;Computer architecture;Collaboration;Productivity;Bridges;Three dimensional displays;Ubiquitous computing;Hardware;Application software","","29","31","22","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Pre-patterns for designing embodied interactions in handheld augmented reality games","Y. Xu; E. Barba; I. Radu; M. Gandy; R. Shemaka; B. Schrank; B. MacIntyre; T. Tseng","Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Augmented Environments Lab, Georgia Institute of Technology; Savannah College of Art and Design","2011 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities","1 Dec 2011","2011","","","19","28","The game industry and related research communities have shown a surge of interest in reality-based interfaces that create “embodied” game play experiences. Handheld AR (HAR) is a reality-based interface that renders digital objects onto a player's perception of the physical world. HAR creates a hybrid space in which players can leverage their existing physical and social skills to interact with the game system and with each other. Although HAR has received some attention in the world of handheld gaming, there is little research that summarizes and communicates design principles and implications across multiple examples. In this paper, we analyze and generate design lessons from dozens of HAR games, drawn from academic and commercial AR games, and also our years of experience designing and teaching HAR game design. We summarize our experience in this new field into a set of design “pre-patterns” as a means of formalizing significant design lessons derived from these existing practices into repeatable principles and solutions. We contribute to both the game and interaction design communities with pre-patterns that support embodied game play.","2381-8360","978-1-4673-0059-9","10.1109/ISMAR-AMH.2011.6093652","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6093652","Handheld augmented reality interface;design patterns;game design;game interface","Games;Communities;Augmented reality;Physics;Handheld computers;Smart phones;Lenses","","28","","65","IEEE","1 Dec 2011","","","IEEE","IEEE Conferences"
"Exploring the effect of vibrotactile feedback through the floor on social presence in an immersive virtual environment","M. Lee; G. Bruder; G. F. Welch","University of Central Florida, USA; University of Central Florida, USA; University of Central Florida, USA",2017 IEEE Virtual Reality (VR),"6 Apr 2017","2017","","","105","111","We investigate the effect of vibrotactile feedback delivered to one's feet in an immersive virtual environment (IVE). In our study, participants observed a virtual environment where a virtual human (VH) walked toward the participants and paced back and forth within their social space. We compared three conditions as follows: participants in the “Sound” condition heard the footsteps of the VH; participants in the “Vibration” condition experienced the vibration of the footsteps along with the sounds; while participants in the “Mute” condition were not exposed to sound nor vibrotactile feedback. We found that the participants in the “Vibration” condition felt a higher social presence with the VH compared to those who did not feel the vibration. The participants in the “Vibration” condition also exhibited greater avoidance behavior while facing the VH and when the VH invaded their personal space.","2375-5334","978-1-5090-6647-6","10.1109/VR.2017.7892237","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892237","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems — Artificial, Augmented, and Virtual Realities;J.4 [Computer Applications]: Social and Behavioral Sciences — Psychology","Vibrations;Virtual environments;Rubber;Foot;Transducers;Legged locomotion;Back","","28","","43","IEEE","6 Apr 2017","","","IEEE","IEEE Conferences"
"From 5G-Advanced to 6G in 2030: New Services, 3GPP Advances, and Enabling Technologies","R. Giuliano","Department of Engineering Science, Guglielmo Marconi University, Rome, Italy",IEEE Access,"8 May 2024","2024","12","","63238","63270","The telecommunications systems are in continuous evolution. After voice, video, mobile internet, and Internet of Things, what services will be supported in the near future? In the paper, three envisioned services are highlighted, which will be provided in the coming years by new telecommunication systems: immersive communications, everything connected, and high-positioning. The author provides a comprehensive description of their characteristics and investigates the developments that will be implemented in 3GPP Releases 17, Release 18, and Release 19, including technologies that could be integrated for supporting the three new services. In order to evaluate the performance of the new technologies and services, it is important to define appropriate Key Performance Indicators (KPIs). The paper reports and proposes new KPIs for network evaluation to support specific new services such as virtual/mixed reality, smart sensors, and gesture recognition, then facilitating the effective design of the next-generation network and its performance assessment optimally. Requirements of the major application fields that will see widespread adoption in the next 3–8 years due to these developments are also investigated. Finally, the paper further outlines the most promising enabling technologies, supporting the three bearer services.","2169-3536","","10.1109/ACCESS.2024.3396361","Guglielmo Marconi University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10517597","5G-advanced;6G;immersive communications;everything connected;high-positioning;3GPP enhancements;Release 18;Release 19","Telecommunications;6G mobile communication;3GPP;5G mobile communication;X reality;Smart phones;Next generation networking","","26","","174","CCBYNCND","2 May 2024","","","IEEE","IEEE Journals"
"Literature Review on Co-Located Collaboration Modeling Using Multimodal Learning Analytics—Can We Go the Whole Nine Yards?","S. Praharaj; M. Scheffel; H. Drachsler; M. Specht","Open University of the Netherlands, AT Heerlen, Netherlands; Ruhr-Universität Bochum, Bochum, Germany; DIPF Leibniz Institute for Research and Information in Education, Frankfurt am Main, Germany; Delft University of Technology, Delft, CD, Netherlands",IEEE Transactions on Learning Technologies,"3 Sep 2021","2021","14","3","367","385","Collaboration is one of the important 21st-century skills. It can take place in remote or co-located settings. Co-located collaboration (CC) is a very complex process that involves subtle human interactions that can be described with indicators like eye gaze, speaking time, pitch, and social skills from different modalities. With the advent of sensors, multimodal learning analytics has gained momentum to detect CC quality. Indicators (or low-level events) can be used to detect CC quality with the help of measurable markers (i.e., indexes composed of one or more indicators) which give the high-level collaboration process definition. However, this understanding is incomplete without considering the scenarios (such as problem solving or meetings) of CC. The scenario of CC affects the set of indicators considered: For instance, in collaborative programming, grabbing the mouse from the partner is an indicator of collaboration; whereas in collaborative meetings, eye gaze, and audio level are indicators of collaboration. This can be a result of the differing goals and fundamental parameters (such as group behavior, interaction, or composition) in each scenario. In this article, we present our work on profiles of indicators on the basis of a scenario-driven prioritization, the parameters in different CC scenarios are mapped onto the indicators and the available indexes. This defines the conceptual model to support the design of a CC quality detection and prediction system.","1939-1382","","10.1109/TLT.2021.3097766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9490371","Co-located collaboration (CC);CC analytics;collaboration analytics;collaborative learning tools;multimodal interactions;multimodal learning analytics (MMLA)","Collaboration;Task analysis;Indexes;Bibliographies;Microphones;Systematics;Programming profession","","25","","119","CCBYNCND","19 Jul 2021","","","IEEE","IEEE Journals"
"An Overview of Enhancing Distance Learning Through Emerging Augmented and Virtual Reality Technologies","E. Childs; F. Mohammad; L. Stevens; H. Burbelo; A. Awoke; N. Rewkowski; D. Manocha","University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA; University of Maryland, College Park, MD, USA",IEEE Transactions on Visualization and Computer Graphics,"1 Jul 2024","2024","30","8","4480","4496","Although distance learning presents a number of interesting educational advantages as compared to in-person instruction, it is not without its downsides. We first assess the educational challenges presented by distance learning as a whole and identify 4 main challenges that distance learning currently presents as compared to in-person instruction: the lack of social interaction, reduced student engagement and focus, reduced comprehension and information retention, and the lack of flexible and customizable instructor resources. After assessing each of these challenges in-depth, we examine how AR/VR technologies might serve to address each challenge along with their current shortcomings, and finally outline the further research that is required to fully understand the potential of AR/VR technologies as they apply to distance learning.","1941-0506","","10.1109/TVCG.2023.3264577","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10098484","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Mixed / augmented reality;Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Virtual reality","Computer aided instruction;Education;Virtual reality;Headphones;Visualization;Pandemics;Sensors","","25","","94","IEEE","10 Apr 2023","","","IEEE","IEEE Journals"
"Multiparty Holomeetings: Toward a New Era of Low-Cost Volumetric Holographic Meetings in Virtual Reality","S. F. Langa; M. Montagud; G. Cernigliaro; D. R. Rivera","Fundació i2CAT, Barcelona, Spain; Fundació i2CAT, Barcelona, Spain; Fundació i2CAT, Barcelona, Spain; Department of Network Engineering, Universitat Politècnica de Catalunya (UPC), Barcelona, Spain",IEEE Access,"10 Aug 2022","2022","10","","81856","81876","Fueled by advances in multi-party communications, increasingly mature immersive technologies being adopted, and the COVID-19 pandemic, a new wave of social virtual reality (VR) platforms have emerged to support socialization, interaction, and collaboration among multiple remote users who are integrated into shared virtual environments. Social VR aims to increase levels of (co-)presence and interaction quality by overcoming the limitations of 2D windowed representations in traditional multi-party video conferencing tools, although most existing solutions rely on 3D avatars to represent users. This article presents a social VR platform that supports real-time volumetric holographic representations of users that are based on point clouds captured by off-the-shelf RGB-D sensors, and it analyzes the platform’s potential for conducting interactive holomeeting scenarios (i.e., holoconferencing sessions for remote gathering and formal discussion). This work evaluates such a platform’s performance and readiness for conducting holomeetings with up to four users, and it provides insights into aspects of the user experience when using single-camera and low-cost capture systems in scenarios with both frontal and side viewpoints. Overall, the obtained results confirm the platform’s maturity and the potential of holographic communications for conducting interactive multi-party meetings, even when using low-cost systems and single-camera capture systems in scenarios where users are sitting or have a limited translational movement along the X, Y, and Z axes within the 3D virtual environment (commonly known as 3 Degrees of Freedom plus, 3DoF+).","2169-3536","","10.1109/ACCESS.2022.3196285","European Union’s Horizon 2020 (EU H2020) Program through VR-Together Project(grant numbers:762111); Agència per a la Competitivitat de l’Empresa, Generalitat de Catalunya (ACCIÓ) through the Visió per computador per Video Immersiu Multi-plataforma (ViVIM) Project(grant numbers:COMRDI18-1-0008); Cisco Research and the Silicon Valley Community Foundation under the Grant Extended Reality Multipoint Control Unit(grant numbers:1779376); MCIN/AEI/10.13039/501100011033(grant numbers:RYC2020-030679-I); “the European Social Fund (ESF) Investing in Your Future.”; MCIN/AEI/10.13039/501100011033(grant numbers:PID2019-108713RB-C51); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9848469","Holograms;holographic communications;presence;social VR;togetherness;video conferencing;virtual reality;volumetric media","Videoconferences;Media;Collaboration;Avatars;Quality of experience;Virtual environments;Three-dimensional displays","","24","","54","CCBY","3 Aug 2022","","","IEEE","IEEE Journals"
"Collaborative augmented reality: exploring dynamical systems","A. Fuhrmann; H. Loffelmann; D. Schmalstieg","Institute of Computer Graphics, University of Technology, Vienna, Vienna, Austria; Institute of Computer Graphics, University of Technology, Vienna, Vienna, Austria; Institute of Computer Graphics, University of Technology, Vienna, Vienna, Austria",Proceedings. Visualization '97 (Cat. No. 97CB36155),"6 Aug 2002","1997","","","459","462","We present collaborative scientific visualization in STUDIERSTUBE. STUDIERSTUBE is an augmented reality system that has several advantages over conventional desktop and other virtual reality environments, including true stereoscopy, 3D-interaction, individual viewpoints and customized views for multiple users, unhindered natural collaboration and low cost. We demonstrate the application of this concept for the interaction of multiple users and illustrate it with several visualizations of dynamical systems in DynSys3D, a visualization system running on top of AVS.","","0-8186-8262-0","10.1109/VISUAL.1997.663921","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=663921","","Collaboration;Augmented reality;Data visualization;Virtual reality;Collaborative work;Computer graphics;Computer displays;Three dimensional displays;Virtual environment;Head","","24","","17","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Effects of Sharing Real-Time Multi-Sensory Heart Rate Feedback in Different Immersive Collaborative Virtual Environments","A. Dey; H. Chen; C. Zhuang; M. Billinghurst; R. W. Lindeman","University of South Australia, Australia; University of Canterbury, New Zealand; Northwestern Polytechnical University, Xi'an, Shaanxi, CN; University of South Australia, Australia; University of Canterbury, New Zealand",2018 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"17 Jan 2019","2018","","","165","173","Collaboration is an important application area for virtual reality (VR). However, unlike in the real world, collaboration in VR misses important empathetic cues that can make collaborators aware of each other’s emotional states. Providing physiological feedback, such as heart rate or respiration rate, to users in VR has been shown to create a positive impact in single user environments. In this paper, through a rigorous mixed-factorial user experiment, we evaluated how providing heart rate feedback to collaborators influences their collaboration in three different environments requiring different kinds of collaboration. We have found that when provided with real-time heart rate feedback participants felt the presence of the collaborator more and felt that they understood their collaborator’s emotional state more. Heart rate feedback also made participants feel more dominant when performing the task. We discuss the implication of this research for collaborative VR environments, provide design guidelines, and directions for future research.","1554-7868","978-1-5386-7459-8","10.1109/ISMAR.2018.00052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613762","","Heart rate;Collaboration;Real-time systems;Physiology;Avatars;Task analysis;Virtual environments","","22","","31","IEEE","17 Jan 2019","","","IEEE","IEEE Conferences"
"Forging the Industrial Metaverse for Industry 5.0: Where Extended Reality, IIoT, Opportunistic Edge Computing, and Digital Twins Meet","T. M. Fernández-Caramés; P. Fraga-Lamas","Department of Computer Engineering, Faculty of Computer Science, A Coruña, Spain; Department of Computer Engineering, Faculty of Computer Science, A Coruña, Spain",IEEE Access,"19 Jul 2024","2024","12","","95778","95819","The Industrial Metaverse can benefit from the concepts fostered by Industry 5.0, since it implies making use of dynamic and up-to-date content, as well as fast human-to-machine interactions. To enable such enhancements, this article proposes the concept of Meta-Operator, which is essentially an industrial worker that follows the principles of Industry 5.0 and interacts with Industrial Metaverse applications and with his/her surroundings through advanced Extended Reality (XR) devices. In order to build the foundations of future Meta-Operators, this article provides a thorough description of the main technologies that support such a concept: the main components of the Industrial Metaverse, the latest XR technologies and accessories and the use of Opportunistic Edge Computing (OEC) communications (to detect and interact with the surrounding Internet of Things (IoT) and Industrial IoT (IIoT) devices). Moreover, this paper analyzes how to create the next generation of Industrial Metaverse applications based on the Industry 5.0 concepts, including the most relevant standardization initiatives, the integration of AR/MR devices with IoT/IIoT solutions, the development of advanced communications and software architectures and the creation of shared experiences and opportunistic collaborative protocols. Finally, this article provides an extensive list of potential Industry 5.0 applications for the Industrial Metaverse and analyzes thoroughly the main challenges and research lines. Thus, this article provides a holistic view and useful guidelines for the future developers and researchers that will create the next generation of applications for the Industrial Metaverse.","2169-3536","","10.1109/ACCESS.2024.3422109","PID2020-118857RA-100 (ORBALLO, Opportunistic Edge Computing Based on Mobile and Low-Power IoT Devices); MCIN/AEI/10.13039/501100011033; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10596039","Industrial metaverse;Industry 5.0;Meta-Operator;Augmented Reality;Mixed Reality;Opportunistic Edge Computing;Digital Twins;Metaverse;IIoT","Metaverse;Fifth Industrial Revolution;Fourth Industrial Revolution;Industries;Industrial Internet of Things;Extended reality;Object recognition;Mixed reality;Edge computing","","22","","276","CCBY","11 Jul 2024","","","IEEE","IEEE Journals"
"A Bibliometric Analysis of Technology in Digital Health: Exploring Health Metaverse and Visualizing Emerging Healthcare Management Trends","H. -S. Nguyen; M. Voznak","Becamex Business School, Eastern International University, Thu Dau Mot, Vietnam; VSB—Technical University of Ostrava, Ostrava, Czech Republic",IEEE Access,"16 Feb 2024","2024","12","","23887","23913","The digital economy has engendered Health Metaverse, an innovative technology with vast potential to transform healthcare through immersive experiences. The Health Metaverse serves as a convergence point for a multitude of technologies, including artificial intelligence (AI), virtual reality in heath, augmented reality in health, internet-connected medical devices, quantum computing, and more. This convergence opens up possibilities, for advancing quality healthcare. Therefore, reviewing recent influential literature is critical to understand current methods and envision future improvements. This study utilizes a hybrid bibliometric-structured methodology combining descriptive and bibliometric network analysis. To gather information we conducted searches on the Web of Science database and reviewed references. Our inclusion criteria focused on articles and reviews published between January 2012 and June 2023. We used keyword groups for our searches. Then performed bibliometric analysis followed by content analysis. Papers were reviewed, analyzed and categorized into focuses on multimodal medical information standards, medical/social data fusion, telemedicine, online health management, and medical AI. This bibliometric analysis of 34 thousand publications over 10 years proposes medical and health informatics in the Metaverse. Five future research direction clusters were identified. It delineates intelligent solutions bridging healthcare barriers. In conclusion, this review examines the Metaverse, in healthcare explores cutting edge technologies, applications, projects and highlights areas where adaptation may be needed. It identifies adaptation issues and suggests solutions warranting further research.","2169-3536","","10.1109/ACCESS.2024.3363165","European Union within the REFRESH Project–Research Excellence For Region Sustainability and High-Tech Industries of the European Just Transition Fund(grant numbers:CZ.10.03.01/00/22 003/0000048); Ministry of Education, Youth and Sports of the Czech Republic (MEYS CZ) through the Project SGS conducted by VSB—Technical University of Ostrava(grant numbers:SP 7/2023); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10423633","Health metaverse;healthcare technology;health informatics;quality of care;digital health;data analysis;bibliometric analysis","Medical services;Metaverse;Bibliometrics;Artificial intelligence;Electronic healthcare;Visualization;Medical devices;Bioinformatics;Quality assessment;Medical services","","21","","143","CCBY","6 Feb 2024","","","IEEE","IEEE Journals"
"Magnoramas: Magnifying Dioramas for Precise Annotations in Asymmetric 3D Teleconsultation","K. Yu; A. Winkler; F. Pankratz; M. Lazarovici; D. Wilhelm; U. Eck; D. Roth; N. Navab","Research Group MITI, Hospital Recht der Isar TUM, Munich, Germany; Chair of Computer Aided Medical Procedures, TUM, Munich, Germany; Institute for Emergency Medicine, LMU, Munich, Germany; Institute for Emergency Medicine, LMU, Munich, Germany; Research Group MITI, Hospital Recht der Isar TUM, Munich, Germany; Chair of Computer Aided Medical Procedures, TUM, Munich, Germany; Chair of Computer Aided Medical Procedures, TUM, Munich, Germany; Chair of Computer Aided Medical Procedures, TUM, Munich, Germany",2021 IEEE Virtual Reality and 3D User Interfaces (VR),"10 May 2021","2021","","","392","401","When users create hand-drawn annotations in Virtual Reality they often reach their physical limits in terms of precision, especially if the region to be annotated is small. One intuitive solution employs magnification beyond natural scale. However, scaling the whole environment results in wrong assumptions about the coherence between physical and virtual space. In this paper, we introduce Mag-noramas, a novel interaction method for selecting and extracting a region of interest that the user can subsequently scale and transform inside the virtual space. Our technique enhances the user's capabilities to perform supernaturally precise virtual annotations on virtual objects. We explored our technique in a user study within asimplified clinical scenario of a teleconsultation-supported craniectomy procedure that requires accurate annotations on a human head. Teleconsultation was performed asymmetrically between a remote expert in Virtual Reality that collaborated with a local user through Augmented Reality. The remote expert operates inside a reconstructed environment, captured from RGB-D sensors at the local site, and is embodied by an avatar to establish co-presence. The results show that Magnoramas significantly improve the precision of annotations while preserving usability and perceived presence measures compared to the baseline method. By hiding the 3D reconstruction while keeping the Magnorama, users can intentionally choose to lower their perceived social presence and focus on their tasks.","2642-5254","978-1-6654-1838-6","10.1109/VR50410.2021.00062","German Federal Ministry of Education and Research (BMBF)(grant numbers:16SV8092); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417638","Interaction Techniques;Medical Information System;Virtual Reality","Manifolds;Three-dimensional displays;Telepresence;Annotations;Transforms;User interfaces;Real-time systems","","21","","67","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"Interpersonal Affordances and Social Dynamics in Collaborative Immersive Virtual Environments: Passing Together Through Apertures","L. E. Buck; J. J. Rieser; G. Narasimham; B. Bodenheimer",Vanderbilt University; Vanderbilt University; Vanderbilt University; Vanderbilt University,IEEE Transactions on Visualization and Computer Graphics,"27 Mar 2019","2019","25","5","2123","2133","An essential question in understanding how to develop and build collaborative immersive virtual environments (IVEs) is recognizing how people perform actions together. Many actions in the real world require that people act without prior planning, and these actions are executed quite successfully. In this paper, we study the common action of two people passing through an aperture together in both the real world (Experiment 1) and in a distributed, collaborative IVE (Experiment 2). The aperture's width is varied from too narrow to be passable to so wide as to be easily passable by both participants together simultaneously. We do this in the real world for all possible gender-based pairings. In virtual reality, however, there is potential for the gender of the participant and the gender of the self-avatar to be different. We also investigate the joint action for all possible gender-based pairings in the distributed IVE. Results indicated that, in the real world, social dynamics between gendered pairings emerged; male-male pairings refused to concede to one another until absolutely necessary while other pairings did not. Male-female pairings were most likely to provide ample space to one another during passage. These behaviors seemed not to appear in the IVE, and avatar gender across all pairings generated no significant behavioral differences. In addition, participants tended to require wider gaps to allow for passage in the IVE. These findings establish base knowledge of social dynamics and affordance behaviors within multi-user IVEs.","1941-0506","","10.1109/TVCG.2019.2899232","National Science Foundation(grant numbers:1526448); Office of Naval Research(grant numbers:N00014-18-1-2964); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643340","Virtual reality;perception;collaborative virtual reality;proxemics;affordances;avatars","Task analysis;Avatars;Apertures;Collaboration;Virtual environments;Legged locomotion","Adult;Computer Graphics;Cooperative Behavior;Female;Humans;Image Processing, Computer-Assisted;Interpersonal Relations;Male;User-Computer Interface;Virtual Reality","20","","84","IEEE","17 Feb 2019","","","IEEE","IEEE Journals"
"Toward Hyper-Realistic and Interactive Social VR Experiences in Live TV Scenarios","S. F. Langa; M. M. Climent; G. Cernigliaro; D. Rincón Rivera","I2CAT, Barcelona, Spain; I2CAT, Barcelona, Spain; I2CAT, Barcelona, Spain; Department of Network Engineering, Universitat Politècnica de Catalunya, Barcelona, Spain",IEEE Transactions on Broadcasting,"3 Mar 2022","2022","68","1","13","32","Social Virtual Reality (VR) allows multiple distributed users getting together in shared virtual environments to socially interact and collaborate. This article explores the applicability and potential of Social VR in the broadcast sector, focusing on a live TV show use case, by providing three main contributions: 1) a novel and lightweight social VR platform; 2) a professional piece of VR content to recreate an interactive live TV show; and 3) an analysis of the performance and user experience. The Social VR platform includes different innovative and outstanding features compared to state-of-the-art solutions. It allows a real-time integration of remote users in shared virtual environments, using realistic volumetric representations and affordable capturing systems, thus not relying on the use of synthetic avatars. It supports a seamless and rich integration of heterogeneous media formats, including 3D scenarios, dynamic volumetric representation of users and (live/stored) stereoscopic 2D and 180°/360° videos. In addition, it enables low-latency interaction between volumetric users and a video-based presenter (Chroma keying) and a dynamic control of the media playout to adapt to the session’s evolution. The article also describes the production process of an immersive an interactive TV show to demonstrate the platform’s capabilities and its potential benefits. On the one hand, the results from objective tests show the satisfactory performance of the platform. On the other hand, the promising results from user tests support the potential impact of the presented platform, opening up new opportunities in the broadcast sector.","1557-9611","","10.1109/TBC.2021.3123499","European Union’s Horizon 2020 Program through VR-Together Project(grant numbers:762111); ACCIÓ through ViVIM Project(grant numbers:COMRDI18-1-0008); Spanish Ministry of Science, Innovation and Universities with a Juan de la Cierva–Incorporación(grant numbers:Ref. IJCI-2017-34611); Agencia Estatal de Investigación of Spain of Ministerio de Ciencia e Innovación of Spain(grant numbers:PID2019-108713RB-C51 MCIN/AEI/10.13039/501100011033); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9609633","Broadband;Broadcast;Immersive Media;Immersive TV;Interactive Media;Social TV;Social VR;Virtual Reality;Volumetric Media;VR TV","TV;Videos;Media;Three-dimensional displays;Social networking (online);Virtual environments;Sports","","20","","57","IEEE","9 Nov 2021","","","IEEE","IEEE Journals"
"Perspective Matters: Design Implications for Motion Guidance in Mixed Reality","X. Yu; K. Angerbauer; P. Mohr; D. Kalkofen; M. Sedlmair",University of Stuttgart; University of Stuttgart; Graz University of Technology; Graz University of Technology; University of Stuttgart,2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"14 Dec 2020","2020","","","577","587","We investigate how Mixed Reality (MR) can be used to guide human body motions, such as in physiotherapy, dancing, or workout applications. While first MR prototypes have shown promising results, many dimensions of the design space behind such applications remain largely unexplored. To better understand this design space, we approach the topic from different angles by contributing three user studies. In particular, we take a closer look at the influence of the perspective, the characteristics of motions, and visual guidance on different user performance measures. Our results indicate that a first-person perspective performs best for all visible motions, whereas the type of visual instruction plays a minor role. From our results we compile a set of considerations that can guide future work on the design of instructions, evaluations, and the technical setup of MR motion guidance systems.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00085","Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284729","Information Interfaces and Presentation—User Interfaces—Evaluation/Methodology;Computer Graphics—ThreeDimensional Graphics and Realism—Virtual Reality","Visualization;Atmospheric measurements;Prototypes;Particle measurements;Timing;Task analysis;Sports","","19","","38","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"Constructing a Gazebo: Supporting Teamwork in a Tightly Coupled, Distributed Task in Virtual Reality","D. Roberts; R. Wolff; O. Otto; A. Steed","Department of Computer Science The University of Reading, United Kingdom, d.j.roberts@rdg.ac.uk; Department of Computer Science The University of Reading, United Kingdom, R.Wolff@rdg.ac.uk; Department of Computer Science The University of Reading, United Kingdom, O.Otto@rdg.ac.uk; Department of Computer Science University College London, United Kingdom, A.Steed@cs.ucl.ac.uk",Presence,"19 May 2014","2003","12","6","644","657","Many tasks require teamwork. Team members may work concurrently, but there must be some occasions of coming together. Collaborative virtual environments (CVEs) allow distributed teams to come together across distance to share a task. Studies of CVE systems have tended to focus on the sense of presence or copresence with other people. They have avoided studying close interaction between us-ers, such as the shared manipulation of objects, because CVEs suffer from inherent network delays and often have cumbersome user interfaces. Little is known about the ef-fectiveness of collaboration in tasks requiring various forms of object sharing and, in particular, the concurrent manipu-lation of objects. This paper investigates the effectiveness of supporting teamwork among a geographically distributed group in a task that requires the shared manipulation of objects. To complete the task, users must share objects through con-current manipulation of both the same and distinct at-tributes. The effectiveness of teamwork is measured in terms of time taken to achieve each step, as well as the impression of users. The effect of interface is examined by comparing various combinations of walk-in cubic immersive projection technology (IPT) displays and desktop devices.","1054-7460","","10.1162/105474603322955932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6790594","","","","18","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Predict-and-Drive: Avatar Motion Adaption in Room-Scale Augmented Reality Telepresence with Heterogeneous Spaces","X. Wang; H. Ye; C. Sandor; W. Zhang; H. Fu","MOEKLINNS Lab, School of Computer Science and Technology, Xi'an Jiaotong University, China; School of Creative Media, City University of Hong Kong, China; Laboratoire Interdisciplinaire des Sciences du Numérique (LISN), Université Paris-Saclay / CNRS, France; MOEKLINNS Lab, School of Computer Science and Technology, Xi'an Jiaotong University, China; School of Creative Media, City University of Hong Kong, China",IEEE Transactions on Visualization and Computer Graphics,"21 Oct 2022","2022","28","11","3705","3714","Avatar-mediated symmetric Augmented Reality (AR) telepresence has emerged with the ability to empower users located in different remote spaces to interact with each other in 3D through avatars. However, different spaces have heterogeneous structures and features, which bring difficulties in synchronizing avatar motions with real user motions and adapting avatar motions to local scenes. To overcome these issues, existing methods generate mutual movable spaces or retarget the placement of avatars. However, these methods limit the telepresence experience in a small sub-area space, fix the positions of users and avatars, or adjust the beginning/ending positions of avatars without presenting smooth transitions. Moreover, the delay between the avatar retargeting and users' real transitions can break the semantic synchronization between users' verbal conversation and perceived avatar motion. In this paper, we first examine the impact of the aforementioned transition delay and explore the preferred transition style with the existence of such delay through user studies. With the results showing a significant negative effect of avatar transition delay and providing the design choice of the transition style, we propose a Predict-and-Drive controller to diminish the delay and present the smooth transition of the telepresence avatar. We also introduce a grouping component as an upgrade to immediately calculate a coarse virtual target once the user initiates a transition, which could further eliminate the avatar transition delay. Once having the coarse virtual target or an exactly predicted target, we find the corresponding target for the avatar according to the pre-constructed mapping of objects of interest between two spaces. The avatar control component maintains an artificial potential field of the space and drives the avatar towards the target while respecting the obstacles in the physical environment. We further conduct ablation studies to evaluate the effectiveness of our proposed components.","1941-0506","","10.1109/TVCG.2022.3203109","National Key Research and Development Program of China(grant numbers:2020AAA0108800); City University of Hong Kong(grant numbers:7005729,9667234,7005590,9229094); National Natural Science Foundation of China(grant numbers:62172326,62137002,61721002); Innovative Research Group; Innovation Research Team of Ministry of Education(grant numbers:IRT 17R86); Project of China Knowledge Centre for Engineering Science and Technology; RGC Postdoc Fellowship Scheme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9873991","AR Telepresence;Avatar Motion Adaption;Heterogeneous Spaces;Redirected Walking","Avatars;Telepresence;Delays;Aerospace electronics;Semantics;Real-time systems;Oral communication","User-Computer Interface;Computer Graphics;Augmented Reality;Communication","17","","41","IEEE","1 Sep 2022","","","IEEE","IEEE Journals"
"Impact of Full-Body Avatars in Immersive Multiplayer Virtual Reality Training for Police Forces","P. Caserman; P. Schmidt; T. Göbel; J. Zinnäcker; A. Kecke; S. Göbel","Department of Electrical Engineering and Information Technology, Technical University of Darmstadt, Darmstadt, Germany; Department of Electrical Engineering and Information Technology, Technical University of Darmstadt, Darmstadt, Germany; Hessian University for Police and Administration, Mühlheim, Germany; Hessian Police Headquarters for Technology, Wiesbaden, Germany; Hessian University for Police and Administration, Mühlheim, Germany; Department of Electrical Engineering and Information Technology, Technical University of Darmstadt, Darmstadt, Germany",IEEE Transactions on Games,"15 Dec 2022","2022","14","4","706","714","Recent advancements in virtual reality technology contributed to the development of immersive games and simulations of any kind. Simulations are a valuable tool for police forces to practice specific skills within threatening, dangerous, and stressful situations without dangerous real-world implications. Effective virtual simulations need to be realistic in terms of actions and also need to elicit emotion, engagement, and stress. To this end, we developed a multiplayer virtual reality training simulation for police forces to explore the effect of full-body avatars, especially regarding the stress level and response to threats. We analyzed the statistical significance and effect sizes of the data from 32 police officers under two conditions: either they could see an assailant with a full-body avatar or only a head and hands. The results reveal an increase in stress level and threat during the immersion with the full-body avatar. This was shown objectively by analyzing the heart rate variability and subjectively by examining a questionnaire in response to a threat to the assailant’s virtual body. These findings indicate that an assailant with a full-body avatar is beneficial during training for police forces, as it increases the feeling of a threat and contributes to a more realistic training experience.","2475-1510","","10.1109/TG.2022.3148791","SimuLab(grant numbers:2019_FO-09); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9706353","Full-body motion reconstruction;immersive virtual reality;multiplayer training simulation;serious games;stress;threat response","Training;Law enforcement;Avatars;Stress;Solid modeling;Heart rate variability;Kinematics","","17","","48","IEEE","7 Feb 2022","","","IEEE","IEEE Journals"
"Tilted tabletops: In between horizontal and vertical workspaces","C. Muller-Tomfelde; A. Wessels; C. Schremmer","Information and Communication Technologies Centre, CSIRO, NSW, Australia; Information and Communication Technologies Centre, CSIRO, NSW, Australia; Information and Communication Technologies Centre, CSIRO, NSW, Australia",2008 3rd IEEE International Workshop on Horizontal Interactive Human Computer Systems,"28 Oct 2008","2008","","","49","56","In this paper we examine tilted tabletops as workspaces for computer-supported group collaboration. The configuration of a tilted tabletop is considered to be in between a fully horizontal tabletop and a vertical whiteboard. We describe related work, and provide an overview of the advantages and disadvantages of such a configuration. Furthermore, we present the results of a user study about tilted tabletops. We captured the tilt angle preference of 78 participants using mock-ups of the basic workspace elements. The study was conducted after they experienced a combined distributed and co-located collaboration. The results of the study reveal that the majority of the participants prefer a tilted workspace rather than a fully horizontal one for interaction. We discuss the implications of these results for the design of tabletop-based collaborative environments.","","978-1-4244-2897-7","10.1109/TABLETOP.2008.4660183","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4660183","","Collaboration;Computers;Layout;Prototypes;Humans;Conferences;Ergonomics","","16","","27","IEEE","28 Oct 2008","","","IEEE","IEEE Conferences"
"MediSim: a prototype VR system for training medical first responders","S. Stansfield; D. Shawver; A. Sobel","Sandia National Laboratories, Albuquerque, NM, USA; Sandia National Laboratories, Albuquerque, NM, USA; Sandia National Laboratories, Albuquerque, NM, USA",Proceedings. IEEE 1998 Virtual Reality Annual International Symposium (Cat. No.98CB36180),"6 Aug 2002","1998","","","198","205","This paper presents a prototype virtual reality (VR) system for training medical first responders. The initial application is to battlefield medicine and focuses on the training of medical corpsmen and other front-line personnel who might be called upon to provide emergency triage on the battlefield. The system is built upon Sandia's multi-user, distributed VR platform and provides an interactive, immersive simulation capability. The user is represented by an Avatar and is able to manipulate his virtual instruments and carry out medical procedures. A dynamic casualty simulation provides realistic cues to the patient's condition (e.g. changing blood pressure and pulse) and responds to the actions of the trainee (e.g. a change in the color of a patient's skin may result from a check of the capillary refill rate). The current casualty simulation is of an injury resulting in a tension pneumothorax. This casualty model was developed by the University of Pennsylvania and integrated into the Sandia MediSim system.","","0-8186-8362-7","10.1109/VRAIS.1998.658490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=658490","","Prototypes;Virtual reality;Medical simulation;Virtual prototyping;Personnel;Avatars;Instruments;Blood pressure;Skin;Injuries","","16","1","14","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"A review of applications of computer games in education and training","F. Arango; E. -S. Aziz; S. K. Esche; C. Chassapis","Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA",2008 38th Annual Frontiers in Education Conference,"22 Dec 2008","2008","","","T4A-1","T4A-6","Scientists, engineers and educators are increasingly using environments enabled by advanced cyberinfrastructure tools for their research, formal and informal education and training, career development and life-long learning. For instance, academic institutions as well as private training and education companies have recently started to explore the potential of commercially available multi-player computer game engines for the development of virtual environments for instructional purposes. Most of these developments are still in their early stages and are focused mainly on investigating the suitability of interactive games for remote user interaction, content distribution and collaborative activities. Some of the ongoing projects have additional research objectives, such as the analysis of patterns of human behavior and the study of the collaboration between users and their interaction with virtual environments. A few other developments are aimed at utilizing computer game technologies as a platform for personnel training and educational laboratory simulations. This paper provides a review of the current state of computer game applications, with a special focus on education and training implementations.","2377-634X","978-1-4244-1969-2","10.1109/FIE.2008.4720514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4720514","Scheduling;Online laboratory;Remote experiment;Sharing;Virtual experiment","Application software;Computer applications;Computer science education;Virtual environment;Collaboration;Career development;Computer aided instruction;Engines;Pattern analysis;Humans","","16","","59","IEEE","22 Dec 2008","","","IEEE","IEEE Conferences"
"Collaborative Virtual Reality in Higher Education: Students' Perceptions on Presence, Challenges, Affordances, and Potential","T. H. Laine; W. Lee","Department of Digital Media, Ajou University, Suwon, Republic of Korea; Department of Digital Media, Ajou University, Suwon, Republic of Korea",IEEE Transactions on Learning Technologies,"29 Dec 2023","2024","17","","280","293","The metaverse is a network of interoperable and persistent 3-D virtual worlds where users can coexist and interact through mechanisms, such as gamification, nonfungible tokens, and cryptocurrencies. Although the metaverse is a theoretical construct today, many collaborative virtual reality (CVR) applications have emerged as potential components of the metaverse. The demand for distance learning in higher education grew rapidly with COVID-19, but it has many challenges such as low motivation, low interest, and lack of suitable environment. We investigated the suitability of CVR applications for higher education by analyzing 9 existing CVR applications and then conducting a mixed-method user study on the Spatial CVR application with 41 university students (24 females, 17 males, mean age: 23.5). The results revealed 14 challenges, 13 affordances, and 20 ideas for using CVR in higher education. Moreover, lack of instructions, cybersickness, discomfort, limited embodiment, and limited sensory stimulation were among the identified issues that may inhibit the sense of presence in Spatial. Based on the findings, we proposed 13 guidelines to facilitate providing CVR learning in higher education and concluded that CVR has some use cases in higher education to complement conventional methods. These results can be useful for researchers, developers, and educators who seek to be at the forefront of adopting CVR as a part of the metaverse to come.","1939-1382","","10.1109/TLT.2023.3319628","MSIT (Ministry of Science and ICT), Korea; Information Technology Research Center(grant numbers:IITP-2021-0-02051); Institute for Information and Communications Technology Planning and Evaluation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10265193","Affordances;challenges;collaborative learning;metaverse;presence;user study;virtual reality (VR)","Metaverse;Usability;Training;Three-dimensional displays;Collaboration;Surgery;Affordances","","15","","50","IEEE","27 Sep 2023","","","IEEE","IEEE Journals"
"Sharing Manipulated Heart Rate Feedback in Collaborative Virtual Environments","A. Dey; H. Chen; A. Hayati; M. Billinghurst; R. W. Lindeman",University of Queensland; University of Canterbury; University of South Australia; University of South Australia; University of Canterbury,2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"30 Dec 2019","2019","","","248","257","We have explored the effects of sharing manipulated heart rate feedback in collaborative virtual environments. In our study, we created two types of different virtual environments (active and passive) with different levels of interactions and provided three levels of manipulated heart rate feedback (decreased, unchanged, and increased). We measured the effects of manipulated feedback on Social Presence, affect, physical heart rate, and overall experience. We noticed a significant effect of the manipulated heart rate feedback in affecting scariness and nervousness. The perception of the collaborator's valance and arousal was also affected where increased heart rate feedback perceived as a higher valance and lower arousal. Increased heart rate feedback decreased the real heart rate. The type of virtual environments had a significant effect on social presence, heart rate, and affect where the active environment had better performances across these measurements. We discuss the implications of this and directions for future research.","1554-7868","978-1-7281-0987-9","10.1109/ISMAR.2019.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8943737","Virtual Reality;Physiological Feedback;Collaboration;Heartrate;Empathic Cues","Collaboration;Real-time systems;Physiology;Heart beat;Games;Skin","","15","","26","IEEE","30 Dec 2019","","","IEEE","IEEE Conferences"
"Motion Synchronization Control of Distributed Multisubsystems With Invariant Local Natural Dynamics","J. Cheong; S. -I. Niculescu; C. Kim","Department of Control and Instrumentation Engineering, Korea University, South Korea; Laboratory of Signals and Systems, CNRS Supélec, National Center for Scientific Research (CNRS), Gif-sur-Yvette, France; LG Electronics Limited, Changwon, South Korea",IEEE Transactions on Robotics,"3 Apr 2009","2009","25","2","382","398","This paper addresses a new control strategy for synchronizing two or more distributed and interconnected dynamic systems having communication time delays. The proposed strategy that uses the Smith predictor principle and delay information not only achieves synchronization but also preserves the natural local dynamics of each subsystem without being affected by the feedback nature of control. The proposed synchronization scheme is generalized to cases that deal with an arbitrary number of heterogeneous interconnected systems through dynamic scaling of input under a ring-type network configuration. In addition, possibility of applying the proposed scheme to nonlinear systems is discussed. Simulation and experimental tests are conducted to validate theoretical results.","1941-0468","","10.1109/TRO.2008.2011529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4770176","Distributed systems;dynamic scaling;motion synchronization;time delay","Distributed control;Motion control;Control systems;Communication system control;Delay effects;Interconnected systems;Force control;Oscillators;Control engineering;Teleoperators","","15","","45","IEEE","2 Feb 2009","","","IEEE","IEEE Journals"
"Inferring User Intent using Bayesian Theory of Mind in Shared Avatar-Agent Virtual Environments","S. Narang; A. Best; D. Manocha","University of North Carolina, Chapel Hill; University of North Carolina, Chapel Hill; University of Maryland, College Park",IEEE Transactions on Visualization and Computer Graphics,"27 Mar 2019","2019","25","5","2113","2122","We present a real-time algorithm to infer the intention of a user's avatar in a virtual environment shared with multiple human-like agents. Our algorithm applies the Bayesian Theory of Mind approach to make inferences about the avatar's hidden intentions based on the observed proxemics and gaze-based cues. Our approach accounts for the potential irrationality in human behavior, as well as the dynamic nature of an individual's intentions. The inferred intent is used to guide the response of the virtual agent and generate locomotion and gaze-based behaviors. Our overall approach allows the user to actively interact with tens of virtual agents from a first-person perspective in an immersive setting. We systematically evaluate our inference algorithm in controlled multi-agent simulation environments and highlight its ability to reliably and efficiently infer the hidden intent of a user's avatar even under noisy conditions. We quantitatively demonstrate the performance benefits of our approach in terms of reducing false inferences, as compared to a prior method. The results of our user evaluation show that 68.18% of participants reported feeling more comfortable in sharing the virtual environment with agents simulated with our algorithm as compared to a prior inference method, likely as a direct result of significantly fewer false inferences and more plausible responses from the virtual agents.","1941-0506","","10.1109/TVCG.2019.2898800","ARO(grant numbers:W911NF-19-1-0069); Intel; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8642370","multi-agent simulation;virtual reality;avatars;human agents;interactive navigation","Avatars;Virtual environments;Computational modeling;Inference algorithms;Two dimensional displays;Bayes methods;Heuristic algorithms","Adult;Algorithms;Bayes Theorem;Computer Graphics;Cues;Female;Humans;Image Processing, Computer-Assisted;Intention;Male;Virtual Reality","14","","59","IEEE","14 Feb 2019","","","IEEE","IEEE Journals"
"Collaborative Software Modeling in Virtual Reality","E. Yigitbas; S. Gorissen; N. Weidmann; G. Engels","Paderborn University, Germany; Paderborn University, Germany; Paderborn University, Germany; Paderborn University, Germany",2021 ACM/IEEE 24th International Conference on Model Driven Engineering Languages and Systems (MODELS),"11 Nov 2021","2021","","","261","272","Modeling is a key activity in conceptual design and system design. Through collaborative modeling, end-users, stakeholders, experts, and entrepreneurs are able to create a shared understanding of a system representation. While the Unified Modeling Language (UML) is one of the major conceptual modeling languages in object-oriented software engineering, more and more concerns arise from the modeling quality of UML and its tool-support. Among them, the limitation of the two-dimensional presentation of its notations and lack of natural collaborative modeling tools are reported to be significant. In this paper, we explore the potential of using Virtual Reality (VR) technology for collaborative UML software design by comparing it with classical collaborative software design using conventional devices (Desktop PC / Laptop). For this purpose, we have developed a VR modeling environment that offers a natural collaborative modeling experience for UML Class Diagrams. Based on a user study with 24 participants, we have compared collaborative VR modeling with conventional modeling with regard to efficiency, effectiveness, and user satisfaction. Results show that the use of VR has some disadvantages concerning efficiency and effectiveness, but the user's fun, the feeling of being in the same room with a remote collaborator, and the naturalness of collaboration were increased.","","978-1-6654-3495-9","10.1109/MODELS50736.2021.00034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9592501","Collaborative Modeling;Virtual Reality;UML","Solid modeling;Object oriented modeling;Collaborative software;Unified modeling language;Collaboration;Virtual reality;Tools","","13","","59","IEEE","11 Nov 2021","","","IEEE","IEEE Conferences"
"Augmented reality maintenance demonstrator and associated modelling","V. Havard; D. Baudry; A. Louis; B. Mazari","LUSINE and IRISE laboratories, CESI; LUSINE and IRISE laboratories, CESI; LUSINE and IRISE laboratories, CESI; LUSINE and IRISE laboratories, CESI",2015 IEEE Virtual Reality (VR),"27 Aug 2015","2015","","","329","330","Augmented reality allows to add virtual object in real scene. It has an increasing interest last years since mobile device becomes performant and cheap. The augmented reality is used in different domains, like maintenance, training, education, entertainment or medicine. The demonstrator we show is focused on maintenance operations. A step by step process is presented to the operator in order to maintain an element of a system. Based on this demonstration, we will explain the modelling we propose allowing describing an entire maintenance process with augmented reality. Indeed it is still difficult creating augmented reality application without computer programming skills. The proposed model will allow to create an authoring tool - or to plug to an existing one - in order to create augmented reality process without deep computer programming skills.","2375-5334","978-1-4799-1727-3","10.1109/VR.2015.7223429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7223429","Augmented Reality;modelling;maintenance;training","Maintenance engineering;Augmented reality;Unified modeling language;Animation;Training;Computational modeling;Laboratories","","13","","5","IEEE","27 Aug 2015","","","IEEE","IEEE Conferences"
"Effects of an in-car augmented reality system on improving safety of younger and older drivers","Wai-Tat Fu; J. Gasper; S. -W. Kim","Beckman Institute of Science and Technology, University of Illinois at Urbana-Champaign; Beckman Institute of Science and Technology, University of Illinois at Urbana-Champaign; Beckman Institute of Science and Technology, University of Illinois at Urbana-Champaign",2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"23 Dec 2013","2013","","","59","66","We designed and tested the effects of an in-car augmented reality system (ARS) on younger and older drivers, with and without a secondary distraction task. When potential danger is detected, the ARS alerts the driver by progressively indicating the time to collision to the lead vehicle as well as merging vehicles from side lanes by an AR display that overlaps with the lead or merging vehicles. We tested the ARS with younger (18–30) and older (65–75) drivers in a high-fidelity driving simulator. Results showed that the ARS could significantly reduce collisions caused by hazard events such as sudden slowing of the lead vehicle or merging of vehicles from sides lanes. Consistent with previous results, older drivers, despite age-related decline in cognitive and motor abilities, could leverage their driving experience to avoid forward collisions with the lead vehicle as much as younger drivers. However, older drivers were poorer in avoiding collisions caused by sudden merging events than younger drivers. The ARS was found to be most useful in helping older adults to avoid collision caused by sudden hazard events, especially with the presence of a distraction task. The ARS was also more effective for older than younger drivers to encourage a safe driving distance with the lead vehicle. Interestingly, there seemed to be differential effects of the ARS on the general driving behavior of younger and older drivers. While older drivers in general became more careful and safer in how they drive with the ARS, younger drivers seemed to rely on the ARS to alert them to potential hazard events without adopting safer driving behavior.","","978-1-4799-2869-9","10.1109/ISMAR.2013.6671764","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671764","","Vehicles;Augmented reality;Merging;Hazards;Visualization;Accidents;Analysis of variance","","13","","30","IEEE","23 Dec 2013","","","IEEE","IEEE Conferences"
"When Holographic Communication Meets Metaverse: Applications, Challenges, and Future Trends","A. V. Shvetsov; S. Hamood Alsamhi","Department of Road Transport and Car Service Operations, North-Eastern Federal University, Yakutsk, Russia; ICT, Bahrain Polytechnic, Isa Town, Bahrain",IEEE Access,"31 Dec 2024","2024","12","","197488","197515","Holographic communication represents a transformative technology for reshaping the digital interaction landscape by enabling the creation of realistic, immersive, and interactive 3D experiences. This survey overviews holographic communication and its integration with the Metaverse technologies’ concepts, advantages, uses, and many applications. Furthermore, we examine a new paradigm for integrating holographic communication with the Metaverse, emphasizing how holography enhances immersive quality of virtual environments within the Metaverse, making interactions more lifelike and engaging. Extending the integration of holographic communication and Metaverse, we examine this combination’s numerous uses in various applications across various industries, such as education where virtual classrooms and 3D simulations redefine remote learning, a business where virtual meetings and product demonstrations create more impactful customer engagements, entertainment where immersive gaming and 3D broadcasting transform user experiences, healthcare where remote consultations and surgical simulations enhance medical training and accessibility, and remote assistance where real-time holographic support improves technical troubleshooting. In addition, we discuss the challenges and prospects of integration of holographic communication into Metaverse ecosystems, emphasizing key approaches and technical developments emerging technologies such as AI-driven content optimization, advanced coding and compression techniques, and new paradigms like terahertz communication and quantum holography. This survey highlights the revolutionary potential of holographic communication and offers insightful information on how it will influence digital engagement and connectivity in the future, eventually opening up new avenues in the quickly changing Metaverse landscape.","2169-3536","","10.1109/ACCESS.2024.3514576","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10788695","Extended reality;digital interaction;immersive communications;holographic communication;Metaverse;connectivity;virtual environments;interaction;immersive experiences","Metaverse;Surveys;Three-dimensional displays;Medical services;Education;Entertainment industry;Ecosystems;Business;Avatars;6G mobile communication","","12","","162","CCBY","11 Dec 2024","","","IEEE","IEEE Journals"
"Evaluating the user Experience of a Photorealistic Social VR Movie","J. Li; S. Subramanyam; J. Jansen; Y. Mei; I. Reimat; K. Ławicka; P. Cesar","Centrum Wiskunde & Informatica, Amsterdam, The Netherlands; Centrum Wiskunde & Informatica, Amsterdam, The Netherlands; Centrum Wiskunde & Informatica, Amsterdam, The Netherlands; Centrum Wiskunde & Informatica, Amsterdam, The Netherlands; Centrum Wiskunde & Informatica, Amsterdam, The Netherlands; Centrum Wiskunde & Informatica, Amsterdam, The Netherlands; Centrum Wiskunde & Informatica, Amsterdam, The Netherlands",2021 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"1 Nov 2021","2021","","","284","293","We all enjoy watching movies together. However, this is not always possible if we live apart. While we can remotely share our screens, the experience differs from being together. We present a social Virtual Reality (VR) system that captures, reconstructs, and transmits multiple users’ volumetric representations into a commercially produced 3D virtual movie, so they have the feeling of “being there” together. We conducted a 48-user experiment where we invited users to experience the virtual movie either using a Head Mounted Display (HMD) or using a 2D screen with a game controller. In addition, we invited 14 VR experts to experience both the HMD and the screen version of the movie and discussed their experiences in two focus groups. Our results showed that both end-users and VR experts found that the way they navigated and interacted inside a 3D virtual movie was novel. They also found that the photorealistic volumetric representations enhanced feelings of co-presence. Our study lays the groundwork for future interactive and immersive VR movie co-watching experiences.","1554-7868","978-1-6654-0158-6","10.1109/ISMAR52148.2021.00044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9583789","Human-centered computing [Human computer interaction (HCI)]: HCI design and evaluation methods;User studies;Human-centered computing [Human computer interaction (HCI)]: Interaction paradigms;Virtual reality.","Human computer interaction;Three-dimensional displays;Navigation;Two dimensional displays;Virtual environments;Resists;Games","","12","","58","IEEE","1 Nov 2021","","","IEEE","IEEE Conferences"
"On the Way to Holographic-Type Communications: Perspectives and Enabling Technologies","R. Petkova; I. Bozhilov; A. Manolova; K. Tonchev; V. Poulkov","Faculty of Telecommunications, Technical University of Sofia, Sofia, Bulgaria; Faculty of Telecommunications, Technical University of Sofia, Sofia, Bulgaria; Faculty of Telecommunications, Technical University of Sofia, Sofia, Bulgaria; Faculty of Telecommunications, Technical University of Sofia, Sofia, Bulgaria; Faculty of Telecommunications, Technical University of Sofia, Sofia, Bulgaria",IEEE Access,"2 May 2024","2024","12","","59236","59259","Holographic-type communication (HTC) is on the verge of revolutionizing current communication paradigms. It will seamlessly connect people from distant locations through a fully immersive experience that will engage all five senses: sight, hearing, touch, smell, and taste. However, the practical realization and widespread adoption of HTC impose significant demands on current networks and end-user devices. While recent studies have primarily focused on discussing the HTC challenges and potential research directions, this paper takes a further step by evaluating the capabilities of wireless networks to meet HTC requirements. Specifically, it highlights the limitations of the fifth-generation (5G) networks by identifying HTC-related Key Performance Indicators (KPIs) and explores the potential of the sixth-generation (6G) networks. Moreover, it not only proposes potential research approaches for HTC enhancement but also analyzes their impact on the challenges in HTC implementation. Finally, the paper questions the ubiquitous potential of 6G, suggesting that a coordinated approach leveraging artificial intelligence (AI) for jointly optimizing user sites and communication networks is the most promising strategy, rather than solely relying on the capabilities of specific network generations.","2169-3536","","10.1109/ACCESS.2024.3393124","European Union-Next Generation EU, through the National Recovery and Resilience Plan of the Republic of Bulgaria(grant numbers:BG-RRP-2.004-0005); “Improving the research capacity and quality to achieve international recognition and resilience of TU-Sofia” (IDEAS); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10507796","5G;6G;AI;communication network;HTC;KPIs;user site","6G mobile communication;5G mobile communication;Optimization;Artificial intelligence;Three-dimensional displays;Communication networks;Telepresence;Web sites;Holography","","12","","120","CCBYNCND","24 Apr 2024","","","IEEE","IEEE Journals"
"An Empirical Study of Hear-Through Augmented Reality: Using Bone Conduction to Deliver Spatialized Audio","R. W. Lindeman; H. Noma; P. G. de Barros","Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA, USA; ATR International, Knowledge Science Labs, 2-2-2 Hikari-dai, Seika-cho, Souraku-gun, 619-0288 Kyoto, JAPAN, e-mail: noma@atr.jp; Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA, USA",2008 IEEE Virtual Reality Conference,"4 Apr 2008","2008","","","35","42","Augmented reality (AR) is the mixing of computer-generated stimuli with real-world stimuli. In this paper, we present results from a controlled, empirical study comparing three ways of delivering spatialized audio for AR applications: a speaker array, headphones, and a bone-conduction headset. Analogous to optical-see-through AR in the visual domain, hear-through AR allows users to receive computer-generated audio using the bone-conduction headset, and real-world audio using their unoccluded ears. Our results show that subjects achieved the best accuracy using a speaker array physically located around the listener when stationary sounds were played, but that there was no difference in accuracy between the speaker array and the bone-conduction device for sounds that were moving, and that both devices outperformed standard headphones for moving sounds. Subjective comments by subjects following the experiment support this performance data.","2375-5334","978-1-4244-1971-5","10.1109/VR.2008.4480747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4480747","Augmented reality;audio;bone conduction;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Audio input/output;Artificial, augmented, and virtual realities","Augmented reality;Bones;Character generation;Ear;Headphones;Loudspeakers;Virtual reality;Frequency;Microphones;Irrigation","","11","","19","IEEE","4 Apr 2008","","","IEEE","IEEE Conferences"
"A collaborative multi-view virtual environment for molecular visualization and modeling","J. W. Chastine; Ying Zhu; J. C. Brooks; G. S. Owen; R. W. Harrison; I. T. Weber","Department of Computer Science, Georgia State University, USA; Department of Computer Science, Georgia State University, USA; Department of Computer Science, Georgia State University, USA; Department of Computer Science, Georgia State University, USA; Department of Computer Science, Georgia State University, USA; Department of Biology, Georgia State University, USA",Coordinated and Multiple Views in Exploratory Visualization (CMV'05),"19 Sep 2005","2005","","","77","84","Molecular modeling has been a long-standing research area for biologists. However, the existing molecular modeling software lacks strong support for collaborative research. In this paper, we describe our effort to develop a collaborative multiview virtual environment for molecular visualization and modeling. In our virtual environment, the users are able to visualize large molecular structures in real-time, create their own view, or share their view with others in the system. The system allows for individual or coordinated collaborative manipulation of the virtual molecular model. Our virtual environment is integrated with a molecular dynamics simulator, and therefore our system is not merely a visualization tool, but an environment where biologists can collaboratively construct their models and test their hypotheses.","","0-7695-2396-X","10.1109/CMV.2005.1","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1508223","","Collaboration;Virtual environment;Visualization;Biological system modeling;Collaborative software;Cancer;Biology;Real time systems;Collaborative work;Computer science","","11","","33","IEEE","19 Sep 2005","","","IEEE","IEEE Conferences"
"TelePhysicalOperation: Remote Robot Control Based on a Virtual “Marionette” Type Interaction Interface","D. Torielli; L. Muratore; A. Laurenzi; N. Tsagarakis","Humanoid and Human Centred Mechatronics (HHCM), Istituto Italiano di Tecnologia, Genova, Italy; Humanoid and Human Centred Mechatronics (HHCM), Istituto Italiano di Tecnologia, Genova, Italy; Humanoid and Human Centred Mechatronics (HHCM), Istituto Italiano di Tecnologia, Genova, Italy; Humanoid and Human Centred Mechatronics (HHCM), Istituto Italiano di Tecnologia, Genova, Italy",IEEE Robotics and Automation Letters,"28 Jan 2022","2022","7","2","2479","2486","Teleoperation permits to control robots from a safe distance while performing tasks in a remote environment. Kinematic differences between the input device and the remotely controlled manipulator or the existence of redundancy in the remote robot may pose challenges in moving intuitively the remote robot as desired by the human operator. Motivated by the above challenges, this work introduces TelePhysicalOperation, a novel teloperation concept, which relies on a virtual physical interaction interface between the human operator and the remote robot in a manner that is equivalent to a “Marionette” based interaction interface. With the proposed approach, the user can virtually “interact” with the remote robot, through the application of virtual forces, which are generated by the operator tracking system and can be then selectively applied to any body part of the remote robot along its kinematic chain. This leads to the remote robot generating motions that comply with the applied virtual forces, thanks to the underlying control architecture. The proposed method permits to command the robot from a distance by exploring the intuitiveness of the “Marionette” based physical interaction with the robot in a virtual/remote manner. The details of the proposed approach are introduced and its effectiveness is demonstrated through a number of experimental trials executed on the CENTAURO, a hybrid leg-wheel platform with an anthropomorphic upper body.","2377-3766","","10.1109/LRA.2022.3144792","European Union’s Horizon 2020 programme(grant numbers:101016007); Italian Fondo per la Crescita Sostenibile - Sportello Fabbrica intelligente(grant numbers:PON I&C 2014 - 2020,F/190042/01-03/X44 RELAX); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9696192","Human-Robot collaboration;physical Human-Robot interaction;telerobotics and teleoperation","Performance evaluation;Tracking;Robot vision systems;Robot control;Redundancy;Input devices;Kinematics","","10","","22","IEEE","28 Jan 2022","","","IEEE","IEEE Journals"
"Development of Head-Mounted Projection Displays for Distributed, Collaborative, Augmented Reality Applications","J. P. Rolland; F. Biocca; F. Hamza-Lup; Y. Ha; R. Martins","Optical Diagnostics and Applications (ODA) Lab, University of Central Florida College of Optics and Photonics, Institute of Simulation and Training, and School of Computer Science University of Central Florida, 4000 Central Florida Boulevard Orlando, FL 32816, Rolland@odalab.ucf.edu; Media Interface and Network Design (MIND) Labs, Michigan State University East Lansing, MI 48824; Optical Diagnostics and Applications (ODA) Lab, School of Computer Science University of Central Florida 4000 Central Florida Boulevard Orlando, FL 32816; Optical Diagnostics and Applications (ODA) Lab, College of Optics and Photonics University of Central Florida 4000 Central Florida Boulevard Orlando, FL 32816; Optical Diagnostics and Applications (ODA) Lab, College of Optics and Photonics University of Central Florida 4000 Central Florida Boulevard Orlando, FL 32816",Presence,"19 May 2014","2005","14","5","528","549","Distributed systems technologies supporting 3D visualization and social collaboration will be increasing in frequency and type over time. An emerging type of head-mounted display referred to as the head-mounted projection display (HMPD) was recently developed that only requires ultralight optics (i.e., less than 8 g per eye) that enables immersive multiuser, mobile augmented reality 3D visualization, as well as remote 3D collaborations. In this paper a review of the development of lightweight HMPD technology is provided, together with insight into what makes this technology timely and so unique. Two novel emerging HMPD-based technologies are then described: a teleportal HMPD (T-HMPD) enabling face-to-face communication and visualization of shared 3D virtual objects, and a mobile HMPD (M-HMPD) designed for outdoor wearable visualization and communication. Finally, the use of HMPD in medical visualization and training, as well as in infospaces, two applications developed in the ODA and MIND labs respectively, are discussed.","1054-7460","","10.1162/105474605774918741","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6790697","","","","10","44","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Real-time Retargeting of Deictic Motion to Virtual Avatars for Augmented Reality Telepresence","J. Kang; D. Yang; T. Kim; Y. Lee; S. -H. Lee","Graduate School of Culture Technology, KAIST; Graduate School of Culture Technology, KAIST; Graduate School of Culture Technology, KAIST; Graduate School of Culture Technology, KAIST; Graduate School of Culture Technology, KAIST",2023 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"4 Dec 2023","2023","","","885","893","Avatar-mediated augmented reality telepresence aims to enable distant users to collaborate remotely through avatars. When two spaces involved in telepresence are dissimilar, with different object sizes and arrangements, the avatar movement must be adjusted to convey the user’s intention rather than directly following their motion, which poses a significant challenge. In this paper, we propose a novel neural network-based framework for real-time retargeting of users’ deictic motions (pointing at and touching objects) to virtual avatars in dissimilar environments. Our framework translates the user’s deictic motion, acquired from a sparse set of tracking signals, to the virtual avatar’s deictic motion for a corresponding remote object in real-time. One of the main features of our framework is that a single trained network can generate natural deictic motions for various sizes of users. To this end, our network includes two sub-networks: AngleNet and MotionNet. AngleNet maps the angular state of the user’s motion into a latent representation, which is subsequently converted by MotionNet into the avatar’s pose, considering the user’s scale. We validate the effectiveness of our method in terms of deictic intention preservation and movement naturalness through quantitative comparison with alternative approaches. Additionally, we demonstrate the utility of our approach through several AR telepresence scenarios.","2473-0726","979-8-3503-2838-7","10.1109/ISMAR59233.2023.00104","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316476","Computing methodologies;Computer graphics;Animation;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed/augmented reality","Telepresence;Tracking;Avatars;Real-time systems;Augmented reality","","9","","35","IEEE","4 Dec 2023","","","IEEE","IEEE Conferences"
"See-through and spatial augmented reality - a novel framework for human-robot interaction","Dinh Quang Huy; I. Vietcheslav; G. Seet Gim Lee","Nanyang Technological University, Singapore, Singapore, SG; Robotic Research Center I Nanyang Technological, University Singapore, Singapore; Sch. of Mechanical and Aerospace Nanyang Technological University Singapore, Singapore","2017 3rd International Conference on Control, Automation and Robotics (ICCAR)","8 Jun 2017","2017","","","719","726","Autonomous and semi-autonomous mobile robots have been deployed to cooperate with humans in many industrial applications. These tasks require human and robot to communicate and present information quickly and effectively. Recent human-robot interfaces usually use a setup including a camera and a projector attached to the mobile robot to project the information to the floor or to the wall during the interaction process. However, there are some limitations to these interfaces. First, using a projector for projecting information seems to be fine for an indoor application. On the contrary, it is very difficult or even impossible for users to view this source of information in outdoor contexts. This makes the current framework inappropriate for many outdoor industrial tasks. Secondly, as the projector is the only device for exchanging information between human and robot, the human-robot interacting process is insecure and people who work in the same environment can control the robot in the same manner as the main operator. Finally, the current interfaces normally use mouse, keyboard or a teach pendant to provide task information to the robot. This approach poses some difficulties if the main operator is working in an industrial context where he is supposed to wear protective equipment such as gloves or helmets which make it hard to control a mouse or to type on a keyboard. This work proposes a new interface framework for human - computer interaction in industry that can overcome the current limitations of previous works. The framework uses a laser-writer instead of a projector which is suitable for both indoor and outdoor applications. Furthermore, the combination of see-through head-mounted display augmented reality and spatial augmented reality would provide the system a novel way to enhance the security level of exchanging information since the system now can separate the information presenting to the main user and to people working in the same environment. Finally, a novel hand-held device is incorporated to the framework which provides various input modalities for users to interact with the mobile robot. The device will allows the elimination of mouse and keyboard or teach pendants in industrial contexts.","","978-1-5090-6088-7","10.1109/ICCAR.2017.7942791","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7942791","human-robot interaction;augmented reality;spatial augmented reality;human robot-collaboration","Service robots;Robot sensing systems;Augmented reality;Security;Manufacturing processes;Cameras","","9","","16","IEEE","8 Jun 2017","","","IEEE","IEEE Conferences"
"A Review of 6G and AI Convergence: Enhancing Communication Networks With Artificial Intelligence","Y. Sanjalawe; S. Fraihat; S. Al-E’Mari; M. Abualhaj; S. Makhadmeh; E. Alzubi","Department of Information Technology, King Abdullah II School for Information Technology, University of Jordan, Amman, Jordan; Artificial Intelligence Research Center, College of Engineering and Information Technology, Ajman University, Ajman, UAE; Department of Information Security, Faculty of Information Technology, University of Petra, Amman, Jordan; Department of Networks and Information Security, Faculty of Information Technology, Al-Ahliyya Amman University, Amman, Jordan; Department of Information Technology, King Abdullah II School for Information Technology, University of Jordan, Amman, Jordan; College of Business Administration, Northern Border University, Arar, Saudi Arabia",IEEE Open Journal of the Communications Society,"7 Apr 2025","2025","6","","2308","2355","This paper explores the integration of Artificial Intelligence into 6G networks, focusing on optimizing communication, resource allocation, and enhancing security. As communication systems transition from 5G to 6G, Artificial Intelligence’s role in addressing the increasing complexity of network management becomes pivotal. The paper reviews key AI technologies such as machine learning, deep learning, and reinforcement learning, demonstrating their applications in predictive maintenance, traffic management, and energy efficiency optimization. It also highlights how Artificial Intelligence enables intelligent network slicing, spectrum management, and resource allocation through dynamic algorithms. Furthermore, Artificial Intelligence-driven solutions are presented for addressing security concerns in 6G networks, focusing on intrusion detection, anomaly detection, and blockchain-based decentralized security. Challenges such as computational overhead, data privacy, and ethical concerns in implementing Artificial Intelligence in 6G systems are also discussed, along with future directions, including quantum AI and federated learning. This paper provides a comprehensive analysis of how Artificial Intelligence can enhance the capabilities of 6G networks, ensuring improved performance, security, and scalability for future communication technologies.","2644-125X","","10.1109/OJCOMS.2025.3553302","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10935636","AI-driven communication optimization;AI in 6G;decentralized security;network resource allocation;reinforcement learning;spectrum management","6G mobile communication;Artificial intelligence;Surveys;Security;Resource management;Real-time systems;5G mobile communication;Reinforcement learning;Optimization;Information technology","","9","","242","CCBY","20 Mar 2025","","","IEEE","IEEE Journals"
"Evaluating the Use of Virtual Reality on Professional Robotics Education","M. C. Charão dos Santos; V. A. Sangalli; M. S. Pinho","Virtual Reality Group - Computer Science School, PUCRS, Porto Alegre, Brazil; Virtual Reality Group - Computer Science School, PUCRS, Porto Alegre, Brazil; Virtual Reality Group - Computer Science School, PUCRS, Porto Alegre, Brazil",2017 IEEE 41st Annual Computer Software and Applications Conference (COMPSAC),"11 Sep 2017","2017","1","","448","455","This work consists of the study of techniques of robotics and virtual reality to develop a simulator that can be used in robotics schools, having an adequate visualization and a simple and intuitive way of interaction. For this, a 3D virtual environment for robotics was developed. Virtual reality resources have been incorporated to improve the visualization and to facilitate the user interaction with the environment. In order to evaluate the effectivity of the environment, user experiments were carried out on four different hardware configurations. During the simulations, the users had to create trajectories while implicitly defining reference points. From these experiments, automatic reports for the quantitative questions were generated, and questionnaires were filled for the qualitative questions. The results have shown that the use of virtual reality do helps the users in task execution, improving the visualization, reducing the time spent for the tasks and increasing the precision.","0730-3157","978-1-5386-0367-3","10.1109/COMPSAC.2017.121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8029641","education;robotics;virtual reality","Educational robots;Visualization;Three-dimensional displays;Virtual reality;Solid modeling;Manipulators","","8","","13","IEEE","11 Sep 2017","","","IEEE","IEEE Conferences"
"A testbed for precise registration, natural occlusion and interaction in an augmented environment using a head-mounted projective display (HMPD)","Hong Hua; Chunyu Gao; L. D. Brown; N. Ahuja; J. P. Rolland","Beckman Institute, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA; Beckman Institute, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA; Beckman Institute, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA; Beckman Institute, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA; School of Optics-CREOL, University of Central Florida, Orlando, FL, USA",Proceedings IEEE Virtual Reality 2002,"7 Aug 2002","2002","","","81","89","A head-mounted projective display (HMPD) consists of a pair of miniature projection lenses, beam splitters and displays mounted on the helmet and retro-reflective sheeting materials placed strategically in the environment. This has recently been proposed as an alternative to existing 3D visualization devices. In this paper, we first briefly review HMPD technology, including its featured capabilities and the recent development in both display implementations and applications. Then the implementation of a testbed for playing a ""Go"" game with a remote opponent in a 3D augmented environment is described. The testbed not only demonstrates the capabilities of virtual-real augmentation and registration, the natural occlusion of virtual objects by real ones, interaction with augmented environments and networking collaboration, but also embodies part of our long-term objective to develop a collaborative framework in 3D augmented environments. Through the testbed, major calibration issues, such as accommodation/convergence considerations and determination of viewing transformations, are studied and discussed in detail. Both calibration methods and results are included, which are applicable to other applications. Finally, experimental results of the testbed implementation are presented.","1087-8270","0-7695-1492-8","10.1109/VR.2002.996508","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=996508","","Biomedical optical imaging;Optical attenuators;Displays;Layout;Visualization;Collaboration;Calibration;Materials testing;Lenses;Cameras","","8","1","21","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Augmented reality in e-learning review of prototype designs for usability evaluation","T. Satpute; S. Pingale; V. Chavan","Department of ComputerScience and Engineering, SKN Sinhgad College of Engineering, Pandharpur, India; Department of ComputerScience and Engineering, SKN Sinhgad College of Engineering, Pandharpur, India; Department of ComputerScience and Engineering, SKN Sinhgad College of Engineering, Pandharpur, India","2015 International Conference on Communication, Information & Computing Technology (ICCICT)","23 Feb 2015","2015","","","1","4","The concept of e-learning has reached beyond use of presentations, videos. Augmented reality (AR) based systems are preferred to support teaching and learning activities along with these e-learning systems. In this paper we present a systematic review of such prototypes developed for educational purposes and compare their usability for finding benefits of AR. It also focuses on use of web 2.0 tools in e- learning and combined use of both technologies.","","978-1-4799-5522-0","10.1109/ICCICT.2015.7045712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045712","Augmented Reality;e-learning;usability;web 2.0","Augmented reality;Prototypes;Web 2.0;Electronic learning;Collaboration;Usability","","8","","18","IEEE","23 Feb 2015","","","IEEE","IEEE Conferences"
"From 3D to VR and further to telexistence","S. Tachi",Keio University / The University of Tokyo,2013 23rd International Conference on Artificial Reality and Telexistence (ICAT),"30 Jan 2014","2013","","","1","10","The history of 3D elucidates that it has a thirty year cycle of evolution. Further, it was discovered that VR (virtual reality) and AR (augmented reality) evolved almost a decade after the 3D crazes occurred. This leads to the conjecture that the next VR and AR craze will be in the 2020s. AR augments the sense and intellect of a human. Human augmentation or augmented human (AH) augments humans not only in their senses and intellect but also in their motions and abilities to transcend time and space. Human augmentation in time and space is termed as telexistence. In addition, the evolution of telexistence is reviewed along with a glance at its future prospects.","","978-4-904490-11-2","10.1109/ICAT.2013.6728898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728898","3D;virtual reality;VR;augmented reality;AR;human augmentation;augmented human;AH;cyborg;telexistence","Three-dimensional displays;Motion pictures;Augmented reality;Synchronization;Head;Real-time systems","","8","","27","","30 Jan 2014","","","IEEE","IEEE Conferences"
"MR Meets Robotics: A Review of Mixed Reality Technology in Robotics","J. Yu; T. Wang; Y. Shi; L. Yang","Zhejiang University/University of Illinois at Urbana-Champaign Institute, Zhejiang University, Haining, China; Zhejiang University/University of Illinois at Urbana-Champaign Institute, Zhejiang University, Haining, China; Zhejiang University/University of Illinois at Urbana-Champaign Institute, Zhejiang University, Haining, China; Zhejiang University/University of Illinois at Urbana-Champaign Institute, Zhejiang University, Haining, China","2022 6th International Conference on Robotics, Control and Automation (ICRCA)","18 Jul 2022","2022","","","11","17","The rising interest in Mixed Reality (MR) technology in robotics and the lack of prior work in the literature of this subject motivate this review paper. Our purpose is to discuss current research and the advancement of MR applications in the context of robotics. Development in modern robots towards a more human-centric role is driven largely by enabling technology including, but not limited to, machine vision, cobots, virtual reality, and more recently, MR technology. The scope encompasses MR technology in various aspects of robotics, namely, robot vision, control and planning, human-robot interaction, multi-user collaborations, and swarm robotics. Through discussions of the benefits and knowledge gaps in contemporary development, the review is expected to provide readers with an in-depth appreciation of the state-of-the-art technology and the possibility of MR technology in robotics.","","978-1-6654-8174-8","10.1109/ICRCA55033.2022.9828895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9828895","mixed reality;robotics;visualization;teleoperation and control","Robot kinematics;Robot vision systems;Swarm robotics;Human-robot interaction;Mixed reality;Collaboration;Virtual reality","","8","","58","IEEE","18 Jul 2022","","","IEEE","IEEE Conferences"
"Exploring Visual Techniques for Boundary Awareness During Interaction in Augmented Reality Head-Mounted Displays","W. Xu; H. -N. Liang; Y. Chen; X. Li; K. Yu","Xi’an Jiaotong-Liverpool University, Suzhou, China; Xi’an Jiaotong-Liverpool University, Suzhou, China; Xi’an Jiaotong-Liverpool University, Suzhou, China; Xi’an Jiaotong-Liverpool University, Suzhou, China; Xi’an Jiaotong-Liverpool University, Suzhou, China",2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),"11 May 2020","2020","","","204","211","Mid-air hand interaction has long been proposed as a ‘natural’ input method for Augmented Reality (AR) systems. Current AR Head-Mounted Displays (HMDs) have a limited area for hand-based interactions. Because of this, users may easily move their hand(s) outside this tracked area during interaction, especially in dynamic tasks (e.g., when translating an object). Compared to common midair interaction issues, such as gesture recognition, arm/hand fatigue, and unnatural ways of interacting with virtual objects (e.g., selecting a distant object), boundary awareness issues in AR devices have received little attention. In this research, we explore visual techniques for boundary awareness in AR HMDs, focusing on object translation tasks. Through a systematic formative study, we first identify the challenges that users might face when interacting with AR HMDs without any boundary awareness information (i.e., how current systems work). Based on the findings, we then propose four methods (i.e., static surfaces, dynamic surface(s), static coordinated lines, and dynamic coordinate line(s)) and evaluate them against the benchmark (i.e., baseline condition without boundary awareness) to make users aware of the tracked interaction area. Our results show that visual methods for boundary awareness can help with dynamic mid-air hand interactions in AR HMDs, but their effectiveness and application are user-dependent.","2642-5254","978-1-7281-5608-8","10.1109/VR46266.2020.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089517","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed/augmented reality;Human-centered computing;Visualization;Visualization techniques","Tracking;Visualization;Cameras;Task analysis;Gesture recognition;Sensors;Collaboration","","8","","37","IEEE","11 May 2020","","","IEEE","IEEE Conferences"
"CoScribe: Using Paper for Collaborative Annotations in Lectures","J. Steimle; O. Brdiczka; M. Mühlhäuser","Telecooperation Group, Technische Universität Darmstadt, Germany; Telecooperation Group, Technische Universität Darmstadt, Germany; Telecooperation Group, Technische Universität Darmstadt, Germany",2008 Eighth IEEE International Conference on Advanced Learning Technologies,"15 Jul 2008","2008","","","306","310","In a study of notetaking in university courses, we found that the large majority of students prefer the paper medium to the computer for taking notes and making annotations. Based on this finding, we developed CoScribe, a system which supports students in making collaborative handwritten annotations on printed lecture slides. It includes mechanisms for the paper-based sharing and semantic tagging of annotations and slides. Moreover, we present a novel visualization of shared handwritten annotations providing an integrated access to annotations from all learners. A user study indicates that the system efficiently supports student annotation and can be easily integrated into current annotation practice.","2161-377X","978-0-7695-3167-0","10.1109/ICALT.2008.39","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4561694","Annotation;tagging;digital paper;lecture;computer-supported collaborative learning (CSCL)","Tagging;Visualization;Conducting materials;Personal communication networks;Paper technology;International collaboration;Organizing;User interfaces;Indexing;Navigation","","8","4","18","IEEE","15 Jul 2008","","","IEEE","IEEE Conferences"
"Enhancing Team Interaction and Cross-platform Access in Web-based Collaborative Virtual Environments","M. HUDÁK; Š. KOREČKO; B. SOBOTA","Department of Computers and Informatics, Technical University of Košice, Slovak Republic; Department of Computers and Informatics, Technical University of Košice, Slovak Republic; Department of Computers and Informatics, Technical University of Košice, Slovak Republic",2019 IEEE 15th International Scientific Conference on Informatics,"17 Jun 2020","2019","","","000171","000176","Utilization of web-based Collaborative Virtual Environments (CVE) enhances user’s interaction over large geographical distances. Deploying a variety of VR technologies increases demands to develop VR applications which would run on various systems and devices. Otherwise, user’s access is limited by the supported operating system. Nowadays, concerning the quality and safety of web technologies, it is possible to provide Global Collaborative Virtual Environments (G-CVE) with cross-platform support. This paper introduces the LIRKIS G-CVE web-based system, built on top of the Networked-Aframe framework. The architecture of LIRKIS G-CVE is presented, together with is innovative Smart-client interface (SCI) component, which utilizes smart devices, such as smartphones and tablets, as input devices. The advantage of SCI over the standard input component of the Networked-Aframe is demonstrated via a series of experiments.","","978-1-7281-3180-1","10.1109/Informatics47936.2019.9119312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9119312","virtual reality;web-based;virtual environment;virtual collaboration;human-machine interaction","Three-dimensional displays;Operating systems;Collaboration;Virtual environments;Motors;Real-time systems;Safety;Smart devices;Standards;Smart phones","","8","","12","IEEE","17 Jun 2020","","","IEEE","IEEE Conferences"
"Navigation Aids in Collaborative Virtual Environments: Comparison of 3DML, Audio, Textual, Arrows-Casting","S. Khalid; S. Ullah; N. Ali; A. Alam; I. Rabbi; I. U. Rehman; M. Azhar","Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science, University of Science and Technology Bannu, Bannu, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan; Department of Computer Science and IT, University of Malakand, Chakdara, Pakistan",IEEE Access,"30 Oct 2019","2019","7","","152979","152989","For Collaborative Virtual Environments (CVEs), many interaction techniques are developed. Depending on the purpose of the collaborative work, techniques of interaction and manipulation change from one application to another. There is no general, good and efficient solution for all the collaborative systems. In addition, people in CVEs also use communication channels to share task goals, task decomposition and task progress. Therefore, awareness and communication are usually considered as important instruments to complete collaborative task. In this paper we present a comparative study of user performance with assembly task across four different guidance navigation aids i.e. 3-Dimensional Map-Liner (3DML), Audio, Textual and Arrows-Casting. Dijkstra's algorithm is used for shortest path selection while making the assembly task in CVEs. We conducted experiments on different college students to check the performance of the students. We reported the results of a precise experiments containing of 24 virtual teams of 48 individual students. Overall results showed that students performed task faster using the arrows while they were slow with audio support in navigation.","2169-3536","","10.1109/ACCESS.2019.2948285","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8876589","Virtual reality (VR);collaborative virtual environments;building navigation;map based navigation;Dijkstra’s algorithms;path planning","Navigation;Task analysis;Collaboration;Visualization;Virtual environments;Three-dimensional displays;Computer science","","7","","44","CCBY","21 Oct 2019","","","IEEE","IEEE Journals"
"The Potential of Virtual Reality for Aerospace Applications","J. Pirker","Graz University of Technology, Graz, Austria",2022 IEEE Aerospace Conference (AERO),"10 Aug 2022","2022","","","1","8","In the past decade, virtual reality (VR) technologies have become increasingly affordable, flexible, and accessible with the release of consumer versions such as the Oculus Rift or the HTC Vive. The immersive and interactive experiences enabled by this technology offer relevant, innovative use cases and training methods in a wide variety of fields. Therefore, VR is becoming more relevant in many areas outside classic entertainment. These include, for example, medical applications, educational environments, industrial applications, and design applications. In particular, immersive simulations and experiences that would often be too dangerous, expensive, difficult or even impossible to perform can be experienced in a safe environment. In this paper, the potential of VR technologies for different areas of aerospace applications is demonstrated and discussed. A systematic literature review based on the PRISMA guideline is conducted to identify relevant publications and applications from the databases IEEE, ACM, and Scopus. The analysis focuses on identifying various use cases of VR in aerospace research, design, manufacturing, operations, maintenance and education. Furthermore, the benefits, potential challenges and relevant technologies are discussed. This paper is designed to give readers a good overview of the state-of-the-art in VR, focusing on use cases and the potential and challenges, and discussing relevant future scenarios for this application field.","1095-323X","978-1-6654-3760-8","10.1109/AERO53065.2022.9843324","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9843324","","Training;Solid modeling;Visualization;Systematics;Collaboration;Medical treatment;Virtual reality","","7","","53","IEEE","10 Aug 2022","","","IEEE","IEEE Conferences"
"A virtual environment for modeling 3D objects through spatial interaction","H. Nishino; M. Fushimi; K. Utsumiya; K. Korida","Department of Computer Science and Intelligent Systems, Oita University, Oita, Japan; Department of Computer Science and Intelligent Systems, Oita University, Oita, Japan; Department of Computer Science and Intelligent Systems, Oita University, Oita, Japan; Department of Communication, Oita Prefectural College of Arts and Culture, Oita, Japan","IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)","6 Aug 2002","1999","6","","81","86 vol.6","While the demand for 3D technologies is growing rapidly, there are some fundamental problems remaining unresolved, such as a way to intuitively create 3D object data in a virtual environment. This paper proposes a new method for creating 3D objects using bi-manual gestures. To realize an easy-to-use yet powerful modeling capability, we designed a framework defining a dozen primitive hand actions to be used for modeling tasks. Then a 3D modeler was developed to substantiate the framework in a virtual environment, allowing the users to create complex shapes by combining the defined hand actions. We prove that the hand actions described in the framework are essential, and are generally applicable for various modeling tasks, by exemplifying some interesting and practical shapes.","1062-922X","0-7803-5731-0","10.1109/ICSMC.1999.816460","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=816460","","Virtual environment;Shape;Computer graphics;Production;Space technology;Computer science;Intelligent systems;Educational institutions;Art;Virtual reality","","7","7","13","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Virtual Reality: A Paradigm Shift in Architecture and Urban Design Education","N. A. Fathallah; R. Rashed; S. Afifi; G. F. Hassan","Architecture Heliopolis University, Cairo, Egypt; Urban Design and Planning Ain Shams University, Cairo, Egypt; Urban Design and Planning Ain Shams University, Cairo, Egypt; Urban Design and Planning Ain Shams University, Cairo, Egypt",2022 IEEE 1st Industrial Electronics Society Annual On-Line Conference (ONCON),"24 May 2023","2022","","","1","6","Technology is constantly evolving and has radically changed the way societies behave and operate. These advancements have brought enormous benefits - dramatically highlighted in 2020 by the emerging use of remote learning worldwide. The COVID-19 outbreak has served as a tipping point for the technological advances in architecture education in particular and higher education in general. Virtual reality is considered one of the innovative technologies that have been widely applied in different fields. This study, therefore, aims to examine the potential of VR applications in architecture education. The adopted methodology is reviewing articles from the Scopus Database under the Title/Abstract/Keyword field search using the following keywords: (“Virtual Reality” AND “Architecture Education” AND “Urban Design” AND “Design Studio”). Findings provide valuable insights for researchers, educators, and practitioners on integrating virtual reality in education to improve the educational process.","","979-8-3503-9806-9","10.1109/ONCON56984.2022.10126564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10126564","Virtual Reality (VR);architecture education;design studio","COVID-19;Industrial electronics;Visualization;Three-dimensional displays;Electronic learning;Navigation;Metaverse","","7","","53","IEEE","24 May 2023","","","IEEE","IEEE Conferences"
"Engineering methods and tools for collaborative development of industrial cyber-physical based products and services","D. Stokic; S. Scholze; C. Decker; K. Stöbener","ATB-Bremen, Institute for Applied System Technology, Bremen, Germany; ATB-Bremen, Institute for Applied System Technology, Bremen, Germany; KLÖCKNER DESMA Schuhmaschinen GmbH Achim, Germany; KLÖCKNER DESMA Schuhmaschinen GmbH Achim, Germany",2014 12th IEEE International Conference on Industrial Informatics (INDIN),"6 Nov 2014","2014","","","594","599","The objective of the research is to provide a novel methodology and a set of ICT solutions for collaborative design of cyber-physical based product-services. The products which include cyber-physical features, such as Ambience Intelligence (AmI) features, have to be extended with new services. Development of such products and services requires collaborative work of various stakeholders. A Cloud Manufacturing approach is applied for effective collaborative design of product-services, and the effective implementation of innovative services. It involves all the actors of a value chain, within a product ecosystem, allowing manufacturers to strengthen their competitiveness at the global market. The development platform is to be provided, including a set of new engineering tools, such as a tool for selection /use of AmI solutions for building services around the products, tools for embedding context sensitivity into products and services, simulation, configuration of product-services etc. The research is driven by industrial application scenarios addressing different aspects of service and business building as well as products development in different sectors (automotive, home appliances, automation equipment etc.). In this paper the focus is on an application scenario in automation equipment industry.","2378-363X","978-1-4799-4905-2","10.1109/INDIN.2014.6945580","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945580","Collaborative design;Product-services;Engineering tools;Cyber Physical Products;Ambience Intelligence","Context;Collaboration;Context modeling;Monitoring;Biological system modeling;Manufacturing;Production","","7","","21","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"C-IVAL: A Longitudinal Study of Knowledge Retention and Technology Acceptance in Collaborative Virtual Reality-Based Medical Education","M. Kadri; F. -E. Boubakri; G. -J. Hwang; F. Zahra Kaghat; A. Azough; K. Alaoui Zidani","Faculty of Sciences Dhar El Mahraz, Sidi Mohamed Ben Abdellah University, Fes, Morocco; Faculty of Sciences Dhar El Mahraz, Sidi Mohamed Ben Abdellah University, Fes, Morocco; Graduate Institute of Educational Information and Measurement, National Taichung University of Education, Taichung City, Taiwan; Research Center, Léonard de Vinci Pôle Universitaire, Paris, France; Research Center, Léonard de Vinci Pôle Universitaire, Paris, France; Faculty of Sciences Dhar El Mahraz, Sidi Mohamed Ben Abdellah University, Fes, Morocco",IEEE Access,"28 Jan 2025","2025","13","","16055","16071","Anatomy education faces challenges in providing engaging, interactive, and collaborative learning experiences, particularly in understanding complex three-dimensional structures and maintaining long-term knowledge retention. Although virtual reality (VR) has shown promise in addressing spatial comprehension challenges, questions remain regarding its effectiveness in supporting collaborative learning and sustained knowledge retention. This longitudinal study examined Collaborative Immersive Virtual Anatomy Laboratory (C-IVAL), an innovative VR platform designed to enhance traditional anatomy learning through integrated collaborative features, immersive technology, and serious game elements. We conducted an experimental study with 65 medical students to evaluate their knowledge acquisition and technology acceptance compared to its non-collaborative predecessor, the Immersive Virtual Anatomy Laboratory (IVAL). Our evaluation framework combined quantitative assessments (knowledge tests, comprising pre-test, immediate post-test, and delayed post-test) with Technology Acceptance Model (TAM) analysis. Knowledge assessment revealed significant cognitive improvements, with mean knowledge scores increasing from 2.48 to 3.94 in the immediate post-tests, while long-term retention of anatomy knowledge showed sustained engagement for over two months. Importantly, C-IVAL demonstrated significantly higher scores across all TAM dimensions than the non-collaborative IVAL system, particularly for perceived usefulness and intention to use. Post-session feedback analysis showed 73.8% positive responses, highlighting enhanced social presence, immersive engagement, and effective collaboration, with 26.2% of constructive feedback focusing on system refinement and feature enhancement. This study contributes to the understanding of the effectiveness of collaborative features in virtual reality education by offering insights into designing and implementing virtual learning environments that enhance both knowledge retention and user acceptance.","2169-3536","","10.1109/ACCESS.2024.3523860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10817604","Virtual reality;human-computer interaction;user experience;three dimensional computer graphics;technology acceptance model;interactive learning environments;social presence;collaborative learning;medical education;evaluation methodologies","Anatomy;Education;Collaboration;Virtual reality;Federated learning;Three-dimensional displays;Solid modeling;Real-time systems;Knowledge acquisition;Teamwork","","7","","42","CCBY","27 Dec 2024","","","IEEE","IEEE Journals"
"System and Interface Framework for SCAPE as a Collaborative Infrastructure","H. Hua; L. D. Brown; C. Gao","Optical Sciences Center, University of Arizona, Tucson, AZ 85721, Hhua@optics.arizona.edu; Beckman Institute, University of Illinois at Urbana-Champaign, Urbana, IL 61801, lbrown2@uiuc.edu; Beckman Institute, University of Illinois at Urbana-Champaign, Urbana, IL 61801, gao@uiuc.edu",Presence,"19 May 2014","2004","13","2","234","250","We have developed a multi-user collaborative infrastructure, SCAPE (an acronym for Stereoscopic Collaboration in Augmented and Projective Environments), which is based on recent advancement in head-mounted projective display (HMPD) technology. SCAPE combines the functionalities of an interactive workbench and a room-sized immersive display to concurrently create both exocentric and egocentric perspectives. SCAPE intuitively provides a shared space in which multiple users can simultaneously interact with a 3D synthetic environment from their individual viewpoints, and each user has concurrent access to the environment from multiple perspectives at multiple scales. SCAPE also creates a platform to merge the traditionally separate paradigms of virtual and augmented realities. In this paper, we discuss the design principles we have followed to conceptualize the SCAPE system and briefly summarize SCAPE's hardware implementation. Furthermore, we discuss in detail the high-level design and implementation of the SCAPE architecture, and present a set of unique widget interfaces currently available in our implementation that enable and facilitate interaction and cooperation. Finally, we demonstrate SCAPE's unique visualization and interface capabilities via a testbed application— Aztec Explorer.","1054-7460","","10.1162/1054746041382429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6788865","","","","7","21","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Give Me a Hand: Improving the Effectiveness of Near-field Augmented Reality Interactions By Avatarizing Users' End Effectors","R. Venkatakrishnan; R. Venkatakrishnan; B. Raveendranath; C. C. Pagano; A. C. Robb; W. -C. Lin; S. V. Babu","School of Computing at Clemson University, United States; School of Computing at Clemson University, United States; Department of Psychology at Clemson University, United States; Department of Psychology at Clemson University, United States; School of Computing at Clemson University, United States; Department of Computer Science at National Yang Ming Chiao Tung University, Taiwan; School of Computing at Clemson University, United States",IEEE Transactions on Visualization and Computer Graphics,"29 Mar 2023","2023","29","5","2412","2422","Inspired by previous works showing promise for AR self-avatarization - providing users with an augmented self avatar, we investigated whether avatarizing users' end-effectors (hands) improved their interaction performance on a near-field, obstacle avoidance, object retrieval task wherein users were tasked with retrieving a target object from a field of non-target obstacles for a number of trials. We employed a 3 (Augmented hand representation) X 2 (density of obstacles) X 2 (size of obstacles) X 2 (virtual light intensity) multi-factorial design, manipulating the presence/absence and anthropomorphic fidelity of augmented self-avatars overlaid on the user's real hands, as a between subjects factor across three experimental conditions: (1) No-Augmented Avatar (using only real hands); (2) Iconic-Augmented Avatar; (3) Realistic Augmented Avatar. Results indicated that self-avatarization improved interaction performance and was perceived as more usable regardless of the anthropomorphic fidelity of avatar. We also found that the virtual light intensity used in illuminating holograms affects how visible one's real hands are. Overall, our findings seem to indicate that interaction performance may improve when users are provided with a visual representation of the AR system's interacting layer in the form of an augmented self-avatar.","1941-0506","","10.1109/TVCG.2023.3247105","US National Science Foundation (CISE IIS HCC)(grant numbers:2007435); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10049690","Interactions in AR;End-effector representation;Avatars;Augmented Reality","Task analysis;Avatars;Three-dimensional displays;End effectors;Visualization;Hardware;Cameras","","6","","82","IEEE","22 Feb 2023","","","IEEE","IEEE Journals"
"Networked Metaverse Systems: Foundations, Gaps, Research Directions","Y. Zhang; D. Kutscher; Y. Cui","The Hong Kong University of Science and Technology, Guangzhou, China; The Hong Kong University of Science and Technology, Guangzhou, China; The Hong Kong University of Science and Technology, Guangzhou, China",IEEE Open Journal of the Communications Society,"10 Sep 2024","2024","5","","5488","5539","This article discusses ‘Metaverse’ from a technical perspective, focusing on networked systems aspects. Based on a technical definition of the ‘Metaverse,’ we examine the current state and challenges in communication and networking within Metaverse systems. We describe the state-of-the-art in different enabling Metaverse technologies and provide a technical analysis of current Metaverse system architectures. We then detail the state-of-the-art and the gaps in four areas: communication performance, mobility, large-scale operation, and end system architecture. Based on our analysis, we formulate a vision for future Metaverse infrastructure, outlining goals, design concepts, and suggested research directions.","2644-125X","","10.1109/OJCOMS.2024.3426098","Guangzhou Municipal Key Laboratory on Future Networked Systems(grant numbers:024A03J0623); National Natural Science Foundation of China(grant numbers:62371412); National Key Research and Development Program of China(grant numbers:2024YFE0200600); Guangdong Basic and Applied Basic Research Natural Science Funding Scheme(grant numbers:2024A1515011184); Guangzhou-HKUST (GZ) Joint Funding Scheme(grant numbers:2024A03J0539); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10592027","Metaverse;networking;Internet;information-centric networking","Metaverse;Surveys;Blockchains;Artificial intelligence;Computer architecture;Games;Focusing","","6","","431","CCBY","10 Jul 2024","","","IEEE","IEEE Journals"
"Augmented/Virtual Reality: Technological Advancement with Use Cases","A. L. Dwarkadas; R. Krishna Challa; V. Talasila; S. K G","National Institute of Technical Teachers Training and Research, Chandigarh, India; National Institute of Technical Teachers Training and Research, Chandigarh, India; Ramaiah Institute of Technology, Bengaluru, India; International Institute of Information Technology, Naya Raipur, India",2023 Global Conference on Information Technologies and Communications (GCITC),"18 Apr 2024","2023","","","1","7","Augmented reality (AR) technology gives real and computerized elements that appear to coexist in real space. It makes users feel all three senses: smelling, hearing, and touch of the human body. Virtual reality (VR) is technology comprising interactive computer simulations that create the impression of being completely or partially immersed. It is a strong human-computer interface that merges computer animation, image analysis, pattern identification, artificial intelligence, networking, and other technologies. This paper provides an overview of VR and AR technologies. It highlights tracking, interaction techniques, and display technology as key AR technologies, whereas immersive, semi-immersive, and non-immersive are the leading technologies of VR. It discusses the various use cases of VR and AR.","","979-8-3503-0816-7","10.1109/GCITC60406.2023.10425860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10425860","Augmented reality;Virtual reality;Immersion","Human computer interaction;Image analysis;Computer simulation;Auditory system;Information technology;Artificial intelligence;Augmented reality","","6","","42","IEEE","18 Apr 2024","","","IEEE","IEEE Conferences"
"Stepping over Obstacles with Augmented Reality based on Visual Exproprioception","A. Luchetti; E. Parolin; I. Butaslac; Y. Fujimoto; M. Kanbara; P. Bosetti; M. D. Cecco; H. Kato","University of Trento, Italy; University of Trento, Italy; Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; University of Trento, Italy; University of Trento, Italy; University of Trento, Italy; Nara Institute of Science and Technology, Japan",2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"16 Dec 2020","2020","","","96","101","The purpose of this study is to analyze the different kinds of ex- proprioceptive visual cues on an Augmented Reality (AR) system during gait exercise, on top of understanding which cues provide the best visualizations in stepping over obstacles. The main problem for users is to understand the position of virtual objects relative to themselves. Since visual exproprioception provides information about the body position in relation to the environment, it has the possibility to yield positive effects with regards to position control and gait biomechanics in the AR system. This research was born as part of the collaboration with the staff of Takanohara Central Hospital in Japan. Twenty-seven individuals were invited to take part in the user study to test three visual interfaces. The task of the mentioned user study involves making the subjects cross and avoid virtual obstacles of different heights that come from different directions. The AR application was implemented in the experiment by using the Head-Mounted Display (HMD) Microsoft HoloLens. Data obtained from the experiment revealed that the interface projected in front of the user from a third-person point of view resulted to improvements in terms of posture, visual stimuli, and safety.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288475","Augmented Reality;Exproprioception;HoloLens;Rehabilitation;Obstacle crossing","Visualization;Three-dimensional displays;Avatars;Two dimensional displays;Resists;Task analysis;Augmented reality","","6","","18","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Survey of Annotations in Extended Reality Systems","Z. Borhani; P. Sharma; F. R. Ortega","Colorado State University, Fort Collins, CO, USA; University of Florida, Gainesville, FL, USA; Colorado State University, Fort Collins, CO, USA",IEEE Transactions on Visualization and Computer Graphics,"1 Jul 2024","2024","30","8","5074","5096","Annotation in 3D user interfaces such as Augmented Reality (AR) and Virtual Reality (VR) is a challenging and promising area; however, there are not currently surveys reviewing these contributions. In order to provide a survey of annotations for Extended Reality (XR) environments, we conducted a structured literature review of papers that used annotation in their AR/VR systems from the period between 2001 and 2021. Our literature review process consists of several filtering steps which resulted in 103 XR publications with a focus on annotation. We classified these papers based on the display technologies, input devices, annotation types, target object under annotation, collaboration type, modalities, and collaborative technologies. A survey of annotation in XR is an invaluable resource for researchers and newcomers. Finally, we provide a database of the collected information for each reviewed paper. This information includes applications, the display technologies and its annotator, input devices, modalities, annotation types, interaction techniques, collaboration types, and tasks for each paper. This database provides a rapid access to collected data and gives users the ability to search or filter the required information. This survey provides a starting point for anyone interested in researching annotation in XR environments.","1941-0506","","10.1109/TVCG.2023.3288869","NSF(grant numbers:2327569,2238313,2223432,2223459,2106590,2016714,2037417,1948254); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10160139","Annotation;augmented reality;extended reality;immersive technologies;virtual reality","Annotations;X reality;Virtual reality;Surveys;Collaboration;Bibliographies;Three-dimensional displays","","6","","162","IEEE","23 Jun 2023","","","IEEE","IEEE Journals"
"Sustainable Internet of Musical Things: Strategies to Account for Environmental and Social Sustainability in Network-Based Interactive Music Systems","R. Masu; N. Merendino; A. Rodã; L. Turchet","Computational Media and Art, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Department of Information Engineering, University of Padova, Padua, Italy; Department of Information Engineering, University of Padova, Padua, Italy; Department of Information Engineering and Computer Science, University of Trento, Trento, Italy",IEEE Access,"8 May 2024","2024","12","","62818","62833","The use of internet-based and networking technology in computer music systems has greatly increased in the past few years. Such efforts fall in the remits of the emerging filed of the Internet of Musical Things (IoMusT), the extension of the Internet of Things paradigm to the musical domain. Given the increasing importance of connected devices in the musical domain, it is essential to reflect on the relationship between such systems and sustainability at the environmental and social levels. In this paper, we address this aspect from two perspectives: 1) how to design IoMusT systems in a sustainable way, and 2) how IoMusT systems can support sustainability. To this end, we relied on three lenses, combining literature from green IoT (lens 1), Sustainable HCI (lens 2), and the Sustainable Development Goals from the United Nations (lens 3). By combining these three lenses, we developed five strategies for a sustainable IoMusT, which are extensively presented and discussed providing critical reflections.","2169-3536","","10.1109/ACCESS.2024.3393468","Italian Ministry of University and Research, Programma Operativo Nazionale Scholarship(grant numbers:DOT1487343-5); Project(grant numbers:DM 1061-2021,RI 2014-2020); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10508587","IoT;IoMusT;sustainability;SDG;HCI;green IoT","Sustainable development;Green products;Music;Internet of Things;Computer generated music","","6","","139","CCBYNCND","25 Apr 2024","","","IEEE","IEEE Journals"
"Investigating the Effects of Avatarization and Interaction Techniques on Near-field Mixed Reality Interactions with Physical Components","R. Venkatakrishnan; R. Venkatakrishnan; R. Canales; B. Raveendranath; C. C. Pagano; A. C. Robb; W. -C. Lin; S. V. Babu","University of Florida, USA; University of Florida, USA; Clemson University, USA; Clemson University, USA; Department of Psychology, Clemson University, USA; School of Computing at Clemson University, USA; Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan; School of Computing at Clemson University, USA",IEEE Transactions on Visualization and Computer Graphics,"19 Apr 2024","2024","30","5","2756","2766","Mixed reality (MR) interactions feature users interacting with a combination of virtual and physical components. Inspired by research investigating aspects associated with near-field interactions in augmented and virtual reality (AR & VR), we investigated how avatarization, the physicality of the interacting components, and the interaction technique used to manipulate a virtual object affected performance and perceptions of user experience in a mixed reality fundamentals of laparoscopic peg-transfer task wherein users had to transfer a virtual ring from one peg to another for a number of trials. We employed a 3 (Physicality of pegs) X 3 (Augmented Avatar Representation) X 2 (Interaction Technique) multi-factorial design, manipulating the physicality of the pegs as a between-subjects factor, the type of augmented self-avatar representation, and the type of interaction technique used for object-manipulation as within-subjects factors. Results indicated that users were significantly more accurate when the pegs were virtual rather than physical because of the increased salience of the task-relevant visual information. From an avatar perspective, providing users with a reach envelope-extending representation, though useful, was found to worsen performance, while co-located avatarization significantly improved performance. Choosing an interaction technique to manipulate objects depends on whether accuracy or efficiency is a priority. Finally, the relationship between the avatar representation and interaction technique dictates just how usable mixed reality interactions are deemed to be.","1941-0506","","10.1109/TVCG.2024.3372050","US National Science Foundation (CISE IIS HCC)(grant numbers:2007435); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10458376","Mixed Reality;Self-Avatars;Interactions in MR;Tangible entities","Task analysis;Virtual reality;Mixed reality;End effectors;Visualization;Motor drives;Avatars","","6","","84","IEEE","4 Mar 2024","","","IEEE","IEEE Journals"
"Augmented/Mixed Reality Technologies Supporting Digital Surgery","K. Móga; D. B. O. Boesl; T. Haidegger","Doctoral School, Óbuda University/Semmelweis University; Hochschule der Bayerischen Wirtschaft (HDBW), Robotic & AI Governance Foundation; University Research and Innovation Center (EKIK), ÓU",2021 IEEE 19th International Symposium on Intelligent Systems and Informatics (SISY),"26 Oct 2021","2021","","","183","189","The operating room of the future implements a broad set of digital technologies, aimed to improve the quality of care, optimize patient outcome and enhance usability of existing surgical tools. While analyzing and visualizing surgical data and available digital information anytime on demand become a key piece of the modern surgical workflow, their integration remained difficult until the recent advancements of augmented/mixed reality technologies, applications and devices. This systematic review aims to collect and compare outcomes of the most recent (2019–21) articles on the topic of Augmented Reality (AR) and Mixed Reality (MR) used in the medical domain, focusing on surgical practice. The usability of heads-up holographic technology is getting more and more attention through the years on this field too, but comparisons of used devices and benchmarking are still missing. As further technological improvements are still ongoing, possible standards are required to guide future research and applications of AR/MR from surgical trainee assessment to situation awareness (SA). With examining existing recent studies this review could take a possible first step towards the intention of unified standardisation.","1949-0488","978-1-6654-1380-0","10.1109/SISY52375.2021.9582533","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9582533","Augmented Reality;Mixed Reality;Blended Realiy;Data Visualization;Surgery;Medicine;Intraoperative Use","Systematics;Surgery;Data visualization;Mixed reality;Tools;Usability;Intelligent systems","","6","","61","IEEE","26 Oct 2021","","","IEEE","IEEE Conferences"
"CAVEStudy: an infrastructure for computational steering in virtual reality environments","L. Renambot; H. E. Bal; D. Germans; H. J. W. Spoelder","Division of Mathematics and Computer Science, Vrije University, Amsterdam, Netherlands; Division of Physics and Astronomy, Vrije University, Amsterdam, Netherlands; Division Physics and Astronomy, Vrije University, Amsterdam, Netherlands; Division Physics and Astronomy, Vrije University, Amsterdam, Netherlands",Proceedings the Ninth International Symposium on High-Performance Distributed Computing,"6 Aug 2002","2000","","","239","246","We present the CAVEStudy system that enables scientists to interactively steer a simulation from a virtual reality (VR) environment. No modification to the source code is necessary. CAVEStudy allows interactive and immersive analysis of a simulation running on a remote computer. Using a high-level description of the simulation, the system generates the communication layer (based on CAVERN-Soft) needed to control the execution and to gather data at runtime. We describe three case-studies implemented with CAVEStudy: soccer simulation, diode laser simulation and molecular dynamics.","1082-8907","0-7695-0783-2","10.1109/HPDC.2000.868655","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=868655","","Virtual reality;Computational modeling;Virtual environment;Computer simulation;Analytical models;Communication system control;Data visualization;Supercomputers;Collaboration;Mathematics","","6","","28","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"“May I Speak?”: Multi-Modal Attention Guidance in Social VR Group Conversations","G. Lee; D. Y. Lee; G. -M. Su; D. Manocha","University of Maryland, College Park, US; Dolby Laboratories, US; Dolby Laboratories, US; University of Maryland, College Park, US",IEEE Transactions on Visualization and Computer Graphics,"19 Apr 2024","2024","30","5","2287","2297","In this paper, we present a novel multi-modal attention guidance method designed to address the challenges of turn-taking dynamics in meetings and enhance group conversations within virtual reality (VR) environments. Recognizing the difficulties posed by a confined field of view and the absence of detailed gesture tracking in VR, our proposed method aims to mitigate the challenges of noticing new speakers attempting to join the conversation. This approach tailors attention guidance, providing a nuanced experience for highly engaged participants while offering subtler cues for those less engaged, thereby enriching the overall meeting dynamics. Through group interview studies, we gathered insights to guide our design, resulting in a prototype that employs light as a diegetic guidance mechanism, complemented by spatial audio. The combination creates an intuitive and immersive meeting environment, effectively directing users' attention to new speakers. An evaluation study, comparing our method to state-of-the-art attention guidance approaches, demonstrated significantly faster response times ($p < 0.001$), heightened perceived conversation satisfaction ($p < 0.001$), and preference ($p < 0.001$) for our method. Our findings contribute to the understanding of design implications for VR social attention guidance, opening avenues for future research and development.","1941-0506","","10.1109/TVCG.2024.3372119","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10462901","Social VR;Attention Guidance;Multi-modal Interaction;Group Conversations;Turn-taking","Oral communication;Visualization;Prototypes;Interviews;Virtual environments;Time factors;Spatial audio","","6","","65","IEEE","7 Mar 2024","","","IEEE","IEEE Journals"
"Supporting scientific analysis within collaborative problem solving environments","V. R. Watson","NASA Ames Research Center, USA",Proceedings of the 34th Annual Hawaii International Conference on System Sciences,"7 Aug 2002","2001","","","9 pp.","","This paper first lists some features of scientific analysis tools that are important for effective analysis in CPSEs (collaborative problem solving environments). Next, design criteria for achieving these features are presented. Then requirements for a CPSE architecture to support these design criteria are listed. Some proposed architectures for CPSEs are reviewed and their capabilities to support these design criteria are discussed. The most popular architecture for remote application sharing, the ITU (International Telecommunication Union) T.120 architecture, does not support highly interactive, dynamic, high resolution graphics. A popular scientific analysis tool that conforms to the design criteria has been integrated into a collaborative environment and tested for effectiveness. The tests showed that the tool was highly effective for both synchronous and asynchronous collaborative analyses.","","0-7695-0981-9","10.1109/HICSS.2001.927227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=927227","","Collaborative work;Computer graphics;Performance analysis;Testing;Computer architecture;Collaborative tools;NASA;Tellurium;Video sharing;Computer displays","","6","","29","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"Virtual Workspace Positioning Techniques during Teleportation for Co-located Collaboration in Virtual Reality using HMDs","Y. Zhang; H. Nguyen; N. Ladevèze; C. Fleury; P. Bourdot","CNRS, LISN, VENISE team, University Paris-Saclay, Orsay, France; LISN, VENISE Team, University Paris-Saclay, Orsay, France; CNRS, LISN, VENISE team, University Paris-Saclay, Orsay, France; Lab-STICC, UMR CNRS 6285, IMT Atlantique, Brest, France; CNRS, LISN, VENISE team, University Paris-Saclay, Orsay, France",2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),"20 Apr 2022","2022","","","674","682","In many collaborative virtual reality applications, co-located users often have their relative position in the virtual environment matching the one in the real world. The resulting spatial consistency facilitates the co-manipulation of shared tangible props and enables the users to have direct physical contact with each other. However, these applications usually exclude their individual virtual navigation capability, such as teleportation, as it may break the spatial configuration between the real and virtual world. As a result, the users can only explore the virtual environment of approximately similar size and shape compared to their physical workspace. Moreover, their individual tasks with unlimited virtual navigation capability, which often take part in a continuous workflow of a complex collaborative scenario, have to be removed due to this constraint. This work aims to help overcome these limits by allowing users to recover spatial consistency after individual teleportation in order to re-establish their position in the current context of the collaborative task. We use a virtual representation of the user’s shared physical workspace and develop two different techniques to position it in the virtual environment. The first technique allows one user to fully position the virtual workspace, and the second approach enables concurrent positioning by equally integrating the input from all the users. We compared these two techniques in a controlled experiment in a virtual assembly task. The results show that allowing two users to manipulate the workspace significantly reduced the time they spent negotiating the position of the future workspace. However, the inevitable conflicts in simultaneous co-manipulation were also a little confusing to them.","2642-5254","978-1-6654-9617-9","10.1109/VR51125.2022.00088","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9756747","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Human-centered computing;Collaborative interaction","Training;Three-dimensional displays;Navigation;Shape;Avatars;Collaboration;Virtual environments","","5","","40","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Beyond the Screen: An Exploration of Theoretical Foundations and Paradigms in Human-Computer Interface Design","U. A. Usmani; M. U. Usmani","Universiti Teknologi Petronas, Persiaran UTP, Seri Iskandar, Perak, Malaysia; Universiti Malaysia Pahang, Kuantan, Pahang, Malaysia","2023 International Conference on Ambient Intelligence, Knowledge Informatics and Industrial Electronics (AIKIIE)","22 Jan 2024","2023","","","1","7","This paper delves into the multifaceted landscape of Human-Computer Interface (HCI) design, meticulously exploring the foundational theories and cutting-edge paradigms that form the backbone of the digital user experience. It skillfully synthesizes profound insights gleaned from seminal works, including Norman's cognitive model and Fitts' law, as well as delving into socio-technical theories such as Activity Theory and Distributed Cognition. These collective theories illuminate the intricate tapestry of human cognition, motor control, and the dynamic interactions between individuals, technology, and their environment. Furthermore, this paper rigorously analyzes the frontiers of HCI through emerging paradigms like natural user interfaces and affective computing, underlining the paramount importance of user-centered design principles in fostering empathy, inclusivity, and accessibility. By comprehensively exploring and elucidating the theoretical foundations of HCI, this work aspires to invigorate innovative, user-centric design approaches, thus enriching the future of human-computer interactions and enhancing the overall user experience within the digital realm.","","979-8-3503-1646-9","10.1109/AIKIIE60097.2023.10390262","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10390262","Human-Computer Interface (HCI) Design;User Experience;Foundational Theories;Emerging Paradigms;User-Centered Design","Human computer interaction;Industrial electronics;Affective computing;Motor drives;Shape;Computational modeling;User centered design","","5","","61","IEEE","22 Jan 2024","","","IEEE","IEEE Conferences"
"A Survey on the Metaverse Aspects and Opportunities in Education","J. BenedettDörr; L. BeatrysRuizAylon","Manna Research Group, Federal University of Paraná; Manna Research Group, State University of Maringá, Maringá, Brazil",2023 International Conference on Intelligent Metaverse Technologies & Applications (iMETA),"31 Oct 2023","2023","","","1","8","Technological evolution has brought forth the Metaverse, a virtual environment that challenges the boundary between physical and digital reality. This work explores its potential impact on education, delving into scientific publications that elucidate its applications in teaching and learning. The Metaverse presents a third space and emerges as a pertinent medium for communication, collaboration, and exploration, with the potential to reshape education. This study aims to comprehend how the Metaverse can enhance the educational experience of teaching and learning while identifying associated challenges and potentialities. Through an analysis of specialized literature, it probes the ways in which this technology can effectively foster immersive approaches in education. With a focus on perspectives offered by scientific publications, the study strives to examine the potential applications of the Metaverse in the educational context, seeking not only to elevate the educational experience but also to identify the inherent opportunities and challenges inherent in this approach.","","979-8-3503-2845-5","10.1109/iMETA59369.2023.10294573","National Council for Scientific and Technological Development (CNPq); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10294573","Metaverse;education;immersive;student-centered;exponential technology","Surveys;Metaverse;Education;Collaboration;Probes","","5","","79","IEEE","31 Oct 2023","","","IEEE","IEEE Conferences"
"Metaverse Unbound: A Survey on Synergistic Integration Between Semantic Communication, 6G, and Edge Learning","M. Z. Aloudat; A. Aboumadi; A. Soliman; H. A. Al-Mohammed; M. Al-Ali; A. Mahgoub; M. Barhamgi; E. Yaacoub","Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Department of Computer Science and Engineering, Qatar University, Doha, Qatar",IEEE Access,"7 Apr 2025","2025","13","","58302","58350","With a focus on edge learning, blockchain, sixth generation (6G) wireless systems, semantic communication, and large language models (LLMs), this survey paper examines the revolutionary integration of cutting-edge technologies within the metaverse. This thorough examination highlights the critical role these technologies play in improving realism and user engagement on three main levels: technical, virtual, and physical. While the virtual layer focuses on building immersive experiences, the physical layer highlights improvements to the user interface through augmented reality (AR) goggles and virtual reality (VR) headsets. Blockchain-powered technical layer enables safe, decentralized communication. The survey highlights how the metaverse has the potential to drastically change how people interact in society by exploring applications in a variety of fields, such as immersive education, remote work, and entertainment. Concerns about privacy, scalability, and interoperability are raised, highlighting the necessity of continued study to realize the full potential of the metaverse. For scholars looking to broaden the reach and significance of the metaverse in the digital age, this paper is a useful tool.","2169-3536","","10.1109/ACCESS.2025.3555753","Qatar National Library; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10945362","Metaverse;semantic communication;6G wireless systems;edge learning;blockchain technology;large language models (LLMs);extended reality (XR);digital twin technology","Metaverse;Surveys;Semantic communication;6G mobile communication;Blockchains;Digital twins;Large language models;Wireless communication;Systematic literature review;Internet","","5","","309","CCBY","28 Mar 2025","","","IEEE","IEEE Journals"
"Agent-level optimal LQG control of dynamically decoupled systems with processing delays","M. Kashyap; L. Lessard","University of Wisconsin–Madison, Madison, WI, USA; University of Wisconsin–Madison, Madison, WI, USA",2020 59th IEEE Conference on Decision and Control (CDC),"11 Jan 2021","2020","","","5980","5985","We consider the problem of controlling a set of dynamically decoupled plants where the plants' subcontrollers communicate with each other according to a fixed and known network topology. We assume the communication to be instantaneous but there is a fixed processing delay associated with incoming transmissions. We provide explicit closed-form expressions for the optimal decentralized controller under these communication constraints and using standard LQG assumptions for the plants and cost function. Although this problem is convex, it is challenging due to the irrationality of continuous-time delays and the decentralized information-sharing pattern. We show that the optimal subcontrollers each have an observer-regulator architecture containing LTI and FIR blocks and we characterize the signals that subcontrollers should transmit to each other across the network.","2576-2370","978-1-7281-7447-1","10.1109/CDC42340.2020.9303979","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9303979","","Delays;Finite impulse response filters;Matrix decomposition;Linear systems;Time-domain analysis;Standards;Process control","","5","","22","IEEE","11 Jan 2021","","","IEEE","IEEE Conferences"
"Describing a view alignment framework in 3D Tele-immersion systems","K. Venkatraman; S. Raghuraman; B. Prabhakaran","University of Texas at Dallas, USA; University of Texas at Dallas, USA; University of Texas at Dallas, USA",2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW),"3 Oct 2013","2013","","","1","4","A collaborative 3D Tele-immersion (3DTI) system consists of multiple sensor devices sending streams of data to and from each other. We consider the data streams produced from Microsoft Kinect cameras here. A single camera produces large volumes of data every second. A large bandwidth and low network delay is required to support the streaming of large amounts of data in near real time in order to provide a good quality of experience (QoE), High network delay over the Internet causes a view disparity between the multiple sites and an inter-stream disparity between two streams from the same site. Both these issues hinder the QoE. We address these issues here and provide our solutions for it. We touch upon an interpolation based scheme which uses redundant data from the Kinect sensors to only send minimal amounts of data every second. We introduce a framework to put this interpolation scheme to effective use and to measure and minimize the view and inter-stream disparities with multiple sites using a time vector based solution.","","978-1-4799-1604-7","10.1109/ICMEW.2013.6618272","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618272","Synchronization;3D Tele-Immersion;Stereovision Cameras;Networking","Skeleton;Rendering (computer graphics);Delays;Synchronization;Vectors;Cameras;Three-dimensional displays","","5","","9","IEEE","3 Oct 2013","","","IEEE","IEEE Conferences"
"StuckInSpace: Exploring the Difference Between Two Different Mediums of Play in a Multi-Modal Virtual Reality Game","Y. -D. Malinov; D. E. Millard; T. Blount","University of Southampton, Southampton, United Kingdom; University of Southampton, Southampton, United Kingdom; University of Southampton, Southampton, United Kingdom",2021 IEEE Virtual Reality and 3D User Interfaces (VR),"10 May 2021","2021","","","501","510","With the rising popularity of Virtual Reality (VR), there is also a rising interest in co-located multiplayer experiences, as people want to play VR games together with their friends. As having multiple VR headsets is out of reach to the average consumer, we need to look into different possible ways of including multiple people in this play space. We have created a multi-modal co-located multiplayer VR game, Stuck in Space, that introduces a second player in two ways - one with a PC (the baseline that a lot of current games do), as well as a tracked Phone that can be used as a ‘window into the virtual world’. We have conducted a user study (n = 24) where we explore the difference in immersion and co-presence between the two versions using two questionnaires (IPQ and NMMoSP), as well as a thematic analysis of the subsequent interview data, from which 5 themes emerged. Surprisingly, we found no significant difference in co-presence or immersion based on the quantitative data. However, the qualitative analysis helps reveal one of the main reasons why that is - maintaining a mental model of the real world while also being in the virtual world makes it harder for the person wearing the headset to immerse themselves and feel co-present. From these themes and sub-themes we theorize that each of the two versions has positives and negatives that cancel each other out in the quantitative data, and for there to be a difference we would need to accentuate or change certain elements of the game. The results show that introducing a second player through a Phone is not detrimental in terms of co-presence and immersion and that it is a viable way of doing so, although certain design considerations would have to be taken into account to minimize the negatives.","2642-5254","978-1-6654-1838-6","10.1109/VR50410.2021.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417671","Human-centered computing-User studies;Human-centered computing-Virtual reality;Human-centered computing-Collaborative interaction;Applied computing-Computer games","Headphones;Three-dimensional displays;Games;Resists;Virtual reality;User interfaces;Mobile handsets","","5","","47","IEEE","10 May 2021","","","IEEE","IEEE Conferences"
"Autonomous virtual humans and social robots in telepresence","N. M. Thalmann; Z. Yumak; A. Beck","Institute for Media Innovation, Nanyang Technological University, Singapore; Institute for Media Innovation, Nanyang Technological University, Singapore; Institute for Media Innovation, Nanyang Technological University, Singapore",2014 IEEE 16th International Workshop on Multimedia Signal Processing (MMSP),"20 Nov 2014","2014","","","1","6","Telepresence refers to the possibility of feeling present in a remote location through the use of technology. This can be achieved by immersing a user to a place reconstructed in 3D. The reconstructed place can be captured from the real world or can be completely virtual. Another way to realize telepresence is by using robots and virtual avatars that act as proxies for real people. In case a human-mediated interaction is not needed or not possible, the virtual human and the robot can rely on artificial intelligence to act and interact autonomously. In this paper, these forms of telepresence are discussed, how they are related and different from each other and how autonomy takes place in telepresence. The paper concludes with an overview of the ongoing research on autonomous virtual humans and social robots conducted in the BeingThere centre.","","978-1-4799-5896-2","10.1109/MMSP.2014.6958836","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6958836","","Three-dimensional displays;Avatars;Virtual environments;Robot sensing systems;Real-time systems;Speech","","5","","52","IEEE","20 Nov 2014","","","IEEE","IEEE Conferences"
"Investigating User Embodiment of Inverse-Kinematic Avatars in Smartphone Augmented Reality","E. Makled; F. Weidner; W. Broll",Ilmenau University of Technology; Ilmenau University of Technology; Ilmenau University of Technology,2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"27 Dec 2022","2022","","","666","675","Smartphone Augmented Reality (AR) has already provided us with a plethora of social applications such as Pokemon Go or Harry Potter Wizards Unite. However, to enable smartphone AR for social applications similar to VRChat or AltspaceVR, proper user tracking is necessary to accurately animate the avatars. In Virtual Reality (VR), avatar tracking is rather easy due to the availability of hand-tracking, controllers, and HMD whereas smartphone AR has only the back-(and front) camera and IMUs available for this task. In this paper we propose ARIKA, a tracking solution for avatars in smartphone AR. ARIKA uses tracking information from ARCore to track the users hand position and to calculate a pose using Inverse Kinematics (IK). We compare the accuracy of our system against a commercial motion tracking system and compare both systems with respect to sense of agency, self-location, and body-ownership. For this, 20 participants observed their avatars in an augmented virtual mirror and executed a navigation and a pointing task. Our results show that participants felt a higher sense of agency and self location when using the full body tracked avatar as opposed to IK avatars. Interestingly and in favor of ARIKA, there were no significant differences in body-ownership between our solution and the full-body tracked avatars. Thus, ARIKA and it’s single-camera approach is valid solution for smartphone AR applications where body-ownership is essential.","1554-7868","978-1-6654-5325-7","10.1109/ISMAR55827.2022.00084","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9995369","Augmented reality;inverse kinematics;embodiment;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems-Artificial;augmented;and virtual realities; I.4. S [Image Processing and Computer Vision]: Scene Analysis-Tracking","Tracking;Navigation;Avatars;Multimedia systems;Collaboration;Resists;Cameras","","5","","62","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"PetPresence: Investigating the Integration of Real-World Pet Activities in Virtual Reality","N. Xiong; Q. Liu; K. Zhu","School of Creative Media, City University of Hong Kong, China; School of Creative Media, City University of Hong Kong, China; School of Creative Media, City University of Hong Kong and CityU Shenzhen Research Institute, China",IEEE Transactions on Visualization and Computer Graphics,"19 Apr 2024","2024","30","5","2559","2569","For VR interaction, the home environment with complicated spatial setup and dynamics may hinder the VR user experience. In particular, pets' movement may be more unpredictable. In this paper, we investigate the integration of real-world pet activities into immersive VR interaction. Our pilot study showed that the active pet movements, especially dogs, could negatively impact users' performance and experience in immersive VR. We proposed three different types of pet integration, namely semitransparent real-world portal, non-interactive object in VR, and interactive object in VR. We conducted the user study with 16 pet owners and their pets. The results showed that compared to the baseline condition without any pet-integration technique, the approach of integrating the pet as interactive objects in VR yielded significantly higher participant ratings in perceived realism, joy, multisensory engagement, and connection with their pets in VR.","1941-0506","","10.1109/TVCG.2024.3372095","National Natural Science Foundation of China(grant numbers:62172346); CityU Contract Research_RMGS(grant numbers:9239092); CityU Donations for Research Projects_RMGS(grant numbers:9229075); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10458353","Virtual Reality;Haptics;Distractions;Presence;Pet","Virtual reality;Visualization;Virtual environments;Urban areas;Three-dimensional displays;Portals;Media","Humans;Animals;Dogs;Pilot Projects;Computer Graphics;Virtual Reality;Movement","5","","56","IEEE","4 Mar 2024","","","IEEE","IEEE Journals"
"Collaborative Forensic Autopsy Documentation and Supervised Report Generation Using a Hybrid Mixed-Reality Environment and Generative AI","V. Pooryousef; M. Cordeil; L. Besançon; R. Bassed; T. Dwyer","Monash University, USA; University of Queensland, USA; Linköping University, Sweden; Monash University, USA; Monash University, USA",IEEE Transactions on Visualization and Computer Graphics,"10 Oct 2024","2024","30","11","7452","7462","Forensic investigation is a complex procedure involving experts working together to establish cause of death and report findings to legal authorities. While new technologies are being developed to provide better post-mortem imaging capabilities—including mixed-reality (MR) tools to support 3D visualisation of such data—these tools do not integrate seamlessly into their existing collaborative workflow and report authoring process, requiring extra steps, e.g. to extract imagery from the MR tool and combine with physical autopsy findings for inclusion in the report. Therefore, in this work we design and evaluate a new forensic autopsy report generation workflow and present a novel documentation system using hybrid mixed-reality approaches to integrate visualisation, voice and hand interaction, as well as collaboration and procedure recording. Our preliminary findings indicate that this approach has the potential to improve data management, aid reviewability, and thus, achieve more robust standards. Further, it potentially streamlines report generation and minimise dependency on external tools and assistance, reducing autopsy time and related costs. This system also offers significant potential for education. A free copy of this paper and all supplemental materials are available at https://osf.io/ygfzx.","1941-0506","","10.1109/TVCG.2024.3456212","University of Toronto; Knut and Alice Wallenberg Foundation(grant numbers:KAW 2019.0024); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10669822","Forensic autopsy;report generation;documentation;mixed reality;generative AI","Autopsy;Virtual reality;Forensics;Biomedical imaging;Collaboration;Computed tomography;Documentation","Humans;Autopsy;Imaging, Three-Dimensional;Documentation;Computer Graphics;Workflow;Augmented Reality;Artificial Intelligence;User-Computer Interface;Forensic Sciences","5","","82","IEEE","9 Sep 2024","","","IEEE","IEEE Journals"
"Exploring the Design Space for Immersive Embodiment in Dance","D. Lottridge; R. Weber; E. -R. McLean; H. Williams; J. Cook; H. Bai",University of Auckland; University of Auckland; University of Auckland; University of Auckland; University of Auckland; University of Auckland,2022 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),"20 Apr 2022","2022","","","93","102","There are decades of work investigating how to support users in inhabiting avatars’ bodies in immersive experiences, however we are still learning about how Virtual Reality (VR) can support people in more deeply inhabiting their own bodies. Over the course of five action research workshops, we explored the design space for how VR can support feeling embodied and generating movement within a dance context. We explored design factors and participants’ experiences within: games intended to stimulate physical movement, single player and multiplayer 3D painting, 360 live video, and custom real-time audio and visual feedback based on motion capture. We found that participants spontaneously explored collaboration including synchronous, asynchronous, remote and collocated. Where there were mismatches between visual and kinesthetic perceptions, participants explored how to recalibrate, alternate between, and integrate perceptions. Participants were compelled to explore their control of real-time effects, which led to rich movement generation as we iterated through the effects’ parameters. We present a design space that encapsulates the insights of our action research, with axes for control, collaboration, auditory and visual feedback. We discuss implications for the support of immersive embodiment in dance.","2642-5254","978-1-6654-9617-9","10.1109/VR51125.2022.00027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9756774","virtual reality;embodiment;creativity support;dance","Visualization;Three-dimensional displays;Conferences;Collaboration;Virtual reality;Games;Aerospace electronics","","5","","52","IEEE","20 Apr 2022","","","IEEE","IEEE Conferences"
"Laying the Foundation for Augmented Reality in Music Education","L. Nijs; B. Behzadaval","University of Luxembourg, Belval, Esch-sur-Alzette, Luxembourg; University of Luxembourg, Belval, Esch-sur-Alzette, Luxembourg",IEEE Access,"24 Jul 2024","2024","12","","100628","100645","Since the beginning of humankind, the use and development of technologies have played an essential role in enhancing human abilities and creating new possibilities for action and expression. As such, new technologies have captured the imaginations of educational scholars and practitioners. One of the latest developments in the evolution of digital technologies is the ability to enrich or “augment” reality with digital content, thereby establishing an “augmented reality” (AR). This perspective article aims to promote and support advancements in the domain of music educational AR by proposing an interdisciplinary knowledge base and its concrete translation into design ideas for further developments in this emerging domain. We explore the integration of Augmented Reality (AR) into Music Education (MusEdAR), highlighting its nascent state and potential for innovation. First, we provide an overview of the current state-of-the-art, focusing on what types of AR are used, what visual content is digitally added to the learning experience, and how movement is integrated. Next, we discuss how to expand the MusEdAR domain. We argue for a solid interdisciplinary knowledge base to advance the design and use of MusEdAR applications and present themes such as embodied learning or developing creativity and associated theories. Based on these theories, we presented practical design ideas.","2169-3536","","10.1109/ACCESS.2024.3427698","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10597574","Augmented reality;creativity;embodied learning;music education;participatory sense-making","Visualization;Music;Augmented reality;Focusing;Extended reality;Computers;Avatars;Creativity;Educational programs","","5","","150","CCBYNCND","15 Jul 2024","","","IEEE","IEEE Journals"
"A new collaborative infrastructure: SCAPE","Hong Hua; L. D. Brown; Chunyu Gao; N. Ahuja","Beckman Institute, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA; Beckman Institute, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA; Beckman Institute, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA; Beckman Institute, University of Illinois, Urbana-Champaign, Urbana-Champaign, IL, USA","IEEE Virtual Reality, 2003. Proceedings.","2 Apr 2003","2003","","","171","179","This paper presents a multi-user collaborative infrastructure, SCAPE (an acronym for Stereoscopic Collaboration in Augmented and Projective Environments), which is based on recent advancement in head-mounted projective display (HMPD) technology. The SCAPE mainly consists of a 3'/spl times/5' interactive workbench and a 12'/spl times/12'/spl times/9' room-sized walk-through display environment, multiple head-tracked HMPDs, multi-modality interface devices, and a generic application-programming interface (API) designed to coordinate the components. The infrastructure provides a shared space in which multiple users can simultaneously interact with a 3D synthetic environment from their individual viewpoints. We detail the SCAPE implementation and include an application example that demonstrates major interface and cooperation features.","1087-8270","0-7695-1882-6","10.1109/VR.2003.1191136","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1191136","","Collaboration;Virtual reality","","4","22","30","IEEE","2 Apr 2003","","","IEEE","IEEE Conferences"
"Cross-Reality Interaction and Collaboration in Museums, Education, and Rehabilitation","X. Xia; J. Liang; R. Zhao; Z. Zhao; M. Wu; Y. Li; H. -N. Liang","School of Advanced Technology, Xi’an Jiaotong-Liverpool University; School of Advanced Technology, Xi’an Jiaotong-Liverpool University; School of Advanced Technology, Xi’an Jiaotong-Liverpool University; School of Advanced Technology, Xi’an Jiaotong-Liverpool University; School of Advanced Technology, Xi’an Jiaotong-Liverpool University; School of Advanced Technology, Xi’an Jiaotong-Liverpool University; School of Advanced Technology, Xi’an Jiaotong-Liverpool University",2023 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"4 Dec 2023","2023","","","815","820","With Virtual Reality Head-Mounted Displays (VR HMDs) establishing themselves as a potent platform for collaborative tasks, their cross-reality capability and cross-domain applicability remain largely unexplored. This study intends to assess the effectiveness of cross-reality collaboration systems using a VR HMD and a desktop PC across three disparate sectors: museum visiting, chemical education, and assisted rehabilitation. The systems were designed to support social interactions and scenario-specific collaborative tasks. Evaluation of the systems showed above-average system usability and user experience. By probing into these varied environments, our study offers a comprehensive understanding of the applicability of such collaborative cross-reality systems in real scenarios, potentially fostering more immersive, efficient, and enriching multi-field applications of cross-reality technologies.","2771-1110","979-8-3503-2891-2","10.1109/ISMAR-Adjunct60411.2023.00180","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10322225","virtual reality;museums;education;rehabilitation","Training;Head-mounted displays;Chemistry;Collaboration;Resists;Museums;User experience","","4","","26","IEEE","4 Dec 2023","","","IEEE","IEEE Conferences"
"Toward an enhanced mutual awareness in asymmetric CVE","M. Le Chénéchal; S. Chalmé; T. Duval; J. Royan; V. Gouranton; B. Arnaldi","IRT b<>com, Cesson-Sévigné, France; IRT b<>com, Cesson-Sévigné, France; Télécom Bretagne, LabSTICC, Brest, France; IRT b<>com, Cesson-Sévigné, France; INSA Rennes, IRISA/Inria, Rennes, France; IRT b<>com, Cesson-Sévigné, France",2015 International Conference on Collaboration Technologies and Systems (CTS),"20 Aug 2015","2015","","","233","240","Collaborative Virtual Environments (CVEs) aim at providing several users with a consistent shared virtual world. In this work, we focus on the lack of mutual awareness that may appear in many situations and we evaluate different ways to present the distant user and his actions in the Virtual Environment (VE) in order to understand his perception and cognitive process. Indeed, an efficient collaboration involves not only the good perception of some objects but their meaning too. This second criterion introduces the concept of distant analysis that could be a great help in improving the understanding of distant activities. For this work, we focus on a common case consisting in estimating accurately the time at which a distant user analyzed the meaning of a remotely pointed object. Thus, we conduct some experiments to evaluate the concept and compare different techniques for implementing this new awareness feature in a CVE. Amongst others, results show that expertise of the users influences on how they estimate the distant activity and the type of applied strategies.","","978-1-4673-7648-8","10.1109/CTS.2015.7210428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7210428","Awareness in Collaboration Systems;Cognitive and Psychological Issues in Collaboration;Shared Virtual Reality and Applications;Coordination;Cooperation and Collaboration","Estimation;Collaboration;Virtual environments;Accuracy;Electronic mail;Context;Time measurement","","4","","16","IEEE","20 Aug 2015","","","IEEE","IEEE Conferences"
"Towards Augmented Reality user interfaces in 3D media production","M. Krichenbauer; G. Yamamoto; T. Taketomi; C. Sandor; H. Kato","Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology; Interactive Media Design Laboratory, Nara Institute of Science and Technology",2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"6 Nov 2014","2014","","","23","28","The idea of using Augmented Reality (AR) user interfaces (UIs) to create 3D media content, such as 3D models for movies and games has been repeatedly suggested over the last decade. Even though the concept is intuitively compelling and recent technological advances have made such an application increasingly feasible, very little progress has been made towards an actual real-world application of AR in professional media production. To this day, no immersive 3D UI has been commonly used by professionals for 3D computer graphics (CG) content creation. In this paper, we are first to publish a requirements analysis for our target application in the professional domain. Based on a survey that we conducted with media professionals, the analysis of professional 3D CG software, and professional training tutorials, we identify these requirements and put them into the context of AR UIs. From these findings, we derive several interaction design principles that aim to address the challenges of real-world application of AR to the production pipeline. We implemented these in our own prototype system while receiving feedback from media professionals. The insights gained in the survey, requirements analysis, and user interface design are relevant for research and development aimed at creating production methods for 3D media production.","","978-1-4799-6184-9","10.1109/ISMAR.2014.6948405","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6948405","Augmented Reality;Immersive Authoring","Three-dimensional displays;Collaboration;Software;Media;Production;Solid modeling;Navigation","","4","4","27","IEEE","6 Nov 2014","","","IEEE","IEEE Conferences"
"Can We Revitalize Interventional Healthcare with AI-XR Surgical Metaverses?","A. Qayyum; M. Bilal; M. Hadi; P. Capik; M. Caputo; H. Vohra; A. Al-Fuqaha; J. Qadir","University of Glasgow, Glasgow, United Kingdom; University of the West of England, Bristol, England; Information Technology University, Lahore, Pakistan; University of the West of England, Bristol, England; Bristol Heart Institute, University of Bristol, Bristol, England; Bristol Heart Institute, University of Bristol, Bristol, England; Hamad Bin Khalifa University, Doha, Qatar; Qatar University, Doha, Qatar","2023 IEEE International Conference on Metaverse Computing, Networking and Applications (MetaCom)","6 Oct 2023","2023","","","496","503","Recent advancements in technology, particularly in machine learning (ML), deep learning (DL), and the metaverse, offer great potential for revolutionizing surgical science. The combination of artificial intelligence and extended reality (AI-XR) technologies has the potential to create a surgical metaverse, a virtual environment where surgeries can be planned and performed. This paper aims to provide insight into the various potential applications of an AI-XR surgical metaverse and the challenges that must be addressed to bring its full potential to fruition. It is important for the community to focus on these challenges to fully realize the potential of the AI-XR surgical metaverses. Furthermore, to emphasize the need for secure and robust AI-XR surgical metaverses and to demonstrate the real-world implications of security threats to the AI-XR surgical metaverses, we present a case study in which the ""an immersive surgical attack"" on incision point localization is performed in the context of preoperative planning in a surgical metaverse.","","979-8-3503-3333-6","10.1109/MetaCom57706.2023.00091","Qatar University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10271784","metaverse;augmented reality;mixed reality;virtual reality;surgical science;artificial intelligence","Location awareness;Technological innovation;Metaverse;Extended reality;Surgery;Medical services;Planning","","4","","20","IEEE","6 Oct 2023","","","IEEE","IEEE Conferences"
"Generative AI Meets Virtual Reality: A Comprehensive Survey on Applications, Challenges, and Future Direction","F. Rahimi; A. Sadeghi-Niaraki; S. -M. Choi","Department of Computer Science and Engineering and Convergence Engineering for Intelligent Drone, XR Research Center, Sejong University, Seoul, South Korea; Department of Computer Science and Engineering and Convergence Engineering for Intelligent Drone, XR Research Center, Sejong University, Seoul, South Korea; Department of Computer Science and Engineering and Convergence Engineering for Intelligent Drone, XR Research Center, Sejong University, Seoul, South Korea",IEEE Access,"4 Jun 2025","2025","13","","94893","94909","The integration of generative artificial intelligence (AI) with virtual reality (VR) is reshaping how immersive environments are designed, personalized, and experienced. Unlike traditional VR systems that rely on static and pre-scripted content, Generative VR leverages AI-driven content generation, multimodal interaction, and contextual adaptation to create dynamic virtual spaces. This paper presents a comprehensive survey of the core components, applications, and challenges associated with Generative VR. It explores its transformative impact across education, healthcare, industrial training, entertainment, and emerging fields such as environmental conservation and virtual tourism. While Generative VR enhances user engagement and realism, it also introduces critical challenges, including computational scalability, ethical concerns, AI explainability, and real-time performance constraints. The paper further identifies key research gaps and future directions, such as AI-driven multi-user collaboration, cognitive load management, and cross-domain interoperability. By addressing these challenges and advancing the integration of AI with VR, Generative VR has the potential to reshape human-computer interaction, unlocking new possibilities for creativity, accessibility, and intelligent virtual ecosystems.","2169-3536","","10.1109/ACCESS.2025.3574779","ITRC Support Program(grant numbers:IITP-2025-RS-2022-00156354); Metaverse Support Program to Nurture the Best Talents; the Ministry of Science and ICT of Korea and the Institute of Information and Communications Technology Planning and Evaluation (IITP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11017583","Generative AI;virtual reality;generative VR","Generative AI;Artificial intelligence;Virtual reality;Three-dimensional displays;Real-time systems;Scalability;Ethics;Bibliometrics;Technological innovation;Surveys","","4","","85","CCBY","29 May 2025","","","IEEE","IEEE Journals"
"Integration of mobile robot into virtual reality testbed","D. Gracanin; M. Matijasevic; A. Chandrupatla; P. Subramaniam; S. L. V. Ippagunta","Virtual Reality and Multimedia Laboratory Robotics and Automation Laboratory, University of Southwestern Louisiana, Lafayette, LA, USA; Virtual Reality and Multimedia Laboratory Robotics and Automation Laboratory, University of Southwestern Louisiana, Lafayette, LA, USA; Virtual Reality and Multimedia Laboratory Robotics and Automation Laboratory, University of Southwestern Louisiana, Lafayette, LA, USA; Virtual Reality and Multimedia Laboratory Robotics and Automation Laboratory, University of Southwestern Louisiana, Lafayette, LA, USA; Virtual Reality and Multimedia Laboratory Robotics and Automation Laboratory, University of Southwestern Louisiana, Lafayette, LA, USA",Proceedings of the 1998 IEEE International Conference on Control Applications (Cat. No.98CH36104),"6 Aug 2002","1998","2","","1302","1306 vol.2","A combination of virtual reality and networking technologies has provided a basis for virtual environments distributed over a communication network. This paper presents a framework for using these technologies in robotics applications. A robot can be controlled in a virtual environment by creating a corresponding virtual robot and by merging virtual with actual data. In case of mobile robots, the integration of path planning, navigation and motion control is more difficult. In addition, collision avoidance and safety constraints are emphasized. A case study, based on Nomad 200 mobile robot, is presented and some communication issues are discusses.","","0-7803-4104-X","10.1109/CCA.1998.721671","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=721671","","Mobile robots;Virtual reality;Testing;Virtual environment;Communication networks;Robot control;Communication system control;Merging;Path planning;Navigation","","4","","13","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Designing virtual spaces to support learning communities and e-collaboration","C. Bouras; E. Giannaka; T. Tsiatsos","Computer Engineering and Informatics Department, University of Patras, Greece; Research Academic Computer Technology Institute, Greece; Research Academic Computer Technology Institute, Greece",Fifth IEEE International Conference on Advanced Learning Technologies (ICALT'05),"19 Sep 2005","2005","","","328","332","In this paper, we present the design principles for virtual spaces and two different tools as solutions for supporting e-collaboration and multi-user communication in Web-based learning communities. The first solution, called Virtual Conference, is designed and implemented in the framework of the VirRAD European project. It is a two-dimensional space where participants represented by their photos can use various e-collaboration tools. The second solution, called EVE Training Area, is a three-dimensional space where participants, represented by 3D humanoid avatars, can use a variety of e-collaboration tools. This paper describes the functionality provided by both tools, compares them, and proposes cases for exploiting each solution.","2161-377X","0-7695-2338-2","10.1109/ICALT.2005.113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1508691","","Space technology;Management training;Avatars;Videoconference;Design engineering;Informatics;Navigation;Electronic learning;User interfaces;Virtual reality","","4","","7","IEEE","19 Sep 2005","","","IEEE","IEEE Conferences"
"InfrActables: Multi-User Tracking System for Interactive Surfaces","C. Ganser; A. Steinemann; A. Kunz","ICVR-Innovation Center Virtual Reality, Swiss Federal Institute of Technology, Zurich, Switzerland; ICVR-Innovation Center Virtual Reality, Swiss Federal Institute of Technology, Zurich, Switzerland; ICVR-Innovation Center Virtual Reality, Swiss Federal Institute of Technology, Zurich, Switzerland",IEEE Virtual Reality Conference (VR 2006),"7 Aug 2006","2006","","","253","256","We present InfrActables, a wireless technology for human computer interaction devices. It allows multiple users to interact simultaneously on back-projection displays. It recognizes each device’s position, orientation, and identification, but also enables the tools to communicate their states to the application that the user interacts with. This makes it possible to build complex interaction devices for direct manipulation with buttons, sliders, and other input capabilities. The technology was developed for a computer-supported environment, allowing multiple users to interact simultaneously on a surface using multiple styli and other user input devices. The principle of operation is not limited to two-dimensional surfaces, three-dimensional user input devices can also profit from its advantages.","2375-5334","1-4244-0224-7","10.1109/VR.2006.86","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1667653","Tracking;User Input Devices;Single Display Groupware;Stylus-based User Input Device","Computer displays;Collaborative work;Technological innovation;Virtual reality;Computer graphics;Collaborative software;Elbow;Delay;Human computer interaction;Application software","","4","3","14","IEEE","7 Aug 2006","","","IEEE","IEEE Conferences"
"Optimal Control of Multi-Agent Systems With Processing Delays","M. Kashyap; L. Lessard","Department of Electrical and Computer Engineering, Northeastern University, Boston, MA, USA; Department of Mechanical and Industrial Engineering, Northeastern University, Boston, MA, USA",IEEE Transactions on Automatic Control,"29 Jul 2024","2024","69","8","5141","5153","In this article, we consider a cooperative control problem involving a heterogeneous network of dynamically decoupled continuous-time linear plants. The (output-feedback) controllers for each plant may communicate with each other according to a fixed and known transitively closed directed graph. Each transmission incurs a fixed and known time delay. We provide an explicit closed-form expression for the optimal decentralized controller and its associated cost under these communication constraints and standard linear quadratic Gaussian assumptions for the plants and cost function. We find the exact solution without discretizing or otherwise approximating the delays. We also present an implementation of each subcontroller that is efficiently computable, and is composed of standard finite-dimensional linear time-invariant and finite impulse response components, and has an intuitive observer–regulator architecture reminiscent of the classical separation principle.","1558-2523","","10.1109/TAC.2023.3346934","National Science Foundation(grant numbers:2136317); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10373880","Cooperative control;decentralized control;delay systems;optimal control","Delays;Optimal control;Transfer functions;Linear systems;Finite impulse response filters;Costs;Vehicle dynamics","","4","","37","IEEE","25 Dec 2023","","","IEEE","IEEE Journals"
"Seamless Crime Scene Reconstruction in Mixed Reality for Investigation Training: A Design and Evaluation Study","M. Albeedan; H. Kolivand; R. Hammady; T. Saba","School of Computer Science and Mathematics, Faculty of Engineering and Technology, Liverpool John Moores University (LJMU), Liverpool, U.K.; School of Computer Science and Mathematics, Faculty of Engineering and Technology, Liverpool John Moores University (LJMU), Liverpool, U.K.; Department of Computer Science and Electronic Engineering, University of Essex, Colchester, U.K.; Artificial Intelligence and Data Analytics (AIDA) Laboratory, College of Computer and Information Sciences (CCIS), Prince Sultan University, Riyadh, Saudi Arabia",IEEE Transactions on Learning Technologies,"10 Jan 2024","2024","17","","856","873","Investigation training at the real crime scene is a critical component of forensic science education. However, bringing young investigators to real crime scenes is costly and faces significant challenges. Mixed reality (MR) is one of the most evolving technologies that provides unlimited possibilities for practical activities in the education sector. This article aims to propose and evaluate a novel design of an MR system using Microsoft HoloLens 2.0 that is tailored to work in a spatial 3-D-scanned and reconstructed crime scene. The system was designed to be a cost-effective experience that helps young Kuwaiti police officers enhance their investigation skills. The proposed system has been evaluated through system usability, user interaction, and performance metrics quantitatively via 44 young police officers and qualitatively using the think-aloud protocols via a group of experts. Both groups showed positive levels of usability, user interaction, and overall satisfaction, with minimal negative feedback. Based on the positive feedback, the system will be taken into the commercialization stage in the future. Despite the high cost of the MR device, experts stated that the system is needed as an essential tool for crime scene education and investigation practices.","1939-1382","","10.1109/TLT.2023.3337107","Ministry of Interior, Kuwait; Kuwait Police Academy, Kuwait; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10329468","3-D reconstruction;3-D scanning;crime investigation;crime scene;investigation training;mixed reality (MR);photogrammetry;usability","Training;Three-dimensional displays;Mixed reality;Forensics;Virtual reality;Usability;Law enforcement","","4","","80","Crown","28 Nov 2023","","","IEEE","IEEE Journals"
"Cybersecurity threats in Virtual Reality Environments: A Literature Review","A. N. Ramaseri-Chandra; P. Pothana","Computer Science, Academic Success, Turtle Mountain College, Belcourt, North Dakota, USA; College of Engineering and Mines, University of North Dakota, Grand Forks, North Dakota, USA",2024 Cyber Awareness and Research Symposium (CARS),"13 Dec 2024","2024","","","1","7","As VR technology gains popularity and is increasingly being adopted across various domains, there is a need to comprehensively understand potential cyber threats in immersive environments and effectively confront them with utmost urgency. This literature review is a timely endeavor, aiming to comprehensively analyze existing research on cyber threats specific to VR systems, their underlying causes, and potential mitigation strategies. The review encompasses a wide range of VR applications, including gaming, training simulations, virtual workspaces, and educational settings. The paper first examines the unique attack surfaces and vulnerabilities such as sensor manipulation, data injection, and avatar hijacking introduced by VR systems. It then details the severe consequences of successful cyber attacks, including privacy breaches, significant financial losses, and even physical harm to users from existing literature. This review synthesizes findings from academic literature, industry reports, and relevant case studies to provide a comprehensive understanding of the current cyber threat landscape in VR environments. It not only highlights the gaps in existing research, such as the lack of standardized security protocols for VR systems and the limited understanding of user behaviors that may lead to vulnerabilities, but also outlines future directions for developing robust security frameworks, standards, and best practices to ensure the safe and secure adoption of VR technology across various applications. Furthermore, the review explores the challenges of implementing effective security measures in VR environments, considering factors like real-time processing, user immersion, and hardware limitations.","","979-8-3503-8641-7","10.1109/CARS61786.2024.10778838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778838","Virtual Reality (VR);Cyber threats;Immersive environments;Attack surfaces;Vulnerabilities;Mitigation strategies","Training;Industries;Solid modeling;Protocols;Reviews;Tracking;Prevention and mitigation;Avatars;Bibliographies;Privacy breach","","4","","47","IEEE","13 Dec 2024","","","IEEE","IEEE Conferences"
"Evaluating 6G Network Technology Principles and Applications: A Review","J. Singh; G. Singh; N. Vashisht","Department of CSE, Chandigarh University, Mohali, India; Department of CSE, Chandigarh University, Mohali, India; Department of ECE, Chandigarh University, Mohali, India","2023 3rd International Conference on Smart Generation Computing, Communication and Networking (SMART GENCON)","28 Feb 2024","2023","","","1","5","As mobile communication networks continue to evolve rapidly, the fifth-generation (5G) technology is already transforming industries and societies worldwide. However, as data demands soar and new applications emerge, the need for even more advanced and efficient wireless networks becomes evident. This review paper presents an in-depth exploration of the emerging sixth-generation (6G) network technology, which is anticipated to revolutionize the way we interact with the digital world. By reviewing the current state of 6G research, this paper aims to offer valuable insights for researchers, practitioners, policymakers, and industry stakeholders, fostering a deeper understanding of the technology's capabilities and challenges and paving the way for the successful deployment of 6G networks in the near future.","","979-8-3503-1912-5","10.1109/SMARTGENCON60755.2023.10442029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10442029","6G Mobile Communication Network;6G Network Architecture;6G Applications;5G vs 6G","6G mobile communication;Industries;Technological innovation;Reviews;5G mobile communication;Wireless networks;Stakeholders","","3","","21","IEEE","28 Feb 2024","","","IEEE","IEEE Conferences"
"The Essentials: A Comprehensive Survey to Get Started in Augmented Reality","F. M. Haneefa; A. Shoufan; E. Damiani","Center for Cyber-Physical Systems (C2PS), Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Center for Cyber-Physical Systems (C2PS), Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates; Center for Cyber-Physical Systems (C2PS), Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates",IEEE Access,"13 Aug 2024","2024","12","","109012","109070","Augmented Reality (AR) has experienced a significant resurgence in popularity and interest in recent years. Despite numerous surveys and reviews in the field, information remains scattered and challenging to consolidate for newcomers. This paper addresses this gap with a comprehensive study of AR’s state of the art. We begin with an introduction to AR and related terminologies. We then describe three enabling of AR and four enhancing technologies. A survey then covers different types of commercial AR hardware with detailed specifications and elaborations. We then address AR software and discuss its basic and advanced features, mapping them to software with feature matrices. Based on a thematic literature analysis, we extract a comprehensive set of guidelines for developing AR solutions into seven themes, from ideation to best practices for implementation and deployment. Finally, we explore some essential challenges in the field of AR. This paper serves as an essential resource for those looking to understand what AR is, what is needed to get started, how to approach development, and what the future holds for AR. By consolidating essential information and providing a solid foundation, this paper aims to help researchers and developers capitalize on the current cycle of interest in AR.","2169-3536","","10.1109/ACCESS.2024.3439442","Center for Cyber-Physical Systems at Khalifa University of Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10623629","Augmented reality (AR);survey;tutorial","Surveys;Augmented reality;Cameras;Three-dimensional displays;Transforms;Reviews;Visualization","","3","","358","CCBY","6 Aug 2024","","","IEEE","IEEE Journals"
"An Implementation of Multi-Modal Game Interface Based on PDAs","K. -B. Lee; J. -H. Kim; K. -S. Hong","School of Information and Communication Engineering, Sungkyunkwan University, South Korea; School of Information and Communication Engineering, Sungkyunkwan University, South Korea; School of Information and Communication Engineering, Sungkyunkwan University, South Korea","5th ACIS International Conference on Software Engineering Research, Management & Applications (SERA 2007)","4 Sep 2007","2007","","","759","768","In computer animation and interactive computer games, gesture and speech modality can be a powerful interface between humans and computers. In this paper, we propose a personal digital assistant (PDA)- based multi-modal network game interface using speech, gesture and touch sensations. To verify the validity of our approach, we implement a multi-modal omok game using TCP/IP on a PDA network. The experimental results using the proposed multi-modal network game resulted in an average recognition rate of 97.4%, and accordingly as the weaknesses of uni- modality, such as incorrect command processing by recognition error, are offset by the strengths of other modalities, the user can enjoy a more interactive mobile game interface in any given environment.","","978-0-7695-2867-0","10.1109/SERA.2007.48","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297013","","Personal digital assistants;Application software;Speech recognition;Mice;Virtual environment;Computer interfaces;Power engineering computing;Computer vision;Virtual reality;Interactive systems","","3","10","15","IEEE","4 Sep 2007","","","IEEE","IEEE Conferences"
"Motion duplication control for distributed dynamic systems by natural damping","Joono Cheong; Seungjin Lee; Jung Kim","Department of Control & Instrumentation Engineering, Korea University, Jochiwon, South Korea; Department of Control & Instrumentation Engineering, Korea University, Jochiwon, South Korea; Department of Mechanical Engineering, KAIST, Daejeon, South Korea","Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006.","26 Jun 2006","2006","","","387","392","This paper proposes a motion duplication control scheme, which not only synchronizes motions between two distributed separate dynamic systems but also perfectly preserves prescribed dynamics. The proposed scheme sophisticatedly utilizes two-way Smith predictor to meet the simultaneous purposes. Closed loop behavior is mathematically investigated, and stability via natural damping and robustness are analyzed over the system, by examining the characteristic equation with delay components. Ways to compute robust stability margins are presented under the uncertainties in plant dynamics and amount of delay. Numerical simulations are presented to verify the theoretical results proposed in this paper","1050-4729","0-7803-9505-0","10.1109/ROBOT.2006.1641742","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1641742","","Distributed control;Motion control;Control systems;Damping;Robust stability;Delay;Stability analysis;Equations;Uncertainty;Numerical simulation","","3","","13","IEEE","26 Jun 2006","","","IEEE","IEEE Conferences"
"Interactive spatial copy wall for embodied interaction in a virtual co-existing space","S. Wesugi; K. Ishikawa; N. Suzuki; Y. Miwa","School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; Graduate school of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; Graduate school of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan",RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),"10 Jan 2005","2004","","","265","270","A significance of a sense of togetherness or co-existence among remote communication partners has been pointed out in computer mediated communication area. In order to create such a co-existing situation, the presence of remote partners should be expressed at each place. In this paper, we propose a novel tangible human avatar display for remote interpersonal communication based on an idea integrating a video avatar expressing the fidelity of the embodiment, with a robot avatar as the physical presence. As a result, we devised ""interactive spatial copy wall"" (""ISCW"") system, which represents a three-dimensional shape of remote partners with hundreds of movable pipes and remote participants can interact with each other by operating these movable pipes. We design this system based on modularity and we construct ""ISCW"" system of 192 cylinder modules. At the end, we discuss a possibility of this tangible avatar display when compared to the previous communication systems.","","0-7803-8570-5","10.1109/ROMAN.2004.1374771","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1374771","","Avatars;Humans;Computer mediated communication;Shape;Educational institutions;Computer displays;Robots;Engine cylinders;Psychology;Mood","","3","","18","IEEE","10 Jan 2005","","","IEEE","IEEE Conferences"
"How Visualising Emotions Affects Interpersonal Trust and Task Collaboration in a Shared Virtual Space","A. Jing; M. Frederick; M. Sewell; A. Karlson; B. Simpson; M. Smith",Meta Reality Labs; Meta Reality Labs; Meta Reality Labs; Meta Reality Labs; Meta Reality Labs; Meta Reality Labs,2023 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"4 Dec 2023","2023","","","849","858","Emotion is dynamic. Changes in emotion can be hard to process during face-to-face interaction, yet transferring them into a shared virtual space becomes more challenging. This research first explores nine visual representations to amplify emotions in a virtual space, leading to a bi-directional emotion-sharing system (FeelMoji i/o). The second study investigates the effect of explicit emotion-sharing in interpersonal trust and task collaboration through three conditions - verbal only, verbal+positive visual, and verbal+honest visual using FeelMoji through the proposal of a framework of four factors (usability, integrity, behaviour, and collaboration). The results indicate that FeelMoji yields frequent emotion consensus as task milestones and positive interdependent behaviours between collaborators, which help develop conversations, affirm decision-making, and build familiarity and trust between strangers. Moreover, we discuss how our study can inspire future investigation in human-AI agent behaviours and large-scale multi-user virtual environments.","2473-0726","979-8-3503-2838-7","10.1109/ISMAR59233.2023.00100","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10316483","VR;Emotion;Empathic Computing;visualization","Visualization;Emotion recognition;Decision making;Collaboration;Virtual environments;Bidirectional control;Proposals","","3","","53","IEEE","4 Dec 2023","","","IEEE","IEEE Conferences"
"Enabling Customizable Workflows for Industrial AR Applications","V. Lehrbaum; A. MacWilliams; J. Newman; N. Sudharsan; S. Bien; K. Karas; C. Eghtebas; S. Weber; G. Klinker",Siemens Technology; Siemens Technology; Siemens Technology; Siemens Technology; TU Munich; TU Munich; TU Munich; TU Munich; TU Munich,2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"27 Dec 2022","2022","","","622","630","Augmented Reality (AR) is increasingly considered for use in real industrial applications [8]. In our industrial research lab at Siemens Technology, we are continuously discussing suitable AR scenarios in business sectors involving power plants, wind turbine plants, and oil and gas factories. We have developed a company-internal AR system architecture, Hololayer, which provides AR facilities in a reusable manner to development engineers such that they can build their own AR applications for their specialized use cases. The integration of AR technology into industrial processes encounters many complex issues: we need to adhere to many safety, security and quality guarantees while also adapting quickly to the rapidly changing state of the art of AR devices (HMDs, tablets). To increase flexibility, it might be good to integrate Hololayer with one of the open frameworks that have recently been proposed [11], [29], [38]. Yet, care must be taken when converting an already existing, large company-owned framework like Hololayer to such platforms. Some of the proposed standardized APIs and communication protocols may be difficult to abide by, without requiring significant rewriting efforts or even violating company-internal regulations. In this paper, we report on our efforts to combine Hololayer with one such platform, Ubi-Interact [38]. This is a collaboration between Siemens technology and the FAR group at TU Munich. After exemplary descriptions of typical application scenarios, we present the underlying principles of Hololayer to support this range of applications. We then describe rudimentary concepts of Ubi-Interact, followed by an elaboration on the efforts to combine both systems for a selected application scenario and a discussion of the results achieved thus far.","1554-7868","978-1-6654-5325-7","10.1109/ISMAR55827.2022.00079","Siemens; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9995600","Human-centered computingUbiquitous and mobile computing;Human-centered computingHuman computer interaction (HCI)Interaction ParadigmsMixed / Augmented Reality","Protocols;Collaboration;Systems architecture;Regulation;Production facilities;Wind turbines;Safety","","3","","39","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"A Scoping Review of the Metaverse for Software Engineering Education: Overview, Challenges, and Opportunities","F. A. Fernandes; C. M. L. Werner","Systems Engineering and Computer Science Program Federal University of Rio de Janeiro Rio de Janeiro, Brazil; Systems Engineering and Computer Science Program Federal University of Rio de Janeiro Rio de Janeiro, Brazil",Presence,"1 Nov 2023","2022","31","","107","146","In the Software Engineering Education (SEE) context, virtual worlds have been used in order to improve learning outcomes. However, there is a gap in the literature in order to characterize the use of the Metaverse for SEE. The objective of this work is to characterize the state of the art of virtual worlds in SEE and provide research opportunities and challenges to fill the limitations found. We conducted a systematic literature review, and we established 8 research questions that guided the study, as well as performed data extraction. We report on 17 primary studies that deal mostly with immersive experiences in SEE. The results show some limitations: few Software Engineering (SE) topics are covered; most applications simulate environments and do not explore new ways of viewing and interacting; there is no interoperability between virtual worlds; learning analysis techniques are not applied; and biometric data are not considered in the validations of the studies. Although there are virtual worlds for SEE, the results indicate the need to develop mechanisms in order to support the integration between virtual worlds. Therefore, based on the findings of the review, we established a set of components grouped by 5 layers to enable the Metaverse for SEE through fundamental requirements. We hope that this work can motivate promising research in order to foster immersive learning experiences in SE through the Metaverse.","1054-7460","","10.1162/pres_a_00371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10304630","","","","3","","","","1 Nov 2023","","","MIT Press","MIT Press Journals"
"Evaluation of Smart Home Systems and Novel UV-Oriented Solution for Integration, Resilience, Inclusiveness & Sustainability","L. Geng; X. Xiong; Z. Liu; Y. Wei; Z. Lan; M. Hu; M. Guo; R. Xu; H. Yuan; Z. Yang; H. Li; Y. Zhou; H. Jin; C. Wang; L. Jiao; Q. Huang; F. Wang; K. Sung; C. Zhang; M. Sun; X. Li; N. Zhang; X. Liu; R. Gao; H. Wang; J. Jiang; Y. Tao; L. Zhang; S. Cao; L. Zhou; X. Duan; Y. Fang","Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Northeastern University, Boston, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; University of Cambridge, Cambridge, UK; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Ningbo University, Ningbo, China; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA; Gannon University, Erie, USA; Universal Village Society, Cambridge, USA; Universal Village Society, Cambridge, USA",2022 6th International Conference on Universal Village (UV),"26 Jul 2023","2022","","","1","386","At present, smart Homes are receiving more attention as they are becoming the predominant space that houses people’s activities. Even though intelligent home appliances are capable of ameliorating residents’ quality of life and decreasing their household workload, current Smart Homes are still limited to providing support and services to satisfy the needs of the aging society, small families, and busy lifestyles.In addition to their limited capability, current Smart Homes lack robustness and resilience and introduce some unexpected new challenges, including waste of energy and resource, safety and security concerns, compatibility, discontinued service due to technology obsolescence, and financial challenges which are further aggravated by the imbalanced development of different regions and communities.In this paper, we first discuss the new trend in people’s lifestyles, the major needs of the current society, and the special requirements for their future homes. We further elaborate on the significance and contribution of existing Smart Home systems, the challenges of Smart Home applications, the importance of human involvement, and future development.We then propose the concept of the UV Smart Home and its general framework and evaluate, from the UV perspective, the current status of the Smart Home system based on the framework of a closed feedback control loop: data acquisition, communication, decision-making, and action, as well as the available technologies relevant to each element of the systems.After that, we explore the information flow and material cycle associated with UV Smart Home systems and study how Smart Homes would be affected by these two major impacting factors: information flow and material cycle. The need for information flow and the current absence of centralized management and disorganized information-sharing practices are discussed. We also propose the concept of hierarchical information fusion, addressing the lack of fusion between data content, temporal and spatial information, data from different sources, and the lack of fusion between different informational layers, such as human know-how and system data. The paper also points out that the material cycle is a key element in Smart Homes as it connects all UV components through the exchange of physical products, energy, and natural resources. We investigate and highlight several issues within the current Smart Home material cycle, ranging from improper handling of hazardous materials and exposed electrical wires to unauthorized access to firearms and improper mixing of cleaning substances. This part also emphasizes the risk of cascading failures in interconnected systems and processes. It underscores the need for improved information management, fusion, and coordination, as well as proper handling of materials and resources to ensure the safety and functionality of the UV Smart Home system.In addition, we propose that an effective Smart Home should take into consideration the interaction between Smart Home subsystems and the other seven smart city subsystems: smart medicine and healthcare, intelligent transportation, urban planning and crowd management, smart energy management, smart city infrastructure, smart environmental protection, smart response system for city emergency, and smart humanity. We identify the categories of information exchanges required for the interactions between UV Smart Home systems and other smart subsystems and how such information would support each other and enhance the performance of other smart subsystems.Moreover, we will be examining how human lifestyle and community dynamics could potentially shape the UV Smart Home concept, with a particular focus on their potential to enhance unique and diverse lifestyles, such as those of vulnerable groups. We will delve into how these smart homes can provide tailored support, catering to specific needs, and creating a more inclusive and supportive living environment. Whether it’s aiding the elderly with health monitoring or assisting people with disabilities through enhanced accessibility features, we’ll explore how smart homes can be a beneficial tool for a wide spectrum of lifestyles. In addition to individual lifestyles, we’ll explore how UV Smart Homes can integrate with and benefit diverse communities. We’ll delve into how these smart homes can provide specialized functions to cater to unique community needs, such as communal healthcare monitoring for elderly communities, or enhanced security features for urban neighborhoods. Furthermore, we’ll discuss how the collective strength of a community can compensate for certain limitations of smart homes, like addressing the digital divide or reinforcing community-wide data security, ultimately working towards a better, more sustainable living experience for all.Lastly, based on the in-depth exploration of the complicated dynamic relationship between multiple impacting factors, we propose a UV-oriented, integrated, resilient, inclusive, and sustainable UV Smart Home framework design to address current imminent challenges and to improve residents’ quality of life through multi-source real-time smart monitoring, hierarchical and context-based data fusion, directed information disclosure within families and communities, “home operating system” featuring life-long learning of users’ dynamic preferences, and smart appliances integration for subject-oriented, event-triggered and coordinated home services and actions.The proposed UV Smart Home system offers a comprehensive solution to the challenges identified in this paper. It addresses the diversity of human needs and lifestyles by structuring an integrated, personalized, and dynamic information package that captures various aspects of residents’ lives. The system incorporates a Multiple-Input-Multiple-Output (MIMO) package of coordinated processes, consisting of seven core functions and six system objectives, to provide personalized services and functionalities for different living groups and communities. By adopting a closed feedback loop, dynamic adaptiveness, and interactive human involvement, the UV Smart Home system aims to be a highly automated, intelligent, and human-controllable system. It leverages machine learning techniques and user feedback to continually update its knowledge base and adapt to changing lifestyles. The system’s coordination and automation capabilities ensure efficient information flow and seamless coordination across sensing, communication, decision-making, and action stages.","","978-1-6654-7477-1","10.1109/UV56588.2022.10185519","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10185519","smart home;vulnerable group support;homeless support;chronic disease management;senior care;independent living;smart energy management;smart infrastructure support;smart response system for urgent situations;smart mobility;smart humanity;information flow;material cycle;smart lifestyle management;smart community user acceptance;Universal Village;smart monitoring;smart activity understanding;human-computer interaction;computer vision;machine learning;safety and security;adversarial attach;reinforcement learning;adaptive control;system theory;dynamic relationship;coordination & automation;closed feedback loop;robustness & resilience;sustainability","Home appliances;Smart cities;Decision making;Smart homes;Medical services;Safety;Older adults","","3","","471","IEEE","26 Jul 2023","","","IEEE","IEEE Conferences"
"Electronic Visualization Laboratory's 50th Anniversary Retrospective: Look to the Future, Build on the Past","A. E. Johnson; L. Renambot; G. E. Marai; D. Tsoupikova; M. E. Papka; L. Long; D. Plepys; J. Talandis; M. D. Brown; J. Leigh; D. J. Sandin; T. A. DeFanti","EVL, University of Illinois Chicago Chicago, IL, USA; EVL, University of Illinois Chicago Chicago, IL, USA; EVL, University of Illinois Chicago Chicago, IL, USA; EVL, University of Illinois Chicago Chicago, IL, USA; EVL, University of Illinois Chicago Chicago, IL; EVL, University of Illinois Chicago Chicago, IL, USA; EVL, University of Illinois Chicago Chicago, IL, USA; EVL, University of Illinois Chicago Chicago, IL, USA; EVL, University of Illinois Chicago 851 S. Morgan St., Room 1120 Chicago, IL 60607-7053; LAVA, University of Hawaii at Manoa Honolulu, HI, USA; EVL, University of Illinois Chicago Chicago, IL, USA; Calit2-Qualcomm Institute UC San Diego San Diego, CA, USA",Presence,"3 Jan 2025","2024","33","","77","127","","1054-7460","","10.1162/pres_a_00421","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10824751","","","","3","","","CCBY","3 Jan 2025","","","MIT Press","MIT Press Journals"
"Personal Tele-Immersion devices","T. DeFanti; D. Sandin; G. Dawe; M. Brown; M. Rawlings; G. Lindahl; A. Johnson; J. Leigh","Electronic Visualization Laboratory, University of Illinois, Chicago, Chicago, IL, USA; Electronic Visualization Laboratory, University of Illinois, Chicago, Chicago, IL, USA; Electronic Visualization Laboratory, University of Illinois, Chicago, Chicago, IL, USA; Electronic Visualization Laboratory, University of Illinois, Chicago, Chicago, IL, USA; Electronic Visualization Laboratory, University of Illinois, Chicago, Chicago, IL, USA; Electronic Visualization Laboratory, University of Illinois, Chicago, Chicago, IL, USA; Electronic Visualization Laboratory, University of Illinois, Chicago, Chicago, IL, USA; Electronic Visualization Laboratory, University of Illinois, Chicago, Chicago, IL, USA",Proceedings. The Seventh International Symposium on High Performance Distributed Computing (Cat. No.98TB100244),"6 Aug 2002","1998","","","198","205","The Electronic Visualization Laboratory (EVL) at the University of Illinois at Chicago (UIC) has partnered with dozens of computational scientists and engineers to create visualization and virtual reality (VR) devices and applications for collaborative exploration of scientific and engineering data. Since 1995, our research and development activities have incorporated emerging high bandwidth networks like the vBNS and the Internet2 in an effort now called Tele-Immersion. As a result of our six years' experience in building first and second generation VR devices to support these applications, we consider third generation VR devices that will provide desktop/office sized displays. Since no current technology is yet configurable with ideal resolution and size, we will first simulate these devices with available parts, and then build more advanced prototypes. We believe that the devices we propose to build using the new display technologies form a set of desirable human/computer interface requirements for successful Tele-Immersion adoption. A goal of this research is to develop clearly compelling prototypes so that these devices can be improved and reproduced by the private sector.","1082-8907","0-8186-8579-4","10.1109/HPDC.1998.709973","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=709973","","Virtual reality;Data visualization;Data engineering;Computer displays;Laboratories;Collaboration;Research and development;Bandwidth;IP networks;Computational modeling","","2","1","24","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Creation and co-share of ""Maai"" (""ma"" - perceptive distance) by the interface employing the embodiment","S. Itai; Y. Miwa","Graduate School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; School of Science and Engineering, Waseda University, Japan",RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),"10 Jan 2005","2004","","","193","198","For establishing a communicative atmosphere, it is indispensably important to create a spatial distance (""ma"" - perceptive distance or ""Maai"" in Japanese). In this research, the ""Kendo"" (Japanese-style fencing) match system using a ""Kendo"" robot (a video character) was employed to investigate a supporting method for the generation of the ""ma"" - perceptive distance in a telecommunication where participants operate their own argents within the virtual space. It was found that a transmission of the rhythmic robot-control signal and representations of the coherency between each rhythmic robot-control signal can support to generate the ""ma"" - perceptive distance with remote opponents. It was also found that a transmission of the rhythmic robot-control signal and the expression of the opponent's existence by the shadow can support to create the ""ma"" - perceptive distance. It was suggested that there was a possibility that the 1/f fluctuation could be related to such a generation of the ""ma"" - perceptive distance. These findings provide us an important design guideline for the telecommunication system where participants operate their own argents within the virtual space.","","0-7803-8570-5","10.1109/ROMAN.2004.1374755","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1374755","","Orbital robotics;Rhythm;Robots;Character generation;Context;Signal generators;Collaboration;Atmosphere;Fluctuations;Guidelines","","2","","10","IEEE","10 Jan 2005","","","IEEE","IEEE Conferences"
"Engaging Engineering Education Through Multi-Sensory Virtual Decision-Making Centers: A Gamified Approach","J. D. Azofeifa; V. Rueda-Castro; L. J. Gonzalez-Gomez; G. M. Chans; P. Caratozzolo; J. Noguez","Institute for the Future of Education, Tecnologico de Monterrey, Monterrey, Mexico; Institute for the Future of Education, Tecnologico de Monterrey, Monterrey, Mexico; Institute for the Future of Education, Tecnologico de Monterrey, Monterrey, Mexico; Institute for the Future of Education, Tecnologico de Monterrey, Monterrey, Mexico; Institute for the Future of Education, Tecnologico de Monterrey, Monterrey, Mexico; School of Engineering and Sciences, Tecnologico de Monterrey, Mexico City, Mexico",2024 IEEE Global Engineering Education Conference (EDUCON),"8 Jul 2024","2024","","","1","5","The article explores the transformative impact of gamification in education, highlighting the integration of theory and practice to create dynamic and engaging learning experiences using multi-sensory virtual reality environments, such as the Multi-Sensory Virtual Decision-Making Center (MVDC). Among the state of the art of gamification, it has been shown that gamification significantly improves students' attention, motivation, and knowledge acquisition, leading to better academic performance. In addition, it promotes the use of new technologies and encourages teamwork. The Multi-sensory Virtual Decision-Making Center facilitates the creation of immersive collaborative virtual environments where multiple decision-makers can participate remotely in real-time without losing the sense of presence, thus providing an enhanced user experience by conducting joint decision-making sessions remotely and in real-time. Therefore, this work proposes a novel approach to engineering education by combining the synergistic potential of gamification and MVDC, improving both the educational experience and the efficiency of remote and real-time collaborative decision-making. This proposal includes the realization of joint exercises in the classroom with the combination of these technological tools. The initial results are encouraging because they offer an improved user experience when performing collaborative gamification exercises in the classroom and promote efficient and engaging real-time remote decision-making. This work will provide valuable insights and recommendations for future research in this dynamic and promising field.","2165-9567","979-8-3503-9402-3","10.1109/EDUCON60312.2024.10578682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10578682","Gamification;Decision-making;Multi-sensory virtual environments;Multimodal interaction;Human-computer interaction;Higher Education;Educational Innovation","Technological innovation;Knowledge acquisition;Decision making;Virtual environments;Real-time systems;User experience;Teamwork","","2","","23","IEEE","8 Jul 2024","","","IEEE","IEEE Conferences"
"Technology Usage For Education: Polytechnic Deaf or Hard-of-Hearing Student","R. H. Abdul Rahim; D. N. Mohd Nizam; N. F. Mohd Naim; A. Baharum","User Experience Group Faculty of Computing and Informatics, Universiti Malaysia Sabah, Kota Kinabalu, Sabah, Malaysia; User Experience Group Faculty of Computing and Informatics, Universiti Malaysia Sabah, Kota Kinabalu, Sabah, Malaysia; User Experience Group Faculty of Computing and Informatics, Universiti Malaysia Sabah, Kota Kinabalu, Sabah, Malaysia; Computing and Information System School of Engineering and Technology, Sunway University, Selangor, Malaysia",2024 IEEE 6th Symposium on Computers & Informatics (ISCI),"12 Sep 2024","2024","","","170","175","This article investigates the application of technology to enhance education for polytechnic deaf or hard-of-hearing (DHH) students. Polytechnic institutions play a crucial role in preparing students for diverse careers through hands-on, practical education. However, DHH students face unique challenges in accessing and fully participating in polytechnic programs. To provide a diverse approach, the technology focusing on visual technology, such as Augmented Reality and Virtual Reality, incorporates crucial components suitable for DHH visual learning modalities. The study uses a mixed-method approach, integrating questionnaires, interviews, and observational data to discover more about DHH lecturers’ and students’ preferred learning methods. 77 DHH Sijil Khas Operasi Katering student from selected three Polytechnic and Community Colleges gave their feedback from questionnaires, and five lecturers were interviewed to get a clearer picture of the current usage of technology among DHH students at polytechnic and community college. Results of the lecturer’s interview suggest that DHH students need visual aids, communication tools, and focus-enhancing resources to help them learn effectively, especially in cooking classes where understanding kitchen equipment and safety is crucial to prevent injuries. Meanwhile, results from DHH students’ questionnaires show students’ interest and prefer to use technology, with 88% agreeing to use technology such as Games, AR, VR and AR Games for their teaching and learning process and to make their learning process more interesting, fun and enjoyable. Integrating the use of technology and information technology as part of the approach of teaching aids to deaf students is hoped to help them to understand better, focus and have more fun in learning.","2996-6752","979-8-3503-5385-3","10.1109/ISCI62787.2024.10668307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10668307","Technology Usage;Deaf student;Hard-of-hearing","Learning systems;Visualization;Education;Focusing;Games;Safety;Interviews","","2","","34","IEEE","12 Sep 2024","","","IEEE","IEEE Conferences"
"Challenges in metaverse in problem-based learning as a game-changing virtual-physical environment for personalized content development","P. K. Dutta; M. Bose; A. Sinha; R. Bhardwaj; S. Ray; S. Roy; K. B. Prakash","School of Engineering and Technology, Amity University Kolkata, Kolkata, India; School of Computer Application, Amity University Kolkata, Kolkata, India; School of Computer Application, Amity University Kolkata, Kolkata, India; Department of Mathematics, Amity University Kolkata, Kolkata, India; Senior Researcher, Petersburg Polytechnic University; Artificial Intelligence & Data Science, Jio Institute, Navi Mumbai, India; Department of Computer Science and Engineering, Konneru Lakshmaih Education Foundation",6th Smart Cities Symposium (SCS 2022),"29 May 2023","2022","2022","","417","421","The benefits and drawbacks of using the metaverse in the field of education are discussed, along with the possibilities and potential issues it will open up. Utilizing the idea of personalised knowledge transfer and the use of an immersive environment to match students' learning pace using horizon classroom, the Metaverse environment can add a new dimension to the field of educational technologies. We have also highlighted the virtualization-based redesign of educational environments using a personalised cloud, which is anticipated to improve learning for students by making it more affordable, collaborative, and useful. The goal is to build a metaversity that can serve as a communication tool for teachers and students anywhere in the world by providing each with an individual avatar. This platform will offer a virtual setting for students to socialise with their friends and peers and receive peer-to-peer learning, which is lacking in the current e-learning environment. The students won't need an entrance score card; instead, they will need critical learning skills to advance and mature.","","978-1-83953-854-4","10.1049/icp.2023.0641","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10137544","","","","2","","","","29 May 2023","","","IET","IET Conferences"
"Utilizing Data Strategy Framework for Retail Business in the Metaverse","P. Tancharoen; W. Pongpech","Graduate School of Applied Statistics, National Institute of Development Administration, Bangkok, Thailand; Graduate School of Applied Statistics, National Institute of Development Administration, Bangkok, Thailand",2023 International Conference on Intelligent Metaverse Technologies & Applications (iMETA),"31 Oct 2023","2023","","","1","8","The emergence of the metaverse has brought about a significant shift in the retail industry as businesses strive to couple from the physical and digital worlds. However, this transition presents challenges in managing the massive and rapidly streaming data originating from the metaverse. In this paper, we explore the business opportunities that the metaverse offers for retail businesses and shed light on the ways to utilize data strategy in metaverse retailing. Our research analyzes the potential metaverse scenarios and the characteristics of metaverse data. We identify these scenarios into three key categories: Decoupled, Semi-coupled, and Tightly coupled. In particular, we highlight the importance of robust data strategies for organizations to effectively handle metaverse data and unlock success in this new realm. As a result, we propose a comprehensive data strategy framework that empowers retail businesses to effectively manage metaverse data, leverage valuable data insights, and make informed decisions at the rapid pace of the metaverse, enabling them to stay competitive in this evolving digital realm.","","979-8-3503-2845-5","10.1109/iMETA59369.2023.10294793","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10294793","Metaverse;Retailing;Data Management;Data Strategy;Metaverse Scenarios;Data Characteristics","Industries;Metaverse;Organizations","","2","","24","IEEE","31 Oct 2023","","","IEEE","IEEE Conferences"
"Nonverbal Communication in Immersive Virtual Reality through the Lens of Presence: A Critical Review","I. Xenakis; D. Gavalas; V. Kasapakis; E. Dzardanova; S. Vosinakis","Department of Product and Systems Design Engineering University of the Aegean Ermoupoli, Syros, Greece; Department of Product and Systems Design Engineering University of the Aegean Ermoupoli, Syros, Greece; Department of Cultural Technology & Communication University of the Aegean Greece; Department of Product and Systems Design Engineering University of the Aegean Ermoupoli, Syros, Greece; Department of Product and Systems Design Engineering University of the Aegean Ermoupoli, Syros, Greece",Presence,"1 Nov 2023","2022","31","","147","187","The emergence of metaverse signifies the transformation of virtual reality (VR) from an isolated digital experience into a social medium, which facilitates new contexts of information exchange and communication. In fact, VR comprises the first-ever computer-mediated communication paradigm that enables the transfer of a broad range of nonverbal cues, including some unique cues which are not even known from face-to-face social encounters. This highlights the urgency to theoretically and experimentally investigate aspects of nonverbal communication (NVC) in immersive virtual environments (IVEs). We provide a critical outlook on empirical studies aiming at widening the discussion on how presence, as a core social factor, is affected by the perception of nonverbal signals and how NVC may be effectively utilized to facilitate social interactions in immersive environments. Our review proposes a classification of the most fundamental cues and modalities of NVC, which we associate with conceptualizations of presence that are more relevant to interpersonal communication. We also investigate the NVC-related aspects that are essential to construct an “active” virtual self-concept and highlight associations among NVC-related aspects through forming a complex web of research topics coming from the field of IVEs. We establish that the key research challenge is to go beyond simply studying nonverbal cues and technological settings in isolation.","1054-7460","","10.1162/pres_a_00387","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10304643","","","","2","","","","1 Nov 2023","","","MIT Press","MIT Press Journals"
"Force skill training with a hybrid trainer model","H. Esen; Ken'ichi Yano; M. Buss","Institute of Automatic Control Engineering, Technische Universität München, Munich, Germany; Deparment of Mechanical and Systems Engineering, Gifu University, Gifu, Japan; Institute of Automatic Control Engineering, Technische Universität München, Munich, Germany",RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication,"15 Aug 2008","2008","","","9","14","In this work, we present novel VR training strategies that incorporate a hybrid trainer model to train force. For modeling the trainer skill, weighted K-means algorithm in parameter space with LS optimization is implemented. The efficiency of the training strategies is verified via user tests in frame of a bone drilling training application. An objective evaluation method based on n dimensional Euclidean distances is introduced to assess user tests results. It is shown that the proposed strategies improve the student skill and accelerate force learning.","1944-9437","978-1-4244-2212-8","10.1109/ROMAN.2008.4600635","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4600635","","Robots","","2","","15","IEEE","15 Aug 2008","","","IEEE","IEEE Conferences"
"Rebuilding Skills Through Collaborative Virtual Reality Drawing: A New Path for Stroke Recovery","S. Oliveira; B. Marques; P. Amorim; B. S. Santos","IEETA, DETI, LASI, University of Aveiro, Aveiro, Portugal; IEETA, DETI, LASI, University of Aveiro, Aveiro, Portugal; CMRRC-Rovisco Pais FCS, University of Beira Interior, Tocha, Portugal; IEETA, DETI, LASI, University of Aveiro, Aveiro, Portugal",2024 IEEE 3rd International Conference on Intelligent Reality (ICIR),"1 May 2025","2024","","","1","8","Conventional rehabilitation methods for stroke rehabilitation face limitations in keeping stroke survivors motivated due to their repetitive and monotonous nature. This lack of engagement can result in physical setbacks and social isolation, as survivors frequently undergo rehabilitation alone, disconnected from others. These isolated experiences further diminish their enthusiasm to continue with therapy, hindering overall recovery. This paper proposes a multi-user Virtual Reality (VR) framework designed for stroke rehabilitation, centering on an immersive drawing experience. The collaborative virtual setting is also designed to encourage participants to perform specific gestures during drawing activities to facilitate upper-limb rehabilitation, with the ultimate goal of enhancing both physical and mental well-being. Additionally, the framework provides healthcare professionals the ability to observe survivors in real time, enabling to modify the rehabilitation process when necessary. This ensures that they can offer immediate support, fostering an encouraging atmosphere for participants immersed in the collaborative drawing sessions. The framework followed a Human-Centered Design (HCD) methodology, incorporating feedback from stroke survivors and healthcare professionals at a rehabilitation center. We conducted an initial user study at the center involving 10 participants, and the results indicate that the collaborative drawing experience fosters motivation, social interaction, and engagement. Furthermore, the drawing techniques were found to be appropriate for stroke survivors, with participants reporting low physical effort, highlighting the framework's suitability for the target population.","","979-8-3315-3442-4","10.1109/ICIR64558.2024.10976842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10976842","Virtual Reality;Stroke Rehabilitation;Collabo-rative Scenarios;Social Interaction;Immersive Drawing","Design methodology;Collaboration;Medical treatment;Atmosphere;Virtual reality;Stroke (medical condition);Real-time systems;Faces","","2","","28","IEEE","1 May 2025","","","IEEE","IEEE Conferences"
"Position Paper: Low-Cost Solutions for Home-Based Healthcare","S. Yamanoor; N. S. Yamanoor","DesignAbly San Jose, CA, USA; DesignAbly Kenmore, NY, USA",2021 International Conference on COMmunication Systems & NETworkS (COMSNETS),"17 Feb 2021","2021","","","709","714","This paper describes approaches to the use of wearables and related monitoring and diagnostic tools to glean and present data to patients and their caregivers in the form of Personal Health Dashboard. Raw data from devices such as fitness watches, blood glucose and blood pressure monitors can be analyzed by machine learning algorithms ensembles over the cloud or at the edge, and the resulting patterns can be presented to allow for actionable responses. The advent of low-cost computational, sensing, monitoring and diagnostic tools allow for cost-effective solutions that can have wide adaptability. The paper draws from prior and ongoing research conducted by the team to present these positions in the advancement of healthcare.","2155-2509","978-1-7281-9127-0","10.1109/COMSNETS51098.2021.9352859","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9352859","Frugal Engineering;Data Analytics;Machine Learning;Healthcare;Dashboarding","Machine learning algorithms;Wearable computers;Medical services;Tools;Sensors;Biomedical monitoring;Monitoring","","2","","43","IEEE","17 Feb 2021","","","IEEE","IEEE Conferences"
"Virtual Frontiers Navigating the Impact and Potential of AR and VR","C. M. Varun; R. P. Anto Kumar; E. Gokila; S. Gayathri; M. Nalini; R. Siva Subramanian","Dept of Computer Science and Business Systems, R.M.K. Engineering College, Kavaraipettai; Dept: of CSE, St. Xavier’s Catholic College of Engineering; Vel Tech Rangarajan Dr.Sagunthala R&D Institute of science and technology and technology; Dept of CSE, S.A Engineering College, Chennai; Dept of CSE, S.A Engineering College; Dept of CSE, RMK College of Engg and Tech",2024 2nd International Conference on Self Sustainable Artificial Intelligence Systems (ICSSAS),"28 Nov 2024","2024","","","1559","1565","This research study aims to investigate the two rapidly growing fields of Augmented Reality and Virtual Reality from their technical aspect, possible uses, issues, and evolution. AR and VR are innovations that have experienced a massive advancement and are prevalent across the entertainment industry and the learning process, healthcare, industries, and more. The study defines the basic concepts and the physical components that form the basis of AR and VR. It then goes over specific examples, using AR in the context of interactive education and its social impact as well as in operations such as surgeries and in factory maintenance while demonstrating the applications of VR in gaming, education and as a therapy tool. A fundamental question of the examined technologies, which is primarily discussed in the paper, includes the distinct challenges it encountered the hardware constraints of the solutions, the problems related to UX and UI, and the privacy-related concerns. Moreover, it covers the morality and social impact of the integration of AR and VR into society. Finally, examining the future directions of the survey, it is revealed that possible technologies and research areas for the next generation of AR and VR applications are discussed. Consequently, this overview seeks to present useful recommendations regarding the current status of four AR and VR technologies and their possible future developments.","","979-8-3503-6841-3","10.1109/ICSSAS64001.2024.10760749","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10760749","Virtual Reality;Augmented Reality;Technology;Gamimg;Education","Training;Ethics;Technological innovation;Entertainment industry;Surgery;Virtual environments;Market research;Hardware;Artificial intelligence;Augmented reality","","2","","15","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"HandyNotes: using the hands to create semantic representations of contextually aware real-world objects","C. Quere; A. Menin; R. Julien; H. -Y. Wu; M. Winckler","CNRS, Inria, I3S, Université Côte d’Azur, Sophia-Antipolis, France; CNRS, Inria, I3S, Université Côte d’Azur, Sophia-Antipolis, France; CNRS, Inria, I3S, Université Côte d’Azur, Sophia-Antipolis, France; Inria, Université Côte d’Azur, Sophia-Antipolis, France; CNRS, Inria, I3S, Université Côte d’Azur, Sophia-Antipolis, France",2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR),"15 Apr 2024","2024","","","265","275","This paper uses Mixed Reality (MR) technologies to provide a seamless integration of digital information in physical environments through human-made annotations. Creating digital annotations of physical objects evokes many challenges for performing (simple) tasks such as adding digital notes and connecting them to real-world objects. For that, we have developed an MR system using the Microsoft HoloLens2 to create semantic representations of contextually-aware real-world objects while interacting with holographic virtual objects. User interaction is enhanced with use of fingers as placeholders for menu items. We demonstrate our approach through two real-world scenarios. We also discuss the challenges for using MR technologies.","2642-5254","979-8-3503-7402-5","10.1109/VR58804.2024.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494192","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Interaction techniques;Gestural input;Graphical user interfaces","Three-dimensional displays;Annotations;Semantics;Mixed reality;Virtual reality;User interfaces;Task analysis","","2","","47","IEEE","15 Apr 2024","","","IEEE","IEEE Conferences"
"Performance evaluation of networked virtual reality services in a gprs network","I. Perovic; Lea Skorin-Kapov; D. Vilendecic","Core Network Department, VIPNet d.o.o., Zagreb, Croatia; Ericsson Nikola Tesla, Research and Development Center, Zagreb, Croatia; Department of Telecommunications, University of Zagreb, Zagreb, Croatia","Proceedings of the 7th International Conference on Telecommunications, 2003. ConTEL 2003.","2 May 2005","2003","1","","359","366","","","953-184-052-0","10.1109/CONTEL.2003.176932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1214669","","Virtual reality;Intelligent networks;Ground penetrating radar;Quality of service;Packet radio networks;Web and internet services;Performance evaluation;Delay;Jitter;Resource management","","2","","15","","2 May 2005","","","IEEE","IEEE Conferences"
"A next generation collaborative system for micro devices assembly","J. Cecil; R. Gunda; A. Cecil-Xavier","Computer Science Department, Oklahoma State University (OSU), Stillwater, Ok; Computer Science Department, Oklahoma State University (OSU), Stillwater, Ok; Eagle Program, Stillwater High School & Soaring, Stillwater, Ok",2017 Annual IEEE International Systems Conference (SysCon),"29 May 2017","2017","","","1","8","This paper discusses the development of an advanced collaborative system to support the assembly of micro devices. The overall system Virtual Reality based assembly analysis environment (VAE) which is part of a larger collaborative framework for the emerging domain of Micro Devices Assembly (MDA). MDA involves the assembly of micron sized devices which cannot be manufactured by Micro electro mechanical systems (MEMS) technologies. The VAE is comprised of several modules including an assembly plan generator, path planner and a network based cyber physical interface which allows it to support collaboration involving distributed users. As the current Internet has several limitations, a major initiative is underway to develop the Next Generation Internet frameworks which can reduce latency, increase the bandwidth of data exchange and support distributed collaboration. VAE has been implemented as part of a national initiative aimed at exploring Next Generation Internet technologies.","2472-9647","978-1-5090-4623-2","10.1109/SYSCON.2017.7934715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7934715","VR simulation;distributed collaborative environment;micro devices assembly;next generation network;internet of things","Collaboration;Manufacturing;Planning;Production facilities;Cloud computing;Solid modeling","","2","","37","IEEE","29 May 2017","","","IEEE","IEEE Conferences"
"AR-Chat: an AR-based instant messaging system","P. Jouet; V. Alleaume; A. Laurent; M. Fradet; T. Luo; C. Baillard","InterDigital, Rennes, France; InterDigital, Rennes, France; InterDigital, Rennes, France; InterDigital, Rennes, France; InterDigital, Rennes, France; InterDigital, Rennes, France",2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"16 Dec 2020","2020","","","153","157","We describe a multi-user system enabling instant messaging in Augmented Reality. A user can get in contact with another one without requiring his/her identification number and can easily localize the person initiating the contact. It is also possible to exchange various types of personal information in a private manner. This innovative type of social interaction can significantly increase consumer interest for AR experiences.","","978-1-7281-7675-8","10.1109/ISMAR-Adjunct51615.2020.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288380","Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Mixed / augmented reality;Computer systems organization;Architectures;Distributed architectures;Client-server architectures","Solid modeling;Three-dimensional displays;Protocols;Prototypes;Instant messaging;Servers;Augmented reality","","2","","16","IEEE","16 Dec 2020","","","IEEE","IEEE Conferences"
"Comparing Avatar and Face-to-Face Collaboration in VR Education: Concept and Preliminary Insights","A. Mayer; K. Kastner; J. Reichwald; J. -R. Chardonnet; J. Ovtcharova","Information Management in Engineering, Karlsruhe Institute of Technology, Karlsruhe, Germany; Virtual Engineering Competence Center, Mannheim University of Applied Sciences, Mannheim, Germany; Virtual Engineering Competence Center, Mannheim University of Applied Sciences, Mannheim, Germany; Arts et Metiers Institute of Technology, LISPEN, HESAM Université, Chalon-sur-Saône, France; Information Management in Engineering, Karlsruhe Institute of Technology, Karlsruhe, Germany",2023 IEEE 2nd German Education Conference (GECon),"31 Oct 2023","2023","","","1","5","Virtual education is gaining prominence, providing opportunities for dynamic interactive content, such as Digital Twins, and novel collaboration modalities, including options for remote classrooms. In this work, we present a concept that leverages Digital Twins for interactive group work in engineering education through the use of Virtual Reality technology. We propose an experimental investigation to compare diverse collaboration alternatives facilitated by Virtual Reality, specifically face-to-face and avatar-based interaction. Preliminary findings are discussed, along with their implications for the design and implementation of future experiments in this emerging field.","","979-8-3503-4813-2","10.1109/GECon58119.2023.10295113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10295113","collaboration;digital twins;education;virtual reality","Avatars;Collaboration;Digital twins;Engineering education","","1","","23","IEEE","31 Oct 2023","","","IEEE","IEEE Conferences"
"Large-Scale Stereo Display Wall Using Programmable Graphics Hardware","I. -J. Kim; S. C. Ahn; H. -G. Kim","KIST, Imaging Media Research Center, Seoul, South Korea; KIST, Imaging Media Research Center, Seoul, South Korea; KIST, Imaging Media Research Center, Seoul, South Korea","2008 3DTV Conference: The True Vision - Capture, Transmission and Display of 3D Video","20 Jun 2008","2008","","","173","176","In this paper, we present an large-scale stereo display wall system for tangible telemeeting using programmable graphics hardware. For tangible telemeeting, it is important to provide immersive display with high resolution image to cover up the field of view and provide to the local user the same environment as that of remote site. To achieve these, a high resolution image needs to be transmitted for reconstruction of remote world, and it should be displayed using a large display. However, it is hard to transmit high resolution image in real time due to the limit of network bandwidth, and so we receive multiple images and reconstruct a remote world with received images in advance. Then, we update only a specific area where remote user exists by receiving low resolution image in real-time. We synthesize the transmitted image to the existing environmental map of remote world and display it as a stereo image. For this, we developed a new system which supports GPU based real time warping, blending and automatic feature extraction using machine vision technique.","2161-203X","978-1-4244-1760-5","10.1109/3DTV.2008.4547836","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4547836","large-scale display;GPU;stereo display","Large-scale systems;Displays;Graphics;Hardware;Image resolution;Image reconstruction;Bandwidth;Network synthesis;Real time systems;Feature extraction","","1","","8","IEEE","20 Jun 2008","","","IEEE","IEEE Conferences"
"Review of Virtual Reality Integration for Safer and Efficient Mining Operations","N. K. B. Akbulut; A. Anani; S. O. Adewuyi","Department of Mining and Geological Engineering, The University of Arizona, Tucson, AZ, USA; Department of Mining and Geological Engineering, The University of Arizona, Tucson, AZ, USA; Department of Mining and Geological Engineering, The University of Arizona, Tucson, AZ, USA",IEEE Access,"25 Feb 2025","2025","13","","34177","34199","Mining is a complex, multifaceted industry that requires ongoing adaptation. The integration of Virtual Reality (VR) offers promising solutions to some of the industry’s key challenges, such as the need for safety simulations and task training for harsh working conditions, data analysis, remote operations, and many more. VR, as part of the broader Extended Reality (XR) framework, provides immersive environments that enable users to experience scenarios that may be costly and dangerous to replicate or that are not possible to replicate in the real world. However, despite the potential of VR, there is a limited comprehensive review of its applications within the mining sector, particularly in recent years. This paper presents a literature review focused on VR’s use in mining, aiming to provide answers to the extent of VR-related publications over the years, current use areas of VR in the industry, existing research gaps, and potential future applications. By examining the state of VR in mining, this review seeks to offer a roadmap for future research and development, highlighting areas where VR can significantly enhance education, safety, operational processes, and more.","2169-3536","","10.1109/ACCESS.2025.3541724","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10884748","Virtual reality (VR);training;higher education;immersive analytics (IA);digital twins;outreach and communications","Virtual environments;Mining industry;Headphones;Virtual reality;Resists;Safety;Hardware;Data mining;Three-dimensional displays;Training","","1","","110","CCBY","13 Feb 2025","","","IEEE","IEEE Journals"
"Representations of bodily interaction on networked ""Lazy Susan""","S. Wesugi; K. Ishikawa; T. Katayama; Y. Miwa","Graduate School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; Graduate School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; Graduate School of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan; Faculty of Science and Engineering, Waseda University, Shinjuku, Tokyo, Japan",Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No.03EX694),"18 Aug 2003","2003","1","","223","228 vol.1","In order to support a virtual community from the view-point of trust and secure feeling, a co-existing space where people feel as if they are collocated should be supported to create a communicable situation. For creating a virtual co-existing space between remote places, we develop a telecommunication system, which consists of a bodily interaction system (networked ""Lazy Susan""), which includes a round, rotatable disk, the rotations of which are synchronized with the remote disk, and a video projection system, which represents remote participants and local self in one synthesized video image for sharing the tabletop at each site. This shared tabletop is promising for supporting remote collaborative work.","","0-7803-7866-0","10.1109/CIRA.2003.1222093","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1222093","","Video sharing;Collaborative work;Network synthesis;Space technology;Internet;Communications technology;Context","","1","","14","IEEE","18 Aug 2003","","","IEEE","IEEE Conferences"
"Virtual Animal Embodiment for Actor Training","A. Jovane; D. Egan; M. F. Vargas; S. Mythen; R. McDonnell","Trinity College, Dublin; Trinity College, Dublin; Trinity College, Dublin; The Lir - National Academy of Dramatic Art; Trinity College, Dublin",2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"29 May 2024","2024","","","428","431","In this work-in-progress paper, we discuss the development of a real-time system allowing actors to drive the motion of an animal avatar, our test case being a photorealistic eagle. The aim of the work is to enhance actor training for studies related to the connection between the mind and body, imagination and action. In our proposed perceptual experiments, we plan to assess the quality of experience for the actors and also if there is a performance improvement due to the embodiment.","","979-8-3503-7449-0","10.1109/VRW62533.2024.00083","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10536547","Human-centered computing-Interaction design-Epirical studies in interaction design;Human-centered computing-Interaction paradigms-Virtual reality","Training;Three-dimensional displays;Animals;Conferences;Avatars;User interfaces;Drives","","1","","28","IEEE","29 May 2024","","","IEEE","IEEE Conferences"
"Traces in Virtual Environments: A Framework and Exploration to Conceptualize the Design of Social Virtual Environments","L. Hirsch; C. George; A. Butz","LMU Munich, Germany; University of Augsburg, Germany; LMU Munich, Germany",IEEE Transactions on Visualization and Computer Graphics,"21 Oct 2022","2022","28","11","3874","3884","Creating social Virtual Environments (VEs) is an ongoing challenge. Traces of prior human interactions, or traces of use, are used in Physical Environments (PEs) to create more meaningful relationships with the PE and the people within it. In this paper, we explore how the concept of traces of use can be transferred from PEs to VEs to increase known success factors for social VEs, such as increased social presence. First, we introduce a conceptualization and discussion ($N=4$ expert interviews) of a “Traces in VEs” framework. Second, we evaluate the framework in two lab studies ($N=46$ in total), exploring the effect of traces in (i) VE vs. PE, and (ii) on social presence. Our findings confirm that traces increase the feeling of social presence. However, their meaning may differ depending on the environment. Our framework offers a structured overview of relevant components and relationships that need to be considered when designing meaningful user experiences in VE using traces. Thus, our work is valuable for practitioners and researchers who systematically want to create social VEs.","1941-0506","","10.1109/TVCG.2022.3203092","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9873959","traces;traces of use;asynchronous;social VE;framework;social presence","Visualization;Shape;Interviews;Games;Behavioral sciences;User experience;Navigation","Humans;Computer Graphics;Emotions;Environment;User-Computer Interface","1","","79","IEEE","1 Sep 2022","","","IEEE","IEEE Journals"
"Virtual reality and learning by design: tools for integrating mechanical engineering concepts","T. Impelluso; T. Metoyer","Department of Mechanical Engineering, San Diego State University, San Diego, CA, USA; Department of Mechanical Engineering, San Diego State University, San Diego, CA, USA",30th Annual Frontiers in Education Conference. Building on A Century of Progress in Engineering Education. Conference Proceedings (IEEE Cat. No.00CH37135),"6 Aug 2002","2000","2","","F3C/14","F3C/19 vol.2","The Department of Mechanical Engineering at San Diego State University has begun to re-design its introductory mechanical engineering courses. The objectives of these newly designed courses are to incorporate the learner as designer strategy and to positively impact students' conceptual understanding of mechanical engineering concepts. To achieve these objectives, the courses are designed to use virtual reality as a tool that integrates the fundamental concepts of design, analysis and manufacturing. The first implementation of one of these courses afforded an opportunity to study a particular type of learner as designer strategy, the learner as instructional designer strategy. This paper describes the course and the impact of the learner as instructional designer strategy on students' conceptual understanding of and attitude towards mechanical engineering concepts.","0190-5848","0-7803-6424-4","10.1109/FIE.2000.896573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=896573","","Virtual reality;Mechanical engineering;Stress;Design engineering;Engineering students;Solid modeling;Finite element methods;Packaging;Manufacturing;Context","","1","","16","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"ISE-intelligent synthesis environment for future aerospace systems","A. K. Noor; S. L. Venneri","Center for Advanced Computational Technology, University of Virginia NASA Langley Research Center, Hampton, VA, USA; NASA Headquarters, Washington D.C., DC, USA",1998 IEEE Aerospace Conference Proceedings (Cat. No.98TH8339),"6 Aug 2002","1998","2","","467","486 vol.2","The Intelligent Synthesis Environment (ISE) being developed by NASA, UVA and JPL for significantly enhancing the rapid creation of innovative affordable products and missions is described. ISE uses a synergistic combination of leading-edge technologies, including high-performance computing, high-capacity communications and networking, virtual product development, knowledge-based engineering, computational intelligence, human-computer interaction, and product information management. The environment will link scientists, design teams, manufacturers, suppliers and consultants who participate in the mission synthesis, as well as in the creation and operation of the aerospace system. It will radically advance the process by which complex science missions are synthesized, and high-tech engineering systems are designed, manufactured and operated. The evolution of engineering design is described along with the shortcomings of current product development techniques. The need for ISE to create high-science payoff missions and aerospace systems at affordable costs is discussed. The five major components critical to ISE and some of their subelements are described; namely, human-ISE interaction; infrastructure for distributed collaboration; rapid synthesis and simulation tools; intelligent life-cycle system integration; and cultural change in the creative process. Related government and industry programs are outlined and future impact of ISE on complex missions and aerospace systems is discussed.","1095-323X","0-7803-4311-5","10.1109/AERO.1998.687931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=687931","","Network synthesis;Aerospace engineering;Aerospace industry;Intelligent systems;Computational intelligence;Competitive intelligence;Product development;Design engineering;NASA;Space technology","","1","","10","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Towards the control room of the future","D. Wenn; R. Mitchell; M. Gabb","Department of Cybernetics, University of Reading, Reading, UK; Department of Cybernetics, University of Reading, Reading, UK; National Grid Company Public Limited Company, Wokingham, UK","2001 People in Control. The Second International Conference on Human Interfaces in Control Rooms, Cockpits and Command Centres","7 Aug 2002","2001","","","79","85","The National Grid Company PLC (NGC) is responsible for the development, operation and maintenance of the electricity transmission system in England and Wales. As such it has a statutory duty to deliver safe and reliable electricity supplies to the Regional Electricity Companies (REC) and some other large consumers. The network currently has nearly 14,000 circuit kilometres of overhead lines, 21,812 towers and 323 substations. With such a large network advanced systems are required to present and manage the information in real-time. The control room of the future (CRF) project is centred on researching technologies that could aid the system operators and that can be brought online in the 10-15 year time-scale. The CRF project is constructing a virtual control room that will allow the seamless integration and testing of advanced display devices whilst at the same time keeping them in context with the existing, real, environment. This paper describes some of the issues involved in designing such a virtual control room and presents an approach that allows for multimodal interfaces to be tested within this environment. Since the research at this stage is in its early phase a mixture of demonstrated results and plausible ideas for future systems are presented.","0537-9989","0-85296-742-X","10.1049/cp:20010437","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=942716","","","","1","","","","7 Aug 2002","","","IET","IET Conferences"
"Presence and Communication in Hybrid Virtual and Augmented Reality Environments","Y. Li; E. Ch'ng; S. Cobb; S. See",Department of Computing School of Advanced Technology Xi'an Jiaotong--Liverpool University Suzhou China; NVIDIA Joint-Lab on Mixed Reality University of Nottingham Ningbo China; Human Factors Research Group Faculty of Engineering University of Nottingham United Kingdom; NVIDIA AI Technology Centre NVIDIA Singapore,Presence,"4 Dec 2024","2019","28","","29","52","","1054-7460","","10.1162/pres_a_00340","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10778240","","","","1","","","","4 Dec 2024","","","MIT Press","MIT Press Journals"
"A Scoping Review and Expert Recommendations for Immersive Solutions towards Predictive Maintenance","R. Guarese; M. G. Khan; D. Lassiter; J. Vachier; F. Johnson; B. Edvinsson; A. Bergman; X. V. Wang; M. Romero","KTH Royal Institute of Technology, Sweden; KTH Royal Institute of Technology, Sweden; AstraZeneca, Sweden; AstraZeneca, Sweden; AstraZeneca, Sweden; AstraZeneca, Sweden; AstraZeneca, Sweden; KTH Royal Institute of Technology, Sweden; Linköping University, Sweden",2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"24 Apr 2025","2025","","","1081","1088","Under an industrial-academic partnership project, the present work aims to map and catalog the different applications of Augmented and Virtual Reality in predictive maintenance (PdM) practices. Through a preliminary scoping review, we targeted two main digital libraries in computing and engineering. Thus, we address the key attributes regarding the types of immersive technologies and the solutions used in several industries for PdM. By categorizing the surveyed prototypes according to 10 parameters in their interaction, visualization, and research methods, we expose the state-of-the-art and valuable knowledge gaps within immersive PdM. After this analysis, we conducted a workshop with 3 manufacturing experts discussing the future of maintenance interfaces, bringing forth their feedback in the shape of recommendations for what to further explore within immersive PdM.","","979-8-3315-1484-6","10.1109/VRW66409.2025.00217","AstraZeneca; KT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972714","Predictive maintenance;augmented and mixed reality;virtual reality;situated visualization;collaborative interfaces","Visualization;Three-dimensional displays;Reviews;Shape;Conferences;Prototypes;Mixed reality;Virtual reality;User interfaces;Predictive maintenance","","1","","66","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"A Scientometric History of IEEE VR","R. Skarbez; D. Jiang",La Trobe University; La Trobe University,2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR),"15 Apr 2024","2024","","","990","999","As of IEEE VR 2023, there have been 30 installments of the IEEE Virtual Reality conference (VR) or its predecessor, the Virtual Reality Annual International Symposium (VRAIS). As such, it seems an opportune time to reflect on the intellectual history of the conference, and by extension, the VR research community. This article uses scientometric techniques to undertake such an intellectual history, using co-word analysis and citation analysis to identify core themes and trends in VR research over time. We identify the papers that have stood the test of time, the most esteemed authors and researchers in the IEEE VR community, and the topics that have shaped our field to date.","2642-5254","979-8-3503-7402-5","10.1109/VR58804.2024.00118","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494072","bibliometrics;scientometrics;history;survey;General and reference;Surveys and overviews;Social and professional topics;History of computing;Human-centered computing;Virtual reality","Visualization;Three-dimensional displays;Citation analysis;Virtual reality;User interfaces;Motors;Rendering (computer graphics)","","1","","25","IEEE","15 Apr 2024","","","IEEE","IEEE Conferences"
"Designing and Analyzing Virtual Avatar Based on Rigid-Body Tracking in Immersive Virtual Environments","M. Park; J. Lee; H. Yang; J. Kim","Department of Computer Engineering, Graduate School, Hansung University, Seoul, South Korea; Department of Information and Computer Engineering, Graduate School, Hansung University, Seoul, South Korea; Department of Computer Engineering, Graduate School, Hansung University, Seoul, South Korea; Department of Computer Engineering, Graduate School, Hansung University, Seoul, South Korea",IEEE Access,"9 Jan 2025","2025","13","","5522","5533","This study proposes a novel method for virtual avatar applications based on rigid-body tracking in immersive virtual environments (IVEs). This method aims to design a method to efficiently and accurately estimate motions defined with few conditions. For this purpose, we design a virtual avatar motion process that proceeds from rigid-body tracking to motion estimation using Final IK (inverse kinematics). This study uses optical motion capture equipment based on markers for rigid-body tracking and calculating the movement of a defined virtual avatar based on the transformation information of the precisely tracked rigid-body object. To analyze the effectiveness of the proposed method, a comparative analysis of equipment and environment with existing research on animation fidelity in self-avatars is performed. In addition, two upper body-centered actions (simultaneous two-hand motion and separate two-hand motion) are presented to analyze latent factors of virtual avatar embodiment. A comparative survey experiment using the virtual embodiment questionnaire (VEQ) is conducted based on full-body tracking and the proposed rigid-body tracking-based method. Furthermore, to compare and analyze users’ realism in an environment where they coexist with virtual avatars in IVE, a survey experiment using a presence questionnaire is conducted. Therefore, we confirmed that similar avatar motion generation is possible compared to full-body tracking even with fewer tracking targets (e.g. type of tracking device or number of markers), inputs, and processing steps. Additionally, it is possible to design a virtual avatar that provides satisfactory realism in IVE.","2169-3536","","10.1109/ACCESS.2025.3525630","Hansung University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10824787","Virtual avatar;immersive virtual environment;rigid-body tracking;motion estimation;motion capture;virtual embodiment","Avatars;Accuracy;Target tracking;Animation;Motion capture;Motion estimation;Hands;Optical sensors;Visualization;Resists","","1","","44","CCBYNCND","3 Jan 2025","","","IEEE","IEEE Journals"
"Development of Touch Interface Using LIDAR for Multi-user Interactions in Projection-based VR","H. Lee; S. Kim; S. -W. Ryu; J. Lee; K. Kwon; S. Lim; E. -S. Lee","VR/AR Content Research Section, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea; VR/AR Content Research Section, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea; VR/AR Content Research Section, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea; VR/AR Content Research Section, Electronics and Telecommunications Research Institute (ETRI), Daejeon, South Korea; Department of SmartIT, Hanyang Women's University, Seoul, South Korea; Department of Smart Information Technology, Baewha Women's University, Seoul, South Korea; Department of VR Game Application, Yuhan University, Bucheon, South Korea",2022 13th International Conference on Information and Communication Technology Convergence (ICTC),"25 Nov 2022","2022","","","1783","1785","Tangible user interfaces are frequently utilized in projection-based VR to merge virtual space into real large-scale environments. In this work, we introduce a LIDAR-based touch system that enables tangible touch interactions with five surfaces (four-sided walls and a floor) of a large room for projection-based VR. We develop a network of LIDAR distance sensors to identify touch events by multiple human users that can detect surrounding obstacles in any omnidirectional direction. We experiment with single-user and multi-user, multi-touch interaction scenarios in our specialized room-scale settings. As a result, we verified that our LIDAR network could provide appropriate feedback in real- time, with minimized human perception delay.","2162-1241","978-1-6654-9939-2","10.1109/ICTC55196.2022.9952443","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9952443","Projection-based VR;tangible user interface (TUI);touch sensing;multi-user system;haptics;LIDAR","Laser radar;Tactile sensors;User interfaces;Sensor systems;Sensors;Information and communication technology;Delays","","1","","9","IEEE","25 Nov 2022","","","IEEE","IEEE Conferences"
"Multi-Platform Virtual Reality Interaction with Hand Gestures for Precise Object Manipulation and Multi-User Collaboration","M. N. Iman Sa’adon; M. S. Sunar; K. N. Ali","Faculty of Computing, Universiti Teknologi Malaysia, Johor, Malaysia; Institute of Human Centered Engineering (iHumEn), Universiti Teknologi Malaysia, Johor, Malaysia; Faculty of Built Environment and Surveying, Universiti Teknologi Malaysia, Johor, Malaysia",2023 3rd International Conference on Intelligent Cybernetics Technology & Applications (ICICyTA),"13 Feb 2024","2023","","","312","317","Virtual reality (VR) offers immersive digital experiences that engage users in interactive environments, both visually and emotionally. Collaborative and competitive interactions in multi-user VR environments enhance user experiences. However, accessibility remains a challenge due to the variety of VR hardware. Specialized VR equipment, such as controllers, can limit access and inhibit collaboration across platforms. This research addresses these accessibility challenges by proposing a novel approach that utilizes hand gesture interaction techniques for precise and accurate object manipulation in VR with a focus on multi-user interactions. The primary aim is to enable users with a variety of devices, including VR headsets, smartphones equipped with Google Cardboard, and CAVE systems, to participate in an immersive VR environment, ultimately encouraging cooperative and collaborative multi-user experiences. To achieve this aim, the study employs a comparative experimental design using a range of VR platforms to assess the feasibility and effectiveness of hand gestures in achieving accurate and precise object manipulation in the multi-platform VR environment. Through experimentation and analysis, this research is expected to demonstrate the feasibility and effectiveness of hand gestures in achieving accurate and precise object manipulation, making VR applications more inclusive and enjoyable for a broader range of users. The successful implementation of hand gesture interaction techniques can lead to increased accessibility to VR experiences, promote cross-platform collaboration, and pave the way for innovative applications in fields such as education, entertainment, and professional training, ultimately transforming the landscape of VR technology.","","979-8-3503-9455-9","10.1109/ICICyTA60173.2023.10428981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10428981","Virtual reality;Multi-platform;Multi-user collaboration;Hand-gesture interaction;Object manipulation","Training;Technological innovation;Collaboration;Virtual reality;Speech recognition;Hardware;Smart phones","","1","","20","IEEE","13 Feb 2024","","","IEEE","IEEE Conferences"
"Immersion, Attention, and Collaboration in Spatial Computing: A Study on Work Performance with Apple Vision Pro","C. Wienrich; D. Obremski","Psychology of Intelligent Interactive Systems (PIIS) Group, University of Wurzburg, Germany; Psychology of Intelligent Interactive Systems (PIIS) Group, University of Wurzburg, Germany",IEEE Transactions on Visualization and Computer Graphics,"25 Apr 2025","2025","31","5","2995","3002","Spatial computing is set to change the way we work. It will enable both focused work through a higher degree of immersion and collaborative work through enhanced integration of shared interaction spaces or interaction partners. With the Apple Vision Pro, the level of immersion can be adjusted seamlessly. So far, there have been no systematic studies on how this adjustability affects work performance when working alone or together. The present empirical study fills this research gap by varying the level of immersion across three stages (high, medium, low) while solving various tasks with the Apple Vision Pro. The results show that selective attention improves significantly with increasing immersion levels. In contrast, social presence decreases with increasing immersion. In general, participants performed better in the individual task than in the collaborative task. However, the degree of immersion did not influence the collaborative performance. In addition, we could not determine any adverse effects on depth perception or user experience after use. The present study provides initial contributions to the future of spatial computing in professional settings and highlights the importance of balancing immersion and social interaction in a world where digital and physical spaces seamlessly coexist.","1941-0506","","10.1109/TVCG.2025.3549145","German Federal Ministry of Labor(grant numbers:DKI.00.00030.21); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10917012","Spatial Computing;Augmented Reality;Immersion;Collaborative Work;Selective Attention","Collaboration;Virtual environments;User experience;Mixed reality;Virtual reality;Spatial computing;Coherence;Performance evaluation;Psychology;Federated learning","","1","","36","CCBY","7 Mar 2025","","","IEEE","IEEE Journals"
"Social Augmented Reality: A Multiperspective Survey","A. Nijholt","University of Twente Enschede, the Netherlands","2021 Joint 10th International Conference on Informatics, Electronics & Vision (ICIEV) and 2021 5th International Conference on Imaging, Vision & Pattern Recognition (icIVPR)","18 Oct 2021","2021","","","1","8","We introduce research on social augmented reality with an emphasis on social face-to-face interaction. In social interaction interactants employ knowledge about their conversational partner and have their verbal interaction supported by nonverbal interaction cues. We survey the issues that arise when we pursue social interaction in augmented reality. Since handhelds and bulky head-mounted devices hardly allow unobtrusive interaction we pay extensive attention to developments in the field of smart glasses and smart contact lenses. The focus is on the use of smart augmented reality glasses during social interactions. Acceptance issues and disruption of social interaction due to the use of these devices are also touched upon.","","978-1-6654-4923-6","10.1109/ICIEVicIVPR52578.2021.9564182","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9564182","augmented reality;social interaction;smart glasses;smart contact lenses;social signals;human-computer interaction","Training;Visualization;Decision making;Collaboration;Glass;Games;Companies","","1","","41","IEEE","18 Oct 2021","","","IEEE","IEEE Conferences"
"Multi-user efficacy of collaborative virtual environments","A. Erfanian; Y. Hu","Dept. of Electrical and Computer Engineering, University of Calgary, Calgary, Alberta, CANADA; Dept. of Electrical and Computer Engineering, University of Calgary, Calgary, Alberta, CANADA",2016 IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD),"15 Sep 2016","2016","","","389","394","Multi-user efficacy is a key factor of genuine collaboration among multiple users towards a common goal. To assess multi-user efficacy, social scientists have traditionally applied subjective measurements from a theoretical perspective. Researchers in human-computer interaction have developed combined metrics of objective and subjective measurements. Nevertheless, the combined metrics fall short to fully cover the theoretical perspective of social scientists. To remedy this shortfall, we have developed a set of objective and subjective metrics to complete the theoretical perspective. Utilizing the metrics, we present in this paper a study to verify the robustness of our dynamic priority (DP) model, which under a quasi-practical scenario resolves command conflicts and promotes perceived equality in interaction among multiple users. In the study, we utilized a realistic scenario which differs from the quasi-practical scenario in the allowance of verbal communication among users. The results of the study revealed that the DP model yielded a significantly higher degree of multi-user efficacy under the realistic scenario than the quasi-practical scenario. Moreover, there was no significant difference of the perceived equality in interaction between both scenarios. These observations confirm the robustness of the DP model, and imply the potential application of the model for genuine collaboration within multi-user VEs.","","978-1-5090-1915-1","10.1109/CSCWD.2016.7566020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566020","Multi-user efficacy;collaborative virtual environments;interaction models;verbal communication","Collaboration;Measurement;Vocabulary;Human computer interaction;Instruction sets;Computational modeling;Geology","","1","","19","IEEE","15 Sep 2016","","","IEEE","IEEE Conferences"
"Extensive Research: Novel Direction of Extended Reality and the Trailing Challenges","S. J. Isaac; J. Naivalya; B. P. Lohani; A. K. Khan; S. K. Shivam; R. Kumar","Computer Science Department, Amity University, Greater Noida, Uttar Pradesh, India; Computer Science Department, Amity University, Greater Noida, Uttar Pradesh, India; Computer Science Department, Amity University, Greater Noida, Uttar Pradesh, India; Lloyd Law College, Greater Noida, Uttar Pradesh, India; Computer Science Department, Amity University, Greater Noida, Uttar Pradesh, India; Lloyd Institute of Engineering and Technology, Greater Noida, Uttar Pradesh, India",2023 6th International Conference on Contemporary Computing and Informatics (IC3I),"26 Jan 2024","2023","6","","742","749","Few years back, we couldn't even imagine an object like wireless extended reality (XR).A Brol-Iy(umbrella) term that covers augmented, reality, mixed reality, and virtual reality. Time and Memorial technology has improved that and continues to only climb up. This fascinating device is getting popular among this generation because of its interactive nature, and also the coolness and the X factor that it brings along. There is a tremendous increase in the market size and will deeply impact the way we interact with the physical world. There is still a lot to work on as the current XR devices, lack mobility and quality of ex-perience, as they are tethered by cables. With the coming of future technologies, such as 6G can free users by enabling them with surplus of applications, and getting rid of cables that are the reason for its lack in mobility progressive nature. 5G improved the rate with which with and data, but it doesn't satisfy the requirements for and high quality XR to work. At the least, it requires an uncompressed data rate, with almost, fewer to no latency. In this paper we go through the advantages of wire-less XR, and the requirements to make it an ultimate device, realising challenges of using 6G wireless sys-tems, Wi-Fi and communication and network via wireless medium.","","979-8-3503-0448-0","10.1109/IC3I59117.2023.10398067","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10398067","Wireless Extended Reality Augmented Reality;Mixed Reality;Virtual Reality","Wireless communication;6G mobile communication;Training;Extended reality;Mixed reality;Transforms;Safety","","1","","12","IEEE","26 Jan 2024","","","IEEE","IEEE Conferences"
"When Industrial Metaverse Meets 6G: The Next Revolution and Deployment Challenges","J. Li; S. Dang; Z. Zhang; L. Wang","School of Computer, Electronics and Information, Guangxi University, Nanning, China; Department of Electrical and Electronic Engineering, University of Bristol, Bristol, UK; School of Computer, Electronics and Information, Guangxi University, Nanning, China; School of Computer, Electronics and Information, Guangxi University, Nanning, China",2024 IEEE Wireless Communications and Networking Conference (WCNC),"3 Jul 2024","2024","","","1","6","Web 3.0 or Web3 is the next-generation Internet paradigm, which aims to realize the vision of a decentralized and open Web that provides greater utility to users. Due to the rapid development of technologies, such as augmented reality (AR) and extended reality (XR), the industrial metaverse, which is an immersive and interactive simulation mirroring real-world processes, systems, and objects, is gradually becoming a reality. Simultaneously, the industrial metaverse represents a new paradigm for the next generation of industrial transformation. However, data communications supporting the industrial meta-verse require extremely high reliability and low latency to ensure a high level of quality of service (QoS). Therefore, achieving an immersive and interactive industrial metaverse poses significant challenges to data communications. In this article, we first review the big picture of the industry and high-tech companies of industrial metaverse. Subsequently, we explore the application potential of sixth-generation (6G) communication technology and various enabling technologies, such as ultra-reliable and low-latency communication (URLLC) and reconfigurable intelligent surfaces (RIS) in the industrial metaverse. Then, we propose an RIS-enhanced communication paradigm to solve the challenges of privacy, security, reliability, and latency for industrial meta-verse applications. Finally, we discuss potential communication research directions for the industrial metaverse.","1558-2612","979-8-3503-0358-2","10.1109/WCNC57260.2024.10570966","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10570966","","6G mobile communication;Semantic Web;Metaverse;Extended reality;Quality of service;Reconfigurable intelligent surfaces;Ultra reliable low latency communication","","1","","15","IEEE","3 Jul 2024","","","IEEE","IEEE Conferences"
"Hearing but not listening: Auditory icons and presence","H. Baharin; R. Mühlberger","School of Information Technology & Electrical Engineering, University of Queensland, QLD, Australia; School of Information Technology & Electrical Engineering, University of Queensland, QLD, Australia",2010 International Conference on User Science and Engineering (i-USEr),"22 Feb 2011","2010","","","179","184","This paper explores the usage of auditory icons in creating the feeling of presence of a remote person in a virtual simulation of domestic life. Auditory icons are the representation of processes or activities using everyday sounds. Presence is defined in this research as `the feeling of being with others'. In this research, domestic life is simulated using the game called The Sims. Participants were asked to play the game while being able to hear auditory icons that represent another player who were playing the game in a remote place. In actuality the auditory icons is just a sound loop. A presence questionnaire given to 49 users participating in 2 research trials shows that auditory icons can easily be ignored and thus do not induce a high level of social presence, but when the auditory icons are given attention to, social presence is significantly increased. The results from the trials are also discussed from the perspective of Acoustic Communication Theory, which shows that as the auditory environment becomes saturated with sound objects, people tend to be `distracted listeners'. At the time of writing more experiments are being done to study the effects of auditory icons on presence.","","978-1-4244-9049-3","10.1109/IUSER.2010.5716747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5716747","Auditory Icons;Presence","Audio user interfaces;Games;Auditory system;Correlation;Music;Visualization;Psychology","","1","","19","IEEE","22 Feb 2011","","","IEEE","IEEE Conferences"
"Enhancing Human Task Performance through Audiovisual Augmentation","T. Schwandt; G. Kumari; G. Stolz; S. Werner; W. Broll","Virtual Worlds and Digital Games Group, Technische Universität, IImenau; Virtual Worlds and Digital Games Group, Technische Universität, IImenau; Electronic Media Research Group, Technische Universität, IImenau; Electronic Media Research Group, Technische Universität, IImenau; Virtual Worlds and Digital Games Group, Technische Universität, IImenau",2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"28 Nov 2024","2024","","","797","805","In unusual environments and situations like extreme sports, underground environments, underwater, conflict zones or outer space, human sensory perception is often limited, which can adversely affect task performance, situational awareness, and the feeling of presence. This paper explores the efficacy of augmenting human perception with audiovisual information to support individuals in such contexts. Specifically, we investigate the impact of audiovisual augmentation on presence, situational awareness, and task performance. To conduct this research, we designed a virtual reality (VR) simulation of a space mission aboard the International Space Station (ISS). Within this simulation, participants were tasked with performing maintenance activities while receiving artificial augmentations. We conducted a user study involving 43 participants who performed the same maintenance task under four augmentation conditions: audio cues, visual cues, audiovisual cues, and no cues. Our findings reveal that adding audiovisual information significantly enhances performance. Participants with audiovisual augmentations had a 60% improvement in task completion speed compared to those without augmentations. Moreover, the workload was substantially reduced, and the sense of presence was increased when audiovisual support was used. The results highlight the potential of audiovisual augmentation as a valuable tool for individuals engaging in situations with reduced audiovisual perception. The insights demonstrating the versatility and promise of audiovisual augmentation in enhancing task performance.","2473-0726","979-8-3315-1647-5","10.1109/ISMAR62088.2024.00095","European Space Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765474","Audiovisual augmentation;Task performance;Workload;Maintenance;Virtual reality;User study","Visualization;Space missions;International Space Station;Maintenance;Augmented reality;Sports","","","","39","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"Assessing State-of-the-Art Mission Planning User Interfaces for Application to Next Generation Fighter Concept of Operations","T. Laudien","German Aerospace Center (DLR), Institute of Flight Guidance, Braunschweig, Germany",2024 AIAA DATC/IEEE 43rd Digital Avionics Systems Conference (DASC),"15 Nov 2024","2024","","","1","8","Within the next ten to twenty years, nations and associations of nations are planning to roll out a new generation of air combat technology. Although playing a central role, this not only comprises a future fighter aircraft but rather a whole system of systems that incorporates manned as well as unmanned assets. It is envisioned that the management of those assets will be done from onboard the next generation fighter jet which ultimately affects the scope of work of the pilot: Shifting from the current tactical flying of the aircraft to the role of a commander tasking multiple unmanned combat aerial vehicles. With this, it is conceivable that there will also be a change in cockpit and human-machine interface design. In order to address this challenge, this paper presents a literature analysis that assesses the state-of-the-art in research on mission planning HMIs. From a combination of gained insights and the author's own ideas, three visualization methods for the display of an onboard mixed reality mission planning HMI for the future fighter are introduced. Additionally, benefits and drawbacks in the use of mixed reality are discussed and an outlook on future work is given.","2155-7209","979-8-3503-4961-0","10.1109/DASC62030.2024.10749429","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10749429","Virtual Reality;Mixed Reality;Mission Planning;Mission Management;Remote Carrier;UAV;UCAV;User Interface;Human-Machine Interface","Visualization;Three-dimensional displays;Two-dimensional displays;Mixed reality;Virtual reality;User interfaces;Military aircraft;Planning;Next generation networking;System of systems","","","","19","IEEE","15 Nov 2024","","","IEEE","IEEE Conferences"
"The Impact of Immersive Virtual and Augmented Reality on Medical Field: A Review of Cognitive Load, Learning Efficiency, and Practical Applications","N. K. P; M. G; S. Pavithra","Computer Science and Engineering, Chennai Institute of Technology, Chennai, India; Computer Science and Engineering, Chennai Institute of Technology, Chennai, India; Department of Computer Science and Engineering, Computer Science and Engineering","2025 International Conference on Data Science, Agents & Artificial Intelligence (ICDSAAI)","29 May 2025","2025","","","1","7","This paper describes how AR is transformed into healthcare, particularly when viewed from the perspective of medical imaging, surgical precision, and education, and examines how this integration is done, demonstrating its potential for enhancing clinical practice, engagement of patients, and customized interventions. Thus, AR combined with VR, AI, and robotics will open a new door for healthcare delivery, educational, and training revolutions. The main drawbacks include regulatory challenges, high costs, and clinical validation. This needs further research on this area to move forward. Cognitive load measuring using AR is another important aspect of user experience which removes the traditional method on performance tests or subjective ratings. The use of non-invasive sensors has been combined with physiological measures in recent times. An example is eye-tracking, which will provide us with real-time data of cognitive load; but it is still uneven, and we require a multi-method approach to overcome this. AR and immersive VR are together known as XR technologies. XR is used in medical education, and it is absorbed that it increases knowledge gain much higher in comparison to traditional learning resources in anatomy learning. A Cross-study analysis on students showed that 80% of participants reporting a positive learning experience on XR. Collectively we need intensive research to maximize its impact and address regulatory, developmental, and cognitive considerations.","","979-8-3315-3755-5","10.1109/ICDSAAI65575.2025.11011531","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11011531","Augmented Reality (AR);Virtual Reality (VR);Cognitive Load Measurement;Artificial Intelligence (AI);Robotics in HealthCare","Training;Reviews;Neuroanatomy;Medical services;Cognitive load;User experience;Sensors;Artificial intelligence;Augmented reality;Biomedical imaging","","","","13","IEEE","29 May 2025","","","IEEE","IEEE Conferences"
"Augmented Reality (AR) and Virtual Reality (VR) in Software Development: Transforming User Experiences and Interactions","M. M; V. Lavanya; M. S. Maharajan; E. Sivajothi; V. S. Pandi; W. V. S. Sherly","Department of Information Technology, University of Technology and Applied Sciences, Ibri, Oman; Department of CSE, Veltech Multitech Dr. Rangarajan Dr. Sakunthala Engineering College, Chennai, India; Department of AI&DS, Panimalar Engineering College, Chennai, India; Department of CSE, Vel Tech Rangarajan Dr. Sagunthala R& D Institute of Science and Technology, Chennai, India; Centre for Advanced Wireless Integrated Technology, Chennai Institute of Technology, Chennai, India; Department of Artificial Intelligence and Data Science, Jeppiaar Institute of Technology, Sunguvarchathram, India",2024 1st International Conference on Sustainability and Technological Advancements in Engineering Domain (SUSTAINED),"15 Jul 2025","2024","","","342","347","Virtual reality (VR) and augmented reality (AR) technologies are causing a revolution in software development by radically altering the ways in which users interact with software. This study investigates the incorporation of augmented reality (AR) and virtual reality (VR) into software development, with a particular emphasis on the ways in which these immersive technologies improve design processes, promote user engagement, and build unique interaction paradigms. Virtual reality (VR) immerses users in totally virtual surroundings, enabling new forms of interaction and visualization, whereas augmented reality (AR) provides experiences that are contextually relevant and interactive by superimposing digital information onto the actual world. This study investigates the present uses of augmented reality (AR) and virtual reality (VR) in a variety of software areas, such as gaming, education, and industrial training, with a focus on the influence these trends have on user experience and functioning. It is explained how significant breakthroughs have been made in augmented reality and virtual reality hardware and software, including enhanced motion tracking, realistic rendering, and user interface design. This research also covers the obstacles that are associated with the implementation of augmented and virtual reality, such as high development costs, user adaptability, and interaction with preexisting systems. By presenting a comprehensive overview of the advantages and disadvantages of augmented reality (AR) and virtual reality (VR) in software development, the purpose of this study is to provide insights into how these technologies can be utilized to create innovative and immersive user experiences, which will ultimately transform the landscape of software interaction and application.","","979-8-3503-9165-7","10.1109/SUSTAINED63638.2024.11074041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11074041","Real-time Rendering;Motion Tracking;User Interface Design;Digital Overlays;Virtual Environments;Interactive Systems;Technology Integration;Immersive User Experiences","Visualization;Tracking;Virtual environments;Virtual reality;User interfaces;Rendering (computer graphics);Software;User experience;Augmented reality;Software development management","","","","19","IEEE","15 Jul 2025","","","IEEE","IEEE Conferences"
"5G/6G Architecture Evolution for XR and Metaverse: Feasibility Study, Security, and Privacy Challenges for Smart Culture Applications","M. Christopoulou; I. Koufos; G. Xilouris; N. Dimitriou","Institute of Informatics and Telecommunications, NCSR ‘‘Demokritos,’’, Agia Paraskevi, Greece; Institute of Informatics and Telecommunications, NCSR ‘‘Demokritos,’’, Agia Paraskevi, Greece; Institute of Informatics and Telecommunications, NCSR ‘‘Demokritos,’’, Agia Paraskevi, Greece; Institute of Informatics and Telecommunications, NCSR ‘‘Demokritos,’’, Agia Paraskevi, Greece",IEEE Access,"17 Jun 2025","2025","13","","103077","103094","This paper investigates the evolution of 5G/6G architectures to support demanding Extended Reality (XR) and Metaverse applications, focusing specifically on the “smart culture” domain. We evaluate the capabilities of the 5G Service-Based Architecture (SBA), including Multi-Access Edge Computing (MEC) and network analytics, through a comprehensive feasibility study comparing stringent XR requirements (bitrate, latency, capacity, power, accuracy) against current 5G performance. Our key contribution is the identification of significant performance gaps where 5G struggles to meet the demands of advanced XR, particularly concerning capacity, scalability, and ultra-low latency. Furthermore, we provide a detailed analysis of critical security and privacy challenges inherent in 5G-enabled XR environments, including virtualization vulnerabilities, API security, and sensitive data protection. While 5G provides core capabilities, significant challenges persist, emphasizing the need for continued research and the evolution toward 6G to effectively support immersive experiences in smart culture and the Metaverse.","2169-3536","","10.1109/ACCESS.2025.3578595","IoT2Cloud Operating System-Towards a functional continuum operating system (ICOS) Project funded by European Union’s Horizon Research and Innovation Program(grant numbers:101070177); Smart Networks and Services Joint Undertaking (SNS JU) under the European Union (EU) Horizon Europe Program Privateer(grant numbers:101096110); 6G-Cloud Project(grant numbers:101139073); National Recovery and Resilience Plan Greece 2.0 funded by European Union–NextGenerationEU (Project: Smart Cities)(grant numbers:TAEDR-0536642); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11030451","5G/6G networks;AR/XR/VR;metaverse;smart culture;education;edge computing;MEC;immersive applications;cybersecurity;privacy","Metaverse;Security;5G mobile communication;Cultural differences;Computer architecture;Privacy;6G mobile communication;Real-time systems;Museums;Art","","","","73","CCBYNCND","11 Jun 2025","","","IEEE","IEEE Journals"
"Scaling immersive visualization with COTS VR: the Voxar Labs experience","J. M. Teixeira; V. Teichrieb","Voxar Labs - Centro de Informática, Universidade Federal de Pernambuco, Recife, Pernambuco, Brazil; Voxar Labs - Centro de Informática, Universidade Federal de Pernambuco, Recife, Pernambuco, Brazil",2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"24 Apr 2025","2025","","","189","192","Over the past decade, new commercial off-the-shelf (COTS) virtual reality (VR) devices have substantially lowered the entry barriers for immersive visualization in academic and industrial settings. Voxar Labs, based at the Federal University of Pernambuco (UFPE), has consistently favored smaller, more flexible installations and HMD-based immersive solutions over large-scale, high-cost visualization environments. This paper presents Voxar Labs’ strategies for fostering immersive research and innovation with limited resources, discusses the advantages and challenges of adopting COTS technology, and highlights successes in education, research, and outreach. Our experience suggests that nimble, decentralized, and portable approaches can broaden the impact of immersive visualization labs while still meeting the demanding requirements of scientific research.","","979-8-3315-1484-6","10.1109/VRW66409.2025.00047","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972980","Immersive Visualization;COTS VR Technology;Research and Innovation","Headphones;Visualization;Technological innovation;Three-dimensional displays;Conferences;Education;Virtual reality;User interfaces;Trajectory;Sustainable development","","","","8","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"Immersive Computing: Vision, Infrastructure, and Use Cases","B. Han; S. Chen; J. Martin; P. Pathak; A. Varshney; H. Xue; L. -F. Yu; J. Zhang; X. Zhao",George Mason University; George Mason University; George Mason University; George Mason University; University of Maryland; George Mason University; George Mason University; George Mason University; George Mason University,2023 IEEE 9th International Conference on Collaboration and Internet Computing (CIC),"19 Feb 2024","2023","","","1","10","Immersive computing signifies a paradigm shift in how people interact with digital content and their surrounding 3D environments. In this vision paper, we first outline a comprehensive roadmap for advancing immersive computing, encompassing virtual, augmented, and mixed reality, which are often collectively referred to as extended reality, and immersive content delivery, including 360-degree panoramic video streaming and volumetric video streaming, by identifying key challenges and opportunities. We then describe CoMIC, a research infrastructure that offers a collaborative, visual-first, and hologram-based computing space and a quality-driven, multi-site, and immersive communication framework for collaborative mobile immersive computing. Given the interdisciplinary nature of immersive computing, we present several key use cases that could be enabled by CoMIC. We conclude this paper by envisioning a future where our digital experiences will transcend the boundaries of screens and devices, immersing us in a world where the virtual and physical seamlessly merge.","","979-8-3503-3912-3","10.1109/CIC58953.2023.00022","NSF(grant numbers:CNS-2212296,CNS-2235049); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10429917","Immersive Computing;Extended Reality;Metaverse;Research Infrastructure;Use Cases","Humanities;Three-dimensional displays;Extended reality;Collaboration;Mixed reality;Streaming media;Internet","","","","55","IEEE","19 Feb 2024","","","IEEE","IEEE Conferences"
"The Impact of Heterogeneity on Network Resource Allocation Process for Managing Education in Real Time","T. Z. Dawood; A. R. Muzata; M. S. Stepanov; G. Singh; M. G. Kanishcheva","Moscow Technical University of Communications and Informatics, Moscow, Russia; Department of Electrical and Electronic Engineering Science, University of Johannesburg, Johannesburg, South Africa; Moscow Technical University of Communications and Informatics, Moscow, Russia; Department of Electrical and Electronic Engineering Science, University of Johannesburg, Johannesburg, South Africa; Moscow Technical University of Communications and Informatics, Moscow, Russia",2025 Systems of Signals Generating and Processing in the Field of on Board Communications,"8 Apr 2025","2025","","","1","9","The use of technology in education has increased In recent years, especially after the emergence of the COVID-19 pandemic and the trend towards digital learning. Solutions such as e-learning, blended learning, and game-based learning are being used. Virtual Reality (VR) and Augmented Reality (AR) can help significantly change the style of education towards making it more interesting, useful, and possible. Of course, this type of application requires specific traffic characteristics that must be taken into account when allocating resources in the network in order to obtain an acceptable quality of service. The article provides a numerical study of the influence of the heterogeneity property on the characteristics of the joint servicing of information flows of various types in modern networks. To conduct the study, a generalized mathematical model of a network access node is used, and parameters and characteristics are discussed.","2768-0118","979-8-3315-3263-5","10.1109/IEEECONF64229.2025.10948040","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10948040","Augmented Reality;Virtual Reality;resource allocation;mathematical modeling;Telecommunication Systems;heterogeneous traffic;Education","Solid modeling;Pandemics;Education;Process control;Quality of service;Real-time systems;Mathematical models;Telecommunications;Resource management;Augmented reality","","","","58","IEEE","8 Apr 2025","","","IEEE","IEEE Conferences"
"Towards 6G Semantic Communication: Technologies, Applications, and Research Challenges","S. N. Karahan; O. Kaya","R&D Department, Türk Telekom, Ankara, Türkiye; Department of Electronics Engineering, Turkish Air Force Academy at National Defense University, İstanbul, Türkiye","2025 7th International Congress on Human-Computer Interaction, Optimization and Robotic Applications (ICHORA)","2 Jun 2025","2025","","","1","7","This study provides a comprehensive literature review of the idea of Semantic Communication in 6G networks, covering its basic ideas, supporting technologies, potential applications and issues. Traditional communication systems prioritize bit-level correctness, but SemCom aims to create a more efficient, context-aware and successful communication model by preserving the meaning of the information being communicated. In this study the ideas behind SemCom and the three-layer communication model are first considered. Details of the technical, semantic and effectiveness layers are then given. The enabling technologies for SemCom are then examined, including deep learning, reinforcement learning, AI-native networks, edge computing and digital twins. The benefits and future opportunities of SemCom in various application domains are assessed, including IoT, smart cities, autonomous systems, the metaverse, UAV networks, and healthcare. Finally, we explore and provide remedies for the main barriers to mainstream SemCom adoption, including security vulnerabilities, semantic code optimization, resource allocation, and standards deficiencies. By reviewing the latest advances in the current literature on how SemCom should be applied in 6G communication systems, this study aims to provide a thorough foundation for further research.","2996-4393","979-8-3315-1088-6","10.1109/ICHORA65333.2025.11017247","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11017247","semantic communication;sixth-generation (6G) networks;AI for semantic communication","6G mobile communication;Wireless communication;Smart cities;Metaverse;Reinforcement learning;Semantic communication;Security;Resource management;Optimization;Standards","","","","28","IEEE","2 Jun 2025","","","IEEE","IEEE Conferences"
"Establishing Design Computing and Extended Reality Facilities for Remote Virtual Reality Training","L. -F. Yu; C. Li; Y. Zhang; R. Alghofaili; H. Huang; L. Yu; H. Liu; M. Choi; B. Bannan; C. Mousas",George Mason University; George Mason University; George Mason University; George Mason University; George Mason University; George Mason University; Purdue University; Purdue University; George Mason University; Purdue University,2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"1 May 2023","2023","","","216","220","We discuss the existing facilities at the Design Computing and Extended Reality (DCXR) Lab at George Mason University, which comprise mostly commercial-off-the-shelf computing and extended reality devices, for conducting research on virtual reality-based training. We also share thoughts on extending the facilities for conducting more sophisticated virtual reality (VR) training research in the future, which features more advanced functionalities such as remote VR training, adaptive training, and co-training in VR. In particular, we discuss a remote VR training platform to be established between George Mason University and Purdue University.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00053","National Science Foundation(grant numbers:1565978,1942531,2128867); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108855","Computing methodologies-Computer graphics-Graphics systems and interfaces-Virtual reality;Human-centered computing-Ruman-computer interaction-Interaction paradigms-Virtual reality","Training;Visualization;Three-dimensional displays;Adaptive systems;Extended reality;Conferences;Collaboration","","","","20","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Potentials and Barriers of the Metaverse for Circular Economy","J. Kunert; H. van der Valk; H. Scheerer; C. Hoppe","Chair for Industrial Inform. Management, TU Dortmund University, Dortmund, NRW, Germany; Chair for Industrial Inform. Management, TU Dortmund University, Dortmund, NRW, Germany; Chair for Industrial Inform. Management, TU Dortmund University, Dortmund, NRW, Germany; Dept. of Industrial Manufacturing, Fraunhofer ISST, Dortmund, NRW, Germany",2024 Winter Simulation Conference (WSC),"20 Jan 2025","2024","","","3034","3045","Sustainability is a challenge for society that circular economy tries to tackle. The metaverse, as an emerging technology that incorporates digital twins and simulation in an immersive virtual environment, has not been thoroughly investigated in connection to circular economy. Thus, the purpose of this study is to summarize the potentials and barriers of the use of the metaverse for circular economy. By conducting a structured literature review, this paper categorizes the findings into dimensions that are important for both the metaverse and circular economy. A variety of potentials and barriers that cover different perspectives important for businesses aiming to comply with circular economy principles is discovered. The findings include potentials and barriers in several areas, like the access to the metaverse, connected costs, data, knowledge transfer, collaboration, innovation, product design, production planning, training of employees, and transportation. The results can be used to promote the implementation of circular economy principles.","1558-4305","979-8-3315-3420-2","10.1109/WSC63780.2024.10838869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10838869","","Training;Technological innovation;Costs;Metaverse;Transportation;Collaboration;Product design;Sustainable development;Business;Systematic literature review","","","","57","IEEE","20 Jan 2025","","","IEEE","IEEE Conferences"
"FPGA-Based Improved Background Subtraction for Ultra-Low Latency","Y. Oshima; Y. Yamaguchi; R. Tsugami; T. Fujiwara; T. Fukui; S. Narikawa","Graduate School of Science and Technology, University of Tsukuba, Tsukuba-shi, Ibaraki, Japan; Graduate School of Science and Technology, University of Tsukuba, Tsukuba-shi, Ibaraki, Japan; NTT Access Network Service Systems Laboratories, Nippon Telegraph and Telephone Corporation, Musashino-shi, Tokyo, Japan; NTT Access Network Service Systems Laboratories, Nippon Telegraph and Telephone Corporation, Musashino-shi, Tokyo, Japan; NTT Access Network Service Systems Laboratories, Nippon Telegraph and Telephone Corporation, Musashino-shi, Tokyo, Japan; NTT Access Network Service Systems Laboratories, Nippon Telegraph and Telephone Corporation, Musashino-shi, Tokyo, Japan",IEEE Access,"11 Nov 2024","2024","12","","164063","164080","In recent years, advancements in telecommunication technology have led to the proliferation of high-speed, large-capacity, low-latency communication. The COVID-19 pandemic has also accelerated the adoption of remote work globally, making real-time remote communication applications like web conferencing crucial for business, education, and other sectors. Despite the various demands for streaming applications, existing services often fail to meet the requirements of scenarios demanding ultra-low latency, such as surgical operations, remote control of automobiles, and real-time collaborative performances. To address this, we explored using FPGAs to achieve ultra-low latency processing in image processing tasks, explicitly focusing on background removal. Our study demonstrated the feasibility of using commercially available FPGA devices to reduce latency in background subtraction significantly compared to conventional methods. The results indicate that FPGA-based processing can provide the ultra-low latency needed for critical applications, enhancing the performance and user experience in remote operations and real-time streaming.","2169-3536","","10.1109/ACCESS.2024.3483548","Japan Society for the Promotion of Science(grant numbers:19H00806,21H04869); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10721462","FPGA;hardware direct implementation;low-latency;stream processing;background subtraction;background removal","Streaming media;Real-time systems;Performance evaluation;Hardware;Low latency communication;Image color analysis;Optical fiber networks;Field programmable gate arrays;Accuracy;Software","","","","43","CCBYNCND","18 Oct 2024","","","IEEE","IEEE Journals"
"Human-Centric Robotics: Enhancing Human-Robot Interaction with Reconfigurable Manipulators","A. S. Rajawat; S. B. Goyal; C. Chauhan; H. H. Khalaf","School of Computer Science & Engineering, Sandip University, Nashik, India; Faculty of Information Technology, City University Malaysia, Petaling Jaya, Malaysia; PCCOE, Pune, India; Department of Sciences, Al-Manara College for Medical Sciences, Maysan, Iraq","2024 International Conference on Augmented Reality, Intelligent Systems, and Industrial Automation (ARIIA)","1 Jul 2025","2024","","","1","7","Human Centric robotics is an emerging discipline of research in human robot interaction (HRI) through advanced and adaptable systems. Additional value is offered by integration of reconfigurable manipulators which provide superior flexibility and adaptability versus traditional rigid designs. The interaction techniques achieved by these manipulators sufficiently vary the shape, assemble and disassemble in real time, and can manipulate in a dynamic environment. This versatility is critical for such application as collaborative industrial tasks and personal assistant robots, where it helps increase both safety and productivity. Reconfigurable manipulators represent a significant leap toward more effective and human friendly robotics by enabling precise, task specific configurations.","","979-8-3315-1836-3","10.1109/ARIIA63345.2024.11051946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11051946","Human-Centric Robotics;Reconfigurable Manipulators;Human-Robot Interaction;Adaptive Robotics;Collaborative Robots;User-Centric Interfaces","Productivity;Adaptive systems;Service robots;Shape;Human-robot interaction;Real-time systems;Safety;Manufacturing;Robots;Manipulator dynamics","","","","20","IEEE","1 Jul 2025","","","IEEE","IEEE Conferences"
"XR Technologies-Based Experimental Therapy System for Visual Enhancement of Patient's Brain Associations","B. Sobota; Š. Korečko; R. Grec","Dept. of Computers and Informatics, Technical University of Košice, Slovakia; Dept. of Computers and Informatics, Technical University of Košice, Slovakia; Dept. of Computers and Informatics, Technical University of Košice, Slovakia",2024 IEEE 17th International Scientific Conference on Informatics (Informatics),"5 Mar 2025","2024","","","367","371","This paper describes an experimental therapeutic system based on eXtended reality technologies for the visual enhancement of the patient's brain associations. The application was implemented using Unreal Engine. The application environment can be easily customized and changed according to the patient's needs, which improves the therapist-patient interaction. The system increases the possibility of improving the patient's motor skills and partially also his cognitive abilities in the form of working with a virtual machine (the virtual lathe). The patient performs tasks through an interaction with virtual objects (lathe controllers). The system was verified and evaluated by 6 respondents using the SUS questionnaire.","","979-8-3503-8768-1","10.1109/Informatics62280.2024.10900882","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10900882","therapist-patient interaction;simulation;therapy;virtual reality;motor skills","Visualization;Extended reality;Virtual environments;Medical treatment;Motors;Virtual machines;Digital twins;Informatics;Engines","","","","20","IEEE","5 Mar 2025","","","IEEE","IEEE Conferences"
"Virtual and Augmented Reality in Interactive Entertainment: Unlocking New Dimensions of Immersive Interaction","J. S. Ghulam Al Balushi; M. I. Ahmed Al Jabri; S. Palarimath; C. R. Mohamed; V. Radhakrishnan; M. B. Thumu","College of Computing and Information Sciences, University of Technology and Applied Sciences, Salalah, Sultanate of Oman; College of Computing and Information Sciences, University of Technology and Applied Sciences, Salalah, Sultanate of Oman; College of Computing and Information Sciences, University of Technology and Applied Sciences, Salalah, Sultanate of Oman; College of Computing and Information Sciences, University of Technology and Applied Sciences, Salalah, Sultanate of Oman; College of Computing and Information Sciences, University of Technology and Applied Sciences, Salalah, Sultanate of Oman; College of Computing and Information Sciences, University of Technology and Applied Sciences, Salalah, Sultanate of Oman",2024 2nd International Conference on Computing and Data Analytics (ICCDA),"10 Feb 2025","2024","","","1","6","Virtual Reality (VR) offers an immersive experience with position tracking and 3D near-eye displays, enabling users to enter virtual surroundings. Conversely, Augmented Reality (AR) superimposes computer-generated content onto the real world, integrating digital and physical environments through visual, aural, tactile, and other sensory modalities. Both technologies are transforming user engagement with content, providing the opportunity to explore remote locations, communicate with digital characters, or assume leading roles in interactive entertainment events. While VR completely immerses users in simulated surroundings, AR enriches real-world contexts by incorporating interactive elements and contextual data. This study examines the transformative effects of VR and AR in interactive entertainment, emphasizing its various uses, benefits, and constraints. It emphasizes how new technologies have transformed narrative, facilitating enhanced user involvement and a more dynamic feeling of presence. The review analyzes the present and prospective capabilities of VR and AR in transforming social interactions, narrative-centric experiences, and cooperative gameplay. In addition to entertainment, the article examines the ramifications of AR and VR in education, training, and healthcare, where immersive environments demonstrate significant efficacy. The report highlights the crucial impact these technologies have in enhancing human-computer interaction across various industries.","","979-8-3315-4257-3","10.1109/ICCDA64887.2024.10867296","Ministry of Higher Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10867296","augmented reality;virtual reality;architecture;gaming;health sector","Headphones;Video games;Visualization;Three-dimensional displays;Entertainment industry;Medical services;Immersive experience;Transforms;Software;Hardware","","","","30","IEEE","10 Feb 2025","","","IEEE","IEEE Conferences"
"Unleashing the Power of Wireless Communication in Healthcare by Empowering Patient Care and Connectivity: A Comprehensive Survey","U. Chaudhary; M. Furqan Ali; A. Kumar; A. Sharma; D. K. Nalin Jayakody","COPELABS, Lusófona University, Lisbon, Portugal; COPELABS, Lusófona University, Lisbon, Portugal; School of Computer Science Engineering and Technology, Bennett University (The Times Group), Greater Noida, Uttar Pradesh, India; The LNM Institute of Information Technology, Jaipur, Rajasthan, India; COPELABS, Lusófona University, Lisbon, Portugal",IEEE Access,"11 Jul 2025","2025","13","","117239","117299","The emergence of the wireless network as a potentially revolutionary innovation has the ability to change the field of medical diagnostics. This in-depth study aims to explore the various aspects of using the latest wireless technologies to improve the standard of care given to patients and the interactions between patients and healthcare providers. This study investigates a wide range of issues such as patient-centric communication technology, 6G based applications using smart technologies, real-time communication protocols, implementation of artificial intelligence (AI) and blockchain technology in healthcare and the use of wireless devices for remote patient monitoring. 6G wireless communication brings transformative capabilities to healthcare, offering ultra-reliable and low-latency communication (URLLC), improved network capacity, and higher data rates. These advances enable the real-time transmission of critical health data, support complex medical applications, facilitate remote consultations, surgical robotics, and AI-driven diagnostics. This study highlights the significance and implications of combining these concepts in the context of 5G and beyond, paving the way for connected healthcare, personalized medicine, and unprecedented levels of efficiency and innovation. In addition, it also investigates the obstacles and potential associated with the implementation of wireless communication in the healthcare industry. These challenges and opportunities include data security and privacy issues, as well as the need for a robust communication infrastructure. This paper demonstrates the influence that wireless communication","2169-3536","","10.1109/ACCESS.2025.3578344","Scheme for Promotion of Academic and Research Collaboration (SPARC), Government of India(grant numbers:SPARC/2024-2025/NXTG/P3524); Sri Lanka Institute of Information Technology(grant numbers:PVC(R&I)/RG/2024/12); Cooperativa de Formação e Animação Cultural (COFAC), C.R.L. (University of Lusófona University), via the Project PortuLight/Centro de Tecnologia e Sistemas-Universidade NOVA de Lisboa/People-Centered Computing and Cognition Research Center (COFAC/ILIND/COPELABS/2/2023); National Funds through the Fundação para a Ciência e a Tecnologia (FCT)—as part of the projects Ultra Reliable and Low Latency Communications-Unmanned Aerial Vehicle (URLLC-UAV)(grant numbers:2023.08191.CEECIND); Centro de Tecnologia e Sistemas-Universidade NOVA de Lisboa (UNINOVA-CTS)(grant numbers:UIDB/00066/2020); COPELABS(grant numbers:UIDB/04111/2020); European Commission via Marie Skłodowska-Curie Actions (MSCA) as part of the Project REMARKABLE(grant numbers:101086387); European Commission via Marie Skłodowska-Curie Actions (HORIZON MSCA-SE-2023) as part of the Project ArgumeNtaTIon-Driven explainable artificial intelligence fOr digiTal mEdicine (ANTIDOTE)(grant numbers:101183162); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029189","Internet of Things (IoTs);Internet of Healthcare Things (IoHTs);Internet of Medical Things (IOMT);non orthogonal multiple access (NOMA);artificial intelligence (AI);blockchain;massive machine type communication (mMTC);network slicing;physical layer security (PLS);5G and 6G wireless communication","Medical services;Wireless communication;Internet of Things;Real-time systems;Medical diagnostic imaging;Artificial intelligence;Wireless networks;Telemedicine;Technological innovation;Protocols","","","","289","CCBY","10 Jun 2025","","","IEEE","IEEE Journals"
"Towards a Unified Definition of Social XR","M. Moslavac; S. Vlahović; L. Skorin-Kapov","Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia",2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"24 Apr 2025","2025","","","569","573","Social Extended Reality (Social XR) is an evolving domain within Extended Reality (XR), encompassing immersive technologies such as Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR). Despite its growing significance in both research and practice, the term “Social XR” remains ambiguously defined, with inconsistent usage across academic and industry contexts. This paper seeks to address this challenge by synthesising existing definitions and interpretations of Social XR, aiming to encourage a clearer, unified conceptualisation. Through an analysis of current research, we identify key themes underpinning the concept of Social XR, such as shared immersive 3D environments, blending of virtual and physical elements, real-time multiuser interaction, and user representation. Thus, we propose a comprehensive definition of Social XR, aiming to stimulate further discussion, encouraging refinement toward a coherent understanding of the term. Additionally, we build on previous work and introduce the XR3C Model, for a better understanding of collaboration within immersive environments and its relation to Social XR.","","979-8-3315-1484-6","10.1109/VRW66409.2025.00121","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972808","Extended reality (XR);immersive experience;social computing;multimedia communication;collaboration","Solid modeling;Social computing;Three-dimensional displays;Extended reality;Collaboration;Mixed reality;User interfaces;Real-time systems;Multimedia communication;Research and development","","","","34","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"XR for educational anatomy: an Immersive human atlas with chatbot","J. -F. Uhl; P. Reyes; C. Quihuis; P. Belchior; J. Jorge","Director of the UNESCO Chair of Digital Anatomy, Paris Cité University, Paris, France; Universidad Nacional Autónoma de México, México City, México; Instituto Tecnológico y de Estudios Superiores de Monterrey, Mexico City, México; INESC-ID, Tagus Park, Porto Salvo, Portugal; UNESCO Chair on AI & VR, Instituto Superior Técnico, Av Rovisco Pais, Lisboa, Portugal",2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"24 Apr 2025","2025","","","1016","1020","Immersive reality has emerged as a groundbreaking and promising approach for teaching anatomy, providing unique learning experiences while complementing traditional educational methods. Existing immersive software, such as Organon® and HoloLens®, offer valuable tools but remain limited in anatomical detail and interactivity. We present a novel educational approach: an immersive human atlas that integrates anatomical slices from the Visible Korean Human dataset (male and female) into a 3D environment. This platform enhances anatomical visualization and incorporates a Large Language Model (LLM) to support user interaction and understanding. By combining precise anatomical slices within the 3D model, the atlas provides an enriched and comprehensive learning experience for medical education.","","979-8-3315-1484-6","10.1109/VRW66409.2025.00205","Fundação para a Ciência e a Tecnologia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972851","Extended Reality;Immersive Environments;Anatomy Education;Large Language Models;Cross Computing","Visualization;Solid modeling;Three-dimensional displays;Extended reality;Large language models;Conferences;Education;User interfaces;Software;Anatomy","","","","18","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"An Architecture for Real-Time Interactive Music Performances","N. Amarie; G. Fadda; M. Murroni; M. Alexandru; V. Popescu","University of Brasov, Romania; University of Cagliari, UdR CNIT of Cagliari, Italy; University of Cagliari, UdR CNIT of Cagliari, Italy; University of Brasov, Romania; University of Brasov, Romania",2025 23rd Mediterranean Communication and Computer Networking Conference (MedComNet),"6 Aug 2025","2025","","","1","3","We present a system architecture that delivers real-time Extended Reality (XR) music performances. Live shows are captured using multichannel audio and depth-enhanced video, then processed and streamed through a distributed media platform that supports low-latency audio rendering and dynamic scene composition. This approach balances performance with scalability and is suitable for deployment on standard infrastructure. Our findings demonstrate that the system can bridge physical distances, support audience feedback, and provide an engaging, interactive concert experience that is scalable across diverse environments.","2996-4261","979-8-3315-0327-7","10.1109/MedComNet65822.2025.11103534","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11103534","XR Audio;Networked Music Performance;Real-Time Interaction","Extended reality;Spectral efficiency;Scalability;Systems architecture;Real-time systems;Quality of experience;Synchronization;Low latency communication;Standards;Videos","","","","12","IEEE","6 Aug 2025","","","IEEE","IEEE Conferences"
"Role of Metaverse in Operating Business for Accounting","R. Maurya; S. S. M; S. K. Baral; K. Kumar","School of Management Studies, National Forensic Sciences University, New Delhi, India; Department of Commerce, Indira Gandhi National Tribal University, Amarkantak, Madhya Pradesh, India; Department of Commerce, Faculty of Commerce & Management, Indira Gandhi National Tribal University, Amarkantak, Madhya Pradesh, India; Faculty of Commerce, Shri Rawatpura Sankar University, Raipur, Chhatisgarh, India",2024 International Conference on Artificial Intelligence and Quantum Computing (AIQC),"17 Jul 2025","2024","","","107","112","The emergence of the metaverse presents unprecedented opportunities for businesses, particularly within the accounting sector, by enabling immersive, interactive digital environments. This study explores the transformative role of metaverse technology in accounting business operations, addressing its potential and the associated challenges. Integrating metaverse solutions within accounting can revolutionize financial analysis, auditing, and client interactions. The metaverse offers a platform to enhance the goodwill of IT firms, manage NFT (non-fungible tokens), and sales expenses and improve customer experiences. However, practical implementation faces hurdles such as data security, technological adaptability, cost concerns, and a significant learning curve for professionals. This research investigates these obstacles and proposes strategic frameworks for adopting metaverse technology in accounting. The study also assesses the future impact of metaverse integration on business operations, suggesting that, despite the challenges, the metaverse can reshape traditional accounting practices. Ultimately, the findings contribute to a roadmap for accounting firms and professionals seeking to harness the benefits of metaverse technology in a rapidly evolving digital landscape. The study concludes that metaenvironment businesses' reporting structure uses accounting to access all significant financial activities virtually.","","979-8-3315-2764-8","10.1109/AIQC64330.2024.00042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11079438","Metaverse;technology;business models;accounting;virtual environment","Quantum computing;Costs;Metaverse;Data security;Computational modeling;Nonfungible tokens;Artificial intelligence;Faces;Business","","","","23","IEEE","17 Jul 2025","","","IEEE","IEEE Conferences"
"Immersive VR User Interaction Design in MaxWhere XR","G. Persa; D. Mészáros; N. Rajos; T. Budai; G. Peller; C. Tóth; B. Heilig; S. Puspán; P. Galambos","MISTEMS Innovation and Services Ltd., Győr, Hungary; MISTEMS Innovation and Services Ltd., Győr, Hungary; MISTEMS Innovation and Services Ltd., Győr, Hungary; MISTEMS Innovation and Services Ltd., Győr, Hungary; MISTEMS Innovation and Services Ltd., Győr, Hungary; MISTEMS Innovation and Services Ltd., Győr, Hungary; MISTEMS Innovation and Services Ltd., Győr, Hungary; MISTEMS Innovation and Services Ltd., Győr, Hungary; MISTEMS Innovation and Services Ltd., Győr, Hungary",2024 IEEE 24th International Symposium on Computational Intelligence and Informatics (CINTI),"13 Jan 2025","2024","","","000111","000116","This paper presents a case study on transitioning user experience from desktop VR to immersive VR within the MaxWhere XR framework. It explores modifications to accommodate the shift to immersive virtual reality environments. Drawing from scientific research, the study focuses on user interaction design, including locomotion techniques, spatial UI elements, and hybrid interaction models. The paper details the technical implementations required to use MaxWhere XR on wide variety of VR devices. It presents the components form the foundation for designing and implementing the immersive user interactions, ensuring that they are intuitive and efficient in a virtual reality environment. Finally, the paper outlines the effects of these changes on user experience and suggests future development directions for further enhancement.","2471-9269","979-8-3503-5343-3","10.1109/CINTI63048.2024.10830883","National Research, Development and Innovation Fund(grant numbers:2021-1.1.4-GYORSÍTÓSÁV); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10830883","MaxWhere;XR;VR;user interaction design","Performance evaluation;Hands;Solid modeling;Virtual reality;Aerospace electronics;User experience;Usability;Informatics;Computational intelligence","","","","18","IEEE","13 Jan 2025","","","IEEE","IEEE Conferences"
"An Overview of the 4th International Workshop on eXtended Reality for Industrial and Occupational Supports (XRIOS)","B. Marques; S. Silva; F. Barros; T. Araújo; C. Ferreira; P. Dias; B. S. Santos","IEETA, DETI, LASI, University of Aveiro, Portugal; IEETA, DETI, LASI, University of Aveiro, Portugal; IEETA, DETI, LASI, University of Aveiro, Portugal; IEETA, ESAN, LASI, University of Aveiro, Portugal; IEETA, DEGEIT, LASI, University of Aveiro, Portugal; IEETA, DETI, LASI, University of Aveiro, Portugal; IEETA, DETI, LASI, University of Aveiro, Portugal",2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"24 Apr 2025","2025","","","1044","1045","The 4th International Workshop on the eXtended Reality for Industrial and Occupational Supports (XRIOS) aims to identify the current state of XR research and the gaps in the scope of human factors and ergonomics, related to industrial and occupational tasks, and discuss potential future directions. XRIOS was held for the first time at IEEE VR 2022, where it served as the first venue to build an interdisciplinary community that bridges XR developers/practitioners and human factors and ergonomics researchers interested in industrial and occupational XR applications. XRIOS 2025 follows the success of previous editions in response to society’s growing needs by expanding the community and providing more opportunities.","","979-8-3315-1484-6","10.1109/VRW66409.2025.00210","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10973014","eXtended Reality;Virtual Reality;Augmented Reality;Industrial Support;Occupational Support;Human Factors","Bridges;Three-dimensional displays;Extended reality;Conferences;Ergonomics;Human factors;User interfaces;Augmented reality","","","","7","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"Use of Virtual Reality in the Teaching of Industrial Instrumentation","J. D. Guzmán; D. E. Guzmán; C. F. Rengifo","Programa de Ingeniería Industrial, Facultad de Ingeniería y Arquitectura, Fundación Universitaria de Popayán, Popayán, Colombia; Escuela de Ciencias Básicas, Tecnología e Ingeniería, Universidad Nacional Abierta y a Distancia, Bogota, Colombia; Departamento de Electrónica, Instrumentación y Control, Universidad del Cauca, Popayán, Colombia",IEEE Revista Iberoamericana de Tecnologias del Aprendizaje,"15 Oct 2024","2024","19","","212","219","Virtual reality (VR) has seen remarkable advancements, becoming more compact and feature-rich. Although VR has become immensely popular in the video game industry, its adoption in training, healthcare, and education has been relatively modest. The decreasing costs of VR technology make it increasingly accessible, making it an attractive alternative to expensive laboratory facilities, such as those required in engineering programs. This article describes the development of LABNICA, an immersive virtual reality application designed to enhance the teaching process in industrial instrumentation courses. Built with Unity3D and incorporating Meta Quest 2 technology, LABNICA allows users to interact with a virtual industrial environment that simulates the process of setting the parameters for the differential pressure transmitter, performing electrical connections, measuring voltages and currents, and manipulating tank valves. The students’ perception of the tool was evaluated through a usability survey, which considered reference frameworks: 96.5% found the laboratory guide instructions clear, while 94.1% were satisfied with the application mechanics, user interface, and aesthetic design; 80% indicated that there is a need for some prior knowledge in instrumentation. Additionally, 95.3% considered the application convenient for learning industrial instrumentation, highlighting the need to implement virtual reality laboratories in other subjects.","1932-8540","","10.1109/RITA.2024.3471980","Fundaci?n Universitaria de Popay?n(grant numbers:10000000 COP); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10703112","Education;industrial instrumentation;simulator;virtual reality","Instruments;Process control;Tutorials;Education;Virtual reality;Training;Pressure measurement;Industries","","","","32","IEEE","2 Oct 2024","","","IEEE","IEEE Journals"
"Vibrotactile cues on multiuser collaboration within virtual environments","A. Erfanian; Y. Hu","Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, CANADA; Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, CANADA","2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","30 Nov 2017","2017","","","3541","3546","Multiuser collaboration within virtual environments (VEs) need effective means of communication. A real-world collaboration benefits from verbal and nonverbal communication channels. To promote the nonverbal communication within VEs, some research studies have explored various forms of vibrotactile cues that are either spatially co-located with an interaction device held by a user's hand, or dislocated from the device. These studies are focused on VEs that are established on a leader and a follower paradigm. A multiuser collaborative VE is however governed by an interaction model to handle the simultaneous interactive commands issued by multiple peer users. Proposed in our earlier work, the dynamic priority model (DP) is an interaction model that yields perceived equality in interaction and promotes the multiuser collaboration when peer users communicate through verbal dialogue. As a key means of nonverbal communication in VEs, co-located and dislocated vibrotactile cues might affect the perceived equality in interaction, and how users collaborate under the DP model. In this study, we have thus investigated the role of vibrotactile cues on multiuser collaboration under the DP model. We undertook this investigation in two cue settings: co-located and dislocated. We observed that the DP model yields perceived equality in interaction both in the absence and presence of vibrotactile cues. Also, the co-located cues significantly enhanced the multiuser collaboration compared to the dislocated cues. These observations imply a potential application of co-located vibrotactile cues to enhance multiuser collaboration within VEs.","","978-1-5386-1645-1","10.1109/SMC.2017.8123180","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8123180","multiuser collaboration;virtual environments;vibrotactile cues;interaction models","Collaboration;Instruction sets;Geology;Color;Virtual environments;Force","","","","25","IEEE","30 Nov 2017","","","IEEE","IEEE Conferences"
"ISE provides a new frontier for synthesis of complex engineering products and missions","A. K. Noor; S. L. Venneri","Center for Advanced Computational Technology, NASA Langley Research Center, University of Virginia, Hampton, VA, USA; Chief Technologist, NASA Headquarters, Washington D.C., DC, USA","SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)","6 Aug 2002","1998","3","","2698","2703 vol.3","The intelligent synthesis environment (ISE) being developed by NASA, UVA and JPL for significantly enhancing the rapid creation of innovative affordable products and missions is described. ISE uses a synergistic combination of leading-edge technologies, including high performance computing, high-capacity communications and networking, virtual product development, knowledge-based engineering, computational intelligence, human-centered computing, and product information management. The environment will link scientists, design teams, manufacturers, suppliers and consultants who participate in the mission synthesis, as well as in the creation and operation of the aerospace system. It will radically advance the process by which complex science missions are synthesized, and high-tech engineering systems are designed, manufactured and operated. The human-centered computing, infrastructure for distributed collaboration, rapid synthesis and simulation tools, and life cycle integration and validation are described.","1062-922X","0-7803-4778-1","10.1109/ICSMC.1998.725068","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=725068","","Network synthesis;Computational intelligence;Human computer interaction;Competitive intelligence;NASA;Space technology;High performance computing;Product development;Knowledge engineering;Information management","","","","9","IEEE","6 Aug 2002","","","IEEE","IEEE Conferences"
"Development and Implementation of a Virtual Reality Simulation for an Immersive College Environment Using the Unity Game Engine","A. R. Lendalay; R. Pabba; S. R. Katta; M. A. Ahmed; R. U. Karthik; K. S. Prasad","Computer Science With AI & ML, Hyderabad Institute of Technology and Management, Hyderabad, India; Computer Science With AI & ML, Hyderabad Institute of Technology and Management, Hyderabad, India; Computer Science With AI & ML, Hyderabad Institute of Technology and Management, Hyderabad, India; Computer Science With AI & ML, Hyderabad Institute of Technology and Management, Hyderabad, India; Computer Science With AI & ML, Hyderabad Institute of Technology and Management, Hyderabad, India; Mechanical Engineering, Hyderabad Institute of Technology and Management, Hyderabad, India",2024 IEEE North Karnataka Subsection Flagship International Conference (NKCon),"10 Dec 2024","2024","","","1","8","Virtual Reality (VR) simulation has emerged as a transformative technology with applications spanning various fields such as education, healthcare, training, and entertainment. This research paper explores the advancements, methodologies, and impacts of VR simulation, providing a comprehensive review of current technologies and their implementations.This paper details the development and implementation of a Virtual Reality (VR) walkthrough simulation of a college environment using the Unity game engine. The project aims to offer users an immersive and interactive experience that closely mirrors the sensation of navigating through a physical establishment. The simulation integrates lifelike visuals, intuitive navigation, and interactive elements to create a compelling virtual environment. Through this innovative approach, users can experience a realistic and engaging representation of the college, enhancing their understanding and exploration of the space. Traditional architectural models, typically rendered with pen-and-paper blueprints or clay models, often lack detailed visualization and feasibility for quick modifications. This research explores the advantages of utilizing Virtual Reality (VR) for visualizing architectural models of college environments with significantly enhanced detail, both exterior and interior. VR technology allows for the immediate identification and correction of errors, facilitating rapid and efficient updates. Unlike traditional methods, which require redrawing entire blueprints for minor changes, VR’s layered structure permits individual modifications without impacting the whole model. Leveraging the Unity game engine, multiple architects can collaborate seamlessly, working together with clients to develop a satisfactory and detailed VR model of the building. This approach not only improves design accuracy but also enhances collaborative efforts, demonstrating the substantial benefits of VR in modern architectural practices.","","979-8-3503-6456-9","10.1109/NKCon62728.2024.10774914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10774914","Virtual Reality (VR);Unity game engine;V R -simulation;College environment;Modern architectural practices;Transformative technology","Solid modeling;Visualization;Accuracy;Navigation;Virtual environments;Games;Space exploration;Stakeholders;Engines;Image reconstruction","","","","27","IEEE","10 Dec 2024","","","IEEE","IEEE Conferences"
"Interaction Prediction for Content Synchronization of Net-based Shared Workspaces","B. Migge; A. Kunz","Institute for Machine Tools and Ma, ETH Zurich, Zurich, Switzerland; Institute for Machine Tools and Ma, ETH Zurich, Zurich, Switzerland",2012 International Conference on Cyberworlds,"25 Oct 2012","2012","","","241","245","Digital collaborative environments enable spatially separated users to access and modify shared data over network. However, transmission delays of the network lead to inconsistent data and reduce the efficiency of collaboration due to interaction conflicts. In this paper, we present a predictive screen-locking algorithm to avoid interaction collisions on net-based shared interactive screens. A model-based predictor calculates the user's next interaction given his past one. The algorithms locks critical objects to the remote station which is less likely to interact with the object. Although the predictor continuously adapts to the user's interaction behavior, an initial interaction model is needed when the collaboration session is started. Hence, we deduce a reasonable, probabilistic interaction model from a large screen collaboration user study.","","978-1-4673-2736-7","10.1109/CW.2012.42","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6337427","Networked collaboration;Human-computer interfaces;User modeling","Predictive models;Collaboration;Adaptation models;Synchronization;Prediction algorithms;Probabilistic logic;Delay","","","","13","IEEE","25 Oct 2012","","","IEEE","IEEE Conferences"
"Investigating the Factors Influencing User Loyalty, Purchase Intention, and Word-of-Mouth in Virtual Reality","H. Jo; S. Jang","Headquarters, HJ Institute of Technology and Management Jungdong-ro 71 39, Bucheon-si, Gyeonggi-do, 14721 Republic of Korea; Headquarters, Jini Factory Cheongsa-ro 65, Seo-gu, Daejeon, 118-101, 35216 Republic of Korea",Presence,"3 Jan 2025","2024","33","","193","219","","1054-7460","","10.1162/pres_a_00423","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10824738","","","","","","","","3 Jan 2025","","","MIT Press","MIT Press Journals"
"A Review: 3D Sketching Technology and Applications in Augmented Reality","J. Bai; M. S. Sunar; N. M. Suaib","Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Johor, Malaysia; Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Johor, Malaysia; Faculty of Computing, Universiti Teknologi Malaysia, Johor Bahru, Johor, Malaysia",IEEE Access,"21 Aug 2025","2025","13","","144745","144769","AR (Augmented Reality) sketching technology has driven innovation in content creation and design, and the popularity of mobile devices has increased the usability of 3D (three-dimensional) sketching, but many challenges still exist, which limit the full potential of AR sketching. Among them, interaction and technical limitations, such as recognition accuracy, the diversity of interaction manipulations, and steep learning curves and other interaction issues, continuously affect user experience and creative efficiency. These aspects have not yet been comprehensively reviewed, leaving a crucial gap in the literature. This paper fills this gap by conducting an in-depth review of the interactive technologies, interactive manipulations, hardware devices, and basic software tools used in various AR sketching studies classified by interactive devices. By systematically analyzing these elements, this review clearly understands how current AR sketching methods promote or limit user interaction and creative expression, and identifies existing challenges in terms of operational limitations, technical limitations, user experience and other aspects. Furthermore, this review explores emerging trends including more natural user interaction, more comprehensive sketching manipulations, and enhanced real-time collaboration, and summarizes a conceptual framework for AR sketching research and future research directions. By filling these knowledge gaps, this review not only highlights the current limitations, but also provides guidance for future research, offers valuable insights, and promotes the development of more complex and humanized AR 3D sketching technologies.","2169-3536","","10.1109/ACCESS.2025.3598869","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11124858","Interaction technology;3D drawing;sketching;augmented reality;gesture;review","Three-dimensional displays;Augmented reality;Brushes;Collaboration;Visualization;Training;Tracking;Technological innovation;Gesture recognition;User experience","","","","71","CCBYNCND","14 Aug 2025","","","IEEE","IEEE Journals"
"Align-RDW: Alignment-based Redirected Walking for Multi-User VR scenarios","T. Dong; H. Zhang; H. Kong; S. Lv; F. Li","College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China",2024 IEEE International Conference on Multimedia and Expo (ICME),"30 Sep 2024","2024","","","1","6","In recent years, multi-user collaboration has emerged as a trend in virtual reality. However, the existing redirected walking methods for multi-user VR scenarios usually are devoted to the obstacle avoidance, neglecting the users’ relative positions in both virtual environment(VE) and physical environments (PE), as well as the natural visual relationships. In order to enhance the collaborative experience, this paper presents a novel Alignment-based Redirected Walking for Multi-User VR scenarios, Align-RDW. Our algorithm will dynamically selects an optimal moving target for the current user’s alignment. Our approach integrates concepts such as user state loss and dynamic guiding points, applying auxiliary forces to enhance user alignment performance. Simultaneously, we utilize the calculated optimal deviation angle to adjust the user’s orientation. We evaluated the algorithm through simulations and Live-User experiments. The results demonstrate that our strategy achieves a longer reset distance, as well as smaller alignment distance errors and angle errors than others.","1945-788X","979-8-3503-9015-5","10.1109/ICME57554.2024.10687846","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10687846","Virtual Reality;Multi-user redirected walking;Dynamic Alignment;State Loss;Experience Optimization","Legged locomotion;Visualization;Solid modeling;Heuristic algorithms;Dynamics;Collaboration;Virtual reality;Market research;Collision avoidance;Optimization","","","","21","IEEE","30 Sep 2024","","","IEEE","IEEE Conferences"
"Guest Editors’ Introduction","A. Riener; M. Jeon; M. Reiner","Johannes Kepler University Linz, Austria; Michigan Technological University, USA; Technion, Israel Institute of Technology, Haifa, Israel",Presence,"17 Jul 2014","2014","23","1","iii","iv","","1054-7460","","10.1162/PRES_e_00186","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6855499","","","","","","","","17 Jul 2014","","","MIT Press","MIT Press Journals"
"Advances in Collaborative Virtual Environments Guest Editors' Introduction","R. W. H. Lau; M. Zyda","Department of Computer Science and Department of CEIT, City University of Hong Kong, Hong Kong; The MOVES Institute, Naval Postgraduate School, Monterey, California, U.S.A.",Presence,"19 May 2014","2004","13","3","iii","iv","","1054-7460","","10.1162/1054746041422361","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6788795","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"AirBoard: An AI Powered Whiteboard","H. Gandhi; B. Wanamaker; A. Kulowski; C. Jaiswal; K. Shah; B. O’Neill; S. Rzeszutek","School of Computing and Engineering, Quinnipiac University, Connecticut; School of Computing and Engineering, Quinnipiac University, Connecticut; School of Computing and Engineering, Quinnipiac University, Connecticut; School of Computing and Engineering, Quinnipiac University, Connecticut; School of Computing and Engineering, Quinnipiac University, Connecticut; School of Computing and Engineering, Quinnipiac University, Connecticut; Innovations in Learning and Teaching, Quinnipiac University, Connecticut",2025 IEEE World AI IoT Congress (AIIoT),"12 Aug 2025","2025","","","0333","0339","The increasing reliance on remote and hybrid learning environments has highlighted the need for intuitive and accessible digital collaboration tools. Digital whiteboarding solutions often require special hardware such as tablets and styluses, which can be costly and restrictive. AirBoard is a virtual whiteboard that uses hand-tracking technology to enable users to write, draw, and interact with digital content using only an ordinary webcam and hand gestures. By eliminating the need for additional hardware, AirBoard enhances accessibility for educators. The system features session storage for retrieving previous content and an AI assist tool that provides real-time suggestions, facilitating a more interactive and engaging teaching experience. Designed for users of all technical backgrounds, AirBoard maintains the familiarity of a traditional whiteboard while integrating modern tools for an improved experience. By bridging the gap between physical and digital whiteboarding, AirBoard promotes engagement and efficiency across many applications.","","979-8-3315-2508-8","10.1109/AIIoT65859.2025.11105304","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11105304","Virtual Whiteboard;Hand Tracking;Gesture Recognition;Artificial Intelligence;Remote Learning;Accessibility","Hands;Webcams;Collaboration;Gesture recognition;Touch sensitive screens;Hardware;Real-time systems;Data models;Usability;Videos","","","","14","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"Tutorials and workshops","",,2009 IEEE Virtual Reality Conference,"7 Apr 2009","2009","","","313","324","Listing of the tutorials and workshops available as part of the 2009 IEEE Virtual Reality Conference.","2375-5334","978-1-4244-3943-0","10.1109/VR.2009.4811072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4811072","","","","","","1","IEEE","7 Apr 2009","","","IEEE","IEEE Conferences"
"An animated 3D manipulator for distributed collaborative window-based applications","M. L. Davies; B. H. Thomas","School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia; School of Computer and Information Science, University of South Australia, Mawson Lakes, SA, Australia",Proceedings Second Australasian User Interface Conference. AUIC 2001,"7 Aug 2002","2001","","","116","123","This paper presents a new animated 3D graphical object manipulator to improve the visualisation of distributed window-based collaborative 3D applications. By applying animation techniques to the user interface, the experience of multi-user interaction may be enhanced. A major problem associated with distributed collaborative 3D applications is that interactions among users may cause conflicts, and it may be difficult to convey what these conflicts are. In addition, there is a need for additional feedback when interacting with 3D objects in current workstation 3D virtual reality applications. A prototype application is presented in the paper to demonstrate this new animated manipulator.","1530-0951","0-7695-0969-X","10.1109/AUIC.2001.906287","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=906287","","Animation;Collaboration;Collaborative work;Virtual environment;Mice;Application software;User interfaces;Workstations;Feedback;Avatars","","","","12","IEEE","7 Aug 2002","","","IEEE","IEEE Conferences"
"TeamPortal: Exploring Virtual Reality Collaboration Through Shared and Manipulating Parallel Views","X. Wang; L. Shen; L. Chen; M. Fan; L. Lee","Hong Kong Polytechnic University, Hong Kong, Hong Kong; Hong Kong University of Science and Technology, Guangzhou, China; Hebei GEO University, China; Hong Kong University of Science and Technology, Guangzhou, China; Hong Kong Polytechnic University, Hong Kong, Hong Kong",IEEE Transactions on Visualization and Computer Graphics,"25 Apr 2025","2025","31","5","3314","3324","Virtual Reality (VR) offers a unique collaborative experience, with parallel views playing a pivotal role in Collaborative Virtual Environments by supporting the transfer and delivery of items. Sharing and manipulating partners' views provides users with a broader perspective that helps them identify the targets and partner actions. We proposed TeamPortal accordingly and conducted two user studies with 72 participants (36 pairs) to investigate the potential benefits of interactive, shared perspectives in VR collaboration. Our first study compared ShaView and TeamPortal against a baseline in a collaborative task that encompassed a series of searching and manipulation tasks. The results show that TeamPortal significantly reduced movement and increased collaborative efficiency and social presence in complex tasks. Following the results, the second study evaluated three variants: TeamPortal+, SnapTeamPortal+, and DropTeamPortal+. The results show that both SnapTeamPortal+ and DropTeamPortal+ improved task efficiency and willingness to further adopt these technologies, though SnapTeamPortal+ reduced co-presence. Based on the findings, we proposed three design implications to inform the development of future VR collaboration systems.","1941-0506","","10.1109/TVCG.2025.3549569","Hong Kong Polytechnic University's Start-up Fund for New Recruits(grant numbers:P0046056); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10918848","TeamPortal;Virtual Reality;Collaboration;Share Perspectives;Parallel Views","Collaboration;Visualization;Virtual environments;Avatars;Object recognition;Videos;User experience;Training;Synchronization;Real-time systems","","","","73","IEEE","11 Mar 2025","","","IEEE","IEEE Journals"
"Exploring Audio Interfaces for Vertical Guidance in Augmented Reality via Hand-Based Feedback","R. Guarese; E. Pretty; A. Renata; D. Polson; F. Zambetta","School of Computing Technologies, RMIT University, Austria; School of Computing Technologies, RMIT University, Austria; School of Psychology, Deakin University, Austria; School of Design, RMIT University, Austria; School of Computing Technologies, RMIT University, Austria",IEEE Transactions on Visualization and Computer Graphics,"19 Apr 2024","2024","30","5","2818","2828","This research proposes an evaluation of pitch-based sonification methods via user experiments in real-life scenarios, specifically vertical guidance, with the aim of standardizing the use of audio interfaces in AR in guidance tasks. Using literature on assistive technology for people who are blind or visually impaired, we aim to generalize their applicability to a broader population and for different use cases. We propose and test sonification methods for vertical guidance in a series of hand-navigation assessments with users without visual feedback. Including feedback from a visually impaired expert in digital accessibility, results (N=19) outlined that methods that do not rely on memorizing pitch had the most promising accuracy and self-reported workload performances. Ultimately, we argue for audio AR's ability to enhance user performance in different scenarios, from video games to finding objects in a pantry.","1941-0506","","10.1109/TVCG.2024.3372040","Australian Technology Network of Universities; RMIT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10458345","Audio interfaces;augmented and mixed reality;assistive technologies","Task analysis;Visualization;Sonification;Navigation;Cataracts;Three-dimensional displays;Blindness","","","","79","IEEE","4 Mar 2024","","","IEEE","IEEE Journals"
"Mixed Dining: Enhancing Social Interaction of Elderly Individuals Living Alone with Smart Dining Environment and Wearable MR","J. Li; G. Wang; Z. Yao; Z. Huo; R. Li; Z. Cheng; G. Ren","School of Design Arts, Xiamen University of Technology, Xiamen, China; School of Design Arts, Xiamen University of Technology, Xiamen, China; Quanzhou No.5 Middle School, Quanzhou, China; School of Design Arts, Xiamen University of Technology, Xiamen, China; School of Design Arts, Xiamen University of Technology, Xiamen, China; School of Design Arts, Xiamen University of Technology, Xiamen, China; School of Design Arts, Xiamen University of Technology, Xiamen, China",2023 IEEE 6th International Conference on Knowledge Innovation and Invention (ICKII),"4 Dec 2023","2023","","","88","91","The aging population is an issue in many countries with a substantial proportion of the elderly living alone. Social isolation and loneliness represent significant challenges for the elderly, impacting their mental, emotional, and physical well-being. For this problem, we proposed Mixed Dining, an innovative system that integrated a smart dining environment with wearable MR (MR) devices to encourage social engagement and enhance the overall quality of life for the elderly. Mixed Dining combined ambient intelligence sensors and Internet of Things (IoT) devices to create a personalized and interactive dining environment. The wearable mixed reality (MR) device seamlessly was integrated into the smart dining environment, providing real-time holographic interactions with friends, family members, or even virtual companions during mealtime. The system was designed to detect the user's emotional state and adjust the experience accordingly, promoting a more engaging and emotionally supportive dining experience, enabling the elderly to engage in social interactions, access information, and receive assistance during meals through intuitive and user-friendly interaction. The Mixed Dining represented a promising solution for enhancing the social interaction of the elderly living alone.","2770-4785","979-8-3503-2353-5","10.1109/ICKII58656.2023.10332774","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10332774","MR;Social Interaction;Smart Dining","Technological innovation;Visualization;Three-dimensional displays;Tracking;Sociology;Mixed reality;Real-time systems","","","","13","IEEE","4 Dec 2023","","","IEEE","IEEE Conferences"
"Intersecting Realms: Examining the Convergence of Vision and AI in Extended Reality Graphics","A. Alhakamy","Department of Computer Science, Faculty of Computers and Information Technology, and Artificial Intelligence and Sensing Technologies (AIST) Research Center, University of Tabuk, Tabuk, Saudi Arabia",IEEE Access,"25 Aug 2025","2025","13","","144828","144850","Exploring the integration of Artificial Intelligence (AI) with Extended Reality (XR), this research addresses four critical questions: (R.Q.1) How can AI enhance the realism of virtual environments through dynamic texture and material generation? (R.Q.2) What methods can be developed for AI-driven adaptive learning systems that adjust environment difficulty and content based on user performance? (R.Q.3) What are the best practices for training AI to achieve real-time object recognition, spatial mapping, and scene understanding in diverse environments? And (R.Q.4) How have the themes and focal areas within XR research evolved over time, and what are the predominant topics and trends as evidenced by bibliographic references and citations in scholarly reviews? A thorough literature review and systematic analysis confirm that AI significantly advances the fidelity and interactivity of XR environments. This research not only highlights how AI enriches user experience and procedural functioning in XR but also delves into the evolutionary trajectories in XR research, identifying major thematic trends and shifts over time. These findings underscore the complex interplay between technological advancements and thematic trends within the academic discourse on XR, advocating for consistent innovation and ethical considerations in the utilization of AI across various domains, including education, healthcare, and entertainment.","2169-3536","","10.1109/ACCESS.2025.3599337","Artificial Intelligence and Sensing Technologies (AIST) Research Center at the University of Tabuk, Saudi Arabia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11126015","Extended reality;artificial intelligence;computer graphics;realism;spatial data","Artificial intelligence;Market research;Object recognition;Surveys;Real-time systems;Ethics;Technological innovation;Systematics;User experience;Extended reality","","","","111","CCBY","15 Aug 2025","","","IEEE","IEEE Journals"
"Internet of Things and Augmented Reality in Cultural Industry: Enhancing Engagement and Participation","J. Nie; Y. Cao; T. Xu; Y. Ji; M. Gu; X. Zhu; Y. Cheng; Y. Jiang","School of Software, Jiangxi Normal University, Nanchang, China; School of Software, Jiangxi Normal University, Nanchang, China; School of Economics & Management, Tongji University, Shanghai, China; Centre for Design Engineering, Cranfield University, Bedfordshire, UK; School of Aerospace, Transport and Manufacturing Cranfield University, Bedfordshire, UK; Centre for Design Engineering, Cranfield University, Bedfordshire, UK; School of Economics, Shanghai Jiaotong University, Shanghai, China; School of Water, Energy and Environment Cranfield University, Bedfordshire, UK",2023 IEEE 9th World Forum on Internet of Things (WF-IoT),"30 May 2024","2023","","","1","5","The emergence of Internet of Things (IoT) and augmented reality (AR) technologies has opened up exciting new horizons for cultural experiences. This paper explores the immense potential of integrating IoT and AR technologies to enrich engagement and enhance participation within the cultural industry. It explores the challenges faced by the industry in a digital era and delves into the concepts of IoT and AR, highlighting their capabilities and applications. This paper examines how IoT enables seamless connectivity and how AR overlays digital content, creating immersive experiences. Best practices in arts, entertainment, design, fashion, and education, exemplify the benefits of IoT and AR in enhancing engagement and participation. This paper addresses challenges and considerations associated with IoT and AR integration, and provides strategies for effective implementation. Overall, this paper emphasizes the transformative potential of IoT and AR in the cultural industry, offering immersive, interactive, and personalized experiences that bridge traditional and digital realms.","2768-1734","979-8-3503-1161-7","10.1109/WF-IoT58464.2023.10539600","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10539600","Arts;augmented reality;creative and cultural activities;cultural industry;design;education;entertainment;fashion;Internet of Things","Bridges;Art;Education;Entertainment industry;Cultural differences;Internet of Things;Augmented reality","","","","13","IEEE","30 May 2024","","","IEEE","IEEE Conferences"
"QoE-Driven Adaptive Video Streaming: Architectures, Techniques, and Future Research Challenges Toward 6G Networks","M. Alsader; A. A. Barakabitze; I. -H. Mkwawa","College of Computing and Informatics, Saudi Electronic University, Riyadh, Saudi Arabia; School of Computer Science and Information Technology, University College Cork, Cork, Ireland; School of Engineering, Computing and Mathematics, University of Plymouth, Plymouth, U.K.",IEEE Access,"12 Sep 2025","2025","13","","157408","157441","The paper provides a survey of architectures and techniques for QoE-driven adaptive video streaming services based on two (2) classifications: client-based video streaming, and delivery-based video rate adaptation. The paper presents in-depth review of QoE- driven network softwarization and virtualization approaches using SDN, NFV, and MEC, leveraging AI/ML techniques and cloud/edge computing architectures. Additionally, the paper provides a review of QoE-driven video streaming in various aspects including 6G-based Metaverse for Multi-User Extended Reality (MER), holographic telepresence, personalized media, Internet of Senses (IoS), Industrial Internet of Things (IIoT) and video coding compression standards. Moreover, the paper provide highlights on multimedia streaming in new verticals and next-generation mobile technologies by putting emphasis in 6G and beyond factories, education, social and entertainment, automotive and healthcare. Finally, the paper present concrete challenges and future research directions in emerging applications, video standards and new business cases towards 6G networks. This paper aims to guide and inspire the multimedia and networking research community both in academia and industry toward developing innovative solutions for monitoring, managing, and optimizing performance in future 6G networks.","2169-3536","","10.1109/ACCESS.2025.3597058","College of Computing and Informatics, Saudi Electronics University; European Union’s Horizon 2020 Research and Innovation Program under the Marie Skłodowska-Curie(grant numbers:801522); Science Foundation Ireland and co-funded by European Regional Development Fund through the Centre for Digital Content Platform Research Centre for Digital Content Technology(grant numbers:13/RC/2106); Royal Academy of Engineering, U.K., through the Distinguished International Associates Program Round 4: 2024-2025.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11121143","Metaverse;video QoE;multimedia streaming services;network slicing;SDN/NFV;5G/6G;industrial IoT;network softwarization;network management;holographic streaming;AR/VR","6G mobile communication;Quality of experience;Videos;Surveys;Computer architecture;Reviews;Adaptive systems;Monitoring;Media;Taxonomy","","","","185","CCBY","8 Aug 2025","","","IEEE","IEEE Journals"
"Immersive Authoring by Demonstration of Industrial Procedures","L. R. Skreinig; P. Mohr; B. Berger; M. Tatzgern; D. Schmalstieg; D. Kalkofen",Graz University of Technology; Graz University of Technology; Graz University of Technology; Salzburg University of Applied Sciences; Graz University of Technology; Graz University of Technology,2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"28 Nov 2024","2024","","","1293","1302","This work presents an authoring tool for supporting the creation of immersive instructions for industrial processes. Our system simplifies the creation of instructional content by providing an immersive virtual reality environment that enables expert operators to interact directly with virtual replicas of industrial devices. Hand movements, tool usage, gaze, spoken comments, and machine part movement are recorded using a head-mounted display. Editing of instructions in virtual reality is aided by automatic segmentation of recorded data into individual steps and visualizations of regions with intensive activity. A qualitative evaluation of our system by industrial experts shows that it is a viable alternative to current practices in authoring instructions for assembly and maintenance.","2473-0726","979-8-3315-1647-5","10.1109/ISMAR62088.2024.00146","Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765379","Virtual reality;Computer-assisted instruction;User interface design","Head-mounted displays;Authoring systems;Data visualization;Maintenance;Augmented reality;Assembly","","","","40","IEEE","28 Nov 2024","","","IEEE","IEEE Conferences"
"From Display to Interaction: Design Patterns for Cross-Reality Systems","R. Cools; J. Han; A. Esteves; A. L. Simeone","ARIA at KU, Leuven, Belgium; ARIA at KU, Leuven, Belgium; University of Lisbon, ITI / LARSyS, Instituto Superior Técnico, Portugal; ARIA at KU, Leuven, Belgium",IEEE Transactions on Visualization and Computer Graphics,"25 Apr 2025","2025","31","5","3129","3139","Cross-reality is an emerging research area concerned with systems operating across different points on the reality-virtuality continuum. These systems are often complex, involving multiple realities and users, and thus there is a need for an overarching design framework, which, despite growing interest has yet to be developed. This paper addresses this need by presenting eleven design patterns for cross-reality applications across the following four categories: fundamental, origin, display, and interaction patterns. To develop these design patterns we analysed a sample of 60 papers, with the goal of identifying recurring solutions. These patterns were then described in form of intent, solution, and application examples, accompanied by a diagram and archetypal example. This paper provides designers with a comprehensive set of patterns that they can use and draw inspiration from when creating cross-reality systems.","1941-0506","","10.1109/TVCG.2025.3549893","Internal Funds KU Leuven(grant numbers:C14/20/078); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10922183","Cross-Reality;Design Patterns","Virtual reality;Mixed reality;Augmented reality;Training;Systematic literature review;Data mining;Collaboration;Codes;Bidirectional control;Augmented virtuality","","","","77","IEEE","11 Mar 2025","","","IEEE","IEEE Journals"
"User interfaces design for CVE software","M. K. Othman; R. J. Lapeer","Faculty of Cognitive Siences and Human Development (FCSHD), Universiti Malaysia Sarawak, Sarawak, Malaysia; School of Computing Sciences (CMP), University of East Anglia, Norwich, UK",2006 International Conference on Computing & Informatics,"2 Oct 2009","2006","","","1","6","The project aims to study and design an alternative user interface for collaborative virtual environments (CVE's) software also known as networked virtual environments (NVE's). To reduce cost, most current and operative CVE's use the Internet and standard PC to create a visual virtual environment (VE), which can be shared by a large number of users. This project also involves an image processing technique (morphing technique using thin plate spline) for creating a facial expression for the CVE software and in volves OpenGL API for implementation. This project discusses communication aspects in the CVE system and suggests the different types of communication that are suitable for the project. It also suggests a suitable user interfaces for the software.","2166-5729","978-1-4244-0219-9","10.1109/ICOCI.2006.5276558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5276558","","User interfaces;Software design;Collaborative software;Virtual environment;Humans;Protocols;Computer networks;Image processing;Spline;Graphical user interfaces","","","","35","IEEE","2 Oct 2009","","","IEEE","IEEE Conferences"
"Precisely Exploring Medical Models and Volumes in Collaborative Virtual Reality","J. C. Silverstein; F. Dech","Department of Surgery, The University of Chicago, Chicago IL 60637-1470 USA; Department of Surgery, The University of Chicago, Chicago IL 60637-1470 USA",Presence,"19 May 2014","2005","14","1","47","59","We describe a virtual-reality widget library and two medical applications built on the widget library. These two applications, education using surface models and radiological volume visualization, make use of collaborative interaction techniques. These techniques support a high degree of precision with respect to manipulation of data and data parameters. The 3D widgets instantiated in these applications are synchronized between clients in order to facilitate the high degree of interactivity necessary for productive investigation of shared medical models and volume data. We discuss challenges that face the investigator in an immersive 3D environment as opposed to that of a 2D desktop environment. We describe how these differences have led us to criteria for development of the shared 3D Virtual Reality (VR) graphical user interfaces (GUIs) used in the biomedical applications presented. We review our educational validations already conducted for the surface model exploration application and preview our future work toward a single advanced biomedical collaboration environment.","1054-7460","","10.1162/1054746053890233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6788778","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"Evolution of Human-Machine Translation: From Early Interface to Modern AI","Y. E. Ogunwale","Department of Computer Science, University of Ilesa, Ilesa, Nigeria",2024 IEEE 5th International Conference on Electro-Computing Technologies for Humanity (NIGERCON),"24 Mar 2025","2024","","","1","5","The evolution of Human-Machine Interaction (HMI) has been a transformative journey, marked by significant advancements in technology and a deepening understanding of user needs. This review paper explores the historical progression of HMI, tracing its origins from early mechanical and command-line interfaces to the sophisticated, AI-driven systems of today. By examining key milestones and technological breakthroughs, the paper highlights the transition from basic interaction models to more intuitive, adaptive, and user-centric designs. The review also discusses the impact of these developments on various industries, alongside the challenges and opportunities that have emerged in the quest for seamless human-machine collaboration. The paper concludes with insights into the future trajectory of HMI, emphasizing the potential of emerging technologies to further revolutionize the way humans interact with machines.","2377-2697","979-8-3315-4255-9","10.1109/NIGERCON62786.2024.10927385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10927385","Human-Machine Interaction;Interface Evolution;Artificial Intelligence;User-Centric Design;Interactive Systems","Human computer interaction;Privacy;Ethics;Reviews;Personal voice assistants;Virtual reality;Market research;Natural language processing;User experience;Artificial intelligence","","","","28","IEEE","24 Mar 2025","","","IEEE","IEEE Conferences"
"Voices Unveiled: Quality of Experience in Collaborative VR via AssemblyAI and NASA-TLX Analysis","B. Moharana; C. Keighrey; N. Murray","Department of Computer and Software Engineering, Technological University of the Shannon, Ireland; Department of Computer and Software Engineering, Technological University of the Shannon, Ireland; Department of Computer and Software Engineering, Technological University of the Shannon, Ireland",2024 16th International Conference on Quality of Multimedia Experience (QoMEX),"22 Jul 2024","2024","","","15","21","In order to understand the sentiments between users as they worked together as part of a collaborative Virtual Reality (VR) task, this research analyzed voice interaction using Assembly AI. The real-time conversations between 11 pairs of users were captured as they performed a joint puzzle task. The users were in separate physical spaces but connected in a shared virtual setting. The extracted voice sentiments were correlated with self-reported frustration levels and task completion times. The findings reveal a significant positive correlation between negative sentiments and frustration (r=0.73, p≤0.05) and a negative correlation between positive sentiments and task completion time (r=-0.87, p≤0.001). This shows the relationship between sentiment (positive and negative) and task completion in collaborative VR. These results highlight the potential benefits of analyzing voice sentiment in collaborative VR applications.","2472-7814","979-8-3503-6158-2","10.1109/QoMEX61742.2024.10598261","Science Foundation Ireland; Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10598261","Quality of Experience (QoE);Virtual Reality (VR);Head-mounted display (HMD);Sentiment Analysis","Sentiment analysis;Correlation;Collaboration;Virtual environments;Oral communication;Real-time systems;Quality of experience","","","","41","IEEE","22 Jul 2024","","","IEEE","IEEE Conferences"
"A novel Multi-channel Visual Simulation system with one PC","D. Ying; F. Jing-tao; Z. Chao; D. Ying; Z. Ji-hong","School of Computer Science and Technology, Changchun University of Science and Technology, Changchun, China; School of Computer Science and Technology, Changchun University of Science and Technology, Changchun, China; School of Computer Science and Technology, Changchun University of Science and Technology, Changchun, China; School of Computer Science and Technology, Tsinghua University, Beijing, China; School of Computer Science and Technology, Tsinghua University, Beijing, China",2014 7th International Congress on Image and Signal Processing,"8 Jan 2015","2014","","","741","746","Now the advanced visual simulation system is usually equipped with the large-wide projection or multi-projection display system, and several graphic workstations to achieve the real-time rendering task for multiple channels, which can provide the large field of view for user and bring the immersive feeling with the interactive devices' supporting. This paper presented a novel multi-channel visual simulation system with on one single PC, analyzed the system architecture of multi-channel visual simulation and the process of visual generation, studied the technology bottlenecks and the key factors of visual simulation expanding from single to multi-channel, and presented a visual simulation expanding scheme based on graphics card programming. The experimental results verified that this scheme has a more flexible and scalable architecture, a close or even better performance compared to distributed simulation system based on PC cluster, and easier to expand and upgrade, the system cost will be cut down.","","978-1-4799-5835-1","10.1109/CISP.2014.7003876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7003876","Visual Simulation;Multi-channel;graphics programming","Visualization;Synchronization;Computational modeling;Rendering (computer graphics);Computer architecture;Analytical models","","","","15","IEEE","8 Jan 2015","","","IEEE","IEEE Conferences"
"Zooviz – Unveiling Anatomy Virtually","R. R; A. M. A; A. S. S; N. M","M. TECH CSE (Integrated), Sri Sai Ram Engineering College, Chennai, India; M. TECH CSE (Integrated), Sri Sai Ram Engineering College, Chennai, India; M. TECH CSE (Integrated), Sri Sai Ram Engineering College, Chennai, India; M. TECH CSE (Integrated), Sri Sai Ram Engineering College, Chennai, India","2024 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS)","12 Dec 2024","2024","","","1","5","Zooviz is at the forefront of a transformative shift in biology education, harnessing the power of Mixed Reality (MR) technology to redefine how students explore and understand the natural world. By merging MR with a specially developed application, this initiative offers a revolutionary approach to traditional dissection practices in educational settings. The need for this project arises from the growing ethical concerns and environmental impact associated with conventional dissections, as well as the limitations they impose on the accessibility and inclusivity of biology education. Zooviz addresses these challenges by providing a humane, sustainable, and universally accessible alternative. With a strong focus on ethical, environmental, and pedagogical values, Zooviz replaces the need for live specimens, instead offering students an immersive, hands-on experience that mirrors the intricacies of biological dissections. This cutting-edge tool not only enhances the educational experience but also aligns with modern ethical standards, providing a sustainable and humane alternative to conventional methods. Consolidate an enormous amount of information from various sources to produce general data, and afterward utilize diverse AI calculations to create models and give continuous outcomes [9]. Zooviz empowers students to delve deeply into the study of flora and fauna, ensuring a rich, interactive learning journey that respects both life and the environment.","","979-8-3315-0884-5","10.1109/ICPECTS62210.2024.10780123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10780123","Mixed Reality (MR);Virtual Dissection;Biology Education;Environmental Sustainability;Interactive Learning;Humane Alternatives","Ethics;Technological innovation;Navigation;Education;Merging;Mixed reality;Virtual reality;Life sciences;Mirrors;Standards","","","","10","IEEE","12 Dec 2024","","","IEEE","IEEE Conferences"
"A comprehensive case study of the impact of multicast routing protocols on mobile health care training systems","A. Zarrad; A. R. Mahlous","Department of computer science and Information Systems, Prince Sultan University, Riyadh, Saudi Arabia; Department of computer science and Information Systems, Prince Sultan University, Riyadh, Saudi Arabia",The Third International Conference on e-Technologies and Networks for Development (ICeND2014),"18 Dec 2014","2014","","","70","74","Nowadays, Health Care Training-based System (HCTS) is a vital component in the education and training of health care in 3D Virtual Environment (VE). The practice of HCTS continues to grow at rapid pace throughout all of the healthcare disciplines, however research in this field still in its early stage. Increasingly, decision makers and developer look forward to offer more sophisticated, much larger, and more complex HCTS to serve the desired outcome and improve the quality and safety of patient care. Due to the rapidly increasing usage of personal mobile devices and the need of executing HCTS applications in environments that have no previous network infrastructure available, Mobile Health Care Training-based System (MHCTS) is an expected future trend. In such systems, medical staff will share and collaborate in a 3D virtual environment through their mobile devices in an ad-hoc network (MANET) in order to accomplish specific missions' typically surgical emergency room. Users are organized into various groups (Radiologists, Maternity departments, and General surgery etc.), and need to be managed by a multicast scheme to save network bandwidth and offer immersive sense. MHCTS are sensitive to networking issues, since interactive 3D graphics requires additional load due to the use of mobile devices. Therefore, we need to emphasize on the importance and the improvement of multicast techniques for the effectiveness of MHCTS and the management of collaborative group interaction. Research so far has devoted little attention to the network communication protocols design of such systems which is crucial to preserve the sense of immersion for participating users. In this paper, we investigate the effect of multicast routing protocol in advancing the field of Health care Training-based System to the benefit of patient's safety, and health care professional. A comprehensive analysis about various ad-hoc multicast routing protocols is proposed. The selection key factors for the right protocol for MHCTS applications were safety and robustness. To the best of our knowledge, this work will be the first initiative involving systematic literature reviews to identify a research gate for the use of multicast protocol in health care simulation learning community.","","978-1-4799-3166-8","10.1109/ICeND.2014.6991355","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991355","Ad-hoc;Multicast Protocol;Health care training system;3D Virtual Environment","Routing;Routing protocols;Medical services;Virtual environments;Peer-to-peer computing;Multicast protocols","","","","21","IEEE","18 Dec 2014","","","IEEE","IEEE Conferences"
"From a Binary Feature Matrix to Correlation Analysis: A Dual-Paradigm Classification of Global Robotics Research Objectives","E. A. Alamoudi","Electrical Engineering Department, University of Aden, Aden, Yemen",IEEE Access,"11 Sep 2025","2025","13","","156318","156358","Robotics research encompasses a wide range of technical challenges and interdisciplinary approaches. This study introduces a dual-paradigm classification framework for organizing the stated objectives of 130 leading robotics laboratories across North America, Europe, Asia, and Australia. The framework includes a Problem-Based paradigm that addresses core technical challenges and a Solution-Based paradigm that focuses on methodological strategies. Each laboratory’s objectives are encoded into a  $130\times 17$  binary matrix, enabling large-scale quantitative analysis. Spearman correlation analysis, corrected using the Benjamini–Hochberg False Discovery Rate (FDR) method, reveals statistically significant co-occurrence trends. Key findings include the synergy between artificial intelligence and cognition, a hardware–software divide, and underexplored intersections between AI and physical system innovation. In addition to correlation heatmaps, visualizations such as PCA biplots and radial similarity networks reveal research gaps and collaboration opportunities. These insights can guide agencies, industry partners, and academic institutions in shaping future robotics research. By identifying promising scientific directions, stakeholders can strategically combine these areas to develop more advanced, integrated, and capable robotic systems. All data and analysis tools have been deposited on IEEE DataPort and GitHub to ensure transparency and reproducibility.","2169-3536","","10.1109/ACCESS.2025.3604842","Requesting waiver for authors from low-income countries as per IEEE Access policy; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11146652","Robotics research classification;binary feature analysis;problem-based paradigm;solution-based paradigm;research correlation analysis;reproducible datasets;interdisciplinary robotics","Robots;Service robots;Object recognition;Correlation;Collaboration;North America;Europe;Adaptation models;Market research;Laboratories","","","","425","CCBY","2 Sep 2025","","","IEEE","IEEE Journals"
"Analyzing Exergame Recordings with Embedded Bio-Data in Immersive Virtual Reality","P. Bimberg; M. Minuth; D. Zielasko; B. Weyers",Trier University; Trier University; Trier University; Trier University,2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"29 May 2024","2024","","","138","144","Virtual Reality exergames are a type of serious game that has been used to support therapy and rehabilitation by encouraging patients to exercise within a controlled environment. One challenge of in-corporating virtual reality into clinical interventions is the need for intuitive ways to evaluate recordings of the patients' performance within such applications. As related work shows the benefits of re-viewing interactions with virtual environments while being im-mersed within these environments, this approach could be beneficial in the context of clinical interventions as well. In our work, we present a prototype for an analysis module built on top of a VR exergame that connects movement recordings with recordings of the player's heartrate and makes them explorable in an immersive virtual environment. An initial evaluation of the prototype with six users shows the potential of exploring exergame recordings in VR as well as possible benefits of the multimodal representation of bio-data in parallel to the recorded movements.","","979-8-3503-7449-0","10.1109/VRW62533.2024.00029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10536558","Human-centered computing—Human computer interaction (HCI)—Interaction paradigms—Virtual Reality;Applied computing—Human computer interaction (HCI)—Empirical studies in HCI","Three-dimensional displays;Conferences;Virtual environments;Prototypes;Medical treatment;Games;User interfaces","","","","42","IEEE","29 May 2024","","","IEEE","IEEE Conferences"
"Metaverse in Manufacturing: A Digital Revolution","Aniket; S. Sengupta","Amity University, Noida, India; Amity University, Noida, India",2025 International Conference on Networks and Cryptology (NETCRYPT),"12 Aug 2025","2025","","","1362","1366","Metaverse has emerged as a trending term globally, shaping the trajectory of growth and development across various sectors. Its scope extends from entertainment and learning to manufacturing, where technologies such as augmented reality (AR) and virtual reality (VR) are driving innovation. Smart manufacturing, in particular, is undergoing a transformation toward industrial digitalization, integrating advanced technologies to enhance efficiency and productivity. Metaverse, as a next-generation paradigm of a digital space augmented by reality, offers significant potential for smart manufacturing. This paper discusses the concept of Metaverse and its applications in enabling smarter, more efficient manufacturing processes across various industries.","","979-8-3315-2605-4","10.1109/NETCRYPT65877.2025.11102308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11102308","Metaverse;Smart Manufacturing;Augmented Reality (AR);Virtual Reality (VR);Industrial Digitalization;Advanced Technologies;Digital Space;Smart Technologies;Manufacturing Innovation","Training;Technological innovation;Metaverse;Collaboration;Digital twins;Trajectory;Sustainable development;Augmented reality;Smart manufacturing;Automotive engineering","","","","22","IEEE","12 Aug 2025","","","IEEE","IEEE Conferences"
"Exposing Movement Correlates of Presence Experience in Virtual Reality Using Parametric Maps","L. Gehrke; K. Gramann",TU Berlin; TU Berlin,2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"29 May 2024","2024","","","374","380","Genuine experiences where users feel a deep level of connection are the key quality of room-scale virtual reality (VR). The freedom to move promises natural sensory experiences stimulating a feeling of presence. However, users differ in their eagerness to move, some prefer movement by teleportation while others would keep walking forever. Such individual differences challenge the inclusive design necessary for bestseller applications. In this methodological research contribution, we propose to study user behavior and experience using parametric maps based on general linear models (GLM) to overcome limitations of traditional data aggregation techniques. In the investigated study, participants explored invisible mazes touching hidden walls for brief moments of visual guidance. We demonstrate that experienced presence correlated with where participants spent time exploring the VR. We found an increase in presence coinciding with participants being less likely to collide with invisible walls and spending more time in segments critical for navigational success.","","979-8-3503-7449-0","10.1109/VRW62533.2024.00073","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10536309","Human-centered computing—Visualization—Visualization techniques—Treemaps;Human-centered computing—Visualization—Visualization design and evaluation methods","Legged locomotion;Visualization;Solid modeling;Three-dimensional displays;Navigation;Virtual reality;User interfaces","","","","55","IEEE","29 May 2024","","","IEEE","IEEE Conferences"
"Revolutionizing Training in Continuing Engineering Education: An Experimental Proposal Using the Multi-Sensory Virtual Decision-Making Center","J. Daniel Azofeifa; V. Rueda-Castro; L. Jose Gonzalez-Gomez; J. Noguez; P. Caratozzolo","Institute for the Future of Education, Tecnológico de Monterrey, Monterrey, Mexico; Institute for the Future of Education, Tecnológico de Monterrey, Monterrey, Mexico; Institute for the Future of Education, Tecnológico de Monterrey, Monterrey, Mexico; School of Engineering and Sciences, Tecnológico de Monterrey, Mexico City, Mexico; Institute for the Future of Education, Tecnológico de Monterrey, Monterrey, Mexico",IEEE Access,"20 Dec 2024","2024","12","","192440","192448","In the context of Industry 4.0, engineering education is evolving rapidly, requiring new approaches to continuing engineering education (CEE). Traditional methods struggle to meet the demands of professionals looking to update their skills. This study presents an experimental proposal using the Multisensory Virtual Decision Making Center (MVDC) to improve CEE training creation. The MVDC creates collaborative and immersive virtual environments, enabling real-time participation and decision-making with a greater sense of presence and complete data visualization. The proposed experiment compares the effectiveness of MVDC sessions with traditional video call sessions in developing CEE courses. The research aims to evaluate improvements in the quality of decisions, participation, and user satisfaction in this collaborative process by streamlining the training planning process for continuing education. This study anticipates significant insights into integrating cutting-edge technologies such as MVDC for CEE, proposing it as a crucial tool for upskilling and reskilling. Expected outcomes include practical guidelines for implementing multisensory environments in CEE curriculum development, highlighting their potential to revolutionize the planning process. The research underscores the need for innovative approaches to meet the changing demands of the engineering workforce in the era of Industry 4.0. It lays the foundation for future studies that validate and expand these findings, paving the way for more effective and engaging CEE programs.","2169-3536","","10.1109/ACCESS.2024.3519015","Writing Laboratory and the Challenge-Based Research Funding Program(grant numbers:I030-IFE002-C2-T1-E); Institute for the Future of Education, Tecnológico de Monterrey, Mexico(grant numbers:I030-IFE002-C2-T1-E); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10804163","Collaborative decision-making;education innovation;lifelong learning;industry 4.0;virtual reality","Decision making;Collaboration;Training;Engineering education;Fourth Industrial Revolution;Real-time systems;Proposals;Videoconferences;Video conferencing;Planning","","","","45","CCBY","16 Dec 2024","","","IEEE","IEEE Journals"
"Mixed Reality Learning System","J. P.; R. A. V; S. C","Department of CSE, St. Joseph's College of Engineering, Chennai, Tamil Nadu; Department of CSE, St. Joseph's College of Engineering, Chennai, Tamil Nadu; Department of CSE, St. Joseph's College of Engineering, Chennai, Tamil Nadu","2024 International Conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (ICSES)","12 Mar 2025","2024","","","1","6","A Virtual Trainer based on MR technology represents a quantum leap in immersive training. Integrating the hardware and software elements, a Virtual Trainer could offer its clients an unprecedented opportunity to participate in highly realistic simulations in a wide range of training scenarios. The environments themselves also are visually realistic and dynamically sensitive, updating in real time to reflect user activity. Most critical is the Virtual Trainer provides for immediate feedback on a user's performance. It does this through the use of computer vision algorithms and motion tracking sensors which analyze the performed actions to give tailored advice. This real-time feedback makes the learning process more effective since it allows a user to iteratively improve both their methods and abilities. The Virtual Trainer also adapts its coaching style according to the client's preferences and level of ability, ensuring a fully customized. It can actually train each of the users with a good learning environment in all subjects and simulations to perform various things from the most complex thinking to physical training for users. In addition, performance analytics enriches the training process because it allows users to monitor their development as well as detect areas where one can improve over time. Training sessions are no longer a one-way passive endeavor because of the social and collaborative elements built into the Virtual Trainer. Elements, contributing to an enhanced sense of motivation and engagement. In general, virtual trainers in MR technology represent a milestone development in the realisation of new approaches to learning and skill acquisition and training.","","979-8-3315-4362-4","10.1109/ICSES63760.2024.10910371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10910371","Virtual reality(VR);Augmented reality (AR);Machine learning;User Satisfaction Scores;physiological reactions","Training;Learning systems;Solid modeling;Tracking;Mixed reality;Machine learning;Real-time systems;Software;Sensors;Monitoring","","","","25","IEEE","12 Mar 2025","","","IEEE","IEEE Conferences"
"Elicitation of Interaction Techniques with 3D Data Visualizations in Immersive Environment using HMDs","F. Aktar; F. Maurer",University of Calgary; University of Calgary,2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"15 Dec 2022","2022","","","238","243","The design practices of current techniques for interacting with 3D data visualizations offered by state-of-the-art immersive head-mounted displays (HMD) are constrained by technological limitations and designer bias. We argue that understanding user-preferred interaction techniques with 3D data visualizations can lead to improved usability by helping system designers or architects formulate a set of interactions that are most intuitive and natural to the users.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974368","User-centered design;Data Visualization;Interaction Techniques;Immersive analytics-Interaction;Visualization-3D-Interaction;Extended reality;Virtual reality;Augmented reality;Mixed reality;Head-mounted Display","Vocabulary;Three-dimensional displays;Uncertainty;Head-mounted displays;Data visualization;Resists;Cultural differences","","","","69","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Augmented reality for motion analysis of patients with upper extremity motor dysfunction","M. Cidota; S. Lukosch; P. J. M. Bank","Faculty of Technology, Delft University of Technology, The Netherlands; Faculty of Technology, Delft University of Technology, The Netherlands; Department of Neurology, Leiden University Medical Center, The Netherlands",2015 3rd IEEE VR International Workshop on Virtual and Augmented Assistive Technology (VAAT),"16 Jul 2015","2015","","","1","4","Various diseases affect human motion (e.g. neurovascular diseases, neurodegenerative diseases, and musculoskeletal pain conditions). Currently, each medical discipline uses disease-specific clinical tests to assess motor (dys)function, based on subjectively scored and low-resolution clinimetric tests, qualitative video analysis, or cumbersome marker-based motion capturing. As such, no standard protocols for motion recording exist with respect to type of movements and activities of the upper extremity in various patient groups. For a better understanding of how different disorders affect motor function, a uniform, standardized and objective evaluation is a desirable goal in the study of motion disorders. Our aim is to explore the capabilities of the augmented reality (AR) technology for uniform assessment of the motor function, both for diagnosis and treatment.","","978-1-4673-6518-5","10.1109/VAAT.2015.7155401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155401","human motion assessment;augmented reality;optical see-through Head Mounted Device;serious gaming","Training;Augmented reality;Collaboration;Medical diagnostic imaging;Monitoring;Diseases;Real-time systems","","","","19","IEEE","16 Jul 2015","","","IEEE","IEEE Conferences"
"Augmented Dynamic Data Physicalization: Blending Shape-Changing Data Sculptures With Virtual Content for Interactive Visualization","S. Engert; A. Peetz; K. Klamka; P. Surer; T. Isenberg; R. Dachselt","Interactive Media Lab Dresden, Technische Universität Dresden, Dresden, Germany; Interactive Media Lab Dresden, Technische Universität Dresden, Dresden, Germany; Interactive Media Lab Dresden, Technische Universität Dresden, Dresden, Germany; Polytech Paris-Saclay, Orsay, France; Université Paris-Saclay, CNRS, Inria, LISN, Gif-sur-Yvette, France; Interactive Media Lab Dresden, Technische Universität Dresden, Dresden, Germany",IEEE Transactions on Visualization and Computer Graphics,"4 Sep 2025","2025","31","10","7580","7597","We investigate the concept of Augmented Dynamic Data Physicalization, the combination of shape-changing physical data representations with high-resolution virtual content. Tangible data sculptures, for example using mid-air shape-changing interfaces, are aesthetically appealing and persistent, but also technically and spatially limited. Blending them with Augmented Reality overlays such as scales, labels, or other contextual information opens up new possibilities. We explore the potential of this promising combination and propose a set of essential visualization components and interaction principles. They facilitate sophisticated hybrid data visualizations, for example Overview & Detail techniques or 3D view aggregations. We discuss three implemented applications that demonstrate how our approach can be used for personal information hubs, interactive exhibitions, and immersive data analytics. Based on these use cases, we conducted hands-on sessions with external experts, resulting in valuable feedback and insights. They highlight the potential of combining dynamic physicalizations with dynamic AR overlays to create rich and engaging data experiences.","1941-0506","","10.1109/TVCG.2025.3547432","DFG; Germany’s Excellence Strategy EXC 2050/1(grant numbers:390696704); Cluster of Excellence in part by “Centre for Tactile Internet with Human-in-the-Loop(grant numbers:EXC-2068); Cluster of Excellence; Physics of Life” (PoL) of Technische Universität Dresden, by DFG(grant numbers:389792660); Federal Ministry of Education and Research of Germany(grant numbers:16KISK001K); BMBF(grant numbers:SCADS22B); Saxon State Ministry for Science, Culture and Tourism by funding the competence center for Big Data; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10930699","Augmented physicalization;Augmented Dynamic Data Physicalization;hybrid visualization;physical-virtual continuum;tangible interaction;shape-changing interface;data visualization;interactive storytelling;holographic overlays;data sculptures","Data visualization;Visualization;Augmented reality;Data analysis;Electronic mail;Training;Shape;Resists;Museums;Meteorology","","","","128","IEEE","17 Mar 2025","","","IEEE","IEEE Journals"
"Gesture3DFramework: A Generic Gesture-Based Interaction Middleware Applied to 3D Environments","D. Passos Costa; P. N. M. Sampaio; V. F. Martins","Universidade Salvador, Salvador, BA, BR; Universidade Salvador, Salvador, BA, BR; School of Computing and Informatics Marckenzie Presbiterian University São Paulo, São Paulo, Brazil",2018 XLIV Latin American Computer Conference (CLEI),"5 Aug 2019","2018","","","590","598","The technological advances provide the development and wide adoption of different kinds of humanmachine interfaces, which leads to the creation of new applications such as those based on multimedia and virtual reality (3D). In particular, the proposal of interaction metaphors applied to 3D environments which aim at replicating real world concepts into the virtual environment, facilitates user's interaction. The utilization of gestural interaction metaphors within a 3D environment can turn the user experience more familiar and concrete, making the training curb smaller. However, in order to apply interaction metaphors it is necessary their classification and generalization, so that they can be widely deployed in different applications. This paper introduces the development of a generic and customizable solution for the mediation of user gestural interaction (selection, manipulation and navigation) with heterogeneous rendering engines for virtual reality environments. This solution, called Gesture3DFramework, allows the users context and gesture-metaphors configuration to be easily customized so that it can be adaptable to multiple 3D virtual environments. With Gesture3DFramework, the final user (and developer) will be provided with a higher level of abstraction when it comes to the development of interactive virtual reality applications, since once the configuration directives have been described, the system will adapt itself to the specific interaction routines of the applied rendering engine.","","978-1-7281-0437-9","10.1109/CLEI.2018.00076","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786315","Virtual Reality;Gesture Interaction;Selection;Manipulation;Navigation;Immersion;3D environment","Three-dimensional displays;Casting;Navigation;Middleware;Virtual environments;Rendering (computer graphics)","","","","","IEEE","5 Aug 2019","","","IEEE","IEEE Conferences"
"WHAT'S HAPPENING","",,Presence,"19 May 2014","1998","7","3","320","326","","1054-7460","","10.1162/105474698565758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6788079","","","","","","","","19 May 2014","","","MIT Press","MIT Press Journals"
"TICE Workshop Final Report","A. Ferscha","Linz Department of Pervasive Computing Altenberger, Johannes Kepler University, Linz, Austria",16th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE 2007),"26 Dec 2007","2007","","","409","412","Tangible user interfaces (TUI) promise to enable natural and intuitive interaction with digital informa- tion through the physical environment. They are not limited to the interactions of a single person, but also support collaboration among ­ even dislocated ­ groups. Technological advances make it possible to integrate sensors and actuators as well as wireless communica- tion and processing technologies into everyday objects, and the vision of ""everywhere interfaces"" is coming within reach. In this report we briefly discuss the con- tents of the papers presented at the second international workshop on Tangible Interaction in Collaborative En- vironments (TICE), and summarize the main issues of the discussions. The aim of the workshop was to explore the potentials and perspectives of tangible in- teraction for supporting collaborative work, and it was held in conjunction with WETICE'07 in Paris, France, on June 18th 2007.","1524-4547","978-0-7695-2879-3","10.1109/WETICE.2007.4407199","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4407199","","","","","","4","IEEE","26 Dec 2007","","","IEEE","IEEE Conferences"
"6th International Workshop on Performance Modeling, Evaluation, and Optimization of Parallel and Distributed Systems (PMEO-PDS'07)","",,2007 IEEE International Parallel and Distributed Processing Symposium,"11 Jun 2007","2007","","","nil22","nil24","","1530-2075","1-4244-0909-8","10.1109/IPDPS.2007.370578","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4228306","","","","","","","IEEE","11 Jun 2007","","","IEEE","IEEE Conferences"
"IEEE VR 2025 Workshops","",,2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"24 Apr 2025","2025","","","30","40","","","979-8-3315-1484-6","10.1109/VRW66409.2025.00005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10972433","","","","","","","IEEE","24 Apr 2025","","","IEEE","IEEE Conferences"
"IEEE VR 2023 Conference Awards","",,2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR),"15 Apr 2024","2024","","","38","40","","2642-5254","979-8-3503-7402-5","10.1109/VR58804.2024.00022","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10494122","","","","","","","IEEE","15 Apr 2024","","","IEEE","IEEE Conferences"
"[Front matter]","",,2008 IEEE International Workshop on Haptic Audio visual Environments and Games,"21 Nov 2008","2008","","","i","iii","The following topics are dealt with: haptic audio visual environment; games; surgical applications; medical applications; distributed collaborative virtual environment; telepresence; augmented reality; human-computer interaction; rendering; motion modeling; shape modeling and object modeling.","","978-1-4244-2668-3","10.1109/HAVE.2008.4685284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4685284","","","","","","","IEEE","21 Nov 2008","","","IEEE","IEEE Conferences"
"Contents","",,2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),"30 Aug 2018","2018","","","1","9","Presents the table of contents/splash page of the proceedings record.","","978-1-5386-3365-6","10.1109/VR.2018.8446238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8446238","","","","2","","","IEEE","30 Aug 2018","","","IEEE","IEEE Conferences"
"Table of Contents","",,2022 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"27 Dec 2022","2022","","","5","10","Presents the conference table of contents.","1554-7868","978-1-6654-5325-7","10.1109/ISMAR55827.2022.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9995007","","","","","","","IEEE","27 Dec 2022","","","IEEE","IEEE Conferences"
"Table of Contents","",,2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR),"14 Dec 2020","2020","","","5","18","Presents the table of contents/splash page of the proceedings record.","1554-7868","978-1-7281-8508-8","10.1109/ISMAR50242.2020.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9284813","","","","","","","IEEE","14 Dec 2020","","","IEEE","IEEE Conferences"
"VR 2020 table of contents","",,2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR),"11 May 2020","2020","","","i","xiv","Presents the table of contents/splash page of the proceedings record.","2642-5254","978-1-7281-5608-8","10.1109/VR46266.2020.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9089544","","","","","","","IEEE","11 May 2020","","","IEEE","IEEE Conferences"
"EEE VR 2023 Table of Contents","",,2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR),"1 May 2023","2023","","","v","ix","EEE VR 2023 Table of Contents.","2642-5254","979-8-3503-4815-6","10.1109/VR55154.2023.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108441","","","","","","","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"Table of Contents","",,2025 8th International Conference on Advanced Algorithms and Control Engineering (ICAACE),"9 Jun 2025","2025","","","1","28","","","979-8-3315-3508-7","10.1109/ICAACE65325.2025.11019561","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11019561","","","","","","","IEEE","9 Jun 2025","","","IEEE","IEEE Conferences"
"Table of Contents","",,2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW),"1 May 2023","2023","","","xi","lii","Table of Contents.","","979-8-3503-4839-2","10.1109/VRW58643.2023.00343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10108630","","","","","","","IEEE","1 May 2023","","","IEEE","IEEE Conferences"
"IEEE ISMAR 2022 - Tutorials","",,2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"15 Dec 2022","2022","","","xxix","xxxiii","Presents information on conference courses, tutorials, or workshops.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00009","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974194","","","","","","","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
"Table of Contents","",,2024 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"2 Dec 2024","2024","","","5","15","","2771-1110","979-8-3315-0691-9","10.1109/ISMAR-Adjunct64951.2024.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10765344","","","","","","","IEEE","2 Dec 2024","","","IEEE","IEEE Conferences"
"Table of Contents","",,2023 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"4 Dec 2023","2023","","","5","14","","2771-1110","979-8-3503-2891-2","10.1109/ISMAR-Adjunct60411.2023.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10322213","","","","","","","IEEE","4 Dec 2023","","","IEEE","IEEE Conferences"
"Table of Contents","",,IEEE Transactions on Visualization and Computer Graphics,"29 Mar 2019","2019","25","5","ii","iii","Presents the table of contents for this issue of the publication.","1941-0506","","10.1109/TVCG.2019.2902969","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8676207","","","","","","0","IEEE","29 Mar 2019","","","IEEE","IEEE Journals"
"2019 Index IEEE Transactions on Visualization and Computer Graphics Vol. 25","",,IEEE Transactions on Visualization and Computer Graphics,"31 Dec 2019","2020","26","2","1","40","Presents the 2019 subject/author index for this publication.","1941-0506","","10.1109/TVCG.2019.2953450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8946777","","","","","","","IEEE","31 Dec 2019","","","IEEE","IEEE Journals"
"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)","",,2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct),"15 Dec 2022","2022","","","v","xvi","Presents the conference table of contents.","2771-1110","978-1-6654-5365-3","10.1109/ISMAR-Adjunct57072.2022.00004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9974514","","","","","","","IEEE","15 Dec 2022","","","IEEE","IEEE Conferences"
