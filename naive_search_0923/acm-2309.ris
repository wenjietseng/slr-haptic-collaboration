TY  - JOUR
TI  - A survey on synchronous augmented, virtual, andMixed reality remote collaboration systems
AU  - Schäfer, Alexander
AU  - Reis, Gerd
AU  - Stricker, Didier
T2  - Acm Computing Surveys
AB  - Remote collaboration systems have become increasingly important in today’s society, especially during times when physical distancing is advised. Industry, research, and individuals face the challenging task of collaborating and networking over long distances. While video and teleconferencing are already widespread, collaboration systems in augmented, virtual, and mixed reality are still a niche technology. We provide an overview of recent developments of synchronous remote collaboration systems and create a taxonomy by dividing them into three main components that form such systems: Environment, Avatars, and Interaction. A thorough overview of existing systems is given, categorising their main contributions to help researchers working in different fields by providing concise information about specific topics such as avatars, virtual environment, visualisation styles, and interaction. The focus of this work is clearly on synchronised collaboration from a distance. A total of 87 unique systems for remote collaboration are discussed, including more than 100 publications and 25 commercial systems.
DA  - 2022/12//
PY  - 2022
DO  - 10.1145/3533376
VL  - 55
IS  - 6
J2  - ACM Comput. Surv.
SN  - 0360-0300
UR  - https://doi.org/10.1145/3533376
KW  - Virtual reality
KW  - augmented reality
KW  - mixed reality
KW  - literature review
KW  - collaboration
KW  - distant cooperation
KW  - remote assistance
ER  - 

TY  - CONF
TI  - HoloBots: Augmenting holographic telepresence with mobile robots for tangible remote collaboration in mixed reality
AU  - Ihara, Keiichi
AU  - Faridan, Mehrad
AU  - Ichikawa, Ayumi
AU  - Kawaguchi, Ikkaku
AU  - Suzuki, Ryo
T3  - Uist '23
AB  - This paper introduces HoloBots, a mixed reality remote collaboration system that augments holographic telepresence with synchronized mobile robots. Beyond existing mixed reality telepresence, HoloBots lets remote users not only be visually and spatially present, but also physically engage with local users and their environment. HoloBots allows the users to touch, grasp, manipulate, and interact with the remote physical environment as if they were co-located in the same shared space. We achieve this by synchronizing holographic user motion (Hololens 2 and Azure Kinect) with tabletop mobile robots (Sony Toio). Beyond the existing physical telepresence, HoloBots contributes to an exploration of broader design space, such as object actuation, virtual hand physicalization, world-in-miniature exploration, shared tangible interfaces, embodied guidance, and haptic communication. We evaluate our system with twelve participants by comparing it with hologram-only and robot-only conditions. Both quantitative and qualitative results confirm that our system significantly enhances the level of co-presence and shared experience, compared to the other conditions.
C1  - San Francisco, CA, USA
C3  - Proceedings of the 36th annual ACM symposium on user interface software and technology
DA  - 2023///
PY  - 2023
DO  - 10.1145/3586183.3606727
PB  - Association for Computing Machinery
SN  - 979-8-4007-0132-0
UR  - https://doi.org/10.1145/3586183.3606727
KW  - Mixed Reality
KW  - Remote Collaboration
KW  - Actuated Tangible UI
KW  - Mobile Robots
KW  - Physical Telepresence
ER  - 

TY  - JOUR
TI  - Supporting complex decision-making: Evidence from an eye tracking study on in-person and remote collaboration
AU  - Wisiecka, Katarzyna
AU  - Konishi, Yuumi
AU  - Krejtz, Krzysztof
AU  - Zolfaghari, Mahshid
AU  - Kopainsky, Birgit
AU  - Krejtz, Izabela
AU  - Koike, Hideki
AU  - Fjeld, Morten
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - This article examines the attentional mechanism of in-person collaboration by means of System Dynamics-based simulations using an eye tracking experiment. Three experimental conditions were tested: in-person collaboration, remote collaboration, and single user. We hypothesized that collaboration focuses users’ attention on key information facilitating decision-making. Collaborating participants dwelt longer on key elements of the simulation than single users. Moreover, in-person collaboration and single users yielded a strategy of decision-making similar to an optimal strategy. Finally, in-person collaboration was less cognitively demanding and of higher quality. The contribution of this article is a deeper understanding of how in-person collaboration on a large display can help users focus their visual attention on the most important areas. With this novel understanding, we believe collaborative systems designers will be better equipped to design more effective attention-guiding mechanisms in remote collaboration systems. The present work has the potential to advance the study of collaborative, interactive technologies.
DA  - 2023/09//
PY  - 2023
DO  - 10.1145/3581787
VL  - 30
IS  - 5
SN  - 1073-0516
UR  - https://doi.org/10.1145/3581787
KW  - collaboration
KW  - eye tracking
KW  - natural resource management
KW  - System dynamics simulation
KW  - visual attention
ER  - 

TY  - JOUR
TI  - ColabAR: a toolkit for remote collaboration in tangible augmented reality laboratories
AU  - Villanueva, Ana
AU  - Zhu, Zhengzhe
AU  - Liu, Ziyi
AU  - Wang, Feiyang
AU  - Chidambaram, Subramanian
AU  - Ramani, Karthik
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Current times are accelerating new technologies to provide high-quality education for remote collaboration, as well as hands-on learning. This is particularly important in the case of laboratory-based classes, which play an essential role in STEM education. In this paper, we introduce ColabAR, a toolkit that uses physical proxies to manipulate virtual objects in Tangible Augmented Reality (TAR) laboratories. ColabAR introduces haptic-based customizable interaction techniques to promote remote collaboration between students. Our toolkit provides hardware and software that enable haptic feedback to improve user experience and promote collaboration during learning. Also, we present the architecture of our cloud platform for haptic interaction that supports information sharing between students in a TAR laboratory. We performed two user studies (N=40) to test the effect of our toolkit in enriching local and remote collaborative experiences. Finally, we demonstrated that our TAR laboratory enables students' performance (i.e., lab completion rate, lab scores) to be similar to their performance in an in-person laboratory.
DA  - 2022/04//
PY  - 2022
DO  - 10.1145/3512928
VL  - 6
IS  - CSCW1
UR  - https://doi.org/10.1145/3512928
KW  - augmented reality
KW  - haptics
KW  - collaboration
KW  - distance
KW  - education
KW  - laboratory
KW  - learning
KW  - remote
KW  - STEM
KW  - tangibles
ER  - 

TY  - CONF
TI  - Get real with me: Effects of avatar realism on social presence and comfort in augmented reality remote collaboration and self-disclosure
AU  - Kaiser, Jonah-Noël
AU  - Kimmel, Simon
AU  - Licht, Eva
AU  - Landwehr, Eric
AU  - Hemmert, Fabian
AU  - Heuten, Wilko
T3  - Chi '25
AB  - Augmented reality (AR) is poised to transform remote communication with realistic user representations authentically simulating in-person interactions in one’s own environment. While increased avatar realism is beneficial in various social contexts, as it generally fosters social presence, its impact in intimate interactions is less clear, possibly creating discomfort. We explored how varying avatar realism affects social presence and comfort in AR across different social interactions. Realism preferences were established in an online survey (N=157), informing our subsequent experiment (N=42). Participants engaged in remote AR collaboration and self-disclosure tasks with avatars ranging from abstract to realistic point-cloud. Quantitative and qualitative feedback revealed that higher avatar realism generally enhances social presence and comfort, though preferences can vary. The self-disclosure task increased social presence but reduced comfort compared to the collaboration task. This research provides an empirical analysis of avatar realism, highlighting the benefits of realistic avatars in various scenarios.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713541
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713541
KW  - augmented reality
KW  - social presence
KW  - collaboration
KW  - avatar realism
KW  - self-disclosure
KW  - user-representation
ER  - 

TY  - CONF
TI  - Coding together: On co-located and remote collaboration between children with mixed-visual abilities
AU  - Rocha, Filipa
AU  - Correia, Filipa
AU  - Neto, Isabel
AU  - Pires, Ana Cristina
AU  - Guerreiro, João
AU  - Guerreiro, Tiago
AU  - Nicolau, Hugo
T3  - Chi '23
AB  - Collaborative coding environments foster learning, social skills, computational thinking training, and supportive relationships. In the context of inclusive education, these environments have the potential to promote inclusive learning activities for children with mixed-visual abilities. However, there is limited research focusing on remote collaborative environments, despite the opportunity to design new modes of access and control of content to promote more equitable learning experiences. We investigated the tradeoffs between remote and co-located collaboration through a tangible coding kit. We asked ten pairs of mixed-visual ability children to collaborate in an interdependent and asymmetric coding game. We contribute insights on six dimensions - effectiveness, computational thinking, accessibility, communication, cooperation, and engagement - and reflect on differences, challenges, and advantages between collaborative settings related to communication, workspace awareness, and computational thinking training. Lastly, we discuss design opportunities of tangibles, audio, roles, and tasks to create inclusive learning activities in remote and co-located settings.
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI conference on human factors in computing systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544548.3581261
PB  - Association for Computing Machinery
SN  - 978-1-4503-9421-5
UR  - https://doi.org/10.1145/3544548.3581261
KW  - Collaboration
KW  - Accessible
KW  - Children
KW  - Computational thinking
KW  - Mixed-visual ability
KW  - Robot
KW  - Tangible
KW  - Visually impaired
ER  - 

TY  - CONF
TI  - Designing telepresence drones to support synchronous, mid-air remote collaboration: An exploratory study
AU  - Sabet, Mehrnaz
AU  - Orand, Mania
AU  - W. McDonald, David
T3  - Chi '21
AB  - Drones are increasingly used to support humanitarian crises and events that involve dangerous or costly tasks. While drones have great potential for remote collaborative work and aerial telepresence, existing drone technology is limited in its support for synchronous collaboration among multiple remote users. Through three design iterations and evaluations, we prototyped Squadrone, a novel aerial telepresence platform that supports synchronous mid-air collaboration among multiple remote users. We present our design and report results from evaluating our iterations with 13 participants in 3 different collaboration configurations. Our first design iteration validates the basic functionality of the platform. Then, we establish the effectiveness of collaboration using a 360-degree shared aerial display. Finally, we simulate a type of search task in an open environment to see if collaborative telepresence impacts members’ participation. The results validate some initial goals for Squadrone and are used to reflect back on a recent telepresence design framework.
C1  - Yokohama, Japan
C3  - Proceedings of the 2021 CHI conference on human factors in computing systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411764.3445041
PB  - Association for Computing Machinery
SN  - 978-1-4503-8096-6
UR  - https://doi.org/10.1145/3411764.3445041
KW  - Telepresence
KW  - Collaborative work
KW  - User Interface
KW  - Remote collaboration
KW  - Collaborative remote control
KW  - Drones
KW  - Quadcopters
KW  - UAV
ER  - 

TY  - CONF
TI  - HapticPointer: a neck-worn device that presents direction by vibrotactile feedback for remote collaboration tasks
AU  - Matsuda, Akira
AU  - Nozawa, Kazunori
AU  - Takata, Kazuki
AU  - Izumihara, Atsushi
AU  - Rekimoto, Jun
T3  - AHs '20
AB  - We designed a necklace-style device named HapticPointer for presenting a direction as pointing cues in remote collaboration tasks. The device has 16 vibration motors placed along a line of flexible string. Our vibration algorithm represents horizontal and vertical directions by changing the position and intensity of each vibration. In our experiment, participants attempted to find a specific target, and the accuracy of successful trials reached 90.65
C1  - Kaiserslautern, Germany
C3  - Proceedings of the augmented humans international conference
DA  - 2020///
PY  - 2020
DO  - 10.1145/3384657.3384777
PB  - Association for Computing Machinery
SN  - 978-1-4503-7603-7
UR  - https://doi.org/10.1145/3384657.3384777
KW  - telepresence
KW  - haptic feedback
KW  - remote collaboration
KW  - wearable device
ER  - 

TY  - CONF
TI  - Performance and user based analysis of a collaborative virtual environment system
AU  - Rodrigues, Maria Andréia Formico
AU  - Chaves, Ricardo Régis Cavalcante
T3  - Graphite '07
AB  - In this work, we analyse the effect of network parameters on the judged usability of a collaborative virtual environment. Participants were trained to find the exit of a virtual maze by a trainer, which guided the exploration of the virtual space. An extensive experimental evaluation was conducted by simulating a series of operational parameters (network bandwidth and latency) to assess the reported effectiveness of the training. An objective similarity metric based on processing time per test was also defined and used, as well as subjective user's evaluations. Further, we have successfully correlated subjective evaluation and objective measure by computing the correlation values and showing how the two values co-vary.
C1  - Perth, Australia
C3  - Proceedings of the 5th international conference on computer graphics and interactive techniques in australia and southeast asia
DA  - 2007///
PY  - 2007
DO  - 10.1145/1321261.1321296
SP  - 195
EP  - 202
PB  - Association for Computing Machinery
SN  - 978-1-59593-912-8
UR  - https://doi.org/10.1145/1321261.1321296
KW  - training
KW  - collaborative virtual environment system
KW  - performance analysis
ER  - 

TY  - CONF
TI  - TwinCam go: Proposal of vehicle-ride sensation sharing with stereoscopic 3D visual perception and vibro-vestibular feedback for immersive remote collaboration
AU  - Yem, Vibol
AU  - Nashiki, Reon
AU  - Morita, Tsubasa
AU  - Miyashita, Fumiya
AU  - Amemiya, Tomohiro
AU  - Ikei, Yasushi
T3  - Sa '19
AB  - Personal vehicles such as the Segway have been actively used for security patrols or supervision of construction sites, because of their mobility capabilities. In the current study, we proposed a vehicle-ride sensation sharing system enabling a rider to remotely collaborate with a driver, and to receive both 3D visual perception and vibro-vestibular sensation. We developed a prototype personal vehicle system with two 360° cameras attached to the Segway with a stabilizer to capture stereoscopic 3D images and send them to each eye of a head-mounted display worn by a remotely collaborating rider. We also developed a prototype of vibro-vestibular display by modifying a conventional wheelchair with a simple lightweight mechanism for actuation and vibration by two DC motors. In our presentation algorithm, each wheel of the wheelchair is accelerated or decelerated proportionally to the acceleration of each wheel of the Segway. When the velocity of each wheel was almost constant and the acceleration was nearly zero, the wheelchair slowly moved to the initial position, with movement that the rider could not perceive, to keep the wheelchair accelerating or decelerating in a limited space.
C1  - Brisbane, QLD, Australia
C3  - SIGGRAPH asia 2019 emerging technologies
DA  - 2019///
PY  - 2019
DO  - 10.1145/3355049.3360540
SP  - 53
EP  - 54
PB  - Association for Computing Machinery
SN  - 978-1-4503-6942-8
UR  - https://doi.org/10.1145/3355049.3360540
KW  - telepresence
KW  - collaboration
KW  - ride sensation sharing
KW  - stereoscopic 3D image
KW  - vibro-vestibular feedback
ER  - 

TY  - JOUR
TI  - Modeling the effects of delayed haptic and visual feedback in a collaborative virtual environment
AU  - Jay, Caroline
AU  - Glencross, Mashhuda
AU  - Hubbold, Roger
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - Collaborative virtual environments (CVEs) enable two or more people, separated in the real world, to share the same virtual “space.” They can be used for many purposes, from teleconferencing to training people to perform assembly tasks. Unfortunately, the effectiveness of CVEs is compromised by one major problem: the delay that exists in the networks linking users together. Whilst we have a good understanding, especially in the visual modality, of how users are affected by delayed feedback from their own actions, little research has systematically examined how users are affected by delayed feedback from other people, particularly in environments that support haptic (force) feedback. The current study addresses this issue by quantifying how increasing levels of latency affect visual and haptic feedback in a collaborative target acquisition task. Our results demonstrate that haptic feedback in particular is very sensitive to low levels of delay. Whilst latency affects visual feedback from 50 ms, it impacts on haptic task performance 25 ms earlier, and causes the haptic measures of performance deterioration to rise far more steeply than visual. The “impact-perceive-adapt” model of user performance, which considers the interaction between performance measures, perception of latency, and the breakdown of perception of immediate causality, is proposed as an explanation for the observed pattern of performance.
DA  - 2007/08//
PY  - 2007
DO  - 10.1145/1275511.1275514
VL  - 14
IS  - 2
SP  - 8
EP  - es
SN  - 1073-0516
UR  - https://doi.org/10.1145/1275511.1275514
KW  - virtual environments
KW  - latency
KW  - Haptics
KW  - distributed collaboration
ER  - 

TY  - CONF
TI  - Real-time bidirectional head rotation sharing for collaborative interaction enhancement
AU  - Li, Wanhui
AU  - Nakamura, Takuto
AU  - Zhang, Qing
AU  - Rekimoto, Jun
T3  - Sui '24
AB  - Remote collaboration is becoming more prevalent, yet it often struggles with effectively conveying the spatial orientation of a remote participant. We introduce an innovative communication method that enables users to share their head direction. While traditional methods like written text and spoken language suit most situations, new approaches are necessary for scenarios lacking sufficient visual or auditory cues. For instance, how can hearing-impaired individuals share directional information during a remote collaborative game? This research presents an interactive system that induces head rotation based on the other user’s head direction, allowing users to grasp each other’s intended direction intuitively. This system improves communication by offering an additional means to share directional cues, especially in settings where visual and auditory cues are inadequate.
C1  - Trier, Germany
C3  - Proceedings of the 2024 ACM symposium on spatial user interaction
DA  - 2024///
PY  - 2024
DO  - 10.1145/3677386.3688878
PB  - Association for Computing Machinery
SN  - 979-8-4007-1088-9
UR  - https://doi.org/10.1145/3677386.3688878
KW  - Remote Collaboration
KW  - Body Sharing
KW  - Hanger Reflex
KW  - Synchronous Rotation
ER  - 

TY  - JOUR
TI  - Haptic network protocols: a comprehensive review and directions for next-gen metaverse applications
AU  - Faisal, Mohd
AU  - Martinez-Velazquez, Roberto Alejandro
AU  - Laamarti, Fedwa
AU  - Al Osman, Hussein
AU  - El Saddik, Abdulmotaleb
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
AB  - This paper presents a systematic review of haptic network protocols, in the context of the Metaverse. With the increasing integration of haptic technologies into applications like remote collaboration and robotic surgery, the need for reliable, low-latency data transmission has intensified. This work provides a comprehensive analysis of existing haptic protocols and frameworks, focusing on their development, implementation, and the methods employed to optimize Quality of Service (QoS) parameters such as latency, delay, packet loss, jitter, throughput, and bandwidth. By examining the strengths and limitations of these protocols in real-time applications, this paper identifies critical areas for improvement and suggests future directions, including the potential for incorporating machine learning (ML) and artificial intelligence (AI) to enable next-generation haptic communication suited for high-demand environments like the Metaverse.
DA  - 2025/08//
PY  - 2025
DO  - 10.1145/3759459
SN  - 1551-6857
UR  - https://doi.org/10.1145/3759459
N1  - Just Accepted
KW  - Latency
KW  - Jitter
KW  - Systematic Review
KW  - Haptic
KW  - Tactile Internet
KW  - Metaverse
KW  - Delay
KW  - Bandwidth
KW  - Communication
KW  - Data Integration Frameworks
KW  - Data Transmission
KW  - Network
KW  - Packet Loss
KW  - Protocol
KW  - Quality of Experience (QoE)
KW  - Quality of Service (QoS)
KW  - Real-Time
KW  - Throughput
ER  - 

TY  - CONF
TI  - In touch with the remote world: remote collaboration with augmented reality drawings and virtual navigation
AU  - Gauglitz, Steffen
AU  - Nuernberger, Benjamin
AU  - Turk, Matthew
AU  - Höllerer, Tobias
T3  - Vrst '14
AB  - Augmented reality annotations and virtual scene navigation add new dimensions to remote collaboration. In this paper, we present a touchscreen interface for creating freehand drawings as world-stabilized annotations and for virtually navigating a scene reconstructed live in 3D, all in the context of live remote collaboration. Two main focuses of this work are (1) automatically inferring depth for 2D drawings in 3D space, for which we evaluate four possible alternatives, and (2) gesture-based virtual navigation designed specifically to incorporate constraints arising from partially modeled remote scenes. We evaluate these elements via qualitative user studies, which in addition provide insights regarding the design of individual visual feedback elements and the need to visualize the direction of drawings.
C1  - Edinburgh, Scotland
C3  - Proceedings of the 20th ACM symposium on virtual reality software and technology
DA  - 2014///
PY  - 2014
DO  - 10.1145/2671015.2671016
SP  - 197
EP  - 205
PB  - Association for Computing Machinery
SN  - 978-1-4503-3253-8
UR  - https://doi.org/10.1145/2671015.2671016
KW  - telepresence
KW  - augmented reality
KW  - CSCW
KW  - video-mediated communication
KW  - touch
KW  - gesture recognition
KW  - depth interpretation
ER  - 

TY  - CONF
TI  - Tangible interfaces for remote collaboration and communication
AU  - Brave, Scott
AU  - Ishii, Hiroshi
AU  - Dahley, Andrew
T3  - Cscw '98
C1  - Seattle, Washington, USA
C3  - Proceedings of the 1998 ACM conference on computer supported cooperative work
DA  - 1998///
PY  - 1998
DO  - 10.1145/289444.289491
SP  - 169
EP  - 178
PB  - Association for Computing Machinery
SN  - 1-58113-009-0
UR  - https://doi.org/10.1145/289444.289491
KW  - telemanipulation
KW  - force-feedback
KW  - haptic interfaces
KW  - physical presence
KW  - tangble interfaces
ER  - 

TY  - JOUR
TI  - A systematic review of XR-enabled remote human-robot interaction systems
AU  - Wang, Xian
AU  - Shen, Luyao
AU  - Lee, Lik-Hang
T2  - Acm Computing Surveys
AB  - The rising interest in creating versatile robots to handle multiple tasks in various environments, with humans interacting through immersive interfaces. This survey provides a comprehensive review of extended reality (XR) applications in remote human–robot interaction (HRI). We developed a systematic search strategy based on the PRISMA methodology, focusing on peer-reviewed publications that demonstrate practical implementations of XR in remote robot control, real robot system deployment, and HRI applications, we analyzed research published between January 2013 and December 2023. From the initial 2,561 articles, 100 met our inclusion criteria were included. We categorized and summarized the domain in detail, delving into the methods used in these articles to achieve intuitive and effective remote HRI, highlighting user experience enhancement and interaction designs. This survey identifies research opportunities, particularly emphasizes that future researchers should explore the potential of XR, such as exploring multimodal enhancement techniques that seamlessly integrate visual, haptic, and auditory feedback for more intuitive teleoperation. Our analysis reveals that while XR shows promising potential in remote HRI, there are significant gaps, such as user-centered design. This survey provides a framework for understanding the current state of XR-based remote HRI, establishing a foundation for future research.
DA  - 2025/06//
PY  - 2025
DO  - 10.1145/3730574
VL  - 57
IS  - 11
J2  - ACM Comput. Surv.
SN  - 0360-0300
UR  - https://doi.org/10.1145/3730574
KW  - virtual reality
KW  - augmented reality
KW  - teleoperation
KW  - Human-robot interaction
KW  - remote collaboration
KW  - extended reality
ER  - 

TY  - CONF
TI  - RemoconHanger: Making head rotation in remote person using the hanger reflex
AU  - Li, Wanhui
AU  - Nakamura, Takuto
AU  - Rekimoto, Jun
T3  - UIST '22 adjunct
AB  - For remote collaboration, it is essential to intuitively grasp the situation and spatial location. However, the difficulty in grasping information about the remote user’s orientation can hinder remote communication. For example, if a remote user turns his or her head to the right to operate a device on the right, and this sensation cannot be shared, the image sent by the remote user suddenly appears to flow laterally, and it will lose the positional relationship like Figure 1 (left). Therefore, we propose a device using the ”hanger reflex” to experience the sensation of head rotation intuitively. The ”hanger reflex” is a phenomenon in which the head turns unconsciously when a wire hanger is placed on the head. It has been verified that the sensation of turning is produced by the distribution of pressure exerted by a device worn on the head. This research aims to construct a mechanism to verify its effectiveness for telecommunication that can unconsciously experience the remote user’s rotation sensation using the hanger reflex phenomenon. An inertial measurement unit(IMU) grasps the remote user’s rotation information like Figure 1 (right).
C1  - Bend, OR, USA
C3  - Adjunct proceedings of the 35th annual ACM symposium on user interface software and technology
DA  - 2022///
PY  - 2022
DO  - 10.1145/3526114.3558700
PB  - Association for Computing Machinery
SN  - 978-1-4503-9321-8
UR  - https://doi.org/10.1145/3526114.3558700
KW  - Remote Collaboration
KW  - Hanger Reflex
KW  - Synchronous Rotation
KW  - Positional Relationship
ER  - 

TY  - CONF
TI  - Understanding how to support remote co-design with a conceptual modular shape-changing interface toolkit
AU  - Ye, Huizhong
AU  - Janssen, Charlaine
AU  - Noordman, Daan
AU  - Liang, Rong-Hao
T3  - Tei '22
AB  - Remote collaboration is a challenge for physical product designers, and especially limits the mutual communication of the “thinking through prototyping” approach. Inspired by the NURBSforms and self-shape sensing technologies, we investigate how to support remote co-design with a conceptual modular shape-changing interface toolkit. By using stop-motion videos and low-fi non-electronic prototypes as probes, the concept was evaluated through on-line questionnaires and workshops. The result shows its potential especially in the exploration phase of remote co-design.
C1  - Daejeon, Republic of Korea
C3  - Proceedings of the sixteenth international conference on tangible, embedded, and embodied interaction
DA  - 2022///
PY  - 2022
DO  - 10.1145/3490149.3505563
PB  - Association for Computing Machinery
SN  - 978-1-4503-9147-4
UR  - https://doi.org/10.1145/3490149.3505563
KW  - Remote collaboration
KW  - modular
KW  - prototyping
KW  - shape memory alloys
KW  - shape-changing
KW  - toolkit
ER  - 

TY  - CONF
TI  - Physical telepresence: shape capture and display for embodied, computer-mediated remote collaboration
AU  - Leithinger, Daniel
AU  - Follmer, Sean
AU  - Olwal, Alex
AU  - Ishii, Hiroshi
T3  - Uist '14
AB  - We propose a new approach to Physical Telepresence, based on shared workspaces with the ability to capture and remotely render the shapes of people and objects. In this paper, we describe the concept of shape transmission, and propose interaction techniques to manipulate remote physical objects and physical renderings of shared digital content. We investigate how the representation of user's body parts can be altered to amplify their capabilities for teleoperation. We also describe the details of building and testing prototype Physical Telepresence workspaces based on shape displays. A preliminary evaluation shows how users are able to manipulate remote objects, and we report on our observations of several different manipulation techniques that highlight the expressive nature of our system.
C1  - Honolulu, Hawaii, USA
C3  - Proceedings of the 27th annual ACM symposium on user interface software and technology
DA  - 2014///
PY  - 2014
DO  - 10.1145/2642918.2647377
SP  - 461
EP  - 470
PB  - Association for Computing Machinery
SN  - 978-1-4503-3069-5
UR  - https://doi.org/10.1145/2642918.2647377
KW  - teleoperation
KW  - actuated tangible interfaces
KW  - physical telepresence
KW  - shape displays
KW  - shape-changing user interfaces
ER  - 

TY  - CONF
TI  - GazeMolVR: Sharing eye-gaze cues in a collaborative VR environment for molecular visualization
AU  - Darbar, Rajkumar
AU  - Santuz, Hubert
AU  - Taly, Antoine
AU  - Baaden, Marc
T3  - Mum '24
AB  - Virtual Reality (VR) has significantly enhanced the visualization of molecular structures, offering an intuitive and immersive experience. However, immersive collaborative virtual environments, despite their benefits that can come close to physical co-location, often lack crucial non-verbal communication cues such as gaze awareness, essential for enriching face-to-face collaboration. This research introduces GazeMolVR, a tool based on the UnityMol software that enables a remote pair to collaboratively explore and discuss a protein’s structure and function within a VR environment. It incorporates bi-directional eye-gaze cues through four distinct representations—GazePoint, GazeArrow, GazeSpotlight, and GazeTrail—to enhance mutual awareness of visual focus during discussions. We conducted two user studies to evaluate GazeMolVR. The first aimed to identify the most suitable gaze visualization for discussing proteins depicted in cartoon, ball-and-stick, and surface models. The second compared the effects of bi-directional gaze sharing during collaborative discussions to a scenario without gaze sharing, especially in the field of structural biology. Study results showed a preference for GazeTrail with cartoon and ball-and-stick models, and GazeSpotlight for the surface model. Additionally, sharing bi-directional eye-gaze cues significantly enhanced collaborative discussions compared to not using gaze cues.
C1  - New York, NY, USA
C3  - Proceedings of the international conference on mobile and ubiquitous multimedia
DA  - 2024///
PY  - 2024
DO  - 10.1145/3701571.3701599
SP  - 7
EP  - 23
PB  - Association for Computing Machinery
SN  - 979-8-4007-1283-8
UR  - https://doi.org/10.1145/3701571.3701599
KW  - Remote Collaboration
KW  - Augmented Reality (AR)
KW  - Eye-Gaze
KW  - Molecular Visualization
KW  - Scientific Data Visualization.
KW  - Virtual Reality (VR)
ER  - 

TY  - CONF
TI  - AMMP-Vis: a collaborative virtual environment for molecular modeling
AU  - Chastine, Jeffrey W.
AU  - Brooks, Jeremy C.
AU  - Zhu, Ying
AU  - Owen, G. Scott
AU  - Harrison, Robert W.
AU  - Weber, Irene T.
T3  - Vrst '05
AB  - Molecular modeling is an important research area, helping scientists develop new drugs against diseases such as AIDS and cancer. Prior studies have demonstrated that immersive virtual environments have unique advantages over desktop systems in visualizing molecular models. However, exploration and interaction in existing molecular modeling virtual environments is often limited to a single user, lacking strong support for collaboration. In addition, scientists are often reluctant to adopt these systems because of their lack of availability and high cost. We propose an affordable immersive system that allows biologists and chemists to manipulate molecular models via natural gestures, receive and visualize real-time feedback from a molecular dynamics simulator, allow the sharing of customized views, and provide support for both local and remote collaborative research.
C1  - Monterey, CA, USA
C3  - Proceedings of the ACM symposium on virtual reality software and technology
DA  - 2005///
PY  - 2005
DO  - 10.1145/1101616.1101620
SP  - 8
EP  - 15
PB  - Association for Computing Machinery
SN  - 1-59593-098-1
UR  - https://doi.org/10.1145/1101616.1101620
KW  - virtual environments
KW  - augmented reality
KW  - interaction techniques
KW  - collaboration
KW  - molecular modeling
KW  - shaders
ER  - 

TY  - CONF
TI  - Legible+: integrated system for remote collaboration through document creation
AU  - Pelaez, Mariano Perez
AU  - Fujii, Toshiya
AU  - Nam, Wonsuk
AU  - Yachiune, Masaki
AU  - Choh, Ikuro
T3  - Icis '09
AB  - The computer has become an essential tool for collaboration between remote users and group work. But, for different reasons, current systems do not take advantage of all the possibilities of current computers and user interfaces for creating a more efficient, natural and enjoyable working environment. We are developing a system, Legible +, which try to solve what we consider are the most important flaws in remote communication, including a set of features that is not present in other long distance communication environments. Legible+ provides an integrated environment, with software and hardware device, for the collaborative document creation through the internet, the resource management and document distribution. Our system take advantages of new interface technologies while also remains compatible with standard computer hardware.
C1  - Seoul, Korea
C3  - Proceedings of the 2nd international conference on interaction sciences: Information technology, culture and human
DA  - 2009///
PY  - 2009
DO  - 10.1145/1655925.1656028
SP  - 568
EP  - 570
PB  - Association for Computing Machinery
SN  - 978-1-60558-710-3
UR  - https://doi.org/10.1145/1655925.1656028
KW  - user interface
KW  - design
KW  - computer support
KW  - online collaboration
KW  - resource management
ER  - 

TY  - CONF
TI  - Mixed reality collaboration for complementary working styles
AU  - Wang, Keru
AU  - Wang, Zhu
AU  - Rosenberg, Karl
AU  - He, Zhenyi
AU  - Yoo, Dong Woo
AU  - Christopher, Un Joo
AU  - Perlin, Ken
T3  - Siggraph '22
AB  - Our project combines immersive VR, multitouch AR, real-time volumetric capture, motion capture, robotically-actuated tangible interfaces at multiple scales, and live coding, in service of a human-centric way of collaborating. Participants bring their unique talents and preferences to collaboratively tackle complex problems in a shared mixed reality world.
C1  - Vancouver, BC, Canada
C3  - ACM SIGGRAPH 2022 immersive pavilion
DA  - 2022///
PY  - 2022
DO  - 10.1145/3532834.3536216
PB  - Association for Computing Machinery
SN  - 978-1-4503-9369-0
UR  - https://doi.org/10.1145/3532834.3536216
KW  - Mixed reality
KW  - remote collaboration
KW  - tangible interface
ER  - 

TY  - CONF
TI  - Supporting collaborative discussions in surgical teleconsulting through augmented reality head mounted displays
AU  - Maria, Sophie
AU  - Mentis, Helena M.
AU  - Canlorbe, Geoffroy
AU  - Avellino, Ignacio
T3  - Chi '23
AB  - Although Augmented Reality (AR) has been touted as the future of surgery, its contribution to distributed collaboration such as in surgical teleconsulting has not been articulated. We propose AR-Head Mounted Displays (AR-HMD) to tackle two previously-identified challenges: operating surgeons needing to view and interact with imaging systems that reside away from the operative field, and, their lack of gesturing tools to point and annotate on the shared images and physical environment. We report on a controlled lab experiment where 12 expert gynecology surgeons perform a tumor localisation task guided by a remote radiologist (confederate) via an AR-HMD. We find that bringing the shared images to the place of work reduces the need for clarifications and provides opportunistic access to information when required, and, that pointing and annotating provides opportunities to further support verbal instruction in deictic communication. Our results inform the design of intraoperative AR-HMD systems for surgical telecollaboration.
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI conference on human factors in computing systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544548.3580714
PB  - Association for Computing Machinery
SN  - 978-1-4503-9421-5
UR  - https://doi.org/10.1145/3544548.3580714
KW  - augmented reality
KW  - remote collaboration
KW  - teleconsulting
ER  - 

TY  - CONF
TI  - Collaborative metaphor for haptic designation in complex 3D environments
AU  - Girard, Adrien
AU  - Auvray, Malika
AU  - Ammi, Mehdi
T3  - Sap '14
AB  - Designating targets, such as elementary primitives (e.g., vertices, edges and faces) or complex objects (e.g., 3D objects and structures), to a partner in Collaborative Virtual Environments is a real challenge in different applications. In fact, the communication constraints in such environments limit the understanding of the partner's actions, which lead to wrong selections and thus to conflicting actions. Beyond these limitations, applications providing complex data to manipulate, such as molecular environments, introduce additional constraints which limit the perception and access to the partner's working space. This paper proposes a remote designation procedure linked with an haptic attraction model for molecular deformation tasks, we propose to guide physically the partner to the designated atom. Experimental results showed a significant improvement in performance and efficiency for the different steps of collaborative tasks (i.e., designation/selection of atoms and deformation of structures). Moreover, this haptic guidance method enables more accurate selections of atoms for the partner.
C1  - Vancouver, British Columbia, Canada
C3  - Proceedings of the ACM symposium on applied perception
DA  - 2014///
PY  - 2014
DO  - 10.1145/2628257.2628262
SP  - 31
EP  - 37
PB  - Association for Computing Machinery
SN  - 978-1-4503-3009-1
UR  - https://doi.org/10.1145/2628257.2628262
KW  - haptic feedback
KW  - collaborative virtual environment
ER  - 

TY  - CONF
TI  - Haptic-aware interaction: Design and evaluation
AU  - Fang, Ying
T3  - Mm '23
AB  - The emerging haptic technology has introduced new media perceptions and also increased the immersive experiences of end-users. To date, novel haptic-audio-visual environments and their Quality of Experience (QoE) assessments are still challenging issues. In this work, we investigate the haptic-visual interaction QoE in virtual as well as real-world environments. First, we establish a haptic-visual interaction platform based on a balance ball Virtual Reality (VR) game scene and a haptic-visual interaction platform with data-glove-assisted remote control. Second, we conduct subjective tests to qualitatively and quantitatively analyze the impacts of system-related, user-related and task-related factors on QoE evaluation. Third, we propose learning-based QoE models to effectively evaluate the user-perceived QoE in haptic-visual interaction. In the future work, we aim to focus on the improvement of the two established platforms, with the addition of audio-related influencing factors and more haptic feedback, and optimizing the proposed QoE model for further improvement of haptic-audio-visual interaction applications.
C1  - Ottawa ON, Canada
C3  - Proceedings of the 31st ACM international conference on multimedia
DA  - 2023///
PY  - 2023
DO  - 10.1145/3581783.3613437
SP  - 9350
EP  - 9354
PB  - Association for Computing Machinery
SN  - 979-8-4007-0108-5
UR  - https://doi.org/10.1145/3581783.3613437
KW  - immersion
KW  - haptic
KW  - multimedia interaction
KW  - quality of experience
ER  - 

TY  - CONF
TI  - ChameleonControl: Teleoperating real human surrogates through mixed reality gestural guidance for remote hands-on classrooms
AU  - Faridan, Mehrad
AU  - Kumari, Bheesha
AU  - Suzuki, Ryo
T3  - Chi '23
AB  - We present ChameleonControl, a real-human teleoperation system for scalable remote instruction in hands-on classrooms. In contrast to existing video or AR/VR-based remote hands-on education, ChameleonControl uses a real human as a surrogate of a remote instructor. Building on existing human-based telepresence approaches, we contribute a novel method to teleoperate a human surrogate through synchronized mixed reality hand gestural navigation and verbal communication. By overlaying the remote instructor’s virtual hands in the local user’s MR view, the remote instructor can guide and control the local user as if they were physically present. This allows the local user/surrogate to synchronize their hand movements and gestures with the remote instructor, effectively teleoperating a real human. We deploy and evaluate our system in classrooms of physiotherapy training, as well as other application domains such as mechanical assembly, sign language and cooking lessons. The study results confirm that our approach can increase engagement and the sense of co-presence, showing potential for the future of remote hands-on classrooms.
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI conference on human factors in computing systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544548.3581381
PB  - Association for Computing Machinery
SN  - 978-1-4503-9421-5
UR  - https://doi.org/10.1145/3544548.3581381
KW  - Telepresence
KW  - Mixed Reality
KW  - Remote Collaboration
KW  - Hands-on Training
KW  - Human Surrogates
KW  - Remote Guidance
KW  - Visual Cue
ER  - 

TY  - CONF
TI  - GazeTorch: Enabling gaze awareness in collaborative physical tasks
AU  - Akkil, Deepak
AU  - James, Jobin Mathew
AU  - Isokoski, Poika
AU  - Kangas, Jari
T3  - Chi ea '16
AB  - We present GazeTorch, a novel interface that provides gaze awareness during remote collaboration on physical tasks. GazeTorch uses a spotlight to display gaze information of the remote helper on the physical task space of the worker. We conducted a preliminary user study to evaluate user's subjective opinion on the quality of collaboration, using GazeTorch and a camera-only setup. Our preliminary results suggest that the participants felt GazeTorch made collaboration easier, made referencing and identifying of objects effortless, and improved the worker's confidence that the task was completed accurately. We conclude by presenting some novel application scenarios for the concept of augmenting real-time gaze information in the physical world.
C1  - San Jose, California, USA
C3  - Proceedings of the 2016 CHI conference extended abstracts on human factors in computing systems
DA  - 2016///
PY  - 2016
DO  - 10.1145/2851581.2892459
SP  - 1151
EP  - 1158
PB  - Association for Computing Machinery
SN  - 978-1-4503-4082-3
UR  - https://doi.org/10.1145/2851581.2892459
KW  - remote collaboration
KW  - augmentation
KW  - gaze sharing
ER  - 

TY  - CONF
TI  - I’m in control! Transferring object ownership between remote users with haptic props in virtual reality
AU  - Auda, Jonas
AU  - Busse, Leon
AU  - Pfeuffer, Ken
AU  - Gruenefeld, Uwe
AU  - Rivu, Radiah
AU  - Alt, Florian
AU  - Schneegass, Stefan
T3  - Sui '21
AB  - Virtual Reality (VR) remote collaboration is becoming more and more relevant in a wide range of scenarios, such as remote assistance or group work. A way to enhance the user experience is using haptic props that make virtual objects graspable. But physical objects are only present in one location and cannot be manipulated directly by remote users. We explore different strategies to handle ownership of virtual objects enhanced by haptic props. In particular, two strategies of handling object ownership – SingleOwnership and SharedOwnership. SingleOwnership restricts virtual objects to local haptic props, while SharedOwnership allows collaborators to take over ownership of virtual objects using local haptic props. We study both strategies for a collaborative puzzle task regarding their influence on performance and user behavior. Our findings show that SingleOwnership increases communication and enhanced with virtual instructions, results in higher task completion times. SharedOwnership is less reliant on verbal communication and faster, but there is less social interaction between the collaborators.
C1  - Virtual Event, USA
C3  - Proceedings of the 2021 ACM symposium on spatial user interaction
DA  - 2021///
PY  - 2021
DO  - 10.1145/3485279.3485287
PB  - Association for Computing Machinery
SN  - 978-1-4503-9091-0
UR  - https://doi.org/10.1145/3485279.3485287
KW  - Virtual Reality
KW  - Collaboration
KW  - Haptic Props
KW  - Interaction Techniques
ER  - 

TY  - CONF
TI  - Exploring audio, visual, and tactile cues for synchronous remote assistance
AU  - Günther, Sebastian
AU  - Kratz, Sven
AU  - Avrahami, Daniel
AU  - Mühlhäuser, Max
T3  - Petra '18
AB  - Today, remote collaboration techniques between field workers and remotely located experts mainly focus on traditional communication channels, such as voice- or video-conferencing. Those systems may not be suitable in every situation or the communication gets cumbersome if both parties do not share a common ground. In this paper, we explore three supporting communication channels based on audio, visual, and tactile cues. We built a prototypical application implementing those cues and evaluated them in a user study. Based on the user feedback, we report first insights for building remote assistance systems utilizing additional cues.
C1  - Corfu, Greece
C3  - Proceedings of the 11th pervasive technologies related to assistive environments conference
DA  - 2018///
PY  - 2018
DO  - 10.1145/3197768.3201568
SP  - 339
EP  - 344
PB  - Association for Computing Machinery
SN  - 978-1-4503-6390-7
UR  - https://doi.org/10.1145/3197768.3201568
KW  - Navigation
KW  - Augmented Reality
KW  - Haptics
KW  - Remote Collaboration
KW  - 3D-Space
KW  - Assistive Technology
KW  - Audio Cues
KW  - Spatial Guidance
KW  - Vibrotactile Feedback
ER  - 

TY  - CONF
TI  - Investigating teleoperation of UR5 robot using haptic device for different network configuration
AU  - Kumar, Deepak
AU  - Sharma, Aayush D.
AU  - Rebeiro, John
AU  - Bhardwaj, Amit
AU  - Shah, Suril
T3  - Air '23
AB  - Remotely operated robotic systems have gained importance in executing tasks in complex and challenging environments which are difficult to automate. This paper focuses on developing reference hardware and software architectures for haptic-based teleoperation under various physical and network conditions. The system consists of a 6-DOF haptic device as the leader and a 6-DOF robotic manipulator as the follower. The control architecture used for teleoperation is Jacobian inverse control, which enables the follower to follow the leader when commanded. The performance of the proposed architecture is determined in terms of the error between current and commanded motion for different input velocities, communication delays in different network configurations, and the stable haptic force feedback at the haptic end.
C1  - Ropar, India
C3  - Proceedings of the 2023 6th international conference on advances in robotics
DA  - 2023///
PY  - 2023
DO  - 10.1145/3610419.3610470
PB  - Association for Computing Machinery
SN  - 978-1-4503-9980-7
UR  - https://doi.org/10.1145/3610419.3610470
KW  - Haptic
KW  - Teleoperation
KW  - communication
ER  - 

TY  - CONF
TI  - CakeVR: a social virtual reality (VR) tool for co-designing cakes
AU  - Mei, Yanni
AU  - Li, Jie
AU  - de Ridder, Huib
AU  - Cesar, Pablo
T3  - Chi '21
AB  - Cake customization services allow clients to collaboratively personalize cakes with pastry chefs. However, remote (e.g., email) and in-person co-design sessions are prone to miscommunication, due to natural restrictions in visualizing cake size, decoration, and celebration context. This paper presents the design, implementation, and expert evaluation of a social VR application (CakeVR) that allows a client to remotely co-design cakes with a pastry chef, through real-time realistic 3D visualizations. Drawing on expert semi-structured interviews (4 clients, 5 pastry chefs), we distill and incorporate 8 design requirements into our CakeVR prototype. We evaluate CakeVR with 10 experts (6 clients, 4 pastry chefs) using cognitive walkthroughs, and find that it supports ideation and decision making through intuitive size manipulation, color/flavor selection, decoration design, and custom celebration theme fitting. Our findings provide recommendations for enabling co-design in social VR and highlight CakeVR’s potential to transform product design communication through remote interactive and immersive co-design.
C1  - Yokohama, Japan
C3  - Proceedings of the 2021 CHI conference on human factors in computing systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411764.3445503
PB  - Association for Computing Machinery
SN  - 978-1-4503-8096-6
UR  - https://doi.org/10.1145/3411764.3445503
KW  - Remote Collaboration
KW  - Cake Design
KW  - Co-design
KW  - Social Virtual Reality
ER  - 

TY  - CONF
TI  - Sensorimotor-aligned design for pareto-efficient haptic immersion in XR
AU  - Shen, Vivian
T3  - Chi ea '25
AB  - Augmented and virtual reality headsets, collectively referred to as extended reality (XR), can alter, augment, or even replace our reality. While these headsets have made impressive strides in audio-visual immersion over the past half-century, XR interactions remain almost completely absent of appropriately expressive tactile sensations. At present, even mainstream consumer systems rely on vibrotactile haptic actuators in the controllers, which are inherently limited to clicks and buzzes — an exceedingly limited range of expressivity with which to represent the rich tactile world.Realizing the holistic promise of XR requires full-body haptic immersion, just as much as it requires full audio-visual immersion. To frame critical design considerations in haptics research, I propose an immersion-practicality tradeoff model. These competing objectives underscore the inherent tension between providing rich sensory feedback (often e.g. costly, bulky), while maintaining consumer feasibility and usability (e.g., low cost, easy to use). Under this framework, I sought to identify and build Pareto-efficient haptic systems where the haptic approach is aligned with humans’ sensorimotor system. I present three published projects that embody my design approach with tactile haptics to different regions of the body. My proposed future work extends this framework to the other major dimensions of haptics (kinesthetic/force feedback). These systems serve as probes into my research approach and advance the vision of practical, immersive, full-body haptics.
C1  - New York, NY, USA
C3  - Proceedings of the extended abstracts of the CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706599.3707606
PB  - Association for Computing Machinery
SN  - 979-8-4007-1395-8
UR  - https://doi.org/10.1145/3706599.3707606
ER  - 

TY  - CONF
TI  - LocalAnesthesiaVR
AU  - Grandhi, Uttam
AU  - Opazo, Cristián
T3  - Siggraph '21
AB  - LocalAnesthesiaVRis a virtual reality training system for dental anesthesia, a clinical procedure every dentist must be competent with, and one that is particularly challenging to master throughout the demanding dental curriculum. This unique VR-based system provides learners with visual, auditory and haptic feedback enabling experiential learning in pre-clinical education.
C1  - Virtual Event, USA
C3  - ACM SIGGRAPH 2021 educators forum
DA  - 2021///
PY  - 2021
DO  - 10.1145/3450549.3464411
PB  - Association for Computing Machinery
SN  - 978-1-4503-8363-9
UR  - https://doi.org/10.1145/3450549.3464411
KW  - Virtual reality
KW  - haptics
KW  - HCI
KW  - education
KW  - remote collaboration
KW  - analytics
KW  - anatomy
KW  - anesthesia
KW  - assessment.
KW  - dentistry
KW  - experiential learning
KW  - hand tracking
KW  - interfaces
KW  - Oculus
KW  - oral surgery
KW  - simulation
ER  - 

TY  - CONF
TI  - Exploring mobile devices as haptic interfaces for mixed reality
AU  - Stellmacher, Carolin
AU  - Mathis, Florian
AU  - Weiss, Yannick
AU  - Loerakker, Meagan B.
AU  - Wagener, Nadine
AU  - Schöning, Johannes
T3  - Chi '24
AB  - Dedicated handheld controllers facilitate haptic experiences of virtual objects in mixed reality (MR). However, as mobile MR becomes more prevalent, we observe the emergence of controller-free MR interactions. To retain immersive haptic experiences, we explore the use of mobile devices as a substitute for specialised MR controller. In an exploratory gesture elicitation study (n = 18), we examined users’ (1) intuitive hand gestures performed with prospective mobile devices and (2) preferences for real-time haptic feedback when exploring haptic object properties. Our results reveal three haptic exploration modes for the mobile device, as an object, hand substitute, or as an additional tool, and emphasise the benefits of incorporating the device’s unique physical features into the object interaction. This work expands the design possibilities using mobile devices for tangible object interaction, guiding the future design of mobile devices for haptic MR experiences.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI conference on human factors in computing systems
DA  - 2024///
PY  - 2024
DO  - 10.1145/3613904.3642176
PB  - Association for Computing Machinery
SN  - 979-8-4007-0330-0
UR  - https://doi.org/10.1145/3613904.3642176
KW  - haptic feedback
KW  - mixed reality
KW  - haptic interfaces
KW  - gesture elicitation
KW  - haptic exploration
KW  - mobile gestures
KW  - mobile phones
ER  - 

TY  - CONF
TI  - CollabJam: Studying collaborative haptic experience design for on-body vibrotactile patterns
AU  - Wittchen, Dennis
AU  - Ramian, Alexander
AU  - Sabnis, Nihar
AU  - Böhme, Richard
AU  - Chlebowski, Christopher
AU  - Freitag, Georg
AU  - Fruchard, Bruno
AU  - Degraen, Donald
T3  - Chi '25
AB  - Designing vibrotactile experiences collaboratively requires communicating using multiple senses. This is challenging in remote scenarios as designers need to effectively express and communicate their intention while iteratively building and refining experiences, ideally in real-time. We formulate design considerations for collaborative haptic design tools, and propose CollabJam, a collaborative prototyping suite enabling remote synchronous design of vibrotactile experiences for on-body applications. We first outline CollabJam’s features and present a technical evaluation. Second, we use CollabJam to understand communication and design patterns used during haptic experience design. We performed an in-depth design evaluation spanning four sessions in which four pairs of participants designed and reviewed vibrotactile experiences remotely. A qualitative content analysis revealed how multi-sensory communication is essential to convey ideas, how stimulating the tactile sense can interfere with personal boundaries, and how freely placing actuators on the skin can provide both benefits and challenges.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713469
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713469
KW  - collaborative design
KW  - tacton
KW  - vibrotactile design
KW  - vibrotactile patterns
ER  - 

TY  - CONF
TI  - A haptic-enabled, distributed and networked immersive system for multi-user collaborative virtual reality
AU  - Van Damme, Sam
AU  - Van de Velde, Fangio
AU  - Sameri, Mohammad Javad
AU  - De Turck, Filip
AU  - Vega, Maria Torres
T3  - Ixr '23
AB  - Virtual Reality (VR) is gaining attention in various domains such as entertainment, industry, mental healthcare and VR training. Al- though most of these use-cases are still limited to single-user tasks, a lot of applications are heavily depending on multi-user collaboration. Existing multi-user VR systems are most often created in a classic server-client architecture, however, which induces unpredictable network behaviour which can affect the end-user's Quality-of-Experience (QoE) and performance. In addition, the interaction methods in these systems are often constrained to either traditional VR controllers or very use-case specific interaction methods, such that general purpose haptic gloves form a somewhat under-explored part of literature. Therefore, we (i) present a networked, distributed multi-user VR system with synchronization of environments over a low-bandwidth networked connection. In addition, we (ii) enhance the experience by adding haptic gloves to the system, which we compare to the traditional VR controllers in a subjective experiment. As a proof-of-concept, a use case is implemented in which two users have to prepare and bake a virtual pizza. The results show that high framerates (&gt; 90 Frames Per Second (FPS)) can be obtained while keeping network throughput to a minimum ( &lt; 1 Mbps). The accompanying user study shows that haptic gloves are preferred when immersiveness is the main emphasis of the virtual environment, while controllers are more suited when performance is in the center of attention. In objective terms, the applicability of haptic feedback is highly dependent on the task at hand.
C1  - Ottawa ON, Canada
C3  - Proceedings of the 2nd international workshop on interactive extended reality
DA  - 2023///
PY  - 2023
DO  - 10.1145/3607546.3616804
SP  - 11
EP  - 19
PB  - Association for Computing Machinery
SN  - 979-8-4007-0280-8
UR  - https://doi.org/10.1145/3607546.3616804
KW  - haptic feedback
KW  - collaborative vr
KW  - multi-user
KW  - quality-of-experience (qoe)
KW  - virtual reality (vr)
ER  - 

TY  - CONF
TI  - "Overlapping our worlds": Designing biometric-based haptic interactions to enhance synchrony in long-distance relationships
AU  - Yang, Mengshi
AU  - Hu, Ruochen
T3  - Chi ea '25
AB  - Although the absence of bodily contact in Long-Distance Relationships (LDRs) often results in emotional distress, the design of haptic interactions has the potential to address these challenges by fostering intimacy and emotional connection. We explore how long-distance couples perceive the role of bodily contact in their daily lives and their perspectives on using haptic technologies for remote communication. Through in-depth interviews with 12 individuals who have been in LDRs and a thematic analysis, we 1) identify empirical evidence of how remote haptic interactions can support intimate relationships, 2) propose a design framework and 3) present a design case, Onni, a haptic interface that illustrates the framework’s application. Our findings may inform future design and research on how haptic technologies can be used to enhance emotional well-being and connectedness in LDRs.
C1  - New York, NY, USA
C3  - Proceedings of the extended abstracts of the CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706599.3719945
PB  - Association for Computing Machinery
SN  - 979-8-4007-1395-8
UR  - https://doi.org/10.1145/3706599.3719945
KW  - Affective computing
KW  - Haptic interaction
KW  - Affective haptics
KW  - Biometric synchronization
KW  - Long-distance relationships
KW  - Physical telepresence
KW  - Social interactions
ER  - 

TY  - CONF
TI  - Your place and mine: Designing a shared VR experience for remotely located users
AU  - Sra, Misha
AU  - Mottelson, Aske
AU  - Maes, Pattie
T3  - Dis '18
AB  - Virtual reality can help realize mediated social experiences where distance disappears and we interact as richly with those around the world as we do with those in the same room. The design of social virtual experiences presents a challenge for remotely located users with room-scale setups like those afforded by recent commodity virtual reality devices. Since users inhabit different physical spaces that may not be the same size, a mapping to a shared virtual space is needed for creating experiences that allow everyone to use real walking for locomotion. We designed three mapping techniques that enable users from diverse room-scale setups to interact together in virtual reality. Results from our user study (N = 26) show that our mapping techniques positively influence the perceived degree of togetherness and copresence while the size of each user's tracked space influences individual presence.
C1  - Hong Kong, China
C3  - Proceedings of the 2018 designing interactive systems conference
DA  - 2018///
PY  - 2018
DO  - 10.1145/3196709.3196788
SP  - 85
EP  - 97
PB  - Association for Computing Machinery
SN  - 978-1-4503-5198-0
UR  - https://doi.org/10.1145/3196709.3196788
KW  - virtual reality
KW  - embodiment
KW  - remote collaboration
KW  - dancing
KW  - room-scale vr
KW  - social
ER  - 

TY  - CONF
TI  - HapticPuppet: a kinesthetic mid-air multidirectional force-feedback drone-based interface
AU  - Feick, Martin
AU  - Tang, Anthony
AU  - Krüger, Antonio
T3  - UIST '22 adjunct
AB  - Providing kinesthetic force-feedback for human-scale interactions is challenging due to the relatively large forces needed. Therefore, robotic actuators are predominantly used to deliver this kind of haptic feedback; however, they offer limited flexibility and spatial resolution. In this work, we introduce HapticPuppet, a drone-based force-feedback interface which can exert multidirectional forces onto the human body. This can be achieved by attaching strings to different parts of the human body such as fingers, hands or ankles, which can then be affixed to multiple coordinated drones - puppeteering the user. HapticPuppet opens up a wide range of potential applications in virtual, augmented and mixed reality, exercising, physiotherapy, remote collaboration as well as haptic guidance.
C1  - Bend, OR, USA
C3  - Adjunct proceedings of the 35th annual ACM symposium on user interface software and technology
DA  - 2022///
PY  - 2022
DO  - 10.1145/3526114.3558694
PB  - Association for Computing Machinery
SN  - 978-1-4503-9321-8
UR  - https://doi.org/10.1145/3526114.3558694
KW  - AR
KW  - VR
KW  - Haptics
KW  - Drones
KW  - Directional Kinesthetic Force-Feedback
ER  - 

TY  - CONF
TI  - Birds of a rhythm: The effects of haptic pattern similarity on people's social perceptions in virtual reality
AU  - Jang, Hyuckjin
AU  - Lee, Jeongmi
T3  - Chi '25
AB  - Virtual reality (VR) expands opportunities for social interaction, yet its heavy reliance on visual cues can limit social engagement and hinder immersive experiences in visually overwhelming situations. To explore alternative social cues beyond the visual domain, we verified the potential of haptic cues for social identification in VR by examining the effects of haptic pattern similarity on social perceptions. Unique haptic patterns were assigned to participants and virtual agents for identification, while the similarity of haptic patterns was manipulated (same, similar, distinct). The results demonstrated that participants maintained closer interpersonal distances and reported higher senses of belonging, social connection, and comfort toward agents as the similarity of patterns increased. Our findings validate the potential of haptic patterns in social identification and provide scientific evidence that homophily extends beyond the visual domain to the haptic domain. We also suggest a novel haptic-based methodology for conveying relationship information and enhancing social VR experiences.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3714264
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3714264
KW  - Virtual Reality
KW  - Haptic Pattern Similarity
KW  - Interpersonal Distance
KW  - Multidimensional Scaling
KW  - Social Perception
ER  - 

TY  - CONF
TI  - Visuo-haptic interaction
AU  - Wolf, Katrin
AU  - Kurzweg, Marco
AU  - Weiss, Yannick
AU  - Brewster, Stephen
AU  - Schmidt, Albrecht
T3  - Avi '22
AB  - While traditional interfaces in human-computer interaction mainly rely on vision and audio, haptics becomes more and more important. Haptics cannot only increase the user experience and make technology more immersive, it can also transmit information that is hard to interpret only through vision and audio, such as the softness of a surface or other material properties. In this workshop, we aim at discussing how we could interact with technology if haptics is strongly supported and which novel research areas could emerge.
C1  - Frascati, Rome, Italy
C3  - Proceedings of the 2022 international conference on advanced visual interfaces
DA  - 2022///
PY  - 2022
DO  - 10.1145/3531073.3535260
PB  - Association for Computing Machinery
SN  - 978-1-4503-9719-3
UR  - https://doi.org/10.1145/3531073.3535260
KW  - interaction
KW  - haptic feedback
KW  - visual feedback
KW  - interfaces
ER  - 

TY  - CONF
TI  - CheckMate: Exploring a tangible augmented reality interface for remote interaction
AU  - Günther, Sebastian
AU  - Müller, Florian
AU  - Schmitz, Martin
AU  - Riemann, Jan
AU  - Dezfuli, Niloofar
AU  - Funk, Markus
AU  - Schön, Dominik
AU  - Mühlhäuser, Max
T3  - Chi ea '18
AB  - The digitalized world comes with increasing Internet capabilities, allowing to connect persons over distance easier than ever before. Video conferencing and similar online applications create great benefits bringing people who physically cannot spend as much time as they want virtually together. However, such remote experiences can also tend to lose the feeling of traditional experiences. People lack direct visual presence and no haptic feedback is available. In this paper, we tackle this problem by introducing our system called CheckMate. We combine Augmented Reality and capacitive 3D printed objects that can be sensed on an interactive surface to enable remote interaction while providing the same tangible experience as in co-located scenarios. As a proof-of-concept, we implemented a sample application based on the traditional chess game.
C1  - Montreal QC, Canada
C3  - Extended abstracts of the 2018 CHI conference on human factors in computing systems
DA  - 2018///
PY  - 2018
DO  - 10.1145/3170427.3188647
SP  - 1
EP  - 6
PB  - Association for Computing Machinery
SN  - 978-1-4503-5621-3
UR  - https://doi.org/10.1145/3170427.3188647
KW  - augmented reality
KW  - mixed reality
KW  - tangibles
KW  - remote collaboration
KW  - 3d fabrication
KW  - chess
KW  - tabletops
ER  - 

TY  - CONF
TI  - Investigating size congruency between the visual perception of a VR object and the haptic perception of its physical world agent
AU  - Zheng, Wenqi
AU  - Xiong, Dawei
AU  - Li, Junwei
AU  - Jiang, Jiajun
AU  - Weng, Cekai
AU  - Zhou, Jinni
AU  - Fan, Mingming
T3  - Vinci '24
AB  - Sandplay is an effective psychotherapy for mental retreatment, and many people prefer to engage in sandplay in Virtual Reality (VR) due to its convenience. Haptic perception of physical objects and miniatures enhances the realism and immersion in VR. Previous studies have rendered sizes by exerting pressure on the user’s fingertips or employing tangible, shape-changing devices. However, these interfaces are limited by the physical shapes they can assume, making it difficult to simulate objects that grow larger or smaller than the interface. Motivated by literature on visual-haptic illusions, this work aims to convey the haptic sensation of a virtual object’s shape to the user by exploring the relationships between the haptic feedback from real objects and their visual renderings in VR. Our study focuses on the confirmation and adjustment ratios for different virtual object sizes. The results show that the likelihood of participants confirming the correct size of virtual cubes decreases as the object size increases, requiring more adjustments for larger objects. This research provides valuable insights into the relationships between haptic sensations and visual inputs, contributing to the understanding of visual-haptic illusions in VR environments.
C1  - New York, NY, USA
C3  - Proceedings of the 17th international symposium on visual information communication and interaction
DA  - 2024///
PY  - 2024
DO  - 10.1145/3678698.3678706
PB  - Association for Computing Machinery
SN  - 979-8-4007-0967-8
UR  - https://doi.org/10.1145/3678698.3678706
KW  - cross-modal integration
KW  - perceptual illusion
KW  - visual-haptic illusion
ER  - 

TY  - JOUR
TI  - ANISMA: a prototyping toolkit to explore haptic skin deformation applications using shape-memory alloys
AU  - Messerschmidt, Moritz Alexander
AU  - Muthukumarana, Sachith
AU  - Hamdan, Nur Al-Huda
AU  - Wagner, Adrian
AU  - Zhang, Haimo
AU  - Borchers, Jan
AU  - Nanayakkara, Suranga Chandima
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - We present ANISMA, a software and hardware toolkit to prototype on-skin haptic devices that generate skin deformation stimuli like pressure, stretch, and motion using shape-memory alloys (SMAs). Our toolkit embeds expert knowledge that makes SMA spring actuators more accessible to human–computer interaction (HCI) researchers. Using our software tool, users can design different actuator layouts, program their spatio-temporal actuation and preview the resulting deformation behavior to verify a design at an early stage. Our toolkit allows exporting the actuator layout and 3D printing it directly on skin adhesive. To test different actuation sequences on the skin, a user can connect the SMA actuators to our customized driver board and reprogram them using our visual programming interface. We report a technical analysis, verify the perceptibility of essential ANISMA skin deformation devices with 8 participants, and evaluate ANISMA regarding its usability and supported creativity with 12 HCI researchers in a creative design task.
DA  - 2022/01//
PY  - 2022
DO  - 10.1145/3490497
VL  - 29
IS  - 3
SN  - 1073-0516
UR  - https://doi.org/10.1145/3490497
KW  - design
KW  - tactile
KW  - Haptic
KW  - prototyping
KW  - toolkit
KW  - authoring
KW  - deformation
KW  - fabrication
KW  - hardware
KW  - programming
KW  - shape-memory alloy
KW  - skin
KW  - SMA
KW  - software
ER  - 

TY  - CONF
TI  - CoSense: Creating shared emotional experiences
AU  - Ayyagari, Sudhanshu S.D.P.
AU  - Gupta, Kunal
AU  - Tait, Matt
AU  - Billinghurst, Mark
T3  - Chi ea '15
AB  - In this paper we describe a prototype wearable interface that shares a user's first person view and their current emotional state with a remote user in order to create a shared emotional experience. A user evaluation was conducted to explore which interface cues best helped a remote user understand what the local user was feeling. The results showed simple visual cues provided a significantly enhanced experience over no cues at all, or a more detailed data representation.
C1  - Seoul, Republic of Korea
C3  - Proceedings of the 33rd annual ACM conference extended abstracts on human factors in computing systems
DA  - 2015///
PY  - 2015
DO  - 10.1145/2702613.2732839
SP  - 2007
EP  - 2012
PB  - Association for Computing Machinery
SN  - 978-1-4503-3146-3
UR  - https://doi.org/10.1145/2702613.2732839
KW  - wearables
KW  - remote collaboration
KW  - emotional interfaces
ER  - 

TY  - CONF
TI  - Effects of haptic feedback on user perception and performance in interactive projected augmented reality
AU  - Van Damme, Sam
AU  - Legrand, Nicolas
AU  - Heyse, Joris
AU  - De Backere, Femke
AU  - De Turck, Filip
AU  - Vega, Maria Torres
T3  - Ixr '22
AB  - By means of vibrotactile and force feedback, i.e., haptics, users are given the sensation of touching and manipulating virtual objects in interactive Extended Reality (XR) environments. However, research towards the influence of this feedback on the users' perception and performance in interactive XR is currently still scarce. In this work, we present an experimental evaluation of the effects of haptic feedback in interactive immersive applications. By means of a Projected Augmented Reality (PAR) setup, users were asked to interact with a projected environment by completing three different tasks based on finger-tracking and in the presence of visual latency. Evaluations were performed both subjectively (questionnaire) and objectively (i.e. duration and accuracy). We found out that while haptic feedback does not enhance the performance for simple tasks, it substantially improves it for more complex ones. This effect is more evident in presence of network degradation, such as latency. However, the subjective questionnaires showed a general skepticism about the potential of incorporating haptic information into immersive applications. As such, we believe that this paper provides an important contribution toward the understanding and assessment of the influence of haptic technology in interactive immersive systems.
C1  - Lisboa, Portugal
C3  - Proceedings of the 1st workshop on interactive extended reality
DA  - 2022///
PY  - 2022
DO  - 10.1145/3552483.3556456
SP  - 11
EP  - 18
PB  - Association for Computing Machinery
SN  - 978-1-4503-9501-4
UR  - https://doi.org/10.1145/3552483.3556456
KW  - haptic feedback
KW  - interactive extended reality
KW  - projected augmented reality
KW  - user perception
KW  - user performance
KW  - visual latency
ER  - 

TY  - CONF
TI  - A classification of human-to-human communication during the use of immersive teleoperation interfaces
AU  - Kraus, Martin
AU  - Kibsgaard, Martin
T3  - Vric '15
AB  - We propose a new classification of the human-to-human communication during the use of immersive teleoperation interfaces based on real-life examples. While a large body of research is concerned with communication in collaborative virtual environments (CVEs), less research focuses on cases where only one of two communicating users is immersed in a virtual or remote environment. Furthermore, we identify the unmediated communication between co-located users of an immersive teleoperation interface as another conceptually important – but usually neglected – case. To cover these scenarios, one of the dimensions of the proposed classification is the level of copresence of the communicating users. Further dimensions are the virtuality of the immersive environment, the virtual transport of the immersed user(s), the communication channel, and the mediation of the communication. We find that an extension of the proposed classification to real environments can offer useful reference cases. Using this extended classification not only allows us to discuss and understand differences and similarities of various forms of communication in a more systematic way, but it also provides guidelines and reference cases for the design of immersive teleoperation interfaces that support human-to-human communication.
C1  - Laval, France
C3  - Proceedings of the 2015 virtual reality international conference
DA  - 2015///
PY  - 2015
DO  - 10.1145/2806173.2806198
PB  - Association for Computing Machinery
SN  - 978-1-4503-3313-9
UR  - https://doi.org/10.1145/2806173.2806198
KW  - virtual reality
KW  - presence
KW  - immersion
KW  - augmented reality
KW  - Telepresence
KW  - computer-mediated communication
KW  - teleoperation
KW  - collaboration
KW  - collaborative virtual environment
KW  - human-to-human communication
KW  - shared virtual space
ER  - 

TY  - JOUR
TI  - ShiSha: Enabling shared perspective with face-to-face collaboration using redirected avatars in virtual reality
AU  - Hoppe, Adrian H.
AU  - van de Camp, Florian
AU  - Stiefelhagen, Rainer
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - The importance of remote collaboration grows in an interconnected world as the reasons to avoid travel increase. The spatial rendering and collaboration capabilities of virtual and augmented reality systems are well suited for tasks such as support or training. Users can take a shared perspective to build a common understanding. Also, users may engage in face-to-face cooperation to support interpersonal communication. However, a shared perspective and face-to-face collaboration are both desirable but naturally exclude each other. We place all users at the same location to provide a shared perspective. To avoid overlapping body parts, the avatars of the other connected users are shifted to the side. A redirected body pose modification corrects the resulting inconsistencies. The implemented system is compared to a baseline of two users standing in the same location and working with overlapping avatars. The results of a user study show that the proposed modifications provide an easy to use, efficient collaboration and yield higher co-presence and the feeling of teamwork. Applying redirection techniques to other users opens up novel ways to increase social presence for local or remote collaboration.
DA  - 2021/01//
PY  - 2021
DO  - 10.1145/3432950
VL  - 4
IS  - CSCW3
UR  - https://doi.org/10.1145/3432950
KW  - virtual reality
KW  - social presence
KW  - avatar modification
KW  - redirected interaction
KW  - shared perspective
KW  - social redirection
ER  - 

TY  - CONF
TI  - Demonstrating HapticBots: Distributed encountered-type haptics for VR with multiple shape-changing mobile robots
AU  - Suzuki, Ryo
AU  - Ofek, Eyal
AU  - Sinclair, Mike
AU  - Leithinger, Daniel
AU  - Gonzalez-Franco, Mar
T3  - UIST '21 adjunct
AB  - HapticBots introduces a novel encountered-type haptic approach for Virtual Reality (VR) based on multiple tabletop-size shape-changing robots. These robots move on a tabletop and change their height and orientation to haptically render various surfaces and objects on-demand. Compared to previous encountered-type haptic approaches like shape displays or robotic arms, our proposed approach has an advantage in deployability, scalability, and generalizability—these robots can be easily deployed due to their compact form factor. They can support multiple concurrent touch points in a large area thanks to the distributed nature of the robots. We propose and evaluate a novel set of interactions enabled by these robots which include: 1) rendering haptics for VR objects by providing just-in-time touch-points on the user’s hand, 2) simulating continuous surfaces with the concurrent height and position change, and 3) enabling the user to pick up and move VR objects through graspable proxy objects. Finally, we demonstrate HapticBots with various applications, including remote collaboration, education and training, design and 3D modeling, and gaming and entertainment.
C1  - Virtual Event, USA
C3  - Adjunct proceedings of the 34th annual ACM symposium on user interface software and technology
DA  - 2021///
PY  - 2021
DO  - 10.1145/3474349.3480202
SP  - 131
EP  - 133
PB  - Association for Computing Machinery
SN  - 978-1-4503-8655-5
UR  - https://doi.org/10.1145/3474349.3480202
KW  - virtual reality
KW  - encountered-type haptics
KW  - swarm user interfaces
KW  - tabletop mobile robots
ER  - 

TY  - CONF
TI  - Keep in touch: Portable haptic display with 192 high speed taxels
AU  - Zarate, Juan Jose
AU  - Gudozhnik, Olexandr
AU  - Ruch, Anthony Sébastien
AU  - Shea, Herbert
T3  - Chi ea '17
AB  - We present a portable 12x16 taxel haptic display optimized to rapidly display dynamic graphical information. Each taxel changes state (up/down) in under 5 milliseconds, allowing the entire display of 192 independent taxels to be refreshed in under 2 seconds. The user uses his sense of fine touch to explore the 7-inch display. We demonstrate applications in serious gaming (tactile Pong for the visually impaired), remote collaboration between sighted and visually-impaired users (remote user draws in real-time on the local haptic display), and navigation scenarios. Information can be displayed as a series of static relief images, or as a static image with moving or vibrating taxels. For the navigation task, the outline of a room and furniture is shown first as a static relief, the path to be followed is added as a moving taxels, and the user location is shown as a vibrating taxel. The taxels latch in both up and down states, leading to low power consumption.
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI conference extended abstracts on human factors in computing systems
DA  - 2017///
PY  - 2017
DO  - 10.1145/3027063.3052957
SP  - 349
EP  - 352
PB  - Association for Computing Machinery
SN  - 978-1-4503-4656-6
UR  - https://doi.org/10.1145/3027063.3052957
KW  - electromagnetic actuators
KW  - haptic display
KW  - serious gaming
KW  - taxel array
ER  - 

TY  - CONF
TI  - Influence of annotation media on proof-reading tasks
AU  - Schmid, Andreas
AU  - Sautmann, Marie
AU  - Wittmann, Vera
AU  - Kaindl, Florian
AU  - Schauhuber, Philipp
AU  - Gottschalk, Philipp
AU  - Wimmer, Raphael
T3  - MuC '23
AB  - Annotating and proof-reading documents are common tasks. Digital annotation tools provide easily searchable annotations and facilitate sharing documents and remote collaboration with others. On the other hand, advantages of paper, such as creative freedom and intuitive use, can get lost when annotating digitally. There is a large amount of research indicating that paper outperforms digital annotation tools in task time, error recall and task load. However, most research in this field is rather old and does not take into consideration increasing screen resolution and performance, as well as better input techniques in modern devices. We present three user studies comparing different annotation media in the context of proof-reading tasks. We found that annotating on paper is still faster and less stressful than with a PC or tablet computer, but the difference is significantly smaller with a state-of-the-art device. We did not find a difference in error recall, but the used medium has a strong influence on how users annotate.
C1  - Rapperswil, Switzerland
C3  - Proceedings of mensch und computer 2023
DA  - 2023///
PY  - 2023
DO  - 10.1145/3603555.3603572
SP  - 277
EP  - 288
PB  - Association for Computing Machinery
SN  - 979-8-4007-0771-1
UR  - https://doi.org/10.1145/3603555.3603572
KW  - annotaion
KW  - digitalization
KW  - proof-reading
ER  - 

TY  - CONF
TI  - HapticBots: Distributed encountered-type haptics for VR with multiple shape-changing mobile robots
AU  - Suzuki, Ryo
AU  - Ofek, Eyal
AU  - Sinclair, Mike
AU  - Leithinger, Daniel
AU  - Gonzalez-Franco, Mar
T3  - Uist '21
AB  - HapticBots introduces a novel encountered-type haptic approach for Virtual Reality (VR) based on multiple tabletop-size shape-changing robots. These robots move on a tabletop and change their height and orientation to haptically render various surfaces and objects on-demand. Compared to previous encountered-type haptic approaches like shape displays or robotic arms, our proposed approach has an advantage in deployability, scalability, and generalizability—these robots can be easily deployed due to their compact form factor. They can support multiple concurrent touch points in a large area thanks to the distributed nature of the robots. We propose and evaluate a novel set of interactions enabled by these robots which include: 1) rendering haptics for VR objects by providing just-in-time touch-points on the user’s hand, 2) simulating continuous surfaces with the concurrent height and position change, and 3) enabling the user to pick up and move VR objects through graspable proxy objects. Finally, we demonstrate HapticBots with various applications, including remote collaboration, education and training, design and 3D modeling, and gaming and entertainment.
C1  - Virtual Event, USA
C3  - The 34th annual ACM symposium on user interface software and technology
DA  - 2021///
PY  - 2021
DO  - 10.1145/3472749.3474821
SP  - 1269
EP  - 1281
PB  - Association for Computing Machinery
SN  - 978-1-4503-8635-7
UR  - https://doi.org/10.1145/3472749.3474821
KW  - virtual reality
KW  - encountered-type haptics
KW  - swarm user interfaces
KW  - tabletop mobile robots
ER  - 

TY  - JOUR
TI  - INC-hg: An intelligent collaborative haptic-gripper virtual reality system
AU  - Zhao, Huan
AU  - Zaini Amat, Ashwaq
AU  - Migovich, Miroslava
AU  - Swanson, Amy
AU  - Weitlauf, Amy S.
AU  - Warren, Zachary
AU  - Sarkar, Nilanjan
T2  - ACM Trans. Access. Comput.
AB  - Collaborative Virtual Environments (CVE) have shown potential to be an effective social skill training platform for children with Autism Spectrum Disorders (ASD) to learn and practice collaborative and communication skills through peer interactions. However, most existing CVE systems require that appropriately matched partners be available at the same time to promote interaction, which limits their applicability to some community settings due to scheduling constraints. A second shortcoming of these more naturalistic peer-based designs is the intensive resources required to manually code the unrestricted conversations that occurred during the peer-based interactions. To preserve the benefits of CVE-based platforms and mitigate some of the resource limitations related to peer availability, we developed an Intelligent Collaborative Haptic-Gripper System (INC-Hg). This system provides an intelligent agent partner who can understand, communicate, and haptically interact with the user, without requiring the presence of another human peer. The INC-Hg operates in real time and thus is able to perform collaborative training tasks at any time and at the user's pace. INC-Hg can also record the real-time data regarding spoken language and task performance, thereby greatly reducing the resource burden of communication and interaction performance analysis. A preliminary usability study with 10 participants with ASD (ages 8–12 years) indicated that the system could classify the participant's utterances into five classes with an accuracy of 70.34
DA  - 2022/03//
PY  - 2022
DO  - 10.1145/3487606
VL  - 15
IS  - 1
SN  - 1936-7228
UR  - https://doi.org/10.1145/3487606
KW  - social interaction
KW  - AI techniques
KW  - Autism Spectrum Disorders
KW  - collaborative virtual environments
KW  - conversational agent
KW  - haptic interaction
ER  - 

TY  - CONF
TI  - TwinSpace: an infrastructure for cross-reality team spaces
AU  - Reilly, Derek F.
AU  - Rouzati, Hafez
AU  - Wu, Andy
AU  - Hwang, Jee Yeon
AU  - Brudvik, Jeremy
AU  - Edwards, W. Keith
T3  - Uist '10
AB  - We introduce TwinSpace, a flexible software infrastructure for combining interactive workspaces and collaborative virtual worlds. Its design is grounded in the need to support deep connectivity and flexible mappings between virtual and real spaces to effectively support collaboration. This is achieved through a robust connectivity layer linking heterogeneous collections of physical and virtual devices and services, and a centralized service to manage and control mappings between physical and virtual. In this paper we motivate and present the architecture of TwinSpace, discuss our experiences and lessons learned in building a generic framework for collaborative cross-reality, and illustrate the architecture using two implemented examples that highlight its flexibility and range, and its support for rapid prototyping.
C1  - New York, New York, USA
C3  - Proceedings of the 23nd annual ACM symposium on user interface software and technology
DA  - 2010///
PY  - 2010
DO  - 10.1145/1866029.1866050
SP  - 119
EP  - 128
PB  - Association for Computing Machinery
SN  - 978-1-4503-0271-5
UR  - https://doi.org/10.1145/1866029.1866050
KW  - collaborative virtual environment
KW  - cross-reality
KW  - interactive room
KW  - ontology
KW  - rdf
KW  - smart room
KW  - tuplespace
KW  - virtual world
ER  - 

TY  - CONF
TI  - Bridging physical and electronic media for distributed design collaboration
AU  - Klemmer, Scott
AU  - Everitt, Katherine
T3  - Chi ea '02
AB  - Research on distributed collaboration has predominantly focused on shared electronic media. We have found, as other researchers have, that users often have good reason to want to work with physical media. Yet they would still like to collaborate with each other. A fundamental tension exists in the design of systems to support remote collaboration when the interaction primitives are physical: physical objects live in one place. We have designed and implemented a remote collaboration system where users can still use physical objects. We introduce an interaction paradigm where objects that are physical in one space are electronic in the other space, and vice versa. Our distributed system is designed for two groups, with multiple users at each end. Our tangible approach is the first system to enable simultaneous, multi-input across locations. We have implemented this system as an extension to the Designers' Outpost[5].
C1  - Minneapolis, Minnesota, USA
C3  - CHI '02 extended abstracts on human factors in computing systems
DA  - 2002///
PY  - 2002
DO  - 10.1145/506443.506644
SP  - 878
EP  - 879
PB  - Association for Computing Machinery
SN  - 1-58113-454-1
UR  - https://doi.org/10.1145/506443.506644
KW  - CSCW
KW  - remote collaboration
KW  - shared workspace
KW  - tangible
ER  - 

TY  - CONF
TI  - VoxelHap: a toolkit for constructing proxies providing tactile and kinesthetic haptic feedback in virtual reality
AU  - Feick, Martin
AU  - Biyikli, Cihan
AU  - Gani, Kiran
AU  - Wittig, Anton
AU  - Tang, Anthony
AU  - Krüger, Antonio
T3  - Uist '23
AB  - Experiencing virtual environments is often limited to abstract interactions with objects. Physical proxies allow users to feel virtual objects, but are often inaccessible. We present the VoxelHap toolkit which enables users to construct highly functional proxy objects using Voxels and Plates. Voxels are blocks with special functionalities that form the core of each physical proxy. Plates increase a proxy’s haptic resolution, such as its shape, texture or weight. Beyond providing physical capabilities to realize haptic sensations, VoxelHap utilizes VR illusion techniques to expand its haptic resolution. We evaluated the capabilities of the VoxelHap toolkit through the construction of a range of fully functional proxies across a variety of use cases and applications. In two experiments with 24 participants, we investigate a subset of the constructed proxies, studying how they compare to a traditional VR controller. First, we investigated VoxelHap’s combined haptic feedback and second, the trade-offs of using ShapePlates. Our findings show that VoxelHap’s proxies outperform traditional controllers and were favored by participants.
C1  - San Francisco, CA, USA
C3  - Proceedings of the 36th annual ACM symposium on user interface software and technology
DA  - 2023///
PY  - 2023
DO  - 10.1145/3586183.3606722
PB  - Association for Computing Machinery
SN  - 979-8-4007-0132-0
UR  - https://doi.org/10.1145/3586183.3606722
KW  - Virtual Reality
KW  - haptics
KW  - tactile
KW  - toolkit
KW  - kinesthetic
KW  - reconfigurable
ER  - 

TY  - CONF
TI  - SoundCells: designing a browser-based music technology for braille and print notation
AU  - Payne, William
AU  - Ahmed, Fabiha
AU  - Gardell, Michael
AU  - DuBois, R. Luke
AU  - Hurst, Amy
T3  - W4a '22
AB  - Technologies for notating music pose usage barriers to blind and visually impaired musicians requiring many to overcome a significant learning curve and/or rely on complicated tool chains with limited screen reader support. To address a need for accessible music notation software, we present SoundCells, a browser-based system designed to make music notation easy, intuitive, and accessible to screen reader users, and output music in audio, print, and braille formats. We share findings from a co-design process, in which two experienced musicians used SoundCells for two months guided by four remote meetings, and from a Design Probe, in which five other musicians tried SoundCells with a screen reader and reflected on its usability and accessibility in the context of their current practices. Finally, we discuss design recommendations relevant to a broader ecosystem of creative technologies, including how text-editing and multi-modal output capabilities could be extended and improved, how SoundCells' current design facilitated remote collaboration between sighted researchers and blind musicians, and future opportunities for learning and sharing music on the web.
C1  - Lyon, France
C3  - Proceedings of the 19th international web for all conference
DA  - 2022///
PY  - 2022
DO  - 10.1145/3493612.3520462
PB  - Association for Computing Machinery
SN  - 978-1-4503-9170-2
UR  - https://doi.org/10.1145/3493612.3520462
KW  - accessibility
KW  - braille
KW  - co-design
KW  - music notation
KW  - music technology
KW  - visual impairments
ER  - 

TY  - CONF
TI  - "I think i can see it now!": evidence of learning in video transcripts of a collaborative virtual reality surgical training trial
AU  - Hutchins, Matthew
AU  - Stevenson, Duncan
AU  - Gunn, Chris
AU  - Krumpholz, Alexander
AU  - Pyman, Brian
AU  - O'Leary, Stephen
T3  - Ozchi '05
AB  - Networked collaborative virtual reality systems have been proposed for surgical education. They allow an instructor to teach a student using a shared virtual model, even if separated by distance. For these systems to be accepted within the surgical community there must be a compelling body of evidence that demonstrates that learning occurs in the training environment, and is transferable to the operating theatre. We have developed a networked multisensory virtual reality system for teaching surgery of the temporal bone and conducted a training transfer trial. To augment the quantitative analysis of the results, we have performed a qualitative analysis of the transcripts of videotapes of the learning phase of the trial, using techniques from Conversation Analysis. In this short paper we present a single case study that convincingly demonstrates that learning occurred within the instruction phase of the trial.
C1  - Canberra, Australia
C3  - Proceedings of the 17th australia conference on computer-human interaction: Citizens online: Considerations for today and the future
DA  - 2005///
PY  - 2005
SP  - 1
EP  - 4
PB  - Computer-Human Interaction Special Interest Group (CHISIG) of Australia
SN  - 1-59593-222-4
KW  - collaborative virtual environment
KW  - conversation analysis
KW  - evaluation
KW  - surgical simulation
ER  - 

TY  - CONF
TI  - Feel it: Using proprioceptive and haptic feedback for interaction with virtual embodiment
AU  - Teo, Theophilus
AU  - Nakamura, Fumihiko
AU  - Sugimoto, Maki
AU  - Verhulst, Adrien
AU  - A. Lee, Gun
AU  - Billinghurst, Mark
AU  - Adcock, Matt
T3  - Siggraph '20
AB  - Virtual embodiment has become popular for enhancing virtual interaction in terms of sharing object information. A user can control a character or object in a virtual environment to provide immersive interactive experience. However, one of the limitations for the virtual interactions was the incapability to receive feedback apart from visual hints. In this demonstration, we present using servo motor and Galvanic Vestibular Stimulation to provide feedback from a virtual interaction. Our technique transforms information of the virtual objects (e.g.: weight) into haptic and proprioceptive feedback that stimulates different sensations to a user. We present the user experience to the attendees of SIGGRAPH 2020 through a live demonstration in a virtual environment controlled using a virtual robotic arm.
C1  - Virtual Event, USA
C3  - ACM SIGGRAPH 2020 emerging technologies
DA  - 2020///
PY  - 2020
DO  - 10.1145/3388534.3407288
PB  - Association for Computing Machinery
SN  - 978-1-4503-7967-0
UR  - https://doi.org/10.1145/3388534.3407288
KW  - Haptic Feedback
KW  - Human Augmentation
KW  - Proprioceptive feedback
ER  - 

TY  - CONF
TI  - Hands or controllers? How input devices and audio impact collaborative virtual reality
AU  - Adkins, Alex
AU  - Canales, Ryan
AU  - Jörg, Sophie
T3  - Vrst '24
AB  - Advancing virtual reality technologies are enabling real-time virtual-face to virtual-face communication. Hand tracking systems that are integrated into Head-Mounted Displays (HMD) enable users to directly interact with their environments and with each other using their hands as opposed to using controllers. Due to the novelties of these technologies our understanding of how they impact our interactions is limited. In this paper, we investigate the consequences of using different interaction control systems, hand tracking or controllers, when interacting with others in a virtual environment. We design and implement NASA’s Survival on the Moon teamwork evaluation exercise in virtual reality (VR) and test for effects with and without allowing verbal communication. We evaluate social presence, perceived comprehension, team cohesion, group synergy, task workload, as well as task performance and duration. Our findings reveal that audio communication significantly enhances social presence, perceived comprehension, and team cohesion, but it also increases effort workload and negatively impacts group synergy. The choice of interaction control systems has limited impact on various aspects of virtual collaboration in this scenario, although participants using hand tracking reported lower effort workload, while participants using controllers reported lower mental workload in the absence of audio.
C1  - Trier, Germany
C3  - Proceedings of the 30th ACM symposium on virtual reality software and technology
DA  - 2024///
PY  - 2024
DO  - 10.1145/3641825.3687718
PB  - Association for Computing Machinery
SN  - 979-8-4007-0535-9
UR  - https://doi.org/10.1145/3641825.3687718
KW  - avatars
KW  - gestures
KW  - collaboration
KW  - Communication
ER  - 

TY  - CONF
TI  - Virtual collaborative environments with distributed multitouch support
AU  - Ardaiz, Oscar
AU  - Arroyo, Ernesto
AU  - Righi, Valeria
AU  - Galimany, Oriol
AU  - Blat, Josep
T3  - Eics '10
AB  - In this paper, we present a new application framework aimed to support distributed synchronous collaboration using multitouch interaction. The framework supports 2D and 3D virtual workspaces that enable two or more users to collaboratively or cooperatively manipulate shared objects with multitouch interfaces. We present two applications developed with the aim to explore 2D/3D immersive collaborative environments with multitouch interaction. We also present our experience and preliminary results in designing, developing and integrating these applications on educational settings.
C1  - Berlin, Germany
C3  - Proceedings of the 2nd ACM SIGCHI symposium on engineering interactive computing systems
DA  - 2010///
PY  - 2010
DO  - 10.1145/1822018.1822055
SP  - 235
EP  - 240
PB  - Association for Computing Machinery
SN  - 978-1-4503-0083-4
UR  - https://doi.org/10.1145/1822018.1822055
KW  - remote collaboration
KW  - distributed virtual environment
KW  - multitouch interaction
ER  - 

TY  - CONF
TI  - An integrated multi-modal actuated tangible user interface for distributed collaborative planning
AU  - Riedenklau, Eckard
AU  - Hermann, Thomas
AU  - Ritter, Helge
T3  - Tei '12
AB  - In this paper we showcase an integrative approach for our actuated Tangible Active Objects (TAOs), that demonstrates distributed collaboration support to become a versatile and comprehensive dynamic user interface with multi-modal feedback. We incorporated physical actuation, visual projection in 2D and 3D, and vibro-tactile feedback. We demonstrate this approach in a furniture placing scenario where the users can interactively change the furniture model represented by each TAO using a dial-based tangible actuated menu. We demonstrate virtual constraints between our TAOs to automatically maintain spatial relations.
C1  - Kingston, Ontario, Canada
C3  - Proceedings of the sixth international conference on tangible, embedded and embodied interaction
DA  - 2012///
PY  - 2012
DO  - 10.1145/2148131.2148167
SP  - 169
EP  - 174
PB  - Association for Computing Machinery
SN  - 978-1-4503-1174-8
UR  - https://doi.org/10.1145/2148131.2148167
KW  - remote collaboration
KW  - actuated tangible objects
KW  - mixed-reality
KW  - multimodal feedback
KW  - tangible interaction
KW  - virtual constraints
ER  - 

TY  - JOUR
TI  - An empirical method for causal inference of constructs for QoE in haptic–audiovisual communications
AU  - Tasaka, Shuji
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
AB  - This article proposes an empirical method for inferring causal directions in multidimensional Quality of Experience (QoE) in multimedia communications, noting that causation in QoE is perceptual. As an example for modeling framework, we pick up a Bayesian structural equation model (SEM) previously built for haptic audiovisual interactive communications. The SEM includes three constructs (Audiovisual quality, Haptic quality, and User experience quality), which are latent variables each representing a group of observed variables with similar characteristics. In the SEM, the causal directions of the constructs were assumed by resorting to the domain knowledge. This article aims at proposing a methodology for inferring causal directions of constructs in general by verifying the assumption of causal directions in the SEM through their observed data alone. For that purpose, we compare six SEMs each with different causal directions of constructs, one of which is the one from the domain knowledge. The proposed method is based on QoE prediction by a Bayesian approach with Markov chain Monte Carlo (MCMC) simulation. Setting observed scores to the indicators of exogenous variables in each SEM, we predict values of all the indicators; we then assess the mean square error (MSE) between predicted QoE and mean opinion score (MOS) from observed scores and estimate the probability distribution of the MSE in each SEM. We can compare any two SEMs to find which is more plausible by examining the probability that the MSE for one SEM is smaller than or equal to that for the other. These probabilities are estimated with MCMC simulation. The method indicates that the causal directions thus inferred for the haptic audiovisual interactive communications adequately support the original ones drawn from the domain knowledge. In addition, we demonstrate that QoE can behave like the “impact-perceive-adapt” model of the effects of delayed haptic and visual feedback on performance in a collaborative environment, which Jay, Glencross, and Hubbold proposed in 2007, and that it accompanies reversal of plausible causal directions like a flip–flop.
DA  - 2022/01//
PY  - 2022
DO  - 10.1145/3473986
VL  - 18
IS  - 1
SN  - 1551-6857
UR  - https://doi.org/10.1145/3473986
KW  - Quality of Experience (QoE)
KW  - Bayesian modeling
KW  - Causal inference
KW  - causation
KW  - construct
KW  - haptic–audiovisual interactive communications
KW  - latent variables
KW  - MCMC
KW  - media synchronization
KW  - OpenBUGS
KW  - SEM
ER  - 

TY  - CONF
TI  - Applications of networked virtual reality for tele-operation and tele-assistance systems in the mining industry
AU  - Bednarz, Tomasz
AU  - James, Craig
AU  - Caris, Con
AU  - Haustein, Kerstin
AU  - Adcock, Matt
AU  - Gunn, Chris
T3  - Vrcai '11
AB  - The mining industry is interested in tele-operation systems to remove mining operators from hazardous or inconvenient environments without losing efficiency. Technologies to enhance the operator's experience are advancing but there is a lack of evidence supporting the extent to which these emerging technologies positively affect user experience. In this paper, we describe three applications that make use of networked virtual and mixed reality. These prototype systems each represent a step towards new VR based technologies that will increase the efficiency and safety of the mining industry.
C1  - Hong Kong, China
C3  - Proceedings of the 10th international conference on virtual reality continuum and its applications in industry
DA  - 2011///
PY  - 2011
DO  - 10.1145/2087756.2087845
SP  - 459
EP  - 462
PB  - Association for Computing Machinery
SN  - 978-1-4503-1060-4
UR  - https://doi.org/10.1145/2087756.2087845
KW  - virtual reality
KW  - presence
KW  - remote collaboration
KW  - measures
KW  - remote control
KW  - tele-operation
ER  - 

TY  - CONF
TI  - Teachyverse: Collaborative e-learning in virtual reality lecture halls
AU  - Marky, Karola
AU  - Müller, Florian
AU  - Funk, Markus
AU  - Geiß, Alexander
AU  - Günther, Sebastian
AU  - Schmitz, Martin
AU  - Riemann, Jan
AU  - Mühlhäuser, Max
T3  - MuC '19
AB  - Over the last decades, E-learning has gained a lot of popularity and enabled students to learn in front of their computers using Internet-based learning systems rather than physically attending lectures. Those E-learning systems are different from traditional learning and do not fully immerse the student in the learning environment. Thus, we propose Teachyverse, an immersive VR lecture hall that combines e-learning, traditional learning, and remote collaboration. Teachyverse immerses the student in a virtual lecture hall. A proof-of-concept study shows that students perceive lectures in Teachyverse as fun and would like to use Teachyverse as a further E-Learning option.
C1  - Hamburg, Germany
C3  - Proceedings of mensch und computer 2019
DA  - 2019///
PY  - 2019
DO  - 10.1145/3340764.3344917
SP  - 831
EP  - 834
PB  - Association for Computing Machinery
SN  - 978-1-4503-7198-8
UR  - https://doi.org/10.1145/3340764.3344917
KW  - Virtual Reality
KW  - E-Learning
KW  - Lecture halls
KW  - Virtual Lecture
ER  - 

TY  - CONF
TI  - Trans-world haptic collaboration
AU  - Gunn, Chris
AU  - Hutchins, Matthew
AU  - Adcock, Matt
AU  - Hawkins, Rhys
T3  - Siggraph '03
AB  - This sketch describes a collaborative virtual environment application involving haptic interaction over long Internet distances. We have developed algorithms to accommodate significant latency for certain applications, notably in the medical domain. The results have shown that we can manipulate simulated human body organs, as well as guide each other's 'hands' (and shake hands!) over 22,000 km.
C1  - San Diego, California
C3  - ACM SIGGRAPH 2003 sketches &amp; applications
DA  - 2003///
PY  - 2003
DO  - 10.1145/965400.965495
SP  - 1
PB  - Association for Computing Machinery
SN  - 978-1-4503-7466-8
UR  - https://doi.org/10.1145/965400.965495
ER  - 

TY  - CONF
TI  - Persuading people in a remote destination to sing by beaming there
AU  - Bourdin, Pierre
AU  - Sanahuja, Josep Maria Tomàs
AU  - Moya, Carlota Crusafon
AU  - Haggard, Patrick
AU  - Slater, Mel
T3  - Vrst '13
AB  - We built a Collaborative Virtual Environment (CVE) allowing one person, the 'visitor' to be digitally transported to a remote destination to interact with local people there. This included full body tracking, vibrotactile feedback and voice. This allowed interactions in the same CVE between multiple people situated in different physical remote locations. This system was used for an experiment to study whether the conveyance of touch has an impact on the willingness of participants embodied in the CVE to sing in public.In a first experimental condition, the experimenter virtually touched the avatar of the participants on the shoulder, producing vibrotactile feedback. In another condition using the identical physical setup, the vibrotactile displays were not activated, so that they would not feel the touch. Our hypothesis was that the tactile touch condition would produce a greater likelihood of compliance with the request to sing. In a second part we examined the hypothesis that people might be more willing to sing (execute an embarrassing task) in a CVE, because of the anonymity provided by virtual reality. Hence we carried out a similar study in physical reality.The results suggest that the tactile intervention had no effect on the sensations of body ownership, presence or the behaviours of the participants, in spite of the finding that the sensation of touch itself was effectively realised. Moreover we found an overall similarity in responses between the VR and real conditions.
C1  - Singapore
C3  - Proceedings of the 19th ACM symposium on virtual reality software and technology
DA  - 2013///
PY  - 2013
DO  - 10.1145/2503713.2503724
SP  - 123
EP  - 132
PB  - Association for Computing Machinery
SN  - 978-1-4503-2379-6
UR  - https://doi.org/10.1145/2503713.2503724
KW  - presence
KW  - embodiment
KW  - social touch
KW  - collaborative virtual environments
KW  - haptic interaction
ER  - 

TY  - CONF
TI  - Virtual whiskers: Spatial directional guidance using cheek haptic stimulation in a virtual environment
AU  - Nakamura, Fumihiko
AU  - Verhulst, Adrien
AU  - Sakurada, Kuniharu
AU  - Sugimoto, Maki
T3  - AHs '21
AB  - Spatial cues are an important element of navigating people in physical/virtual spaces. In terms of spatial navigation, integrating vision with other modalities, such as haptics, can guide users more effectively. Haptic cues are presented on the body parts that are sensitive to stimuli such as hands and a head. The head is reported to be superior to the body for spatial directional perception. In this paper, we propose Virtual Whiskers, a spatial directional guidance technique by haptic stimulation of the cheeks using tiny robot arms attached to a Head-Mounted Display (HMD). We deploy photo reflective sensors attached to the tip of 2 robotic arms to detect the distance between the tip and the cheek surface. Using the robot arms, we stimulate a point on the cheek obtained by calculating an intersection between the cheek surface and the target direction. We experimentally investigated how accurately participants identify the target direction provided by our guidance method. We evaluated an error between the actual target direction and the participant’s pointed direction. The experimental result shows that our method achieves the average absolute directional error of 2.76 degrees in the azimuthal plane and 7.32 degrees in the elevation plane. We also conducted a spatial guidance experiment to evaluate task performance in a target search task. We compared the condition of only vision and vision with haptics for task completion time. The average of task completion time in visual-only condition was M=12.45 s, SD=14.51 s, and visual with haptic condition resulted in M=6.91 s, SD=5.48 s. Statistical test revealed a significant difference in task completion time between the visual condition and the visual+haptic condition.
C1  - Rovaniemi, Finland
C3  - Proceedings of the augmented humans international conference 2021
DA  - 2021///
PY  - 2021
DO  - 10.1145/3458709.3458987
SP  - 141
EP  - 151
PB  - Association for Computing Machinery
SN  - 978-1-4503-8428-5
UR  - https://doi.org/10.1145/3458709.3458987
KW  - virtual reality
KW  - facial haptics
KW  - robot arm
KW  - spatial guidance
ER  - 

TY  - CONF
TI  - AR over NDN: augmented reality applications and the rise of information centric networking
AU  - Dóka, János
AU  - Nagy, Bálint György
AU  - Rehman, Muhammad Atif Ur
AU  - Kim, Dong-Hak
AU  - Kim, Byung-Seo
AU  - Toka, László
AU  - Sonkoly, Balázs
T3  - Sigcomm '20
AB  - Collaborative multi-user Augmented Reality (AR) applications pose serious challenges to the underlying network infrastructure due to their all-to-all communication pattern. The Named Data Networking (NDN) paradigm can be a crucial enabler of these applications operated in extremely large scale in terms of users, amount of content, and network size. The inherent multicast support together with a carefully designed naming scheme can provide the efficient network operation, while the inflated Forwarding Information Base (FIB) tables of typical NDN routers can be compressed by powerful algorithms to make the concept feasible.In this demonstration, we showcase an AR application supporting remote collaboration for a large number of users. The software stack of our proof-of-concept prototype leverages open source tools, such as ChronoSync, NDN Forwarding Daemon (NFD), Named Data Link State Routing Protocol (NLSR), and in order to validate the feasibility of the concept, we established a flexible NDN test environment based on Docker containers, real Android clients and emulated users. The framework enables starting arbitrary NDN topologies with predefined FIB contents and to emulate thousands of users. During the live demo, we can show the current network status and relevant performance metrics, such as end-to-end application latency, crucial for AR applications.
C1  - Virtual event
C3  - Proceedings of the SIGCOMM '20 poster and demo sessions
DA  - 2021///
PY  - 2021
DO  - 10.1145/3405837.3411386
SP  - 44
EP  - 45
PB  - Association for Computing Machinery
SN  - 978-1-4503-8048-5
UR  - https://doi.org/10.1145/3405837.3411386
KW  - augmented reality
KW  - named data networking
KW  - scalability
ER  - 

TY  - CONF
TI  - face2faceVR: using AR to assist VR in ubiquitous environment usage
AU  - Pai, Yun Suen
AU  - Isogai, Megumi
AU  - Ochi, Daisuke
AU  - Kimata, Hideaki
AU  - Kunze, Kai
T3  - UbiComp '17
AB  - As virtual reality (VR) usage becomes more popular, one of the issues, among others, which still prevents VR from being used in a more ubiquitous manner is spatial awareness, unlike augmented reality (AR). Generally, there are two forms of such an awareness; recognizing the environment and recognizing other people around us. We propose face2faceVR; an easy to use implementation of AR tracking to assist VR towards recognizing other nearby VR users. The contribution of this work are the following; 1) it is compatible with mobile VR technology that already caters towards a wider adoption, 2) it does not require a networked or shared virtual environment, and 3) it is an inexpensive implementation without any additional peripherals or hardware.
C1  - Maui, Hawaii
C3  - Proceedings of the 2017 ACM international joint conference on pervasive and ubiquitous computing and proceedings of the 2017 ACM international symposium on wearable computers
DA  - 2017///
PY  - 2017
DO  - 10.1145/3123024.3123155
SP  - 173
EP  - 176
PB  - Association for Computing Machinery
SN  - 978-1-4503-5190-4
UR  - https://doi.org/10.1145/3123024.3123155
KW  - virtual reality
KW  - augmented reality
KW  - spatial awareness
KW  - ubiquitous VR
ER  - 

TY  - CONF
TI  - Free-space haptic feedback for 3D displays via air-vortex rings
AU  - Shtarbanov, Ali
AU  - Bove Jr., V. Michael
T3  - Chi ea '18
AB  - With recent developments in 3D display interfaces, which are now capable of delivering rich and immersive visual experiences, a need has arisen to develop haptic-feedback technologies that can seamlessly be integrated with such displays – in order to maintain the sense of visual realism during interactions and to enable multimodal user experiences. We present an approach to augmenting conventional and 3D displays with free-space haptic feedback capabilities via a large number of closely-spaced air-vortex-ring generators mounted along the periphery of the display. We then present our ongoing work on building an open-source system based on this approach that uses 16 vortex-ring generators, and show how it could serve as a multimodal interactive interface, as a research tool, and as a novel platform for creative expressions.
C1  - Montreal QC, Canada
C3  - Extended abstracts of the 2018 CHI conference on human factors in computing systems
DA  - 2018///
PY  - 2018
DO  - 10.1145/3170427.3188622
SP  - 1
EP  - 6
PB  - Association for Computing Machinery
SN  - 978-1-4503-5621-3
UR  - https://doi.org/10.1145/3170427.3188622
KW  - haptic feedback
KW  - tactile feedback
KW  - 3d displays
KW  - air-vortex rings
KW  - methods
KW  - multimodal interfaces
ER  - 

TY  - CONF
TI  - CASPER: a haptic enhanced telepresence exercise system for elderly people
AU  - Kadomura, Azusa
AU  - Matsuda, Akira
AU  - Rekimoto, Jun
T3  - Ah '16
AB  - Although the necessity and importance of exercise support for the elderly people is largely recognized, the lack of skilled and adequate instructors often limits such activities physically. Remote exercise systems can be a solution for this problem because they may be able to support exercise activities even when instructors and participants are in separate locations. However, when simply using normal video-conferencing systems, instructors and participants have difficulty understanding each side's situation, particularly during guided physical actions. In addition, remote exercise systems cannot support the adjustment of the position of each user, a task that is quite naturally performed in normal exercise activities. Our system, called CASPER, solves these problems by proposing a mirror-like image composition method in which all the participants and the instructor are shown on the same screen so that both sides can understand the situation clearly. We also introduce an airy haptic device to remotely send tactile feedback for further enhancing sensations. In this paper, we describe the system design and its evaluation. The evaluation confirms that our system could effectively allow users to perform exercise activities even at remote locations.
C1  - Geneva, Switzerland
C3  - Proceedings of the 7th augmented human international conference 2016
DA  - 2016///
PY  - 2016
DO  - 10.1145/2875194.2875197
PB  - Association for Computing Machinery
SN  - 978-1-4503-3680-2
UR  - https://doi.org/10.1145/2875194.2875197
KW  - Telepresence
KW  - Haptic
KW  - Airy feedback
KW  - Elderly people
KW  - Exercise
KW  - Fitness
KW  - Rehabilitation
ER  - 

TY  - CONF
TI  - Robotic assembly of haptic proxy objects for tangible interaction and virtual reality
AU  - Zhao, Yiwei
AU  - Kim, Lawrence H.
AU  - Wang, Ye
AU  - Le Goc, Mathieu
AU  - Follmer, Sean
T3  - Iss '17
AB  - Passive haptic proxy objects allow for rich tangible interaction, and this is especially true in VR applications. However, this requires users to have many physical objects at hand. Our paper proposes robotic assembly at run-time of low-resolution haptic proxies for tangible interaction and virtual reality. These assembled physical proxy objects are composed of magnetically attached blocks which are assembled by a small multi robot system, specifically Zooids. We explore the design of the basic building blocks and illustrate two approaches to assembling physical proxies: using multirobot systems to (1) self-assemble into structures and (2) assemble 2.5D structure with passive blocks of various heights. The success rate and completion time are evaluated for both approaches. Finally, we demonstrate the potential of assembled proxy objects for tangible interaction and virtual reality through a set of demonstrations.
C1  - Brighton, United Kingdom
C3  - Proceedings of the 2017 ACM international conference on interactive surfaces and spaces
DA  - 2017///
PY  - 2017
DO  - 10.1145/3132272.3134143
SP  - 82
EP  - 91
PB  - Association for Computing Machinery
SN  - 978-1-4503-4691-7
UR  - https://doi.org/10.1145/3132272.3134143
KW  - Haptics
KW  - Haptic Proxy Objects
KW  - Passive Haptics
KW  - Robotic Assembly
KW  - Self-Assembly
KW  - Tangible Virtual Reality
ER  - 

TY  - CONF
TI  - MetaDragonBoat: Exploring paddling techniques of virtual dragon boating in a metaverse campus
AU  - He, Wei
AU  - Li, Xiang
AU  - Xu, Shengtian
AU  - Chen, Yuzheng
AU  - Sio, Chan-In
AU  - Kan, Ge Lin
AU  - Lee, Lik-Hang
T3  - Mm '24
AB  - The preservation of cultural heritage, as mandated by the United Nations Sustainable Development Goals (SDGs), is integral to sustainable urban development. This paper focuses on the Dragon Boat Festival, a prominent event in Chinese cultural heritage, and proposes leveraging Virtual Reality (VR), to enhance its preservation and accessibility. Traditionally, participation in the festival's dragon boat races was limited to elite athletes, excluding broader demographics. Our proposed solution, named MetaDragonBoat, enables virtual participation in dragon boat racing, offering immersive experiences that replicate physical exertion through a cultural journey. Thus, we build a digital twin of a university campus located in a region with a rich dragon boat racing tradition. Coupled with three paddling techniques that are enabled by either commercial controllers or physical paddle controllers with haptic feedback, diversified users can engage in realistic rowing experiences. Our results demonstrate that by integrating resistance into the paddle controls, users could simulate the physical effort of dragon boat racing, promoting a deeper understanding and appreciation of this cultural heritage.
C1  - Melbourne VIC, Australia
C3  - Proceedings of the 32nd ACM international conference on multimedia
DA  - 2024///
PY  - 2024
DO  - 10.1145/3664647.3681078
SP  - 6335
EP  - 6344
PB  - Association for Computing Machinery
SN  - 979-8-4007-0686-8
UR  - https://doi.org/10.1145/3664647.3681078
KW  - culture
KW  - exergame
KW  - haptic simulator
KW  - metaverse
ER  - 

TY  - CONF
TI  - Visuo-haptic illusions for improving the perceived performance of shape displays
AU  - Abtahi, Parastoo
AU  - Follmer, Sean
T3  - Chi '18
AB  - In this work, we utilize visuo-haptic illusions to improve the perceived performance of encountered-type haptic devices, specifically shape displays, in virtual reality. Shape displays are matrices of actuated pins that travel vertically to render physical shapes; however, they have limitations such as low resolution, small display size, and low pin speed. To address these limitations, we employ illusions such as redirection, scaling, and retargeting that take advantage of the visual dominance effect, the idea that vision often dominates when senses conflict. Our evaluation of these techniques suggests that redirecting sloped lines with angles less than 40 degrees onto a horizontal line is an effective technique for increasing the perceived resolution of the display. Scaling up the virtual object onto the shape display by a factor less than 1.8x can also increase the perceived resolution. Finally, using vertical redirection a perceived 3x speed increase can be achieved.
C1  - Montreal QC, Canada
C3  - Proceedings of the 2018 CHI conference on human factors in computing systems
DA  - 2018///
PY  - 2018
DO  - 10.1145/3173574.3173724
SP  - 1
EP  - 13
PB  - Association for Computing Machinery
SN  - 978-1-4503-5620-6
UR  - https://doi.org/10.1145/3173574.3173724
KW  - virtual reality
KW  - perception
KW  - haptics
KW  - illusion
KW  - shape displays
ER  - 

TY  - CONF
TI  - Collaboration in tele-immersive environments
AU  - Mortensen, J.
AU  - Vinayagamoorthy, V.
AU  - Slater, M.
AU  - Steed, A.
AU  - Lok, B.
AU  - Whitton, M. C.
T3  - Egve '02
AB  - This paper describes a study of remote collaboration between people in a shared virtual environment. Seventeen subjects were recruited at University College London, who worked with a confederate at University of North Carolina Chapel Hill. Each pair was required to negotiate the task of handling an object together, and moving a few metres into a building. The DIVE system was used throughout, and the network support was Internet-2. This was an observational study to examine the extent to which such collaboration was possible, to explore the limitations of DIVE within this context, and to examine the relationship between several variables such as co-presence and task performance. The results suggest that although the task is possible under this framework, it could only be achieved by various software tricks within the DIVE framework. A new Virtual Environment system is required that has better knowledge of network performance, and that supports shared object manipulation across a network. The participant-study suggests that co-presence, the sense of being together with another person, was significantly and positively correlated with task performance.
C1  - Barcelona, Spain
C3  - Proceedings of the workshop on virtual environments 2002
DA  - 2002///
PY  - 2002
SP  - 93
EP  - 101
PB  - Eurographics Association
SN  - 1-58113-535-1
KW  - virtual reality
KW  - presence
KW  - collaborative virtual environments
KW  - internet-2
ER  - 

TY  - JOUR
TI  - C-hg: a collaborative haptic-gripper fine motor skill training system for children with autism spectrum disorder
AU  - Zhao, Huan
AU  - Amat, Ashwaq Zaini
AU  - Migovich, Miroslava
AU  - Swanson, Amy
AU  - Weitlauf, Amy S.
AU  - Warren, Zachary
AU  - Sarkar, Nilanjan
T2  - ACM Trans. Access. Comput.
AB  - Computer-assisted systems can provide efficient and engaging ASD intervention environments for children with Autism Spectrum Disorder (ASD). However, most existing computer-assisted systems target only one skill deficit (e.g., social conversation skills) and ignore the importance of other areas, such as motor skills, that could also impact social interaction. This focus on a single domain may hinder the generalizability of learned skills to real-world scenarios, because the targeted teaching strategies do not reflect that real-world tasks often involve more than one skill domain. The work presented in this article seeks to bridge this gap by developing a Collaborative Haptic-gripper virtual skill training system (C-Hg). This system includes individual and collaborative games that provide opportunities for simultaneously practicing both fine motor skills (hand movement and grip control skills) as well as social skills (communication and collaboration) and investigating how they relate to each other. We conducted a usability study with 10 children with ASD and 10 Typically Developing (TD) children (8–12 years), who used C-Hg to play a series of individual and collaborative games requiring differing levels of motor and communication skill. Results revealed that participant performance significantly improved in both individual and collaborative fine motor skill training tasks, including significant improvements in collaborative manipulations between partners. Participants with ASD were found to conduct more collaborative manipulations and initiate more conversations with their partners in the post collaborative tasks, suggesting more active collaboration and communication of participants with ASD in the collaborative tasks. Results support the potential of our C-Hg system for simultaneously improving fine motor and social skills, with implications for impacts of improved fine motor skills on social outcomes.
DA  - 2021/07//
PY  - 2021
DO  - 10.1145/3459608
VL  - 14
IS  - 2
SN  - 1936-7228
UR  - https://doi.org/10.1145/3459608
ER  - 

TY  - CONF
TI  - Influence of multimodal instructions on learning tool manipulation skills through mentoring in an immersive environment: Influence des instructions multimodales sur l’apprentissage par compagnonnage des compétences de manipulation d’outil dans un environnement immersif
AU  - Simon, Cassandre
AU  - Hacene, Manel Boukli
AU  - Lebrun, Flavien
AU  - Otmane, Samir
AU  - Chellali, Amine
T3  - Ihm '24
AB  - La formation par compagnonnage permet aux novices d’acquérir des compétences sous la supervision d’experts qui utilisent diverses modalités de communication. Cependant, reproduire ce modèle dans des simulateurs immersifs reste un défi, notamment pour assurer une communication efficace entre experts et novices. Notre étude explore l’impact de la communication multimodale expert-novice pour transmettre des instructions sur l’amplitude des mouvements dans une tâche de manipulation d’outils en environnement immersif. Les résultats révèlent que la combinaison des modalités visuelle-haptique améliore la précision, la vitesse et la qualité des mouvements. De plus, la combinaison verbale-visuelle-haptique renforce le sentiment de présence et de coprésence, et l’expérience d’apprentissage. Ces résultats suggèrent que la combinaison visuelle-haptique est optimale pour améliorer les performances des novices, et que l’intégration de la modalité verbale améliore l’expérience utilisateur. Ces conclusions ouvrent de nouvelles perspectives pour améliorer l’acquisition de gestes techniques par compagnonnage en réalité virtuelle grâce à la communication multimodale.
C1  - Paris, France
C3  - Proceedings of the 35th conference on l'Interaction humain-machine
DA  - 2024///
PY  - 2024
DO  - 10.1145/3649792.3649793
PB  - Association for Computing Machinery
SN  - 979-8-4007-1811-3
UR  - https://doi.org/10.1145/3649792.3649793
KW  - Apprentissage des gestes
KW  - Formation par compagnonnage
KW  - Interactions multimodale
KW  - Mentorship
KW  - Multimodal interactions
KW  - Skill learning
ER  - 

TY  - CONF
TI  - From remote media immersion to Distributed Immersive Performance
AU  - Sawchuk, A. A.
AU  - Chew, E.
AU  - Zimmermann, R.
AU  - Papadopoulos, C.
AU  - Kyriakakis, C.
T3  - Etp '03
AB  - We present the architecture, technology and experimental applications of a real-time, multi-site, interactive and collaborative environment called Distributed Immersive Performance (DIP). The objective of DIP is to develop the technology for live, interactive musical performances in which the participants - subsets of musicians, the conductor and the audience - are in different physical locations and are interconnected by very high fidelity multichannel audio and video links. DIP is a specific realization of broader immersive technology - the creation of the complete aural and visual ambience that places a person or a group of people in a virtual space where they can experience events occurring at a remote site or communicate naturally regardless of their location. The DIP experimental system has interaction sites and servers in different locations on the USC campus and at several partners, including the New World Symphony of Miami Beach, FL. The sites have different types of equipment to test the effects of video and audio fidelity on the ease of use and functionality for different applications. Many sites have high-definition (HD) video or digital video (DV) quality images projected onto wide screen wall displays completely integrated with an immersive audio reproduction system for a seamless, fully three-dimensional aural environment with the correct spatial sound localization for participants. The system is capable of storage and playback of the many streams of synchronized audio and video data (immersidata), and utilizes novel protocols for the low-latency, seamless, synchronized real-time delivery of immersidata over local area networks and wide-area networks such as Internet2. We discuss several recent interactive experiments using the system and many technical challenges common to the DIP scenario and a broader range of applications. These challenges include: (1). low latency continuous media (CM) stream transmission, synchronization and data loss management; (2). low latency, real-time video and multichannel immersive audio acquisition and rendering; (3). real-time continuous media stream recording, storage, playback; (4). human factors studies: psychophysical, perceptual, artistic, performance evaluation; (5). robust integration of all these technical areas into a seamless presentation to the participants.
C1  - Berkeley, California
C3  - Proceedings of the 2003 ACM SIGMM workshop on experiential telepresence
DA  - 2003///
PY  - 2003
DO  - 10.1145/982484.982506
SP  - 110
EP  - 120
PB  - Association for Computing Machinery
SN  - 1-58113-775-3
UR  - https://doi.org/10.1145/982484.982506
KW  - remote collaboration
KW  - information interfaces and presentation
KW  - music performance
KW  - real-time interaction
ER  - 

TY  - CONF
TI  - An AR system for haptic communication
AU  - Cha, Jongeun
AU  - Oakley, Ian
AU  - Lee, Junhun
AU  - Ryu, Jeha
T3  - Icat '05
AB  - Touch is an important part of human communication. Through handshakes, hugs and a myriad of personal gestures, we convey our emotions and express our feelings. However, how such interactions can be achieved over distance remains a relatively unexplored area of research. To begin to rectify this we present the description of a system that enables one user to reach out and touch another distant user and for both to feel the resultant physical contact. In this initial exploration, we focus on the practical feasibility of this idea, and describe the technical components required.
C1  - Christchurch, New Zealand
C3  - Proceedings of the 2005 international conference on augmented tele-existence
DA  - 2005///
PY  - 2005
DO  - 10.1145/1152399.1152444
SP  - 241
EP  - 242
PB  - Association for Computing Machinery
SN  - 0-473-10657-4
UR  - https://doi.org/10.1145/1152399.1152444
KW  - augmented reality
KW  - haptic
KW  - communication
ER  - 

TY  - JOUR
TI  - MetaTwin: a collaborative XR platform for seamless physical-virtual synchronization
AU  - Bhardwaj, Ayush
AU  - Pratap, Ashish
AU  - Carrizales, Edilberto F.
AU  - Ko, Dongbeom
AU  - Kang, Sungjoo
AU  - Kim, Jin Ryong
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
AB  - This paper presents MetaTwin, a collaborative platform that enables seamless synchronization between physical and virtual realms for co-existing Extended Reality (XR) experiences. MetaTwin employs a hybrid decentralized server architecture to synchronize user interactions and environments within a shared space, allowing users to collaborate and socialize across physical locations while experiencing the convergence of real and virtual spaces. Integrated IoT devices act as both physical and virtual entities, supporting shared control and enabling resource sharing, such as presentation slides and music. We detail the configuration and deployability of MetaTwin as a solution for XR collaboration. To evaluate performance and feasibility, we compared MetaTwin with an existing XR platform and conducted an ablation study to identify the benefits and limitations of our approach. Additionally, a user study investigates the impact of spatial and temporal synchronization offsets on collaboration quality. Our findings inform the development of operational guidelines for future collaborative XR platforms.
DA  - 2025/09//
PY  - 2025
DO  - 10.1145/3749533
VL  - 9
IS  - 3
UR  - https://doi.org/10.1145/3749533
KW  - Metaverse
KW  - Collaborative Virtual Environments
KW  - Digital Twin
KW  - XR Collaborative Platform
ER  - 

TY  - CONF
TI  - Mediate: a spatial tangible interface for mixed reality
AU  - Fitzgerald, Daniel
AU  - Ishii, Hiroshi
T3  - Chi ea '18
AB  - Recent Virtual Reality (VR) systems render highly immersive visual experiences, yet currently lack tactile feedback for feeling virtual objects with our hands and bodies. Shape Displays offer solid tangible interaction but have not been integrated with VR or have been restricted to desktop-scale workspaces. This work represents a fusion of mobile robotics, haptic props, and shape-display technology and commercial Virtual Reality to overcome these limitations. We present Mediate, a semi-autonomous mobile shape-display that locally renders 3D physical geometry co-located with room-sized virtual environments as a conceptual step towards large-scale tangible interaction in Virtual Reality. We compare this "dynamic just-in-time mockup" concept to other haptic paradigms and discuss future applications and interaction scenarios.
C1  - Montreal QC, Canada
C3  - Extended abstracts of the 2018 CHI conference on human factors in computing systems
DA  - 2018///
PY  - 2018
DO  - 10.1145/3170427.3188472
SP  - 1
EP  - 6
PB  - Association for Computing Machinery
SN  - 978-1-4503-5621-3
UR  - https://doi.org/10.1145/3170427.3188472
KW  - virtual reality
KW  - haptic
KW  - tangible interface
KW  - hand
KW  - pin display
KW  - robotic
KW  - robotic graphics
KW  - shape display
ER  - 

TY  - CONF
TI  - Haptic communication to enhance collaboration in virtual environments
AU  - Chellali, Amine
AU  - Dumas, Cédric
AU  - Milleville, Isabelle
T3  - Ecce '10
AB  - Motivation – To study haptic communication in collaborative virtual environments.Research approach – An experimental study was conducted, in which 60 students were asked to perform in dyads a shared manual task after a training period.Findings/Design – The results show that haptic communication can influence the common frame of reference development in a shared manual task.Research limitations/Implications – Deeper verbalization analyses are needed to evaluate the common frame of reference development.Originality/Value – This study highlights haptic interactions importance when designing virtual environment that support shared manual tasks.Take away message – Haptic communication, combined with visual and verbal communication, enriches interactions in collaborative virtual environments.
C1  - Delft, Netherlands
C3  - Proceedings of the 28th annual european conference on cognitive ergonomics
DA  - 2010///
PY  - 2010
DO  - 10.1145/1962300.1962319
SP  - 83
EP  - 90
PB  - Association for Computing Machinery
SN  - 978-1-60558-946-6
UR  - https://doi.org/10.1145/1962300.1962319
KW  - haptic communication
KW  - collaborative virtual environments
KW  - common frame of reference
KW  - human interactions
ER  - 

TY  - CONF
TI  - A quality of experience model for haptic user interfaces
AU  - Hamam, Abdelwahab
AU  - Eid, Mohamad
AU  - El Saddik, Abdulmotaleb
AU  - Georganas, Nicolas D.
T3  - Has '08
AB  - Multimedia systems and applications have recently started to integrate the sense of touch and force feedback in the human-computer interaction. Surprisingly, measuring the quality of experience when haptic modality is incorporated in a graphical user interface has received limited attention from the research community. In this paper, we propose a taxonomy for measuring the quality of experience of a haptic user interface (HUI) applications. Furthermore, the taxonomy is modeled using a mathematical model. Finally, the proposed model is evaluated using two HUI-based applications: the haptic learning system and the haptic enabled UML CASE tool. The performance evaluation demonstrated that the proposed model is capable of reflecting the user estimation of the applications.
C1  - Quebec City, Canada
C3  - Proceedings of the 2008 ambi-sys workshop on haptic user interfaces in ambient media systems
DA  - 2008///
PY  - 2008
PB  - ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)
KW  - haptic perception
KW  - quality of experience
KW  - haptic user interface
ER  - 

TY  - CONF
TI  - Collaborative augmented reality in schools
AU  - Pemberton, Lyn
AU  - Winter, Marcus
T3  - CSCL'09
AB  - Augmented Reality as an interactive real-time technology combining real and virtual objects in a real 3D space carries enormous educational potential. We describe a project (ARISE: Augmented Reality in School Environments) that aims to realise this potential by developing a collaborative, robust and affordable Augmented Reality learning platform for schools. The learning affordances of Augmented Reality are discussed, and an educational application is described that supports remote collaboration between students in a shared 3D workspace, where students from different countries present, discuss and manipulate virtual objects relating to their local culture. The evaluation of the application is based on a distributed summer school project involving students from two European countries. In addition to more conventional evaluation approaches, special requirements for evaluating remote collaboration in a shared Augmented Reality workspace have been met with a customised approach involving synchronised video observations in both locations with subsequent editing of the material into and a single screen giving a comprehensive overview of the collaboration from both ends. The results of the evaluation study are currently being analysed, but preliminary findings suggest that the Augmented Reality learning platform has been well received by students and teachers, and is well suited for remote collaborative learning.
C1  - Rhodes, Greece
C3  - Proceedings of the 9th international conference on computer supported collaborative learning - volume 2
DA  - 2009///
PY  - 2009
SP  - 109
EP  - 111
PB  - International Society of the Learning Sciences
SN  - 978-1-4092-8598-4
ER  - 

TY  - CONF
TI  - Children using tabletop telepresence robots for collaboration: a longitudinal case study of hybrid and online intergenerational participatory design
AU  - Hunt, Casey Lee
AU  - Sun, Kaiwen
AU  - Dhuliawala, Zahra
AU  - Tsukiyama, Fumi
AU  - Druin, Allison
AU  - Huynh, Amanda
AU  - Leithinger, Daniel
AU  - Yip, Jason
T3  - Chi '25
AB  - Improving telepresence for children expands educational opportunities and connects faraway family. Yet, research about child-centered physical telepresence systems (tangible interfaces for telepresence) remains sparse, despite established benefits of tangible interaction for children. To address this gap, we collaborated with child designers (ages 8-12) over 2-years of online/1-year of hybrid participatory design. Together, we adapted one approach to physical telepresence (tabletop robots) for child users. Using a case study methodology, we explore how our tabletop telepresence robot platform influenced children’s connections with one another over the 3-year study. In our analysis, we compare four vignettes representing cooperation/conflict between children while using the platform; centering theories of ownership, collaboration, and co-design roles. Through this exploration of children’s interpersonal dynamics while using the platform, we uncover four key features of tabletop telepresence robots for children: (1) Anonymous Robot Control (2) Robot/Material Distribution, (3) Robot Form/Size, and (4) Robot Stewardship.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713746
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713746
KW  - Children
KW  - Physical telepresence
KW  - Actuated tangible user interfaces
KW  - Hybrid collaboration
KW  - Online Collaboration
KW  - Participatory design
ER  - 

TY  - CONF
TI  - Collaborative stretcher carrying: a case study
AU  - Hubbold, Roger J.
T3  - Egve '02
AB  - This paper describes a simulation of a collaborative task in a shared virtual environment — two users carrying a shared object (a stretcher) in a complex chemical plant. The implementation includes a haptic interface for each user, so that forces transmitted through the stretcher from one user to the other can be experienced. Preliminary experiments show that the addition of haptic feedback significantly enhances the sense of sharing and each user's perception of the actions of the other user. The implementation is described, and some conclusions about the value of haptics, and plans for future work are given.
C1  - Barcelona, Spain
C3  - Proceedings of the workshop on virtual environments 2002
DA  - 2002///
PY  - 2002
SP  - 7
EP  - 12
PB  - Eurographics Association
SN  - 1-58113-535-1
KW  - haptics
KW  - force feedback
KW  - collaborative virtual environments
KW  - shared virtual environments
ER  - 

TY  - CONF
TI  - A haptic multimedia handwriting learning system
AU  - Eid, Mohamad A.
AU  - Mansour, Mohamed
AU  - El Saddik, Abdulmotaleb H.
AU  - Iglesias, Rosa
T3  - Emme '07
AB  - In this paper, we describe a multimedia system for learning handwriting and pronunciation of alphabet letters or characters in different languages. This system provides haptic, audio and visual information according to the desired letter or character chosen by a user. Letters or characters from the Arabic, English, French, Japanese, and Spanish languages have been considered, although the system utilizes an XML-based schema to easily introduce new characters from another language.Three different modes of learning can be chosen in terms of haptic information: full guidance, partial guidance and a no guidance mode (no haptic feedback). The full guidance guides the user to follow a pre-recorded letter trajectory; whereas in partial guidance, a user can freely follow a letter-drawing path, but if the user deviates significantly, the system automatically brings him/her back to the optimal displayed path. The no guidance mode allows users to perform letter handwriting with only visual information. This system guides users to write a character, in a similar way as a teacher holds a student.s hand. Moreover, the character trajectory is displayed as the user is performing it. The results of this system evaluation show its potential as a virtual tool for learning handwriting.
C1  - Augsburg, Bavaria, Germany
C3  - Proceedings of the international workshop on educational multimedia and multimedia education
DA  - 2007///
PY  - 2007
DO  - 10.1145/1290144.1290161
SP  - 103
EP  - 108
PB  - Association for Computing Machinery
SN  - 978-1-59593-783-4
UR  - https://doi.org/10.1145/1290144.1290161
KW  - haptics
KW  - multimedia
KW  - education
KW  - haptic playback
KW  - virtual teaching
ER  - 

TY  - CONF
TI  - Transforming design reviews with XR: a no-code media experience creation strategy for manufacturing design
AU  - Sharma, Sahir
AU  - Keighrey, Conor
AU  - Gilligan, Shane
AU  - Lardner, James
AU  - Murray, Niall
T3  - Imx '25
AB  - Extended Reality (XR) has proven effective in reducing cognitive load, enhancing spatial perception, and improving decision-making within mechanical engineering environments. However, hardware and software limitations have slowed its widespread adoption in industrial manufacturing. In particular, there is a notable gap in enabling non-programming stakeholders to create immersive, process-oriented experiences from CAD models for use in design meetings. Futhermore, the cost of traditional XR development workflows is proving prohibitive with respect to industry-wide implementation. This paper details the design, implementation, and evaluation of a no-code workflow that enables the creation of Virtual Reality (VR) experiences from CAD models for early-stage design reviews. Although developed to meet the rigorous requirements of equipment design engineering, the underlying philosophy is adaptable to other manufacturing domains working with CAD data. By integrating an enterprise-grade CAD-to-mesh translation tool with a freely available, cross-platform XR Software Development Kit, we have developed a reusable VR software container that allows CAD models to be imported without any programming expertise. Documented no-code instructions and pre-programmed XR components simplify the creation of VR-based Equipment Design Review (VR-EDR) experiences. Our research demonstrates that transforming industrial equipment design reviews using XR is feasible and efficient when supported by a container-based software solution and context-specific no-code guidelines, as validated through continuous qualitative assessments.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 ACM international conference on interactive media experiences
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706370.3727860
SP  - 30
EP  - 48
PB  - Association for Computing Machinery
SN  - 979-8-4007-1391-0
UR  - https://doi.org/10.1145/3706370.3727860
KW  - Virtual Reality
KW  - Equipment Design Review
KW  - Experience Creation
KW  - Immersive Design Assessments
KW  - Reusable software
KW  - Technology Adoption
KW  - Thematic Analysis
ER  - 

TY  - CONF
TI  - Enhancing collaborative manipulation through the use of feedback and awareness in CVEs
AU  - Garcı́a, Arturo S.
AU  - Molina, José P.
AU  - Martı́nez, Diego
AU  - González, Pascual
T3  - Vrcai '08
AB  - In the research community, Collaborative Virtual Environment (CVE) developers usually refer to the terms awareness and feedback as something necessary to maintain a fluent collaboration when highly interactive task have to be performed. However, it is remarkable that few studies address the effect that including special kind of awareness has on the task performance and the user experience.This paper proposes how to face the implementation of awareness in order to be taken into account early in the development of a CVE. In addition, it is also described an experiment that was carried out to evaluate the effect of providing some visual cues, showing that users tend to make more mistakes when they are not provided.
C1  - Singapore
C3  - Proceedings of the 7th ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry
DA  - 2008///
PY  - 2008
DO  - 10.1145/1477862.1477904
PB  - Association for Computing Machinery
SN  - 978-1-60558-335-8
UR  - https://doi.org/10.1145/1477862.1477904
KW  - CSCW
KW  - feedback
KW  - collaborative virtual environments
KW  - awareness
ER  - 

TY  - CONF
TI  - Elaboration of a common frame of reference in collaborative virtual environments
AU  - Chellali, Amine
AU  - Milleville-Pennel, Isabelle
AU  - Dumas, Cédric
T3  - Ecce '08
AB  - Motivation – To design virtual environments that support collaborative activities.Research approach – An experimental approach in which 44 students were asked to work in pairs to reconstruct five 3D figures.Findings/Design – The results show that including a contextual clue in virtual environments improves collaboration between operators.Research limitations – Further investigative work must be carried out to extract accurate female collaboration profiles.Originality/Value – The results enable three collaboration profiles to be identified. They also allow the extraction of some characteristics of a contextual clue which can be added to a virtual environment to improve collaboration.Take away message – The contents of a collaborative virtual environment influences the way that users collaborate.
C1  - Funchal, Portugal
C3  - Proceedings of the 15th european conference on cognitive ergonomics: The ergonomics of cool interaction
DA  - 2008///
PY  - 2008
DO  - 10.1145/1473018.1473045
PB  - Association for Computing Machinery
SN  - 978-1-60558-399-0
UR  - https://doi.org/10.1145/1473018.1473045
KW  - virtual environment
KW  - collaboration
KW  - common frame of reference
KW  - 3D interface
ER  - 

TY  - CONF
TI  - Chameleon: Unobtrusive substitution of real-world obstacles in VR with risk-level-aware adaptation
AU  - Yu, Yichen
AU  - Jin, Qiao
T3  - Chi ea '25
AB  - In VR environments, free movement in real space enhances immersion but increases the risk of collisions with real-world obstacles. Prior solutions investigated using substitute obstacles with context-related digital objects in VR but often treat all obstacles uniformly without considering their varying levels of risk. This oversight might result in reduced awareness for high-risk obstacles and a missed opportunity to utilize low-risk objects to enhance haptic feedback and interactivity in VR. In this study, we propose Chameleon, a system that classifies real-world obstacles by their varying risk levels and substitutes them with context-related virtual objects in VR. The substitutions are designed to align with the obstacles’ real-world risk levels to ensure both safety and immersion. A preliminary heuristic evaluation assessed the usability of using visual textures to implicitly represent obstacle risk levels.
C1  - New York, NY, USA
C3  - Proceedings of the extended abstracts of the CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706599.3719779
PB  - Association for Computing Machinery
SN  - 979-8-4007-1395-8
UR  - https://doi.org/10.1145/3706599.3719779
KW  - Safety
KW  - Virtual Reality
KW  - Cross-reality System
KW  - Obstacle Avoidance
ER  - 

TY  - CONF
TI  - A survey on measuring presence in mixed reality
AU  - Tran, Tanh Quang
AU  - Langlotz, Tobias
AU  - Regenbrecht, Holger
T3  - Chi '24
AB  - Presence is a defining element of virtual reality (VR), but it is also increasingly used when assessing mixed reality (MR) experiences. The increased interest in measuring presence in MR and recent works underpinning the specific nature of presence in MR raise the question of the current state and practice of assessing presence in MR. To address this question, we present an analysis of more than 320 studies that report on presence measurements in MR. Our analysis showed that questionnaires are the dominant measurement but also identify problematic trends that stem from the lack of a generally agreed-upon concept or measurement for presence in MR. More specifically, we show that using measurements that are not validated in MR or custom questionnaires limiting the comparability of results is commonplace and could contribute to a looming replication crisis in an increasingly relevant field.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI conference on human factors in computing systems
DA  - 2024///
PY  - 2024
DO  - 10.1145/3613904.3642383
PB  - Association for Computing Machinery
SN  - 979-8-4007-0330-0
UR  - https://doi.org/10.1145/3613904.3642383
KW  - Virtual Reality
KW  - Augmented Reality
KW  - Mixed Reality
KW  - Extended Reality
KW  - Sense of Presence
KW  - Spatial Presence
ER  - 

TY  - CONF
TI  - Insights from youth co-designers on remote multimodal prototyping with paper playground
AU  - Fiedler, Brett L
AU  - Smith, Taliesin L.
AU  - Greenberg, Jesse
AU  - Eisenberg, Ann
AU  - Moore, Emily B.
T3  - Idc '24
AB  - Paper prototyping presents a low-entry barrier method to engaging youth in interaction design. Purely paper-based designs leave a large gap between ideation and implementation. Paper Playground is a prototyping tool that connects physical and virtual papers with JavaScript programs, enabling the creation of multimodal prototypes in both face-to-face and virtual settings. Paper Playground is being designed and developed through iterative co-design activities including youth and adults. Here we present findings from remote co-design sessions with youth, investigating what affordances the participants requested from a multimodal prototyping tool. We reflect on the co-designers desires and remarks on paper use for interactive project design, remote collaborative use, and extensibility for physical computing.
C1  - Delft, Netherlands
C3  - Proceedings of the 23rd annual ACM interaction design and children conference
DA  - 2024///
PY  - 2024
DO  - 10.1145/3628516.3659400
SP  - 818
EP  - 822
PB  - Association for Computing Machinery
SN  - 979-8-4007-0442-0
UR  - https://doi.org/10.1145/3628516.3659400
KW  - co-design
KW  - interactive design
KW  - web design
KW  - web interactives
ER  - 

TY  - CONF
TI  - The programming of robots by haptic means
AU  - Teh, James Keng Soon
AU  - Kato, Daishi
AU  - Kunieda, Kazuo
AU  - Yamada, Keiji
T3  - Siggraph '08
C1  - Los Angeles, California
C3  - ACM SIGGRAPH 2008 new tech demos
DA  - 2008///
PY  - 2008
DO  - 10.1145/1401615.1401653
PB  - Association for Computing Machinery
SN  - 978-1-4503-7847-5
UR  - https://doi.org/10.1145/1401615.1401653
ER  - 

TY  - CONF
TI  - Exploring virtual representations of physical artefacts in a multi-touch clothing design collaboration system
AU  - Yang, Jason
AU  - Dekker, Andrew
AU  - Muhlberger, Ralf
AU  - Viller, Stephen
T3  - Ozchi '09
AB  - This paper describes a pilot study that investigates how a multi-touch system can support remote collaboration within the clothing design and manufacturing industries. We first examine and discuss the existing collaboration processes and issues found in the day-to-day operations of the clothing industry. To further refine our understanding of what forms of collaboration are important when discussing design and manufacturing techniques, we conducted an ethnographic study with fashion design students. Based on this background research, we designed, developed and evaluated a multi-touch gestural prototype interface. We conclude with reflections on whether collocated natural interactions can be extended remotely via technology.
C1  - Melbourne, Australia
C3  - Proceedings of the 21st annual conference of the australian computer-human interaction special interest group: Design: Open 24/7
DA  - 2009///
PY  - 2009
DO  - 10.1145/1738826.1738895
SP  - 353
EP  - 356
PB  - Association for Computing Machinery
SN  - 978-1-60558-854-4
UR  - https://doi.org/10.1145/1738826.1738895
KW  - observation
KW  - collaboration
KW  - tangible interface
KW  - gestural interface
KW  - multi-touch
KW  - user-centred design
ER  - 

TY  - CONF
TI  - Designing together, miles apart: a longitudinal tabletop telepresence adventure in online co-design with children
AU  - Hunt, Casey Lee
AU  - Sun, Kaiwen
AU  - Dhuliawala, Zahra
AU  - Tsukiyama, Fumi
AU  - Matkovic, Iva
AU  - Schwemler, Zachary
AU  - Wolf, Anastasia
AU  - Zhang, Zihao
AU  - Druin, Allison
AU  - Huynh, Amanda
AU  - Leithinger, Daniel
AU  - Yip, Jason
T3  - Idc '23
AB  - Children’s online co-design has become prevalent since COVID-19. However, related research focuses on insights gained across several shorter-term projects, rather than longitudinal investigations. To explore longitudinal co-design online, we engaged in participatory design with children (ages 8 - 12) for 20 sessions in two years on a single project: an online collaboration platform with tabletop telepresence robots. We found that (1) the online technology space required children to play a role as technology managers and troubleshooters, (2) the home setting shaped online social dynamics, and (3) providing children the ability to choose their design techniques prevented gridlock from situational uncertainties. We discuss how each finding resulted from interplay between our long-term technology design and online co-design processes. We then present insights about the future of online co-design, a conceptual model for longitudinal co-design online, and describe opportunities for further longitudinal online co-design research to generate new methods, techniques, and theories.
C1  - Chicago, IL, USA
C3  - Proceedings of the 22nd annual ACM interaction design and children conference
DA  - 2023///
PY  - 2023
DO  - 10.1145/3585088.3589359
SP  - 52
EP  - 67
PB  - Association for Computing Machinery
SN  - 979-8-4007-0131-3
UR  - https://doi.org/10.1145/3585088.3589359
KW  - Children
KW  - Physical telepresence
KW  - Actuated tangible user interfaces
KW  - Participatory design
KW  - Design methods
ER  - 

TY  - CONF
TI  - Telextiles: End-to-end remote transmission of fabric tactile sensation
AU  - Kitagishi, Takekazu
AU  - Hiroi, Yuichi
AU  - Watanabe, Yuna
AU  - Itoh, Yuta
AU  - Rekimoto, Jun
T3  - Uist '23
AB  - The tactile sensation of textiles is critical in determining the comfort of clothing. For remote use, such as online shopping, users cannot physically touch the textile of clothes, making it difficult to evaluate its tactile sensation. Tactile sensing and actuation devices are required to transmit the tactile sensation of textiles. The sensing device needs to recognize different garments, even with hand-held sensors. In addition, the existing actuation device can only present a limited number of known patterns and cannot transmit unknown tactile sensations of textiles. To address these issues, we propose Telextiles, an interface that can remotely transmit tactile sensations of textiles by creating a latent space that reflects the proximity of textiles through contrastive self-supervised learning. We confirm that textiles with similar tactile features are located close to each other in the latent space through a two-dimensional plot. We then compress the latent features for known textile samples into the 1D distance and apply the 16 textile samples to the rollers in the order of the distance. The roller is rotated to select the textile with the closest feature if an unknown textile is detected.
C1  - San Francisco, CA, USA
C3  - Proceedings of the 36th annual ACM symposium on user interface software and technology
DA  - 2023///
PY  - 2023
DO  - 10.1145/3586183.3606764
PB  - Association for Computing Machinery
SN  - 979-8-4007-0132-0
UR  - https://doi.org/10.1145/3586183.3606764
KW  - Machine learning
KW  - Haptic feedback
KW  - Passive haptic feedback
KW  - Self supervised learning
KW  - Tactile Display
KW  - Tactile perception
KW  - Texture
KW  - Texture perception
KW  - Texture recognition
ER  - 

TY  - CONF
TI  - Investigating effects of visual and tactile feedback on spatial coordination in collaborative handheld systems
AU  - Yatani, Koji
AU  - Gergle, Darren
AU  - Truong, Khai
T3  - Cscw '12
AB  - Mobile and handheld devices have become platforms to support remote collaboration. But, their small form-factor may impact the effectiveness of the visual feedback channel often used to help users maintain an awareness of their partner's activities during synchronous collaborative tasks. We investigated how visual and tactile feedback affects collaboration on mobile devices, with emphasis on spatial coordination in a shared workspace. From two user studies, our results highlight different benefits of each feedback channel in collaborative handheld systems. Visual feedback can provide precise spatial information for collaborators, but degrades collaboration when the feedback is occluded, and sometimes can distract the user's attention. Spatial tactile feedback can reduce the overload of information in visual space and gently guides the user's attention to an area of interest. Our results also show that visual and tactile feedback can complement each other, and systems using both feedback channels can support better spatial coordination than systems using only one form of feedback.
C1  - Seattle, Washington, USA
C3  - Proceedings of the ACM 2012 conference on computer supported cooperative work
DA  - 2012///
PY  - 2012
DO  - 10.1145/2145204.2145305
SP  - 661
EP  - 670
PB  - Association for Computing Machinery
SN  - 978-1-4503-1086-4
UR  - https://doi.org/10.1145/2145204.2145305
KW  - tactile feedback
KW  - visual feedback
KW  - collaboration
KW  - mobile/handheld devices
KW  - spatial coordination
KW  - touch screen
ER  - 

TY  - CONF
TI  - InflatableBots: Inflatable shape-changing mobile robots for large-scale encountered-type haptics in VR
AU  - Gomi, Ryota
AU  - Suzuki, Ryo
AU  - Takashima, Kazuki
AU  - Fujita, Kazuyuki
AU  - Kitamura, Yoshifumi
T3  - Chi '24
AB  - We introduce InflatableBots, shape-changing inflatable robots for large-scale encountered-type haptics in VR. Unlike traditional inflatable shape displays, which are immobile and limited in interaction areas, our approach combines mobile robots with fan-based inflatable structures. This enables safe, scalable, and deployable haptic interactions on a large scale. We developed three coordinated inflatable mobile robots, each of which consists of an omni-directional mobile base and a reel-based inflatable structure. The robot can simultaneously change its height and position rapidly (horizontal: 58.5 cm/sec, vertical: 10.4 cm/sec, from 40 cm to 200 cm), which allows for quick and dynamic haptic rendering of multiple touch points to simulate various body-scale objects and surfaces in real-time across large spaces (3.5 m x 2.5 m). We evaluated our system with a user study (N = 12), which confirms the unique advantages in safety, deployability, and large-scale interactability to significantly improve realism in VR experiences.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI conference on human factors in computing systems
DA  - 2024///
PY  - 2024
DO  - 10.1145/3613904.3642069
PB  - Association for Computing Machinery
SN  - 979-8-4007-0330-0
UR  - https://doi.org/10.1145/3613904.3642069
KW  - Virtual Reality
KW  - Haptics
KW  - Mobile Robots
KW  - Encountered-Type Haptics
KW  - Inflatables
KW  - Shape-Changing Interfaces
ER  - 

TY  - JOUR
TI  - Probing the potential of extended reality to connect experts and novices in the garden
AU  - Maddali, Hanuma Teja
AU  - Irlitti, Andrew
AU  - Lazar, Amanda
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - As extended reality (XR) systems become increasingly available, XR-based remote instruction is being adopted for diverse purposes in professional settings such as surgery and field servicing. Hobbyists have been well-studied in HCI and may similarly benefit from remote skill-sharing. However, little is known about how XR technologies might support expert-novice collaboration for skilled hobby activities. This paper examines the potential and limitations of XR to connect experts and novices for one such activity: gardening. Through two studies involving 27 expert and novice gardeners, we designed prototypes to understand 1) practitioner perceptions of XR and remote skill-sharing in the garden and 2) what kinds of interactions can be supported in XR for expert-novice groups. We discuss design opportunities and challenges for XR systems in supporting informal connecting interactions and meaningful sensory interactions with a remote environment during skill-sharing.
DA  - 2022/11//
PY  - 2022
DO  - 10.1145/3555211
VL  - 6
IS  - CSCW2
UR  - https://doi.org/10.1145/3555211
KW  - extended reality
KW  - gardening
KW  - skill-sharing
KW  - skilled hobbies
ER  - 

TY  - CONF
TI  - Tangible message bubbles for children's communication and play
AU  - Ryokai, Kimiko
AU  - Raffle, Hayes
AU  - Brooks, Andy
T3  - Chi ea '09
AB  - We introduce Tangible Message Bubbles, a new composition and communication tool that invites youngsters to express and record their everyday expressions, play with these original recordings, and share these personal creations with their friends and family. We present a design rationale that focuses on supporting both co-located and remote collaboration, and on balancing play with tool design. Results from pilot evaluations with our initial prototypes informed us with ways to leverage the physical properties of the toys and support playful exploration of children's recorded video messages for sharing.
C1  - Boston, MA, USA
C3  - CHI '09 extended abstracts on human factors in computing systems
DA  - 2009///
PY  - 2009
DO  - 10.1145/1520340.1520706
SP  - 4597
EP  - 4602
PB  - Association for Computing Machinery
SN  - 978-1-60558-247-4
UR  - https://doi.org/10.1145/1520340.1520706
KW  - tangible
KW  - children
KW  - communication tools
KW  - toys
ER  - 

TY  - CONF
TI  - Advances in voxel-based 6-DOF haptic rendering
AU  - McNeely, William A.
AU  - Puterbaugh, Kevin D.
AU  - Troy, James J.
T3  - Siggraph '05
AB  - An approach is presented for realizing an order-of-magnitude improvement in spatial accuracy for voxel-based 6-DOF haptics. It trades constant-time performance for greater spatial accuracy. This helps to make 6-DOF haptics applicable to extraordinarily complex real-world task simulations, which often admit no other known solution short of physical mockup. A reduction of haptic fidelity is tactically incurred but simultaneously mitigated by augmenting standard voxel-sampling methodology with distance fields, temporal coherence, and culling of redundant polyhedral surface interactions. This is applied to large-scale haptic scenarios involving multiple moving objects and to collaborative virtual environments.
C1  - Los Angeles, California
C3  - ACM SIGGRAPH 2005 courses
DA  - 2005///
PY  - 2005
DO  - 10.1145/1198555.1198606
SP  - 50
EP  - es
PB  - Association for Computing Machinery
SN  - 978-1-4503-7833-8
UR  - https://doi.org/10.1145/1198555.1198606
KW  - haptics
KW  - collaborative virtual environments
KW  - collision detection
KW  - physically based modeling
KW  - voxel sampling
ER  - 

TY  - CONF
TI  - Two-step gaze guidance
AU  - Kwok, Tiffany C.K.
AU  - Kiefer, Peter
AU  - Raubal, Martin
T3  - Icmi '22
AB  - One challenge of providing guidance for search tasks consists in guiding the user’s visual attention to certain objects in a potentially large search space. Previous work has tried to guide the user’s attention by providing visual, audio, or haptic cues. The state-of-the-art methods either provide hints pointing towards the approximate direction of the target location for a fast but less accurate search or require the user to perform a fine-grained search from the beginning for a precise yet less efficient search. To combine the advantage of both methods, we propose an interaction concept called Two-Step Gaze Guidance. The first-step guidance focuses on quick guidance toward the approximate direction, and the second-step guidance focuses on fine-grained guidance toward the exact location of the target. A between-subject study (N = 69) with five conditions was carried out to compare the two-step gaze guidance method with the single-step gaze guidance method. Results revealed that the proposed method outperformed the single-step gaze guidance method. More precisely, the introduction of Two-Step Gaze Guidance slightly improves the searching accuracy, and the use of spatial audio as the first-step guidance significantly helps in enhancing the searching efficiency. Our results also indicated several design suggestions for designing gaze guidance methods.
C1  - Bengaluru, India
C3  - Proceedings of the 2022 international conference on multimodal interaction
DA  - 2022///
PY  - 2022
DO  - 10.1145/3536221.3556612
SP  - 299
EP  - 309
PB  - Association for Computing Machinery
SN  - 978-1-4503-9390-4
UR  - https://doi.org/10.1145/3536221.3556612
KW  - haptic feedback
KW  - audio feedback
KW  - gaze-guidance
KW  - non-visual guidance
ER  - 

TY  - CONF
TI  - Toward immersive telecommunication: 3D video avatar with physical interaction
AU  - Lee, Sang-Yup
AU  - Kim, Ig-Jae
AU  - Ahn, Sang C.
AU  - Lim, Myo-Taeg
AU  - Kim, Hyoung-Gon
T3  - Icat '05
AB  - Immersive telecommunication is a new challenging field that enables a user to share a virtual space with remote participants. The main objective is to offer rich communication modalities, as similar as those used in the face-to-face meetings like gestures, gaze awareness, realistic images, and correct sound direction. Moreover, full body interaction with physics simulation is presented as a natural interface. As a result, the user can be immersed and has interaction with virtual objects including remote participants. This would overcome the limitations both of the conventional video-based telecommunication and also the VR-based collaborative virtual environment approaches.
C1  - Christchurch, New Zealand
C3  - Proceedings of the 2005 international conference on augmented tele-existence
DA  - 2005///
PY  - 2005
DO  - 10.1145/1152399.1152411
SP  - 56
EP  - 61
PB  - Association for Computing Machinery
SN  - 0-473-10657-4
UR  - https://doi.org/10.1145/1152399.1152411
KW  - mixed reality
KW  - 3D video avatar
KW  - telepresences
ER  - 

TY  - CONF
TI  - Practice-informed patterns for organising large groups in distributed mixed reality collaboration
AU  - Wong, Emily
AU  - Sánchez Esquivel, Juan
AU  - Leiva, Germán
AU  - Grønbæk, Jens Emil Sloth
AU  - Velloso, Eduardo
T3  - Chi '24
AB  - Collaborating across dissimilar, distributed spaces presents numerous challenges for computer-aided spatial communication. Mixed reality (MR) can blend selected surfaces, allowing collaborators to work in blended f-formations (facing formations), even when their workstations are physically misaligned. Since collaboration often involves more than just participant pairs, this research examines how we might scale MR experiences for large-group collaboration. To do so, this study recruited collaboration designers (CDs) to evaluate and reimagine MR for large-scale collaboration. These CDs were engaged in a four-part user study that involved a technology probe, a semi-structured interview, a speculative low-fidelity prototyping activity and a validation session. The outcomes of this paper contribute (1) a set of collaboration design principles to inspire future computer-supported collaborative work, (2) eight collaboration patterns for blended f-formations and collaboration at scale and (3) theoretical implications for f-formations and space-place relationships. As a result, this work creates a blueprint for scaling collaboration across distributed spaces.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI conference on human factors in computing systems
DA  - 2024///
PY  - 2024
DO  - 10.1145/3613904.3642502
PB  - Association for Computing Machinery
SN  - 979-8-4007-0330-0
UR  - https://doi.org/10.1145/3613904.3642502
KW  - mixed reality
KW  - collaboration
KW  - f-formations
KW  - scale
KW  - space and place
ER  - 

TY  - CONF
TI  - Tangible construction kit for blind and partially sighted drawers: Co-designing a cross-sensory 3D interface with blind and partially sighted drawers during covid-19
AU  - Kamat, Mitali
AU  - Uribe Quevedo, Alvaro
AU  - Coppin, Peter
T3  - Tei '22
AB  - Drawing as an activity aids problem solving, collaboration, and presentation in design, science, and engineering and artistic creativity as well as expression in the arts. Unfortunately, blind, and partially sighted learners still lack an inclusive and effective drawing tool, even in the digital age. In response, this research aims to explore what an effective drawing tool for blind and partially sighted individuals (BPSI) would be. Raised-line drawing kits aim to provide this, but in prior work, our usability tests of raised line graphics with blind and partially sighted participants rated the raised line graphics that we tested as barely comprehensible relative to 3D models, which they rated as highly comprehensible. Semi-structured interviews with our participants afterward suggest that they found 3D models to be more comprehensible because these are consistent with haptic principles of perception whereas conventions of raised line graphics, such as a line representing a surface edge, replicate visual cues of source images and thereby violate haptic principles of perception. Therefore, we hypothesize that a drawing tool for blind and partially sighted drawers could be effective by recruiting affordances of 3D models. Through co-design sessions conducted during the Covid-19 pandemic with blind and partially sighted drawers (BPSD), we prototyped a tangible 3D model construction kit for non-visual haptic drawing with a digital interface to a 3D virtual environment. Our current investigation of user needs is informing us of our ongoing iterative development of an accessible 3D scanning application that is enabling blind and partially sighted individuals to build and scan in 3D models constructed from a more flexible range of materials beyond what was possible with our previous prototype.
C1  - Daejeon, Republic of Korea
C3  - Proceedings of the sixteenth international conference on tangible, embedded, and embodied interaction
DA  - 2022///
PY  - 2022
DO  - 10.1145/3490149.3505580
PB  - Association for Computing Machinery
SN  - 978-1-4503-9147-4
UR  - https://doi.org/10.1145/3490149.3505580
KW  - 3D Drawing
KW  - Blind and Partially Sighted
KW  - Haptic Drawing
KW  - Tangible User Interface
ER  - 

TY  - CONF
TI  - DJuggling: Sonification of expressive movement performance
AU  - Leischner, Vojtěch Žák
AU  - Husa, Pavel
T3  - Siggraph '23
AB  - In the real-time demo, we demonstrate how to create a musical performance using juggling movement as an instrument. We have equipped juggling balls with accelerometers, gyroscopes, and WiFi sensors. The system measures acceleration and rotation in a small HW footprint, allowing us to map various events to music. We provide hardware and software platforms to ease the creation of real-time live performances for artists and researchers alike. A movement-driven controller can be used to create music, trigger media or lights in theater performances, serve as a lighting console or VR controller, or track performance in sports or scientific experiments. We provide OSC and MIDI APIs that are widely used in before mentioned fields.
C1  - Los Angeles, CA, USA
C3  - ACM SIGGRAPH 2023 real-time live!
DA  - 2023///
PY  - 2023
DO  - 10.1145/3588430.3597246
PB  - Association for Computing Machinery
SN  - 979-8-4007-0158-0
UR  - https://doi.org/10.1145/3588430.3597246
KW  - performance
KW  - movement
KW  - music performance
KW  - demo
KW  - haptic interface
KW  - juggling
KW  - MIDI
KW  - musical instrument
KW  - OSC
KW  - postdigital
KW  - realtime
KW  - sonification
KW  - spatial audio
KW  - synesthesia
KW  - synthetizer
ER  - 

TY  - CONF
TI  - CollaXRSearch: a collaborative virtual reality system for lifelog retrieval
AU  - Ly, Duy-Nam
AU  - Duong-Le, Dinh-Thuan
AU  - Vuong, Gia Huy
AU  - Ho, Van-Son
AU  - Ninh, Van-Tu
AU  - Tran, Minh-Triet
AU  - Le, Khanh-Duy
T3  - Lsc '24
AB  - In lifelog data search, despite automatic supports for identifying relevant pieces of information, the processes of inputting queries and filtering information from the generated results still heavily rely on human searchers.With the rapid increase in volume of such data, these tasks could become both mentally and physically tedious for an individual to perform. In this paper, we present CollaXRSearch, a collaborative virtual reality (VR) information retrieval system, which we aim to use for participating at the Lifelog Search Challenge 2024. This is a collaborative virtual reality system based on a heterogeneous setup of VR headsets, mobile devices and public displays. Its purpose is to facilitate coordination between teammates in terms of inputting and exploration operations in lifelog search.For efficiently providing textual query input and filtering, this system utilizes an interface which can be operated on a personal computer or a mobile device. Search results returned by the engine will be displayed in a VR environment where a user wearing a VR headset can explore to identify suitable items. To reduce the workload for the VR user during the searching process, we employs collaborative VR interface designs on a large physical display which enable he/she to communicate findings on the search results to the rest of the team. In this paper, we describe the conceptual interface and interaction designs of aforementioned setup.
C1  - Phuket, Thailand
C3  - Proceedings of the 7th annual ACM workshop on the lifelog search challenge
DA  - 2024///
PY  - 2024
DO  - 10.1145/3643489.3661125
SP  - 76
EP  - 81
PB  - Association for Computing Machinery
SN  - 979-8-4007-0550-2
UR  - https://doi.org/10.1145/3643489.3661125
KW  - VR
KW  - collaborative interface
KW  - heterogeneous system
KW  - interactive retrieval
KW  - lifelog
ER  - 

TY  - JOUR
TI  - A haptic tool for group work on geometrical concepts engaging blind and sighted pupils
AU  - Moll, Jonas
AU  - Pysander, Eva-Lotta Sallnäs
T2  - ACM Trans. Access. Comput.
AB  - In the study presented here, two haptic and visual applications for learning geometrical concepts in group work in primary school have been designed and evaluated. The aim was to support collaborative learning among sighted and visually impaired pupils. The first application is a static flattened 3D environment that supports learning to distinguish between angles by means of a 3D haptic device providing touch feedback. The second application is a dynamic 3D environment that supports learning of spatial geometry. The scene is a room with a box containing geometrical objects, which pupils can pick up and move around. The applications were evaluated in four schools with groups of two sighted and one visually impaired pupil. The results showed the support for the visually impaired pupil and for the collaboration to be satisfying. A shared understanding of the workspace could be achieved, as long as the virtual environment did not contain movable objects. Verbal communication was crucial for the work process but haptic guiding to some extent substituted communication about direction. When it comes to joint action between visually impaired and sighted pupils a number of interesting problems were identified when the dynamic and static virtual environments were compared. These problems require further investigation. The study extends prior work in the areas of assistive technology and multimodal communication by evaluating functions for joint haptic manipulation in the unique setting of group work in primary school.
DA  - 2013/07//
PY  - 2013
DO  - 10.1145/2493171.2493172
VL  - 4
IS  - 4
SN  - 1936-7228
UR  - https://doi.org/10.1145/2493171.2493172
ER  - 

TY  - BOOK
TI  - SUI '22: Proceedings of the 2022 ACM symposium on spatial user interaction
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9948-7
ER  - 

TY  - JOUR
TI  - A scoping survey on cross-reality systems
AU  - Auda, Jonas
AU  - Gruenefeld, Uwe
AU  - Faltaous, Sarah
AU  - Mayer, Sven
AU  - Schneegass, Stefan
T2  - Acm Computing Surveys
AB  - Immersive technologies such as Virtual Reality (VR) and Augmented Reality (AR) empower users to experience digital realities. Known as distinct technology classes, the lines between them are becoming increasingly blurry with recent technological advancements. New systems enable users to interact across technology classes or transition between them—referred to as cross-reality systems. Nevertheless, these systems are not well understood. Hence, in this article, we conducted a scoping literature review to classify and analyze cross-reality systems proposed in previous work. First, we define these systems by distinguishing three different types. Thereafter, we compile a literature corpus of 306 relevant publications, analyze the proposed systems, and present a comprehensive classification, including research topics, involved environments, and transition types. Based on the gathered literature, we extract nine guiding principles that can inform the development of cross-reality systems. We conclude with research challenges and opportunities.
DA  - 2023/10//
PY  - 2023
DO  - 10.1145/3616536
VL  - 56
IS  - 4
J2  - ACM Comput. Surv.
SN  - 0360-0300
UR  - https://doi.org/10.1145/3616536
KW  - virtual reality
KW  - augmented reality
KW  - augmented virtuality
KW  - collaboration
KW  - bystander inclusion
KW  - Cross-reality systems
KW  - reality-virtuality continuum
KW  - transitional interfaces
ER  - 

TY  - CONF
TI  - Wheeler: a three-wheeled input device for usable, efficient, and versatile non-visual interaction
AU  - Islam, Md Touhidul
AU  - Sojib, Noushad
AU  - Kabir, Imran
AU  - Amit, Ashiqur Rahman
AU  - Amin, Mohammad Ruhul
AU  - Billah, Syed Masum
T3  - Uist '24
AB  - Blind users rely on keyboards and assistive technologies like screen readers to interact with user interface (UI) elements. In modern applications with complex UI hierarchies, navigating to different UI elements poses a significant accessibility challenge. Users must listen to screen reader audio descriptions and press relevant keyboard keys one at a time. This paper introduces Wheeler, a novel three-wheeled, mouse-shaped stationary input device, to address this issue. Informed by participatory sessions, Wheeler enables blind users to navigate up to three hierarchical levels in an app independently using three wheels instead of navigating just one level at a time using a keyboard. The three wheels also offer versatility, allowing users to repurpose them for other tasks, such as 2D cursor manipulation. A study with 12 blind users indicates a significant reduction (40
C1  - Pittsburgh, PA, USA
C3  - Proceedings of the 37th annual ACM symposium on user interface software and technology
DA  - 2024///
PY  - 2024
DO  - 10.1145/3654777.3676396
PB  - Association for Computing Machinery
SN  - 979-8-4007-0628-8
UR  - https://doi.org/10.1145/3654777.3676396
KW  - haptics
KW  - blind
KW  - input device
KW  - mouse
KW  - multi-wheel
KW  - Non-visual interaction
KW  - rotational input
KW  - vision impairments.
ER  - 

TY  - CONF
TI  - Effects of information widgets on time perception during mentally demanding tasks
AU  - Li, Zengrui
AU  - Shi, Di
AU  - Gao, Qijun
AU  - Chen, Yichen
AU  - Wang, Nanyi
AU  - Ren, Xipei
T3  - Chi '25
AB  - This article examined how different time and task management information widgets affect time perception across modalities. In mentally demanding office environments, effective countdown representations are crucial for enhancing temporal awareness and productivity. We developed TickSens, a set of information widgets with different modalities, and conducted a within-subjects experiment with 30 participants to evaluate the five types of time perception modes: visual, auditory, haptic, as well as the blank and the timer modes. Our assessment focused on the technology acceptance, cognitive performance and emotional responses. Results indicated that compared to the blank and the timer modes, the use of modalities significantly improved the cognitive performance and positive emotional responses, and was better received by participants. The visual mode had the best task performance, while the auditory feedback was effective in boosting focus and the haptic mode significantly enhances user acceptance. The study revealed varied user preferences that enlightened the integration of these widgets into office.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713270
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713270
ER  - 

TY  - JOUR
TI  - Augmented human, extended machine: extended reality systems for robotic fabrication in architecture, engineering, and construction
AU  - Mitterberger, Daniela
T2  - XRDS
AB  - How can we trigger the process of digital embodiment and corporeality in human-robot collaboration through extended reality and digitally enhanced environments?
DA  - 2022/10//
PY  - 2022
DO  - 10.1145/3558196
VL  - 29
IS  - 1
SP  - 48
EP  - 53
SN  - 1528-4972
UR  - https://doi.org/10.1145/3558196
ER  - 

TY  - CONF
TI  - Understanding takeovers and telestration in laparoscopic surgery to inform telementoring system design
AU  - Lambert, Solène
AU  - Voros, Sandrine
AU  - Canlorbe, Geoffroy
AU  - Troccaz, Jocelyne
AU  - Avellino, Ignacio
T3  - Chi '24
AB  - Surgery is primarily taught through mentoring, where an expert mentor supervises a mentee performing surgery, taking over when necessary. Telementoring systems aim to provide mentees with access to remote mentors, but the physical distance between mentors and mentees poses unique challenges to surgical training. We investigate the underlying needs leading to takeovers in onsite mentoring and assess mentors’ ability to fulfill address these needs remotely using existing telestration tools, namely pointers and drawings on shared views. Through interviews and workshops with expert surgeons, we find that (1) mentors take over to convey gestures related to instrument placement, tissue displacement, force, and movement, (2) mentors gather information about location of tissue, equipment, and instruments, as well as gesture constraints, and (3) surgeons judge telestration insufficient for these needs. Based on this gap between onsite mentoring practices and telementoring tools, we discuss novel tools to address these needs and their evaluation.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI conference on human factors in computing systems
DA  - 2024///
PY  - 2024
DO  - 10.1145/3613904.3641978
PB  - Association for Computing Machinery
SN  - 979-8-4007-0330-0
UR  - https://doi.org/10.1145/3613904.3641978
KW  - gestures
KW  - remote instruction
KW  - surgical telementoring
KW  - takeovers
ER  - 

TY  - JOUR
TI  - Supporting presence in collaborative environments by haptic force feedback
AU  - Sallnäs, Eva-Lotta
AU  - Rassmus-Gröhn, Kirsten
AU  - Sjöström, Calle
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - An experimental study of interaction in a collaborative desktop virtual environment is described. The aim of the experiment was to investigate if added haptic force feedback in such an environment affects perceived virtual presence, perceived social presence, perceived task performance, and task performance. A between-group design was employed, where seven pairs of subjects used an interface with graphic representation of the environment, audio connection, and haptic force feedback. Seven other pairs of subjects used an interface without haptic force feedback, but with identical features otherwise. The PHANToM, a one-point haptic device, was used for the haptic force feedback, and a program especially developed for the purpose provided the virtual environment. The program enables for two individuals placed in different locations to simultaneously feel and manipulate dynamic objects in a shared desktop virtual environment. Results show that haptic force feedback significantly improves task performance, perceived task performance, and pereceived virtual presence in the collaborative distributed environment. The results suggest that haptic force feedback increases perceived social presence, but the difference is not significant.
DA  - 2000/12//
PY  - 2000
DO  - 10.1145/365058.365086
VL  - 7
IS  - 4
SP  - 461
EP  - 476
SN  - 1073-0516
UR  - https://doi.org/10.1145/365058.365086
KW  - presence
KW  - distributed collaboration
KW  - haptic force feedback
ER  - 

TY  - JOUR
TI  - Agents of MASK: Mobile analytics from situated knowledge
AU  - ElSayed, Neven
AU  - Veas, Eduardo
AU  - Schmalstieg, Dieter
T2  - Interactions
DA  - 2024/01//
PY  - 2024
DO  - 10.1145/3633521
VL  - 31
IS  - 1
SP  - 48
EP  - 55
SN  - 1072-5520
UR  - https://doi.org/10.1145/3633521
ER  - 

TY  - CONF
TI  - Spatial heterogeneity in distributed mixed reality collaboration
AU  - Wong, Emily
AU  - Genay, Adélaı̈de
AU  - Grønbæk, Jens Emil Sloth
AU  - Velloso, Eduardo
T3  - Chi '25
AB  - Collaborative Mixed Reality (MR) enables embodied meetings for distributed collaborators working across a variety of locations. However, providing a coherent experience for all users regardless of the spatial configurations of their respective physical environments is a central challenge. We present the Spatial Heterogeneity Framework, which breaks the problem into four core components: the activity zones, heterogeneity ladder, blended proxemics, and MR solutions matrix. We explain the interplay between these components, demonstrating their interconnectivity via a case study. Our framework enables researchers to navigate differences and trade-offs between solutions for distributed MR collaboration. It also supports designers to think about the role of space, technology, and social behaviours in MR collaboration. Ultimately, our contributions advance the field by conceptualising the challenges of spatial heterogeneity and strategies to overcome them.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3714033
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3714033
KW  - Proxemics
KW  - Mixed Reality
KW  - Distributed Collaboration
KW  - Spatial Heterogeneity
ER  - 

TY  - CONF
TI  - Reverse vampire UI: Reflecting on AR interaction with smart mirrors
AU  - Rigling, Sebastian
AU  - Avdić, Ševal
AU  - Özver, Muhammed Enes
AU  - Sedlmair, Michael
T3  - Chi ea '25
AB  - Mirror surfaces can be used as information displays in smart homes and even for augmented reality (AR). The big advantage is the seamless integration of the visual output into the user’s natural environment. However, user input poses a challenge. On the one hand, touch input would make the mirror dirty. On the other hand, mid-air gestures have proven to be less accurate, slower and more error-prone. We propose the use of an AR user interface (UI): Interactive UI elements are visible “on the other side of the mirror” and can be pressed by the user’s reflection. We built a functional prototype and investigated whether this is a viable option for interacting with mirrors. In a pilot study, we compared the interaction with UI elements placed on three different planes relative to the mirror surface: Behind the mirror (reflection), on the mirror (touch) and in front of the mirror (hologram).
C1  - New York, NY, USA
C3  - Proceedings of the extended abstracts of the CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706599.3719930
PB  - Association for Computing Machinery
SN  - 979-8-4007-1395-8
UR  - https://doi.org/10.1145/3706599.3719930
KW  - augmented reality
KW  - interaction
KW  - mirror
ER  - 

TY  - CONF
TI  - Social touch as an allostatic tool in cooperative multi-agent reinforcement learning
AU  - Ozdemir, Yagmur Idil
AU  - Gatti, Elia
T3  - Chi ea '25
AB  - This study explores the computational modeling of social touch in a cooperative multi-agent reinforcement learning (MARL) setting. Inspired by research on social allostasis and affective neurobiology, we implement a novel model of social touch in artificial agents within a cooperative game setting, where interoception-inspired internal states are modulated by eating and agent-to-agent contact. A memory-augmented Proximal Policy Optimization (PPO) is used to explore and exploit social touch for cooperative reward optimization and internal state regulation. Our paradigm reveals that agents trained with modulatory social touch achieve better game performance, even in environments where touch is ineffective. We observe an evolution of touch behavior from frequent exploration to selective usage, showing better internal-state regulation and adaptability to heterogeneous starting conditions between agents. The findings demonstrate how interactive systems might incorporate non-verbal communication cues to enhance cooperation, with implications for designing more intuitive human-AI and robot-robot collaborative systems.
C1  - New York, NY, USA
C3  - Proceedings of the extended abstracts of the CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706599.3720216
PB  - Association for Computing Machinery
SN  - 979-8-4007-1395-8
UR  - https://doi.org/10.1145/3706599.3720216
KW  - HCI
KW  - Haptics
KW  - Affective Neuroscience
KW  - Cooperation
KW  - Embodied Cognition
KW  - Multi-agent Reinforcement Learning
KW  - Social Allostasis
KW  - Social Touch
ER  - 

TY  - CONF
TI  - Optimizing curve-based selection with on-body surfaces in virtual environments
AU  - Li, Xiang
AU  - Kristensson, Per Ola
T3  - Chi ea '25
AB  - Virtual Reality (VR) interfaces often rely on linear ray-casting for object selection but struggle with precision in dense or occluded environments. This late-breaking work introduces an optimized dual-layered selection mechanism combining dynamic Bézier Curves, controlled via finger gestures, with on-body interaction surfaces to enhance precision and immersion. Bézier Curves offer fine-grained control and flexibility in complex scenarios, while on-body surfaces project nearby virtual objects onto the user’s forearm, leveraging proprioception and tactile feedback. A preliminary qualitative study (N = 24) compared two interaction paradigms (Bézier Curve vs. Linear Ray) and two interaction media (On-body vs. Mid-air). Participants praised the Bézier Curve’s ability to target occluded objects but noted the physical demand. On-body interactions were favored for their immersive qualities, while mid-air interactions were appreciated for maintaining focus on the virtual scene. These findings highlight the importance of balancing ease of learning and precise control when designing VR selection techniques, opening avenues for further exploration of curve-based and on-body interactions in dense virtual environments.
C1  - New York, NY, USA
C3  - Proceedings of the extended abstracts of the CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706599.3719908
PB  - Association for Computing Machinery
SN  - 979-8-4007-1395-8
UR  - https://doi.org/10.1145/3706599.3719908
KW  - Virtual Reality
KW  - Mixed Reality
KW  - B\'{e}zier Curve
KW  - Disambiguation
KW  - Object Selection
KW  - On-Body Interaction
ER  - 

TY  - CONF
TI  - The effects of network delay on task performance in a visual-haptic collaborative environment
AU  - Lambeth, Benjamin M.
AU  - LaPlant, James
AU  - Clapan, Elena
AU  - Hamza-Lup, Felix G.
T3  - Acmse '09
AB  - Computer networks have grown considerably over the past decade. Faster and cheaper Internet connections have brought millions of PCs into a domain where rich content and fast downloads have become a necessity. New technology such as haptics must integrate into the existing infrastructures if it is to be considered a viable resource. As with visual and audio that preceded it, haptics too will find its home on the Internet. This research investigates the problems inherent in networks that haptic technology must overcome to make the step from a fascinating technology to a practical one.
C1  - Clemson, South Carolina
C3  - Proceedings of the 47th annual ACM southeast conference
DA  - 2009///
PY  - 2009
DO  - 10.1145/1566445.1566527
PB  - Association for Computing Machinery
SN  - 978-1-60558-421-8
UR  - https://doi.org/10.1145/1566445.1566527
KW  - haptics
KW  - collaborative virtual environments
KW  - network delays
ER  - 

TY  - CONF
TI  - Simulation-based FABO first-aid education: a scoping review
AU  - Wang, Jiaxi
AU  - Yoo, Soojeong
T3  - Chi ea '25
AB  - While simulation-based FABO (foreign body airway obstruction) emergency training has been common practice for medical professional, few studies have investigated the needs of the public first responders. To understand design trends, gaps and opportunities for simulation-based first aid training in this context, researchers conducted a scoping review across four databases and this process yielded 19 eligible papers that shared the design and application of simulation-based education in the FABO setting. Through this analysis, we understand the state-of-art in simulation content themes, design considerations and technologies discussed in these papers, identifying key research opportunities and challenges for the future. Dominant design strategies include (1) skill acquisition and decision making, (2) interactive procedure guidance, and (3) evaluation of the learning outcome. Key underlying design considerations are immersion and presence, as well as preparation emotion for the real-world scenes. Notably, knowledge retention, cognitive load, holistic scenarios, multi-sensory interaction are ought to be stressed for future layperson centred FABO simulation.
C1  - New York, NY, USA
C3  - Proceedings of the extended abstracts of the CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706599.3719741
PB  - Association for Computing Machinery
SN  - 979-8-4007-1395-8
UR  - https://doi.org/10.1145/3706599.3719741
KW  - virtual reality
KW  - mixed reality
KW  - simulation
KW  - airway emergencies
KW  - airway obstruction
KW  - choking
KW  - first-aid
KW  - medical education
KW  - pediatric airways
ER  - 

TY  - JOUR
TI  - What is happening behind the wall? Towards a better understanding of a hidden robot's intent by multimodal cues
AU  - Kassem, Khaled
AU  - Ungerböck, Tobias
AU  - Wintersberger, Philipp
AU  - Michahelles, Florian
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Research in human-robot collaboration explores aspects of using interaction modalities and their effect on human perception. Particular attention is paid to intent communication, which is essential for successful interaction and collaboration. This work investigates the effect of using audio, visual, and haptic feedback on intent communication in a human-robot collaboration task where the collaborators do not share a direct line of sight. A user study was conducted in virtual reality with 20 participants. Qualitative and quantitative feedback was collected from all participants. When compared with a baseline of no feedback given to the participants, results show that using visual feedback had a significant impact on task efficiency, user experience, and cognitive load. Audio feedback was slightly less impactful, while haptic feedback had a divisive effect. Multimodal feedback combining the three modalities showed the highest impact compared to the individual modalities, leading to the highest task efficiency and user experience, and the lowest cognitive load.
DA  - 2022/09//
PY  - 2022
DO  - 10.1145/3546731
VL  - 6
IS  - MHCI
UR  - https://doi.org/10.1145/3546731
KW  - user studies
KW  - human-robot interaction
KW  - robotics
KW  - human-robot collaboration
ER  - 

TY  - CONF
TI  - VRCaptions: Design captions for DHH users in multiplayer communication in VR
AU  - Xie, Tianze
AU  - Zhang, Xuesong
AU  - Huang, Feiyu
AU  - Liu, Di
AU  - An, Pengcheng
AU  - Je, Seungwoo
T3  - Chi '25
AB  - Accessing auditory information remains challenging for DHH individuals in real-world situations and multiplayer VR interactions. To improve this, we investigated caption designs that specialize in the needs of DHH users in multiplayer VR settings. First, we conducted three co-design workshops with DHH participants, social workers, and designers to gather insights into the specific needs of design directions for DHH users in the context of a room escape game in VR. We further refined our designs with 13 DHH users to determine the most preferred features. Based on this, we developed VRCaptions, a caption prototype for DHH users to better experience multiplayer conversations in VR. We lastly invited two mixed-hearing groups to participate in the VR room escape game with our VRCaptions to validate. The results demonstrate that VRCaptions can enhance the ability of DHH participants to access information and reduce the barrier to communication in VR.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3714186
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3714186
KW  - Virtual Reality
KW  - Communication
KW  - Accessibility
KW  - Caption Design
KW  - Deaf and Hard of Hearing
ER  - 

TY  - JOUR
TI  - Immersive multimedia communication: State-of-the-art on extended reality streaming
AU  - Wang, Haopeng
AU  - Dong, Haiwei
AU  - El Saddik, Abdulmotaleb
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
AB  - Extended reality (XR) is rapidly advancing and poised to revolutionize content creation and consumption. In XR, users integrate various sensory inputs to form a cohesive perception of the virtual environment. This survey reviews the state-of-the-art in XR streaming, focusing on multiple paradigms. To begin, we define XR and introduce various XR headsets along with their multimodal interaction methods to provide a foundational understanding. We then analyze XR traffic characteristics to highlight the unique data transmission requirements. We also explore factors that influence the quality of experience in XR systems, aiming to identify key elements for enhancing user satisfaction. Following this, we present visual attention-based optimization methods for XR streaming to improve efficiency and performance. Finally, we examine current applications and highlight challenges to provide insights into ongoing and future developments of XR.
DA  - 2025/07//
PY  - 2025
DO  - 10.1145/3721292
VL  - 21
IS  - 7
SN  - 1551-6857
UR  - https://doi.org/10.1145/3721292
KW  - Virtual Reality
KW  - Augmented Reality
KW  - Mixed Reality
KW  - eXtended Reality
KW  - Deep Learning
KW  - XR Streaming
ER  - 

TY  - CONF
TI  - Scaling distributed collaboration in mixed reality
AU  - Genay, Adélaı̈de
AU  - Syiem, Brandon Victor
AU  - Wong, Emily
AU  - Feuchtner, Tiare
AU  - Knibbe, Jarrod
AU  - Grønbæk, Jens Emil Sloth
AU  - Velloso, Eduardo
T3  - Chi ea '25
AB  - Distributed collaboration in Mixed Reality (MR) promises to revolutionise how people connect across different physical environments, offering experiences akin to face-to-face interactions. However, previous work has mostly focused on enabling this vision in overly simplified settings such as with only two users interacting in identical distributed environments. Scaling current systems to work with large groups and for common real-life scenarios is a persistent challenge that requires addressing multiple tensions. We identified six challenges: 1) supporting locally congruent actions from heterogeneous remote spaces, 2) communicating accurate user behaviours through virtual representation instead of physical bodies, 3) facilitating organic group interactions within limited physical space, 4) maintaining conversational dynamics even in asynchronous exchanges, 5) providing equal access to physical objects for all participants, and 6) enabling efficient task switching within a complex ecology of applications, devices, and accessibility needs. This workshop aims to gather researchers and practitioners to explore actionable strategies for resolving these challenges. Through a mix of presentations, hands-on activities, and group discussions, participants will generate new ideas and develop a research agenda to articulate the future of MR collaboration systems. The workshop outcomes will include a list of concrete next steps for the community to bring distributed MR collaboration at scale.
C1  - New York, NY, USA
C3  - Proceedings of the extended abstracts of the CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706599.3706722
PB  - Association for Computing Machinery
SN  - 979-8-4007-1395-8
UR  - https://doi.org/10.1145/3706599.3706722
KW  - Collaboration
KW  - Mixed Reality
KW  - Distributed Systems
KW  - Human-Computer Interaction
ER  - 

TY  - CONF
TI  - Intelligent music interfaces: When interactive assistance and augmentation meet musical instruments
AU  - Deja, Jordan Aiko
AU  - Eska, Bettina
AU  - Shrestha, Snehesh
AU  - Hoppe, Matthias
AU  - Karolus, Jakob
AU  - Kosch, Thomas
AU  - Matviienko, Andrii
AU  - Weiß, Andreas
AU  - Marky, Karola
T3  - AHs '23
AB  - The interactive augmentation of musical instruments to foster self-expressiveness and learning has a rich history. Over the past decades, the incorporation of interactive technologies into musical instruments emerged into a new research field requiring strong collaboration between different disciplines. The workshop "Intelligent Music Interfaces" covers a wide range of musical research subjects and directions, including (a) current challenges in musical learning, (b) prototyping for improvements, (c) new means of musical expression, and (d) evaluation of the solutions.
C1  - Glasgow, United Kingdom
C3  - Proceedings of the augmented humans international conference 2023
DA  - 2023///
PY  - 2023
DO  - 10.1145/3582700.3582731
SP  - 379
EP  - 383
PB  - Association for Computing Machinery
SN  - 978-1-4503-9984-5
UR  - https://doi.org/10.1145/3582700.3582731
KW  - Artistic Performance
KW  - Augmented Instruments
KW  - Music Interfaces
KW  - Musical Instruments
KW  - Self-Expression
ER  - 

TY  - CONF
TI  - CaneXR: Building a cane-based XR controller for knowledge work
AU  - Zhang, Yaying
AU  - Li, Ziming
AU  - Shi, Rongkai
AU  - Jones, Brennan
AU  - Liang, Hai-Ning
T3  - Chi ea '25
AB  - While extended reality (XR) has gained traction in entertainment, its application in knowledge work remains limited. This is partially due to challenges of existing interaction methods on facilitating prolonged, high-precision operations without fatiguing the user. Previous research suggests that a "cane" shaped design may mitigate these issues by providing ergonomic arm support. However, designs exploring this configuration are lacking. We present CaneXR, a cane-based controller with ergonomic arm support that provides controls with five degrees of freedom and operates a 3D cursor in the 3D space for object manipulation. We conducted a pilot study on its usability and received positive feedback on the adoption of support. Based on the results, we presented improvement opportunities to iterate on this prototype and expand its supporting features.
C1  - New York, NY, USA
C3  - Proceedings of the extended abstracts of the CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706599.3720121
PB  - Association for Computing Machinery
SN  - 979-8-4007-1395-8
UR  - https://doi.org/10.1145/3706599.3720121
KW  - Extended Reality
KW  - Tangible User Interface
KW  - Cane Stick
KW  - Device Form Factor
KW  - Dynamic Arm Support
KW  - Ergonomic
KW  - Handheld Device
KW  - Knowledge Work
ER  - 

TY  - CONF
TI  - SketCHI 4.0: Hands-on special interest group on remote sketching in HCI
AU  - Sturdee, Miriam
AU  - Lewis, Makayla
AU  - Spiel, Katta
AU  - Priego, Ernesto
AU  - Fernández Camporro, Marina
AU  - Hoang, Thuong
T3  - Chi ea '21
AB  - Sketching is a physical activity: moving a stylus to create marks on paper or screen, from mind to visual output. But sketching can also translate to the virtual space. When we sketch collaboratively, we look for cues, exchange ideas, and annotate work via mark-making or comment. The digital medium has evolved to explore the potentials of sketching online, and this Special Interest Group aims to bring together researchers and practitioners interested in Sketching in HCI to explore the new virtual landscape of sketching, popularised by the constraints of the current world situation. We invite you to join our virtual group, discuss and share sketches, query the existing state-of-the-art, and help pave the way for the development of this medium in the virtual space with your imagery and ideation.
C1  - Yokohama, Japan
C3  - Extended abstracts of the 2021 CHI conference on human factors in computing systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411763.3450401
PB  - Association for Computing Machinery
SN  - 978-1-4503-8095-9
UR  - https://doi.org/10.1145/3411763.3450401
KW  - collaboration
KW  - drawing
KW  - sketching
KW  - visual thinking
KW  - visualisation
ER  - 

TY  - CONF
TI  - Drawxi: An accessible drawing tool for collaboration
AU  - Chiplunkar, Suraj
AU  - Maini, Anany
AU  - Ram, Dinesh
AU  - Zheng, Zixuan
AU  - Zheng, Yaxin
T3  - Chi ea '19
AB  - Visual impairment can profoundly impact well-being and social advancement. Current solutions for accessing graphical information fail to provide an affordable, user-friendly collaborative platform for visually impaired and sighted people to work together. Therefore, sighted users tend to have low expectations from visually impaired people while working in a team. Hence, visually impaired people feel discouraged to participate in a mixed population collaborative environment. Consequently, their generative capabilities remain devalued. In this paper, we propose an audio-haptic enabled tool (Drawxi) for free-form sketching and sharing simple diagrams (processes, workflows, ideas, perspectives, etc.). It provides a common platform for visually-impaired and sighted people to work together by communicating each other's ideas visually. Thus, enabling the discovery of generative capabilities in a hands-on way. We relied upon participatory research methods (Contextual inquiry, Co-Design) involving visually impaired participants throughout the design process. We evaluated our proposed design through usability testing which revealed that collaboration between visually impaired and sighted people benefits from the use of common tools and platforms. Thereby, enhancing the degree of their participation in a collaborative environment and quality of co-creation activities.
C1  - Glasgow, Scotland Uk
C3  - Extended abstracts of the 2019 CHI conference on human factors in computing systems
DA  - 2019///
PY  - 2019
DO  - 10.1145/3290607.3309696
SP  - 1
EP  - 6
PB  - Association for Computing Machinery
SN  - 978-1-4503-5971-9
UR  - https://doi.org/10.1145/3290607.3309696
KW  - haptic feedback
KW  - collaboration
KW  - accessibility
KW  - diagrams
KW  - drawing tool
KW  - gestural
KW  - inclusive design
KW  - multi-modal
KW  - touch device
KW  - visual impairment
ER  - 

TY  - CONF
TI  - Evaluating outside the box: Lessons learned on eXtended reality multi-modal experiments beyond the laboratory
AU  - Marques, Bernardo
AU  - Silva, Samuel
AU  - Maio, Rafael
AU  - Alves, João
AU  - Ferreira, Carlos
AU  - Dias, Paulo
AU  - Santos, Beatriz Sousa
T3  - Icmi '23
AB  - Over time, numerous multimodal eXtended Reality (XR) user studies have been conducted in laboratory environments, with participants fulfilling tasks under the guidance of a researcher. Although generalizable results contributed to increase the maturity of the field, it is also paramount to address the ecological validity of evaluations outside the laboratory. Despite real-world scenarios being clearly challenging, successful in-situ and remote deployment has become realistic to address a broad variety of research questions, thus, expanding participants’ sample to more specific target users, considering multi-modal constraints not reflected in controlled laboratory settings and other benefits. In this paper, a set of multimodal XR experiments conducted outside the laboratory are described (e.g., industrial field studies, remote collaborative tasks, longitudinal rehabilitation exercises). Then, a list of lessons learned is reported, illustrating challenges, and opportunities, aiming to increase the level of awareness of the research community and facilitate performing further evaluations.
C1  - Paris, France
C3  - Proceedings of the 25th international conference on multimodal interaction
DA  - 2023///
PY  - 2023
DO  - 10.1145/3577190.3614134
SP  - 234
EP  - 242
PB  - Association for Computing Machinery
SN  - 979-8-4007-0055-2
UR  - https://doi.org/10.1145/3577190.3614134
KW  - eXtended Reality
KW  - Ecological Validity
KW  - Lessons Learned
KW  - Multimodal Interaction
KW  - Outside the Laboratory
KW  - User Evaluation
ER  - 

TY  - CONF
TI  - Comparison of performance of virtual coupling schemes for haptic collaboration using real and emulated internet connections
AU  - Sankaranarayanan, Ganesh
AU  - Hannaford, Blake
T3  - RoboComm '07
AB  - Networked haptic virtual environments (NHVEs) are those in which multiple users collaborate and experience force feedback at the same time. The robustness of such systems needs to be tested under various network conditions that closely mirror the Internet. Previously, we had proposed three virtual coupling schemes to maintain position coherency in a NHVE, which were tested using constant and then time-varying delays using the actual Internet through UDP packet reflectors. In this paper we present the results of comparing performance of the virtual coupling schemes for a time varying delay emulated using the popular network emulator NIST Net, with delay conditions that existed during our real Internet experiment to Italy. UDP was used for haptic data communication because of the high transmission rate requirements for NHVEs. Experiments were conducted for three fixed packet transmission rates of 1000, 500 and 100 Hz, and their performance compared using an independent-samples t-test to the data obtained using the Internet. Locally, the haptic update rate was maintained at 1000 Hz during the experiments. Our results show that the NIST Net was a suitable emulator for testing with lower packet transmission rates. At the transmission rate of 1000 Hz the performance of the virtual coupling schemes were significantly different from that of the actual Internet experiment.
C1  - Athens, Greece
C3  - Proceedings of the 1st international conference on robot communication and coordination
DA  - 2007///
PY  - 2007
PB  - IEEE Press
SN  - 978-963-9799-08-0
ER  - 

TY  - CONF
TI  - Intelligent music interfaces: When interactive assistance and adaptive augmentation meet musical instruments
AU  - Kosch, Thomas
AU  - Weiß, Andreas
AU  - Deja, Jordan Aiko
AU  - Shrestha, Snehesh
AU  - Hoppe, Matthias
AU  - Matviienko, Andrii
AU  - Marky, Karola
T3  - AHs '24
AB  - The interactive augmentation of musical instruments to foster self-expression and learning has a rich history. Over the past decades, incorporating interactive technologies into musical instruments has emerged as a research field requiring strong collaboration between disciplines. The workshop “Intelligent Music Interfaces” covers a wide range of musical research subjects and directions, including (a) current challenges in musical learning, (b) prototyping for improvements, (c) new means of musical expression, and (d) evaluation of the solutions.
C1  - Melbourne, VIC, Australia
C3  - Proceedings of the augmented humans international conference 2024
DA  - 2024///
PY  - 2024
DO  - 10.1145/3652920.3653039
SP  - 327
EP  - 330
PB  - Association for Computing Machinery
SN  - 979-8-4007-0980-7
UR  - https://doi.org/10.1145/3652920.3653039
KW  - Augmented Instruments
KW  - Music Interfaces
KW  - Musical Instruments
KW  - Self-Expression
ER  - 

TY  - CONF
TI  - Tangible-3d: hand shaking model
AU  - Ozawa, Shiro
AU  - Abe, Takao
AU  - Ogawa, Takuya
AU  - Ogawara, Masanori
AU  - Hirano, Mitsusnori
AU  - Tanaka, Kazuhiko
T3  - Chi ea '08
AB  - We have developed the ”Hand Shaking Model,” an application of Tangible-3D, which is a new type of remote communication interface, another example of which is the haptic 3D video phone. In this paper, we explain the Hand Shaking Model application, which allows users to shake hands with remote users, one example of Tangible-3D.
C1  - Florence, Italy
C3  - CHI '08 extended abstracts on human factors in computing systems
DA  - 2008///
PY  - 2008
DO  - 10.1145/1358628.1358674
SP  - 2303
EP  - 2308
PB  - Association for Computing Machinery
SN  - 978-1-60558-012-8
UR  - https://doi.org/10.1145/1358628.1358674
KW  - virtual reality
KW  - haptic
KW  - communication
KW  - tangible
KW  - 3d
ER  - 

TY  - CONF
TI  - Exploring the accessibility of social virtual reality for people with ADHD and autism: Preliminary insights
AU  - Collins, Jazmin
AU  - Ko, Woojin
AU  - Shende, Tanisha
AU  - Lin, Sharon Y
AU  - Jiang, Lucy
AU  - Stevenson Won, Andrea
AU  - Azenkot, Shiri
T3  - Assets '24
AB  - Social virtual reality (VR) has become one of the most popular forms of VR. However, despite years of research on how VR interventions can be useful as diagnostic or therapeutic tools for neurodivergent (ND) users, there has been little examination of how accessible social VR may be for such ND individuals. In this paper, we describe an ongoing user study with participants who self-identify with both autism and ADHD (AuDHD) and also self-identify with facing frequent challenges with social interaction. So far, we have recruited four AuDHD participants; we had each participant briefly explore a world on a popular commercial social VR platform and then reflect on this experience afterward in a longer interview section. Through this process, we uncovered various accessibility challenges in social VR, such as difficulties with navigating social norms or managing certain sensory inputs. We also noted ideas on potential accommodations, like a text-based prompt system that can suggest “appropriate” conversation responses. Our work outlines opportunities to improve the accessibility of social VR for an often-overlooked user group.
C1  - St. John's, NL, Canada
C3  - Proceedings of the 26th international ACM SIGACCESS conference on computers and accessibility
DA  - 2024///
PY  - 2024
DO  - 10.1145/3663548.3687134
PB  - Association for Computing Machinery
SN  - 979-8-4007-0677-6
UR  - https://doi.org/10.1145/3663548.3687134
KW  - VR
KW  - accessibility
KW  - ADHD
KW  - autism
KW  - neurodivergence
ER  - 

TY  - CONF
TI  - Digital proxemics: Designing social and collaborative interaction in virtual environments
AU  - Williamson, Julie R.
AU  - O'Hagan, Joseph
AU  - Guerra-Gomez, John Alexis
AU  - Williamson, John H
AU  - Cesar, Pablo
AU  - Shamma, David A.
T3  - Chi '22
AB  - Behaviour in virtual environments might be informed by our experiences in physical environments, but virtual environments are not constrained by the same physical, perceptual, or social cues. Instead of replicating the properties of physical spaces, one can create virtual experiences that diverge from reality by dynamically manipulating environmental, aural, and social properties. This paper explores digital proxemics, which describe how we use space in virtual environments and how the presence of others influences our behaviours, interactions, and movements. First, we frame the open challenges of digital proxemics in terms of activity, social signals, audio design, and environment. We explore a subset of these challenges through an evaluation that compares two audio designs and two displays with different social signal affordances: head-mounted display (HMD) versus desktop PC. We use quantitative methods using instrumented tracking to analyse behaviour, demonstrating how personal space, proximity, and attention compare between desktop PC and HMDs.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI conference on human factors in computing systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491102.3517594
PB  - Association for Computing Machinery
SN  - 978-1-4503-9157-3
UR  - https://doi.org/10.1145/3491102.3517594
KW  - Digital Proxemics
KW  - Quantitative Methods.
KW  - Social Signal Processing
KW  - Virtual Environments
ER  - 

TY  - CONF
TI  - Let’s frets! Mastering guitar playing with capacitive sensing and visual guidance
AU  - Marky, Karola
AU  - Weiß, Andreas
AU  - Müller, Florian
AU  - Schmitz, Martin
AU  - Mühlhäuser, Max
AU  - Kosch, Thomas
T3  - Chi ea '21
AB  - Mastering the guitar requires regular exercise to develop new skills and maintain existing abilities. We present Let’s Frets - a modular guitar support system that provides visual guidance through LEDs that are integrated into a capacitive fretboard to support the practice of chords, scales, melodies, and exercises. Additional feedback is provided through a 3D-printed fretboard that senses the finger positions through capacitive sensing. We envision Let’s Frets as an integrated guitar support system that raises the awareness of guitarists about their playing styles, their training progress, the composition of new pieces, and facilitating remote collaborations between teachers as well as guitar students. This interactivity demonstrates Let’s Frets with an augmented fretboard and supporting software that runs on a mobile device.
C1  - Yokohama, Japan
C3  - Extended abstracts of the 2021 CHI conference on human factors in computing systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411763.3451536
PB  - Association for Computing Machinery
SN  - 978-1-4503-8095-9
UR  - https://doi.org/10.1145/3411763.3451536
KW  - capacitive sensing
KW  - musical instruments
KW  - support setup
ER  - 

TY  - CONF
TI  - Intelligent music interfaces: When interactive assistance and augmentation meet musical instruments
AU  - Marky, Karola
AU  - Kilian, Annika
AU  - Weiß, Andreas
AU  - Karolus, Jakob
AU  - Hoppe, Matthias
AU  - Wozniak, Pawel W.
AU  - Mühlhäuser, Max
AU  - Kosch, Thomas
T3  - Chi ea '22
AB  - The interactive augmentation of musical instruments to foster self-expressiveness and learning has a rich history. Over the past decades, the incorporation of interactive technologies into musical instruments emerged into a new research field requiring strong collaboration between different disciplines. The workshop ”Intelligent Music Interfaces” consequently covers a wide range of musical research subjects and directions, including (a) current challenges in musical learning, (b) prototyping for improvements, (c) new means of musical expression, and (d) evaluation of the solutions.
C1  - New Orleans, LA, USA
C3  - Extended abstracts of the 2022 CHI conference on human factors in computing systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491101.3503743
PB  - Association for Computing Machinery
SN  - 978-1-4503-9156-6
UR  - https://doi.org/10.1145/3491101.3503743
KW  - Artistic Performance
KW  - Augmented Instruments
KW  - Music Interfaces
KW  - Musical Instruments
KW  - Self-Expression
ER  - 

TY  - CONF
TI  - nRoom: an immersive virtual environment for collaborative spatial design
AU  - Zaman, Cagri Hakan
AU  - Yakhina, Asiya
AU  - Casalegno, Federico
T3  - CHIuXiD '15
AB  - In this paper, we present the results of an experimental study aiming to explore the collaborative user experience in an immersive virtual environment. We designed and implemented an application that enables users to collaboratively design a spatial layout using head-mounted VR displays and hand tracking devices. With a strong emphasis on the relationship between spatial interaction and communication, we assert that a shared-view virtual environment allows collaborative articulation of spatial design problems and improves communication between designers. Our study combines qualitative and quantitative methods to test the usability of the proposed system, and to determine the aspects of spatial communication in virtual environments.
C1  - Bandung, Indonesia
C3  - Proceedings of the international HCI and UX conference in indonesia
DA  - 2015///
PY  - 2015
DO  - 10.1145/2742032.2742034
SP  - 10
EP  - 17
PB  - Association for Computing Machinery
SN  - 978-1-4503-3334-4
UR  - https://doi.org/10.1145/2742032.2742034
KW  - virtual reality
KW  - collaborative design
KW  - embodied communication
KW  - gestural interaction
ER  - 

TY  - JOUR
TI  - An experimental study on the role of touch in shared virtual environments
AU  - Basdogan, Cagatay
AU  - Ho, Chih-Hao
AU  - Srinivasan, Mandayam A.
AU  - Slater, Mel
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - Investigating virtual environments has become an increasingly interesting research topic for engineers, computer and cognitive scientists, and psychologists. Although there have been several recent studies focused on the development of multimodal virtual environments (VEs) to study human-machine interactions, less attention has been paid to human-human and human-machine interactions in shared virtual environments (SVEs), and to our knowledge, no attention paid at all to what extent the addition of haptic communication between people would contribute to the shared experience. We have developed a multimodal shared virtual environment and performed a set of experiments with human subjects to study the role of haptic feedback in collaborative tasks and whether haptic communication through force feedback can facilitate a sense of being and collaborating with a remote partner. The study concerns a scenario where two participants at remote sites must cooperate to perform a joint task in an SVE. The goals of the study are (1) to assess the impact of force feedback on task performance, (2) to better understand the role of haptic communication in human-human interactions, (3) to study the impact of touch on the subjective sense of collaborating with a human as reported by the participants based on what they could see and feel, and (4) to investigate if gender, personality, or emotional experiences of users can affect haptic communication in SVEs. The outcomes of this research can have a powerful impact on the development of next-generation human-computer interfaces and network protocols that integrate touch and force feedback technology into the internet, development of protocols and techniques for collaborative teleoperation such as hazardous material removal, space station.
DA  - 2000/12//
PY  - 2000
DO  - 10.1145/365058.365082
VL  - 7
IS  - 4
SP  - 443
EP  - 460
SN  - 1073-0516
UR  - https://doi.org/10.1145/365058.365082
KW  - copresence
KW  - haptic interaction
KW  - shared virtual environments
KW  - force feedback devices
ER  - 

TY  - CONF
TI  - Enhancing human-machine interactions: a novel framework for AR-based digital twin systems in industrial environments
AU  - Grego, Giovanni
AU  - Nenna, Federica
AU  - Gamberini, Luciano
T3  - Petra '24
AB  - Industry 5.0 represents a paradigm shift initiated by the European Commission, which emphasizes human-centricity, sustainability, and resilience in industrial settings. This novel paradigm underscores the importance of giving a central role to humans in every process entailed in the implementation of advanced technologies into work and industrial scenarios. By following this view, in this work, we present a novel human-centric framework integrating Digital Twins (DTs) and Augmented Reality (AR) within a manufacturing setting, focusing on a design and evaluation process that facilitates seamless interaction between humans and machines. This work contributes to the ongoing discourse on Industry 5.0 by offering a twofold yet integrated perspective on humans and novel industrial technologies, providing insights into the transformative potential of integrating AR and DT technologies within industrial settings. From a technical perspective, the framework’s hardware and software specifications, design principles, and technical implementation are elucidated, followed by an evaluation of its responsiveness and spatial accuracy. Results demonstrate the framework’s efficacy in providing real-time monitoring and control of robotic systems. Parallely, the potential impacts of our AR-based digital twin systems on human labor and work routines are discussed, providing a more human-based perspective to complement the technical one.
C1  - Crete, Greece
C3  - Proceedings of the 17th international conference on pervasive technologies related to assistive environments
DA  - 2024///
PY  - 2024
DO  - 10.1145/3652037.3663946
SP  - 456
EP  - 462
PB  - Association for Computing Machinery
SN  - 979-8-4007-1760-4
UR  - https://doi.org/10.1145/3652037.3663946
KW  - Extended Reality
KW  - Digital Twin
KW  - Human-Computer Interaction
KW  - Manufacturing
KW  - Pervasive Devices
KW  - Robotics
ER  - 

TY  - CONF
TI  - VTuber's atelier: The design space, challenges, and opportunities for vtubing
AU  - Kim, Daye
AU  - Lee, Sebin
AU  - Jun, Yoonseo
AU  - Shin, Yujin
AU  - Lee, Jungjin
T3  - Chi '25
AB  - VTubing, the practice of live streaming using virtual avatars, has gained worldwide popularity among streamers seeking to maintain anonymity. While previous research has primarily focused on the social and cultural aspects of VTubing, there is a noticeable lack of studies examining the practical challenges VTubers face in creating and operating their avatars. To address this gap, we surveyed VTubers’ equipment and expanded the live-streaming design space by introducing six new dimensions related to avatar creation and control. Additionally, we conducted interviews with 16 professional VTubers to comprehensively explore their practices, strategies, and challenges throughout the VTubing process. Our findings reveal that VTubers face significant burdens compared to real-person streamers due to fragmented tools and the multi-tasking nature of VTubing, leading to unique workarounds. Finally, we summarize these challenges and propose design opportunities to improve the effectiveness and efficiency of VTubing.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3714107
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3714107
KW  - design space
KW  - live streaming
KW  - virtual avatar
KW  - VTuber
KW  - VTubing equipment
ER  - 

TY  - CONF
TI  - LLM integration in extended reality: a comprehensive review of current trends, challenges, and future perspectives
AU  - Tang, Yiliu
AU  - Situ, Jason
AU  - Cui, Andrea Yaoyun
AU  - Wu, Mengke
AU  - Huang, Yun
T3  - Chi '25
AB  - The rapid evolution of Extended Reality (XR) technologies—encompassing Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR)—has paved the way for richer and more immersive user experiences. Concurrently, the emergence of Large Language Models (LLMs), such as GPT-4, has unlocked new opportunities to enhance interactions within XR environments. This paper presents the first comprehensive review addressing the underexplored synergy between XR and LLMs, examining how the integration of these technologies can augment various aspects of human awareness: spatial, situational, social, and self-awareness. By systematically analyzing 135 papers, we synthesize and categorize the research field into seven dimensions: 1) diverse application domains, 2) types of human awareness expanded, 3) interaction paradigms between users and systems, 4) effects of LLMs in XR, 5) practices for effectively integrating LLMs into XR environments, and 6) evaluation metrics. We also discuss remaining challenges and propose future research focusing on ethical awareness.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3714224
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3714224
KW  - Extended Reality
KW  - Large Language Models
KW  - Scoping Review
ER  - 

TY  - CONF
TI  - The collaborative cube puzzle: a comparison of virtual and real environments
AU  - Wideström, Josef
AU  - Axelsson, Ann-Sofie
AU  - Schroeder, Ralph
AU  - Nilsson, Alexander
AU  - Heldal, Ilona
AU  - Abelin, Åsa
T3  - Cve '00
AB  - In this study we compared collaboration on a puzzle-solving task carried out by two persons in a virtual and a real environment. The task, putting together a cube consisting of different coloured blocks in a 'Rubiks' cubetype puzzle, was performed both in a shared virtual environment (VE) setting, using a Cave-type virtual reality (VR) system networked with a desktop VR system, and with cardboard coloured blocks in an equivalent real setting. The aims of the study were to investigate collaboration, leadership and performance in the two settings. We found that the participants contributed unequally to the task in the VE, and also differences in collaboration between the virtual and the real setting.
C1  - San Francisco, California, USA
C3  - Proceedings of the third international conference on collaborative virtual environments
DA  - 2000///
PY  - 2000
DO  - 10.1145/351006.351035
SP  - 165
EP  - 171
PB  - Association for Computing Machinery
SN  - 1-58113-303-0
UR  - https://doi.org/10.1145/351006.351035
KW  - virtual reality
KW  - virtual environments
KW  - presence
KW  - collaboration
KW  - co-presence
KW  - leadership
ER  - 

TY  - CONF
TI  - LeARn at home: Comparing augmented reality and video conferencing remote tutoring
AU  - Wittig, Nick
AU  - Drey, Tobias
AU  - Wettig, Theresa
AU  - Auda, Jonas
AU  - Koelle, Marion
AU  - Goedicke, David
AU  - Schneegass, Stefan
T3  - Mum '24
AB  - Remote tutoring has gained significant traction due to technological advances, primarily relying on video-conferencing tools. However, these tools are not specifically designed for tutoring. Positive tutoring experiences rely on interaction with and immediate feedback from the tutor. Moreover, traditional methods like writing, reading, and drawing in physical spaces enhance learning outcomes. Integrating these methods with physical materials and digital remote guidance could improve remote learning experiences. A technology that enables this integration is spatial augmented reality (SAR), which utilizes projection to integrate digital content into the physical world. This work introduces a Spatial Augmented Reality (SAR) remote tutoring tool that enables augmented annotations and projected video streams. We conducted a between-subject lab study (N=18) comparing learning experiences in remote tutoring between standard video conferencing tools and the introduced Spatial Augmented Reality (SAR) tool. Qualitative analysis revealed the Spatial Augmented Reality (SAR) system’s benefits over video conferencing, specifically immediate feedback, in-situ annotations, improved interactivity, and enhanced social presence.
C1  - New York, NY, USA
C3  - Proceedings of the international conference on mobile and ubiquitous multimedia
DA  - 2024///
PY  - 2024
DO  - 10.1145/3701571.3701577
SP  - 255
EP  - 263
PB  - Association for Computing Machinery
SN  - 979-8-4007-1283-8
UR  - https://doi.org/10.1145/3701571.3701577
KW  - education
KW  - augmented surfaces
KW  - remote tutoring
KW  - spatial augmented reality
ER  - 

TY  - CONF
TI  - TRANS-DOCK: Expanding the interactivity of pin-based shape displays by docking mechanical transducers
AU  - Nakagaki, Ken
AU  - Liu, Yingda (Roger)
AU  - Nelson-Arzuaga, Chloe
AU  - Ishii, Hiroshi
T3  - Tei '20
AB  - This paper introduces TRANS-DOCK, a docking system for pin-based shape displays that enhances their interaction capabilities for both the output and input. By simply interchanging the transducer module, composed of passive mechanical structures, to be docked on a shape display, users can selectively switch between different configurations including display sizes, resolutions, and even motion modalities to allow pins moving in a linear motion to rotate, bend and inflate. We introduce a design space consisting of several mechanical elements and enabled interaction capabilities. We then explain the implementation of the docking system and transducer design components. Our implementation includes providing the limitations and characteristics of each motion transmission method as design guidelines. A number of transducer examples are then shown to demonstrate the range of interactivity and application space achieved with the approach of TRANS-DOCK. Potential use cases to take advantage of the interchangeability of our approach are discussed. Through this paper we intend to expand expressibility, adaptability and customizability of a single shape display for dynamic physical interaction. By converting arrays of linear motion to several types of dynamic motion in an adaptable and flexible manner, we advance shape displays to enable versatile embodied interactions.
C1  - Sydney NSW, Australia
C3  - Proceedings of the fourteenth international conference on tangible, embedded, and embodied interaction
DA  - 2020///
PY  - 2020
DO  - 10.1145/3374920.3374933
SP  - 131
EP  - 142
PB  - Association for Computing Machinery
SN  - 978-1-4503-6107-1
UR  - https://doi.org/10.1145/3374920.3374933
KW  - mechanical transducers
KW  - pin-based shape display
KW  - shape changing interfaces
ER  - 

TY  - CONF
TI  - Simulation of ancient technology works using haptic interaction and gesture recognition
AU  - Nikolakis, G.
AU  - Tzovaras, D.
AU  - Malassiotis, S.
AU  - Strintzis, M. G.
T3  - VAST'04
AB  - The objective of the proposed application is the development of a new interactive application for the simulation of Ancient Greek Technology works, with the use of advanced virtual reality and computer vision technologies. In order to achieve these objectives haptic interaction mechanisms and a gesture recognition system were implemented in a virtual environment platform. A novel collision detection method was developed and virtual reality agents were used in order to achieve the desired results. The developed system was evaluated by real users and conclusions were drawn concerning the potentiality of the proposed application.
C1  - Oudenaarde, Belgium
C3  - Proceedings of the 5th international conference on virtual reality, archaeology and intelligent cultural heritage
DA  - 2004///
PY  - 2004
SP  - 261
EP  - 270
PB  - Eurographics Association
SN  - 3-905673-18-5
ER  - 

TY  - CONF
TI  - Single display groupware: a model for co-present collaboration
AU  - Stewart, Jason
AU  - Bederson, Benjamin B.
AU  - Druin, Allison
T3  - Chi '99
AB  - We introduce a model for supporting collaborative work between people that are physically close to each other. We call this model Single Display Groupware (SDG). In this paper, we describe the model, comparing it to more traditional remote collaboration, We describe the requirements that SDG places on computer technology, and our understanding of the benefits and costs of SDG systems. Finally, we describe a prototype SDG system that we built and the results of a usability test we ran with 60 elementary school children.
C1  - Pittsburgh, Pennsylvania, USA
C3  - Proceedings of the SIGCHI conference on human factors in computing systems
DA  - 1999///
PY  - 1999
DO  - 10.1145/302979.303064
SP  - 286
EP  - 293
PB  - Association for Computing Machinery
SN  - 0-201-48559-1
UR  - https://doi.org/10.1145/302979.303064
KW  - CSCW
KW  - children
KW  - educational applications
KW  - input devices
KW  - KidPad
KW  - Pad++
KW  - single display groupware
ER  - 

TY  - CONF
TI  - Augmented reality and robotics: a survey and taxonomy for AR-enhanced human-robot interaction and robotic interfaces
AU  - Suzuki, Ryo
AU  - Karim, Adnan
AU  - Xia, Tian
AU  - Hedayati, Hooman
AU  - Marquardt, Nicolai
T3  - Chi '22
AB  - This paper contributes to a taxonomy of augmented reality and robotics based on a survey of 460 research papers. Augmented and mixed reality (AR/MR) have emerged as a new way to enhance human-robot interaction (HRI) and robotic interfaces (e.g., actuated and shape-changing interfaces). Recently, an increasing number of studies in HCI, HRI, and robotics have demonstrated how AR enables better interactions between people and robots. However, often research remains focused on individual explorations and key design strategies, and research questions are rarely analyzed systematically. In this paper, we synthesize and categorize this research field in the following dimensions: 1) approaches to augmenting reality; 2) characteristics of robots; 3) purposes and benefits; 4) classification of presented information; 5) design components and strategies for visual augmentation; 6) interaction techniques and modalities; 7) application domains; and 8) evaluation strategies. We formulate key challenges and opportunities to guide and inform future research in AR and robotics.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI conference on human factors in computing systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491102.3517719
PB  - Association for Computing Machinery
SN  - 978-1-4503-9157-3
UR  - https://doi.org/10.1145/3491102.3517719
KW  - augmented reality
KW  - mixed reality
KW  - human-robot interaction
KW  - robotics
KW  - actuated tangible UI
KW  - AR-HRI
KW  - shape-changing UI
KW  - VAM-HRI
ER  - 

TY  - CONF
TI  - Videoconferencing in the age of COVID: How well has it worked out?
AU  - Russell, Daniel
AU  - Neustaedter, Carman
AU  - Tang, John
AU  - Judge, Tejinder
AU  - Olson, Gary
T3  - Chi ea '21
AB  - During the past year we've all spent many hours on videoconference calls, sometimes more than was comfortable. While CHI might not have anticipated a viral-driven surge in videoconferencing, online meetings has been a topic of CHI research for the past 25 years. This is a good time to assess how well our research has matched what this natural experiment is telling us. What did we get right? And what did the field get wrong? The panel, comprised of people who directly witnessed much of this history, will reflect on these questions. We don't expect all to agree with each panelist's conclusions, and we will invite reactions and contributions from the audience as well..
C1  - Yokohama, Japan
C3  - Extended abstracts of the 2021 CHI conference on human factors in computing systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411763.3450398
PB  - Association for Computing Machinery
SN  - 978-1-4503-8095-9
UR  - https://doi.org/10.1145/3411763.3450398
KW  - CSCW
KW  - meeting fatigue
KW  - videoconference
ER  - 

TY  - CONF
TI  - bARefoot: Generating virtual materials using motion coupled vibration in shoes
AU  - Strohmeier, Paul
AU  - Güngör, Seref
AU  - Herres, Luis
AU  - Gudea, Dennis
AU  - Fruchard, Bruno
AU  - Steimle, Jürgen
T3  - Uist '20
AB  - Many features of materials can be experienced through tactile cues, even using one's feet. For example, one can easily distinguish between moss and stone without looking at the ground. However, this type of material experience is largely not supported in AR and VR applications. We present bARefoot, a prototype shoe providing tactile impulses tightly coupled to motor actions. This enables generating virtual material experiences such as compliance, elasticity, or friction. To explore the parameter space of such sensorimotor coupled vibrations, we present a design tool enabling rapid design of virtual materials. We report initial explorations to increase understanding of how parameters can be optimized for generating compliance, and to examine the effect of dynamic parameters on material experiences. Finally, we present a series of use cases that demonstrate the potential of bARefoot for VR and AR.
C1  - Virtual Event, USA
C3  - Proceedings of the 33rd annual ACM symposium on user interface software and technology
DA  - 2020///
PY  - 2020
DO  - 10.1145/3379337.3415828
SP  - 579
EP  - 593
PB  - Association for Computing Machinery
SN  - 978-1-4503-7514-6
UR  - https://doi.org/10.1145/3379337.3415828
KW  - virtual reality
KW  - augmented reality
KW  - haptic feedback
KW  - haptic rendering
KW  - body-based interaction
KW  - material experiences
KW  - shoes
KW  - wearable computing
ER  - 

TY  - CONF
TI  - Effect of visual cues on pointing tasks in co-located augmented reality collaboration
AU  - Chen, Lei
AU  - Liu, Yilin
AU  - Li, Yue
AU  - Yu, Lingyun
AU  - Gao, BoYu
AU  - Caon, Maurizio
AU  - Yue, Yong
AU  - Liang, Hai-Ning
T3  - Sui '21
AB  - Visual cues are essential in computer-mediated communication. It is especially important when communication happens in a collaboration scenario that requires focusing several users’ attention on a specific object among other similar ones. This paper explores the effect of visual cues on pointing tasks in co-located Augmented Reality (AR) collaboration. A user study (N = 32, 16 pairs) was conducted to compare two types of visual cues: Pointing Line (PL) and Moving Track (MT). Both are head-based visual techniques. Through a series of collaborative pointing tasks on objects with different states (static and dynamic) and density levels (low, medium and high), the results showed that PL was better on task performance and usability, but MT was rated higher on social presence and user preference. Based on our results, some design implications are provided for pointing tasks in co-located AR collaboration.
C1  - Virtual Event, USA
C3  - Proceedings of the 2021 ACM symposium on spatial user interaction
DA  - 2021///
PY  - 2021
DO  - 10.1145/3485279.3485297
PB  - Association for Computing Machinery
SN  - 978-1-4503-9091-0
UR  - https://doi.org/10.1145/3485279.3485297
KW  - Augmented Reality
KW  - Co-located collaboration
KW  - Pointing Tasks
KW  - Visual cues
ER  - 

TY  - CONF
TI  - RoomShift: Room-scale dynamic haptics for VR with furniture-moving swarm robots
AU  - Suzuki, Ryo
AU  - Hedayati, Hooman
AU  - Zheng, Clement
AU  - Bohn, James L.
AU  - Szafir, Daniel
AU  - Do, Ellen Yi-Luen
AU  - Gross, Mark D.
AU  - Leithinger, Daniel
T3  - Chi '20
AB  - RoomShift is a room-scale dynamic haptic environment for virtual reality, using a small swarm of robots that can move furniture. RoomShift consists of nine shape-changing robots: Roombas with mechanical scissor lifts. These robots drive beneath a piece of furniture to lift, move and place it. By augmenting virtual scenes with physical objects, users can sit on, lean against, place and otherwise interact with furniture with their whole body; just as in the real world. When the virtual scene changes or users navigate within it, the swarm of robots dynamically reconfigures the physical environment to match the virtual content. We describe the hardware and software implementation, applications in virtual tours and architectural design and interaction techniques.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI conference on human factors in computing systems
DA  - 2020///
PY  - 2020
DO  - 10.1145/3313831.3376523
SP  - 1
EP  - 11
PB  - Association for Computing Machinery
SN  - 978-1-4503-6708-0
UR  - https://doi.org/10.1145/3313831.3376523
KW  - virtual reality
KW  - haptic interfaces
KW  - room-scale haptics
KW  - swarm robots
ER  - 

TY  - CONF
TI  - Potentials and barriers of the metaverse for circular economy
AU  - Kunert, Julia
AU  - van der Valk, Hendrik
AU  - Scheerer, Hannah
AU  - Hoppe, Christoph
T3  - Wsc '24
AB  - Sustainability is a challenge for society that circular economy tries to tackle. The metaverse, as an emerging technology that incorporates digital twins and simulation in an immersive virtual environment, has not been thoroughly investigated in connection to circular economy. Thus, the purpose of this study is to summarize the potentials and barriers of the use of the metaverse for circular economy. By conducting a structured literature review, this paper categorizes the findings into dimensions that are important for both the metaverse and circular economy. A variety of potentials and barriers that cover different perspectives important for businesses aiming to comply with circular economy principles is discovered. The findings include potentials and barriers in several areas, like the access to the metaverse, connected costs, data, knowledge transfer, collaboration, innovation, product design, production planning, training of employees, and transportation. The results can be used to promote the implementation of circular economy principles.
C1  - Orlando, Florida, USA
C3  - Proceedings of the winter simulation conference
DA  - 2025///
PY  - 2025
SP  - 3034
EP  - 3045
PB  - IEEE Press
SN  - 979-8-3315-3420-2
ER  - 

TY  - CONF
TI  - NEXUS: a tangible multi-user sensor-based telematic novel mixing-interface for multimedial exploration
AU  - Walter, Hannah
AU  - Larrieux, Eric
AU  - Torche, Robert
AU  - Spindler, Cedric
AU  - Müller, Patrick
T3  - Am '24
AB  - This paper explores the realm of telematic performance practice, interconnecting geographically disparate locations and performers through telecommunication technologies. Specifically, we focus on networked multimedia mixing and advance the field within the framework of third-wave human-computer interaction, emphasizing embodied interaction. Along with a detailed introduction of our Novel Interface for Multimedial Exploration, the NEXUS, we provide insights into our first use-case scenario, employing the NEXUS-NIME within a telematic performance context. Adapting and expanding on existing examples of dimension spaces, we introduce a novel Dimension Space for Phenomenologically Situated Interaction, which accounts for situated embodiment. It is employed in a dimension space analysis comparing the NEXUS with historical interfaces for networked musical and multimedial expression that incorporate multimodal interactions through tangible user interfaces. In doing so we demonstrate the NEXUS’s role as a transformative multi-user tool and bundle of NIMEs, shifting sound engineering practices from one of transparency and social fidelity to one of hypermediacy, risk and respons-ability. Drawing on concepts from feminist new materialism and posthumanism, the NEXUS opens new avenues for rendering-capable, for exploring complex interdependencies between human and non-human actors becoming-with in telematic ecosystems.
C1  - Milan, Italy
C3  - Proceedings of the 19th international audio mostly conference: Explorations in sonic cultures
DA  - 2024///
PY  - 2024
DO  - 10.1145/3678299.3678323
SP  - 245
EP  - 259
PB  - Association for Computing Machinery
SN  - 979-8-4007-0968-5
UR  - https://doi.org/10.1145/3678299.3678323
KW  - digital musical instrument
KW  - mixed reality
KW  - extended reality
KW  - Human-Computer Interaction
KW  - digital augmentation
KW  - dimension space analysis
KW  - embedded systems
KW  - embodied interaction
KW  - feminist new materialism.
KW  - networked multimedia mixing
KW  - New Interfaces for Musical Expression
KW  - posthumanism
KW  - responsive environments
KW  - sonic interaction design
KW  - tangible user interfaces
KW  - Telematic performance
ER  - 

TY  - JOUR
TI  - “Together with who?” recognizing partners during collaborative avatar manipulation
AU  - Hashiura, Kenta
AU  - Hagiwara, Takayoshi
AU  - Barbareschi, Giulia
AU  - Wakisaka, Sohei
AU  - Minamizawa, Kouta
T2  - ACM Trans. Appl. Percept.
AB  - The development of novel computer interfaces has led to the possibility of integrating inputs from multiple individuals into a single avatar, fostering collaboration by combining skills and sharing the cognitive load. However, the collaboration dynamic and its effectiveness may vary depending on the individuals involved. Particularly in scenarios where two individuals remotely control a robotic avatar without the possibility of direct communication, understanding each other’s characteristics can result in enhanced performance. To achieve this, it is essential to ascertain if individuals can discern their partner’s characteristics within the merged embodiment. This paper investigates the accuracy with which participants can distinguish between two different collaborating partners (one attempting to lead and one attempting to follow) when sharing control of a robot arm during a block pick-and-place task. The results suggested that participants who changed their roles according to the different roles of the two partners achieved the highest discrimination rates. Furthermore, participants changed their movements through the trials, adapting their actions to their preferred approach. This research provides insights into the factors determining individuals’ ability to understand partner characteristics during control of collaborative avatars.
DA  - 2024/11//
PY  - 2024
DO  - 10.1145/3698237
VL  - 21
IS  - 4
SN  - 1544-3558
UR  - https://doi.org/10.1145/3698237
KW  - collaborative avatar
KW  - cybernetic avatar
KW  - Joint Action
KW  - perceptual discrimination
KW  - shared avatar
KW  - shared experience
ER  - 

TY  - JOUR
TI  - Don’t block my stuff: Fostering personal object awareness in multi-user mixed reality environments
AU  - Khan, Talha
AU  - Lindlbauer, David
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - In Mixed Reality (MR), users can collaborate efficiently by creating personalized layouts that incorporate both personal and shared virtual objects. Unlike in the real world, personal objects in MR are only visible to their owner. This makes them susceptible to occlusions from shared objects of other users, who remain unaware of their existence. Thus, achieving unobstructed layouts in collaborative MR settings requires knowledge of where others have placed their personal objects. In this paper, we assessed the effects of three visualizations, and a baseline without any visualization, on occlusions and user perceptions. Our study involved 16 dyads (N=32) who engaged in a series of collaborative sorting tasks. Results indicate that the choice of visualization significantly impacts both occlusion and perception, emphasizing the need for effective visualizations to enhance collaborative MR experiences. We conclude with design recommendations for multi-user MR systems to better accommodate both personal and shared interfaces simultaneously.
DA  - 2024/10//
PY  - 2024
DO  - 10.1145/3698126
VL  - 8
IS  - ISS
UR  - https://doi.org/10.1145/3698126
KW  - Visualization
KW  - Collaboration
KW  - Augmented Reality
KW  - Mixed Reality
KW  - Personal Interfaces
ER  - 

TY  - CONF
TI  - Volumetric video use cases for XR immersive streaming
AU  - Fasogbon, Peter
AU  - Bisht, Surarshan
AU  - Kernen, Jaakko
AU  - Budak, Ugurcan
AU  - Ilola, Lauri
AU  - Kondrad, Lukasz
T3  - Icemt '24
AB  - This paper proposes a summarized analyses for volumetric video streaming use cases and its applicability for immersive extended reality applications. It also closely evaluates and illustrates the usability of standardized technologies for one of the use cases, i.e., real-time fitness training between remote participants.
C1  - Tokyo, Japan
C3  - Proceedings of the 2024 8th international conference on education and multimedia technology
DA  - 2024///
PY  - 2024
DO  - 10.1145/3678726.3678754
SP  - 1
EP  - 8
PB  - Association for Computing Machinery
SN  - 979-8-4007-1761-1
UR  - https://doi.org/10.1145/3678726.3678754
KW  - HMD
KW  - Metaverse
KW  - Augmented Reality (AR)
KW  - Virtual Reality (VR)
KW  - Extended Reality (XR)
KW  - Volumetric Video
ER  - 

TY  - CONF
TI  - A human touch: Social touch increases the perceived human-likeness of agents in virtual reality
AU  - Hoppe, Matthias
AU  - Rossmy, Beat
AU  - Neumann, Daniel Peter
AU  - Streuber, Stephan
AU  - Schmidt, Albrecht
AU  - Machulla, Tonja-Katrin
T3  - Chi '20
AB  - Virtual Reality experiences and games present believable virtual environments based on graphical quality, spatial audio, and interactivity. The interaction with in-game characters, controlled by computers (agents) or humans (avatars), is an important part of VR experiences. Pre-captured motion sequences increase the visual humanoid resemblance. However, this still precludes realistic social interactions (eye contact, imitation of body language), particularly for agents. We aim to make social interaction more realistic via social touch. Social touch is non-verbal, conveys feelings and signals (coexistence, closure, intimacy). In our research, we created an artificial hand to apply social touch in a repeatable and controlled fashion to investigate its effect on the perceived human-likeness of avatars and agents. Our results show that social touch is effective to further blur the boundary between computer- and human-controlled virtual characters and contributes to experiences that closely resemble human-to-human interactions.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI conference on human factors in computing systems
DA  - 2020///
PY  - 2020
DO  - 10.1145/3313831.3376719
SP  - 1
EP  - 11
PB  - Association for Computing Machinery
SN  - 978-1-4503-6708-0
UR  - https://doi.org/10.1145/3313831.3376719
KW  - virtual reality
KW  - agency
KW  - social touch
KW  - human-likeness
ER  - 

TY  - JOUR
TI  - ViGather: Inclusive virtual conferencing with a joint experience across traditional screen devices and mixed reality headsets
AU  - Qiu, Huajian
AU  - Streli, Paul
AU  - Luong, Tiffany
AU  - Gebhardt, Christoph
AU  - Holz, Christian
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Teleconferencing is poised to become one of the most frequent use cases of immersive platforms, since it supports high levels of presence and embodiment in collaborative settings. On desktop and mobile platforms, teleconferencing solutions are already among the most popular apps and accumulate significant usage time—not least due to the pandemic or as a desirable substitute for air travel or commuting.In this paper, we present ViGather, an immersive teleconferencing system that integrates users of all platform types into a joint experience via equal representation and a first-person experience. ViGather renders all participants as embodied avatars in one shared scene to establish co-presence and elicit natural behavior during collocated conversations, including nonverbal communication cues such as eye contact between participants as well as body language such as turning one's body to another person or using hand gestures to emphasize parts of a conversation during the virtual hangout. Since each user embodies an avatar and experiences situated meetings from an egocentric perspective no matter the device they join from, ViGather alleviates potential concerns about self-perception and appearance while mitigating potential 'Zoom fatigue', as users' self-views are not shown. For participants in Mixed Reality, our system leverages the rich sensing and reconstruction capabilities of today's headsets. For users of tablets, laptops, or PCs, ViGather reconstructs the user's pose from the device's front-facing camera, estimates eye contact with other participants, and relates these non-verbal cues to immediate avatar animations in the shared scene.Our evaluation compared participants' behavior and impressions while videoconferencing in groups of four inside ViGather with those in Meta Horizon as a baseline for a social VR setting. Participants who participated on traditional screen devices (e.g., laptops and desktops) using ViGather reported a significantly higher sense of physical, spatial, and self-presence than when using Horizon, while all perceived similar levels of active social presence when using Virtual Reality headsets. Our follow-up study confirmed the importance of representing users on traditional screen devices as reconstructed avatars for perceiving self-presence.
DA  - 2023/09//
PY  - 2023
DO  - 10.1145/3604279
VL  - 7
IS  - MHCI
UR  - https://doi.org/10.1145/3604279
KW  - virtual reality
KW  - avatars
KW  - social VR
KW  - mixed reality
KW  - collaboration
KW  - co-presence
KW  - cross-platform
KW  - embodied presence
KW  - immersive social interaction
KW  - teleconferencing
KW  - video conferencing
ER  - 

TY  - CONF
TI  - TactJam: An end-to-end prototyping suite for collaborative design of on-body vibrotactile feedback
AU  - Wittchen, Dennis
AU  - Spiel, Katta
AU  - Fruchard, Bruno
AU  - Degraen, Donald
AU  - Schneider, Oliver
AU  - Freitag, Georg
AU  - Strohmeier, Paul
T3  - Tei '22
AB  - We present TactJam, an end-to-end suite for creating and sharing low fidelity prototypes of on-body vibrotactile feedback. With TactJam, designers can create, record and share vibrotactile patterns online. This opens up new ways of collaboratively designing vibrotactile patterns both in collocated as well as in remote settings. We evaluate TactJam in a two-part distributed online workshop, exploring the design of on-body tactons. Participants were able to successfully use TactJam to learn about tacton design. We present an overview of mappings between tactons and their associated concepts before comparing the results of tactons created using solely a GUI and tactons created through experimenting with placements directly on the body. Conducting both parts of the workshop separately highlighted the importance of designing directly with bodies: less implicit assumptions were made, and designs were guided by personal experience. We reflect on these results and close on deliberations for the future development of TactJam.
C1  - Daejeon, Republic of Korea
C3  - Proceedings of the sixteenth international conference on tangible, embedded, and embodied interaction
DA  - 2022///
PY  - 2022
DO  - 10.1145/3490149.3501307
PB  - Association for Computing Machinery
SN  - 978-1-4503-9147-4
UR  - https://doi.org/10.1145/3490149.3501307
KW  - tactile feedback
KW  - embodied interaction
KW  - collaborative sketching
KW  - embodied design
KW  - on-body design
KW  - tactile prototyping
KW  - tactons
KW  - vibrotactile feedback
ER  - 

TY  - CONF
TI  - Stepping into the unknown: Immersive spatial hypertext
AU  - Eidloth, Lisa
AU  - Atzenbeck, Claus
AU  - Pfeiffer, Thies
T3  - Human '24
AB  - Traditional spatial hypertext systems, predominantly limited to two-dimensional (2D) interfaces, offer limited support for addressing long debated inherent problems such as orientation difficulties and navigation in large information spaces. In this context, we present opportunities from interdisciplinary fields such as immersive analytics (IA) and embodied cognition that may mitigate some of these challenges. However, while some research has explored the extension of spatial hypertext to three dimensions, there is a lack of discussion on recent advances in virtual reality technologies and related fields, and their potential impact on immersive spatial hypertext systems. This paper addresses this gap by exploring the integration of immersive technologies into spatial hypertext systems, proposing a novel approach to enhance user engagement and comprehension through three-dimensional (3D) environments and multisensory interaction.
C1  - Poznan, Poland
C3  - Proceedings of the 7th workshop on human factors in hypertext
DA  - 2024///
PY  - 2024
DO  - 10.1145/3679058.3688632
PB  - Association for Computing Machinery
SN  - 979-8-4007-1120-6
UR  - https://doi.org/10.1145/3679058.3688632
KW  - virtual reality
KW  - extended reality
KW  - hypertext
KW  - immersiveness
KW  - information exploration
KW  - knowledge
KW  - spatial hypertext
ER  - 

TY  - CONF
TI  - Collective embodiment, or the social nature of the sense of embodiment in social VR
AU  - Kukshinov, Eugene
AU  - Nacke, Lennart E.
T3  - Imx '25
AB  - In Social Virtual Reality (SVR), mediated social communication blends with simulated virtual environments and bodies. However, little is known about how these social and physical (or embodied) affordances intersect in user experiences. We bridge this research gap by applying phenomenological analysis to SVR user interviews to reveal embodiment in SVR based on their lived experiences. We contribute empirical evidence to the concept of “collective embodiment,” described as a mutually maintained feeling of embodiment that SVR provides beyond individual experiences and avatar-related sensations. This involves intertwined senses of agency, location, and appearance influenced by the presence and actions of others in the virtual environment. We also observed SVR users’ difficulties controlling avatar visual representations and communication or social functions. This research uncovers the multifaceted nature of collective embodiment in SVR, offering insights into its social dynamics, design, and user experience implications.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 ACM international conference on interactive media experiences
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706370.3727895
SP  - 187
EP  - 199
PB  - Association for Computing Machinery
SN  - 979-8-4007-1391-0
UR  - https://doi.org/10.1145/3706370.3727895
KW  - Presence
KW  - Avatars
KW  - Phenomenological Analysis.
KW  - Sense of Embodiment
KW  - Social Interaction
KW  - Social VR
ER  - 

TY  - CONF
TI  - vIIIS: a vocational intelligent interactive immersive storytelling framework to support task performance
AU  - Doolani, Sanika
AU  - Wessels, Callen
AU  - Makedon, Fillia
T3  - Petra '21
AB  - This paper presents a framework for developing Intelligent, Interactive, and Immersive Storytelling systems for vocational training by improving task performance. We present a systematic framework that can be used to personalize training for a worker in a factory environment. We also present a system implementation that builds upon the vIIIS framework and also describes the design decisions made throughout the system. In this paper, we focus on improving a user’s episodic and working memory by employing picture sequence and object sorting tasks taken from the NIH toolbox and presenting an intelligent Augmented Reality system. A major advantage of using an intelligent and interactive system using storytelling is that the training can be curated towards each specific user, thereby enhancing the learning outcome based on individual needs.
C1  - Corfu, Greece
C3  - Proceedings of the 14th pervasive technologies related to assistive environments conference
DA  - 2021///
PY  - 2021
DO  - 10.1145/3453892.3461631
SP  - 527
EP  - 533
PB  - Association for Computing Machinery
SN  - 978-1-4503-8792-7
UR  - https://doi.org/10.1145/3453892.3461631
KW  - Reinforcement Learning
KW  - Augmented Reality
KW  - Immersive Storytelling
KW  - Vocational Training
ER  - 

TY  - CONF
TI  - Design and field study of syn-leap: a symmetric telepresence system for immersion switching and walking across multiple locations
AU  - Yazaki, Takeru
AU  - Watanabe, Yuna
AU  - Kong, Lingrong
AU  - Inami, Masahiko
T3  - Mum '23
AB  - Outdoor activities, such as traveling and sightseeing, become challenging to realize when individuals are geographically distant. This paper introduces Syn-Leap, a symmetrical wearable telepresence system designed to allow multiple users to explore outdoor settings while mutually sharing their environments. With Syn-Leap, users wear a 360° camera and AR glasses, allowing them to share their environment through video streaming while simultaneously viewing the videos of other users while walking outdoors. To investigate the experiences and communication generated by this system, we conducted a field study in Kyoto, Japan, focusing on tourism scenarios. The results revealed that participants could achieve a sense of walking together by seamlessly switching between exploring their own environment and viewing the video feeds of other users, occasionally overlaying the AR content from other users onto their own environment.
C1  - Vienna, Austria
C3  - Proceedings of the 22nd international conference on mobile and ubiquitous multimedia
DA  - 2023///
PY  - 2023
DO  - 10.1145/3626705.3627772
SP  - 353
EP  - 365
PB  - Association for Computing Machinery
SN  - 979-8-4007-0921-0
UR  - https://doi.org/10.1145/3626705.3627772
KW  - Telepresence
KW  - Augmented Reality
KW  - Remote Communication
KW  - Research through Design
ER  - 

TY  - CONF
TI  - Immersive inclusivity at CHI: Design and creation of inclusive user interactions through immersive media
AU  - Ryskeldiev, Bektur
AU  - Ochiai, Yoichi
AU  - Kusano, Koki
AU  - Li, Jie
AU  - Saraiji, Yamen
AU  - Kunze, Kai
AU  - Billinghurst, Mark
AU  - Nanayakkara, Suranga
AU  - Sugano, Yusuke
AU  - Honda, Tatsuya
T3  - Chi ea '21
AB  - Immersive media is becoming increasingly common in day-to-day scenarios: from extended reality systems to multimodal interfaces. Such ubiquity opens an opportunity for building more inclusive environments for users with disabilities (permanent, temporary, or situational) by either introducing immersive and multimodal elements into existing applications, or designing and creating immersive applications with inclusivity in mind. Thus the aim of this workshop is to create a discussion platform on intersections between the fields of immersive media, accessibility, and human-computer interaction, outline the key current and future problems of immersive inclusive design, and define a set of methodologies for design and evaluation of immersive systems from inclusivity perspective.
C1  - Yokohama, Japan
C3  - Extended abstracts of the 2021 CHI conference on human factors in computing systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411763.3441322
PB  - Association for Computing Machinery
SN  - 978-1-4503-8095-9
UR  - https://doi.org/10.1145/3411763.3441322
KW  - virtual reality
KW  - augmented reality
KW  - human-computer interaction
KW  - mixed reality
KW  - artificial intelligence
KW  - extended reality
KW  - accessibility
KW  - inclusive design
KW  - assistive technology
KW  - augmented human
KW  - collaborative technology
KW  - internet of things
ER  - 

TY  - CONF
TI  - Exploring the effects of social VR coupling modes on engagement and task performance for older adults
AU  - Vo, Thuan T
AU  - Das, Satabdi
AU  - Noroozi, Shamim
AU  - Dang, Lakshay
AU  - Sin, Jaisie
AU  - Boger, Jennifer N
AU  - Jakobi, Jennifer
AU  - Hasan, Khalad
T3  - Chi '25
AB  - Social Virtual Reality (VR) presents a promising avenue for older adults to connect with others and engage in collaborative activities remotely. However, many social VR experiences focus on individual tasks, reducing opportunities for meaningful social interaction. To investigate the potential of VR to enhance engagement with other participants, this paper explores two modes of coupling: (i) loosely coupled, where participants focus on their individual tasks within a collaborative setting, and (ii) tightly coupled, where participants need to rely on each other’s assistance to complete their tasks. We conducted a user study with 20 older adults to evaluate how these modes affect task performance and engagement. Results show that the tightly coupled mode, focused on collaboration, increases engagement, while the loosely coupled mode, centers on individual tasks, improves performance in time and attempts. We provide guidelines for collaborative VR applications to enhance social engagement and interaction among older adults.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713345
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713345
KW  - Collaborative Game
KW  - Healthy Aging
KW  - Loosely Coupled Collaboration
KW  - Older Adults
KW  - Tightly Coupled Collaboration
ER  - 

TY  - CONF
TI  - ConeAct: a multistable actuator for dynamic materials
AU  - Lin, Yuyu
AU  - Gonzalez, Jesse T
AU  - Cui, Zhitong
AU  - Banka, Yash Rajeev
AU  - Ion, Alexandra
T3  - Chi '24
AB  - Complex actuators in a small form factor are essential for dynamic interfaces. In this paper, we propose ConeAct, a cone-shaped actuator that can extend, contract, and bend in multiple directions to support rich expression in dynamic materials. A key benefit of our actuator is that it is self-contained and portable as the whole system. We designed our actuator’s structure to be multistable to hold its shape passively, while we control its transition between states using active materials, i.e., shape memory alloys. We present the design space by showcasing our actuator module as part of self-rolling robots, reconfigurable deployable structures, volumetric shape-changing objects and tactile displays. To assist users in designing such structures, we present an interactive editor including simulation to design such interactive capabilities.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI conference on human factors in computing systems
DA  - 2024///
PY  - 2024
DO  - 10.1145/3613904.3642949
PB  - Association for Computing Machinery
SN  - 979-8-4007-0330-0
UR  - https://doi.org/10.1145/3613904.3642949
KW  - Dynamic materials
KW  - Fabrication
KW  - Programmable Matter
ER  - 

TY  - CONF
TI  - Dyadic interactions with avatars in immersive virtual environments: high fiving
AU  - Young, Mary K.
AU  - Rieser, John J.
AU  - Bodenheimer, Bobby
T3  - Sap '15
AB  - Collaborative immersive virtual environments allow the behavior of one user to be observed by other users. In particular, behavior of users in such an environment is represented by each user possessing a self-avatar, a digital representation of themself. In this study we examined dyadic interactions in a collaborative immersive virtual environment when both users were present in the same physical space. This collocation in physical space allows for physical interaction between users as well as virtual interaction. In the context of a common physical gesture, high fiving, we examined the question of whether the form of the self-avatar was important, and whether collocation in the physical world provided benefits or not. We find that the form of the avatar is important but that physical collocation is not. These results reinforce the growing body of evidence that indicates that having a full-body avatar in a virtual environment provides benefits, and these results are significant because they demonstrate this in the context of a dyadic interaction.
C1  - Tübingen, Germany
C3  - Proceedings of the ACM SIGGRAPH symposium on applied perception
DA  - 2015///
PY  - 2015
DO  - 10.1145/2804408.2804410
SP  - 119
EP  - 126
PB  - Association for Computing Machinery
SN  - 978-1-4503-3812-7
UR  - https://doi.org/10.1145/2804408.2804410
KW  - virtual environments
KW  - head-mounted displays
KW  - virtual avatar
KW  - virtual reality (VR)
ER  - 

TY  - CONF
TI  - Out of sight,... how asymmetry in video-conference affects social interaction
AU  - Sallaberry, Camille
AU  - Englebienne, Gwenn
AU  - Van Erp, Jan
AU  - Evers, Vanessa
T3  - Icmi '23
AB  - As social-mediated interaction is becoming increasingly important and multi-modal, even expanding into virtual reality and physical telepresence with robotic avatars, new challenges emerge. For instance, video calls have become the norm and it is increasingly common that people experience a form of asymmetry, such as not being heard or seen by their communication partners online due to connection issues. Previous research has not yet extensively explored the effect on social interaction. In this study, 61 Dyads, i.e. 122 adults, played a quiz-like game using a video-conferencing platform and evaluated the quality of their social interaction by measuring five sub-scales of social presence. The Dyads had either symmetrical access to social cues (both only audio, or both audio and video) or asymmetrical access (one partner receiving only audio, the other audio and video). Our results showed that in the case of asymmetrical access, the party receiving more modalities, i.e. audio and video from the other, felt significantly less connected than their partner. We discuss these results in relation to the Media Richness Theory (MRT) and the Hyperpersonal Model: in asymmetry, more modalities or cues will not necessarily increase feeling socially connected, in opposition to what was predicted by MRT. We hypothesize that participants sending fewer cues compensate by increasing the richness of their expressions and that the interaction shifts towards an equivalent richness for both participants.
C1  - Paris, France
C3  - Proceedings of the 25th international conference on multimodal interaction
DA  - 2023///
PY  - 2023
DO  - 10.1145/3577190.3614168
SP  - 465
EP  - 469
PB  - Association for Computing Machinery
SN  - 979-8-4007-0055-2
UR  - https://doi.org/10.1145/3577190.3614168
KW  - Social Interaction
KW  - "Mediated Communication
KW  - Asymmetry
KW  - Social Computing
KW  - Social Presence
KW  - Social Signals"
KW  - Video-Conference
ER  - 

TY  - CONF
TI  - The roles of haptic-ostensive referring expressions in cooperative, task-based human-robot dialogue
AU  - Foster, Mary Ellen
AU  - Bard, Ellen Gurman
AU  - Guhe, Markus
AU  - Hill, Robin L.
AU  - Oberlander, Jon
AU  - Knoll, Alois
T3  - Hri '08
AB  - Generating referring expressions is a task that has received a great deal of attention in the natural-language generation community, with an increasing amount of recent effort targeted at the generation of multimodal referring expressions. However, most implemented systems tend to assume very little shared knowledge between the speaker and the hearer, and therefore must generate fully-elaborated linguistic references. Some systems do include a representation of the physical context or the dialogue context; however, other sources of contextual information are not normally used. Also, the generated references normally consist only of language and, possibly, deictic pointing gestures.When referring to objects in the context of a task-based interaction involving jointly manipulating objects, a much richer notion of context is available, which permits a wider range of referring options. In particular, when conversational partners cooperate on a mutual task in a shared environment, objects can be made accessible simply by manipulating them as part of the task. We demonstrate that such expressions are common in a corpus of human-human dialogues based on constructing virtual objects, and then describe how this type of reference can be incorporated into the output of a humanoid robot that engages in similar joint construction dialogues with a human partner.
C1  - Amsterdam, The Netherlands
C3  - Proceedings of the 3rd ACM/IEEE international conference on human robot interaction
DA  - 2008///
PY  - 2008
DO  - 10.1145/1349822.1349861
SP  - 295
EP  - 302
PB  - Association for Computing Machinery
SN  - 978-1-60558-017-3
UR  - https://doi.org/10.1145/1349822.1349861
KW  - multimodal dialogue
KW  - referring expressions
ER  - 

TY  - CONF
TI  - VXSlate: Exploring combination of head movements and mobile touch for large virtual display interaction
AU  - Le, Khanh-Duy
AU  - Tran, Tanh Quang
AU  - Chlasta, Karol
AU  - Krejtz, Krzysztof
AU  - Fjeld, Morten
AU  - Kunz, Andreas
T3  - Dis '21
AB  - Virtual Reality (VR) headsets can open opportunities for users to accomplish complex tasks on large virtual displays using compact and portable devices. However, interacting with such large virtual displays using existing interaction techniques might cause fatigue, especially for precise manipulation tasks, due to the lack of physical surfaces. To deal with this issue, we explored the design of VXSlate, an interaction technique that uses a large virtual display as an expansion of a tablet. We combined a user’s head movements as tracked by the VR headset, and touch interaction on the tablet. Using VXSlate, a user head movements positions a virtual representation of the tablet together with the user’s hand, on the large virtual display. This allows the user to perform fine-tuned multi-touch content manipulations. In a user study with seventeen participants, we investigated the effects of VXSlate on users in problem-solving tasks involving content manipulations at different levels of difficulty, such as translation, rotation, scaling, and sketching. As a baseline for comparison, off-the-shelf touch-controller interactions were used. Overall, VXSlate allowed participants to complete the task with completion times and accuracy that are comparable to touch-controller interactions. After an interval of use, VXSlate significantly reduced users’ time to perform scaling tasks in content manipulations, as well as reducing perceived effort. We reflected on the advantages and disadvantages of VXSlate in content manipulation on large virtual displays and explored further applications within the VXSlate design space.
C1  - Virtual Event, USA
C3  - Proceedings of the 2021 ACM designing interactive systems conference
DA  - 2021///
PY  - 2021
DO  - 10.1145/3461778.3462076
SP  - 283
EP  - 297
PB  - Association for Computing Machinery
SN  - 978-1-4503-8476-6
UR  - https://doi.org/10.1145/3461778.3462076
KW  - VR
KW  - touch interaction
KW  - head movements
KW  - mobile device
KW  - virtual large displays
ER  - 

TY  - CONF
TI  - Move'n'hold pro: Consistent spatial interaction techniques for object manipulation with handheld and head-mounted displays in extended reality
AU  - Memmesheimer, Vera Marie
AU  - Klingshirn, Kai Jonas
AU  - Herold, Cindy
AU  - Ravani, Bahram
AU  - Ebert, Achim
T3  - Ecce '24
AB  - Extended Reality (XR) technologies are still lacking appropriate interaction methods that enable users to seamlessly switch between different XR devices and degrees of virtuality. Addressing this gap, we present Move’n’Hold Pro – a set of consistent object manipulation techniques that are available for Mixed Reality handheld displays (MR-HHDs) as well as for Mixed and Virtual Reality head-mounted displays (MR-/VR-HMDs). Move’n’Hold Pro extends MR- and VR-HMDs with a tablet controller that implements object manipulation methods proposed by latest research on MR-HHD-UIs. Thereby, users can combine tablet movement and peripheral touch to translate or rotate virtual objects through direct or continuous manipulations. In our evaluation, comparing Move’n’Hold Pro to a State of the Art system, Move’n’Hold Pro was rated as the preferred system and to be easier to relearn. Furthermore, Move’n’Hold Pro reduced cognitive efforts, improved usability, and provided more cross-device benefits.
C1  - Paris, France
C3  - Proceedings of the european conference on cognitive ergonomics 2024
DA  - 2024///
PY  - 2024
DO  - 10.1145/3673805.3673814
PB  - Association for Computing Machinery
SN  - 979-8-4007-1824-3
UR  - https://doi.org/10.1145/3673805.3673814
KW  - Virtual Reality
KW  - Augmented Reality
KW  - Mixed Reality
KW  - User Interface
KW  - Extended Reality
KW  - Handheld displays
KW  - Head-mounted Displays
KW  - Interaction Technique
KW  - Spatial Interaction
ER  - 

TY  - CONF
TI  - Construction of SVS: Scale of virtual twin's similarity to physical counterpart in simple environments
AU  - Zhang, Xuesong
AU  - Simeone, Adalberto L.
T3  - Sui '24
AB  - Due to the lack of a universally accepted definition for the term “virtual twin”, there are varying degrees of similarity between physical prototypes and their virtual counterparts across different research papers. This variability complicates the comparison of results from these papers. To bridge this gap, we introduce the Scale of Virtual Twin’s Similarity (SVS), a questionnaire intended to quantify the similarity between a virtual twin and its physical counterpart in simple environments in terms of visual fidelity, physical fidelity, environmental fidelity, and functional fidelity. This paper describes the development process of the SVS questionnaire items and provides an initial evaluation through two between-subjects user studies to validate the items under the categories of visual and functional fidelity. Additionally, we discuss the way to apply it in research and development settings.
C1  - Trier, Germany
C3  - Proceedings of the 2024 ACM symposium on spatial user interaction
DA  - 2024///
PY  - 2024
DO  - 10.1145/3677386.3682100
PB  - Association for Computing Machinery
SN  - 979-8-4007-1088-9
UR  - https://doi.org/10.1145/3677386.3682100
KW  - Evaluation
KW  - Fidelity
KW  - Questionnaire
KW  - Similarity
KW  - Virtual twin
ER  - 

TY  - CONF
TI  - CoAR-TV: Design and evaluation of asynchronous collaboration in AR-supported TV experiences
AU  - Bouquet, Elizabeth
AU  - Von Der Au, Simon
AU  - Schneegass, Christina
AU  - Alt, Florian
T3  - Imx '24
AB  - Television has long since been a uni-directional medium. However, when TV is used for educational purposes, like in edutainment shows, interactivity could enhance the learning benefit for the viewer. In recent years, AR has been increasingly explored in HCI research to enable interaction among viewers as well as viewers and hosts. Yet, how to implement this collaborative AR (CoAR) experience remains an open research question. This paper explores four approaches to asynchronous collaboration based on the Cognitive Apprenticeship Model: scaffolding, coaching, modeling, and collaborating. We developed a pilot show for a fictional edutainment series and evaluated the concept with two TV experts. In a wizard-of-oz study, we test our AR prototype with eight users and evaluate the perception of the four collaboration styles. The AR-enhanced edutainment concept was well-received by the participants, and the coaching collaboration style was perceived as favorable and could possibly be combined with the modeling style.
C1  - Stockholm, Sweden
C3  - Proceedings of the 2024 ACM international conference on interactive media experiences
DA  - 2024///
PY  - 2024
DO  - 10.1145/3639701.3656320
SP  - 231
EP  - 245
PB  - Association for Computing Machinery
SN  - 979-8-4007-0503-8
UR  - https://doi.org/10.1145/3639701.3656320
KW  - AR
KW  - collaboration
KW  - edutainment
KW  - interactive television
KW  - mobile
ER  - 

TY  - CONF
TI  - Telematic wearable music: Remote ensembles and inclusive embodied education
AU  - Thorn, Seth
T3  - Am '21
AB  - The author discusses telematic wearable music, recounting the design and evolution of improvised techniques and approaches in a remotely taught course offered to undergraduates. This new contribution to interactive interfaces for remote ensembles is musically motivated and inclusive for non-specialists who apply musical instincts they discover through participation. Students are introduced to wearable ”Internet of Things” (IoT) computing, synthesis, and sound design, with the goal of developing rich, movement responsive, individually and/or collectively playable wearable instruments. The course facilitates practice-situated investigation of accessible, agile, and inexpensive modes of distributed creativity in musical interaction through experiential inquiry and tinkering. Telematic wearable music aspires to enact shared, situated spaces and less ocularcentric modes of learning through embodied sonic telepresence, emphasizing and enhancing embodied participation in synchronous remote learning.
C1  - virtual/Trento, Italy
C3  - Proceedings of the 16th international audio mostly conference
DA  - 2021///
PY  - 2021
DO  - 10.1145/3478384.3478386
SP  - 188
EP  - 195
PB  - Association for Computing Machinery
SN  - 978-1-4503-8569-5
UR  - https://doi.org/10.1145/3478384.3478386
KW  - wearables
KW  - distance learning
KW  - distributed creativity
KW  - Internet of Things
KW  - music
KW  - remote ensembles
KW  - telematic music
ER  - 

TY  - JOUR
TI  - Towards bare-hand interaction for whiteboard collaboration in virtual reality
AU  - Liu, Guangtian
AU  - Su, Haonan
AU  - Wang, Jingyu
AU  - Qi, Qi
AU  - Sun, Haifeng
AU  - Zhuang, Zirui
AU  - Ren, Pengfei
AU  - Liao, Jianxin
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Whiteboard collaboration in virtual reality (VR) is an important task in collaborative virtual environments. The current research mainly relies on the use of controllers or dedicated pens but additional devices will cause inconvenience to users. Bare-hand writing offers rich collaborative semantics through natural gestures but remains underexplored. This paper addresses challenges and solutions for bare-hand whiteboard collaboration. We analyze the input process and identify key challenges in determining pen-drop, writing, and pen-lift intentions while maintaining user control over their avatar. Our approach addresses two VR scenarios: one without and one with physical planes. The method for the first case is called Air-writing, which dynamically adjusts the distance between the avatar's torso and the virtual whiteboard during the processes of pen-drop and pen-lift to ensure a consistent writing experience in VR. The method for the second case is called Physical-writing, which allows users to write smoothly with passive haptic feedback and physical constraints provided by the real surface by remapping the whiteboard in VR with a plane in reality. A comprehensive user study is conducted to evaluate communication efficiency, input accuracy, collaboration efficiency, and user experience of the two methods. The experimental results indicate that bare-hand interaction improves communication efficiency by 8
DA  - 2025/05//
PY  - 2025
DO  - 10.1145/3711092
VL  - 9
IS  - 2
UR  - https://doi.org/10.1145/3711092
KW  - virtual reality
KW  - bare-hand whiteboard collaboration
ER  - 

TY  - CONF
TI  - AvatARoid: a motion-mapped AR overlay to bridge the embodiment gap between robots and teleoperators in robot-mediated telepresence
AU  - Ghimire, Amit
AU  - Hou, Anova
AU  - Kim, Ig-Jae
AU  - Yoon, Dongwook
T3  - Chi '25
AB  - Robot-mediated telepresence promises to facilitate effective social interaction between remote teleoperators and on-site users. However, disparities between the robot’s form and the teleoperator’s representation cause perceptual conflict in on-site users, degrading interaction quality. We introduce AvatARoid, a novel design that bridges this embodiment gap by superimposing the teleoperator’s motion-mapped AR avatar overlay on a humanoid. We evaluated our design in a mixed-method study (n=48) using an immersive simulation where participants interacted with a confederate teleoperator, presented in either (a) a humanoid robot, (b) a humanoid robot with video, or (c) AvatARoid. Results suggest AvatARoid significantly improved teleoperator embodiment for on-site users, particularly enhancing co-location, and control perceptions, and providing richer non-verbal gestures. In contrast, video and baseline conditions often resulted in a pronounced disconnect between the teleoperator and the robot for on-site users. Our study offers new insights into designing novel teleoperator representations to promote social interaction in robot-mediated telepresence.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713812
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713812
KW  - telepresence
KW  - embodiment
KW  - robot
KW  - AR overlay
KW  - avatar
KW  - AvatARoid
KW  - humanoid
ER  - 

TY  - JOUR
TI  - Toward video-conferencing tools for hands-on activities in online teaching
AU  - Labrie, Audrey
AU  - Mok, Terrance
AU  - Tang, Anthony
AU  - Lui, Michelle
AU  - Oehlberg, Lora
AU  - Poretski, Lev
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Many instructors in computing and HCI disciplines use hands-on activities for teaching and training new skills. Beyond simply teaching hands-on skills like sketching and programming, instructors also use these activities so students can acquire tacit skills. Yet, current video-conferencing technologies may not effectively support hands-on activities in online teaching contexts. To develop an understanding of the inadequacies of current video-conferencing technologies for hands-on activities, we conducted 15 interviews with university-level instructors who had quickly pivoted their use of hands-on activities to an online context during the early part of the COVID-19 pandemic. Based on our analysis, we uncovered four pedagogical goals that instructors have when using hands-on activities online and how instructors were unable to adequately address them due to the technological limitations of current video-conferencing tools. Our work provides empirical data about the challenges that many instructors experienced, and in so doing, the pedagogical goals we identify provide new requirements for video-conferencing systems to better support hands-on activities.
DA  - 2022/01//
PY  - 2022
DO  - 10.1145/3492829
VL  - 6
IS  - GROUP
UR  - https://doi.org/10.1145/3492829
KW  - remote instruction
KW  - hands-on activities
KW  - online teaching
ER  - 

TY  - JOUR
TI  - Making and accessibility: a systematic literature review on the multilayered dimensions of accessible making
AU  - Sarwar, Saquib
AU  - Wilson, David
T2  - ACM Trans. Access. Comput.
AB  - In recent years, the making phenomenon has shown great potential in personal design and fabrication capabilities using modern fabrication tools (e.g., 3D printers, laser cutters, CNC machines), personal electronics (e.g., Arduino, Raspberry Pi, sensors), and related crafting techniques. With this trend of making, people have also engaged in developing a wide variety of assistive devices (e.g., prostheses, orthotics), adaptations (e.g., cane-hanger/cup-holder for wheelchairs), and support systems (e.g., tactile braille maps). While there are some successful projects, substantive gaps remain between current traction and overall potential in the field of making and accessibility. To better understand the relationship between people with disabilities and making and identify the types of ecosystems involved in these overlapping areas of research, we conducted a systematic literature review on design-related ACM conferences between January 2010 and December 2023. Our analysis highlights the concentration of research across diverse communities, adaptations for accessible making, and the utilization of maker tools for the development of assistive devices. We also highlight trending design, development, and evaluation methodologies adopted to support collaboration between stakeholders with mixed abilities. Based on the findings of this systematic literature review, we critically reflect on the gaps and provide recommendations for future researchers and practitioners in this growing field.
DA  - 2025/05//
PY  - 2025
DO  - 10.1145/3726530
VL  - 18
IS  - 2
SN  - 1936-7228
UR  - https://doi.org/10.1145/3726530
KW  - Accessibility
KW  - Assistive technology
KW  - Making
KW  - Personal Fabrication
ER  - 

TY  - CONF
TI  - Physica: Interactive tangible physics simulation based on tabletop mobile robots towards explorable physics education
AU  - Li, Jiatong
AU  - Suzuki, Ryo
AU  - Nakagaki, Ken
T3  - Dis '23
AB  - In this paper, we introduce Physica, a tangible physics simulation system and approach based on tabletop mobile robots. In Physica, each tabletop robot can physically represent distinct simulated objects that are controlled through an underlying physics simulation, such as gravitational force, molecular movement, and spring force. It aims to bring the benefits of tangible and haptic interaction into explorable physics learning, which was traditionally only available on screen-based interfaces. The system utilizes off-the-shelf mobile robots (Sony Toio) and an open-source physics simulation tool (Teilchen). Built on top of them, we implement the interaction software pipeline that consists of 1) an event detector to reflect tangible interaction by users, and 2) target speed control to minimize the gap between the robot motion and simulated moving objects. To present the potential for physics education, we demonstrate various application scenarios that illustrate different forms of learning using Physica. In our user study, we investigate the effect and the potential of our approach through a perception study and interviews with physics educators.
C1  - Pittsburgh, PA, USA
C3  - Proceedings of the 2023 ACM designing interactive systems conference
DA  - 2023///
PY  - 2023
DO  - 10.1145/3563657.3596037
SP  - 1485
EP  - 1499
PB  - Association for Computing Machinery
SN  - 978-1-4503-9893-0
UR  - https://doi.org/10.1145/3563657.3596037
KW  - Actuated Tangible UIs
KW  - Physics Simulation
KW  - Swarm UIs
ER  - 

TY  - CONF
TI  - VRception: Rapid prototyping of cross-reality systems in virtual reality
AU  - Gruenefeld, Uwe
AU  - Auda, Jonas
AU  - Mathis, Florian
AU  - Schneegass, Stefan
AU  - Khamis, Mohamed
AU  - Gugenheimer, Jan
AU  - Mayer, Sven
T3  - Chi '22
AB  - Cross-reality systems empower users to transition along the reality-virtuality continuum or collaborate with others experiencing different manifestations of it. However, prototyping these systems is challenging, as it requires sophisticated technical skills, time, and often expensive hardware. We present VRception, a concept and toolkit for quick and easy prototyping of cross-reality systems. By simulating all levels of the reality-virtuality continuum entirely in Virtual Reality, our concept overcomes the asynchronicity of realities, eliminating technical obstacles. Our VRception Toolkit leverages this concept to allow rapid prototyping of cross-reality systems and easy remixing of elements from all continuum levels. We replicated six cross-reality papers using our toolkit and presented them to their authors. Interviews with them revealed that our toolkit sufficiently replicates their core functionalities and allows quick iterations. Additionally, remote participants used our toolkit in pairs to collaboratively implement prototypes in about eight minutes that they would have otherwise expected to take days.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI conference on human factors in computing systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491102.3501821
PB  - Association for Computing Machinery
SN  - 978-1-4503-9157-3
UR  - https://doi.org/10.1145/3491102.3501821
KW  - Virtual Reality
KW  - Augmented Reality
KW  - Cross-Reality Systems
KW  - Prototyping
KW  - Transitional Interfaces
ER  - 

TY  - CONF
TI  - The TaPSI research framework - a systematization of knowledge on tangible privacy and security interfaces
AU  - Delgado Rodriguez, Sarah
AU  - Windl, Maximiliane
AU  - Alt, Florian
AU  - Marky, Karola
T3  - Chi '25
AB  - This paper presents a comprehensive Systematization of Knowledge on tangible privacy and security interfaces (TaPSI). Tangible interfaces provide physical forms for digital interactions. They can offer significant benefits for privacy and security applications by making complex and abstract security concepts more intuitive, comprehensible, and engaging. Through a literature survey, we collected and analyzed 80 publications. We identified terminology used in these publications and addressed usable privacy and security domains, contributions, applied methods, implementation details, and opportunities or challenges inherent to TaPSI. Based on our findings, we define TaPSI and propose the TaPSI Research Framework, which guides future research by offering insights into when and how to conduct research on privacy and security involving TaPSI as well as a design space of TaPSI.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713968
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713968
KW  - framework
KW  - tangible interface
KW  - tangible privacy
KW  - tangible security
KW  - TaPSI
ER  - 

TY  - CONF
TI  - Finger contact in gesture interaction improves time-domain input accuracy in HMD-based augmented reality
AU  - Oh, Seo Young
AU  - Yoon, Boram
AU  - Kim, Hyung-il
AU  - Woo, Woontack
T3  - Chi ea '20
AB  - This paper reports that the time-domain accuracy of bare-hand interactions in HMD-based Augmented Reality can be improved by using finger contact: touching a finger with another or tapping one's own hand. The activation of input can be precisely defined by the moment of finger contact, allowing the user to perform the input precisely at the desired moment. Finger contact is better suited to the user's mental model, and natural tactile feedback from the fingertip also benefits the user with the self-perception of the input. The experimental results revealed that using finger contact is the preferred method of input that increases the time-domain accuracy and enables the user to be aware of the moment the input is activated.
C1  - Honolulu, HI, USA
C3  - Extended abstracts of the 2020 CHI conference on human factors in computing systems
DA  - 2020///
PY  - 2020
DO  - 10.1145/3334480.3383098
SP  - 1
EP  - 8
PB  - Association for Computing Machinery
SN  - 978-1-4503-6819-3
UR  - https://doi.org/10.1145/3334480.3383098
KW  - augmented reality
KW  - passive haptic feedback
KW  - 3d gesture interaction
KW  - finger contact
KW  - time-domain input accuracy
ER  - 

TY  - BOOK
TI  - VRST '24: Proceedings of the 30th ACM symposium on virtual reality software and technology
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0535-9
ER  - 

TY  - JOUR
TI  - A network-based virtual reality simulation training approach for orthopedic surgery
AU  - Cecil, J.
AU  - Gupta, Avinash
AU  - Pirela-Cruz, M.
AU  - Ramanathan, Parmesh
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
AB  - The focus of this article is on the adoption of immersive and haptic simulators for training of medical residents in a surgical process called Less Invasive Stabilization System (LISS) plating surgery. LISS surgery is an orthopedic surgical procedure to treat fractures of the femur bone. Development of such simulators is a complex task which involves multiple systems, technologies, and human experts. Emerging Next Generation Internet technologies were used to develop the standalone on-line haptic-based simulator accessible to the students 24/7. A standalone immersive surgical simulator was also developed using HTC Vive. Expert surgeons played an important role in developing the simulator system; use cases of the target surgical processes were built using a modeling language called the engineering Enterprise Modeling Language (eEML). A detailed study presenting the comparison between the haptic-based simulator and the immersive simulator has been also presented. The outcomes of this study underscore the potential of using such simulators in surgical training.
DA  - 2018/08//
PY  - 2018
DO  - 10.1145/3232678
VL  - 14
IS  - 3
SN  - 1551-6857
UR  - https://doi.org/10.1145/3232678
KW  - Virtual reality
KW  - immersive simulator
KW  - medical simulation
KW  - Next Generation Internet technologies
KW  - orthopedic surgery
ER  - 

TY  - CONF
TI  - Touch-ting: Sharing touches remotely using tangible computing
AU  - V M, Lokesh Kumar
AU  - Shandilya, Jribh
AU  - Gahlot, Arshiya
T3  - IndiaHCI '21
AB  - As physical distances between people have increased due to the pandemic, some of the most popular and widespread ways to ‘connect’ people remotely, namely audio/video calling and texting, are able to satisfy the auditory and visual sensories but fall short on a very crucial front- being able to communicate the intimate feeling of touch. In this paper we looked at some of the explorations done in the field of touch and haptics. We propose an affective interaction method called ”Touch-ting” that shares the feeling of touch remotely. To achieve this, we designed and prototyped a device which replicates the feeling of a finger sliding across the skin.
C1  - Virtual Event, India
C3  - Proceedings of the 12th indian conference on human-computer interaction
DA  - 2022///
PY  - 2022
DO  - 10.1145/3506469.3506478
SP  - 69
EP  - 72
PB  - Association for Computing Machinery
SN  - 978-1-4503-9607-3
UR  - https://doi.org/10.1145/3506469.3506478
KW  - Haptics
KW  - Affective Interaction
KW  - Remote Touch
KW  - Tactile Feedback
ER  - 

TY  - CONF
TI  - Musical drawing in 2D and 3D: Dimensions and perspectives
AU  - Gruy, Esther
AU  - Berthaut, Florent
T3  - Am '24
AB  - With advances in immersive displays and gesture tracking technologies, many novel interfaces for musical and visual expression have been developed, which often explore combinations of audio and visual productions. One category of such interfaces is musical drawing, in which artists simultaneously produce both visual and sonic content. Since it deals with two different sensory channels, one of the main problematic is to find the right balance between the sonic and the visual aspects of a project. In this article, we regroup the existing 2D and 3D musical drawing projects and we propose a set of dimensions that can be used to describe them, namely: Expression Orientation, Required Expertise, Collaboration, Visual Replay Value, Audio Replay Value, Modifications, Mapping Flexibility, Mapping Structure and Degree of Immersion. Using these dimensions, we analyse the design choices, discuss technological and technical constraints, and establish perspectives for future work.
C1  - Milan, Italy
C3  - Proceedings of the 19th international audio mostly conference: Explorations in sonic cultures
DA  - 2024///
PY  - 2024
DO  - 10.1145/3678299.3678317
SP  - 181
EP  - 188
PB  - Association for Computing Machinery
SN  - 979-8-4007-0968-5
UR  - https://doi.org/10.1145/3678299.3678317
KW  - Human computer interaction
KW  - 2D drawing
KW  - 3D drawing
KW  - Audio-visual interfaces
KW  - Music
KW  - Sonification
ER  - 

TY  - CONF
TI  - Proof-of-concept study to evaluate the impact of spatial audio on social presence and user behavior in multi-modal VR communication
AU  - Immohr, Felix
AU  - Rendle, Gareth
AU  - Neidhardt, Annika
AU  - Göring, Steve
AU  - Ramachandra Rao, Rakesh Rao
AU  - Arevalo Arboleda, Stephanie
AU  - Froehlich, Bernd
AU  - Raake, Alexander
T3  - Imx '23
AB  - This paper presents a proof-of-concept study conducted to analyze the effect of simple diotic vs. spatial, position-dynamic binaural synthesis on social presence in VR, in comparison with face-to-face communication in the real world, for a sample two-party scenario. A conversational task with shared visual reference was realized. The collected data includes questionnaires for direct assessment, tracking data, and audio and video recordings of the individual participants’ sessions for indirect evaluation. While tendencies for improvements with binaural over diotic presentation can be observed, no significant difference in social presence was found for the considered scenario. The gestural analysis revealed that participants used the same amount and type of gestures in face-to-face as in VR, highlighting the importance of non-verbal behavior in communication. As part of the research, an end-to-end framework for conducting communication studies and analysis has been developed.
C1  - Nantes, France
C3  - Proceedings of the 2023 ACM international conference on interactive media experiences
DA  - 2023///
PY  - 2023
DO  - 10.1145/3573381.3596458
SP  - 209
EP  - 215
PB  - Association for Computing Machinery
SN  - 979-8-4007-0028-6
UR  - https://doi.org/10.1145/3573381.3596458
KW  - virtual reality
KW  - social presence
KW  - communication
KW  - spatial audio
KW  - user behavior
ER  - 

TY  - CONF
TI  - PeerEdu: Bootstrapping online learning behaviors via asynchronous area of interest sharing from peer gaze
AU  - Xu, Songlin
AU  - Hu, Dongyin
AU  - Wang, Ru
AU  - Zhang, Xinyu
T3  - Chi '25
AB  - Human visual attention is susceptible to social influences. In education, peer effects impact student learning, but their precise role in modulating attention remains unclear. To this end, we have developed an online education system that provides visual feedback to students based on the area of interest sharing of peer students’ gaze patterns. Our experiment (N=311) suggested that although peer attention manipulated students’ gaze, individuals adapted their viewing strategies rather than always mirroring peer focus. Furthermore, intentionally guiding students’ gaze along the lecture pace did not always improve learning outcomes. Instead, students able to adaptively adjust their focus based on personal needs showed enhanced performance. These findings elucidate how peer visual attention shapes students’ gaze patterns, deepening understanding of peer influence on learning. They also offer insights into designing adaptive online learning interventions leveraging peer attention modelling to optimize student attentiveness and learning success.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713480
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713480
KW  - Gaze Sharing
KW  - Peer Effect
KW  - Student Behavioral Intervention
ER  - 

TY  - CONF
TI  - Making a metaphor sandwich: Analyzing children's use of metaphor during tabletop telepresence robot supported participatory design
AU  - Hunt, Casey Lee
AU  - Sun, Kaiwen
AU  - Tseng, Kaitlyn
AU  - Balasubramaniyam, Priyanka
AU  - Druin, Allison
AU  - Huynh, Amanda
AU  - Leithinger, Daniel
AU  - Yip, Jason
T3  - Idc '24
AB  - ABSTRACTStrengthening telepresence for children can improve their educational and socio-emotional outcomes. Meanwhile, understanding how children conceptualize new technologies supports designers to create engaging and intuitive interactions for them. In this pictorial, we explore children's relationship to a promising and emerging approach to telepresence-tabletop robots. We analyze metaphors children used to describe a tabletop telepresence robot platform during 2-years (100 hours) of online participatory design with this technology. We use illustrations to convey and contextualize how children imagined the tabletop telepresence robots. We find that children used three categories of metaphor in their imaginings: (1) robot capabilities (magic/fragile), (2) robot roles (competitive/play-acting/creative), (3) robot agency (remote controlled/autonomous). We discuss these metaphors in the context of existing child-robot interaction, tangible interaction, and telepresence literature. Finally, we contribute the theoretical framework of a ‘metaphor sandwich’ to describe children's use of mixed metaphors during high engagement with the tabletop telepresence robots.
C1  - Delft, Netherlands
C3  - Proceedings of the 23rd annual ACM interaction design and children conference
DA  - 2024///
PY  - 2024
DO  - 10.1145/3628516.3656272
SP  - 173
EP  - 188
PB  - Association for Computing Machinery
SN  - 979-8-4007-0442-0
UR  - https://doi.org/10.1145/3628516.3656272
ER  - 

TY  - JOUR
TI  - Exploring collaboration in programming activities with children with visual impairments: a 10-session study in a school setting
AU  - Rocha, Filipa
AU  - Gonçalves, David
AU  - Pires, Ana Cristina
AU  - Nicolau, Hugo
AU  - Guerreiro, Tiago
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Introductory coding environments have been used in early education to promote computational thinking, supporting the development of cognitive, critical, and social skills. Many environments focus on individual use, which has limited benefits compared to collaborative learning. In this paper, we present the results of a 10-session study at a local primary school engaging eleven children with visual impairments and three inclusive education teachers in collaborative programming activities. Based on participants' behavior, reactions, and feedback, we contribute an improved understanding of collaborative design in educational settings, focusing on the impact of Goals, Workspace, Interdependence, and Shared Awareness. Our main findings outline how collaboration dynamics can be shaped by asymmetric tasks, workspace proximity, and group awareness. We further discuss factors that led to a lack of investment in the shared goal and instances of unbalanced collaboration, reflecting on challenges and opportunities for designing collaborative inclusive coding kits.
DA  - 2025/05//
PY  - 2025
DO  - 10.1145/3710971
VL  - 9
IS  - 2
UR  - https://doi.org/10.1145/3710971
KW  - robot
KW  - collaboration
KW  - tangible
KW  - children
KW  - accessible
KW  - computational thinking
KW  - mixed-visual ability
KW  - visually impaired
ER  - 

TY  - JOUR
TI  - Understanding the interplay between the digital and the physical in shared augmented reality gaming: Probing through urban legends
AU  - Xu, Jiangnan
AU  - Luna, Sanzida Mojib
AU  - Tigwell, Garreth W.
AU  - Lalone, Nicolas
AU  - Saker, Michael
AU  - Laato, Samuli
AU  - Dunham, John
AU  - Wang, Yihong
AU  - Chamberlain, Alan
AU  - Papangelis, Konstantinos
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - Shared Augmented Reality (Shared AR) is an emerging technology that enables multiple users to interact synchronously within a collocated AR environment. Yet, there is limited research on the group interactions and dynamics in Shared AR, particularly in the context of gaming. To address this gap, we investigate Shared AR group interactions using a phone-based Shared AR mobile game called Urban Legends. Through in-situ observations, focus groups, and one-on-one interviews with 22 participants, we examine how users collaborate and communicate within the game. Our findings reveal that while verbal communication predominates, non-verbal cues are often overlooked by collocated participants, and users initially struggle to recognize the expansive virtual space and the need for physical movement. Over time, users adapt to the hybrid environment, demonstrating increasing spatial awareness and more dynamic collaboration. Based on these insights, we present a suite of design recommendations for enhancing spatial awareness, supporting multi-modal communication, and fostering engaging group dynamics in future Shared AR applications.
DA  - 2025/08//
PY  - 2025
DO  - 10.1145/3749841
SN  - 1073-0516
UR  - https://doi.org/10.1145/3749841
N1  - Just Accepted
KW  - Social Interaction
KW  - Contextual Inquiry
KW  - Group Dynamics
KW  - Shared AR
KW  - Social AR
KW  - Social XR
KW  - Spatial Computing
ER  - 

TY  - CONF
TI  - Datamancer: Bimanual gesture interaction in multi-display ubiquitous analytics environments
AU  - Patnaik, Biswaksen
AU  - Borowski, Marcel
AU  - Peng, Huaishu
AU  - Klokmose, Clemens Nylandsted
AU  - Elmqvist, Niklas
T3  - Chi '25
AB  - We introduce Datamancer, a wearable device enabling bimanual gesture interaction across multi-display ubiquitous analytics environments. Datamancer addresses the gap in gesture-based interaction within data visualization settings, where current methods are often constrained by limited interaction spaces or the need for installing bulky tracking setups. Datamancer integrates a finger-mounted pinhole camera and a chest-mounted gesture sensor, allowing seamless selection and manipulation of visualizations on distributed displays. By pointing to a display, users can acquire the display and engage in various interactions, such as panning, zooming, and selection, using both hands. Our contributions include (1) an investigation of the design space of gestural interaction for physical ubiquitous analytics environments; (2) a prototype implementation of the Datamancer system that realizes this model; and (3) an evaluation of the prototype through demonstration of application scenarios, an expert review, and a user study.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713123
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713123
KW  - immersive analytics
KW  - Augmented Reality
KW  - Gestural interaction
KW  - situated analytics.
KW  - ubiquitous analytics
KW  - visualizations
ER  - 

TY  - JOUR
TI  - Reducing muscle activity when playing tremolo by using electrical muscle stimulation to learn efficient motor skills
AU  - Niijima, Arinobu
AU  - Takeda, Toki
AU  - Tanaka, Kentaro
AU  - Aoki, Ryosuke
AU  - Koike, Yukio
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
AB  - When beginners play the piano, the activity of the forearm muscles tends to be greater than that of experts because beginners move their fingers with more force than necessary. Reducing forearm muscle activity is important for pianists to prevent fatigue and injury. However, it is difficult for beginners to learn how to do so by themselves. We propose using electrical muscle stimulation (EMS) to teach beginners how to reduce this muscle activity while playing a tremolo: a rapid alternation between two notes. Since experts use wrist rotation efficiently when playing tremolos, we propose an EMS-based support system that applies EMS not to muscles that are relevant to moving the fingers but to the supinator and pronator teres muscles, which are involved in wrist rotation. We conducted a user study with 16 beginners to investigate how the forearm muscle activity on the extensor pollicis longus and digitorum muscles changed when using our EMS-based support system. We divided the participants into two groups: an experimental group who practiced by themselves with EMS and a control group who practiced by themselves without EMS and then practiced with instruction. When practicing by themselves, practicing with EMS was more effective than that without EMS; the activity levels of the extensor pollicis longus and digitorum muscles were significantly lower with EMS, and the participants felt less fatigue when playing tremolos. By comparing the improvement in reducing muscle activity between practicing with EMS and practicing with instruction, there was no significant difference. The results suggest that our EMS-based support system can reduce target muscle activity by applying EMS to other muscles to teach beginners how to move limbs efficiently.
DA  - 2021/09//
PY  - 2021
DO  - 10.1145/3478110
VL  - 5
IS  - 3
UR  - https://doi.org/10.1145/3478110
KW  - electrical muscle stimulation
KW  - electromyography
KW  - muscle activity
KW  - piano
KW  - tremolo
ER  - 

TY  - CONF
TI  - Exploring the co-manipulation of physical and virtual objects in tangible mobile augmented reality for collaborative learning
AU  - Gardeli, Anna
AU  - Vosinakis, Spyros
T3  - Chigreece '23
AB  - Collaborative mobile augmented reality (MAR) has emerged as a promising tool in the field of education. This technology enables multiple users to interact with digital content overlaid on the physical world through their mobile devices. Collaborative MAR combined with tangible elements enhances learning by integrating physical objects that can be manipulated and interacted with in the augmented reality environment, providing a hands-on and immersive educational experience. This study explores the impact of tangible mobile augmented reality on collaboration and object manipulation. Our goal is to understand how mobile devices’ manipulation affects collocated students' collaboration in tangible MAR in terms of ease of use and collaboration. The study involves participants working in pairs to facilitate collaboration through a MAR game for developing the computational thinking skills of primary school students. Our goal is to compare the perceived behaviors and interactions that emerged in two distinct MAR settings: (1) Stand-mounted device condition, where the device is fixed on a mobile stand, and (2) Hand-held device condition, where the device is held by one of the team's players. The same task is simulated in both settings to allow for direct comparison. The results of this study can help inform the design and development of future MAR systems and provide insights into the potential benefits and challenges in terms of collaboration and object manipulation.
C1  - Athens, Greece
C3  - Proceedings of the 2nd international conference of the ACM greek SIGCHI chapter
DA  - 2023///
PY  - 2023
DO  - 10.1145/3609987.3610004
PB  - Association for Computing Machinery
SN  - 979-8-4007-0888-6
UR  - https://doi.org/10.1145/3609987.3610004
ER  - 

TY  - CONF
TI  - A palmtop display for dextrous manipulation with haptic sensation
AU  - Noma, Haruo
AU  - Miyasato, Tsutomu
AU  - Kishino, Fumio
T3  - Chi '96
C1  - Vancouver, British Columbia, Canada
C3  - Proceedings of the SIGCHI conference on human factors in computing systems
DA  - 1996///
PY  - 1996
DO  - 10.1145/238386.238454
SP  - 126
EP  - 133
PB  - Association for Computing Machinery
SN  - 0-89791-777-4
UR  - https://doi.org/10.1145/238386.238454
KW  - virtual reality
KW  - user interface
KW  - force display
KW  - haptic sensation
KW  - palmtop display
KW  - teleconference
ER  - 

TY  - CONF
TI  - AirConstellations: In-air device formations for cross-device interaction via multiple spatially-aware armatures
AU  - Marquardt, Nicolai
AU  - Henry Riche, Nathalie
AU  - Holz, Christian
AU  - Romat, Hugo
AU  - Pahud, Michel
AU  - Brudy, Frederik
AU  - Ledo, David
AU  - Park, Chunjong
AU  - Nicholas, Molly Jane
AU  - Seyed, Teddy
AU  - Ofek, Eyal
AU  - Lee, Bongshin
AU  - Buxton, William A.S.
AU  - Hinckley, Ken
T3  - Uist '21
AB  - AirConstellations supports a unique semi-fixed style of cross-device interactions via multiple self-spatially-aware armatures to which users can easily attach (or detach) tablets and other devices. In particular, AirConstellations affords highly flexible and dynamic device formations where the users can bring multiple devices together in-air&nbsp;—&nbsp;with 2–5 armatures poseable in 7DoF within the same workspace&nbsp;—&nbsp;to suit the demands of their current task, social situation, app scenario, or mobility needs. This affords an interaction metaphor where relative orientation, proximity, attaching (or detaching) devices, and continuous movement into and out of ad-hoc ensembles can drive context-sensitive interactions. Yet all devices remain self-stable in useful configurations even when released in mid-air. We explore flexible physical arrangement, feedforward of transition options, and layering of devices in-air across a variety of multi-device app scenarios. These include video conferencing with flexible arrangement of the person-space of multiple remote participants around a shared task-space, layered and tiled device formations with overview+detail and shared-to-personal transitions, and flexible composition of UI panels and tool palettes across devices for productivity applications. A preliminary interview study highlights user reactions to AirConstellations, such as for minimally disruptive device formations, easier physical transitions, and balancing ”seeing and being seen” in remote work.
C1  - Virtual Event, USA
C3  - The 34th annual ACM symposium on user interface software and technology
DA  - 2021///
PY  - 2021
DO  - 10.1145/3472749.3474820
SP  - 1252
EP  - 1268
PB  - Association for Computing Machinery
SN  - 978-1-4503-8635-7
UR  - https://doi.org/10.1145/3472749.3474820
KW  - interaction techniques
KW  - cross-device computing
KW  - cross-device tracking
KW  - device ecologies
KW  - device formations
KW  - multi-device
KW  - platform
KW  - semi-fixed workspaces
KW  - SurfaceFleet
ER  - 

TY  - CONF
TI  - VAction: a lightweight and integrated VR training system for authentic film-shooting experience
AU  - Wang, Shaocong
AU  - Qu, Che
AU  - Yu, Minjing
AU  - Zhou, Chao
AU  - Wang, Yuntao
AU  - Wen, Yu-Hui
AU  - Shi, Yuanchun
AU  - Liu, Yong-Jin
T3  - Chi '25
AB  - The film industry exerts significant economic and cultural influence, and its rapid development is contingent upon the expertise of industry professionals, underscoring the critical importance of film-shooting education. However, this process typically necessitates multiple practice in complex professional venues using expensive equipment, presenting a significant obstacle for ordinary learners who struggle to access such training environments. Despite VR technology has already shown its potential in education, existing research has not addressed the crucial learning component of replicating the shooting process. Moreover, the limited functionality of traditional controllers hinder the fulfillment of the educational requirements. Therefore, we developed VAction VR system, combining high-fidelity virtual environments with a custom-designed controller to simulate the real-world camera operation experience. The system’s lightweight design ensures cost-effective and efficient deployment. Experiment results demonstrated that VAction significantly outperforms traditional methods in both practice effectiveness and user experience, indicating its potential and usefulness in film-shooting education.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3714217
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3714217
KW  - Virtual Reality
KW  - Film Production Education
KW  - Interaction Design
KW  - Training System
ER  - 

TY  - CONF
TI  - Breaking the familiarity bias: Employing virtual reality environments to enhance team formation and inclusion
AU  - Fernandez-Espinosa, Mariana
AU  - Clouse, Kara
AU  - Sellars, Dylan
AU  - Tong, Danny
AU  - Bsales, Michael
AU  - Alcindor, Sophonie
AU  - Hubbard, Timothy D
AU  - Villano, Michael
AU  - Gómez-Zará, Diego
T3  - Chi '25
AB  - Team closeness provides the foundations of trust and communication, contributing to teams’ success and viability. However, newcomers often struggle to be included in a team since incumbents tend to interact more with other existing members. Previous research suggests that online communication technologies can help team inclusion by mitigating members’ perceived differences. In this study, we test how virtual reality (VR) can promote team closeness when forming teams. We conducted a between-subject experiment with teams working in-person and VR, where two members interacted first, and then a third member was added later to conduct a hidden-profile task. Participants evaluated how close they felt with their teammates after the task was completed. Our results show that VR newcomers felt closer to the incumbents than in-person newcomers. However, incumbents’ closeness to newcomers did not vary across conditions. We discuss the implications of these findings and offer suggestions for how VR can promote inclusion.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3714127
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3714127
KW  - Virtual Reality
KW  - Familiarity Bias
KW  - Newcomers
KW  - Team Formation
KW  - Team Inclusion
ER  - 

TY  - CONF
TI  - MechVR: a physics-based proxy for locomotion and interaction in a virtual environment
AU  - Zordan, Victor
AU  - Welter, John
AU  - Hindlekar, Saurabh
AU  - Smith, J. Emerson
AU  - Mckay, W. Garrett
AU  - Lowe, Kunta
AU  - Marti, Carlos
AU  - Taylor, R. Austin
T3  - Mig '17
AB  - We present an immersive Virtural Reality (VR) experience developed through a unique combination of technologies including an actuated hardware rig; a physics model with a responsive control routine; and an interactive 3D gamelike experience. Specifically, this paper introduces a physics-based communication framework that allows force-driven interaction to be conveyed to a user through a physics-based proxy. Because the framework is generic and extendable, the application supports a variety of interaction modes, constrained by the limitations of the physical full-body haptic rig. To showcase the technology, we highlight the experience of riding locomoting robots and vehicles placed in an immersive VR setting.
C1  - Barcelona, Spain
C3  - Proceedings of the 10th international conference on motion in games
DA  - 2017///
PY  - 2017
DO  - 10.1145/3136457.3136468
PB  - Association for Computing Machinery
SN  - 978-1-4503-5541-4
UR  - https://doi.org/10.1145/3136457.3136468
KW  - virtual reality
KW  - motion simulator
KW  - physics-based animation
ER  - 

TY  - CONF
TI  - Fusion: full body surrogacy for collaborative communication
AU  - Saraiji, MHD Yamen
AU  - Sasaki, Tomoya
AU  - Matsumura, Reo
AU  - Minamizawa, Kouta
AU  - Inami, Masahiko
T3  - Siggraph '18
AB  - Effective communication is a key factor in social and professional contexts which involve sharing the skills and actions of more than one person. This research proposes a novel system to enable full body sharing over a remotely operated wearable system, allowing one person to dive into someone's else body. "Fusion" enables body surrogacy by sharing the same point of view of two-person: a surrogate and an operator, and it extends the limbs mobility and actions of the operator using two robotic arms mounted on the surrogate body. These arms can be used independently of the surrogate arms for collaborative scenarios or can be linked to surrogate's arms to be used in remote assisting and supporting scenarios. Using Fusion, we realize three levels of bodily driven communication: Direct, Enforced, and Induced. We demonstrate through this system the possibilities of truly embodying and transferring our body actions from one person to another, realizing true body communication.
C1  - Vancouver, British Columbia, Canada
C3  - ACM SIGGRAPH 2018 emerging technologies
DA  - 2018///
PY  - 2018
DO  - 10.1145/3214907.3214912
PB  - Association for Computing Machinery
SN  - 978-1-4503-5810-1
UR  - https://doi.org/10.1145/3214907.3214912
KW  - body scheme alternation
KW  - collaborative systems
KW  - surrogacy
ER  - 

TY  - CONF
TI  - Towards collaborative learning in virtual reality: a comparison of co-located symmetric and asymmetric pair-learning
AU  - Drey, Tobias
AU  - Albus, Patrick
AU  - der Kinderen, Simon
AU  - Milo, Maximilian
AU  - Segschneider, Thilo
AU  - Chanzab, Linda
AU  - Rietzler, Michael
AU  - Seufert, Tina
AU  - Rukzio, Enrico
T3  - Chi '22
AB  - Pair-learning is beneficial for learning outcome, motivation, and social presence, and so is virtual reality (VR) by increasing immersion, engagement, motivation, and interest of students. Nevertheless, there is a research gap if the benefits of pair-learning and VR can be combined. Furthermore, it is not clear which influence it has if only one or both peers use VR. To investigate these aspects, we implemented two types of VR pair-learning systems, a symmetric system with both peers using VR and an asymmetric system with one using a tablet. In a user study (N=46), the symmetric system statistically significantly provided higher presence, immersion, player experience, and lower intrinsic cognitive load, which are all important for learning. Symmetric and asymmetric systems performed equally well regarding learning outcome, highlighting that both are valuable learning systems. We used these findings to define guidelines on how to design co-located VR pair-learning applications, including characteristics for symmetric and asymmetric systems.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI conference on human factors in computing systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491102.3517641
PB  - Association for Computing Machinery
SN  - 978-1-4503-9157-3
UR  - https://doi.org/10.1145/3491102.3517641
KW  - virtual reality
KW  - collaborative learning
KW  - pair-learning
KW  - signaling
KW  - symmetric and asymmetric system
ER  - 

TY  - CONF
TI  - Exploring the design space of privacy-driven adaptation techniques for future augmented reality interfaces
AU  - Rajaram, Shwetha
AU  - Peralta, Macarena
AU  - Johnson, Janet G.
AU  - Nebeling, Michael
T3  - Chi '25
AB  - Modern augmented reality (AR) devices with advanced display and sensing capabilities pose significant privacy risks to users and bystanders. While previous context-aware adaptations focused on usability and ergonomics, we explore the design space of privacy-driven adaptations that allow users to meet their dynamic needs. These techniques offer granular control over AR sensing capabilities across various AR input, output, and interaction modalities, aiming to minimize degradations to the user experience. Through an elicitation study with 10 AR researchers, we derive 62 privacy-focused adaptation techniques that preserve key AR functionalities and classify them into system-driven, user-driven, and mixed-initiative approaches to create an adaptation catalog. We also contribute a visualization tool that helps AR developers navigate the design space, validating its effectiveness in design workshops with six AR developers. Our findings indicate that the tool allowed developers to discover new techniques, evaluate tradeoffs, and make informed decisions that balance usability and privacy concerns in AR design.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713320
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713320
KW  - threat modeling
KW  - elicitation studies
ER  - 

TY  - JOUR
TI  - Interaction with virtual content using augmented reality: a user study in assembly procedures
AU  - Marques, Bernardo
AU  - Alves, João
AU  - Neves, Miguel
AU  - Justo, Inês
AU  - Santos, André
AU  - Rainho, Raquel
AU  - Maio, Rafael
AU  - Costa, Dany
AU  - Ferreira, Carlos
AU  - Dias, Paulo
AU  - Santos, Beatriz Sousa
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Assembly procedures are a common task in several domains of application. Augmented Reality (AR) has been considered as having great potential in assisting users while performing such tasks. However, poor interaction design and lack of studies, often results in complex and hard to use AR systems. This paper considers three different interaction methods for assembly procedures (Touch gestures in a mobile device; Mobile Device movements; 3D Controllers and See-through HMD). It also describes a controlled experiment aimed at comparing acceptance and usability between these methods in an assembly task using Lego blocks. The main conclusions are that participants were faster using the 3D controllers and Video see-through HMD. Participants also preferred the HMD condition, even though some reported light symptoms of nausea, sickness and/or disorientation, probably due to limited resolution of the HMD cameras used in the video see-through setting and some latency issues. In addition, although some research claims that manipulation of virtual objects with movements of the mobile device can be considered as natural, this condition was the least preferred by the participants.
DA  - 2020/11//
PY  - 2020
DO  - 10.1145/3427324
VL  - 4
IS  - ISS
UR  - https://doi.org/10.1145/3427324
KW  - augmented reality
KW  - interaction
KW  - assembly guidance
KW  - controllers
KW  - device movement
KW  - mid-air gestures
KW  - touch gestures
KW  - user study
ER  - 

TY  - CONF
TI  - Customized toolbox in VR design
AU  - Drampalou, Georgia
AU  - Kourniatis, Nikolaos
AU  - Voyiatzis, Ioannis
T3  - Pci '22
AB  - Designing in an environment of Virtual Reality is a field that gains ground. Although more and more applications are constantly released, the majority of designers have not yet been introduced into Virtual Reality. A widely used tool for designing is Rhino which has been released by McNeel and Rhino Developer encourages the users to create plug-ins for custom use of the software. In parallel, Meta's developing tools offer their users the chance to customize their own applications. Towards the direction of Virtual Reality integration, both have already released new products for their users. RhinoVR is an open source plug-in for Rhino, while at the same time Meta provides Oculus hardware and platform solutions for users to turn their concept into reality. What is yet to be developed is a model that encourages the customization of a VR design platform, focusing mainly on developing a personalized toolbox for designing.
C1  - Athens, Greece
C3  - Proceedings of the 26th pan-hellenic conference on informatics
DA  - 2023///
PY  - 2023
DO  - 10.1145/3575879.3575960
SP  - 14
EP  - 20
PB  - Association for Computing Machinery
SN  - 978-1-4503-9854-1
UR  - https://doi.org/10.1145/3575879.3575960
KW  - cross-platform.NET plug-in SDK
KW  - Oculus Quest 2
KW  - OpenVR API
KW  - Rhino Developer
KW  - VR Design
ER  - 

TY  - CONF
TI  - Spacetime: Enabling fluid individual and collaborative editing in virtual reality
AU  - Xia, Haijun
AU  - Herscher, Sebastian
AU  - Perlin, Ken
AU  - Wigdor, Daniel
T3  - Uist '18
AB  - Virtual Reality enables users to explore content whose physics are only limited by our creativity. Such limitless environments provide us with many opportunities to explore innovative ways to support productivity and collaboration. We present Spacetime, a scene editing tool built from the ground up to explore the novel interaction techniques that empower single user interaction while maintaining fluid multi-user collaboration in immersive virtual environment. We achieve this by introducing three novel interaction concepts: the Container, a new interaction primitive that supports a rich set of object manipulation and environmental navigation techniques, Parallel Objects, which enables parallel manipulation of objects to resolve interaction conflicts and support design workflows, and Avatar Objects, which supports interaction among multiple users while maintaining an individual users' agency. Evaluated by professional Virtual Reality designers, Spacetime supports powerful individual and fluid collaborative workflows.
C1  - Berlin, Germany
C3  - Proceedings of the 31st annual ACM symposium on user interface software and technology
DA  - 2018///
PY  - 2018
DO  - 10.1145/3242587.3242597
SP  - 853
EP  - 866
PB  - Association for Computing Machinery
SN  - 978-1-4503-5948-1
UR  - https://doi.org/10.1145/3242587.3242597
KW  - virtual reality
KW  - interaction techniques
KW  - computer-supported collaborative work
ER  - 

TY  - BOOK
TI  - SA '16: SIGGRAPH ASIA 2016 mobile graphics and interactive applications
AB  - The SIGGRAPH Asia Symposium on Mobile Graphics and Interactive Applications will offer attendees the opportunity to explore the opportunities and challenges of mobile applications relevant to the global graphics community.The program will cover the development, technology, and marketing of mobile graphics and interactive applications. It will especially highlight novel uses of graphics and interactivity on mobile devices. Attendees can expect to be exposed to the latest in mobile graphics and interactive applications through expert keynote talks, paper presentations, panel discussions, industry case studies, and hands-on demonstrations.
CY  - New York, NY, USA
DA  - 2016///
PY  - 2016
PB  - Association for Computing Machinery
SN  - 978-1-4503-4551-4
ER  - 

TY  - CONF
TI  - Employing different viewpoints for remote guidance in a collaborative augmented environment
AU  - Sun, Hongling
AU  - Liu, Yue
AU  - Zhang, Zhenliang
AU  - Liu, Xiaoxu
AU  - Wang, Yongtian
T3  - ChineseCHI '18
AB  - This paper details the design, implementation and an initial evaluation of a collaborative platform named OptoBridge, which is aimed at enhancing remote guidance and skill acquisition for spatially distributed users. OptoBridge integrates augmented reality (AR), gesture interaction with video mediated communication and is preliminarily applied to the experimental teaching of the adjustment task with Michelson interferometer. An exploratory study has been conducted to qualitatively and quantitatively evaluate the extent to which different viewpoints affect the student's sense of presence, task performance, learning outcomes and subjective feelings in the remote collaborative augmented environment. 16 students from local universities have participated in the evaluation. The result shows the influence of two different viewpoints and indicates that OptoBridge can effectively support remote guidance and enhance the collaborators' experience.
C1  - Montreal, QC, Canada
C3  - Proceedings of the sixth international symposium of chinese CHI
DA  - 2018///
PY  - 2018
DO  - 10.1145/3202667.3202676
SP  - 64
EP  - 70
PB  - Association for Computing Machinery
SN  - 978-1-4503-6508-6
UR  - https://doi.org/10.1145/3202667.3202676
KW  - AR
KW  - gesture interaction
KW  - remote guidance
KW  - Viewpoint
ER  - 

TY  - JOUR
TI  - RE methods for virtual reality software product development: a mapping study
AU  - Karre, Sai Anirudh
AU  - Reddy, Y. Raghu
AU  - Mittal, Raghav
T2  - ACM Trans. Softw. Eng. Methodol.
AB  - Software practitioners use various methods in Requirements Engineering (RE) to elicit, analyze, and specify the requirements of enterprise products. The methods impact the final product characteristics and influence product delivery. Ad-hoc usage of the methods by software practitioners can lead to inconsistency and ambiguity in the product. With the notable rise in enterprise products, games, and so forth across various domains, Virtual Reality (VR) has become an essential technology for the future. The methods adopted for RE for developing VR products requires a detailed study. This article presents a mapping study on RE methods prescribed and used for developing VR applications including requirements elicitation, requirements analysis, and requirements specification. Our study provides insights into the use of such methods in the VR community and suggests using specific RE methods in various fields of interest. We also discuss future directions in RE for VR products.
DA  - 2024/04//
PY  - 2024
DO  - 10.1145/3649595
VL  - 33
IS  - 4
SN  - 1049-331X
UR  - https://doi.org/10.1145/3649595
KW  - virtual reality
KW  - industrial practices
KW  - requirements elicitation
KW  - Software requirements
ER  - 

TY  - BOOK
TI  - SA '17: SIGGRAPH asia 2017 emerging technologies
AB  - Interactive technology has been one of the most important inseparable wheels of SIGGRAPH Asia, and the Emerging Technologies program plays a vital role in driving the research communities all over the world to pursue technological innovations that has a great impact on our everyday life.This year, the Emerging Technologies program presents a broad scope of topics, reflecting the innovation of interactive technologies and a maturation of the field as it expands to include interactive visualization and other graphics-related technologies.Be fascinated by hands-on demonstrations that expand the limits of current display technologies, and exciting new hardware that enable sophisticated and nuanced user input, innovative interaction techniques that enable more complex interaction with application data and functionality, as well as excellent examples of haptics developed to support multi-/cross-modality scenarios.
CY  - New York, NY, USA
DA  - 2017///
PY  - 2017
PB  - Association for Computing Machinery
SN  - 978-1-4503-5404-2
ER  - 

TY  - CONF
TI  - Requirements elicitation for virtual reality products - a mapping study
AU  - Karre, Sai Anirudh
AU  - Mittal, Raghav
AU  - Reddy, Raghu
T3  - Isec '23
AB  - Software practitioners use various requirement elicitation methods to produce a well-defined product. These methods impact the software product’s eventual traits and target a particular audience segment. Virtual Reality(VR) products are no different from this influence. With the notable rise in product offerings across various domains, VR has become an essential technology for the future. Nevertheless, the type of methods practiced for requirement elicitation still has not been thoroughly studied. This paper presents a mapping study on requirement elicitation methods practiced by VR practitioners in academia and industry. We consolidated our observations based on their popularity in the practitioner community. Further, we present our insights on the necessary and sufficient conditions to conduct VR requirement elicitation using the identified methods to benefit the VR practitioner community.
C1  - Allahabad, India
C3  - Proceedings of the 16th innovations in software engineering conference
DA  - 2023///
PY  - 2023
DO  - 10.1145/3578527.3578536
PB  - Association for Computing Machinery
SN  - 979-8-4007-0064-4
UR  - https://doi.org/10.1145/3578527.3578536
KW  - Virtual Reality
KW  - Software requirements
KW  - Industrial practices
KW  - Requirement elicitation
ER  - 

TY  - BOOK
TI  - SA '18: SIGGRAPH asia 2018 virtual &amp; augmented reality
AB  - Following the success of Virtual and Augmented Reality at previous SIGGRAPH Asia series, the Virtual and Augmented Reality (VR/AR) program at SIGGRAPH Asia 2018 provides an opportunity to explore emerging media and cutting edge technologies in virtual, augmented, and mixed reality. The SIGGRAPH Asia VR AR offers a highly visible and interactive venue to take a deep dive into these emerging digital media and interactive technologies.
CY  - New York, NY, USA
DA  - 2018///
PY  - 2018
PB  - Association for Computing Machinery
SN  - 978-1-4503-6028-9
ER  - 

TY  - CONF
TI  - Collaborative scenario builder: a VR co-design tool for medical first responders
AU  - Nguyen, Quynh
AU  - Pretolesi, Daniele
AU  - Gallhuber, Katja
T3  - GoodIT '23
AB  - The rising occurrence of natural and human-made disasters emphasises the urgent need for effective training of medical first responders (MFRs). Virtual Reality (VR) has recently been used to enhance traditional MFR training. However, to ensure that VR training improves disaster preparedness, it is not only crucial for MFR stakeholders to actively participate in the design process. It may also be beneficial to place the co-design process in VR so that novice co-designers establish a profound, hands-on understanding of VR as a training tool. Thus, we introduce the Collaborative Scenario Builder (CSB), a prototype for MFRs without technical and designerly expertise with which to co-design scenarios for virtual simulation training in VR. An evaluation with 33 MFR participants indicates that CSB is usable and provides participants with an embodied understanding of VR, leading to new perspectives in their collaborative design considerations. Thus, CSB contributes to a co-design workflow with MFR co-designers that ensures that created VR training tools are needed and beneficial for MFRs so that they can provide better aid to people in the face of disasters.
C1  - Lisbon, Portugal
C3  - Proceedings of the 2023 ACM conference on information technology for social good
DA  - 2023///
PY  - 2023
DO  - 10.1145/3582515.3609553
SP  - 342
EP  - 350
PB  - Association for Computing Machinery
SN  - 979-8-4007-0116-0
UR  - https://doi.org/10.1145/3582515.3609553
KW  - Virtual Reality
KW  - Co-Design
KW  - Medical First Responders
KW  - Virtual Simulation Training
ER  - 

TY  - BOOK
TI  - Chinese CHI '22: Proceedings of the tenth international symposium of chinese CHI
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9869-5
ER  - 

TY  - CONF
TI  - An exploratory study on how AI awareness impacts human-AI design collaboration
AU  - Cheng, Zhuoyi
AU  - Chen, Pei
AU  - Song, Wenzheng
AU  - Zhang, Hongbo
AU  - Li, Zhuoshu
AU  - Sun, Lingyun
T3  - Iui '25
AB  - The collaborative design process is intrinsically complicated and dynamic, and researchers have long been exploring how to enhance efficiency in this process. As Artificial Intelligence technology evolves, it has been widely used as a design tool and exhibited the potential as a design collaborator. Nevertheless, problems concerning how designers should communicate with AI in collaborative design remain unsolved. To address this research gap, we referred to how designers communicate fluently in human-human design collaboration, and found awareness to be an important ability for facilitating communication by understanding their collaborators and current situation. However, previous research mainly studied and supported human awareness, the possible impact AI awareness would bring to the human-AI collaborative design process, and the way to realize AI awareness remain unknown. In this study, we explored how AI awareness will impact human-AI collaboration through a Wizard-of-Oz experiment. Both quantitative and qualitative results supported that enabling AI to have awareness can enhance the communication fluidity between human and AI, thus enhancing collaboration efficiency. We further discussed the results and concluded design implications for future human-AI collaborative design systems.
C1  - New York, NY, USA
C3  - Proceedings of the 30th international conference on intelligent user interfaces
DA  - 2025///
PY  - 2025
DO  - 10.1145/3708359.3712162
SP  - 157
EP  - 172
PB  - Association for Computing Machinery
SN  - 979-8-4007-1306-4
UR  - https://doi.org/10.1145/3708359.3712162
KW  - AI Awareness
KW  - Design collaboration
KW  - Generative AI
KW  - Human-AI collaboration
KW  - Human-AI communication
ER  - 

TY  - CONF
TI  - Estimating detection thresholds of being looked at in virtual reality for avatar redirection
AU  - Schott, Ephraim
AU  - López Garcı́a, Irene
AU  - Semple, Lauren August
AU  - Froehlich, Bernd
T3  - Chi '25
AB  - The human face and eyes provide crucial conversational cues about a person’s focus of attention. In virtual reality applications, avatar faces are typically simplified, and eye movements often neglected. This paper explores how VR users perceive the look-at direction of other avatars and estimates the range within which an avatar’s averted gaze goes unnoticed. Through two-alternative forced choice experiments, we investigate different gaze offsets to quantify thresholds for perceived gaze aversion across three conditions: gaze side (left/right), stimulus duration, and avatar distance. Additionally, we assess the impact of averted gaze on social presence during interactions with an embodied conversational agent in a social game. A user study (N=40) revealed that social presence is significantly affected by averted gaze when noticed, and that detection thresholds are particularly impacted by stimuli duration and interactions between side and distance. Our findings provide a foundation for understanding gaze perception in social virtual reality.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3714041
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3714041
KW  - virtual reality
KW  - avatar redirection
KW  - averted gaze
KW  - embodied conversational agents
KW  - gaze direction
KW  - gaze perception
KW  - threshold detection
ER  - 

TY  - CONF
TI  - Electrical head actuation: Enabling interactive systems to directly manipulate head orientation
AU  - Tanaka, Yudai
AU  - Nishida, Jun
AU  - Lopes, Pedro
T3  - Chi '22
AB  - We propose a novel interface concept in which interactive systems directly manipulate the user's head orientation. We implement this using electrical-muscle-stimulation (EMS) of the neck muscles, which turns the head around its yaw (left/right) and pitch (up/down) axis. As the first exploration of EMS for head actuation, we characterized which muscles can be robustly actuated. Second, we evaluated the accuracy of our system for actuating participants' head orientation towards static targets and trajectories. Third, we demonstrated how it enables interactions not possible before by building a range of applications, such as (1) synchronizing head orientations of two users, which enables a user to communicate head nods to another user while listening to music, and (2) directly changing the user's head orientation to locate objects in AR. Finally, in our second study, participants felt that our head actuation contributed positively to their experience in four distinct applications.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI conference on human factors in computing systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491102.3501910
PB  - Association for Computing Machinery
SN  - 978-1-4503-9157-3
UR  - https://doi.org/10.1145/3491102.3501910
KW  - Electrical Muscle Stimulation
KW  - Virtual Reality
KW  - Augmented Reality
KW  - Haptics
ER  - 

TY  - CONF
TI  - AR-based embodied avatar assistance for nonspeaking autistic people? Design and feasibility study
AU  - Dow, Travis
AU  - Pratishtha, Pratishtha
AU  - Alabood, Lorans
AU  - Jaswal, Vikram K.
AU  - Krishnamurthy, Diwakar
T3  - Dis '25
AB  - Many nonspeaking autistic individuals rely on Communication and Regulation Partners (CRPs) to develop spelling-based communication using physical letterboards, but this support is often geographically inaccessible. We developed a remote presence system using Augmented Reality (AR) to enable immersive, collaborative spelling instruction. The system features holographic letterboards and fully embodied avatars with real-time head and hand tracking, allowing remote interaction between students and CRPs. In a study with 18 nonspeaking autistic participants, 15 (83
C1  - New York, NY, USA
C3  - Proceedings of the 2025 ACM designing interactive systems conference
DA  - 2025///
PY  - 2025
DO  - 10.1145/3715336.3735807
SP  - 423
EP  - 440
PB  - Association for Computing Machinery
SN  - 979-8-4007-1485-6
UR  - https://doi.org/10.1145/3715336.3735807
KW  - Augmented Reality
KW  - Mixed Reality
KW  - Assistive Technology
KW  - Accessibility
KW  - Nonspeaking Autistic People
ER  - 

TY  - CONF
TI  - MAPVI: meeting accessibility for persons with visual impairments
AU  - Gunther, Sebastian
AU  - Koutny, Reinhard
AU  - Dhingra, Naina
AU  - Funk, Markus
AU  - Hirt, Christian
AU  - Miesenberger, Klaus
AU  - Mühlhäuser, Max
AU  - Kunz, Andreas
T3  - Petra '19
AB  - In recent years, the inclusion of persons with visual impairments (PVI) is taking tremendous steps, especially with regards to group meetings. However, a significant part of communication is conveyed through non-verbal communication which is commonly inaccessible, such as deictic pointing gestures or the mimics and body language of participants. In this vision paper, we present an overview of our project MAPVI. MAPVI proposes new technologies on making meetings more accessible for PVIs. Therefore, we explore which relevant information has to be tracked and how those can be sensed for the users. Finally, those captured information get translated into a multitude of haptic feedback to make them accessible.
C1  - Rhodes, Greece
C3  - Proceedings of the 12th ACM international conference on pervasive technologies related to assistive environments
DA  - 2019///
PY  - 2019
DO  - 10.1145/3316782.3322747
SP  - 343
EP  - 352
PB  - Association for Computing Machinery
SN  - 978-1-4503-6232-0
UR  - https://doi.org/10.1145/3316782.3322747
KW  - machine learning
KW  - haptics
KW  - assistive technologies
KW  - meetings
ER  - 

TY  - CONF
TI  - TAPE: Tangible augmented previz environment for filmmaking
AU  - Fei, Guangzheng
AU  - Liu, Dake
T3  - Chchi '23
AB  - This paper presents TAPE, a tangible augmented previsualization environment for filmmaking. Using tangible interfaces and augmented reality technology, TAPE combines physical props and virtual elements, allowing users to manipulate and position objects within and beyond a tabletop space to visualize and refine their film concepts. The paper describes the overall design of the TAPE system and presents key features of the integration of TUI and AR technology. The system was evaluated in a between-subjects user study with film professionals and students, demonstrating its potential to enhance the creative process and facilitate collaboration.
C1  - Denpasar, Bali, Indonesia
C3  - Proceedings of the eleventh international symposium of chinese CHI
DA  - 2024///
PY  - 2024
DO  - 10.1145/3629606.3629629
SP  - 251
EP  - 262
PB  - Association for Computing Machinery
SN  - 979-8-4007-1645-4
UR  - https://doi.org/10.1145/3629606.3629629
KW  - Augmented Reality
KW  - Tangible User Interface
KW  - Filmmaking
KW  - Previsualization
ER  - 

TY  - CONF
TI  - Esports and high performance HCI
AU  - Watson, Benjamin
AU  - Spjut, Josef
AU  - Kim, Joohwan
AU  - Listman, Jennifer
AU  - Kim, Sunjun
AU  - Wimmer, Raphael
AU  - Putrino, David
AU  - Lee, Byungjoo
T3  - Chi ea '21
AB  - Competitive esports is a growing worldwide phenomenon now rivaling traditional sports, with over 450 million views and 1 billion US dollars in revenue each year. For comparison, Major League Baseball has 500 million views and 10billioninrevenue,FIFASoccer900millionand1.6 billion. Despite this significant popularity, much of the world remains unaware of esports — and in particular, research on and for esports is still extremely scarce compared to esports’ impact and potential. The Esports and High Performance HCI (EHPHCI) workshop will begin addressing that research gap. In esports, athletes compete through the computer interface. Because this interface can make the difference between winning and losing, esports athletes are among the most expert computer interface users in the world, as other athletes are experts in using balls and shoes in traditional sports. The premise of this workshop is that people will apply esports technology broadly, improving performance in a wide range of human activity. The workshop will gather experts in engineering, human factors, psychology, design and the social and health sciences to discuss this deeply multidisciplinary enterprise.
C1  - Yokohama, Japan
C3  - Extended abstracts of the 2021 CHI conference on human factors in computing systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411763.3441313
PB  - Association for Computing Machinery
SN  - 978-1-4503-8095-9
UR  - https://doi.org/10.1145/3411763.3441313
KW  - esports
KW  - expert interaction techniques
KW  - expert users
ER  - 

TY  - JOUR
TI  - Six reasons why virtual reality is a game-changing computing and communication platform for organizations
AU  - Torro, Osku
AU  - Jalo, Henri
AU  - Pirkkalainen, Henri
T2  - Communications of The Acm
AB  - Beyond the pandemic, organizations need to recognize what digital assets, interactions, and communication processes reap the most benefits from virtual reality.
DA  - 2021/09//
PY  - 2021
DO  - 10.1145/3440868
VL  - 64
IS  - 10
SP  - 48
EP  - 55
J2  - Commun. ACM
SN  - 0001-0782
UR  - https://doi.org/10.1145/3440868
ER  - 

TY  - JOUR
TI  - NICER: a new and improved consumed endurance and recovery metric to quantify muscle fatigue of mid-air interactions
AU  - Li, Yi
AU  - Tag, Benjamin
AU  - Dai, Shaozhang
AU  - Crowther, Robert
AU  - Dwyer, Tim
AU  - Irani, Pourang
AU  - Ens, Barrett
T2  - ACM Trans. Graph.
AB  - Natural gestures are crucial for mid-air interaction, but predicting and managing muscle fatigue is challenging. Existing torque-based models are limited in their ability to model above-shoulder interactions and to account for fatigue recovery. We introduce a new hybrid model, NICER, which combines a torque-based approach with a new term derived from the empirical measurement of muscle contraction and a recovery factor to account for decreasing fatigue during rest. We evaluated NICER in a mid-air selection task using two interaction methods with different degrees of perceived fatigue. Results show that NICER can accurately model above-shoulder interactions as well as reflect fatigue recovery during rest periods. Moreover, both interaction methods show a stronger correlation with subjective fatigue measurement (ρ = 0.978/0.976) than a previous model, Cumulative Fatigue (ρ = 0.966/0.923), confirming that NICER is a powerful analytical tool to predict fatigue across a variety of gesture-based interactive applications.
DA  - 2024/07//
PY  - 2024
DO  - 10.1145/3658230
VL  - 43
IS  - 4
SN  - 0730-0301
UR  - https://doi.org/10.1145/3658230
KW  - interaction design
KW  - ergonomics
KW  - consumed endurance
KW  - cumulative fatigue
KW  - endurance
KW  - mid-air interactions
KW  - shoulder fatigue
ER  - 

TY  - CONF
TI  - In AI we trust: Investigating the relationship between biosignals, trust and cognitive load in VR
AU  - Gupta, Kunal
AU  - Hajika, Ryo
AU  - Pai, Yun Suen
AU  - Duenser, Andreas
AU  - Lochner, Martin
AU  - Billinghurst, Mark
T3  - Vrst '19
AB  - Human trust is a psycho-physiological state that is difficult to measure, yet is becoming increasingly important for the design of human-computer interactions. This paper explores if human trust can be measured using physiological measures when interacting with a computer interface, and how it correlates with cognitive load. In this work, we present a pilot study in Virtual Reality (VR) that uses a multi-sensory approach of Electroencephalography (EEG), galvanic skin response (GSR), and Heart Rate Variability (HRV) to measure trust with a virtual agent and explore the correlation between trust and cognitive load. The goal of this study is twofold; 1) to determine the relationship between biosignals, or physiological signals with trust and cognitive load, and 2) to introduce a pilot study in VR based on cognitive load level to evaluate trust. Even though we could not report any significant main effect or interaction of cognitive load and trust from the physiological signal, we found that in low cognitive load tasks, EEG alpha band power reflects trustworthiness on the agent. Moreover, cognitive load of the user decreases when the agent is accurate regardless of task’s cognitive load. This could be possible because of small sample size, tasks not stressful enough to induce high cognitive load due to lab study and comfortable environment or timestamp synchronisation error due to fusing data from various physiological sensors with different sample rate.
C1  - Parramatta, NSW, Australia
C3  - Proceedings of the 25th ACM symposium on virtual reality software and technology
DA  - 2019///
PY  - 2019
DO  - 10.1145/3359996.3364276
PB  - Association for Computing Machinery
SN  - 978-1-4503-7001-1
UR  - https://doi.org/10.1145/3359996.3364276
KW  - Virtual Reality
KW  - Cognitive Load
KW  - Physiological signals
KW  - Trust
KW  - Virtual Assistant
ER  - 

TY  - CONF
TI  - From alien to ally: Exploring non-verbal communication with non-anthropomorphic avatars in a collaborative escape-room
AU  - Espositi, Federico
AU  - Vetere, Maurizio
AU  - Bonarini, Andrea
T3  - Chi '25
AB  - Despite the spread of technologies in the physical world and the normalization of virtual experiences, non-verbal communication with radically non-anthropomorphic avatars remains an underexplored frontier. We present an interaction system in which two participants must learn to communicate with each other non-verbally through a digital filter that morphs their appearance. In a collaborative escape room, the Visitor must teach a non-anthropomorphic physical robot to play, while the Controller, in a different location, embodies the robot with an altered perception of the environment and the Visitor’s companion in VR. This study addresses the design of the activity, the robot, and the virtual environment, with a focus on how the Visitor’s morphology is translated in VR. Results show that participants were able to develop emergent and effective communication strategies, with the Controller naturally embodying its avatar’s narrative, making this system a promising testbed for future research on human-technology interaction, entertainment, and embodiment.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3713428
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3713428
KW  - Collaboration
KW  - Qualitative Methods
KW  - Robot
KW  - Interaction Design
KW  - Art
KW  - Artifact or System
KW  - Computer Mediated Communication
KW  - Embodied Interaction
KW  - Empirical study that tells us about how people use a system
KW  - Empirical study that tells us about people
KW  - Entertainment
KW  - Lab Study
KW  - Prototyping/Implementation
KW  - Quantitative Methods
KW  - User Experience Design
KW  - Virtual/Augmented Reality
ER  - 

TY  - CONF
TI  - SandTouch: Empowering virtual sand art in VR with AI guidance and emotional relief
AU  - Liu, Long
AU  - Ren, Junbin
AU  - Fan, Zeyuan
AU  - Li, Chenhui
AU  - He, Gaoqi
AU  - Wang, Changbo
AU  - Gao, Yang
AU  - Li, Chen
T3  - Chi '25
AB  - Sand painting is a highly aesthetic and valuable form of art but often constrained by the need for specific equipment and the associated learning curve. To address these challenges, we developed a VR sand painting system, SandTouch, offering an immersive and intuitive sand painting experience that closely mirrors the interaction with physical sand. Leveraging advanced gesture recognition technology, SandTouch allows users to create intricate sand art in a virtual environment, capturing the fine sensations of real sand manipulation along with realistic sound feedback. The integration of AI agent further enhances the experience by intelligently interpreting users’ creative intentions based on real-time interactions, offering contextually relevant artistic suggestions. Comprehensive evaluations have demonstrated a significant increase in user engagement and immersion. Furthermore, the realistic sound feedback enhances emotional relief and deepens the painting experience.
C1  - New York, NY, USA
C3  - Proceedings of the 2025 CHI conference on human factors in computing systems
DA  - 2025///
PY  - 2025
DO  - 10.1145/3706598.3714275
PB  - Association for Computing Machinery
SN  - 979-8-4007-1394-1
UR  - https://doi.org/10.1145/3706598.3714275
KW  - Virtual Reality
KW  - AI-Guidance
KW  - Emotional Relief
KW  - Sand Painting
ER  - 

TY  - CONF
TI  - Gaining impact with mixed reality in industry – a sustainable approach
AU  - Holly, Fabian
AU  - Zigart, Tanja
AU  - Maurer, Martina
AU  - Wolfartsberger, Josef
AU  - Brunnhofer, Magdalena
AU  - Sorko, Sabrina Romina
AU  - Moser, Thomas
AU  - Schlager, Alexander
T3  - Iccta '22
AB  - Mixed reality (augmented and virtual reality) technology continues to find its way into the industry. Nevertheless, prototypes and island solutions are developed in companies, which are not embedded in the corporate strategy. This paper presents a systematic approach for finding and developing use cases accompanied by a strategic implementation and evaluation process to integrate mixed reality in the industry. Sustainability aspects like energy and resource efficiency, possible reduction of the ecological footprint, and sustainable solutions for lasting and vision-based use in companies are considered. Within several use cases with 20 industry partners in the following areas are developed: 1) novel forms of space-independent collaboration (e.g., collaborative work by integrating real-time 3D depth information of the real environment and visualization of and interaction with real-time production data) and 2) XR-supported training and learning methods (e.g., parameterizable and adaptive training scenarios, roll-out of training content for several participants and integration of gamification mechanisms). Additionally, the methodology for a sustainability assessment, technology acceptance, and a multi-criteria evaluation are shown, and first results are discussed.
C1  - Vienna, Austria
C3  - Proceedings of the 2022 8th international conference on computer technology applications
DA  - 2022///
PY  - 2022
DO  - 10.1145/3543712.3543729
SP  - 128
EP  - 134
PB  - Association for Computing Machinery
SN  - 978-1-4503-9622-6
UR  - https://doi.org/10.1145/3543712.3543729
KW  - Mixed Reality
KW  - Industry Use Cases
KW  - Sustainability
ER  - 

TY  - CONF
TI  - Asymmetric design approach and collision avoidance techniques for room-scale multiplayer virtual reality
AU  - Sra, Misha
T3  - UIST '16 adjunct
AB  - Recent advances in consumer virtual reality (VR) technology have made it easy to accurately capture users' motions over room-sized areas allowing natural locomotion for navigation in VR. While this helps create a stronger match between proprioceptive information from human body movements for enhancing immersion and reducing motion sickness, it introduces a few challenges. Walking is only possible within virtual environments (VEs) that fit inside the boundaries of the tracked physical space which for most users is quite small. Within this space the potential for colliding with physical objects around the play area is high. Additionally, only limited haptic feedback is available. In this paper, I focus on the problem of variations in the size and shape of each user's tracked physical space for multiplayer interactions. As part of the constrained physical space problem, I also present an automated system for steering the user away from play area boundaries using Galvanic Vestibular Stimulation (GVS). In my thesis, I will build techniques to enable the system to intelligently apply redirection and GVS-based steering as users explore virtual environments of arbitrary sizes.
C1  - Tokyo, Japan
C3  - Adjunct proceedings of the 29th annual ACM symposium on user interface software and technology
DA  - 2016///
PY  - 2016
DO  - 10.1145/2984751.2984788
SP  - 29
EP  - 32
PB  - Association for Computing Machinery
SN  - 978-1-4503-4531-6
UR  - https://doi.org/10.1145/2984751.2984788
KW  - virtual reality
KW  - tracking
KW  - head-mounted displays
KW  - games
KW  - 3d mapping
KW  - asymmetric design
KW  - galvanic vestibular stimulation
KW  - natural locomotion
KW  - obstacle avoidance
ER  - 

TY  - CONF
TI  - Video2MR: Automatically generating mixed reality 3D instructions by augmenting extracted motion from 2D videos
AU  - Ihara, Keiichi
AU  - Monteiro, Kyzyl
AU  - Faridan, Mehrad
AU  - Kazi, Rubaiat Habib
AU  - Suzuki, Ryo
T3  - Iui '25
AB  - This paper introduces Video2MR, a mixed reality system that automatically generates 3D sports and exercise instructions from 2D videos. Mixed reality instructions have great potential for physical training, but existing works require substantial time and cost to create these 3D experiences. Video2MR overcomes this limitation by transforming arbitrary instructional videos available online into MR 3D avatars with AI-enabled motion capture (DeepMotion). Then, it automatically enhances the avatar motion through the following augmentation techniques: 1) contrasting and highlighting differences between the user and avatar postures, 2) visualizing key trajectories and movements of specific body parts, 3) manipulation of time and speed using body motion, and 4) spatially repositioning avatars for different perspectives. Developed on Hololens 2 and Azure Kinect, we showcase various use cases, including yoga, dancing, soccer, tennis, and other physical exercises. The study results confirm that Video2MR provides more engaging and playful learning experiences, compared to existing 2D video instructions.
C1  - New York, NY, USA
C3  - Proceedings of the 30th international conference on intelligent user interfaces
DA  - 2025///
PY  - 2025
DO  - 10.1145/3708359.3712159
SP  - 1548
EP  - 1563
PB  - Association for Computing Machinery
SN  - 979-8-4007-1306-4
UR  - https://doi.org/10.1145/3708359.3712159
KW  - Avatar
KW  - Mixed Reality
KW  - Videos
KW  - Automated Generation
KW  - Motion Capture
KW  - Sports and Exercises
ER  - 

TY  - JOUR
TI  - A survey of needs and features for augmented reality collaborations in collocated spaces
AU  - Radu, Iulian
AU  - Joy, Tugce
AU  - Bowman, Yiran
AU  - Bott, Ian
AU  - Schneider, Bertrand
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - In this paper we contribute a literature review and organization framework for classifying the collaboration needs and features that should be considered when designing headset-based augmented reality (AR) experiences for collocated settings. In recent years augmented reality technology has been experiencing significant growth through the emergence of headsets that allow gestural interaction, and AR designers are increasingly interested in using this technology to enhance collaborative activities in a variety of physical environments. However, collaborative AR applications need to contain features that enhance collaboration and satisfy needs that are present during the group activities. When AR designers lack an understanding of what collaborators need during an interaction, or what features have already been designed to solve those needs, then AR creators will spend time redesigning features that have already been created, or worse, create applications that do not contain necessary features. While much work has been done on designing virtual reality (VR) collaborative environments, AR environments are a relatively newer design space, and designers are lacking a comprehensive framework for describing needs that arise during collaborative activities and the features that could be designed into AR applications to satisfy those needs. In this paper we contribute a literature review of 92 papers in the areas of augmented reality and virtual reality, and we contribute a list of design features and needs that are helpful to consider when designing for headset-based collaborative AR experiences.
DA  - 2021/04//
PY  - 2021
DO  - 10.1145/3449243
VL  - 5
IS  - CSCW1
UR  - https://doi.org/10.1145/3449243
KW  - virtual reality
KW  - augmented reality
KW  - collaborative virtual environments
KW  - collaboration taxonomies
ER  - 

TY  - CONF
TI  - Towards designing immersive geovisualisations: Literature review and recommendations for future research
AU  - Gallagher, Cael
AU  - Turkay, Selen
AU  - Brown, Ross Andrew
T3  - OzCHI '21
AB  - Geological fieldwork forms an integral part of science discovery, exploration, and learning in many geoscientific domains. Yet, there are barriers that can hinder its practice. To address this, prior research has investigated immersive geovisualisations, however, there is no consensus on the types of interaction tools and techniques that should be used. We have conducted a literature review of 31 papers and present the visualisation environments, interaction tools and techniques, and evaluation methods from this last decade. We found a lack of established taxonomy for visualisation environments; an absence of thorough reports on interaction tools and techniques; and a lack of use of relevant human-computer interaction (HCI) theories and user-centered approaches. This review contributes towards the development of a design framework as we propose a basic taxonomy; demonstrate the need for holistic records of user interactions; and highlight the need for HCI evaluation methods. Addressing these gaps will facilitate future innovation in the emerging field of immersive geovisualisations.
C1  - Melbourne, VIC, Australia
C3  - Proceedings of the 33rd australian conference on human-computer interaction
DA  - 2022///
PY  - 2022
DO  - 10.1145/3520495.3520511
SP  - 307
EP  - 326
PB  - Association for Computing Machinery
SN  - 978-1-4503-9598-4
UR  - https://doi.org/10.1145/3520495.3520511
KW  - virtual environments
KW  - geovisualisation
KW  - virtual field trips
ER  - 

TY  - BOOK
TI  - SA '17: SIGGRAPH asia 2017 mobile graphics &amp; interactive applications
AB  - The SIGGRAPH Asia Symposium on Mobile Graphics and Interactive Applications will offer attendees the opportunity to explore the opportunities and challenges of mobile applications relevant to the global graphics community.The program will cover the development, technology, and marketing of mobile graphics and interactive applications. It will especially highlight novel uses of graphics and interactivity on mobile devices. Attendees can expect to be exposed to the latest in mobile graphics and interactive applications through expert keynote talks, paper presentations, panel discussions, industry case studies, and hands-on demonstrations.
CY  - New York, NY, USA
DA  - 2017///
PY  - 2017
PB  - Association for Computing Machinery
SN  - 978-1-4503-5410-3
ER  - 

TY  - CONF
TI  - Feeling distance: An investigation of mediated social touch prototypes
AU  - Pallarino, Timothy
AU  - Free, Aaron
AU  - Mutuc, Katrina
AU  - Yarosh, Svetlana
T3  - CSCW '16 companion
AB  - Physical distance presents a challenge for building and maintaining relationships. With recent work showing the effectiveness of both visual and haptic feedback in supporting interpersonal touch over a distance, such technologies look to bridge this gap and improve existing communication technologies. In this project, we explore the potential role of shape-shifting displays for doing so. We present two prototypes, one using linear slide potentiometers and the other using linear actuators, that incorporate these forms of feedback to facilitate mediated social touch. We present the benefits and drawbacks of each system, and conclude that, for a system focused on collaboration and synchronous communication, linear actuators may be better suited due to their load capacity and precision.
C1  - San Francisco, California, USA
C3  - Proceedings of the 19th ACM conference on computer supported cooperative work and social computing companion
DA  - 2016///
PY  - 2016
DO  - 10.1145/2818052.2869124
SP  - 361
EP  - 364
PB  - Association for Computing Machinery
SN  - 978-1-4503-3950-6
UR  - https://doi.org/10.1145/2818052.2869124
KW  - Remote Communication
KW  - HP Sprout
KW  - Mediated Social Touch
KW  - Shape-Shifting Displays
ER  - 

TY  - JOUR
TI  - Sensitivity to hand offsets and related behavior in virtual environments over time
AU  - Kohm, Kristopher
AU  - Porter, John
AU  - Robb, Andrew
T2  - ACM Trans. Appl. Percept.
AB  - This work explored how users’ sensitivity to offsets in their avatars’ virtual hands changes as they gain exposure to virtual reality. We conducted an experiment using a two-alternative forced choice (2-AFC) design over the course of 4 weeks, split into four sessions. The trials in each session had a variety of eight offset distances paired with eight offset directions (across a two-dimensional plane). While we did not find evidence that users became more sensitive to the offsets over time, we did find evidence of behavioral changes. Specifically, participants’ head–hand coordination and completion time varied significantly as the sessions went on. We discuss the implications of both results and how they could influence our understanding of long-term calibration for perception-action coordination in virtual environments.
DA  - 2022/11//
PY  - 2022
DO  - 10.1145/3561055
VL  - 19
IS  - 4
SN  - 1544-3558
UR  - https://doi.org/10.1145/3561055
KW  - Body awareness
KW  - calibration
KW  - hand offsets
KW  - longitudinal
ER  - 

TY  - CONF
TI  - Above-screen fingertip tracking and hand representation for precise touch input with a phone in virtual reality
AU  - Matulic, Fabrice
AU  - Kashima, Taiga
AU  - Beker, Deniz
AU  - Suzuo, Daichi
AU  - Fujiwara, Hiroshi
AU  - Vogel, Daniel
T3  - Gi '24
AB  - Interacting with the touchscreen of a mobile phone in virtual reality (VR) is challenging because users cannot see their fingers when aiming for targets. We propose using two mirrors reflecting the front camera of the phone and a purpose-built deep neural network to infer the 3D position of fingertips above the screen. Network training is self-supervised after only a few hundred initial labelled images and does not require any external sensor. The inferred fingertip positions can be used to control different hand models and objects in VR. Controlled experiments evaluate tracking performance for single-finger touch input, and compare several 3D hand representations with a flat 2D overlay used in previous work. The results confirm the suitability of our fingertip tracker to aid precise tapping of small targets on the phone screen and provide insights about the effect of various hand representations on control and presence. Finally, we provide several application examples showing how 3D fingertip input can complement and extend phone-based touch interaction in VR.
C1  - Halifax, NS, Canada
C3  - Proceedings of the 50th graphics interface conference
DA  - 2024///
PY  - 2024
DO  - 10.1145/3670947.3670961
PB  - Association for Computing Machinery
SN  - 979-8-4007-1828-1
UR  - https://doi.org/10.1145/3670947.3670961
KW  - virtual reality
KW  - hand pose estimation
ER  - 

TY  - CONF
TI  - Coexistent space: toward seamless integration of real, virtual, and remote worlds for 4D+ interpersonal interaction and collaboration
AU  - You, Bum-Jae
AU  - Kwon, Jounghuem R.
AU  - Nam, Sang-Hun
AU  - Lee, Jung-Jea
AU  - Lee, Kwang-Kyu
AU  - Yeom, Kiwon
T3  - Sa '14
AB  - Three worlds are integral to our daily life: the real world, virtual world, and remote world. In the paper, there is proposed coexistent space where networked users can communicate, interact, and collaborate together by exchanging 4D+ sensation, human intension, and emotion. The 4D+ sensation includes 3D vision, 3D sound, force and torque, touch, and movements. The coexistent space is generated by seamless integration of real, virtual, and remote worlds while networked users experience the feeling of coexistence through 4D+ bi-directional interaction. Initial software framework and experimental results for interaction between multiple remote users are shown successfully.
C1  - Shenzhen, China
C3  - SIGGRAPH asia 2014 autonomous virtual humans and social robot for telepresence
DA  - 2014///
PY  - 2014
DO  - 10.1145/2668956.2668957
PB  - Association for Computing Machinery
SN  - 978-1-4503-3243-9
UR  - https://doi.org/10.1145/2668956.2668957
KW  - constant time
KW  - global illumination
KW  - radiosity
ER  - 

TY  - BOOK
TI  - VRST '19: Proceedings of the 25th ACM symposium on virtual reality software and technology
CY  - New York, NY, USA
DA  - 2019///
PY  - 2019
PB  - Association for Computing Machinery
SN  - 978-1-4503-7001-1
ER  - 

TY  - JOUR
TI  - Extended reality (XR) toward building immersive solutions: The key to unlocking industry 4.0
AU  - Alhakamy, A’aeshah
T2  - Acm Computing Surveys
AB  - When developing XR applications for Industry 4.0, it is important to consider the integration of visual displays, hardware components, and multimodal interaction techniques that are compatible with the entire system. The potential use of multimodal interactions in industrial applications has been recognized as a significant factor in enhancing humans’ ability to perform tasks and make informed decisions. To offer a comprehensive analysis of the current advancements in industrial XR, this review presents a structured tutorial that provides answers to the following research questions: (R.Q.1) What are the similarities and differences between XR technologies, including augmented reality (AR), mixed reality (MR), Augmented Virtuality (AV), and virtual reality (VR) under Industry 4.0 consideration? (R.Q.2) What types of visual displays and hardware devices are needed to present XR for Industry 4.0? (R.Q.3) How did the multimodal interaction in XR perceive and relate to Industry 4.0? (R.Q.4) How have modern adaptations of XR technologies dealt with the theme of Industry 4.0? (R.Q.5) How can XR technologies in Industry 4.0 develop their services and usages to be more solution-inclusive? This review showcases various instances that demonstrate XR’s potential to transform how humans interact with the physical world in Industry 4.0. These advancements can increase productivity, reduce costs, and enhance safety.
DA  - 2024/04//
PY  - 2024
DO  - 10.1145/3652595
VL  - 56
IS  - 9
J2  - ACM Comput. Surv.
SN  - 0360-0300
UR  - https://doi.org/10.1145/3652595
KW  - virtual reality (VR)
KW  - 4IR
KW  - and augmented virtuality (AV)
KW  - augmented reality (AR)
KW  - Extended reality (XR)
KW  - Industry 4.0
KW  - mixed reality (MR)
ER  - 

TY  - JOUR
TI  - Evaluating typing performance in different mixed reality manifestations using physiological features
AU  - Chiossi, Francesco
AU  - El Khaoudi, Yassmine
AU  - Ou, Changkun
AU  - Sidenmark, Ludwig
AU  - Zaky, Abdelrahman
AU  - Feuchtner, Tiare
AU  - Mayer, Sven
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Mixed reality enables users to immerse themselves in high-workload interaction spaces like office work scenarios. We envision physiologically adaptive systems that can move users into different mixed reality manifestations, to improve their focus on the primary task. However, it is unclear which manifestation is most conducive for high productivity and engagement. In this work, we evaluate whether physiological indicators for engagement can be discriminated for different manifestations. For this, we engaged participants in a typing task in three different mixed reality manifestations (augmented reality, augmented virtuality, virtual reality) and monitored physiological correlates (EEG, ECG, and eye tracking) of users' engagement and workload. We found that users achieved best typing performances in augmented reality and augmented virtuality. At the same time, physiological engagement peaked in augmented virtuality, while workload decreased. We conclude that augmented virtuality strikes a good balance between the different manifestations, as it facilitates displaying the physical keyboard for improved typing performance and, at the same time, allows one to block out the real world, removing many real-world distractors.
DA  - 2024/10//
PY  - 2024
DO  - 10.1145/3698142
VL  - 8
IS  - ISS
UR  - https://doi.org/10.1145/3698142
KW  - Virtual Reality
KW  - Augmented Reality
KW  - Mixed Reality
KW  - Electroencephalography
KW  - Augmented Virtuality
KW  - Engagement
KW  - Eye Tracking
KW  - Physiological Computing
ER  - 

TY  - CONF
TI  - Swarm body: Embodied swarm robots
AU  - Ichihashi, Sosuke
AU  - Kuroki, So
AU  - Nishimura, Mai
AU  - Kasaura, Kazumi
AU  - Hiraki, Takefumi
AU  - Tanaka, Kazutoshi
AU  - Yoshida, Shigeo
T3  - Chi '24
AB  - The human brain’s plasticity allows for the integration of artificial body parts into the human body. Leveraging this, embodied systems realize intuitive interactions with the environment. We introduce a novel concept: embodied swarm robots. Swarm robots constitute a collective of robots working in harmony to achieve a common objective, in our case, serving as functional body parts. Embodied swarm robots can dynamically alter their shape, density, and the correspondences between body parts and individual robots. We contribute an investigation of the influence on embodiment of swarm robot-specific factors derived from these characteristics, focusing on a hand. Our paper is the first to examine these factors through virtual reality (VR) and real-world robot studies to provide essential design considerations and applications of embodied swarm robots. Through quantitative and qualitative analysis, we identified a system configuration to achieve the embodiment of swarm robots.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI conference on human factors in computing systems
DA  - 2024///
PY  - 2024
DO  - 10.1145/3613904.3642870
PB  - Association for Computing Machinery
SN  - 979-8-4007-0330-0
UR  - https://doi.org/10.1145/3613904.3642870
KW  - embodiment
KW  - tangible interaction
KW  - swarm robotics
ER  - 

TY  - CONF
TI  - Evolving pattern candidates for setting up educational online seminars: - Findings from the COVID-19 pandemic -
AU  - Reiners, René
AU  - Jayhooni, Sam
T3  - EuroPLop '22
AB  - E-Learning, Blended Learning, Massive Online Courses, Distributed Learning, Webinars Hybrid Events and video conferencing are topics treated for decades. Technology-wise, many opportunities were taken and chances were used. However, in many situations, work places, universities and institutions, lectures, courses, trainings, workshops or informative events were still primarily held on-site. All of them, with their specific advantages and disadvantages (e.g., personal contact, networking vs. time loss, ecological footprint, etc.). First with the Corona Pandemic and the subsequent measures, all foremost the lockdown situations worldwide, remote working, learning and video conferencing experienced a dramatic boost. The option of preferring on-site, personal meetings vanished completely. Due to this profound change in collaborative that had to become common overnight, people were forced to face and adapt to available technologies. The latter, on the other side, also evolved quickly to provide more and more features to improve collaboration, usability and privacy. Formats for lectures, courses, workshops and collaboration also had to be adapted quickly. The problem was that all stakeholders, both lecturers as well as learners could not that easily change their habits, ways of teaching and learning, interacting, and – not to forget – their didactic concept, methods and materials. A 1:1 transformation was impossible since different technical background knowledge as well as very different technical and spatial conditions lead to great imbalance in quality of teaching, interaction, use of technology and practicability. In order to address these uncertainties, this work provides a basic set of suggestions for lecturers in form of a pattern collection for setting up educational online courses regarding several aspects like common sense, technology and rules of the game. Since patterns are technology-agnostic and formulated for a broad audience with different professional backgrounds, they qualify as universal format and at the same time keep the validity of time. Even after almost three years with COVID-19, there is still struggle with technology adaption and format generation. The formulated patterns are based on interviews with experts that worked as lecturers, a larger-scale survey including the results from 63 online questionnaires and one focus group. The resulting set of 19 guidelines was then reformulated as patterns in a mid-high maturity state with the perspective of being further supported by new findings and practical experience. The pattern collection is linked to a process model for evolving pattern libraries from previous work.
C1  - Irsee, Germany
C3  - Proceedings of the 27th european conference on pattern languages of programs
DA  - 2023///
PY  - 2023
DO  - 10.1145/3551902.3551978
PB  - Association for Computing Machinery
SN  - 978-1-4503-9594-6
UR  - https://doi.org/10.1145/3551902.3551978
ER  - 

TY  - CONF
TI  - A card-based learning objective design method for collaborative curriculum design
AU  - Recke, Moritz Philip
AU  - Perna, Stefano
T3  - Icslt '21
AB  - This paper takes the Bloom's Taxonomy, more specifically the Revised Bloom's Taxonomy, as a baseline for learning objective and curriculum design adopted by generations of teachers and instructors in their practice. On the backdrop of recent findings and persistent principles of learning design, the authors employ narrative theory and its notion of linguistic statements to propose a collaborative approach to curriculum design using an interactive and card-based method. The conceptual notions of the Learning Objective Design Deck are illustrated and important arguments for the use of a card deck in context of learning objective design workshops are presented. The methodical tool aimed at educators and instructional designers is comprised of a canvas and a card deck that can be used in both physical, in form of an actual card deck, and digital formats, e.g. on collaborative synchronous digital whiteboard solutions. The authors will discuss the current state of their methodological design, perspectives on formalisation for implementation in software and present initial results form a workshop conducted with domain experts to reflect on areas for improvement and further research. The paper concludes with a contextualisation of the method in relation to other learning design tools in development by the authors that integrate the narratively driven learning experience design approach to conceptualise a framework and modelling language for learning experience design that can be extended to a software-based approach for learning activity or even learning unit design.
C1  - Portsmouth, United Kingdom
C3  - Proceedings of the 7th international conference on e-society, e-Learning and e-Technologies
DA  - 2021///
PY  - 2021
DO  - 10.1145/3477282.3477286
SP  - 19
EP  - 25
PB  - Association for Computing Machinery
SN  - 978-1-4503-7684-6
UR  - https://doi.org/10.1145/3477282.3477286
KW  - card-based participatory design
KW  - course design
KW  - Learning objectives
KW  - modelling language
ER  - 

TY  - CONF
TI  - Relief: a scalable actuated shape display
AU  - Leithinger, Daniel
AU  - Ishii, Hiroshi
T3  - Tei '10
AB  - Relief is an actuated tabletop display, which is able to render and animate three-dimensional shapes with a malleable surface. It allows users to experience and form digital models like geographical terrain in an intuitive manner. The tabletop surface is actuated by an array of 120 motorized pins, which are controlled with a low-cost, scalable platform built upon open-source hardware and software tools. Each pin can be addressed individually and senses user input like pulling and pushing.
C1  - Cambridge, Massachusetts, USA
C3  - Proceedings of the fourth international conference on tangible, embedded, and embodied interaction
DA  - 2010///
PY  - 2010
DO  - 10.1145/1709886.1709928
SP  - 221
EP  - 222
PB  - Association for Computing Machinery
SN  - 978-1-60558-841-4
UR  - https://doi.org/10.1145/1709886.1709928
KW  - haptic display
KW  - shape display
KW  - pin array
KW  - relief interface
KW  - tangible input
ER  - 

TY  - JOUR
TI  - Bridging distances through virtual cook-along sessions: Exploring the design space of collaborative remote cooking experiences
AU  - Weber, Philip
AU  - Costa, Lucas Andrade da
AU  - Ludwig, Thomas
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Virtual co-cooking gained visibility during the COVID-19 pandemic due to the increasing use of communication technology for social activities. However, available videoconferencing platforms are not well designed to support virtual co-cooking. Therefore, we explored this practice and the underlying design space and derived guidelines for current videoconferencing interfaces to better meet virtual cook-along enthusiasts' needs. For this, we first observed three remote cook-along sessions and then conducted semi-structured interviews, resulting in 12 requirements and 4 requirements themes culminating in 20 features divided into four dimensions: planning, enabling, co-presence, and food interaction. In the second phase, each feature was evaluated by 14 participants using the Kano questionnaire, followed by structured interviews. This resulted in six design implications related to automation, hands-free interactions, privacy, preserving memories, eliminating stress, and encouraging conjoint activities. This research provides insights and perspectives on the evolving landscape of technology-mediated social interactions and collaborative practices, and how to design for them.
DA  - 2025/01//
PY  - 2025
DO  - 10.1145/3701185
VL  - 9
IS  - 1
UR  - https://doi.org/10.1145/3701185
KW  - collaborative practices
KW  - human-food interaction
KW  - remote social experience
KW  - videoconferencing platforms
KW  - virtual co-cooking
ER  - 

TY  - JOUR
TI  - "Twin Spin": steering karaoke (or anything else) with smartphone wands deployable as spinnable affordances
AU  - Cohen, Michael
AU  - Ranaweera, Rasika
AU  - Ito, Hayato
AU  - Endo, Shun
AU  - Holesch, Sascha
AU  - Villegasc, Julián
T2  - SIGMOBILE Mob. Comput. Commun. Rev.
AB  - We have built haptic interfaces featuring smartphones and tablets that use magnetometerderived orientation sensing to modulate virtual displays, especially spatial sound, allowing, for instance, each side of a karaoke recording to be separately steered around a periphonic display. Embedding such devices into a spinnable affordance allows a "spinning plate"- style interface, a novel interaction technique. Either static (pointing) or dynamic (spinning) modes can be used to control "whirled" multimodal display, including a rotary motion platform, panoramic movies, and the positions of avatars in virtual environments.
DA  - 2013/02//
PY  - 2013
DO  - 10.1145/2436196.2436199
VL  - 16
IS  - 4
SP  - 4
EP  - 5
SN  - 1559-1662
UR  - https://doi.org/10.1145/2436196.2436199
ER  - 

TY  - CONF
TI  - Creating IoT-ready XR-WebApps with Unity3D
AU  - Fleck, Philipp
AU  - Schmalstieg, Dieter
AU  - Arth, Clemens
T3  - Web3D '20
AB  - The rise of IoT-ready devices is supported through well-established web concepts for communication and analytics, but interaction yet remains in the world of web browsers and screen-based 2D interaction during times of tablet and smartphone popularity. Transforming IoT interaction concepts into 3D for future exploitation with head-worn XR devices is a difficult task due to the lack of support and continued disengagement of game engines used in XR development. In this work, we present an approach to overcome this limitation, tightly including web technology into a 3D game engine. Our work leverages the versatility of web concepts to create immersive and scalable web applications in XR, without the need for deep-tech know-how about XR concepts or tiring customization work. We describe the methodology and tools in detail and provide some exemplary XR applications.
C1  - Virtual Event, Republic of Korea
C3  - Proceedings of the 25th international conference on 3D web technology
DA  - 2020///
PY  - 2020
DO  - 10.1145/3424616.3424691
PB  - Association for Computing Machinery
SN  - 978-1-4503-8169-7
UR  - https://doi.org/10.1145/3424616.3424691
KW  - XR
KW  - 3D Engines
KW  - IoT
KW  - Web app
KW  - Web browser
ER  - 

TY  - BOOK
TI  - ICVRT '24: Proceedings of the 2024 international conference on virtual reality technology
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1018-6
ER  - 

TY  - JOUR
TI  - MP remix: Relaxed WYSIWIS immersive interfaces for mixed presence collaboration with 3D content
AU  - Salimian, Hossein
AU  - Brooks, Stephen
AU  - Reilly, Derek
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - to create an integrated space. We consider an MR configuration in which collocated collaborators work around a tabletop display, while remote collaborators wear an HMD to interact with a connected virtual environment that gives a 3D perspective, and consider the impact of varying degrees of view congruence with their collaborators. In a within-subjects study with 18 groups of 3, groups completed task scenarios involving 3D object manipulation around a physical-virtual mapped tabletop. We compare a synchronized Tabletop display baseline and two MR conditions with different levels of view congruence: Fishtank and Hover. Fishtank has a high degree of congruence as it shares a top-down perspective of the 3D objects with the tabletop collaborators. The Hover condition has less view congruence since 3D content hovers front of the remote collaborator above the table. The MR conditions yielded higher self-reported awareness and co-presence than the Tabletop condition for both collocated and remote participants. Remote collaborators significantly preferred the MR conditions for manipulating shared 3D models and communicating with their collaborators. Our findings illustrate strengths and weaknesses of both MR techniques but show that more participants preferred the less-congruent Hover condition overall. Reasons include that it facilitated interaction and viewing 3D objects.
DA  - 2019/11//
PY  - 2019
DO  - 10.1145/3359207
VL  - 3
IS  - CSCW
UR  - https://doi.org/10.1145/3359207
KW  - virtual reality
KW  - CSCW
KW  - 3D interaction
KW  - collaboration
KW  - awareness
KW  - co-presence
KW  - mixed presence
ER  - 

TY  - CONF
TI  - PITAS: Sensing and actuating embedded robotic sheet for physical information communication
AU  - Cheng, Tingyu
AU  - Park, Jung Wook
AU  - Li, Jiachen
AU  - Ramey, Charles
AU  - Lin, Hongnan
AU  - Abowd, Gregory D.
AU  - Brum Medeiros, Carolina
AU  - Oh, HyunJoo
AU  - Giordano, Marcello
T3  - Chi '22
AB  - This work presents PITAS, a thin-sheet robotic material composed of a reversible phase transition actuating layer and a heating/sensing layer. The synthetic sheet material enables non-expert makers to create shape-changing devices that can locally or remotely convey physical information such as shape, color, texture and temperature changes. PITAS sheets can be manipulated into various 2D shapes or 3D geometries using subtractive fabrication methods such as laser, vinyl, or manual cutting or an optional additive 3D printing method for creating 3D objects. After describing the design of PITAS, this paper also describes a study conducted with thirteen makers to gauge the accessibility, design space, and limitations encountered when PITAS is used as a soft robotic material while designing physical information communication devices. Lastly, this work reports on the results of a mechanical and electrical evaluation of PITAS and presents application examples to demonstrate its utility.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI conference on human factors in computing systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491102.3517532
PB  - Association for Computing Machinery
SN  - 978-1-4503-9157-3
UR  - https://doi.org/10.1145/3491102.3517532
KW  - phase transition actuator
KW  - physical telecommunication
KW  - shape-changing interface
ER  - 

TY  - CONF
TI  - Gaze augmentation in egocentric video improves awareness of intention
AU  - Akkil, Deepak
AU  - Isokoski, Poika
T3  - Chi '16
AB  - Video communication using head-mounted cameras could be useful to mediate shared activities and support collaboration. Growing popularity of wearable gaze trackers presents an opportunity to add gaze information on the egocentric video. We hypothesized three potential benefits of gaze-augmented egocentric video to support collaborative scenarios: support deictic referencing, enable grounding in communication, and enable better awareness of the collaborator's intentions. Previous research on using egocentric videos for real-world collaborative tasks has failed to show clear benefits of gaze point visualization. We designed a study, deconstructing a collaborative car navigation scenario, to specifically target the value of gaze-augmented video for intention prediction. Our results show that viewers of gaze-augmented video could predict the direction taken by a driver at a four-way intersection more accurately and more confidently than a viewer of the same video without the superimposed gaze point. Our study demonstrates that gaze augmentation can be useful and encourages further study in real-world collaborative scenarios.
C1  - San Jose, California, USA
C3  - Proceedings of the 2016 CHI conference on human factors in computing systems
DA  - 2016///
PY  - 2016
DO  - 10.1145/2858036.2858127
SP  - 1573
EP  - 1584
PB  - Association for Computing Machinery
SN  - 978-1-4503-3362-7
UR  - https://doi.org/10.1145/2858036.2858127
KW  - wearable computing
KW  - gaze tracking
KW  - intention prediction
KW  - video-based collaboration
ER  - 

TY  - CONF
TI  - Integration of laptop sudden motion sensor as accelerometric control for virtual environments
AU  - Cohen, Michael
T3  - Vrcai '08
AB  - We have developed a gestural controller for a multimodal client suite using a sudden motion sensor (SMS) deployed with many modern laptop computers. Interpreted commands inferred from the SMS accelerometer can be used to adjust position—orientation and location—of egocentric perspectives and exocentric avatars to control panoramic browsing and spatialized sound, adjusting the lateralization, directionalization, and spatialization of musical and audio channels.
C1  - Singapore
C3  - Proceedings of the 7th ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry
DA  - 2008///
PY  - 2008
DO  - 10.1145/1477862.1477911
PB  - Association for Computing Machinery
SN  - 978-1-60558-335-8
UR  - https://doi.org/10.1145/1477862.1477911
KW  - multimodal interaction
KW  - haptic interface
KW  - ambient information systems
KW  - calm technology
KW  - interactive networked media
ER  - 

TY  - CONF
TI  - A systematic mapping literature of immersive learning from SVR publications
AU  - Fernandes, Filipe
AU  - Castro, Diego
AU  - Werner, Claudia
T3  - Svr '21
AB  - Immersive Learning (iL) is known as a recent area of research that uses three-dimensional virtual environments and multi-sensory devices, also known as immersive technologies, to support the improvement of learning outcomes. This work aims to obtain evidence of theoretical and technological aspects of iL from the Symposium on Virtual and Augmented Reality (SVR) publications. A Systematic Literature Mapping protocol was developed and executed in order to select the primary studies to perform the analysis and data extraction. 76 primary studies helped to answer the research questions. A large part of the contributions by the SVR community are virtual environments that support education in the health area. In addition, some gaps and research opportunities were identified: virtual environments that serve audiences with special needs; development frameworks that consider pedagogical aspects and the use of biometric measures to support the validation of improved learning outcomes.
C1  - Virtual Event, Brazil
C3  - Proceedings of the 23rd symposium on virtual and augmented reality
DA  - 2022///
PY  - 2022
DO  - 10.1145/3488162.3488163
SP  - 1
EP  - 13
PB  - Association for Computing Machinery
SN  - 978-1-4503-9552-6
UR  - https://doi.org/10.1145/3488162.3488163
KW  - Immersive Learning
KW  - Symposium on Virtual and Augmented Reality
KW  - Systematic Mapping Study
ER  - 

TY  - CONF
TI  - Loki: Facilitating remote instruction of physical tasks using bi-directional mixed-reality telepresence
AU  - Thoravi Kumaravel, Balasaravanan
AU  - Anderson, Fraser
AU  - Fitzmaurice, George
AU  - Hartmann, Bjoern
AU  - Grossman, Tovi
T3  - Uist '19
AB  - Remotely instructing and guiding users in physical tasks has offered promise across a wide variety of domains. While it has been the subject of many research projects, current approaches are often limited in the communication bandwidth (lacking context, spatial information) or interactivity (unidirectional, asynchronous) between the expert and the learner. Systems that use Mixed-Reality systems for this purpose have rigid configurations for the expert and the learner. We explore the design space of bi-directional mixed-reality telepresence systems for teaching physical tasks, and present Loki, a novel system which explores the various dimensions of this space. Loki leverages video, audio and spatial capture along with mixed-reality presentation methods to allow users to explore and annotate the local and remote environments, and record and review their own performance as well as their peer's. The system design of Loki also enables easy transitions between different configurations within the explored design space. We validate its utility through a varied set of scenarios and a qualitative user study.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 32nd annual ACM symposium on user interface software and technology
DA  - 2019///
PY  - 2019
DO  - 10.1145/3332165.3347872
SP  - 161
EP  - 174
PB  - Association for Computing Machinery
SN  - 978-1-4503-6816-2
UR  - https://doi.org/10.1145/3332165.3347872
KW  - mixed reality
KW  - learning
KW  - remote guidance
KW  - physical tasks
ER  - 

TY  - CONF
TI  - POI Poi: point-of-interest poi for multimodal tethered whirling
AU  - Cohen, Michael
T3  - MobileHCI '12
AB  - We have built haptic interfaces featuring smartphones that use magnetometer-derived orientation sensing to modulate virtual displays. Embedding such devices into swinging a ordances allows a "poi"-style interface, whirling tethered devices, for a novel interaction technique. Dynamic twirling can be used to control multimodal displays - including positions of sources &amp; sinks in spatial sound, subjects (avatars) &amp; objects in virtual environments, and object movies ("turnos") &amp; panoramas ("panos") in image-based renderings. This "practically panoramic" multimodal interface can be enjoyed in an appropriate spot as location-based entertainment, locative media for cross-platform, "mobile ambient" experience.
C1  - San Francisco, California, USA
C3  - Proceedings of the 14th international conference on human-computer interaction with mobile devices and services companion
DA  - 2012///
PY  - 2012
DO  - 10.1145/2371664.2371709
SP  - 199
EP  - 202
PB  - Association for Computing Machinery
SN  - 978-1-4503-1443-5
UR  - https://doi.org/10.1145/2371664.2371709
KW  - cross-platform "ambient mobile" interface
KW  - locative
KW  - multimodal
KW  - practically panoramic interface
KW  - situated panorama
ER  - 

TY  - BOOK
TI  - IMX '25: Proceedings of the 2025 ACM international conference on interactive media experiences
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1391-0
ER  - 

TY  - JOUR
TI  - Exploring immersive interpersonal communication via AR
AU  - Lee, Kyungjun
AU  - Li, Hong
AU  - Wellyanto, Muhammad Rizky
AU  - Tham, Yu Jiang
AU  - Monroy-Hernández, Andrés
AU  - Liu, Fannie
AU  - Smith, Brian A.
AU  - Vaish, Rajan
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - A central challenge of social computing research is to enable people to communicate expressively with each other remotely. Augmented reality has great promise for expressive communication since it enables communication beyond texts and photos and towards immersive experiences rendered in recipients' physical environments. Little research, however, has explored AR's potential for everyday interpersonal communication. In this work, we prototype an AR messaging system, ARwand, to understand people's behaviors and perceptions around communicating with friends via AR messaging. We present our findings under four themes observed from a user study with 24 participants, including the types of immersive messages people choose to send to each other, which factors contribute to a sense of immersiveness, and what concerns arise over this new form of messaging. We discuss important implications of our findings on the design of future immersive communication systems.
DA  - 2023/04//
PY  - 2023
DO  - 10.1145/3579483
VL  - 7
IS  - CSCW1
UR  - https://doi.org/10.1145/3579483
KW  - AR
KW  - experience crafting
KW  - immersive communication
KW  - messaging
KW  - smartglasses
KW  - smartphones
ER  - 

TY  - CONF
TI  - AO-finger: Hands-free fine-grained finger gesture recognition via acoustic-optic sensor fusing
AU  - Xu, Chenhan
AU  - Zhou, Bing
AU  - Krishnan, Gurunandan
AU  - Nayar, Shree
T3  - Chi '23
AB  - Finger gesture recognition is gaining great research interest for wearable device interactions such as smartwatches and AR/VR headsets. In this paper, we propose a hands-free fine-grained finger gesture recognition system AO-Finger based on acoustic-optic sensor fusing. Specifically, we design a wristband with a modified stethoscope microphone and two high-speed optic motion sensors to capture signals generated from finger movements. We propose a set of natural, inconspicuous and effortless micro finger gestures that can be reliably detected from the complementary signals from both sensors. We design a multi-modal CNN-Transformer model for fast gesture recognition (flick/pinch/tap), and a finger swipe contact detection model to enable fine-grained swipe gesture tracking. We built a prototype which achieves an overall accuracy of 94.83
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI conference on human factors in computing systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544548.3581264
PB  - Association for Computing Machinery
SN  - 978-1-4503-9421-5
UR  - https://doi.org/10.1145/3544548.3581264
ER  - 

TY  - CONF
TI  - Bringing everyday applications to interactive surfaces
AU  - Weiss, Malte
T3  - Uist '10
AB  - This paper presents ongoing work that intends to simplify the introduction of everyday applications to interactive tabletops. SLAP Widgets bring tangible general-purpose widgets to tabletops while providing the flexibility of on-screen controls. Madgets maintain consistency between physical controls and their digital state. BendDesk represents our vision of a multi-touch enabled office environment. Our pattern language captures knowledge for the design of interactive tabletops. For each project, we describe its technical background, present the current state of research, and discuss future work.
C1  - New York, New York, USA
C3  - Adjunct proceedings of the 23nd annual ACM symposium on user interface software and technology
DA  - 2010///
PY  - 2010
DO  - 10.1145/1866218.1866227
SP  - 375
EP  - 378
PB  - Association for Computing Machinery
SN  - 978-1-4503-0462-7
UR  - https://doi.org/10.1145/1866218.1866227
KW  - haptic feedback
KW  - interactive tabletops
KW  - tangible user interfaces
KW  - actuation
KW  - applications
KW  - curved surface
ER  - 

TY  - CONF
TI  - Immersive analytics
AU  - Engelke, Ulrich
AU  - Cordeil, Maxime
AU  - Cunningham, Andrew
AU  - Ens, Barrett
T3  - Sa '19
AB  - Welcome and OverviewVisualisation and Visual AnalyticsIntroduction to Immersive AnalyticsComputing Beyond the DesktopCollaboration
C1  - Brisbane, Queensland, Australia
C3  - SIGGRAPH asia 2019 courses
DA  - 2019///
PY  - 2019
DO  - 10.1145/3355047.3359391
PB  - Association for Computing Machinery
SN  - 978-1-4503-6941-1
UR  - https://doi.org/10.1145/3355047.3359391
ER  - 

TY  - JOUR
TI  - Looking forward 10 years to multimedia successes
AU  - Rowe, Lawrence A.
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
AB  - A panel at ACM Multimedia 2012 addressed research successes in the past 20 years. While the panel focused on the past, this article discusses successes since the ACM SIGMM 2003 Retreat and suggests research directions in the next ten years. While significant progress has been made, more research is required to allow multimedia to impact our everyday computing environment. The importance of hardware changes on future research directions is discussed. We believe ubiquitous computing—meaning abundant computation and network bandwidth—should be applied in novel ways to solve multimedia grand challenges and continue the IT revolution of the past century.
DA  - 2013/10//
PY  - 2013
DO  - 10.1145/2490825
VL  - 9
IS  - 1s
SN  - 1551-6857
UR  - https://doi.org/10.1145/2490825
KW  - Multimedia research directions
ER  - 

TY  - CONF
TI  - Emotion sharing and augmentation in cooperative virtual reality games
AU  - Hart, Jonathon D.
AU  - Piumsomboon, Thammathip
AU  - Lawrence, Louise
AU  - Lee, Gun A.
AU  - Smith, Ross T.
AU  - Billinghurst, Mark
T3  - CHI PLAY '18 extended abstracts
AB  - We present preliminary findings from sharing and augmenting facial expression in cooperative social Virtual Reality (VR) games. We implemented a prototype system for capturing and sharing facial expression between VR players through their avatar. We describe our current prototype system and how it could be assimilated into a system for enhancing social VR experience. Two social VR games were created for a preliminary study. We discuss our findings from our pilots, potential games for this system, and future directions for this research.
C1  - Melbourne, VIC, Australia
C3  - Proceedings of the 2018 annual symposium on computer-human interaction in play companion extended abstracts
DA  - 2018///
PY  - 2018
DO  - 10.1145/3270316.3271543
SP  - 453
EP  - 460
PB  - Association for Computing Machinery
SN  - 978-1-4503-5968-9
UR  - https://doi.org/10.1145/3270316.3271543
KW  - virtual reality
KW  - computer games.
KW  - emotion augmentation
KW  - emotion sharing
KW  - facial expression
ER  - 

TY  - BOOK
TI  - IMXw '24: Proceedings of the 2024 ACM international conference on interactive media experiences workshops
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1794-9
ER  - 

TY  - CONF
TI  - Spooky Technology: The ethereal and otherworldly as a resource for design
AU  - Byrne, Daragh
AU  - Lockton, Dan
AU  - Hu, Meijie
AU  - Luong, Miranda
AU  - Ranade, Anuprita
AU  - Escarcha, Karen
AU  - Giesa, Katherine
AU  - Huang, Yiwei
AU  - Yochum, Catherine
AU  - Robertson, Gordon
AU  - Yeung, Lisa (Yip Yan)
AU  - Cruz, Matthew
AU  - Danner, Christi
AU  - Wang, Elizabeth
AU  - Khurana, Malika
AU  - Chen, Zhenfang
AU  - Heyison, Alexander
AU  - Fu, Yixiao
T3  - Dis '22
AB  - Our everyday technologies could have appeared terrifying to our ancestors: instantaneous disembodied communication, access to knowledge, objects with ‘intelligence’ that talk to us (and each other). Black boxes and intangible entities are omnipresent in our homes and lives without our necessarily understanding the hidden flows of data, unknown agendas, imaginary clouds, and mysterious rules that govern them. Have humanity's ways of relating to the unknown throughout history gone away, or have they perhaps transmuted into new forms? In an ongoing project, we have inventoried examples, encounters and reflections on contemporary technology, framed through the perspective of the haunted, spectral and otherworldly. In this paper, we excerpt this collection to illustrate the value and opportunity of an unfamiliar, disquieting perspective in helping to frame the frictions, beliefs and myths that are emerging around interactions with everyday technologies. We posit and demonstrate ‘spooky technology’ as an accessible framework to reflect and respond to our increasingly entangled relationships with technology.
C1  - Virtual Event, Australia
C3  - Proceedings of the 2022 ACM designing interactive systems conference
DA  - 2022///
PY  - 2022
DO  - 10.1145/3532106.3533547
SP  - 759
EP  - 775
PB  - Association for Computing Machinery
SN  - 978-1-4503-9358-4
UR  - https://doi.org/10.1145/3532106.3533547
KW  - disembodied interaction
KW  - entanglement HCI
KW  - everyday tech
KW  - hauntology
KW  - invisible
KW  - numinous
KW  - otherworldly
KW  - Research through design
KW  - spooky
ER  - 

TY  - CONF
TI  - Understanding user perceptions, collaborative experience and user engagement in different human-AI interaction designs for co-creative systems
AU  - Rezwana, Jeba
AU  - Maher, Mary Lou
T3  - C&amp;C '22
AB  - Human-AI co-creativity involves humans and AI collaborating on a shared creative product as partners. In a creative collaboration, communication is an essential component among collaborators. In many existing co-creative systems, users can communicate with the AI, usually using buttons or sliders. Typically, the AI in co-creative systems cannot communicate back to humans, limiting their potential to be perceived as partners rather than just a tool. This paper presents a study with 38 participants to explore the impact of two interaction designs, with and without AI-to-human communication, on user engagement, collaborative experience and user perception of a co-creative AI. The study involves user interaction with two prototypes of a co-creative system that contributes sketches as design inspirations during a design task. The results show improved collaborative experience and user engagement with the system incorporating AI-to-human communication. Users perceive co-creative AI as more reliable, personal, and intelligent when the AI communicates to users. The findings can be used to design effective co-creative systems, and the insights can be transferred to other fields involving human-AI interaction and collaboration.
C1  - Venice, Italy
C3  - Proceedings of the 14th conference on creativity and cognition
DA  - 2022///
PY  - 2022
DO  - 10.1145/3527927.3532789
SP  - 38
EP  - 48
PB  - Association for Computing Machinery
SN  - 978-1-4503-9327-0
UR  - https://doi.org/10.1145/3527927.3532789
KW  - Interaction design
KW  - AI to human Communication
KW  - Co-creativity
KW  - Human-AI Communication
KW  - Human-AI Creative Collaboration
ER  - 

TY  - CONF
TI  - Tiltstacks: composing shape-changing interfaces using tilting and stacking of modules
AU  - Tiab, John
AU  - Boring, Sebastian
AU  - Strohmeier, Paul
AU  - Markussen, Anders
AU  - Alexander, Jason
AU  - Hornbæk, Kasper
T3  - Avi '18
AB  - Many shape-changing interfaces use an array of actuated rods to create a display surface; each rod working as a pixel. However, this approach only supports pixel height manipulation and cannot produce more radical shape changes of each pixel (and thus of the display). Examples of such changes include non-horizontal pixels, pixels that overhang other pixels, or variable gaps between pixels. We present a concept for composing shape-changing interfaces by vertically stacking tilt-enabled modules. Together, stacking and tilting allow us to create a more diverse range of display surfaces than using arrays. We demonstrate this concept through TiltStacks, a shape-changing prototype built using stacked linear actuators and displays. Each tiltable module provides three degrees of freedom (z-movement, roll, and pitch); two more degrees of freedom are added through stacking modules (i.e., planar x- and y-movement).
C1  - Castiglione della Pescaia, Grosseto, Italy
C3  - Proceedings of the 2018 international conference on advanced visual interfaces
DA  - 2018///
PY  - 2018
DO  - 10.1145/3206505.3206530
PB  - Association for Computing Machinery
SN  - 978-1-4503-5616-9
UR  - https://doi.org/10.1145/3206505.3206530
KW  - compositional concept
KW  - shape-changing interfaces
KW  - stacking
KW  - tilting
ER  - 

TY  - CONF
TI  - Exploring advance interactions for augmented reality: From casual activities to in-situ 3D modeling
AU  - Huo, Ke
T3  - Tei '17
AB  - Recent emerging technologies in graphics computation, computer vision, tracking techniques, and display hardware have been accelerating transferring augmented reality (AR) applications to wider, realistic use scenarios. While AR technologies are maturing, studying appropriate interactions for AR becomes equally significant. Driven by this strong need, in this paper we focus on discussing advance interactions for creating, manipulating, and authoring virtual contents in an intuitive manner. We propose to investigate AR interactions for traditional casual applications such as visualizing contents within context, and for complex situations including In-Situ 3D modeling using AR. From our previous works, multi-modal wearable inputs, 3D interactions around mobile devices, and context aware touch inputs have been explored for different applications. Moreover, my on-going research projects and future research directions are structured in the later sections of the paper.
C1  - Yokohama, Japan
C3  - Proceedings of the eleventh international conference on tangible, embedded, and embodied interaction
DA  - 2017///
PY  - 2017
DO  - 10.1145/3024969.3025044
SP  - 725
EP  - 728
PB  - Association for Computing Machinery
SN  - 978-1-4503-4676-4
UR  - https://doi.org/10.1145/3024969.3025044
KW  - augmented reality
KW  - mixed reality
KW  - tangible interaction
KW  - 3d interaction
KW  - sketch-based 3d modeling
ER  - 

TY  - CONF
TI  - Catch-up 360: Digital benefits for physical artifacts
AU  - Perteneder, Florian
AU  - Grossauer, Eva-Maria
AU  - Xu, Yan
AU  - Haller, Michael
T3  - Tei '15
AB  - Industrial designers have a tangible working style. However, compared to digital data, physical mockups are difficult to copy and share over distance. They require a lot of physical space, and earlier versions are lost once they are modified. In this paper, we introduce Catch-Up 360, a tool designed for sharing physical mockups over distance to gain feedback from remote located designers, and compare current models with earlier versions. Summarizing, our approach provides a simple, intuitive, and tangible UI that supports the use of lightweight, web-based clients by using remote manipulation of the physical objects.
C1  - Stanford, California, USA
C3  - Proceedings of the ninth international conference on tangible, embedded, and embodied interaction
DA  - 2015///
PY  - 2015
DO  - 10.1145/2677199.2680564
SP  - 105
EP  - 108
PB  - Association for Computing Machinery
SN  - 978-1-4503-3305-4
UR  - https://doi.org/10.1145/2677199.2680564
KW  - history
KW  - industrial design
KW  - physical mockups
KW  - sharing objects
KW  - tangible user interface
ER  - 

TY  - JOUR
TI  - A surgical scene replay system for learning gastroenterological endoscopic surgery skill by multiple synchronized-video and gaze representation
AU  - Matsuda, Akira
AU  - Okuzono, Toru
AU  - Nakamura, Hiromi
AU  - Kuzuoka, Hideaki
AU  - Rekimoto, Jun
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Gastroenterological endoscopic surgery needs complex surgical skills such as a sensation of body movement and manipulation of the endoscope that is hard to be explained verbally. Prior research reported that endoscopic surgery is one of the most challenging surgery to teach. Thus, surgeons need long-term practice to master the skills. To support learning such skills, we developed a surgical scene replay system. First, we surveyed 12 surgeons to reveal the reason for the difficulty and elicited three requirements for our system: (1) provide multiple videos that include an endoscope, a fluoroscopy, and hand manipulation for the endoscope to observe the surgery from multiple aspects; (2) visualize an experts' gaze position to understand experts' intention of hand manipulation, and (3) enlarge the size of the gazed video to inform learners where they should pay attention to. Our user study with the system indicates that participants could understand the experts' intentions and tacit knowledge easier than the existing video materials.
DA  - 2021/05//
PY  - 2021
DO  - 10.1145/3461726
VL  - 5
IS  - EICS
UR  - https://doi.org/10.1145/3461726
KW  - gastroenterological endoscopic surgery
KW  - gaze
KW  - multiple videos
KW  - skill learning
ER  - 

TY  - JOUR
TI  - Enhancing augmented VR interaction via egocentric scene analysis
AU  - Tian, Yang
AU  - Fu, Chi-Wing
AU  - Zhao, Shengdong
AU  - Li, Ruihui
AU  - Tang, Xiao
AU  - Hu, Xiaowei
AU  - Heng, Pheng-Ann
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
AB  - Augmented virtual reality (AVR) takes portions of the physical world into the VR world to enable VR users to access physical objects. State-of-the-art solutions mainly focus on extracting and showing physical objects in the VR world. In this work, we go beyond previous solutions and propose a novel approach to realize AVR. We first analyze the physical environment in the user's egocentric view through depth sensing and deep learning, then acquire the layout and geometry of the surrounding objects, and further explore their affordances. Based on the above information, we create visual guidance (hollowed guiding path) and hybrid user interfaces (augmented physical notepad, LR finger slider, and LRRL finger slider) to augment the AVR interaction. Empirical evaluations showed that the participants responded positively to our AVR techniques.
DA  - 2019/09//
PY  - 2019
DO  - 10.1145/3351263
VL  - 3
IS  - 3
UR  - https://doi.org/10.1145/3351263
KW  - virtual reality
KW  - depth sensing
KW  - augmented VR interaction
KW  - deep learning
KW  - egocentric view
KW  - scene analysis
KW  - visual guidance
KW  - visual tool
ER  - 

TY  - CONF
TI  - A decade of NML networked graphics
AU  - Stewart, John A.
AU  - Dumoulin, Sarah
AU  - Noël, Sylvie
T3  - Web3D '10
AB  - This paper is a summation of a decade of support for X3D, human-computer Interaction, and networked graphics that occurred at the Networked Media Laboratory, Communications Research Centre, Canada.
C1  - Los Angeles, California
C3  - Proceedings of the 15th international conference on web 3D technology
DA  - 2010///
PY  - 2010
DO  - 10.1145/1836049.1836054
SP  - 27
EP  - 34
PB  - Association for Computing Machinery
SN  - 978-1-4503-0209-8
UR  - https://doi.org/10.1145/1836049.1836054
KW  - virtual reality
KW  - CRC
KW  - FreeWRL
KW  - multicast
KW  - NML
KW  - peer to peer
KW  - shared virtual worlds
KW  - X3D
ER  - 

TY  - BOOK
TI  - SIGGRAPH '25: ACM SIGGRAPH 2025 emerging technologies
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1551-8
ER  - 

TY  - CONF
TI  - A design framework for awareness cues in distributed multiplayer games
AU  - Wuertz, Jason
AU  - Alharthi, Sultan A.
AU  - Hamilton, William A.
AU  - Bateman, Scott
AU  - Gutwin, Carl
AU  - Tang, Anthony
AU  - Toups Dugas, Phoebe O.
AU  - Hammer, Jessica
T3  - Chi '18
AB  - In the physical world, teammates develop situation awareness about each other's location, status, and actions through cues such as gaze direction and ambient noise. To support situation awareness, distributed multiplayer games provide awareness cues - information that games automatically make available to players to support cooperative gameplay. The design of awareness cues can be extremely complex, impacting how players experience games and work with teammates. Despite the importance of awareness cues, designers have little beyond experiential knowledge to guide their design. In this work, we describe a design framework for awareness cues, providing insight into what information they provide, how they communicate this information, and how design choices can impact play experience. Our research, based on a grounded theory analysis of current games, is the first to provide a characterization of awareness cues, providing a palette for game designers to improve design practice and a starting point for deeper research into collaborative play.
C1  - Montreal QC, Canada
C3  - Proceedings of the 2018 CHI conference on human factors in computing systems
DA  - 2018///
PY  - 2018
DO  - 10.1145/3173574.3173817
SP  - 1
EP  - 14
PB  - Association for Computing Machinery
SN  - 978-1-4503-5620-6
UR  - https://doi.org/10.1145/3173574.3173817
KW  - game design
KW  - awareness cues
KW  - distributed multiplayer games
KW  - situation awareness
KW  - workspace awareness
ER  - 

TY  - BOOK
TI  - VRST '22: Proceedings of the 28th ACM symposium on virtual reality software and technology
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9889-3
ER  - 

TY  - BOOK
TI  - ISS companion '23: Companion proceedings of the 2023 conference on interactive surfaces and spaces
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0425-3
ER  - 

TY  - CONF
TI  - Touching the depths: introducing tabletop interaction to reservoir engineering
AU  - Sultanum, Nicole
AU  - Sharlin, Ehud
AU  - Sousa, Mario Costa
AU  - Miranda-Filho, Daniel N.
AU  - Eastick, Rob
T3  - Its '10
AB  - Modern reservoir engineering is dependent on 3D visualization tools. However, as we argue in this paper, the current tools used in this domain are not completely aligned with the reservoir engineer's interactive needs, and do not address fundamental user issues, such as collaboration. We base our work on a set of observations of reservoir engineers, and their unique interactive tasks and needs. We present insightful knowledge of the domain, and follow with a prototype for an interactive reservoir visualization system, on the Microsoft Surface. We conclude by presenting a design critique we performed using our prototype, and reflecting on the impact we believe tabletop interaction will have on the domain of reservoir engineering.
C1  - Saarbrücken, Germany
C3  - ACM international conference on interactive tabletops and surfaces
DA  - 2010///
PY  - 2010
DO  - 10.1145/1936652.1936671
SP  - 105
EP  - 108
PB  - Association for Computing Machinery
SN  - 978-1-4503-0399-6
UR  - https://doi.org/10.1145/1936652.1936671
KW  - collaboration
KW  - tangible user interface
KW  - reservoir engineering
KW  - tabletop
KW  - visualization system
ER  - 

TY  - CONF
TI  - A review on effective closely-coupled collaboration using immersive CVE's
AU  - Otto, Oliver
AU  - Roberts, Dave
AU  - Wolff, Robin
T3  - Vrcia '06
AB  - Many teamwork tasks require a close coupling between the interactions of members of a team. For example, intention and opinion must be communicated, while synchronously manipulating shared artefacts. In face-to-face interaction this communication and manipulation is seamless. Transferring the straightforwardness of such collaboration onto remote located teams is technologically challenging. This survey paper explains why immersive collaborative virtual environments (CVE) suit such tasks. The effectiveness of application of this technology depends on a complex set of factors that determine the efficiency of collaboration. We examine these factors and their interrelationships within the framework of a taxonomy focussed on supporting closely-coupled collaboration using immersive CVEs. In particular we compare the impact of display configurations from distinct aspects within the interaction metaphors: look-in, reach-in and step-in.
C1  - Hong Kong, China
C3  - Proceedings of the 2006 ACM international conference on virtual reality continuum and its applications
DA  - 2006///
PY  - 2006
DO  - 10.1145/1128923.1128947
SP  - 145
EP  - 154
PB  - Association for Computing Machinery
SN  - 1-59593-324-7
UR  - https://doi.org/10.1145/1128923.1128947
KW  - closely-coupled collaboration
KW  - immersive CVEs
KW  - object interaction
ER  - 

TY  - BOOK
TI  - SA '24: SIGGRAPH asia 2024 posters
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1138-1
ER  - 

TY  - BOOK
TI  - MobileHCI '25 adjunct: Adjunct proceedings of the 27th international conference on mobile human-computer interaction
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1970-7
ER  - 

TY  - CONF
TI  - ARnnotate: An augmented reality interface for collecting custom dataset of 3D hand-object interaction pose estimation
AU  - Qian, Xun
AU  - He, Fengming
AU  - Hu, Xiyun
AU  - Wang, Tianyi
AU  - Ramani, Karthik
T3  - Uist '22
AB  - Vision-based 3D pose estimation has substantial potential in hand-object interaction applications and requires user-specified datasets to achieve robust performance. We propose ARnnotate, an Augmented Reality (AR) interface enabling end-users to create custom data using a hand-tracking-capable AR device. Unlike other dataset collection strategies, ARnnotate first guides a user to manipulate a virtual bounding box and records its poses and the user’s hand joint positions as the labels. By leveraging the spatial awareness of AR, the user manipulates the corresponding physical object while following the in-situ AR animation of the bounding box and hand model, while ARnnotate captures the user’s first-person view as the images of the dataset. A 12-participant user study was conducted, and the results proved the system’s usability in terms of the spatial accuracy of the labels, the satisfactory performance of the deep neural networks trained with the data collected by ARnnotate, and the users’ subjective feedback.
C1  - Bend, OR, USA
C3  - Proceedings of the 35th annual ACM symposium on user interface software and technology
DA  - 2022///
PY  - 2022
DO  - 10.1145/3526113.3545663
PB  - Association for Computing Machinery
SN  - 978-1-4503-9320-1
UR  - https://doi.org/10.1145/3526113.3545663
KW  - Augmented Reality
KW  - 3D Pose Estimation
KW  - Dataset Collection
KW  - Hand-Object Interaction
ER  - 

TY  - BOOK
TI  - MobileHCI '23 companion: Proceedings of the 25th international conference on mobile human-computer interaction
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 978-1-4503-9924-1
ER  - 

TY  - CONF
TI  - “Can you help me move this over there?”: training children with ASD to joint action through tangible interaction and virtual agent
AU  - Giraud, Tom
AU  - Ravenet, Brian
AU  - Tai Dang, Chi
AU  - Nadel, Jacqueline
AU  - Prigent, Elise
AU  - Poli, Gael
AU  - Andre, Elisabeth
AU  - Martin, Jean-claude
T3  - Tei '21
AB  - New technologies for autism focus on the training of either social skills or motor skills, but not both. Such a dichotomy omits a wide range of joint action tasks that require the coordination of two persons (e.g. moving a heavy furniture). The training of these physical tasks performed in dyad has great potential to foster inclusiveness while having an impact on both social and motor skills. In this paper, we present the design of a tangible and virtual interactive system for the training of children with Autism Spectrum Disorder (ASD) in performing joint actions. The proposed system is composed of a virtual character projected onto a surface on which a tangible object is magnetized: both the user and the virtual character hold the object, thus simulating a joint action. We report and discuss preliminary results of a field training study, which shows the potential of the interactive system.
C1  - Salzburg, Austria
C3  - Proceedings of the fifteenth international conference on tangible, embedded, and embodied interaction
DA  - 2021///
PY  - 2021
DO  - 10.1145/3430524.3440646
PB  - Association for Computing Machinery
SN  - 978-1-4503-8213-7
UR  - https://doi.org/10.1145/3430524.3440646
KW  - tangible interaction
KW  - autism
KW  - Joint action
KW  - virtual agent
ER  - 

TY  - CONF
TI  - Living with light touch: An autoethnography of a simple communication device in long-term use
AU  - Gaver, William
AU  - Gaver, Frances
T3  - Chi '23
AB  - We are a mother and son who have been using a pair of simple, self-build communication devices to maintain a feeling of connection while separated by over 5,000 miles. The devices, called Light Touch, only allow us to send one another slowly-fading, coloured lights, yet we have been surprised by how much our ongoing interaction with them means to us. This paper contributes an autoethnographical account of our experiences over the last two years, including our initial experiences with the devices, and focusing on various aspects of our day-to-day use. Based on our observations, we discuss the features that have proven important in mediating our feelings of connection. We point out, however, that their success is contingent on our context of use and the nature of our bond, and suggest that simple systems like Light Touch may support emotional communication, but only if they are well-matched to settings and relationships.
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI conference on human factors in computing systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544548.3580807
PB  - Association for Computing Machinery
SN  - 978-1-4503-9421-5
UR  - https://doi.org/10.1145/3544548.3580807
KW  - IoT
KW  - autobiographical design
KW  - autoethnography
KW  - emotional communication
KW  - open source
KW  - research through design
KW  - self-build
ER  - 

TY  - CONF
TI  - Novel tactile display for emotional tactile experience
AU  - Hashimoto, Yuki
AU  - Nakata, Satsuki
AU  - Kajimoto, Hiroyuki
T3  - Ace '09
AB  - We have proposed novel tactile display that presents high-fidelity tactile information by achieving a very wide frequency bandwidth. The system is composed of one or two speakers. Users hold the speakers between their hands while the speakers vibrate the air between the speakers and their palms. The user feels suction or pushing pressure on their palms from the air. Due to the very wide frequency range (1 Hz and below to 1 kHz and above), users can feel a variety of sensations. Furthermore, due to the indirect drive of the palm through the air, users feel uniform pressure without any feeling of the edges or shapes of hard contactors, which are necessary for an ordinary haptic interface to convey high frequency signals. In this paper, we introduce three application ideas by using this display that enable us to experience rich tactile expressions. We also show some pilot studies to realize these ideas, first implementations of them and result of exhibition.
C1  - Athens, Greece
C3  - Proceedings of the international conference on advances in computer entertainment technology
DA  - 2009///
PY  - 2009
DO  - 10.1145/1690388.1690410
SP  - 124
EP  - 131
PB  - Association for Computing Machinery
SN  - 978-1-60558-864-3
UR  - https://doi.org/10.1145/1690388.1690410
KW  - emotion
KW  - air pressure
KW  - hi-fi
KW  - palm
KW  - speaker
KW  - tactile sensation
ER  - 

TY  - CONF
TI  - VRBubble: Enhancing peripheral awareness of avatars for people with visual impairments in social virtual reality
AU  - Ji, Tiger F.
AU  - Cochran, Brianna
AU  - Zhao, Yuhang
T3  - Assets '22
AB  - Social Virtual Reality (VR) is growing for remote socialization and collaboration. However, current social VR applications are not accessible to people with visual impairments (PVI) due to their focus on visual experiences. We aim to facilitate social VR accessibility by enhancing PVI’s peripheral awareness of surrounding avatar dynamics. We designed VRBubble, an audio-based VR technique that provides surrounding avatar information based on social distances. Based on Hall’s proxemic theory, VRBubble divides the social space with three Bubbles—Intimate, Conversation, and Social Bubble—generating spatial audio feedback to distinguish avatars in different bubbles and provide suitable avatar information. We provide three audio alternatives: earcons, verbal notifications, and real-world sound effects. PVI can select and combine their preferred feedback alternatives for different avatars, bubbles, and social contexts. We evaluated VRBubble and an audio beacon baseline with 12 PVI in a navigation and a conversation context. We found that VRBubble significantly enhanced participants’ avatar awareness during navigation and enabled avatar identification in both contexts. However, VRBubble was shown to be more distracting in crowded environments.
C1  - Athens, Greece
C3  - Proceedings of the 24th international ACM SIGACCESS conference on computers and accessibility
DA  - 2022///
PY  - 2022
DO  - 10.1145/3517428.3544821
PB  - Association for Computing Machinery
SN  - 978-1-4503-9258-7
UR  - https://doi.org/10.1145/3517428.3544821
KW  - proxemics
KW  - social virtual reality
KW  - visual impairments
KW  - audio feedback
ER  - 

TY  - CONF
TI  - Tangible interaction for children’s creative learning: a review
AU  - Liang, Meng
AU  - Li, Yanhong
AU  - Weber, Thomas
AU  - Hussmann, Heinrich
T3  - C&amp;C '21
AB  - Creativity is an important part of children’s education. Tangible User Interfaces&nbsp;(TUIs) provide new possibilities for creative learning. In this review, we gave an overview of recent studies that supported children’s creative learning using TUIs. Results showed that TUIs had many advantages, such as they (1)&nbsp;were novice-friendly, (2)&nbsp;supported children’s cognitive process and development, (3)&nbsp;promoted their initiatives, (4)&nbsp;enabled them to think outside the box, and (5)&nbsp;encouraged communication and collaboration in an authentic context. Meanwhile, we summarized previous work’s three main limitations: First, most of the studies did not have a long-term experimental verification with sufficient sample size and objective evaluation; Second, some TUI designs lacked a balance of abstractness, openness, richness, and complexity; Finally, the use of TUIs had little consideration of the teacher’s role. Therefore, further research should focus more on the trans-disciplinary nature of TUIs for creative learning and leverage collaboration between human-computer interaction researchers and school teachers.
C1  - Virtual Event, Italy
C3  - Proceedings of the 13th conference on creativity and cognition
DA  - 2021///
PY  - 2021
DO  - 10.1145/3450741.3465262
PB  - Association for Computing Machinery
SN  - 978-1-4503-8376-9
UR  - https://doi.org/10.1145/3450741.3465262
KW  - review
KW  - tangible interaction
KW  - children
KW  - tangible user interface
KW  - creative learning
KW  - TUI
ER  - 

TY  - JOUR
TI  - Virtual reality aided high-quality 3D reconstruction by remote drones
AU  - Zhang, Di
AU  - Xu, Feng
AU  - Pun, Chi-Man
AU  - Yang, Yang
AU  - Lan, Rushi
AU  - Wang, Liejun
AU  - Li, Yujie
AU  - Gao, Hao
T2  - ACM Trans. Internet Technol.
AB  - Artificial intelligence including deep learning and 3D reconstruction methods is changing the daily life of people. Now, an unmanned aerial vehicle that can move freely in the air and avoid harsh ground conditions has been commonly adopted as a suitable tool for 3D reconstruction. The traditional 3D reconstruction mission based on drones usually consists of two steps: image collection and offline post-processing. But there are two problems: one is the uncertainty of whether all parts of the target object are covered, and another is the tedious post-processing time. Inspired by modern deep learning methods, we build a telexistence drone system with an onboard deep learning computation module and a wireless data transmission module that perform incremental real-time dense reconstruction of urban cities by itself. Two technical contributions are proposed to solve the preceding issues. First, based on the popular depth fusion surface reconstruction framework, we combine it with a visual-inertial odometry estimator that integrates the inertial measurement unit and allows for robust camera tracking as well as high-accuracy online 3D scan. Second, the capability of real-time 3D reconstruction enables a new rendering technique that can visualize the reconstructed geometry of the target as navigation guidance in the HMD. Therefore, it turns the traditional path-planning-based modeling process into an interactive one, leading to a higher level of scan completeness. The experiments in the simulation system and our real prototype demonstrate an improved quality of the 3D model using our artificial intelligence leveraged drone system.
DA  - 2021/09//
PY  - 2021
DO  - 10.1145/3458930
VL  - 22
IS  - 1
SN  - 1533-5399
UR  - https://doi.org/10.1145/3458930
KW  - virtual reality
KW  - 3D reconstruction
KW  - human-robot-interaction
KW  - telexistence
KW  - unmanned aerial vehicle
ER  - 

TY  - BOOK
TI  - SIGGRAPH immersive pavilion '25: Proceedings of the special interest group on computer graphics and interactive techniques conference immersive pavilion
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1547-1
ER  - 

TY  - JOUR
TI  - Unleashing creativity in the metaverse: Generative AI and multimodal content
AU  - El Saddik, Abdulmotaleb
AU  - Ahmad, Jamil
AU  - Khan, Mustaqeem
AU  - Abouzahir, Saad
AU  - Gueaieb, Wail
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
AB  - The metaverse presents an emerging creative expression and collaboration frontier where generative artificial intelligence (GenAI) can play a pivotal role with its ability to generate multimodal content from simple prompts. These prompts allow the metaverse to interact with GenAI, where context information, instructions, input data, or even output indications constituting the prompt can come from within the metaverse. However, their integration poses challenges regarding interoperability, lack of standards, scalability, and maintaining a high-quality user experience. This article explores how GenAI can productively assist in enhancing creativity within the contexts of the metaverse and unlock new opportunities. We provide a technical, in-depth overview of the different generative models for image, video, audio, and 3D content within the metaverse environments. We also explore the bottlenecks, opportunities, and innovative applications of GenAI from the perspectives of end users, developers, service providers, and AI researchers. This survey commences by highlighting the potential of GenAI for enhancing the metaverse experience through dynamic content generation to populate massive virtual worlds. Subsequently, we shed light on the ongoing research practices and trends in multimodal content generation, enhancing realism and creativity and alleviating bottlenecks related to standardization, computational cost, privacy, and safety. Last, we share insights into promising research directions toward the integration of GenAI with the metaverse for creative enhancement, improved immersion, and innovative interactive applications.
DA  - 2025/07//
PY  - 2025
DO  - 10.1145/3713075
VL  - 21
IS  - 7
SN  - 1551-6857
UR  - https://doi.org/10.1145/3713075
KW  - Metaverse
KW  - Generative AI
KW  - Content Generation
KW  - Diffusion Models
KW  - Generative Adversarial Networks
KW  - Multimodal
ER  - 

TY  - BOOK
TI  - LSC '24: Proceedings of the 7th annual ACM workshop on the lifelog search challenge
AB  - The LSC workshops are participation workshops, where participants write and present an academic paper describing their prototype lifelog retrieval system, and then take part in a live interactive search competition. Consequently, the workshop is highly interactive and challenging for participants.
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0550-2
ER  - 

TY  - CONF
TI  - TempoString: a tangible tool for children's music creation
AU  - He, Liang
AU  - Li, Guang
AU  - Zhang, Yang
AU  - Wang, Danli
AU  - Wang, Hongan
T3  - UbiComp '12
AB  - In this paper, we introduce the design and implementation of TempoString, an easy-to-use tool which assists children with music creation. It provides such a fun and novel platform by allowing children to "draw" music on a canvas and then edit it using a rope. The main contribution of our work is the novel access which allows children to "paint" music on a canvas and then edit using a rope.
C1  - Pittsburgh, Pennsylvania
C3  - Proceedings of the 2012 ACM conference on ubiquitous computing
DA  - 2012///
PY  - 2012
DO  - 10.1145/2370216.2370345
SP  - 643
EP  - 644
PB  - Association for Computing Machinery
SN  - 978-1-4503-1224-0
UR  - https://doi.org/10.1145/2370216.2370345
KW  - tangible interface
KW  - children
KW  - music creation
KW  - rope interaction
KW  - visual and audio feedback
ER  - 

TY  - CONF
TI  - Collaborative technologies for children with special needs: a systematic literature review
AU  - Baykal, Gökçe Elif
AU  - Van Mechelen, Maarten
AU  - Eriksson, Eva
T3  - Chi '20
AB  - This paper presents a systematic literature review on collaborative technologies for children with special needs in ACM Digital Library. The aim of the review is to (1) reveal the current state of the art, (2) identify the types of technologies and contexts of use, the demographics and special needs of the target group, and the methodological approaches and theoretical groundings, and (3) define a future research agenda. The results of the systematic literature review show that collaborative technologies for children with special needs are increasingly gaining attention, mostly involve tangible and/or embodied interaction, and are often developed for use in the classroom. The target group that is most represented are boys between 6 to 12 years with Autism Spectrum Disorder. The results further show a wide range of evaluation criteria for measuring collaboration, an interchanging use of theoretical concepts and a lack of definitions for the concept collaboration, and a need for more demographically diverse studies.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI conference on human factors in computing systems
DA  - 2020///
PY  - 2020
DO  - 10.1145/3313831.3376291
SP  - 1
EP  - 13
PB  - Association for Computing Machinery
SN  - 978-1-4503-6708-0
UR  - https://doi.org/10.1145/3313831.3376291
KW  - systematic literature review
KW  - collaboration
KW  - collaborative learning
KW  - cci
KW  - collaborative technologies
KW  - special need
ER  - 

TY  - CONF
TI  - Spatial sound control with the yamaha tenori-on
AU  - Sasamoto, Yuya
AU  - Villegas, Julı́an
AU  - Cohen, Michael
T3  - Hc '10
AB  - Musical Instrument Digital Interface (midi) is a standard for music device communication. Midi allows the exchange of information (pitch, velocity, duration of sound, and so on) between electronic instruments and computers. Spatial sound is one of the ways to express sound and music, and also an important feature of virtual reality. By means of using spatial sound in virtual reality, the immersiveness of a user is enhanced. In this research, we explore control of spatial sound using the Yamaha Tenori-On and the University of Aizu Business Innovation Center (ubic) 3d Theater speaker array. This project explores the spatialization of music, by mapping Tenori-On performances and sound localization in a single operation, allowing the notes to freely move around the room.
C1  - Aizu-Wakamatsu, Japan
C3  - Proceedings of the 13th international conference on humans and computers
DA  - 2010///
PY  - 2010
SP  - 62
EP  - 65
PB  - University of Aizu Press
ER  - 

TY  - CONF
TI  - JackIn head: an immersive human-human telepresence system
AU  - Kasahara, Shunichi
AU  - Rekimoto, Jun
T3  - Sa '15
AB  - Sharing full immersive experience in real-time has been the one of ultimate goals of telecommunication. Possible application can include various applications such as entertainment, sports viewing, education, social network and professional assistance. Recent head-worn wearable camera enables to shoot the first person video, however, view of angle is limited with the head direction of the person who is wearing, and also captured video is shaky that makes us dizzy. We propose JackIn Head, an immersive experience sharing system with wearable camera headgear that provides 360 degrees spherical images of the user's surrounding environment. JackIn Head system performs spherical video stabilization and transmits it to other users, so that they are able to view shared video comfortably and also look around at the scene from a different view angle independently from the first person. In this note, we explain the overview of the JackIn Head system implementation, stabilization and viewing experience.
C1  - Kobe, Japan
C3  - SIGGRAPH asia 2015 emerging technologies
DA  - 2015///
PY  - 2015
DO  - 10.1145/2818466.2818486
PB  - Association for Computing Machinery
SN  - 978-1-4503-3925-4
UR  - https://doi.org/10.1145/2818466.2818486
KW  - 360 degrees spherical image
KW  - first person view streaming
KW  - wearable computer
ER  - 

TY  - CONF
TI  - Towards designing playful bodily extensions: Learning from expert interviews
AU  - Buruk, Oğuz 'Oz'
AU  - Matjeka, Louise Petersen
AU  - Mueller, Florian ‘Floyd’
T3  - Chi '23
AB  - Interactive technologies offer novel opportunities for physically extending our bodies, with the most prominent examples being prosthetics along with systems emerging from the wearables community. However, most such systems appear to focus on instrumental benefits, missing out on the opportunity to use bodily extensions for play and its associated benefits (including a lower adoption barrier and the potential to reveal a broader understanding of such technologies). To begin understanding the design of playful bodily extensions, we interviewed five designers of bodily extensions that have been showcased in prestigious academic venues or turned into commercial products. Here we present themes and actionable advice from these interviews for the design of playful bodily extensions through a thematic analysis. Our work aims to support the design of future playful bodily extensions while promoting the experiential qualities of bodily extension design, with the ultimate goal of bringing more playful experiences to people’s lives.
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI conference on human factors in computing systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544548.3581165
PB  - Association for Computing Machinery
SN  - 978-1-4503-9421-5
UR  - https://doi.org/10.1145/3544548.3581165
KW  - Games
KW  - Thematic Analysis
KW  - Bodily Extensions
KW  - Cyborg
KW  - Expert Interviews
KW  - Play
KW  - Posthuman
KW  - Transhuman
KW  - Wearables
ER  - 

TY  - CONF
TI  - Multimodal mobile-ambient transmedial twirling with environmental lighting to complement fluid perspective with phase-perturbed affordance projection
AU  - Cohen, Michael
AU  - Ranaweera, Rasika
AU  - Ryskeldiev, Bektur
AU  - Oyama, Tomohiro
AU  - Hashimoto, Aya
AU  - Tsukida, Naoki
AU  - Miyaji, Toshimune
T3  - Sa '14
AB  - To illuminate the alignment between mixed reality juggling toys and ambidextrous vactors twirling a projection of those toys, roomware lighting control is deployed to show the modeled position of a virtual camera spinning around each player, even while the affordances are whirled. "Tworlds" is a mixed reality multimodal toy using twirled juggling-style affordances built using mobile devices— smartphones, phablets, &amp; tablets— to modulate various displays, including 3D models and, now, environmental lighting. A unique feature of the projection is the preservation of logical alignment even when the virtual camera moves continuously around an avatar between frontal and dorsal views in an "inspection gesture," phase-locked rotation and revolution (like the face of the moon pointing at the Earth). For example, a right-handed user would prefer to see their self-identified puppet holding an affordance in the right hand for dorsal (tethered) views, but would rather see the puppet switch hands for a frontal (mirrored) perspective. Because the projected phase of the toy must be modulated in order to preserve such visual correspondence, even while the prop is being whirled, and to elucidate the inspection gesture, we use networked lighting (Philips Hue Wi-Fi networked bulbs) to indicate the position of the virtual camera. Even though a toy might be twirled too fast for such lights to track in the real world, so that only computer graphic "eye candy" effects are practical, the speed of the orbiting of the virtual camera can be adjusted to accommodate even sluggish lighting switching.
C1  - Shenzhen, China
C3  - SIGGRAPH asia 2014 mobile graphics and interactive applications
DA  - 2014///
PY  - 2014
DO  - 10.1145/2669062.2669080
PB  - Association for Computing Machinery
SN  - 978-1-4503-1891-4
UR  - https://doi.org/10.1145/2669062.2669080
KW  - whole body interaction
KW  - cross-platform multimodal interface
KW  - exertion interface
KW  - mobile-ambient transmedia
KW  - practically panoramic
ER  - 

TY  - CONF
TI  - Embodied axes: Tangible, actuated interaction for 3D augmented reality data spaces
AU  - Cordeil, Maxime
AU  - Bach, Benjamin
AU  - Cunningham, Andrew
AU  - Montoya, Bastian
AU  - Smith, Ross T.
AU  - Thomas, Bruce H.
AU  - Dwyer, Tim
T3  - Chi '20
AB  - We present Embodied Axes, a controller which supports selection operations for 3D imagery and data visualisations in Augmented Reality. The device is an embodied representation of a 3D data space – each of its three orthogonal arms corresponds to a data axis or domain specific frame of reference. Each axis is composed of a pair of tangible, actuated range sliders for precise data selection, and rotary encoding knobs for additional parameter tuning or menu navigation. The motor actuated sliders support alignment to positions of significant values within the data, or coordination with other input: e.g., mid-air gestures in the data space, touch gestures on the surface below the data, or another Embodied Axes device supporting multi-user scenarios. We conducted expert enquiries in medical imaging which provided formative feedback on domain tasks and refinements to the design. Additionally, a controlled user study was performed and found that the Embodied Axes was overall more accurate than conventional tracked controllers for selection tasks.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI conference on human factors in computing systems
DA  - 2020///
PY  - 2020
DO  - 10.1145/3313831.3376613
SP  - 1
EP  - 12
PB  - Association for Computing Machinery
SN  - 978-1-4503-6708-0
UR  - https://doi.org/10.1145/3313831.3376613
KW  - augmented reality
KW  - tangible interaction
KW  - actuation
KW  - 3d visualisation
KW  - device
ER  - 

TY  - CONF
TI  - OmniGlobeVR: a collaborative 360-degree communication system for VR
AU  - Li, Zhengqing
AU  - Teo, Theophilus
AU  - Chan, Liwei
AU  - Lee, Gun
AU  - Adcock, Matt
AU  - Billinghurst, Mark
AU  - Koike, Hideki
T3  - Dis '20
AB  - In this paper, we present a novel collaboration tool, OmniGlobeVR, which is an asymmetric system that supports communication and collaboration between a VR user (occupant) and multiple non-VR users (designers) across the virtual and physical platform. OmniGlobeVR allows designer(s) to explore the VR space from any point of view using two view modes: a 360° first-person mode and a third-person mode. In addition, a shared gaze awareness cue is provided to further enhance communication between the occupant and the designer(s). Finally, the system has a face window feature that allows designer(s) to share their facial expressions and upper body view with the occupant for exchanging and expressing information using nonverbal cues. We conducted a user study to evaluate the OmniGlobeVR, comparing three conditions: (1) first-person mode with the face window, (2) first-person mode with a solid window, and (3) third-person mode with the face window. We found that the first-person mode with the face window required significantly less mental effort, and provided better spatial presence, usability, and understanding of the partner's focus. We discuss the design implications of these results and directions for future research.
C1  - Eindhoven, Netherlands
C3  - Proceedings of the 2020 ACM designing interactive systems conference
DA  - 2020///
PY  - 2020
DO  - 10.1145/3357236.3395429
SP  - 615
EP  - 625
PB  - Association for Computing Machinery
SN  - 978-1-4503-6974-9
UR  - https://doi.org/10.1145/3357236.3395429
KW  - virtual reality
KW  - mixed reality
KW  - collaboration
KW  - communication
KW  - 360-degree camera
KW  - spherical display
ER  - 

TY  - JOUR
TI  - Collaborative tabletops for blind people: The effect of auditory design on workspace awareness
AU  - Mendes, Daniel
AU  - Reis, Sofia
AU  - Guerreiro, João
AU  - Nicolau, Hugo
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Interactive tabletops offer unique collaborative features, particularly their size, geometry, orientation and, more importantly, the ability to support multi-user interaction. Although previous efforts were made to make interactive tabletops accessible to blind people, the potential to use them in collaborative activities remains unexplored. In this paper, we present the design and implementation of a multi-user auditory display for interactive tabletops, supporting three feedback modes that vary on how much information about the partners' actions is conveyed. We conducted a user study with ten blind people to assess the effect of feedback modes on workspace awareness and task performance. Furthermore, we analyze the type of awareness information exchanged and the emergent collaboration strategies. Finally, we provide implications for the design of future tabletop collaborative tools for blind users.
DA  - 2020/11//
PY  - 2020
DO  - 10.1145/3427325
VL  - 4
IS  - ISS
UR  - https://doi.org/10.1145/3427325
KW  - collaboration
KW  - awareness
KW  - blind
KW  - tabletop
KW  - screen reader
ER  - 

TY  - CONF
TI  - Collaborating &amp; being together: influence of screen size and viewing distance during video communication
AU  - Dagonneau, Virginie
AU  - Martin, Elise
AU  - Cosquer, Mathilde
T3  - Vric '14
AB  - Through videoconferencing, people search to interact and communicate with their remote friends or family as they were together in the same place. The influence of form variables such as screen size has been mainly investigated on the sense of physical presence (presence as transportation) in virtual environment and in television area, but less attention has been paid to how these factors can influence the sense of co-presence in videoconferencing. In addition, preferred viewing distance is well known to be a key parameter in order to convey a sense of presence and enjoyment when people watch television, but there is currently no data regarding preferred viewing distance in videoconferencing. This paper presents a user study which explores the influence of screen size on the participant's sense of co-presence and on their preferred viewing distance. The main results of this study revealed that users preferred to get closer to the screen when they communicated in videoconferencing than when they watched TV program. Our study suggests that screen size has an effect on the preferred viewing distance and on the participant's sense of co-presence, with higher scores of co-presence with larger screen.
C1  - Laval, France
C3  - Proceedings of the 2014 virtual reality international conference
DA  - 2014///
PY  - 2014
DO  - 10.1145/2617841.2620717
PB  - Association for Computing Machinery
SN  - 978-1-4503-2626-1
UR  - https://doi.org/10.1145/2617841.2620717
KW  - collaboration
KW  - communication
KW  - co-presence
KW  - field of view
KW  - screen size
KW  - videoconferencing
KW  - viewing distance
ER  - 

TY  - CONF
TI  - Mathematics and geometry education with collaborative augmented reality
AU  - Kaufmann, Hannes
AU  - Schmalstieg, Dieter
T3  - Siggraph '02
AB  - Construct3D is a three-dimensional geometric construction tool specifically designed for mathematics and geometry education. It is based on the mobile collaborative augmented reality system "Studierstube." We describe our efforts in developing a system for the improvement of spatial abilities and maximization of transfer of learning. In order to support various teacher-student interaction scenarios we implemented flexible methods for context and user dependent rendering of parts of the construction. Together with hybrid hardware setups they allow the use of Construct3D in today's classrooms and provide a test bed for future evaluations. Means of application and integration in mathematics and geometry education at the high school, as well as the university, level are being discussed. Anecdotal evidence supports our claim that Construct3D is easy to learn, encourages experimentation with geometric constructions, and improves spatial skills.
C1  - San Antonio, Texas
C3  - ACM SIGGRAPH 2002 conference abstracts and applications
DA  - 2002///
PY  - 2002
DO  - 10.1145/1242073.1242086
SP  - 37
EP  - 41
PB  - Association for Computing Machinery
SN  - 1-58113-525-4
UR  - https://doi.org/10.1145/1242073.1242086
KW  - augmented reality
KW  - geometry education
KW  - mathematics education
KW  - spatial intelligence
ER  - 

TY  - CONF
TI  - Time delay effect on social interaction dynamics
AU  - Iizuka, Hiroyuki
AU  - Saitoh, Sohtaroh
AU  - Marocco, Davide
AU  - Yamamoto, Masahito
T3  - Hai '15
AB  - This paper investigates time-delay effects of the human social interaction to understand how human can adapt to the time delay, which will be required in software agents to establish a harmonic interaction with human. We performed the minimal experiments of social interaction called perceptual crossing experiments with time delay. Our result shows that the social interaction breaks down when the total amount of time delay is given more than about one second. However, the interaction breaks more easily when the time delay is given to both participants than to either participant.
C1  - Daegu, Kyungpook, Republic of Korea
C3  - Proceedings of the 3rd international conference on human-agent interaction
DA  - 2015///
PY  - 2015
DO  - 10.1145/2814940.2814979
SP  - 217
EP  - 219
PB  - Association for Computing Machinery
SN  - 978-1-4503-3527-0
UR  - https://doi.org/10.1145/2814940.2814979
KW  - social interaction
KW  - minimal approach
KW  - perceptual crossing experiment
KW  - time delay
ER  - 

TY  - CONF
TI  - The design of social drones: a review of studies on autonomous flyers in inhabited environments
AU  - Baytas, Mehmet Aydin
AU  - Çay, Damla
AU  - Zhang, Yuchong
AU  - Obaid, Mohammad
AU  - Yantaç, Asim Evren
AU  - Fjeld, Morten
T3  - Chi '19
AB  - The design space of social drones, where autonomous flyers operate in close proximity to human users or bystanders, is distinct from use cases involving a remote human operator and/or an uninhabited environment; and warrants foregrounding human-centered design concerns. Recently, research on social drones has followed a trend of rapid growth. This paper consolidates the current state of the art in human-centered design knowledge about social drones through a review of relevant studies, scaffolded by a descriptive framework of design knowledge creation. Our analysis identified three high-level themes that sketch out knowledge clusters in the literature, and twelve design concerns which unpack how various dimensions of drone aesthetics and behavior relate to pertinent human responses. These results have the potential to inform and expedite future research and practice, by supporting readers in defining and situating their future contributions. The materials and results of our analysis are also published in an open online repository that intends to serve as a living hub for a community of researchers and designers working with social drones.
C1  - Glasgow, Scotland Uk
C3  - Proceedings of the 2019 CHI conference on human factors in computing systems
DA  - 2019///
PY  - 2019
DO  - 10.1145/3290605.3300480
SP  - 1
EP  - 13
PB  - Association for Computing Machinery
SN  - 978-1-4503-5970-2
UR  - https://doi.org/10.1145/3290605.3300480
KW  - user studies
KW  - autonomous agents
KW  - design knowledge
KW  - drone design
KW  - drones
KW  - empirical studies
KW  - human-drone interaction
KW  - social drones
ER  - 

TY  - CONF
TI  - Hybrid paper-digital interfaces: a systematic literature review
AU  - Han, Feng
AU  - Cheng, Yifei
AU  - Strachan, Megan
AU  - Ma, Xiaojuan
T3  - Dis '21
AB  - Past research recognized that paper has many advantages over digital devices, such as affordability, tangibility, and flexibility. Paper, however, also lacks many of the functionalities available in digital technologies, such as access to online resources and the ability to display interactive content. Prior research therefore identified opportunities for fusing the two mediums into a combined interface. This work presents a literature review on this form of innovation - technologies that bridge the paper-digital gap. First, we synthesize an understanding of paper and its relationship with digital devices through the lens of past works. Then, we outline the state-of-the-art for paper-digital interfaces and highlight possible use cases and implementation approaches. Last, we discuss design considerations and future work for developing paper-digital interfaces. Our work may be beneficial for HCI researchers interested in the development of hybrid paper-digital interfaces, and more broadly in embedding digital functionalities in everyday objects.
C1  - Virtual Event, USA
C3  - Proceedings of the 2021 ACM designing interactive systems conference
DA  - 2021///
PY  - 2021
DO  - 10.1145/3461778.3462059
SP  - 1087
EP  - 1100
PB  - Association for Computing Machinery
SN  - 978-1-4503-8476-6
UR  - https://doi.org/10.1145/3461778.3462059
KW  - interactive paper
KW  - paper computing
KW  - paper interfaces
ER  - 

TY  - CONF
TI  - Analysis of peripheral vision and vibrotactile feedback during proximal search tasks with dynamic virtual entities in augmented reality
AU  - Richards, Kendra
AU  - Mahalanobis, Nikhil
AU  - Kim, Kangsoo
AU  - Schubert, Ryan
AU  - Lee, Myungho
AU  - Daher, Salam
AU  - Norouzi, Nahal
AU  - Hochreiter, Jason
AU  - Bruder, Gerd
AU  - Welch, Greg
T3  - Sui '19
AB  - A primary goal of augmented reality (AR) is to seamlessly embed virtual content into a real environment. There are many factors that can affect the perceived physicality and co-presence of virtual entities, including the hardware capabilities, the fidelity of the virtual behaviors, and sensory feedback associated with the interactions. In this paper, we present a study investigating participants’ perceptions and behaviors during a time-limited search task in close proximity with virtual entities in AR. In particular, we analyze the effects of (i) visual conflicts in the periphery of an optical see-through head-mounted display, a Microsoft HoloLens, (ii) overall lighting in the physical environment, and (iii) multimodal feedback based on vibrotactile transducers mounted on a physical platform. Our results show significant benefits of vibrotactile feedback and reduced peripheral lighting for spatial and social presence, and engagement. We discuss implications of these effects for AR applications.
C1  - New Orleans, LA, USA
C3  - Symposium on spatial user interaction
DA  - 2019///
PY  - 2019
DO  - 10.1145/3357251.3357585
PB  - Association for Computing Machinery
SN  - 978-1-4503-6975-6
UR  - https://doi.org/10.1145/3357251.3357585
KW  - Augmented Reality
KW  - Field of View
KW  - Multimodal Feedback
KW  - Search Task
ER  - 

TY  - BOOK
TI  - TEI '25: Proceedings of the nineteenth international conference on tangible, embedded, and embodied interaction
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1197-8
ER  - 

TY  - BOOK
TI  - VRST '23: Proceedings of the 29th ACM symposium on virtual reality software and technology
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0328-7
ER  - 

TY  - CONF
TI  - Yo–yo machines: Self-build devices that support social connections during the pandemic
AU  - Gaver, William
AU  - Boucher, Andy
AU  - Brown, Dean
AU  - Chatting, David
AU  - Matsuda, Naho
AU  - Ovalle, Liliana
AU  - Sheen, Andy
AU  - Vanis, Michail
T3  - Chi '22
AB  - Yo–Yo Machines are playful communication devices designed to help people feel socially connected while physically separated. We designed them to reach as many people as possible, both to make a positive impact during the COVID-19 pandemic and to assess a self-build approach to circulating research products and the appeal of peripheral and expressive communication devices. A portfolio of four distinct designs, based on over 30 years of research, were made available for people to make by following simple online instructions (yoyomachines.io). Each involves connecting a pair of identical devices over the internet to allow simple communication at a distance. This paper describes our motivation for the project, previous work in the area, the design of the devices, supporting website and publicity, and how users have made and used Yo-Yo Machines. Finally, we reflect on what we learned about peripheral and expressive communication devices and implications for the self-build approach.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI conference on human factors in computing systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491102.3517547
PB  - Association for Computing Machinery
SN  - 978-1-4503-9157-3
UR  - https://doi.org/10.1145/3491102.3517547
KW  - IoT
KW  - open source
KW  - research through design
KW  - self-build
KW  - design research
KW  - peripheral and expressive communication
ER  - 

TY  - BOOK
TI  - IUI '25: Proceedings of the 30th international conference on intelligent user interfaces
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1306-4
ER  - 

TY  - JOUR
TI  - Mobile augmented reality: User interfaces, frameworks, and intelligence
AU  - Cao, Jacky
AU  - Lam, Kit-Yung
AU  - Lee, Lik-Hang
AU  - Liu, Xiaoli
AU  - Hui, Pan
AU  - Su, Xiang
T2  - Acm Computing Surveys
AB  - Mobile Augmented Reality (MAR) integrates computer-generated virtual objects with physical environments for mobile devices. MAR systems enable users to interact with MAR devices, such as smartphones and head-worn wearables, and perform seamless transitions from the physical world to a mixed world with digital entities. These MAR systems support user experiences using MAR devices to provide universal access to digital content. Over the past 20 years, several MAR systems have been developed, however, the studies and design of MAR frameworks have not yet been systematically reviewed from the perspective of user-centric design. This article presents the first effort of surveying existing MAR frameworks (count: 37) and further discusses the latest studies on MAR through a top-down approach: (1) MAR applications; (2) MAR visualisation techniques adaptive to user mobility and contexts; (3) systematic evaluation of MAR frameworks, including supported platforms and corresponding features such as tracking, feature extraction, and sensing capabilities; (4) and underlying machine learning approaches supporting intelligent operations within MAR systems. Finally, we summarise the development of emerging research fields and the current state-of-the-art and discuss the important open challenges and possible theoretical and technical directions. This survey aims to benefit both researchers and MAR system developers alike.
DA  - 2023/01//
PY  - 2023
DO  - 10.1145/3557999
VL  - 55
IS  - 9
J2  - ACM Comput. Surv.
SN  - 0360-0300
UR  - https://doi.org/10.1145/3557999
KW  - artificial intelligence
KW  - metaverse
KW  - development framework
KW  - Mobile augmented reality
KW  - user interactions
ER  - 

TY  - CHAP
TI  - Paths forward: Aspirations for TEI
T2  - Weaving fire into form: Aspirations for tangible and embodied interaction
AB  - This book investigates multiple facets of the emerging discipline of Tangible, Embodied, and Embedded Interaction (TEI). This is a story of atoms and bits. We explore the interweaving of the physical and digital, toward understanding some of their wildly varying hybrid forms and behaviors. Spanning conceptual, philosophical, cognitive, design, and technical aspects of interaction, this book charts both history and aspirations for the future of TEI. We examine and celebrate diverse trailblazing works, and provide wide-ranging conceptual and pragmatic tools toward weaving the animating fires of computation and technology into evocative tangible forms. We also chart a path forward for TEI engagement with broader societal and sustainability challenges that will profoundly (re)shape our children’s and grandchildren’s futures. We invite you all to join this quest.
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9769-8
UR  - https://doi.org/10.1145/3544564.3544577
ER  - 

TY  - CONF
TI  - Beyond the prototype: Understanding the challenge of scaling hardware device production
AU  - Khurana, Rushil
AU  - Hodges, Steve
T3  - Chi '20
AB  - The hardware research and development communities have invested heavily in tools and materials that facilitate the design and prototyping of electronic devices. Numerous easy-to-access and easy-to-use tools have streamlined the prototyping of interactive and embedded devices for experts and led to a remarkable growth in non-expert builders. However, there has been little exploration of challenges associated with moving beyond a prototype and creating hundreds or thousands of exact replicas - a process that is still challenging for many. We interviewed 25 individuals with experience taking prototype hardware devices into low volume production. We systematically investigated the common issues faced and mitigation strategies adopted. We present our findings in four main categories: (1) gaps in technical knowledge; (2) gaps in non-technical knowledge; (3) minimum viable rigor in manufacturing preparation; and (4) building relationships and a professional network. Our study unearthed several opportunities for new tools and processes to support the transition beyond a working prototype to cost effective low-volume manufacturing. These would complement the aforementioned tools and materials that support design and prototyping.
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI conference on human factors in computing systems
DA  - 2020///
PY  - 2020
DO  - 10.1145/3313831.3376761
SP  - 1
EP  - 11
PB  - Association for Computing Machinery
SN  - 978-1-4503-6708-0
UR  - https://doi.org/10.1145/3313831.3376761
KW  - hardware device realization
KW  - long tail hardware
KW  - low volume electronics manufacturing
KW  - productization
ER  - 

TY  - BOOK
TI  - SIGGRAPH '17: ACM SIGGRAPH 2017 VR village
AB  - Throughout the week at SIGGRAPH 2017, attendees explore the fascinating potential of real-time immersion in tomorrow's virtual and augmented realities for exploring new modes of communication, interaction, and in powering real-world applications in health, art, education, and gaming. Installations include:•Artistic and scientific installations•Nomadic (untethered) VR•Collaborative and multi-person experiences•Games and themed-entertainment•Unique interactive techniques
CY  - New York, NY, USA
DA  - 2017///
PY  - 2017
PB  - Association for Computing Machinery
SN  - 978-1-4503-5013-6
ER  - 

TY  - CONF
TI  - Augmented reality views for occluded interaction
AU  - Lilija, Klemen
AU  - Pohl, Henning
AU  - Boring, Sebastian
AU  - Hornbæk, Kasper
T3  - Chi '19
AB  - We rely on our sight when manipulating objects. When objects are occluded, manipulation becomes difficult. Such occluded objects can be shown via augmented reality to re-enable visual guidance. However, it is unclear how to do so to best support object manipulation. We compare four views of occluded objects and their effect on performance and satisfaction across a set of everyday manipulation tasks of varying complexity. The best performing views were a see-through view and a displaced 3D view. The former enabled participants to observe the manipulated object through the occluder, while the latter showed the 3D view of the manipulated object offset from the object's real location. The worst performing view showed remote imagery from a simulated hand-mounted camera. Our results suggest that alignment of virtual objects with their real-world location is less important than an appropriate point-of-view and view stability.
C1  - Glasgow, Scotland Uk
C3  - Proceedings of the 2019 CHI conference on human factors in computing systems
DA  - 2019///
PY  - 2019
DO  - 10.1145/3290605.3300676
SP  - 1
EP  - 12
PB  - Association for Computing Machinery
SN  - 978-1-4503-5970-2
UR  - https://doi.org/10.1145/3290605.3300676
KW  - augmented reality
KW  - finger-camera
KW  - manipulation task
ER  - 

TY  - BOOK
TI  - SUI '24: Proceedings of the 2024 ACM symposium on spatial user interaction
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1088-9
ER  - 

TY  - CONF
TI  - Remixed reality: Manipulating space and time in augmented reality
AU  - Lindlbauer, David
AU  - Wilson, Andy D.
T3  - Chi '18
AB  - We present Remixed Reality, a novel form of mixed reality. In contrast to classical mixed reality approaches where users see a direct view or video feed of their environment, with Remixed Reality they see a live 3D reconstruction, gathered from multiple external depth cameras. This approach enables changing the environment as easily as geometry can be changed in virtual reality, while allowing users to view and interact with the actual physical world as they would in augmented reality. We characterize a taxonomy of manipulations that are possible with Remixed Reality: spatial changes such as erasing objects; appearance changes such as changing textures; temporal changes such as pausing time; and viewpoint changes that allow users to see the world from different points without changing their physical location. We contribute a method that uses an underlying voxel grid holding information like visibility and transformations, which is applied to live geometry in real time.
C1  - Montreal QC, Canada
C3  - Proceedings of the 2018 CHI conference on human factors in computing systems
DA  - 2018///
PY  - 2018
DO  - 10.1145/3173574.3173703
SP  - 1
EP  - 13
PB  - Association for Computing Machinery
SN  - 978-1-4503-5620-6
UR  - https://doi.org/10.1145/3173574.3173703
KW  - virtual reality
KW  - augmented reality
KW  - remixed reality
ER  - 

TY  - CONF
TI  - Increasing trust through the use of 3d e-commerce environment
AU  - Nassiri, Nasser
T3  - Sac '08
AB  - Existing 2D e-commerce internet websites provide users with only relatively simple, browser-based interface to access available products and services. These websites often lack in the emulation of real-life human representative which is an important factor in establishing consumer's trust. 3D e-commerce environments with 3D virtual space and human-like avatar facilitating the sale of real-world products may add the human factor to the shopping experience and might therefore enhance the relation of social trust in these environments. This paper explains the concept of 3D e-commerce environments and their roles in increasing consumer's trust and in enhancing e-business profitability.
C1  - Fortaleza, Ceara, Brazil
C3  - Proceedings of the 2008 ACM symposium on applied computing
DA  - 2008///
PY  - 2008
DO  - 10.1145/1363686.1364028
SP  - 1463
EP  - 1466
PB  - Association for Computing Machinery
SN  - 978-1-59593-753-7
UR  - https://doi.org/10.1145/1363686.1364028
KW  - trust
KW  - touch
KW  - 3D e-commerce environment
KW  - appearance
ER  - 

TY  - CONF
TI  - The aircraft of the future: towards the tangible cockpit
AU  - Castillo, Juan Angel Lorenzo del
AU  - Couture, Nadine
T3  - HCI-aero '16
AB  - The future of the cockpit is undeniably tactile. To make this vision become a reality, several usability issues must be first addressed, being the most important one the eyes-free interaction. In fact, different ways of interaction (tactile, physical) will coexist, and it is paramount to identify those elements in the cockpit that can become tactile and those that must remain as tangible (i.e. physical) ones. This work intends to analyze the current situation and the requirements from the point of view of Human-Machine Interaction. In this regard, we propose a new approach that, leading to the concept of "tangibilisation of the cockpit", can facilitate the coexistence between tactile and physical actuators in the cockpit. We believe that this approach will foster and inspire the development of a tangible cockpit in the near future.
C1  - Paris, France
C3  - Proceedings of the international conference on human-computer interaction in aerospace
DA  - 2016///
PY  - 2016
DO  - 10.1145/2950112.2964582
PB  - Association for Computing Machinery
SN  - 978-1-4503-4406-7
UR  - https://doi.org/10.1145/2950112.2964582
KW  - tactile
KW  - tangible
KW  - aircraft
KW  - cockpit
KW  - human centered design
ER  - 

TY  - CONF
TI  - STREAM: Exploring the combination of spatially-aware tablets with augmented reality head-mounted displays for immersive analytics
AU  - Hubenschmid, Sebastian
AU  - Zagermann, Johannes
AU  - Butscher, Simon
AU  - Reiterer, Harald
T3  - Chi '21
AB  - Recent research in the area of immersive analytics demonstrated the utility of head-mounted augmented reality devices for visual data analysis. However, it can be challenging to use the by default supported mid-air gestures to interact with visualizations in augmented reality (e.g. due to limited precision). Touch-based interaction (e.g. via mobile devices) can compensate for these drawbacks, but is limited to two-dimensional input. In this work we present STREAM: Spatially-aware Tablets combined with Augmented Reality Head-Mounted Displays for the multimodal interaction with 3D visualizations. We developed a novel eyes-free interaction concept for the seamless transition between the tablet and the augmented reality environment. A user study reveals that participants appreciated the novel interaction concept, indicating the potential for spatially-aware tablets in augmented reality. Based on our findings, we provide design insights to foster the application of spatially-aware touch devices in augmented reality and research implications indicating areas that need further investigation.
C1  - Yokohama, Japan
C3  - Proceedings of the 2021 CHI conference on human factors in computing systems
DA  - 2021///
PY  - 2021
DO  - 10.1145/3411764.3445298
PB  - Association for Computing Machinery
SN  - 978-1-4503-8096-6
UR  - https://doi.org/10.1145/3411764.3445298
KW  - augmented reality
KW  - immersive analytics
KW  - multimodal interaction
KW  - mobile devices
KW  - visualizations
ER  - 

TY  - CONF
TI  - Is it real? Measuring the effect of resolution, latency, frame rate and jitter on the presence of virtual entities
AU  - Louis, Thibault
AU  - Troccaz, Jocelyne
AU  - Rochet-Capellan, Amélie
AU  - Bérard, François
T3  - Iss '19
AB  - The feeling of presence of virtual entities is an important objective in virtual reality, teleconferencing, augmented reality, exposure therapy and video games. Presence creates emotional involvement and supports intuitive and efficient interactions. As a feeling, presence is mostly measured via subjective questionnaire, but its validity is disputed. We introduce a new method to measure the contribution of several technical parameters toward presence. Its robustness stems from asking participant to rank contrasts rather than asking absolute values, and from the statistical analysis of repeated answers. We implemented this method in a user study where virtual entities were created with a handheld perspective corrected display. We evaluated the impact on two virtual entities' presence of four important parameters of digital visual stimuli: resolution, latency, frame rate and jitter. Results suggest that jitter and frame rate are critical for presence but not latency, and resolution depends on the explored entity.
C1  - Daejeon, Republic of Korea
C3  - Proceedings of the 2019 ACM international conference on interactive surfaces and spaces
DA  - 2019///
PY  - 2019
DO  - 10.1145/3343055.3359710
SP  - 5
EP  - 16
PB  - Association for Computing Machinery
SN  - 978-1-4503-6891-9
UR  - https://doi.org/10.1145/3343055.3359710
KW  - presence
KW  - spatial augmented reality
KW  - user study
KW  - hpcd
ER  - 

TY  - CONF
TI  - Photoportals: shared references in space and time
AU  - Kunert, André
AU  - Kulik, Alexander
AU  - Beck, Stephan
AU  - Froehlich, Bernd
T3  - Cscw '14
AB  - Photoportals build on digital photography as a unifying metaphor for reference-based interaction in 3D virtual environments. Virtual photos and videos serve as threedimensional references to objects, places, moments in time and activities of users. Our Photoportals also provide access to intermediate or alternative versions of a scenario and allow the review of recorded task sequences that include life-size representations of the captured users. We propose to exploit such references to structure collaborative activities of collocated and remote users. Photoportals offer additional access points for multiple users and encourage mutual support through the preparation and provision of references for manipulation and navigation tasks. They support the pattern of territoriality with configurable space representations that can be used for private interaction, as well as be shared and exchanged with others.
C1  - Baltimore, Maryland, USA
C3  - Proceedings of the 17th ACM conference on computer supported cooperative work &amp; social computing
DA  - 2014///
PY  - 2014
DO  - 10.1145/2531602.2531727
SP  - 1388
EP  - 1399
PB  - Association for Computing Machinery
SN  - 978-1-4503-2540-0
UR  - https://doi.org/10.1145/2531602.2531727
KW  - collaborative virtual environments
KW  - 3d interaction
KW  - 3d user interfaces
KW  - interactive systems
KW  - multi-user interaction
ER  - 

TY  - BOOK
TI  - MuC '23: Proceedings of mensch und computer 2023
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0771-1
ER  - 

TY  - CONF
TI  - DesignSpace: a manual interaction environment for computer aided design
AU  - Chapin, William L.
AU  - Lacey, Timothy A.
AU  - Leifer, Larry
T3  - Chi '94
C1  - Boston, Massachusetts, USA
C3  - Conference companion on human factors in computing systems
DA  - 1994///
PY  - 1994
DO  - 10.1145/259963.260001
SP  - 33
EP  - 34
PB  - Association for Computing Machinery
SN  - 0-89791-651-4
UR  - https://doi.org/10.1145/259963.260001
ER  - 

TY  - CONF
TI  - DesignSpace: a manual interaction environment for computer-aided design
AU  - Chapin, William L.
AU  - Lacey, Timothy A.
AU  - Leifer, Larry
T3  - Chi '94
C1  - Boston, Massachusetts, USA
C3  - Conference companion on human factors in computing systems
DA  - 1994///
PY  - 1994
DO  - 10.1145/259963.260018
SP  - 47
EP  - 48
PB  - Association for Computing Machinery
SN  - 0-89791-651-4
UR  - https://doi.org/10.1145/259963.260018
ER  - 

TY  - JOUR
TI  - A survey of augmented, virtual, and mixed reality for cultural heritage
AU  - Bekele, Mafkereseb Kassahun
AU  - Pierdicca, Roberto
AU  - Frontoni, Emanuele
AU  - Malinverni, Eva Savina
AU  - Gain, James
AB  - A multimedia approach to the diffusion, communication, and exploitation of Cultural Heritage (CH) is a well-established trend worldwide. Several studies demonstrate that the use of new and combined media enhances how culture is experienced. The benefit is in terms of both number of people who can have access to knowledge and the quality of the diffusion of the knowledge itself. In this regard, CH uses augmented-, virtual-, and mixed-reality technologies for different purposes, including education, exhibition enhancement, exploration, reconstruction, and virtual museums. These technologies enable user-centred presentation and make cultural heritage digitally accessible, especially when physical access is constrained. A number of surveys of these emerging technologies have been conducted; however, they are either not domain specific or lack a holistic perspective in that they do not cover all the aspects of the technology. A review of these technologies from a cultural heritage perspective is therefore warranted. Accordingly, our article surveys the state-of-the-art in augmented-, virtual-, and mixed-reality systems as a whole and from a cultural heritage perspective. In addition, we identify specific application areas in digital cultural heritage and make suggestions as to which technology is most appropriate in each case. Finally, the article predicts future research directions for augmented and virtual reality, with a particular focus on interaction interfaces and explores the implications for the cultural heritage domain.
DA  - 2018/03//
PY  - 2018
DO  - 10.1145/3145534
VL  - 11
IS  - 2
J2  - J. Comput. Cult. Herit.
SN  - 1556-4673
UR  - https://doi.org/10.1145/3145534
KW  - virtual reality
KW  - augmented reality
KW  - mixed reality
KW  - Cultural heritage
ER  - 

TY  - CONF
TI  - bioSync: a paired wearable device for blending kinesthetic experience
AU  - Nishida, Jun
AU  - Suzuki, Kenji
T3  - Chi '17
AB  - We present a novel, paired, wearable system for combining the kinesthetic experiences of two persons. These devices allow users to sense and combine muscle contraction and joint rigidity bi-directionally. This is achieved through kinesthetic channels based on electromyogram (EMG) measurement and electrical muscle stimulation (EMS). We developed a pair of wearable kinesthetic input-output (I/O) devices called bioSync that uses specially designed electrodes to perform biosignal measurement and stimulation simultaneously on the same electrodes.In a user study, participants successfully evaluated the strength of their partners' muscle contractions while exerting their own muscles. We confirmed that the pair of devices could help participants synchronize their hand movements through tapping, without visual and auditory feedback. The proposed interpersonal kinesthetic communication system can be used to enhance interactions such as clinical gait rehabilitation and sports training, and facilitate sharing of physical experiences with Parkinson's patients, thereby enhancing understanding of the physical challenges they face in daily life.
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI conference on human factors in computing systems
DA  - 2017///
PY  - 2017
DO  - 10.1145/3025453.3025829
SP  - 3316
EP  - 3327
PB  - Association for Computing Machinery
SN  - 978-1-4503-4655-9
UR  - https://doi.org/10.1145/3025453.3025829
KW  - electrical muscle stimulation
KW  - blending kinesthetic experience
KW  - electromyogram signals
KW  - rehabilitation
ER  - 

TY  - CONF
TI  - "Can we work this out?": an evaluation of remote collaborative interaction in a mobile shared environment
AU  - Trendafilov, Dari
AU  - Vazquez-Alvarez, Yolanda
AU  - Lemmelä, Saija
AU  - Murray-Smith, Roderick
T3  - MobileHCI '11
AB  - We describe a novel dynamic method for collaborative virtual environments designed for mobile devices and evaluated in a mobile context. Participants interacted in pairs remotely and through touch while walking in three different feedback conditions: 1) visual, 2) audio-tactile, 3) spatial audio-tactile. Results showed the visual baseline system provided higher shared awareness, efficiency and a strong learning effect. However, and although very challenging, the eyes-free systems still offered the ability to build joint awareness in remote collaborative environments, particularly the spatial audio one. These results help us better understand the potential of different feedback mechanisms in the design of future mobile collaborative environments.
C1  - Stockholm, Sweden
C3  - Proceedings of the 13th international conference on human computer interaction with mobile devices and services
DA  - 2011///
PY  - 2011
DO  - 10.1145/2037373.2037447
SP  - 499
EP  - 502
PB  - Association for Computing Machinery
SN  - 978-1-4503-0541-9
UR  - https://doi.org/10.1145/2037373.2037447
KW  - social presence
KW  - tactile
KW  - collaborative virtual environments
KW  - spatial audio
KW  - mobile shared interaction
ER  - 

TY  - JOUR
TI  - CalMe: a tangible environment to enhance pupils group work regulation
AU  - Bertolo, David
AU  - Faedda, Stéphane
AU  - Olry, Alexis
AU  - Veytizou, Julien
AU  - Vivian, Robin
AU  - Fleck, Stéphanie
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - A large number of studies highlight the importance of regulation in collaborative learning (CL). Nevertheless, only some studies describe how to get or support pupils to learn to regulate group work in school. In this context, we aim to understand if a specifically designed tangible environment can promote a regulated collaboration process during a face-to-face activity in school. Therefore, we conducted a 2-year design-based research (DBR) study. This article describes the DBR cycles in detail, and the steps we have executed to develop, test, implement, and evaluate a set of tangible artifacts called Collective attention led by a Mediated environment (CalMe). First, we identified three specific dimensions that interfere with CL in the classroom: team building and collective decision-making, task regulation awareness, and over-solicitation limitation. Second, we proposed design choices leading to the first iteration of a CalMe device that meets these needs. We then assessed usability and acceptability before the pedagogical validation steps. Third, through a pilot study, we evaluated the pedagogical potential of the second iteration of the CalMe device in a real context of use in an elementary school class. We collected and analyzed data from surveys, focus groups, log data, and video recordings through all the steps. Moreover, to allow for duplication of the study, we propose and detail our methodological approach. This study shows an empirical example of a DBR process that allows responding as closely as possible to the needs of both pupils and teachers. This work also provides input to teachers regarding a better understanding of collaborative problem-solving activities. Although there is still room for improvement on specific dimensions related to task regulation, such as better management of ambient noise or work tempo, the results indicate that the CalMe device allows for a regulated collaboration process in schools. It shows an human–computer interaction design process that can be an example of how to influence classroom activities through technology to promote positive CL experiences.
DA  - 2025/04//
PY  - 2025
DO  - 10.1145/3685273
VL  - 32
IS  - 2
SN  - 1073-0516
UR  - https://doi.org/10.1145/3685273
KW  - Design-based research
KW  - Face-to-face collaborative learning
KW  - K-12
KW  - Learning experience
KW  - Tangible interfaces
KW  - Team and task regulation
ER  - 

TY  - CONF
TI  - Closely coupled collaboration for search tasks
AU  - Simard, J.
AU  - Ammi, M.
AU  - Auvray, M.
T3  - Vrst '10
AB  - This article proposes to study the role of Collaborative Virtual Environments for the search of residues in molecular environments. This research highlights involved working strategies according the type and context of the task and shows some constraints and conflicting actions that may occur during closely coupled collaboration.
C1  - Hong Kong
C3  - Proceedings of the 17th ACM symposium on virtual reality software and technology
DA  - 2010///
PY  - 2010
DO  - 10.1145/1889863.1889904
SP  - 181
EP  - 182
PB  - Association for Computing Machinery
SN  - 978-1-4503-0441-2
UR  - https://doi.org/10.1145/1889863.1889904
ER  - 

TY  - BOOK
TI  - UIST '24: Proceedings of the 37th annual ACM symposium on user interface software and technology
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0628-8
ER  - 

TY  - CONF
TI  - Virtual reality tools for the west digital conservatory of archaeological heritage
AU  - Barreau, Jean-Baptiste
AU  - Gaugne, Ronan
AU  - Bernard, Yann
AU  - Le Cloirec, Gaétan
AU  - Gouranton, Valérie
T3  - Vric '14
AB  - In the continuation of the 3D data production work made by the WDCAH, the use of virtual reality tools allows archaeologists to carry out analysis and understanding research about their sites. In this paper, we focus on the virtual reality services proposed to archaeologists in the WDCAH, through the example of two archaeological sites, the Temple de Mars in Corseul and the Cairn of Carn Island.
C1  - Laval, France
C3  - Proceedings of the 2014 virtual reality international conference
DA  - 2014///
PY  - 2014
DO  - 10.1145/2617841.2617845
PB  - Association for Computing Machinery
SN  - 978-1-4503-2626-1
UR  - https://doi.org/10.1145/2617841.2617845
KW  - virtual reality
KW  - archaeology
KW  - digital heritage
ER  - 

TY  - BOOK
TI  - HUMAN '24: Proceedings of the 7th workshop on human factors in hypertext
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1120-6
ER  - 

TY  - JOUR
TI  - What do researchers need when implementing novel interaction techniques?
AU  - Raffaillac, Thibault
AU  - Huot, Stéphane
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Interaction frameworks are the tools of choice for researchers and UI designers when prototyping new and original interaction techniques. But with little knowledge about actual needs, these frameworks provide incomplete support that restricts, slows down or even prevents the exploration of new ideas. In this context, researchers resort to hacking methods, creating code that lacks robustness beyond experiments, combining libraries of different levels and paradigms, and eventually limiting the dissemination and reproducibility of their work. To better understand this problem, we interviewed 9 HCI researchers and conducted an online survey. From the results we give an overview of the criteria for choosing frameworks, the problems often met with them, and the "tricks" used as solutions. Then we propose three design principles to better support prototyping for research in UI frameworks: (i) duplicate singular elements (e.g. mouse, caret) to foster opportunities for extensions, (ii) accumulate rather than replace to keep a history of changes, and (iii) defer the execution of predefined behaviors to enable their monitoring and replacement.
DA  - 2022/06//
PY  - 2022
DO  - 10.1145/3532209
VL  - 6
IS  - EICS
UR  - https://doi.org/10.1145/3532209
KW  - interaction techniques
KW  - prototyping
KW  - design principles
KW  - hacking
KW  - interaction frameworks
KW  - interviews
KW  - online survey
KW  - toolkits
ER  - 

TY  - BOOK
TI  - IHM '24: Proceedings of the 35th conference on l'Interaction humain-machine
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1811-3
ER  - 

TY  - CONF
TI  - VR almost there: Simulating co-located multiplayer experiences in social virtual reality
AU  - Sykownik, Philipp
AU  - Karaosmanoglu, Sukran
AU  - Emmerich, Katharina
AU  - Steinicke, Frank
AU  - Masuch, Maic
T3  - Chi '23
AB  - Consumer social virtual reality (VR) applications have recently started to enable social interactions at a distance. Yet it is still relatively unknown if and to what extent such applications provide meaningful social experiences in cases where in-person leisure activities are not feasible. To explore this, we developed a custom social VR application and conducted an exploratory lab study with 25 dyads in which we compared an in-person and a virtual version of a co-located multiplayer scenario. Our mixed-methods analysis revealed that both scenarios created a socially rich atmosphere and strengthened the social closeness between players. However, the lack of facial animations, limited body language, and a low field of view led to VR’s main social experiential limitations: a reduced mutual awareness and emotional understanding compared to the in-person scenario. We derive implications for social VR design and research as well as game user research.
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI conference on human factors in computing systems
DA  - 2023///
PY  - 2023
DO  - 10.1145/3544548.3581230
PB  - Association for Computing Machinery
SN  - 978-1-4503-9421-5
UR  - https://doi.org/10.1145/3544548.3581230
KW  - social interaction
KW  - social virtual reality
KW  - social presence
KW  - player experience
KW  - multiplayer games
ER  - 

TY  - CONF
TI  - T(ether): spatially-aware handhelds, gestures and proprioception for multi-user 3D modeling and animation
AU  - Lakatos, David
AU  - Blackshaw, Matthew
AU  - Olwal, Alex
AU  - Barryte, Zachary
AU  - Perlin, Ken
AU  - Ishii, Hiroshi
T3  - Sui '14
AB  - T(ether) is a spatially-aware display system for multi-user, collaborative manipulation and animation of virtual 3D objects. The handheld display acts as a window into virtual reality, providing users with a perspective view of 3D data. T(ether) tracks users' heads, hands, fingers and pinching, in addition to a handheld touch screen, to enable rich interaction with the virtual scene. We introduce gestural interaction techniques that exploit proprioception to adapt the UI based on the hand's position above, behind or on the surface of the display. These spatial interactions use a tangible frame of reference to help users manipulate and animate the model in addition to controlling environment properties. We report on initial user observations from an experiment for 3D modeling, which indicate T(ether)'s potential for embodied viewport control and 3D modeling interactions.
C1  - Honolulu, Hawaii, USA
C3  - Proceedings of the 2nd ACM symposium on spatial user interaction
DA  - 2014///
PY  - 2014
DO  - 10.1145/2659766.2659785
SP  - 90
EP  - 93
PB  - Association for Computing Machinery
SN  - 978-1-4503-2820-3
UR  - https://doi.org/10.1145/2659766.2659785
KW  - 3D user interfaces
KW  - VR
KW  - multi-user
KW  - gestural interaction
KW  - 3D modeling
KW  - collaborative
KW  - spatially-aware displays
ER  - 

TY  - CONF
TI  - ShareSpace: Facilitating shared use of the physical space by both VR head-mounted display and external users
AU  - Yang, Keng-Ta
AU  - Wang, Chiu-Hsuan
AU  - Chan, Liwei
T3  - Uist '18
AB  - Currently, "walkable" virtual reality (VR) is achieved by dedicating a room-sized space for VR activities, which is not shared with non-HMD users engaged in their own activities. To achieve the goal of allowing shared use of space for all users while overcoming the obvious difficulty of integrating use with those immersed in a VR experience, we present ShareSpace, a system that allows external users to communicate their needs for physical space to those wearing an HMD and immersed in their VR experience. ShareSpace works by allowing external users to place "shields" in the virtual environment by using a set of physical shield tools. A pad visualizer helps this process by allowing external users to examine the arrangement of virtual shields. We also discuss interaction techniques that minimize the interference between the respective activities of the HMD wearers and the other users of the same physical space. To evaluate our design, a user study was conducted to collect user feedback from participants in four trial scenarios. The results indicate that our ShareSpace system allows users to perform their respective activities with improved engagement and safety. In addition, this study shows that while the HMD users did perceive a considerable degree of interference due to the internal visual indications from the ShareSpace system, they were still more engaged in their VR experience than when interrupted by direct external physical interference initiated by external users.
C1  - Berlin, Germany
C3  - Proceedings of the 31st annual ACM symposium on user interface software and technology
DA  - 2018///
PY  - 2018
DO  - 10.1145/3242587.3242630
SP  - 499
EP  - 509
PB  - Association for Computing Machinery
SN  - 978-1-4503-5948-1
UR  - https://doi.org/10.1145/3242587.3242630
KW  - virtual reality
KW  - external users experience
KW  - shared use of physical space
ER  - 

TY  - CONF
TI  - Poultry.Internet: a remote human-pet interaction system
AU  - Teh, Keng Soon
AU  - Lee, Shang Ping
AU  - Cheok, Adrian David
T3  - Chi ea '06
AB  - Poultry.Internet leverages on the reach of the Internet to connect humans and pets at different locations. This system has a tangible interface encompassing both visual and tactile modes of communication. It allows humans to interact remotely with pets anytime, anywhere. The pet owner views the real time movement of the pet in the form of a pet doll sitting on a mechanical positioning system. Meanwhile, the real pet wears a special jacket, which is able to reproduce the touching sensation. The pet owner can tangibly touch the pet doll, sending touch signals to the pet far away. Also, the pet owner receives a haptic feedback from the movement of the pet.
C1  - Montréal, Québec, Canada
C3  - CHI '06 extended abstracts on human factors in computing systems
DA  - 2006///
PY  - 2006
DO  - 10.1145/1125451.1125505
SP  - 251
EP  - 254
PB  - Association for Computing Machinery
SN  - 1-59593-298-4
UR  - https://doi.org/10.1145/1125451.1125505
KW  - haptics
KW  - tangible interaction
KW  - wearable computing
KW  - human-pet interaction
ER  - 

TY  - CONF
TI  - PenLight: combining a mobile projector and a digital pen for dynamic visual overlay
AU  - Song, Hyunyoung
AU  - Grossman, Tovi
AU  - Fitzmaurice, George
AU  - Guimbretiere, François
AU  - Khan, Azam
AU  - Attar, Ramtin
AU  - Kurtenbach, Gordon
T3  - Chi '09
AB  - Digital pen systems, originally designed to digitize annotations made on physical paper, are evolving to permit a wider variety of applications. Although the type and quality of pen feedback (e.g., haptic, audio, and visual) have a huge impact on advancing the digital pen technology, dynamic visual feedback has yet to be fully investigated. In parallel, miniature projectors are an emerging technology with the potential to enhance visual feedback for small mobile computing devices. In this paper we present the PenLight system, which is a testbed to explore the interaction design space and its accompanying interaction techniques in a digital pen embedded with a spatially-aware miniature projector. Using our prototype, that simulates a miniature projection (via a standard video projector), we visually augment paper documents, giving the user immediate access to additional information and computational tools. We also show how virtual ink can be managed in single and multi-user environments to aid collaboration and data management. User evaluation with professional architects indicated promise of our proposed techniques and their potential utility in the paper-intensive domain of architecture.
C1  - Boston, MA, USA
C3  - Proceedings of the SIGCHI conference on human factors in computing systems
DA  - 2009///
PY  - 2009
DO  - 10.1145/1518701.1518726
SP  - 143
EP  - 152
PB  - Association for Computing Machinery
SN  - 978-1-60558-246-7
UR  - https://doi.org/10.1145/1518701.1518726
KW  - digital pen input
KW  - mobile projector
KW  - multi-layer interaction
KW  - spatially-aware display
ER  - 

TY  - JOUR
TI  - A composite framework of co-located asymmetric virtual reality
AU  - Ouverson, Kaitlyn M.
AU  - Gilbert, Stephen B.
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - As the variety of possible interactions with virtual reality (VR) continues to expand, researchers need a way to relate these interactions to users' needs and goals in ways that advance understanding. Existing efforts have focused mainly on the symmetric use of technology, which excludes a rising form of interaction known as asymmetric VR, in which co-located participants use different interfaces to interact with a shared environment. There must be a clear path to creating asymmetric VR systems that are rooted in previous work from several fields, as these systems have use cases in education, hybrid reality teams (using VR and other technologies to interact online and face to face), accessibility, as well as entertainment. Currently, there is no systematic way to characterize 1) how a system may be asymmetric, 2) how the different mediation technology and affordances within asymmetric VR support (or do not support) users' goals, and 3) the relationships and collaborative capabilities between users of these different technologies. In this paper, the authors use a scoping review to explore relevant conceptual frameworks for asymmetric interaction, mediation technology, and computer supported cooperative work to clarify the dimensions of asymmetry and synthesize the literature into a Composite framework for Asymmetric VR (CAVR). The paper concludes with suggestions of ways to test and expand the framework in order to guide future research as it identifies the most-beneficial interaction paradigms for co-located asymmetric VR.
DA  - 2021/04//
PY  - 2021
DO  - 10.1145/3449079
VL  - 5
IS  - CSCW1
UR  - https://doi.org/10.1145/3449079
KW  - collaboration
KW  - workspace awareness
KW  - asymmetric vr
KW  - conceptual frameworks
KW  - extended reality (xr)
KW  - mixed reality (mr)
ER  - 

TY  - BOOK
TI  - SA '15: SIGGRAPH asia 2015 mobile graphics and interactive applications
CY  - New York, NY, USA
DA  - 2015///
PY  - 2015
PB  - Association for Computing Machinery
SN  - 978-1-4503-3928-5
ER  - 

TY  - CONF
TI  - TransceiVR: Bridging asymmetrical communication between VR users and external collaborators
AU  - Thoravi Kumaravel, Balasaravanan
AU  - Nguyen, Cuong
AU  - DiVerdi, Stephen
AU  - Hartmann, Bjoern
T3  - Uist '20
AB  - Virtual Reality (VR) users often need to work with other users, who observe them outside of VR using an external display. Communication between them is difficult; the VR user cannot see the external user's gestures, and the external user cannot see VR scene elements outside of the VR user's view. We carried out formative interviews with experts to understand these asymmetrical interactions and identify their goals and challenges. From this, we identify high-level system design goals to facilitate asymmetrical interactions and a corresponding space of implementation approaches based on the level of programmatic access to a VR application. We present TransceiVR, a system that utilizes VR platform APIs to enable asymmetric communication interfaces for third-party applications without requiring source code access. TransceiVR allows external users to explore the VR scene spatially or temporally, to annotate elements in the VR scene at correct depths, and to discuss via a shared static virtual display. An initial co-located user evaluation with 10 pairs shows that our system makes asymmetric collaborations in VR more effective and successful in terms of task time, error rate, and task load index. An informal evaluation with a remote expert gives additional insight on utility of features for real world tasks.
C1  - Virtual Event, USA
C3  - Proceedings of the 33rd annual ACM symposium on user interface software and technology
DA  - 2020///
PY  - 2020
DO  - 10.1145/3379337.3415827
SP  - 182
EP  - 195
PB  - Association for Computing Machinery
SN  - 978-1-4503-7514-6
UR  - https://doi.org/10.1145/3379337.3415827
KW  - virtual reality
KW  - collaboration
KW  - asymmetric interactions
ER  - 

TY  - BOOK
TI  - EICS '25 companion: Companion proceedings of the 17th ACM SIGCHI symposium on engineering interactive computing systems
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1866-3
ER  - 

TY  - CONF
TI  - FluxMarker: Enhancing tactile graphics with dynamic tactile markers
AU  - Suzuki, Ryo
AU  - Stangl, Abigale
AU  - Gross, Mark D.
AU  - Yeh, Tom
T3  - Assets '17
AB  - For people with visual impairments, tactile graphics are an important means to learn and explore information. However, raised line tactile graphics created with traditional materials such as embossing are static. While available refreshable displays can dynamically change the content, they are still too expensive for many users, and are limited in size. These factors limit wide-spread adoption and the representation of large graphics or data sets. In this paper, we present FluxMaker, an inexpensive scalable system that renders dynamic information on top of static tactile graphics with movable tactile markers. These dynamic tactile markers can be easily reconfigured and used to annotate static raised line tactile graphics, including maps, graphs, and diagrams. We developed a hardware prototype that actuates magnetic tactile markers driven by low-cost and scalable electromagnetic coil arrays, which can be fabricated with standard printed circuit board manufacturing. We evaluate our prototype with six participants with visual impairments and found positive results across four application areas: location finding or navigating on tactile maps, data analysis, and physicalization, feature identification for tactile graphics, and drawing support. The user study confirms advantages in application domains such as education and data exploration.
C1  - Baltimore, Maryland, USA
C3  - Proceedings of the 19th international ACM SIGACCESS conference on computers and accessibility
DA  - 2017///
PY  - 2017
DO  - 10.1145/3132525.3132548
SP  - 190
EP  - 199
PB  - Association for Computing Machinery
SN  - 978-1-4503-4926-0
UR  - https://doi.org/10.1145/3132525.3132548
KW  - visual impairment
KW  - dynamic tactile markers
KW  - interactive tactile graphics
KW  - tangible interfaces
ER  - 

TY  - JOUR
TI  - Research alerts
AU  - Campbell, Marisa
T2  - Interactions
DA  - 2001/01//
PY  - 2001
DO  - 10.1145/356978.356981
VL  - 8
IS  - 1
SP  - 11
EP  - 17
SN  - 1072-5520
UR  - https://doi.org/10.1145/356978.356981
ER  - 

TY  - CONF
TI  - Holy smartphones and tablets, Batman! mobile interaction's dynamic duo
AU  - Piazza, Tommaso
AU  - Fjeld, Morten
AU  - Ramos, Gonzalo
AU  - Yantac, AsimEvren
AU  - Zhao, Shengdong
T3  - Apchi '13
AB  - It is becoming increasingly more common for people to own botha smartphone and a tablet, providing a design opportunity to leverage the combination of these two formfactors. Our work aims to explore this by: a) defining the design space of distributed input and output solutions that rely on and benefit from phone–tablet collaboration, both physically and digitally; andb) reveal the idiosyncrasies of each particular device combination via interactive prototypes. Our research provides actionable insight in this emerging area by defining a design space, suggesting a developer's framework and implementing prototypical applicationsin such areas as distributed information display, distributed control and various configurations of these. For each of these, we present several example techniques and demonstrate an application that combinessuch techniques.
C1  - Bangalore, India
C3  - Proceedings of the 11th asia pacific conference on computer human interaction
DA  - 2013///
PY  - 2013
DO  - 10.1145/2525194.2525205
SP  - 63
EP  - 72
PB  - Association for Computing Machinery
SN  - 978-1-4503-2253-9
UR  - https://doi.org/10.1145/2525194.2525205
KW  - human factors
KW  - design
KW  - context-aware computing
KW  - mobile
KW  - device
KW  - content
KW  - PDA
KW  - screen
KW  - smartphone
KW  - tablet
ER  - 

TY  - BOOK
TI  - SA '14: SIGGRAPH asia 2014 autonomous virtual humans and social robot for telepresence
CY  - New York, NY, USA
DA  - 2014///
PY  - 2014
PB  - Association for Computing Machinery
SN  - 978-1-4503-3243-9
ER  - 

TY  - BOOK
TI  - UIST '23: Proceedings of the 36th annual ACM symposium on user interface software and technology
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0132-0
ER  - 

TY  - CONF
TI  - Towards a multisensory augmented reality map for blind and low vision people: a participatory design approach
AU  - Albouys-Perrois, Jérémy
AU  - Laviole, Jérémy
AU  - Briant, Carine
AU  - Brock, Anke M.
T3  - Chi '18
AB  - Current low-tech Orientation &amp; Mobility (O&amp;M) tools for visually impaired people, e.g. tactile maps, possess limitations. Interactive accessible maps have been developed to overcome these. However, most of them are limited to exploration of existing maps, and have remained in laboratories. Using a participatory design approach, we have worked closely with 15 visually impaired students and 3 O&amp;M instructors over 6 months. We iteratively designed and developed an augmented reality map destined at use in O&amp;M classes in special education centers. This prototype combines projection, audio output and use of tactile tokens, and thus allows both map exploration and construction by low vision and blind people. Our user study demonstrated that all students were able to successfully use the prototype, and showed a high user satisfaction. A second phase with 22 international special education teachers allowed us to gain more qualitative insights. This work shows that augmented reality has potential for improving the access to education for visually impaired people.
C1  - Montreal QC, Canada
C3  - Proceedings of the 2018 CHI conference on human factors in computing systems
DA  - 2018///
PY  - 2018
DO  - 10.1145/3173574.3174203
SP  - 1
EP  - 14
PB  - Association for Computing Machinery
SN  - 978-1-4503-5620-6
UR  - https://doi.org/10.1145/3173574.3174203
KW  - augmented reality
KW  - accessibility
KW  - visual impairment
KW  - geographic maps
KW  - participatory design
ER  - 

TY  - CONF
TI  - Changing the appearance of real-world objects by modifying their surroundings
AU  - Lindlbauer, David
AU  - Mueller, Jörg
AU  - Alexa, Marc
T3  - Chi '17
AB  - We present an approach to alter the perceived appearance of physical objects by controlling their surrounding space. Many real-world objects cannot easily be equipped with displays or actuators in order to change their shape. While common approaches such as projection mapping enable changing the appearance of objects without modifying them, certain surface properties (e.g. highly reflective or transparent surfaces) can make employing these techniques difficult. In this work, we present a conceptual design exploration on how the appearance of an object can be changed by solely altering the space around it, rather than the object itself. In a proof-of-concept implementation, we place objects onto a tabletop display and track them together with users to display perspective-corrected 3D graphics for augmentation. This enables controlling properties such as the perceived size, color, or shape of objects. We characterize the design space of our approach and demonstrate potential applications. For example, we change the contour of a wallet to notify users when their bank account is debited. We envision our approach to gain in importance with increasing ubiquity of display surfaces.
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI conference on human factors in computing systems
DA  - 2017///
PY  - 2017
DO  - 10.1145/3025453.3025795
SP  - 3954
EP  - 3965
PB  - Association for Computing Machinery
SN  - 978-1-4503-4655-9
UR  - https://doi.org/10.1145/3025453.3025795
KW  - augmented reality
KW  - dynamic appearance
ER  - 

TY  - CONF
TI  - Vision-based technique and issues for multimodal interaction in augmented reality
AU  - Ismail, Ajune Wanis
AU  - Billinghurst, Mark
AU  - Sunar, Mohd Shahrizal
T3  - Vinci '15
AB  - Although many progresses have been accomplished in multimodal interaction, most researchers still treat each modality such as vision and speech, separately. They integrate the results at the application stage. This is because the roles of multiple modalities and their interactions continue to be quantified and precisely understood. However, there are many remaining issues in combining each modality individually. This paper will highlight the main vision problems based on our review for multimodal applications. This review paper will give an overview of the Augmented Reality (AR) technologies which are contributing in most of recent multimodal applications. We cluster vision techniques according to the natural human senses such as face, gesture, and speech that are frequently used in multimodal applications. The main contribution of this paper is to consolidate some of the main issues and approaches in vision-based technique, and to study some of the applications in AR that have been developed within the context of multimodal interaction. We conclude this paper with the future directions.
C1  - Tokyo, AA, Japan
C3  - Proceedings of the 8th international symposium on visual information communication and interaction
DA  - 2015///
PY  - 2015
DO  - 10.1145/2801040.2801058
SP  - 75
EP  - 82
PB  - Association for Computing Machinery
SN  - 978-1-4503-3482-2
UR  - https://doi.org/10.1145/2801040.2801058
KW  - Augmented Reality
KW  - Multimodal Interaction
KW  - Vision Technique
ER  - 

TY  - JOUR
TI  - "Talking without a voice": Understanding non-verbal communication in social virtual reality
AU  - Maloney, Divine
AU  - Freeman, Guo
AU  - Wohn, Donghee Yvette
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Exploring communication dynamics in digital social spaces such as massively multiplayer online games and 2D/3D virtual worlds has been a long standing concern in HCI and CSCW. As online social spaces evolve towards more natural embodied interaction, it is important to explore how non-verbal communication can be supported in more nuanced ways in these spaces and introduce new social interaction consequences. In this paper we especially focus on understanding novel non-verbal communication in social virtual reality (VR). We report findings of two empirical studies. Study 1 collected observational data to explore the types of non-verbal interactions being used naturally in social VR. Study 2 was an interview study (N=30) that investigated people's perceptions of non-verbal communication in social VR as well as the resulting interaction outcomes. This study helps address the limitations in prior literature on non-verbal communication dynamics in online social spaces. Our findings on what makes non-verbal communication in social VR unique and socially desirable extend our current understandings of the role of non-verbal communication in social interaction. We also highlight potential design implications that aim at better supporting non-verbal communication in social VR.
DA  - 2020/10//
PY  - 2020
DO  - 10.1145/3415246
VL  - 4
IS  - CSCW2
UR  - https://doi.org/10.1145/3415246
KW  - social dynamics
KW  - social virtual reality
KW  - computer-mediated communication
KW  - non-verbal communication
KW  - online social spaces
KW  - social vr
ER  - 

TY  - JOUR
TI  - Immersive virtual exercise environment for people with lower body disabilities
AU  - Zhang, Shaojie
AU  - Banerjee, P. Pat
AU  - Luciano, Cristian
T2  - SIGACCESS Access. Comput.
AB  - This paper presents the development and evaluation of the use of virtual reality technology, together with appropriately adapted exercises through an augmented reality interface, to create Virtual Exercise Environments (VEEs). These environments allow persons with lower body disabilities to exercise and train just like what people do in real world. The major aim of this research is an architecture to create virtual exercise environments for people with lower body disabilities, which can make exercise more enjoyable and less repetitive. This paper presents our current research on this architecture to facilitate participation and adherence using a VEE as a prototype and common-off-the-shelf hardware components.
DA  - 2011/01//
PY  - 2011
DO  - 10.1145/1948954.1948964
IS  - 99
SP  - 55
EP  - 59
SN  - 1558-2337
UR  - https://doi.org/10.1145/1948954.1948964
ER  - 

TY  - CONF
TI  - RoCoS: room-based communication system and its aspect as development tool for 3D entertainment applications
AU  - Miyahara, Katsunori
AU  - Nakamura, Naoto
AU  - Okada, Yoshihiro
T3  - Ace '09
AB  - This paper proposes a new communication system called RoCoS (Room-based Communication System) that allows multiple users to communicate with each other through their virtual 3D spaces called rooms located on the Internet. This system consists of two main sub-systems, i.e., 3D Messenger and Edit Tool. 3D Messenger provides multiple users with their collaborative operable and communicable environment on the Internet. Edit Tool allows each user to create his/her own virtual 3D space, i.e., individual room, and to create any avatar represented as his/her own 3D character used in 3D Messenger. Each room provided by 3D Messenger is regarded as 3D version of a web page because each room exists separately on its dedicated computer managed by its owner (Administrator) and the owner can edit, decorate and modify his/her room as he/she wants using Edit tool. This paper describes details and clarifies the usefulness of the system by showing its several functionalities and application examples.
C1  - Athens, Greece
C3  - Proceedings of the international conference on advances in computer entertainment technology
DA  - 2009///
PY  - 2009
DO  - 10.1145/1690388.1690390
SP  - 3
EP  - 10
PB  - Association for Computing Machinery
SN  - 978-1-60558-864-3
UR  - https://doi.org/10.1145/1690388.1690390
KW  - virtual reality
KW  - collaborative environment
KW  - distributed virtual space
KW  - human interface
KW  - peer-to-peer
KW  - software component
ER  - 

TY  - CONF
TI  - How will VR enter university classrooms? Multi-stakeholders investigation of VR in higher education
AU  - Jin, Qiao
AU  - Liu, Yu
AU  - Yarosh, Svetlana
AU  - Han, Bo
AU  - Qian, Feng
T3  - Chi '22
AB  - VR has received increased attention as an educational tool and many argue it is destined to influence educational practices, especially with the emergence of the Metaverse. Most prior research on educational VR reports on applications or systems designed for specified educational or training objectives. However, it is also crucial to understand current practices and attitudes across disciplines, having a holistic view to extend the body of knowledge in terms of VR adoption in an authentic setting. Taking a higher-level perception of people in different roles, we conducted a qualitative analysis based on 23 interviews with major stakeholders and a series of participatory design workshops with instructors and students. We identified the stakeholders who need to be considered for using VR in higher education, and highlighted the challenges and opportunities critical for VR current and potential practices in the university classroom. Finally, we discussed the design implications based on our findings. This study contributes a detailed description of current perceptions and considerations from a multi-stakeholder perspective, providing new empirical insights for designing novel VR and HCI technologies in higher education.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI conference on human factors in computing systems
DA  - 2022///
PY  - 2022
DO  - 10.1145/3491102.3517542
PB  - Association for Computing Machinery
SN  - 978-1-4503-9157-3
UR  - https://doi.org/10.1145/3491102.3517542
KW  - Virtual Reality
KW  - social VR
KW  - collaboration
KW  - educational VR
KW  - higher education
KW  - multi-stakeholder
ER  - 

TY  - CONF
TI  - Remote active tangible interactions
AU  - Richter, Jan
AU  - Thomas, Bruce H.
AU  - Sugimoto, Maki
AU  - Inami, Masahiko
T3  - Tei '07
AB  - This paper presents a new form of remote active tangible interactions built with the Display-based Measurement and Control System. A prototype system was constructed to demonstrate the concepts of coupled remote tangible objects on rear projected tabletop displays. A user evaluation measuring social presence for two users performing a furniture placement task was performed, to determine a difference between this new system and a traditional mouse.
C1  - Baton Rouge, Louisiana
C3  - Proceedings of the 1st international conference on tangible and embedded interaction
DA  - 2007///
PY  - 2007
DO  - 10.1145/1226969.1226977
SP  - 39
EP  - 42
PB  - Association for Computing Machinery
SN  - 978-1-59593-619-6
UR  - https://doi.org/10.1145/1226969.1226977
KW  - evaluation
KW  - tangible user interfaces
KW  - remote interfaces
ER  - 

TY  - JOUR
TI  - BotMap: Non-visual panning and zooming with an actuated tabletop tangible interface
AU  - Ducasse, Julie
AU  - Macé, Marc
AU  - Oriola, Bernard
AU  - Jouffrais, Christophe
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - The development of novel shape-changing or actuated tabletop tangible interfaces opens new perspectives for the design of physical and dynamic maps, especially for visually impaired (VI) users. Such maps would allow non-visual haptic exploration with advanced functions, such as panning and zooming. In this study, we designed an actuated tangible tabletop interface, called BotMap, allowing the exploration of geographic data through non-visual panning and zooming. In BotMap, small robots represent landmarks and move to their correct position whenever the map is refreshed. Users can interact with the robots to retrieve the names of the landmarks they represent. We designed two interfaces, named Keyboard and Sliders, which enable users to pan and zoom. Two evaluations were conducted with, respectively, ten blindfolded and eight VI participants. Results show that both interfaces were usable, with a slight advantage for the Keyboard interface in terms of navigation performance and map comprehension, and that, even when many panning and zooming operations were required, VI participants were able to understand the maps. Most participants managed to accurately reconstruct maps after exploration. Finally, we observed three VI people using the system and performing a classical task consisting in finding the more appropriate itinerary for a journey.
DA  - 2018/09//
PY  - 2018
DO  - 10.1145/3204460
VL  - 25
IS  - 4
SN  - 1073-0516
UR  - https://doi.org/10.1145/3204460
KW  - tangible interaction
KW  - tangible user interface
KW  - actuated interface
KW  - interactive map
KW  - non-visual interaction
KW  - pan
KW  - tactile map
KW  - Visual impairment
KW  - zoom
ER  - 

TY  - BOOK
TI  - PETRA '23: Proceedings of the 16th international conference on pervasive technologies related to assistive environments
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0069-9
ER  - 

TY  - BOOK
TI  - MUM '24: Proceedings of the international conference on mobile and ubiquitous multimedia
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1283-8
ER  - 

TY  - BOOK
TI  - Web3D '22: Proceedings of the 27th international conference on 3D web technology
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9914-2
ER  - 

TY  - CONF
TI  - Madgets: actuating widgets on interactive tabletops
AU  - Weiss, Malte
AU  - Schwarz, Florian
AU  - Jakubowski, Simon
AU  - Borchers, Jan
T3  - Uist '10
AB  - We present a system for the actuation of tangible magnetic widgets (Madgets) on interactive tabletops. Our system combines electromagnetic actuation with fiber optic tracking to move and operate physical controls. The presented mechanism supports actuating complex tangibles that consist of multiple parts. A grid of optical fibers transmits marker positions past our actuation hardware to cameras below the table. We introduce a visual tracking algorithm that is able to detect objects and touches from the strongly sub-sampled video input of that grid. Six sample Madgets illustrate the capabilities of our approach, ranging from tangential movement and height actuation to inductive power transfer. Madgets combine the benefits of passive, untethered, and translucent tangibles with the ability to actuate them with multiple degrees of freedom.
C1  - New York, New York, USA
C3  - Proceedings of the 23nd annual ACM symposium on user interface software and technology
DA  - 2010///
PY  - 2010
DO  - 10.1145/1866029.1866075
SP  - 293
EP  - 302
PB  - Association for Computing Machinery
SN  - 978-1-4503-0271-5
UR  - https://doi.org/10.1145/1866029.1866075
KW  - multi-touch
KW  - tangible user interfaces
KW  - actuation
KW  - tabletop interaction
KW  - widgets
ER  - 

TY  - CONF
TI  - Ready, set, art: Technology needs and tools for remote K-2 art education
AU  - Mansi, Gennie
AU  - Kim, Sue Reon
AU  - Roberts, Jessica
T3  - Idc '22
AB  - Art education plays a central role in early childhood development, and museum outreach programs can significantly enhance art education experiences for K-2 learners in schools. Increased demand for remote learning environments where students and teachers are not co-located has forced educational contexts to adopt technology-mediated learning. However, little research has investigated how technology can integrate museum content into fully remote, K-2 school art education. We elicited design requirements for K-2 art education platforms in a needs assessment study through surveys (N = 22) and interviews (N = 4) with educators. We created a typology of existing platforms, which we evaluated against these requirements. We identified a key unmet need for students to receive feedback on their fine motor skills, and, in response, we created a prototype system with interactive scissors called Chameleon Clippers. We demonstrate its potential to provide this feedback through preliminary user tests with 4–7-year-old children (N=12).
C1  - Braga, Portugal
C3  - Proceedings of the 21st annual ACM interaction design and children conference
DA  - 2022///
PY  - 2022
DO  - 10.1145/3501712.3529731
SP  - 150
EP  - 184
PB  - Association for Computing Machinery
SN  - 978-1-4503-9197-9
UR  - https://doi.org/10.1145/3501712.3529731
KW  - Art Education
KW  - Distance learning
KW  - K-2
ER  - 

TY  - CONF
TI  - AVUI: Designing a toolkit for audiovisual interfaces
AU  - Correia, Nuno N.
AU  - Tanaka, Atau
T3  - Chi '17
AB  - The combined use of sound and image has a rich history, from audiovisual artworks to research exploring the potential of data visualization and sonification. However, we lack standard tools or guidelines for audiovisual (AV) interaction design, particularly for live performance. We propose the AVUI (AudioVisual User Interface), where sound and image are used together in a cohesive way in the interface; and an enabling technology, the ofxAVUI toolkit. AVUI guidelines and ofxAVUI were developed in a three-stage process, together with AV producers: 1) participatory design activities; 2) prototype development; 3) encapsulation of prototype as a plug-in, evaluation, and roll out. Best practices identified include: reconfigurable interfaces and mappings; object-oriented packaging of AV and UI; diverse sound visualization; flexible media manipulation and management. The toolkit and a mobile app developed using it have been released as open-source. Guidelines and toolkit demonstrate the potential of AVUI and offer designers a convenient framework for AV interaction design.
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI conference on human factors in computing systems
DA  - 2017///
PY  - 2017
DO  - 10.1145/3025453.3026042
SP  - 1093
EP  - 1104
PB  - Association for Computing Machinery
SN  - 978-1-4503-4655-9
UR  - https://doi.org/10.1145/3025453.3026042
KW  - interaction design
KW  - user interface
KW  - audiovisual
KW  - prototyping
KW  - toolkit
KW  - participatory design
KW  - crossmodal interaction
KW  - hackathons
KW  - interface builder
ER  - 

TY  - CONF
TI  - Accuracy of interpreting pointing gestures in egocentric view
AU  - Akkil, Deepak
AU  - Isokoski, Poika
T3  - UbiComp '16
AB  - Communicating spatial information by pointing is ubiquitous in human interactions. With the growing use of head-mounted cameras for collaborative purposes, it is important to assess how accurately viewers of the resulting egocentric videos can interpret pointing acts. We conducted an experiment to compare the accuracy of interpreting four different pointing techniques: hand pointing, head pointing, gaze pointing and hand+gaze pointing. Our results suggest that superimposing the gaze information on the egocentric video can enable viewers to determine pointing targets more accurately and more confidently. Hand pointing performed best when the pointing target was straight ahead and head pointing was the least preferred in terms of ease of interpretation. Our results can inform the design of collaborative applications that make use of the egocentric view.
C1  - Heidelberg, Germany
C3  - Proceedings of the 2016 ACM international joint conference on pervasive and ubiquitous computing
DA  - 2016///
PY  - 2016
DO  - 10.1145/2971648.2971687
SP  - 262
EP  - 273
PB  - Association for Computing Machinery
SN  - 978-1-4503-4461-6
UR  - https://doi.org/10.1145/2971648.2971687
KW  - pointing
KW  - collaboration
KW  - accuracy of spatial referencing
KW  - egocentric video
KW  - gaze augmentation
ER  - 

TY  - BOOK
TI  - MUM '22: Proceedings of the 21st international conference on mobile and ubiquitous multimedia
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9820-6
ER  - 

TY  - CONF
TI  - SmurVEbox: a smart multi-user real-time virtual environment for generating character animations
AU  - Beimler, Rüdiger
AU  - Bruder, Gerd
AU  - Steinicke, Frank
T3  - Vric '13
AB  - Animating virtual characters is a complex task, which requires professional animators and performers, expensive motion capture systems, or considerable amounts of time to generate convincing results. In this paper we introduce the SmurVEbox, which is a cost-effective animating system that encompasses many important aspects of animating virtual characters by providing a novel shared user experience. SmurVEbox is a collaborative environment for generating character animations in real time, which has the potential to enhance the computer animation process. Our setup allows animators and performers to cooperate on the same virtual animation sequence in real time. Performers are able to communicate with the animator in the real space while simultaneously perceiving the effects of their actions on the virtual character in the virtual space. The animator can refine actions of a performer in real time so that both collaborate together on the same animation of a virtual character. We describe the setup and present a simple application.
C1  - Laval, France
C3  - Proceedings of the virtual reality international conference: Laval virtual
DA  - 2013///
PY  - 2013
DO  - 10.1145/2466816.2466818
PB  - Association for Computing Machinery
SN  - 978-1-4503-1875-4
UR  - https://doi.org/10.1145/2466816.2466818
KW  - virtual reality
KW  - computer animation
KW  - motion capture
KW  - computer graphics
KW  - multi-touch
KW  - collaborative environment
KW  - character animation
KW  - real-time
ER  - 

TY  - BOOK
TI  - SIGGRAPH '18: ACM SIGGRAPH 2018 emerging technologies
AB  - Changing the Human ExperienceSIGGRAPH 2018 showcases emerging technologies that are exponentially expanding our human experience. The internet of things, the quantitative self, and immersive technologies have matured, and the new data systems that support these innovations make way for more invention and interconnectedness.A variety of new research at SIGGRAPH 2018 will be showcased, including work focused on personal vicissitude; new products and systems to surround us in comfort and function; and new technologies designed to change the way we will approach sports, games and active watching.
CY  - New York, NY, USA
DA  - 2018///
PY  - 2018
PB  - Association for Computing Machinery
SN  - 978-1-4503-5810-1
ER  - 

TY  - JOUR
TI  - Congestion control for network-aware telehaptic communication
AU  - Gokhale, Vineet
AU  - Nair, Jayakrishnan
AU  - Chaudhuri, Subhasis
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
AB  - Telehaptic applications involve delay-sensitive multimedia communication between remote locations with distinct Quality of Service (QoS) requirements for different media components. These QoS constraints pose a variety of challenges, especially when the communication occurs over a shared network, with unknown and time-varying cross-traffic. In this work, we propose a transport layer congestion control protocol for telehaptic applications operating over shared networks, termed as Dynamic Packetization Module (DPM). DPM is a lossless, network-aware protocol that tunes the telehaptic packetization rate based on the level of congestion in the network. To monitor the network congestion, we devise a novel network feedback module, which communicates the end-to-end delays encountered by the telehaptic packets to the respective transmitters with negligible overhead. Via extensive simulations, we show that DPM meets the QoS requirements of telehaptic applications over a wide range of network cross-traffic conditions. We also report qualitative results of a real-time telepottery experiment with several human subjects, which reveal that DPM preserves the quality of telehaptic activity even under heavily congested network scenarios. Finally, we compare the performance of DPM with several previously proposed telehaptic communication protocols and demonstrate that DPM outperforms these protocols.
DA  - 2017/03//
PY  - 2017
DO  - 10.1145/3052821
VL  - 13
IS  - 2
SN  - 1551-6857
UR  - https://doi.org/10.1145/3052821
KW  - multimedia
KW  - congestion control
KW  - dynamic rate adaptation
KW  - QoS
KW  - Telehaptic communication
KW  - transport layer
ER  - 

TY  - CONF
TI  - Exploitation of heuristics for virtual environments
AU  - Hvannberg, Ebba Thora
AU  - Halldórsdóttir, Gyda
AU  - Rudinsky, Jan
T3  - NordiCHI '12
AB  - Although generic usability heuristics lists have been popular with researchers and practitioners, emerging new technologies have called for more specific heuristics. One of these heuristics was proposed by Sutcliffe and Gault in 2004 [37]. This paper examines research which has cited these heuristics with the aim to see how it has been exploited. The results showed that a fifth of the papers citing the heuristics have used the heuristics fully or partly, and that researchers have adapted it to their current needs. Following this result we proposed that a patchwork of heuristics might be more useful than a single list. We evaluated a crisis management training simulator using the virtual reality heuristics and discussed how the outcome of the evaluation fitted the patchwork.
C1  - Copenhagen, Denmark
C3  - Proceedings of the 7th nordic conference on human-computer interaction: Making sense through design
DA  - 2012///
PY  - 2012
DO  - 10.1145/2399016.2399065
SP  - 308
EP  - 317
PB  - Association for Computing Machinery
SN  - 978-1-4503-1482-4
UR  - https://doi.org/10.1145/2399016.2399065
KW  - virtual reality
KW  - crisis management training
KW  - heuristics evaluation
ER  - 

TY  - CONF
TI  - Feeling alone in public: investigating the influence of spatial layout on users' VR experience
AU  - Mai, Christian
AU  - Wiltzius, Tim
AU  - Alt, Florian
AU  - Hußmann, Heinrich
T3  - NordiCHI '18
AB  - We investigate how spatial layout in public environments like workplaces, fairs, or conferences influences a user's VR experience. In particular, we compare environments in which an HMD user is (a) surrounded by other people, (b) physically separated by a barrier, or (c) in a separate room. In contrast to lab environments, users in public environments are affected by physical threats (for example, other people in the space running into them) but also cognitive threats (for example, not knowing, what happens in the real world), as known from research on proxemics or social facilitation. We contribute an extensive discussion of the factors influencing a user's VR experience in public. Based on this we conducted a between-subject design user study (N=58) to understand the differences between the three environments. As a result, we present implications regarding (1) spatial layout, (2) behavior of the VR system operator, and (3) the VR experience that helps both HCI researchers as well as practitioners to enhance users' VR experience in public environments.
C1  - Oslo, Norway
C3  - Proceedings of the 10th nordic conference on human-computer interaction
DA  - 2018///
PY  - 2018
DO  - 10.1145/3240167.3240200
SP  - 286
EP  - 298
PB  - Association for Computing Machinery
SN  - 978-1-4503-6437-9
UR  - https://doi.org/10.1145/3240167.3240200
KW  - virtual reality
KW  - head-mounted displays
KW  - user experience
KW  - public spaces
ER  - 

TY  - CONF
TI  - Minimising latency and maintaining consistency in distributed virtual prototyping
AU  - Marsh, J.
AU  - Glencross, M.
AU  - Pettifer, S.
AU  - Hubbold, R. J.
AU  - Cook, J.
AU  - Daubrenet, S.
T3  - Vrcai '04
AB  - This paper describes a computer aided design tool for mechanical engineering applications, combining component assembly simulation, the modelling of rigid and flexible bodies and haptic interaction in a multi-user distributed virtual environment. It presents the research challenges encountered, and an architecture designed to address these.
C1  - Singapore
C3  - Proceedings of the 2004 ACM SIGGRAPH international conference on virtual reality continuum and its applications in industry
DA  - 2004///
PY  - 2004
DO  - 10.1145/1044588.1044672
SP  - 386
EP  - 389
PB  - Association for Computing Machinery
SN  - 1-58113-884-9
UR  - https://doi.org/10.1145/1044588.1044672
ER  - 

TY  - BOOK
TI  - UIST '22 adjunct: Adjunct proceedings of the 35th annual ACM symposium on user interface software and technology
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9321-8
ER  - 

TY  - CONF
TI  - HCI as an inter-discipline
AU  - Blackwell, Alan F.
T3  - Chi ea '15
AB  - This paper responds to a 2014 paper by Liu et al seeking a quantifiable thematic core to CHI. As an alternative, I argue that CHI should strategically avoid the search for such a core, instead seeking its identity as a mode of responding and contributing to other disciplines.
C1  - Seoul, Republic of Korea
C3  - Proceedings of the 33rd annual ACM conference extended abstracts on human factors in computing systems
DA  - 2015///
PY  - 2015
DO  - 10.1145/2702613.2732505
SP  - 503
EP  - 516
PB  - Association for Computing Machinery
SN  - 978-1-4503-3146-3
UR  - https://doi.org/10.1145/2702613.2732505
KW  - collaboration
KW  - innovation
KW  - interdisciplinarity
ER  - 

TY  - CONF
TI  - Human-centered computing: a multimedia perspective
AU  - Jaimes, Alejandro
AU  - Sebe, Nicu
AU  - Gatica-Perez, Daniel
T3  - Mm '06
AB  - Human-Centered Computing (HCC) is a set of methodologies that apply to any field that uses computers, in any form, in applications in which humans directly interact with devices or systems that use computer technologies. In this paper, we give an overview of HCC from a Multimedia perspective. We describe what we consider to be the three main areas of Human-Centered Multimedia (HCM): media production, analysis, and interaction. In addition, we identify the core characteristics of HCM, describe example applications, and propose a research agenda for HCM.
C1  - Santa Barbara, CA, USA
C3  - Proceedings of the 14th ACM international conference on multimedia
DA  - 2006///
PY  - 2006
DO  - 10.1145/1180639.1180829
SP  - 855
EP  - 864
PB  - Association for Computing Machinery
SN  - 1-59593-447-2
UR  - https://doi.org/10.1145/1180639.1180829
KW  - human-centered computing
KW  - multimedia
KW  - multimodal
ER  - 

TY  - CONF
TI  - Towards quantifying player's involvement in 3D games based-on player types
AU  - Hanna, Nader
AU  - Richards, Deborah
AU  - Hitchens, Michael
AU  - Jacobson, Michael J.
T3  - IE2014
AB  - With the varied use of games, the need to measure player's involvement has become prominent. Several studies aimed to quantify users' involvement. However, none of these studies presented a robust framework to measure the player's involvement in games nor considered player types as a factor. In this paper, a framework to quantify automatically the players' involvement in games is presented. This framework consists of three levels and each level includes criteria to evaluate three aspects of 3D games: (1) application level, (2) usage level, and (3) content level. Additionally, the framework's criteria considers player types proposed by Bartle. To validate the results of the framework, player involvement was estimated manually on a case-by-case basis by three experienced evaluators. The manual estimation was then compared with the automatically generated-quantified result produced by the framework. The comparison revealed a significant match.
C1  - Newcastle, NSW, Australia
C3  - Proceedings of the 2014 conference on interactive entertainment
DA  - 2014///
PY  - 2014
DO  - 10.1145/2677758.2677763
SP  - 1
EP  - 10
PB  - Association for Computing Machinery
SN  - 978-1-4503-2790-9
UR  - https://doi.org/10.1145/2677758.2677763
KW  - Framework
KW  - Game
KW  - Objective Measurement
KW  - Player Types
KW  - Player's Involvement
KW  - Quantification
ER  - 

TY  - CONF
TI  - Curve: revisiting the digital desk
AU  - Wimmer, Raphael
AU  - Hennecke, Fabian
AU  - Schulz, Florian
AU  - Boring, Sebastian
AU  - Butz, Andreas
AU  - Hußmann, Heinrich
T3  - NordiCHI '10
AB  - Current desktop workspace environments consist of a vertical area (e.g., a screen with a virtual desktop) and a horizontal area (e.g., the physical desk). Daily working activities benefit from different intrinsic properties of both of these areas. However, both areas are distinct from each other, making data exchange between them cumbersome. Therefore, we present Curve, a novel interactive desktop environment, which combines advantages of vertical and horizontal working areas using a continous curved connection. This connection offers new ways of direct multi-touch interaction and new ways of information visualization. We describe our basic design, the ergonomic adaptions we made, and discuss technical challenges we met and expect to meet while building and configuring the system.
C1  - Reykjavik, Iceland
C3  - Proceedings of the 6th nordic conference on human-computer interaction: Extending boundaries
DA  - 2010///
PY  - 2010
DO  - 10.1145/1868914.1868977
SP  - 561
EP  - 570
PB  - Association for Computing Machinery
SN  - 978-1-60558-934-3
UR  - https://doi.org/10.1145/1868914.1868977
KW  - ergonomics
KW  - curve
KW  - digital desks
KW  - direct-touch
KW  - interactive surfaces
KW  - tabletop interfaces
KW  - workplace
ER  - 

TY  - CONF
TI  - Synthetic space: inhabiting binaries
AU  - Takeuchi, Yuichiro
T3  - Chi ea '12
AB  - In this paper we propose the concept of Synthetic Space - architectural space fused with the properties of digital bits. Past efforts at integrating digital technology into architectural space have generally assumed architecture to be a stable, invariant background onto which layers of digital information/devices/services can be overlaid. In Synthetic Space, however, this stability is instead superseded by the capricious plasticity of digital data. For future inhabitants of Synthetic Space, transforming the makeup of the surrounding built environment will be a trivial, effortless task, equivalent to changing the wallpaper image on a modern-day PC or smartphone.
C1  - Austin, Texas, USA
C3  - CHI '12 extended abstracts on human factors in computing systems
DA  - 2012///
PY  - 2012
DO  - 10.1145/2212776.2212803
SP  - 251
EP  - 260
PB  - Association for Computing Machinery
SN  - 978-1-4503-1016-1
UR  - https://doi.org/10.1145/2212776.2212803
KW  - digitizing architecture
KW  - habitable bits
KW  - synthetic space
ER  - 

TY  - JOUR
TI  - Evaluating a scientific collaboratory: Results of a controlled experiment
AU  - Sonnenwald, Diane H.
AU  - Whitton, Mary C.
AU  - Maglaughlin, Kelly L.
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - The evaluation of scientific collaboratories has lagged behind their development. Do the capabilities afforded by collaboratories outweigh their disadvantages? To evaluate a scientific collaboratory system, we conducted a repeated-measures controlled experiment that compared the outcomes and process of scientific work completed by 20 pairs of participants (upper level undergraduate science students) working face-to-face and remotely. We collected scientific outcomes (graded lab reports) to investigate the quality of scientific work, post-questionnaire data to measure the adoptability of the system, and post-interviews to understand the participants' views of doing science under both conditions. We hypothesized that study participants would be less effective, report more difficulty, and be less favorably inclined to adopt the system when collaborating remotely. Contrary to expectations, the quantitative data showed no statistically significant differences with respect to effectiveness and adoption.The qualitative data helped explain this null result: participants reported advantages and disadvantages working under both conditions and developed work-arounds to cope with the perceived disadvantages of collaborating remotely. While the data analysis produced null results, considered as a whole, the analysis leads us to conclude there is positive potential for the development and adoption of scientific collaboratory systems.
DA  - 2003/06//
PY  - 2003
DO  - 10.1145/772047.772051
VL  - 10
IS  - 2
SP  - 150
EP  - 176
SN  - 1073-0516
UR  - https://doi.org/10.1145/772047.772051
KW  - collaboration
KW  - controlled experiment
KW  - geographically-distributed work
KW  - nanoscience
KW  - Scientific collaboratory
ER  - 

TY  - CONF
TI  - ACTO: a modular actuated tangible user interface object
AU  - Vonach, Emanuel
AU  - Gerstweiler, Georg
AU  - Kaufmann, Hannes
T3  - Its '14
AB  - We introduce a customizable, reusable actuated tangible user interface object: ACTO. Its modular design allows quick adaptations for different scenarios and setups on tabletops, making otherwise integral parts like the actuation mechanism or the physical configuration interchangeable. Drawing on the resources of well-established maker communities makes prototyping especially quick and easy. This allows the exploration of new concepts without the need to redesign the whole system, which qualifies it as an ideal research and education platform for tangible user interfaces. We present a detailed description of the hardware and software architecture of our system. Several implemented example configurations and application scenarios demonstrate the capabilities of the platform.
C1  - Dresden, Germany
C3  - Proceedings of the ninth ACM international conference on interactive tabletops and surfaces
DA  - 2014///
PY  - 2014
DO  - 10.1145/2669485.2669522
SP  - 259
EP  - 268
PB  - Association for Computing Machinery
SN  - 978-1-4503-2587-5
UR  - https://doi.org/10.1145/2669485.2669522
KW  - haptics
KW  - tangible user interfaces
KW  - actuation
KW  - tabletop interaction
KW  - widgets
KW  - physical control
KW  - prototyping platform
ER  - 

TY  - CONF
TI  - A multimedia workflow-based collaborative engineering environment for oil &amp; gas industry
AU  - Santos, Ismael H. F.
AU  - Göbel, Martin
AU  - Raposo, Alberto B.
AU  - Gattass, Marcelo
T3  - Vrcai '04
AB  - In this paper we discuss the scenario of Petroleum Engineering projects of Petrobras, a large Brazilian governmental oil &amp; gas company. Based on this scenario, we propose a set of application requirements and system architecture to guide the construction of a Collaborative Engineering Environment (CEE) for assisting the control and execution of large and complex industrial projects in oil and gas industry. The environment is composed by the integration of three different technologies of distributed group work: Workflow Management System (WfMS), Multimedia Collaborative System (MMCS) and Collaborative Virtual Environments (CVE).
C1  - Singapore
C3  - Proceedings of the 2004 ACM SIGGRAPH international conference on virtual reality continuum and its applications in industry
DA  - 2004///
PY  - 2004
DO  - 10.1145/1044588.1044609
SP  - 112
EP  - 119
PB  - Association for Computing Machinery
SN  - 1-58113-884-9
UR  - https://doi.org/10.1145/1044588.1044609
KW  - collaborative virtual environments
KW  - collaborative engineering
KW  - workflow systems
ER  - 

TY  - CONF
TI  - Zooids: Building blocks for swarm user interfaces
AU  - Le Goc, Mathieu
AU  - Kim, Lawrence H.
AU  - Parsaei, Ali
AU  - Fekete, Jean-Daniel
AU  - Dragicevic, Pierre
AU  - Follmer, Sean
T3  - Uist '16
AB  - This paper introduces swarm user interfaces, a new class of human-computer interfaces comprised of many autonomous robots that handle both display and interaction. We describe the design of Zooids, an open-source open-hardware platform for developing tabletop swarm interfaces. The platform consists of a collection of custom-designed wheeled micro robots each 2.6 cm in diameter, a radio base-station, a high-speed DLP structured light projector for optical tracking, and a software framework for application development and control. We illustrate the potential of tabletop swarm user interfaces through a set of application scenarios developed with Zooids, and discuss general design considerations unique to swarm user interfaces.
C1  - Tokyo, Japan
C3  - Proceedings of the 29th annual symposium on user interface software and technology
DA  - 2016///
PY  - 2016
DO  - 10.1145/2984511.2984547
SP  - 97
EP  - 109
PB  - Association for Computing Machinery
SN  - 978-1-4503-4189-9
UR  - https://doi.org/10.1145/2984511.2984547
KW  - swarm user interfaces
KW  - tangible user interfaces
ER  - 

TY  - CONF
TI  - WeBuild: Automatically distributing assembly tasks among collocated workers to improve coordination
AU  - Fraser, C. Ailie
AU  - Grossman, Tovi
AU  - Fitzmaurice, George
T3  - Chi '17
AB  - Physical construction and assembly tasks are often carried out by groups of collocated workers, and they can be difficult to coordinate. Group members must spend time deciding how to split up the task, how to assign subtasks to each other, and in what order subtasks should be completed. Informed by an observational study examining group coordination challenges, we built a task distribution system called WeBuild. Our custom algorithm dynamically assigns subtasks to workers in a group, taking into account factors such as the dependencies between subtasks and the skills of each group member. Each worker views personalized step-by-step instructions on a mobile phone, while a dashboard visualizes the entire process. An initial study found that WeBuild reduced the start-up time needed to coordinate and begin a task, and provides direction for future research to build on toward improving group efficiency and coordination for complex tasks.
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI conference on human factors in computing systems
DA  - 2017///
PY  - 2017
DO  - 10.1145/3025453.3026036
SP  - 1817
EP  - 1830
PB  - Association for Computing Machinery
SN  - 978-1-4503-4655-9
UR  - https://doi.org/10.1145/3025453.3026036
KW  - collaboration
KW  - assembly instructions
KW  - coordination
KW  - task distribution
ER  - 

TY  - CONF
TI  - IllumiPaper: Illuminated interactive paper
AU  - Klamka, Konstantin
AU  - Dachselt, Raimund
T3  - Chi '17
AB  - Due to their simplicity and flexibility, digital pen-and-paper solutions have a promising potential to become a part of our daily work. Unfortunately, they lack dynamic visual feedback and thereby restrain advanced digital functionalities. In this paper, we investigate new forms of paper-integrated feedback, which build on emerging paper-based electronics and novel thin-film display technologies. Our approach focuses on illuminated elements, which are seamlessly integrated into standard paper. For that, we introduce an extended design space for paper-integrated illuminations. As a major contribution, we present a systematic feedback repertoire for real-world applications including feedback components for innovative paper interaction tasks in five categories. Furthermore, we contribute a fully-functional research platform including a paper-controller, digital pen and illuminated, digitally controlled papers that demonstrate the feasibility of our techniques. Finally, we report on six interviews, where experts rated our approach as intuitive and very usable for various applications, in particular educational ones.
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI conference on human factors in computing systems
DA  - 2017///
PY  - 2017
DO  - 10.1145/3025453.3025525
SP  - 5605
EP  - 5618
PB  - Association for Computing Machinery
SN  - 978-1-4503-4655-9
UR  - https://doi.org/10.1145/3025453.3025525
KW  - visual feedback
KW  - anoto
KW  - augmented paper
KW  - digital pen and paper
KW  - electro-luminescence
KW  - pen interaction
KW  - thin-film display
ER  - 

TY  - CONF
TI  - Supporting interoperability and presence awareness in collaborative mixed reality environments
AU  - Oyekoya, Oyewole
AU  - Stone, Ran
AU  - Steptoe, William
AU  - Alkurdi, Laith
AU  - Klare, Stefan
AU  - Peer, Angelika
AU  - Weyrich, Tim
AU  - Cohen, Benjamin
AU  - Tecchia, Franco
AU  - Steed, Anthony
T3  - Vrst '13
AB  - In the BEAMING project we have been extending the scope of collaborative mixed reality to include the representation of users in multiple modalities, including augmented reality, situated displays and robots. A single user (a visitor) uses a high-end virtual reality system (the transporter) to be virtually teleported to a real remote location (the destination). The visitor may be tracked in several ways including emotion and motion capture. We reconstruct the destination and the people within it (the locals). In achieving this scenario, BEAMING has integrated many heterogeneous systems. In this paper, we describe the design and key implementation choices in the Beaming Scene Service (BSS), which allows the various processes to coordinate their behaviour. The core of the system is a light-weight shared object repository that allows loose coupling between processes with very different requirements (e.g. embedded control systems through to mobile apps). The system was also extended to support the notion of presence awareness. We demonstrate two complex applications built with the BSS.
C1  - Singapore
C3  - Proceedings of the 19th ACM symposium on virtual reality software and technology
DA  - 2013///
PY  - 2013
DO  - 10.1145/2503713.2503732
SP  - 165
EP  - 174
PB  - Association for Computing Machinery
SN  - 978-1-4503-2379-6
UR  - https://doi.org/10.1145/2503713.2503732
KW  - telepresence
KW  - virtual reality
KW  - presence
KW  - mixed reality
KW  - interoperability
KW  - telerobotics
ER  - 

TY  - CONF
TI  - Tangible bits: beyond pixels
AU  - Ishii, Hiroshi
T3  - Tei '08
AB  - Tangible user interfaces (TUIs) provide physical form to digital information and computation, facilitating the direct manipulation of bits. Our goal in TUI development is to empower collaboration, learning, and design by using digital technology and at the same time taking advantage of human abilities to grasp and manipulate physical objects and materials. This paper discusses a model of TUI, key properties, genres, applications, and summarizes the contributions made by the Tangible Media Group and other researchers since the publication of the first Tangible Bits paper at CHI 1997. http://tangible.media.mit.edu/
C1  - Bonn, Germany
C3  - Proceedings of the 2nd international conference on tangible and embedded interaction
DA  - 2008///
PY  - 2008
DO  - 10.1145/1347390.1347392
SP  - xv
EP  - xxv
PB  - Association for Computing Machinery
SN  - 978-1-60558-004-3
UR  - https://doi.org/10.1145/1347390.1347392
KW  - interaction design
KW  - augmented reality
KW  - ubiquitous computing
KW  - tangible user interfaces
KW  - ambient media
ER  - 

TY  - CONF
TI  - Overview of augmented reality
AU  - Azuma, Ronald
T3  - Siggraph '04
C1  - Los Angeles, CA
C3  - ACM SIGGRAPH 2004 course notes
DA  - 2004///
PY  - 2004
DO  - 10.1145/1103900.1103926
SP  - 26
EP  - es
PB  - Association for Computing Machinery
SN  - 978-1-4503-7801-7
UR  - https://doi.org/10.1145/1103900.1103926
ER  - 

TY  - BOOK
TI  - MMVE '23: Proceedings of the 15th international workshop on immersive mixed and virtual environment systems
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0189-4
ER  - 

TY  - CONF
TI  - RopePlus: bridging distances with social and kinesthetic rope games
AU  - Yao, Lining
AU  - Dasgupta, Sayamindu
AU  - Cheng, Nadia
AU  - Spingarn-Koff, Jason
AU  - Rudakevych, Ostap
AU  - Ishii, Hiroshi
T3  - Chi ea '11
AB  - Rope-based games such as jump rope, tug-of-war, and kite-flying promote physical activity and social interaction among people of all ages and especially in children during the development of their coordination skills and physical fitness. Our RopePlus system builds on those traditional games by enabling players to participate remotely through interacting with ropes that connect physical and virtual spaces. The RopePlus platform is centered around the rope as a tangible interface with various hardware extensions to allow for multiple playing modes. In this paper, we present two games that have been implemented in detail: a kite-flying game called Multi-Fly and a jump-rope game called Multi-Jump. Our work aims to expand tangible interface gaming to real time social playing environments.
C1  - Vancouver, BC, Canada
C3  - CHI '11 extended abstracts on human factors in computing systems
DA  - 2011///
PY  - 2011
DO  - 10.1145/1979742.1979611
SP  - 223
EP  - 232
PB  - Association for Computing Machinery
SN  - 978-1-4503-0268-5
UR  - https://doi.org/10.1145/1979742.1979611
KW  - tangible interface
KW  - exertion interface
KW  - athletic interaction
KW  - computer supported cooperative play
KW  - enhanced reality
KW  - kinesthetic interaction
KW  - remote playing
KW  - social game
ER  - 

TY  - JOUR
TI  - Mediated atmospheres: a multimodal mediated work environment
AU  - Zhao, Nan
AU  - Azaria, Asaph
AU  - Paradiso, Joseph A.
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
AB  - Atmosphere - the sensorial qualities of a space, shaped by the composition of light, sound, objects, people, etc. - has remarkable influence on our experiences and behavior. Manipulating it has been shown to be powerful, affecting cognitive performance, mood and even physiology, our work envisions and implements a smart office prototype, capable of digitally transforming its atmosphere - creating what we call Mediated Atmospheres (MA) - using computationally controlled lighting, video projection and sound. Additionally, we equipped this space with a modular real-time data collection infrastructure, integrating a set of biosignal sensors. Through a user study (N=29) we demonstrate MA's effects on occupants’ ability to focus and to recover from a stressful situation. Our evaluation is based on subjective measurements of perception, as well as objective measurements, extracted from recordings of heart rate variability and facial features. We compare multiple signal processing approaches for quantifying changes in occupant physiological state. Our findings show that MA significantly (p&lt;0.05) affect occupants’ perception as well as physiological response, which encouragingly correlate with occupants’ perception. Our findings is a first step towards personalized control of the ambient atmosphere to support wellbeing and productivity.
DA  - 2017/06//
PY  - 2017
DO  - 10.1145/3090096
VL  - 1
IS  - 2
UR  - https://doi.org/10.1145/3090096
KW  - Perception
KW  - Augmented Reality
KW  - Productivity
KW  - Multimodal
KW  - Adaptive Building
KW  - Face Tracking
KW  - Heart Rate Variability
KW  - Mediated Atmospheres
KW  - Restoration
KW  - Smart Office
KW  - Ubiquitous Computing
KW  - Wellbeing
ER  - 

TY  - CONF
TI  - Augmented collaborative spaces
AU  - Pingali, Gopal
AU  - Sukaviriya, Noi
T3  - Etp '03
AB  - As collaborative environments evolve beyond the desktop, we see the emergence of a new class of augmented collaborative spaces that employ various devices and technologies to merge electronic information with physical space to support collaboration, both local and remote. To be effective, such spaces should give people the flexibility to combine their individual resources with the resources available in the space, while presenting appropriate information, taking into account the larger process within which a collaborative activity takes place. This demands richer ways of capturing content and actions, new ways of presenting multimodal information, and developing an architecture and infrastructure that unifies individuals, spaces, and processes to facilitate collaboration. Our work in steerable interfaces represents a first step in this direction.
C1  - Berkeley, California
C3  - Proceedings of the 2003 ACM SIGMM workshop on experiential telepresence
DA  - 2003///
PY  - 2003
DO  - 10.1145/982484.982487
SP  - 13
EP  - 20
PB  - Association for Computing Machinery
SN  - 1-58113-775-3
UR  - https://doi.org/10.1145/982484.982487
KW  - ubiquitous computing
KW  - interaction
KW  - interfaces
KW  - meetings
KW  - action capture
KW  - business process modeling
KW  - conferencing
KW  - context modeling
KW  - pervasive systems
KW  - presentation systems
ER  - 

TY  - CONF
TI  - Future trends in oil and gas visualization
AU  - Evans, Francine
AU  - Volz, William
AU  - Dorn, Geoffrey
AU  - Fröhlich, Bernd
AU  - Roberts, David M
T3  - Vis '02
AB  - The question that this panel wishes to explore is: What are the future visualization trends and requirements for the oil and gas industry to efficiently handle and explore the ever-increasing volume and variety of available data?It has been proven many times that 3D visualization helps to reduce the risk in the search for, and development of, oil and gas resources and has been generally acknowledged to be an indispensable technology for the oil and gas industry. The role of the geoscientist is to combine his/her geological and geophysical expertise with the wide variety of data to find these natural resources and minimize the risk in the search for nature resources at the same time. The variety and size of the data makes the requirements unique in the visualization field: The data volumes that must be visualized range from a few megabytes to over 100 gigabytes. Multiple kinds of data and interpretation must be overlaid on the visualization. Multiple models of the subsurface are possible. Multiple specialized visualization software tools are available for the geoscientist to use.Combining the right visualization tools with the right data can reduce exploration risk and make the geoscientist a productive explorationist. This panel will explore the trends that are anticipated to meet the future needs of the Oil and Gas industry.
C1  - Boston, Massachusetts
C3  - Proceedings of the conference on visualization '02
DA  - 2002///
PY  - 2002
SP  - 567
EP  - 570
PB  - IEEE Computer Society
SN  - 0-7803-7498-3
ER  - 

TY  - CONF
TI  - Session management of correlated multi-stream 3D tele-immersive environments
AU  - Arefin, Ahsan
T3  - Mm '11
AB  - Quality control and resource optimization are challenging problems in 3D tele-immersive (3DTI) environments due to their large scale, multi-stream dependencies and dynamic peer (viewer) behavior. Such systems are also prone to performance degradation due to undesired behavior in the event of drastic demand changes, such as view change and large-scale simultaneous viewer arrivals or departures. Therefore, it is crucial to localize undesired behavior inside the system and re-organize the streaming overlay structures accordingly. Doing this accurately for a large scale is even more challenging and it requires to capture all events effecting the data plan and control plan of the system. Moreover, to do this, we need to understand the desired behavior of the application first, which is defined by the dependency patterns of performance and configuration metadata at each participating peers. To assist that, we propose a learning framework that discovers metadata dependency patterns from the time series metadata and uses an online profiler to detect undesired behavior of the system during run-time. Such universal protocol also enables the prediction of large scale performance degradation due to irregular dependencies. Finally an adaptation is proposed that reallocates the resources and rearranges overlay structures to overcome the undesired behavior. In summary, our goal is to provide a universal session monitoring and management framework for complex multi-stream 3DTI environments to support large number of concurrent viewers. We consider the difficulty in overlay construction, collecting metadata, answering queries, learning patterns, detecting undesired behavior at the participating peers and finally overlay adaptation considering multi-stream dependencies.
C1  - Scottsdale, Arizona, USA
C3  - Proceedings of the 19th ACM international conference on multimedia
DA  - 2011///
PY  - 2011
DO  - 10.1145/2072298.2072489
SP  - 849
EP  - 852
PB  - Association for Computing Machinery
SN  - 978-1-4503-0616-4
UR  - https://doi.org/10.1145/2072298.2072489
KW  - learning
KW  - adaptation
KW  - monitoring
KW  - resource allocation
KW  - streaming
ER  - 

TY  - JOUR
TI  - Recurring meetings: An experiential account of repeating meetings in a large organization
AU  - Niemantsverdriet, Karin
AU  - Erickson, Thomas
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - Meetings are often seen solely as a site of collective work. However, as McGrath has noted, groups are concerned with much more than collective work. In this study we examine how individuals experience meetings, and ask what they do, why they do it, and how they feel about it. Our study focuses on recurring meetings, both because recurring meetings are an ordinary aspect of organization life, and because their routine nature lends them a casual character that distinguishes them from one-time, issue-focused meetings. This paper analyzes accounts of 19 meetings and examines how various peripheral activities – side-talk, side-tracking, multi-tasking, pre- and post-meeting talk – have positive effects, as well as negative ones. We argue that viewing recurring meetings as a confluence of individual and collective aims suggests new approaches for designing technology that supports both meetings and participants.
DA  - 2017/12//
PY  - 2017
DO  - 10.1145/3134719
VL  - 1
IS  - CSCW
UR  - https://doi.org/10.1145/3134719
KW  - interruptions
KW  - meeting support technology
KW  - multi-tasking
KW  - recurring meetings
KW  - remote communication
ER  - 

TY  - CONF
TI  - Free-hand pointing for identification and interaction with distant objects
AU  - Rümelin, Sonja
AU  - Marouane, Chadly
AU  - Butz, Andreas
T3  - AutomotiveUI '13
AB  - In this paper, we investigate pointing as a lightweight form of gestural interaction in cars. In a pre-study, we show the technical feasibility of reliable pointing detection with a depth camera by achieving a recognition rate of 96
C1  - Eindhoven, Netherlands
C3  - Proceedings of the 5th international conference on automotive user interfaces and interactive vehicular applications
DA  - 2013///
PY  - 2013
DO  - 10.1145/2516540.2516556
SP  - 40
EP  - 47
PB  - Association for Computing Machinery
SN  - 978-1-4503-2478-6
UR  - https://doi.org/10.1145/2516540.2516556
KW  - pointing
KW  - gesture interaction
KW  - camera-based tracking
ER  - 

TY  - CONF
TI  - Species-appropriate computer mediated interaction
AU  - McGrath, Robert E.
T3  - Chi ea '09
AB  - Given the importance of our non-human companions, do we not want to extend social media to our nonhuman co-species? If "human computer interfaces" should be designed for "Anyone. Anywhere." (the theme of CHI 2001), then why not for all species? Recent pioneering efforts have shown that computer mediated interactions between humans and dogs, cats, chickens, cows, hamsters, and other species are technically possible. These efforts excite the imagination and challenge our understanding the basic nature of computer mediated interaction.
C1  - Boston, MA, USA
C3  - CHI '09 extended abstracts on human factors in computing systems
DA  - 2009///
PY  - 2009
DO  - 10.1145/1520340.1520357
SP  - 2529
EP  - 2534
PB  - Association for Computing Machinery
SN  - 978-1-60558-247-4
UR  - https://doi.org/10.1145/1520340.1520357
KW  - computer-non-human interfaces
KW  - cross-species interaction
KW  - species-appropriate interfaces
ER  - 

TY  - CONF
TI  - Mechanical constraints as computational constraints in tabletop tangible interfaces
AU  - Patten, James
AU  - Ishii, Hiroshi
T3  - Chi '07
AB  - This paper presents a new type of human-computer interface called Pico (Physical Intervention in Computational Optimization) based on mechanical constraints that combines some of the tactile feedback and affordances of mechanical systems with the abstract computational power of modern computers. The interface is based on a tabletop interaction surface that can sense and move small objects on top of it. The positions of these physical objects represent and control parameters inside a software application, such as a system for optimizing the configuration of radio towers in a cellular telephone network. The computer autonomously attempts to optimize the network, moving the objects on the table as it changes their corresponding parameters in software. As these objects move, the user can constrain their motion with his or her hands, or many other kinds of physical objects. The interface provides ample opportunities for improvisation by allowing the user to employ a rich variety of everyday physical objects as mechanical constraints. This approach leverages the user's mechanical intuition for how objects respond to physical forces. As well, it allows the user to balance the numerical optimization performed by the computer with other goals that are difficult to quantify. Subjects in an evaluation were more effective at solving a complex spatial layout problem using this system than with either of two alternative interfaces that did not feature actuation.
C1  - San Jose, California, USA
C3  - Proceedings of the SIGCHI conference on human factors in computing systems
DA  - 2007///
PY  - 2007
DO  - 10.1145/1240624.1240746
SP  - 809
EP  - 818
PB  - Association for Computing Machinery
SN  - 978-1-59593-593-9
UR  - https://doi.org/10.1145/1240624.1240746
KW  - actuation
KW  - tangible interfaces
KW  - improvisation
KW  - interactive surface
KW  - physical interaction
ER  - 

TY  - JOUR
TI  - Radical atoms: beyond tangible bits, toward transformable materials
AU  - Ishii, Hiroshi
AU  - Lakatos, Dávid
AU  - Bonanni, Leonardo
AU  - Labrune, Jean-Baptiste
T2  - Interactions
DA  - 2012/01//
PY  - 2012
DO  - 10.1145/2065327.2065337
VL  - 19
IS  - 1
SP  - 38
EP  - 51
SN  - 1072-5520
UR  - https://doi.org/10.1145/2065327.2065337
ER  - 

TY  - BOOK
TI  - CHIWORK '25: Proceedings of the 4th annual symposium on human-computer interaction for work
AB  - Welcome to CHIWORK 2025, the 4th Annual Symposium on Human-Computer Interaction for Work to be held at Centrum Wiskunde &amp; Informatica (CWI) in Amsterdam, The Netherlands.CHIWORK is the annual symposium that aims to grow our understanding of how Human-Computer Interaction (HCI) will support work in the future. Advances in Computing technology are rapidly changing the way we work. Human-computer interaction (HCI) is a critical aspect of this ongoing change, as a way to support workers in successfully navigating fast-paced changes in working environments, which might include novel computing devices, new sensing and work(er) wellbeing and performance measurement techniques, interacting with AI agents, and the new roles for people in work environments where automation is increasing.
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1384-2
ER  - 

TY  - BOOK
TI  - ISS companion '24: Companion proceedings of the 2024 conference on interactive surfaces and spaces
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1278-4
ER  - 

TY  - CONF
TI  - Exploitation of novel multiplayer gesture-based interaction and virtual puppetry for digital storytelling to develop children's narrative skills
AU  - Liang, Hui
AU  - Chang, Jian
AU  - Deng, Shujie
AU  - Chen, Can
AU  - Tong, Ruofeng
AU  - Zhang, Jianjun
T3  - Vrcai '15
AB  - In recent years, digital storytelling has demonstrated powerful pedagogical functions by improving creativity, collaboration and intimacy among young children. Saturated with digital media technologies in their daily lives, the young generation demands natural interactive learning environments which offer multimodalities of feedback and meaningful immersive learning experiences. Virtual puppetry assisted storytelling system for young children, which utilises depth motion sensing technology and gesture control as the Human-Computer Interaction (HCI) method, has been proved to provide natural interactive learning experience for single player. In this paper, we designed and developed a novel system that allows multiple players to narrate, and most importantly, to interact with other characters and interactive virtual items in the virtual environment. We have conducted one user experiment with four young children for pedagogical evaluation and another user experiment with five postgraduate students for system evaluation. Our user study shows this novel digital storytelling system has great potential to stimulate learning abilities of young children through collaboration tasks.
C1  - Kobe, Japan
C3  - Proceedings of the 14th ACM SIGGRAPH international conference on virtual reality continuum and its applications in industry
DA  - 2015///
PY  - 2015
DO  - 10.1145/2817675.2817680
SP  - 63
EP  - 72
PB  - Association for Computing Machinery
SN  - 978-1-4503-3940-7
UR  - https://doi.org/10.1145/2817675.2817680
KW  - virtual reality
KW  - children learning
KW  - gesture-based control
KW  - interactive storytelling
KW  - virtual puppetry
ER  - 

TY  - CONF
TI  - SEMarbeta: mobile sketch-gesture-video remote support for car drivers
AU  - Chen, Sicheng
AU  - Chen, Miao
AU  - Kunz, Andreas
AU  - Yantaç, Asim Evren
AU  - Bergmark, Mathias
AU  - Sundin, Anders
AU  - Fjeld, Morten
T3  - Ah '13
AB  - Uneven knowledge distribution is often an issue in remote support systems, creating the occasional need for additional information layers that extend beyond plain videoconference and shared workspaces. This paper introduces SEMarbeta, a remote support system designed for car drivers in need of help from an office-bound professional expert. We introduce a design concept and its technical implementation using low-cost hardware and techniques inspired by augmented reality research. In this setup, the driver uses a portable Android tablet PC while the expert mechanic uses a stationary computer equipped with a video camera capturing his gestures and sketches. Hence, verbal instructions can be combined with supportive gestures and sketches added by the expert mechanic to the car's video display. To validate this concept, we carried out a user study involving two typical automotive repair tasks: checking engine oil and examining fuses. Based on these tasks and following a between-group (drivers and expert mechanics) design, we compared voice-only with additional sketch- and gesture-overlay on video screenshots measuring objective and perceived quality of help. Results indicate that sketch- and gesture-overlay can benefit remote car support in typical breakdown situations.
C1  - Stuttgart, Germany
C3  - Proceedings of the 4th augmented human international conference
DA  - 2013///
PY  - 2013
DO  - 10.1145/2459236.2459249
SP  - 69
EP  - 76
PB  - Association for Computing Machinery
SN  - 978-1-4503-1904-1
UR  - https://doi.org/10.1145/2459236.2459249
KW  - AR
KW  - automotive
KW  - mobile
KW  - user study
KW  - handheld computer
KW  - remote support
ER  - 

TY  - BOOK
TI  - Web3D '24: Proceedings of the 29th international ACM conference on 3D web technology
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0689-9
ER  - 

TY  - JOUR
TI  - Vicariously experiencing it all without going outside: a study of outdoor livestreaming in china
AU  - Lu, Zhicong
AU  - Annett, Michelle
AU  - Wigdor, Daniel
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - The livestreaming industry in China is gaining greater traction than its European and North American counterparts and has a profound impact on the stakeholders' online and offline lives. An emerging genre of livestreaming that has become increasingly popular in China is outdoor livestreaming. With outdoor livestreams, streamers broadcast outdoor activities, travel, or socialize with passersby in outdoor settings, often for 6 or more hours, and viewers watch such streams for hours each day. However, given that professionally produced content about travel and outdoor activities are not very popular, it is currently unknown what makes this category of livestreams so engaging and how these techniques can be applied to other content or genres. Thus, we conducted a mixed methods study consisting of a survey (N=287) and interviews (N = 20) to understand how viewers watch and engage with outdoor livestreams in China. The data revealed that outdoor livestreams encompass many categories of content, environments and passersby behaviors create challenges and uncertainty for viewers and streamers, and viewers watch livestreams for surprising lengths of time (e.g., sometimes more than 5 continuous hours). We also gained insights into how live commenting and virtual gifting encourage engagement. Lastly, we detail how the behaviors of dedicated fans and casual viewers differ and provide implications for the design of livestreaming services that support outdoor activities.
DA  - 2019/11//
PY  - 2019
DO  - 10.1145/3359127
VL  - 3
IS  - CSCW
UR  - https://doi.org/10.1145/3359127
KW  - social media
KW  - livestreaming
KW  - outdoor activities
KW  - user engagement
ER  - 

TY  - BOOK
TI  - IHM '23: Proceedings of the 34th conference on l'Interaction humain-machine
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 978-1-4503-9824-4
ER  - 

TY  - CONF
TI  - Integrating active tangible devices with a synthetic environment for collaborative engineering
AU  - Ressler, Sandy
AU  - Antonishek, Brian
AU  - Wang, Qiming
AU  - Godil, Afzal
T3  - Web3D '01
C1  - Paderbon, Germany
C3  - Proceedings of the sixth international conference on 3D web technology
DA  - 2001///
PY  - 2001
DO  - 10.1145/363361.363383
SP  - 93
EP  - 100
PB  - Association for Computing Machinery
SN  - 1-58113-339-1
UR  - https://doi.org/10.1145/363361.363383
KW  - virtual environments
KW  - user interfaces
KW  - device control
KW  - tangible reality
KW  - VRML
ER  - 

TY  - CONF
TI  - Visual immersive mathematics in 3D web
AU  - Lai, Danbo
AU  - Sourin, Alexei
T3  - Vrcai '11
AB  - Existing methods for cyber learning mathematics and geometry are restricted to a limited class of geometric objects, most of which are predefined in the system. Besides, no existing methods emphasize the geometric meaning of mathematic functions. Our research aims at improving learners' three-dimensional spatial abilities by providing an intuitive and efficient environment for learning mathematics and geometry, specifically, the geometric meaning of mathematic functions. We propose a new 3D web learning environment that does not restrict to a list of predefined primitive geometric objects, allows the learner to interactively create objects by defining their properties using analytical functions, and immerses the learner into the environment. The object properties, including geometry, visual appearance and physical properties, are created in their own coordinate domains and then assembled together to define a virtual shape. The shape definition is eventually a function scripts that can be rendered on any suitable graphics system. We have implemented our software using the function-based extension of the Virtual Reality Modeling Language (VRML) and Extensible 3D (X3D).
C1  - Hong Kong, China
C3  - Proceedings of the 10th international conference on virtual reality continuum and its applications in industry
DA  - 2011///
PY  - 2011
DO  - 10.1145/2087756.2087856
SP  - 519
EP  - 526
PB  - Association for Computing Machinery
SN  - 978-1-4503-1060-4
UR  - https://doi.org/10.1145/2087756.2087856
KW  - 3D web
KW  - shape modeling
KW  - shared virtual reality
ER  - 

TY  - CONF
TI  - Model augmented reality curriculum
AU  - Fominykh, Mikhail
AU  - Wild, Fridolin
AU  - Klamma, Ralf
AU  - Billinghurst, Mark
AU  - Costiner, Lisandra S.
AU  - Karsakov, Andrey
AU  - Mangina, Eleni
AU  - Molka-Danielsen, Judith
AU  - Pollock, Ian
AU  - Preda, Marius
AU  - Smolic, Aljosa
T3  - ITiCSE-WGR '20
AB  - Augmented Reality (AR) is a rapidly growing field in information and communication technologies, drawing increasing numbers of professionals. Higher education institutions, however, are struggling to keep abreast of its development and to train specialists quickly, providing few courses which sufficiently align with the needs of industry. In addition to this, the field is developing so rapidly that existing courses struggle to keep pace. They also often focus too narrowly on specifics to allow for the building of the formative foundations of AR education. This paper aims to address this need by proposing a blueprint curriculum in Computer Science Education for teaching AR in universities at two levels, foundations and advanced. To begin, we survey the state of the art, identifying common needs and problems in existing courses which focus on AR. We then detail a skills framework comprised of 12 groups of skills suitable to meet industry needs, and built upon it two model lesson plans for a foundation and an advanced course. We conclude with a discussion of assessment techniques and curricular design options of embedding such coursework into existing academic programs and a forecast of the future of this academic field.
C1  - Trondheim, Norway
C3  - Proceedings of the working group reports on innovation and technology in computer science education
DA  - 2020///
PY  - 2020
DO  - 10.1145/3437800.3439205
SP  - 131
EP  - 149
PB  - Association for Computing Machinery
SN  - 978-1-4503-8293-9
UR  - https://doi.org/10.1145/3437800.3439205
KW  - augmented reality
KW  - curriculum
KW  - software engineering
ER  - 

TY  - CHAP
TI  - Medical and health systems
AU  - Sonntag, Daniel
T2  - The handbook of multimodal-multisensor interfaces: Language processing, software, commercialization, and emerging directions
DA  - 2019///
PY  - 2019
SP  - 423
EP  - 476
PB  - Association for Computing Machinery and Morgan &amp; Claypool
SN  - 978-1-970001-75-4
UR  - https://doi.org/10.1145/3233795.3233808
ER  - 

TY  - JOUR
TI  - Bridging the socio-technical gaps in body-worn interpersonal live-streaming telepresence through a critical review of the literature
AU  - Pfeil, Kevin P.
AU  - Chatlani, Neeraj
AU  - LaViola, Joseph J.
AU  - Wisniewski, Pamela
T2  - Proc. ACM Hum.-Comput. Interact.
AB  - It is important to learn from the past as we endeavor into this uncharted territory of mobile, human-to-human, one-to-one telepresence for interpersonal use. With the ever-increasing access to live-streaming cameras, we are now at the cusp of being able to create novel, immersive, and interpersonal telepresence activities that have the potential to change how humans interact with one another on a daily basis. Due to its novelty, there are likely socio-technical gaps between the needs of users and the technical specifications of the prototypes that are currently being designed to support the complex social interactions of human-to-human telepresence. Therefore, in this paper, we use a socio-technical lens to conduct a systematic literature review of 52 peer-reviewed articles of early work in this space. Overall, we found that while progress has been made to address the social needs of those involved in one-to-one telepresence scenarios, there are discontinuities within the existing literature that need to be addressed, particularly with the way we attempt to measure and quantify human-centered outcomes with unvalidated instruments. We also found that the social needs of on-site users have been neglected, as in many articles the user was merely treated as a surrogate, or reported feeling socially awkward or unsafe, due to the conspicuous nature of the body-worn technology in public environments. These findings are prevalent, even as researchers consider adding to this body-worn burden in an attempt to improve the receiving users' sense of immersion and presence. To preserve the beneficial nature of telepresence interaction while ensuring that all users' needs are met, researchers should endeavor to further understand the dynamics of the relationship between all parties in the remote environment. Our paper creates a future research agenda that emphasizes the importance of ensuring that all parties involved feel comfortable in their role during interpersonal telepresence interactions.
DA  - 2021/04//
PY  - 2021
DO  - 10.1145/3449194
VL  - 5
IS  - CSCW1
UR  - https://doi.org/10.1145/3449194
KW  - telepresence
KW  - literature review
KW  - mobile
KW  - novel interaction
ER  - 

TY  - CONF
TI  - RobotPHONE: RUI for interpersonal communication
AU  - Sekiguchi, Dairoku
AU  - Inami, Masahiko
AU  - Tachi, Susumu
T3  - Chi ea '01
AB  - RobotPHONE is a Robotic User Interface (RUI) that uses robots as physical avatars for interpersonal communication. Using RobotPHONE, users in remote locations can communicate shapes and motion with each other. In this paper we present the concept of RobotPHONE, and describe implementations of two prototypes.
C1  - Seattle, Washington
C3  - CHI '01 extended abstracts on human factors in computing systems
DA  - 2001///
PY  - 2001
DO  - 10.1145/634067.634231
SP  - 277
EP  - 278
PB  - Association for Computing Machinery
SN  - 1-58113-340-5
UR  - https://doi.org/10.1145/634067.634231
KW  - robot
KW  - interpersonal communication
KW  - bilateral servo
KW  - interface
KW  - physical avatar
KW  - RUI
ER  - 

TY  - CONF
TI  - ComTouch: design of a vibrotactile communication device
AU  - Chang, Angela
AU  - O'Modhrain, Sile
AU  - Jacob, Rob
AU  - Gunther, Eric
AU  - Ishii, Hiroshi
T3  - Dis '02
AB  - We describe the design of ComTouch, a device that augments remote voice communication with touch, by converting hand pressure into vibrational intensity between users in real-time. The goal of this work is to enrich inter-personal communication by complementing voice with a tactile channel. We present preliminary user studies performed on 24 people to observe possible uses of the tactile channel when used in conjunction with audio. By recording and examining both audio and tactile data, we found strong relationships between the two communication channels. Our studies show that users developed an encoding system similar to that of Morse code, as well as three original uses: emphasis, mimicry, and turn-taking. We demonstrate the potential of the tactile channel to enhance the existing voice communication channel.
C1  - London, England
C3  - Proceedings of the 4th conference on designing interactive systems: Processes, practices, methods, and techniques
DA  - 2002///
PY  - 2002
DO  - 10.1145/778712.778755
SP  - 312
EP  - 320
PB  - Association for Computing Machinery
SN  - 1-58113-515-7
UR  - https://doi.org/10.1145/778712.778755
KW  - communication
KW  - tangible user interface
KW  - remote communication
KW  - haptic interpersonal
KW  - tactile communication
KW  - tangible telepresence
KW  - touch-vibration mapping
KW  - vibrotactile
ER  - 

TY  - BOOK
TI  - HRI '24: Companion of the 2024 ACM/IEEE international conference on human-robot interaction
AB  - Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is "HRI in the Real World," and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the "real world" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0323-2
ER  - 

TY  - CONF
TI  - MeBot: a robotic platform for socially embodied presence
AU  - Adalgeirsson, Sigurdur O.
AU  - Breazeal, Cynthia
T3  - Hri '10
AB  - Telepresence refers to a set of technologies that allow users to feel present at a distant location; telerobotics is a subfield of telepresence. This paper presents the design and evaluation of a telepresence robot which allows for social expression. Our hypothesis is that a telerobot that communicates more than simply audio or video but also expressive gestures, body pose and proxemics, will allow for a more engaging and enjoyable interaction. An iterative design process of the MeBot platform is described in detail, as well as the design of supporting systems and various control interfaces. We conducted a human subject study where the effects of expressivity were measured. Our results show that a socially expressive robot was found to be more engaging and likable than a static one. It was also found that expressiveness contributes to more psychological involvement and better cooperation.
C1  - Osaka, Japan
C3  - Proceedings of the 5th ACM/IEEE international conference on human-robot interaction
DA  - 2010///
PY  - 2010
SP  - 15
EP  - 22
PB  - IEEE Press
SN  - 978-1-4244-4893-7
KW  - telepresence
KW  - human robot interaction
KW  - embodied videoconferencing
KW  - robot-mediated communication
ER  - 

TY  - CONF
TI  - GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions
AU  - Liang, Rong-Hao
AU  - Cheng, Kai-Yin
AU  - Chan, Liwei
AU  - Peng, Chuan-Xhyuan
AU  - Chen, Mike Y.
AU  - Liang, Rung-Huei
AU  - Yang, De-Nian
AU  - Chen, Bing-Yu
T3  - Chi '13
AB  - We present GaussBits, which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.
C1  - Paris, France
C3  - Proceedings of the SIGCHI conference on human factors in computing systems
DA  - 2013///
PY  - 2013
DO  - 10.1145/2470654.2466185
SP  - 1391
EP  - 1400
PB  - Association for Computing Machinery
SN  - 978-1-4503-1899-0
UR  - https://doi.org/10.1145/2470654.2466185
KW  - magnetism
KW  - near-surface tracking
KW  - occlusion-free
KW  - portable
KW  - tangible interactions
ER  - 

TY  - BOOK
TI  - UIST adjunct '24: Adjunct proceedings of the 37th annual ACM symposium on user interface software and technology
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0718-6
ER  - 

TY  - BOOK
TI  - SUI '23: Proceedings of the 2023 ACM symposium on spatial user interaction
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0281-5
ER  - 

TY  - CONF
TI  - Directions for multi-party human-computer interaction research
AU  - Kirchhoff, Katrin
AU  - Ostendorf, Mari
T3  - Hlt-naacl-dialogue '03
AB  - Research on dialog systems has so far concentrated on interactions between a single user and a machine. In this paper we identify novel research directions arising from multi-party human computer interaction, i.e. scenarios where several human participants interact with a dialog system.
C1  - Edmonton, Alberta, Canada
C3  - Proceedings of the HLT-NAACL 2003 workshop on research directions in dialogue processing - volume 7
DA  - 2003///
PY  - 2003
DO  - 10.3115/1118927.1118930
SP  - 7
EP  - 9
PB  - Association for Computational Linguistics
UR  - https://doi.org/10.3115/1118927.1118930
ER  - 

TY  - CONF
TI  - Creative idea exploration within the structure of a guiding framework: the card brainstorming game
AU  - Hornecker, Eva
T3  - Tei '10
AB  - I present a card brainstorming exercise that transforms a conceptual tangible interaction framework into a tool for creative dialogue and discuss the experiences made in using it. Ten sessions with this card game demonstrate the frameworks' versatility and utility. Observation and participant feedback highlight the value of a provocative question format and of the metaphor of a card game.
C1  - Cambridge, Massachusetts, USA
C3  - Proceedings of the fourth international conference on tangible, embedded, and embodied interaction
DA  - 2010///
PY  - 2010
DO  - 10.1145/1709886.1709905
SP  - 101
EP  - 108
PB  - Association for Computing Machinery
SN  - 978-1-60558-841-4
UR  - https://doi.org/10.1145/1709886.1709905
KW  - design
KW  - creativity
KW  - tangible
KW  - analysis
KW  - embodied
KW  - ideation
ER  - 

TY  - BOOK
TI  - VINCI '24: Proceedings of the 17th international symposium on visual information communication and interaction
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0967-8
ER  - 

TY  - CONF
TI  - The use of MUPPETS in an introductory java programming course
AU  - Bierre, Kevin J.
AU  - Phelps, Andrew M.
T3  - Citc5 '04
AB  - "The Multi-User Programming Pedagogy for Enhancing Traditional Study" (MUPPETS) system has been under development at RIT for the last three years. This multi-user environment is designed to allow students to develop visible 3D objects in Java within a game-world environment with minimal knowledge of graphics programming. Students can interact with these objects through an interface built into the system. (Technical aspects of the MUPPETS system were previously published by the authors at CITC4) [1].In testing the usefulness of MUPPETS as a teaching tool, we have developed a series of course modules that use the environment as its programming environment. The existing "Programming for Information Technology III" course is the ideal place to perform an initial test of this nature, as students have some base familiarity with the Java language but have not yet completed their undergraduate programming core. Students in this course have a final group programming project that we intend to use as the initial test, and develop further MUPPETS modules downwards towards the initial freshman experience.In the past students used a package called "Robocode", which is available from IBM [2]. This project involved programming a virtual robot that could "fight" in an arena according to some agreed upon set of rules, which were developed both as part of the Robocode package and discussed and agreed upon in lecture. While the students enjoyed this project, the proliferation of available code on the Internet for the framework led to this project being removed from the course. We have implemented a variant of "RoboCode" in MUPPETS that addresses the code availability issue and provides a more interesting and graphically rich environment for the students.This paper shall discuss the reasons for the implementation, what we expect the students will gain from the use of MUPPETS based project, and possible methods of comparing this approach to the methods previously used in this course. Also discussed are additions to the MUPPETS system made to facilitate its classroom use including a re-implementation of the Swing graphics classes such that 2D interfaces are available in 3D, and model loading and texturing tools that allow custom robot creation and customization.
C1  - Salt Lake City, UT, USA
C3  - Proceedings of the 5th conference on information technology education
DA  - 2004///
PY  - 2004
DO  - 10.1145/1029533.1029564
SP  - 122
EP  - 127
PB  - Association for Computing Machinery
SN  - 1-58113-936-5
UR  - https://doi.org/10.1145/1029533.1029564
KW  - virtual worlds
KW  - game programming
KW  - graphics
KW  - programming education
ER  - 

TY  - BOOK
TI  - CHI EA '21: Extended abstracts of the 2021 CHI conference on human factors in computing systems
CY  - New York, NY, USA
DA  - 2021///
PY  - 2021
PB  - Association for Computing Machinery
SN  - 978-1-4503-8095-9
ER  - 

TY  - BOOK
TI  - IMX '23: Proceedings of the 2023 ACM international conference on interactive media experiences
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0028-6
ER  - 

TY  - CONF
TI  - Body-centric interaction techniques for very large wall displays
AU  - Shoemaker, Garth
AU  - Tsukitani, Takayuki
AU  - Kitamura, Yoshifumi
AU  - Booth, Kellogg S.
T3  - NordiCHI '10
AB  - We examine the design space of interaction techniques for very large wall displays by drawing from existing theory and practice for reality-based interfaces and whole-body interfaces. We also apply insights drawn from research in psychology about the human cognitive mechanisms that support sensorimotor operations in different coordinate spaces, as well as research in sociology examining how people manage coordination and privacy concerns in these spaces. Using guidelines obtained from these analyses, we designed and implemented a novel suite of body-centric interaction techniques. These were integrated into a map browsing and editing application for a very large (5m×3m) wall display. The application was then used to gather user feedback to guide the further development of the interaction techniques.
C1  - Reykjavik, Iceland
C3  - Proceedings of the 6th nordic conference on human-computer interaction: Extending boundaries
DA  - 2010///
PY  - 2010
DO  - 10.1145/1868914.1868967
SP  - 463
EP  - 472
PB  - Association for Computing Machinery
SN  - 978-1-60558-934-3
UR  - https://doi.org/10.1145/1868914.1868967
KW  - proxemics
KW  - embodied interaction
KW  - multimodal
KW  - gesture-based interaction
KW  - post-WIMP interfaces
KW  - reality-based interaction
ER  - 

TY  - CONF
TI  - A generic virtual reality software system's architecture and application
AU  - Steinicke, Frank
AU  - Ropinski, Timo
AU  - Hinrichs, Klaus
T3  - Icat '05
AB  - Virtual reality (VR) systems utilize additional input and output channels in order to make interaction in virtual environments (VEs) more intuitive and to increase the user's immersion into the virtual world. When developing VR applications, developers should be able to focus on modeling advanced interaction and system behavior instead of rendering issues. Many systems and tools for developing virtual reality applications have been proposed to achieve this goal. However, no de facto standard is available. In this paper we present Virtual Reality VRS (VR2S), a generic VR software system, which is an extension of the high-level rendering system VRS. The system provides flexibility in terms of the rendering system and the user interface toolkit. Thus, with using VR2S rendering can be performed with several low-level rendering APIs such as OpenGL, Render-Man or ray-tracing systems, and the interface can be implemented by arbitrary user interface toolkits to support both desktop- and VR-based interaction. The proposed system meets the demands of VR developers as well as users and has demonstrated its potential in different planning and exploration applications.
C1  - Christchurch, New Zealand
C3  - Proceedings of the 2005 international conference on augmented tele-existence
DA  - 2005///
PY  - 2005
DO  - 10.1145/1152399.1152440
SP  - 220
EP  - 227
PB  - Association for Computing Machinery
SN  - 0-473-10657-4
UR  - https://doi.org/10.1145/1152399.1152440
KW  - virtual reality
KW  - software architecture
KW  - VR applications
KW  - VR interaction techniques
ER  - 

TY  - BOOK
TI  - SIGGRAPH posters '25: Proceedings of the special interest group on computer graphics and interactive techniques conference posters
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1549-5
ER  - 

TY  - BOOK
TI  - ICVARS '24: Proceedings of the 2024 8th international conference on virtual and augmented reality simulations
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0901-2
ER  - 

TY  - BOOK
TI  - ECCE '24: Proceedings of the european conference on cognitive ergonomics 2024
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1824-3
ER  - 

TY  - CONF
TI  - Quantifying the benefits of immersion for collaboration in virtual environments
AU  - Narayan, Michael
AU  - Waugh, Leo
AU  - Zhang, Xiaoyu
AU  - Bafna, Pradyut
AU  - Bowman, Doug
T3  - Vrst '05
AB  - Collaborative Virtual Environments allow multiple users to interact collaboratively while taking advantage of the perceptual richness that Virtual Environments (VEs) provide. In this paper, we demonstrate empirically that increasing the level of immersion in a VE can have a beneficial effect on the usability of that environment in a collaborative context. We present the results of a study in which we varied two immersive factors, stereo and head tracking, within the context of a two person collaborative task. Our results indicate that stereo can have a positive effect on task performance; that different levels of immersion have effects that vary with gender; and that varying the level of immersion has a pronounced effect on communication between users. These results show that the level of immersion can play an important role in determining user performance on some collaborative tasks.
C1  - Monterey, CA, USA
C3  - Proceedings of the ACM symposium on virtual reality software and technology
DA  - 2005///
PY  - 2005
DO  - 10.1145/1101616.1101632
SP  - 78
EP  - 81
PB  - Association for Computing Machinery
SN  - 1-59593-098-1
UR  - https://doi.org/10.1145/1101616.1101632
KW  - immersion
KW  - collaborative virtual environments
KW  - head tracking
KW  - stereo
ER  - 

TY  - CONF
TI  - Simulating educational physical experiments in augmented reality
AU  - Kaufmann, Hannes
AU  - Meyer, Bernd
T3  - SIGGRAPH asia '08
AB  - We present an augmented reality application for mechanics education. It utilizes a recent physics engine developed for the PC gaming market to simulate physical experiments in the domain of mechanics in real time. Students are enabled to actively build own experiments and study them in a three-dimensional virtual world. A variety of tools are provided to analyze forces, mass, paths and other properties of objects before, during and after experiments. Innovative teaching content is presented that exploits the strengths of our immersive virtual environment. PhysicsPlayground serves as an example of how current technologies can be combined to deliver a new quality in physics education.
C1  - Singapore
C3  - ACM SIGGRAPH ASIA 2008 educators programme
DA  - 2008///
PY  - 2008
DO  - 10.1145/1507713.1507717
PB  - Association for Computing Machinery
SN  - 978-1-60558-388-4
UR  - https://doi.org/10.1145/1507713.1507717
KW  - virtual reality
KW  - augmented reality
KW  - mechanics
KW  - physics education
ER  - 

TY  - BOOK
TI  - ASSETS '22: Proceedings of the 24th international ACM SIGACCESS conference on computers and accessibility
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9258-7
ER  - 

TY  - BOOK
TI  - CSCW '23 companion: Companion publication of the 2023 conference on computer supported cooperative work and social computing
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0129-0
ER  - 

TY  - BOOK
TI  - CHI EA '24: Extended abstracts of the CHI conference on human factors in computing systems
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0331-7
ER  - 

TY  - CONF
TI  - The designers' outpost: a tangible interface for collaborative web site
AU  - Klemmer, Scott R.
AU  - Newman, Mark W.
AU  - Farrell, Ryan
AU  - Bilezikjian, Mark
AU  - Landay, James A.
T3  - Uist '01
AB  - In our previous studies into web design, we found that pens, paper, walls, and tables were often used for explaining, developing, and communicating ideas during the early phases of design. These wall-scale paper-based design practices inspired The Designers' Outpost, a tangible user interface that combines the affordances of paper and large physical workspaces with the advantages of electronic media to support information design. With Outpost, users collaboratively author web site information architectures on an electronic whiteboard using physical media (Post-it notes and images), structuring and annotating that information with electronic pens. This interaction is enabled by a touch-sensitive SMART Board augmented with a robust computer vision system, employing a rear-mounted video camera for capturing movement and a front-mounted high-resolution camera for capturing ink. We conducted a participatory design study with fifteen professional web designers. The study validated that Outpost supports information architecture work practice, and led to our adding support for fluid transitions to other tools.
C1  - Orlando, Florida
C3  - Proceedings of the 14th annual ACM symposium on user interface software and technology
DA  - 2001///
PY  - 2001
DO  - 10.1145/502348.502350
SP  - 1
EP  - 10
PB  - Association for Computing Machinery
SN  - 1-58113-438-X
UR  - https://doi.org/10.1145/502348.502350
KW  - CSCW
KW  - Computer Vision
KW  - Informal Interfaces
KW  - Information Architecture
KW  - Sketching
KW  - Tangible Interfaces
KW  - Web Design
ER  - 

TY  - CONF
TI  - Iterative design and evaluation of an event architecture for pen-and-paper interfaces
AU  - Yeh, Ron B.
AU  - Paepcke, Andreas
AU  - Klemmer, Scott R.
T3  - Uist '08
AB  - This paper explores architectural support for interfaces combining pen, paper, and PC. We show how the event-based approach common to GUIs can apply to augmented paper, and describe additions to address paper's distinguishing characteristics. To understand the developer experience of this architecture, we deployed the toolkit to 17 student teams for six weeks. Analysis of the developers' code provided insight into the appropriateness of events for paper UIs. The usage patterns we distilled informed a second iteration of the toolkit, which introduces techniques for integrating interactive and batched input handling, coordinating interactions across devices, and debugging paper applications. The study also revealed that programmers created gesture handlers by composing simple ink measurements. This desire for informal interactions inspired us to include abstractions for recognition. This work has implications beyond paper - designers of graphical tools can examine API usage to inform iterative toolkit development.
C1  - Monterey, CA, USA
C3  - Proceedings of the 21st annual ACM symposium on user interface software and technology
DA  - 2008///
PY  - 2008
DO  - 10.1145/1449715.1449734
SP  - 111
EP  - 120
PB  - Association for Computing Machinery
SN  - 978-1-59593-975-3
UR  - https://doi.org/10.1145/1449715.1449734
KW  - evaluation
KW  - toolkits
KW  - augmented paper
KW  - device ensembles
ER  - 

TY  - BOOK
TI  - SIGGRAPH '16: ACM SIGGRAPH 2016 emerging technologies
AB  - Interact with digital experiences that move beyond digital tradition, blur the boundaries between art and science, and transform social assumptions. See, learn, touch, and try the state of the art in human-computer interaction and robotics. Emerging Technologies presents work from many sub-disciplines of interactive techniques, with a special emphasis on projects that explore science, high-resolution digital-cinema technologies, and interactive art-science narratives.
CY  - New York, NY, USA
DA  - 2016///
PY  - 2016
PB  - Association for Computing Machinery
SN  - 978-1-4503-4372-5
ER  - 

TY  - CONF
TI  - An animated 3D manipulator for distributed collaborative window-based applications
AU  - Davies, Matthew L.
AU  - Thomas, Bruce H.
T3  - Auic '01
AB  - This paper presents a new animated 3D graphical object manipulator to improve the visualisation of distributed window-based collaborative 3D applications. By applying animation techniques to the user interface, the experience of multi-user interaction may be enhanced. A major problem associated with distributed collaborative 3D applications is that interactions among users may cause conflicts, and it may be difficult to convey what these conflicts are. In addition, there is a need for additional feedback when interacting with 3D objects in current workstation 3D virtual reality applications. A prototype application is presented in the paper to demonstrate this new animated manipulator.
C1  - Queensland, Australia
C3  - Proceedings of the 2nd australasian conference on user interface
DA  - 2001///
PY  - 2001
SP  - 116
EP  - 123
PB  - IEEE Computer Society
SN  - 0-7695-0969-X
KW  - 3D graphics
KW  - collaborative applications
KW  - distributed applications
KW  - graphical manipulators
ER  - 

TY  - BOOK
TI  - SIGGRAPH '24: ACM SIGGRAPH 2024 posters
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0516-8
ER  - 

TY  - BOOK
TI  - AM '24: Proceedings of the 19th international audio mostly conference: Explorations in sonic cultures
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0968-5
ER  - 

TY  - BOOK
TI  - C&amp;C '24: Proceedings of the 16th conference on creativity &amp; cognition
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0485-7
ER  - 

TY  - BOOK
TI  - CHI EA '23: Extended abstracts of the 2023 CHI conference on human factors in computing systems
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 978-1-4503-9422-2
ER  - 

TY  - CONF
TI  - Face to face collaborative AR on mobile phones
AU  - Henrysson, Anders
AU  - Billinghurst, Mark
AU  - Ollila, Mark
T3  - Ismar '05
AB  - Mobile phones are an ideal platjorm for augmented reality. In this paper we describe how they also can be used to support face to face collaborative AR applications. We have created a custom port of the ARToolKit library to the Symbian mobile phone operating system and then developed a sample collaborative AR game based on this. We describe the game in detail and user feedback from people who have played it. We also provide general design guidelines that could he useful for others who are developing mobile phone collaborative AR applications.
C1  - USA
C3  - Proceedings of the 4th IEEE/ACM international symposium on mixed and augmented reality
DA  - 2005///
PY  - 2005
DO  - 10.1109/ISMAR.2005.32
SP  - 80
EP  - 89
PB  - IEEE Computer Society
SN  - 0-7695-2459-1
UR  - https://doi.org/10.1109/ISMAR.2005.32
ER  - 

TY  - CONF
TI  - Handheld devices for applications using dynamic multimedia data
AU  - Pham, Binh
AU  - Wong, On
T3  - Graphite '04
AB  - Growing demand for ubiquitous and pervasive computing has triggered a sharp rise in handheld device usage. At the same time, dynamic multimedia data has become accepted as core material which many important applications depend on, despite intensive costs in computation and resources. This paper investigates the suitability and constraints of using handheld devices for such applications. We firstly analyse the capabilities and limitations of current models of handheld devices and advanced features offered by next generation models. We then categorise these applications and discuss the typical requirements of each class. Important issues to be considered include data organisation and management, communication, and input and user interfaces. Finally, we briefly discuss future outlook and identify remaining areas for research.
C1  - Singapore
C3  - Proceedings of the 2nd international conference on computer graphics and interactive techniques in australasia and south east asia
DA  - 2004///
PY  - 2004
DO  - 10.1145/988834.988856
SP  - 123
EP  - 130
PB  - Association for Computing Machinery
SN  - 1-58113-883-0
UR  - https://doi.org/10.1145/988834.988856
KW  - computer graphics
KW  - multimedia
KW  - collaborative
KW  - handheld devices
KW  - image processing
ER  - 

TY  - BOOK
TI  - CHI '23: Proceedings of the 2023 CHI conference on human factors in computing systems
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 978-1-4503-9421-5
ER  - 

TY  - CONF
TI  - Incorporating co-presence in distributed virtual music environment
AU  - Jung, Byungdae
AU  - Hwang, Jaein
AU  - Lee, Sangyoon
AU  - Kim, Gerard Jounghyun
AU  - Kim, Hyunbin
T3  - Vrst '00
AB  - In this paper, we present "PODIUM (POstech Distributed virtual Music environment)", a distributed virtual environment that allows users to participate in a shared space and play music with other participants in a collaborative manner. In addition to playing virtual instruments, users can communicate and interact in various ways to enhance the collaboration and, thus, the quality of the music played together. Musical messages are generated note by note through interaction with the keyboard, mouse, and other devices, and transmitted through an IP-multicasting network among participants. In addition to such note-level information, additional messages for visualization, and interaction are supported. Real world based visualization has been chosen, against, for instance, abstract music world based visualization, to promote "co-presence" (e.g. recognize and interact with other players), which is deemed important for collaborative music production. In addition to the entertainment purpose, we hope that DVME will find great use in casual practice sessions for even professional performers/orchestras/bands.Since even a slight interruption in the flow of the music or out - of-synch graphics and sound would dramatically decrease utility of the system, we employ various techniques to minimize the network delay. An adapted server-client architecture and UDP' s are used to ensure fast packet deliveries and reduce the data bottleneck problem. Time-critical messages such as MIDI messages are multicasted among clients, and the less time-critical and infrequently updated messages are sent through the server. Predefined animations of avatars are invoked by interpreting the musical messages. Using the latest graphics and sound processing hardware, and by maintaining an appropriate scene complexity, and a frame rate sufficiently higher than the fastest note duration, the time constraint for graphics and sound synchronization can be met. However, we expect the network delay could cause considerable problems when the system is scaled up for many users and processing simultaneous notes (for harmony). To assess the scalability, we carried out a performance analysis of our system model to derive the maximum number of simultaneous participants. For example, according to our data, about 50 participants should be able to play together without significant disruption, each using one track with five simultaneous notes and for playing a musical piece at a speed of 16 ticks per second in a typical PC/LAN environment.In hopes of enhancing the feeling of "co-presence" among participants, a simple sound localization technique is used to compute panning and relative volumes from positions and orientations of participants. This reduced sound localization model is used also in order to minimize the computational cost and the network traffic. Participants can send predefined messages by interacting with the keyboard, mouse, and other input devices. All of the predefined messages are mapped into simple avatar motions, such as playing various types of instruments (players), making applause (audience), and conducting gestures (conductors). We believe that for coordinated music performance, indirect interaction will be the main interaction method, for example, exchanging particular gestures, signals, and voice commands to synchronize music, confirming and reminding expression of the upcoming portion of the music, and just exchanging glances to enjoy each others' emotion. In this view, there would be mainly three groups of participants: conductor, players, and the audience, playing different roles, but creating co-presence together through mutual recognition. We ran a simple experiment comparing the music performance of two groups of participants, one provided with co-presence cues and the other without, and found no performance edge by the group with the co-presence cues. Such a result can serve as one guideline for building music-related VR applications.
C1  - Seoul, Korea
C3  - Proceedings of the ACM symposium on virtual reality software and technology
DA  - 2000///
PY  - 2000
DO  - 10.1145/502390.502429
SP  - 206
EP  - 211
PB  - Association for Computing Machinery
SN  - 1-58113-316-2
UR  - https://doi.org/10.1145/502390.502429
KW  - Interaction
KW  - Co-presence
KW  - Distributed Virtual Reality
KW  - Networked Virtual Reality
KW  - Virtual Music
ER  - 

TY  - CONF
TI  - Evaluation of mixed-space collaboration
AU  - Grasset, Raphael
AU  - Lamb, Philip
AU  - Billinghurst, Mark
T3  - Ismar '05
AB  - Recently Augmented Reality (AR) technology has been used to develop the next generation collaborative interfaces. First results have shown the value of using AR for co-located tasks based on exocentric viewpoints. In contrast, Virtual Reality (VR) seems to offer interesting advantages for immersive collaborative experiences with egocentric viewpoints. In this paper we focus on a new area: a mixed collaboration between AR and VR environments. We present a new conceptual model of transitional interfaces that allow users to move between AR and VR viewpoints. We then describe the results of a quantitative evaluation with an AR exocentric viewpoint and a VR egocentric viewpoint for a navigational task. We also conducted a second experiment on the impact of the relationship between the interaction and visualization space in mixed collaboration. Results of these studies can provide a better understanding of how to design interfaces for multispace and transitional collaboration.
C1  - USA
C3  - Proceedings of the 4th IEEE/ACM international symposium on mixed and augmented reality
DA  - 2005///
PY  - 2005
DO  - 10.1109/ISMAR.2005.30
SP  - 90
EP  - 99
PB  - IEEE Computer Society
SN  - 0-7695-2459-1
UR  - https://doi.org/10.1109/ISMAR.2005.30
ER  - 

TY  - BOOK
TI  - AHs '24: Proceedings of the augmented humans international conference 2024
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0980-7
ER  - 

TY  - JOUR
TI  - ACM SIGMM retreat report on future directions in multimedia research
AU  - Rowe, Lawrence A.
AU  - Jain, Ramesh
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
AB  - The ACM Multimedia Special Interest Group was created ten years ago. Since that time, researchers have solved a number of important problems related to media processing, multimedia databases, and distributed multimedia applications. A strategic retreat was organized as part of ACM Multimedia 2003 to assess the current state of multimedia research and suggest directions for future research. This report presents the recommendations developed during the retreat. The major observation is that research in the past decade has significantly advanced hardware and software support for distributed multimedia applications and that future research should focus on identifying and delivering applications that impact users in the real-world.The retreat suggested that the community focus on solving three grand challenges: (1) make authoring complex multimedia titles as easy as using a word processor or drawing program, (2) make interactions with remote people and environments nearly the same as interactions with local people and environments, and (3) make capturing, storing, finding, and using digital media an everyday occurrence in our computing environment. The focus of multimedia researchers should be on applications that incorporate correlated media, fuse data from different sources, and use context to improve application performance.
DA  - 2005/02//
PY  - 2005
DO  - 10.1145/1047936.1047938
VL  - 1
IS  - 1
SP  - 3
EP  - 13
SN  - 1551-6857
UR  - https://doi.org/10.1145/1047936.1047938
KW  - distributed collaboration
KW  - Multimedia authoring
KW  - multimedia query
KW  - multimedia storage and indexing
KW  - tele-presence
ER  - 

TY  - CONF
TI  - Shared walk environment using locomotion interfaces
AU  - Yano, Hiroaki
AU  - Noma, Haruo
AU  - Iwata, Hiroo
AU  - Miyasato, Tsutomu
T3  - Cscw '00
AB  - By sharing data regarding the sensations experienced by individuals, as well as by sharing their knowledge, we are readily able to communicate with each other, and there are possibilities to further evolve this communication method. The different sensations experienced during voluntary walking and enforced walking give us different feelings. Also, the number of individuals involved can create a different feeling when walking. Networked computer-assisted walking can support and enhance these different experiences. In this paper, we introduce another walking style, the shared power-assisted voluntary walk, which is realized by a prototype networked locomotion system. This system can be used in tele-rehabilitation, which allows remote patients to share the sensation of walking. Also, it can be used to teach a group of patients rehabilitative walking. We developed two locomotion interfaces and connected them via a network. We developed enforced and semi-voluntary walking training systems using the shared walk environment and evaluated them with a series of experiments. operation integration process. In the second algorithm, thanks to deferred broadcast of operations to other sites, this process becomes even more simplified.
C1  - Philadelphia, Pennsylvania, USA
C3  - Proceedings of the 2000 ACM conference on computer supported cooperative work
DA  - 2000///
PY  - 2000
DO  - 10.1145/358916.358987
SP  - 163
EP  - 170
PB  - Association for Computing Machinery
SN  - 1-58113-222-0
UR  - https://doi.org/10.1145/358916.358987
KW  - virtual reality
KW  - rehabilitation
KW  - locomotion interface
KW  - shared environment
ER  - 

TY  - BOOK
TI  - Web3D '23: Proceedings of the 28th international ACM conference on 3D web technology
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0324-9
ER  - 

TY  - JOUR
TI  - What does touch tell us about emotions in touchscreen-based gameplay?
AU  - Gao, Yuan
AU  - Bianchi-Berthouze, Nadia
AU  - Meng, Hongying
T2  - ACM Trans. Comput.-Hum. Interact.
AB  - The increasing number of people playing games on touch-screen mobile phones raises the question of whether touch behaviors reflect players’ emotional states. This prospect would not only be a valuable evaluation indicator for game designers, but also for real-time personalization of the game experience. Psychology studies on acted touch behavior show the existence of discriminative affective profiles. In this article, finger-stroke features during gameplay on an iPod were extracted and their discriminative power analyzed. Machine learning algorithms were used to build systems for automatically discriminating between four emotional states (Excited, Relaxed, Frustrated, Bored), two levels of arousal and two levels of valence. Accuracy reached between 69
DA  - 2012/12//
PY  - 2012
DO  - 10.1145/2395131.2395138
VL  - 19
IS  - 4
SN  - 1073-0516
UR  - https://doi.org/10.1145/2395131.2395138
KW  - affective touch
KW  - Automatic emotion recognition
KW  - touch behavior
KW  - touch-based computer games
ER  - 

TY  - CONF
TI  - VisionWand: interaction techniques for large displays using a passive wand tracked in 3D
AU  - Cao, Xiang
AU  - Balakrishnan, Ravin
T3  - Uist '03
AB  - A passive wand tracked in 3D using computer vision techniques is explored as a new input mechanism for interacting with large displays. We demonstrate a variety of interaction techniques that exploit the affordances of the wand, resulting in an effective interface for large scale interaction. The lack of any buttons or other electronics on the wand presents a challenge that we address by developing a set of postures and gestures to track state and enable command input. We also describe the use of multiple wands, and posit designs for more complex wands in the future.
C1  - Vancouver, Canada
C3  - Proceedings of the 16th annual ACM symposium on user interface software and technology
DA  - 2003///
PY  - 2003
DO  - 10.1145/964696.964716
SP  - 173
EP  - 182
PB  - Association for Computing Machinery
SN  - 1-58113-636-6
UR  - https://doi.org/10.1145/964696.964716
KW  - gestures
KW  - interaction techniques
KW  - large displays
KW  - input devices
KW  - buttonless input
KW  - vision tracking
ER  - 

TY  - CONF
TI  - Trends in augmented reality tracking, interaction and display: A review of ten years of ISMAR
AU  - Zhou, Feng
AU  - Duh, Henry Been-Lirn
AU  - Billinghurst, Mark
T3  - Ismar '08
AB  - Although Augmented Reality technology was first developed over forty years ago, there has been little survey work giving an overview of recent research in the field. This paper reviews the ten-year development of the work presented at the ISMAR conference and its predecessors with a particular focus on tracking, interaction and display research. It provides a roadmap for future augmented reality research which will be of great value to this relatively young field, and also for helping researchers decide which topics should be explored when they are beginning their own studies in the area.
C1  - USA
C3  - Proceedings of the 7th IEEE/ACM international symposium on mixed and augmented reality
DA  - 2008///
PY  - 2008
DO  - 10.1109/ISMAR.2008.4637362
SP  - 193
EP  - 202
PB  - IEEE Computer Society
SN  - 978-1-4244-2840-3
UR  - https://doi.org/10.1109/ISMAR.2008.4637362
ER  - 

TY  - BOOK
TI  - CHIGREECE '23: Proceedings of the 2nd international conference of the ACM greek SIGCHI chapter
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0888-6
ER  - 

TY  - BOOK
TI  - UbiComp '24: Companion of the 2024 on ACM international joint conference on pervasive and ubiquitous computing
AB  - Welcome to UbiComp/ISWC 2024, the companion program of two premier conferences: The 2024 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp 2024) and the 2024 International Symposium on Wearable Computers (ISWC 2024). UbiComp and ISWC are premier interdisciplinary venues for international researchers, designers, developers, practitioners and educators in the field to present and discuss novel and impactful research in interactive, mobile, wearable and ubiquitous computing. The companion program has traditionally been a very important part of the UbiComp/ISWC conference series.UbiComp/ISWC 2024 is held from October 5 to 9, 2024 in Melbourne, Australia. Originally, UbiComp/ISWC was scheduled to take place in Melbourne in 2021. However, due to the significant impact of COVID-19, our community decided to postpone conferences taking place in their traditional form until last year, when UbiComp took place as an in-person event in Mexico. Now, in 2024 we look to consolidate the strength and ties in our community by having another fully in-person event and hoping to welcome a new generation of researchers to meet and explore the wonderful people that make up our community.
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1058-2
ER  - 

TY  - BOOK
TI  - C&amp;C '25: Proceedings of the 2025 conference on creativity and cognition
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1289-0
ER  - 

TY  - BOOK
TI  - AM '23: Proceedings of the 18th international audio mostly conference
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0818-3
ER  - 

TY  - JOUR
TI  - Perceptual user interfaces: perceptual intelligence
AU  - Pentland, Alex
T2  - Communications of The Acm
DA  - 2000/03//
PY  - 2000
DO  - 10.1145/330534.330536
VL  - 43
IS  - 3
SP  - 35
EP  - 44
J2  - Commun. ACM
SN  - 0001-0782
UR  - https://doi.org/10.1145/330534.330536
ER  - 

TY  - CONF
TI  - A pattern language for interactive tabletops in collaborative workspaces
AU  - Remy, Christian
AU  - Weiss, Malte
AU  - Ziefle, Martina
AU  - Borchers, Jan
T3  - EuroPLoP '10
AB  - In this paper, we present a Human-Computer Interaction (HCI) design pattern language that bundles existing knowledge on tabletop design and offers solutions to recurring problems. Our patterns enable not only developers, designers, and domain experts to improve their existing systems and facilitate the design process of new systems, we also encourage novice users to comprehend the variety of tabletop research and commercial products in this domain. We consider our language as a starting point to create a sustainable body of knowledge that will be extended and refined by the community.
C1  - Irsee, Germany
C3  - Proceedings of the 15th european conference on pattern languages of programs
DA  - 2010///
PY  - 2010
DO  - 10.1145/2328909.2328921
PB  - Association for Computing Machinery
SN  - 978-1-4503-0259-3
UR  - https://doi.org/10.1145/2328909.2328921
KW  - interactive tabletops
KW  - guidelines
KW  - HCI design patterns
ER  - 

TY  - BOOK
TI  - ECCE '22: Proceedings of the 33rd european conference on cognitive ergonomics
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9808-4
ER  - 

TY  - BOOK
TI  - NordiCHI '22 adjunct: Adjunct proceedings of the 2022 nordic human-computer interaction conference
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9448-2
ER  - 

TY  - BOOK
TI  - DIS '25 companion: Companion publication of the 2025 ACM designing interactive systems conference
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1486-3
ER  - 

TY  - BOOK
TI  - MuC '22: Proceedings of mensch und computer 2022
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9690-5
ER  - 

TY  - BOOK
TI  - SA '24: SIGGRAPH asia 2024 technical communications
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1140-4
ER  - 

TY  - CONF
TI  - Integrating agents into virtual worlds
AU  - Peters, Ralph
AU  - Graeff, Andreas
AU  - Paul, Christian
T3  - Npiv '97
C1  - Las Vegas, Nevada, USA
C3  - Proceedings of the 1997 workshop on new paradigms in information visualization and manipulation
DA  - 1997///
PY  - 1997
DO  - 10.1145/275519.275535
SP  - 69
EP  - 74
PB  - Association for Computing Machinery
SN  - 1-58113-051-1
UR  - https://doi.org/10.1145/275519.275535
KW  - architecture
KW  - cooperation
KW  - integration
KW  - software agents
KW  - usability
KW  - virtual collaborative environment
ER  - 

TY  - BOOK
TI  - SIGGRAPH '15: SIGGRAPH 2015: Studio
AB  - The world is becoming more malleable by the day, with new tools, applications, and methods to create, craft, build, and share. At SIGGRAPH 2015, the Studio focuses on disruptive practices in the world of content creation. Along with a renewed emphasis on technology, it presents projects from alternative fields that utilize and build new foundations in computer graphics - particularly those that extend beyond traditional screens and into the physical world - including themed entertainment, location-based installations, projection mapping, and advancements in augmented and virtual reality.
CY  - New York, NY, USA
DA  - 2015///
PY  - 2015
PB  - Association for Computing Machinery
SN  - 978-1-4503-3637-6
ER  - 

TY  - CONF
TI  - Exploiting perception in high-fidelity virtual environments (Additional presentations from the 24th course are available on the citation page)
AU  - Glencross, Mashhuda
AU  - Chalmers, Alan G.
AU  - Lin, Ming C.
AU  - Otaduy, Miguel A.
AU  - Gutierrez, Diego
T3  - Siggraph '06
AB  - The objective of this course is to provide an introduction to the issues that must be considered when building high-fidelity 3D engaging shared virtual environments. The principles of human perception guide important development of algorithms and techniques in collaboration, graphical, auditory, and haptic rendering. We aim to show how human perception is exploited to achieve realism in high fidelity environments within the constraints of available finite computational resources.In this course we address the challenges faced when building such high-fidelity engaging shared virtual environments, especially those that facilitate collaboration and intuitive interaction. We present real applications in which such high-fidelity is essential. With reference to these, we illustrate the significant need for the combination of high-fidelity graphics in real time, better modes of interaction, and appropriate collaboration strategies.After introducing the concept of high-fidelity virtual environments and why these convey important information to the user, we cover the main issues in two parts linked by the common thread of exploiting human perception. First we explore perceptually driven techniques that can be employed to achieve high-fidelity graphical rendering in real-time, and how incorporating authentic lighting effects helps to convey a sense of realism and scale in virtual re-constructions of historical sites.Secondly, we examine how intuitive interaction between participants, and with objects in the environment, also plays a key role in the overall experience. How perceptual methods can be used to guide interest management and distribution choices, is considered with an emphasis on avoiding potential pitfalls when distributing physically-based simulations. An analysis of real network conditions and the implications of these for distribution strategies that facilitate collaboration is presented. Furthermore, we describe technologies necessary to provide intuitive interaction in virtual environments, paying particular attention to engaging multiple sensory modalities, primarily through physically-based sound simulation and perceptually high-fidelity haptic interaction.The combination of realism and intuitive compelling interaction can lead to engaging virtual environments capable of exhibiting skills transfer, an illusive goal of many virtual environment applications.
C1  - Boston, Massachusetts
C3  - ACM SIGGRAPH 2006 courses
DA  - 2006///
PY  - 2006
DO  - 10.1145/1185657.1185814
SP  - 1
EP  - es
PB  - Association for Computing Machinery
SN  - 1-59593-364-6
UR  - https://doi.org/10.1145/1185657.1185814
KW  - virtual reality
KW  - perception
KW  - human-computer interaction
KW  - haptics
KW  - multi-user
KW  - collaborative environments
KW  - high-fidelity rendering
KW  - networked applications
ER  - 

TY  - BOOK
TI  - CHI '24: Proceedings of the 2024 CHI conference on human factors in computing systems
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0330-0
ER  - 

TY  - BOOK
TI  - CHI '21: Proceedings of the 2021 CHI conference on human factors in computing systems
CY  - New York, NY, USA
DA  - 2021///
PY  - 2021
PB  - Association for Computing Machinery
SN  - 978-1-4503-8096-6
ER  - 

TY  - BOOK
TI  - AHs '23: Proceedings of the augmented humans international conference 2023
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 978-1-4503-9984-5
ER  - 

TY  - BOOK
TI  - Academic mindtrek '22: Proceedings of the 25th international academic mindtrek conference
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9955-5
ER  - 

TY  - BOOK
TI  - MuC '24: Proceedings of mensch und computer 2024
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0998-2
ER  - 

TY  - CONF
TI  - Applying electric field sensing to human-computer interfaces
AU  - Zimmerman, Thomas G.
AU  - Smith, Joshua R.
AU  - Paradiso, Joseph A.
AU  - Allport, David
AU  - Gershenfeld, Neil
T3  - Chi '95
C1  - Denver, Colorado, USA
C3  - Proceedings of the SIGCHI conference on human factors in computing systems
DA  - 1995///
PY  - 1995
DO  - 10.1145/223904.223940
SP  - 280
EP  - 287
PB  - ACM Press/Addison-Wesley Publishing Co.
SN  - 0-201-84705-1
UR  - https://doi.org/10.1145/223904.223940
ER  - 

TY  - BOOK
TI  - SA '17: SIGGRAPH asia 2017 symposium on education
AB  - The SIGGRAPH Asia Symposium on Education program will be inviting experts from both academia and the industry to present innovative research, methods and positions about the teaching and integration of computer graphics and interactive techniques in all areas of learning.This year's main conference theme is "The Celebration of Life and Technology." We view education as a natural part of the lifelong learning process. We wish to support the evolving integration of art and technology embraced by educators.As an international gathering of industry professionals and academics, the Symposium on Education will present perspectives that appeal to a wide spectrum of interests. We will share educational strategies adopted in both industry and academia to make the learning process more satisfying, productive, and meaningful.
CY  - New York, NY, USA
DA  - 2017///
PY  - 2017
PB  - Association for Computing Machinery
SN  - 978-1-4503-5409-7
ER  - 

TY  - BOOK
TI  - NordiCHI '22: Nordic human-computer interaction conference
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9699-8
ER  - 

TY  - BOOK
TI  - ICMI '23: Proceedings of the 25th international conference on multimodal interaction
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0055-2
ER  - 

TY  - BOOK
TI  - Web3D '25: Proceedings of the 30th international conference on 3D web technology
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-2038-3
ER  - 

TY  - BOOK
TI  - SA '15: SIGGRAPH asia 2015 emerging technologies
CY  - New York, NY, USA
DA  - 2015///
PY  - 2015
PB  - Association for Computing Machinery
SN  - 978-1-4503-3925-4
ER  - 

TY  - BOOK
TI  - ICVARS '23: Proceedings of the 2023 7th international conference on virtual and augmented reality simulations
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 978-1-4503-9746-9
ER  - 

TY  - CONF
TI  - MaxwellWorld: learning complex scientific concepts via immersion in virtual reality
AU  - Dede, Chris
AU  - Salzman, Marilyn C.
AU  - Loftin, R. Bowen
T3  - Icls '96
AB  - Subjects such as electrostatics are difficult to teach in part because learners cannot draw analogies to personal experiences that provide metaphors. MaxwellWorld has been designed to allow students to explore electrostatic forces and fields, learn about the concept of electric potential, and "discover" the nature of electric flux. In formative assessments of MaxwellWorld's usability and learnability, students enjoyed learning about electric fields and cited the 3-D representations, the interactivity, the ability to navigate to multiple perspectives, and the use of color as characteristics that were important to their learning experience. Pre- and post-lesson evaluations show that students had a greater understanding of the distribution of forces in an electric field, as well as representations such as test charge traces and field lines. Our studies also indicate that the three-dimensional nature of VR aids with learning and that the virtual reality experience is more motivating for students than a comparable 2-D microworld.
C1  - Evanston, Illinois
C3  - Proceedings of the 1996 international conference on learning sciences
DA  - 1996///
PY  - 1996
SP  - 22
EP  - 29
PB  - International Society of the Learning Sciences
SN  - 1-880094-23-1
ER  - 

TY  - BOOK
TI  - AutomotiveUI '24 adjunct: Adjunct proceedings of the 16th international conference on automotive user interfaces and interactive vehicular applications
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0520-5
ER  - 

TY  - BOOK
TI  - NordiCHI '24 adjunct: Adjunct proceedings of the 2024 nordic conference on human-computer interaction
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0965-4
ER  - 

TY  - BOOK
TI  - GI '24: Proceedings of the 50th graphics interface conference
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1828-1
ER  - 

TY  - BOOK
TI  - MuC '25: Proceedings of the mensch und computer 2025
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1582-2
ER  - 

TY  - BOOK
TI  - UbiComp/ISWC '22 adjunct: Adjunct proceedings of the 2022 ACM international joint conference on pervasive and ubiquitous computing and the 2022 ACM international symposium on wearable computers
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9423-9
ER  - 

TY  - BOOK
TI  - MobileHCI '24 adjunct: Adjunct proceedings of the 26th international conference on mobile human-computer interaction
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0506-9
ER  - 

TY  - BOOK
TI  - MUM '23: Proceedings of the 22nd international conference on mobile and ubiquitous multimedia
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0921-0
ER  - 

TY  - BOOK
TI  - MobileHCI '22: Adjunct publication of the 24th international conference on human-computer interaction with mobile devices and services
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9341-6
ER  - 

TY  - BOOK
TI  - ICCSIE '24: Proceedings of the 2024 9th international conference on cyber security and information engineering
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1813-7
ER  - 

TY  - BOOK
TI  - IDC '24: Proceedings of the 23rd annual ACM interaction design and children conference
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0442-0
ER  - 

TY  - BOOK
TI  - TEI '24: Proceedings of the eighteenth international conference on tangible, embedded, and embodied interaction
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0402-4
ER  - 

TY  - BOOK
TI  - OzCHI '21: Proceedings of the 33rd australian conference on human-computer interaction
CY  - New York, NY, USA
DA  - 2021///
PY  - 2021
PB  - Association for Computing Machinery
SN  - 978-1-4503-9598-4
ER  - 

TY  - BOOK
TI  - ASSETS '24: Proceedings of the 26th international ACM SIGACCESS conference on computers and accessibility
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0677-6
ER  - 

TY  - BOOK
TI  - CHI PLAY companion '24: Companion proceedings of the 2024 annual symposium on computer-human interaction in play
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0692-9
ER  - 

TY  - BOOK
TI  - ICMI '23 companion: Companion publication of the 25th international conference on multimodal interaction
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0321-8
ER  - 

TY  - BOOK
TI  - AIR '23: Proceedings of the 2023 6th international conference on advances in robotics
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 978-1-4503-9980-7
ER  - 

TY  - BOOK
TI  - IMX '24: Proceedings of the 2024 ACM international conference on interactive media experiences
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0503-8
ER  - 

TY  - BOOK
TI  - SVR '23: Proceedings of the 25th symposium on virtual and augmented reality
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0943-2
ER  - 

TY  - BOOK
TI  - IDC '23: Proceedings of the 22nd annual ACM interaction design and children conference
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0131-3
ER  - 

TY  - BOOK
TI  - Weaving fire into form: Aspirations for tangible and embodied interaction
AU  - Ullmer, Brygg
AU  - Shaer, Orit
AU  - Mazalek, Ali
AU  - Hummels, Caroline
AB  - This book investigates multiple facets of the emerging discipline of Tangible, Embodied, and Embedded Interaction (TEI). This is a story of atoms and bits. We explore the interweaving of the physical and digital, toward understanding some of their wildly varying hybrid forms and behaviors. Spanning conceptual, philosophical, cognitive, design, and technical aspects of interaction, this book charts both history and aspirations for the future of TEI. We examine and celebrate diverse trailblazing works, and provide wide-ranging conceptual and pragmatic tools toward weaving the animating fires of computation and technology into evocative tangible forms. We also chart a path forward for TEI engagement with broader societal and sustainability challenges that will profoundly (re)shape our children’s and grandchildren’s futures. We invite you all to join this quest.
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
ET  - 1
VL  - 44
PB  - Association for Computing Machinery
SN  - 978-1-4503-9769-8
ER  - 

TY  - BOOK
TI  - FDG '25: Proceedings of the 20th international conference on the foundations of digital games
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1856-4
ER  - 

TY  - BOOK
TI  - SIGGRAPH '15: ACM SIGGRAPH 2015 posters
AB  - Posters are a convenient method for presenting in-progress research, student projects, and late-breaking work. Poster topics range from applications of computer graphics to in-depth research in specific areas. New this year, SIGGRAPH posters will be presented on video monitors in an electronic format only. Poster authors meet and discuss their work with attendees during Poster Presentations.
CY  - New York, NY, USA
DA  - 2015///
PY  - 2015
PB  - Association for Computing Machinery
SN  - 978-1-4503-3632-1
ER  - 

TY  - BOOK
TI  - MMSys '24: Proceedings of the 15th ACM multimedia systems conference
AB  - Dear MMSys 2024 Participants,On behalf of the organizers, we are very pleased to welcome you to the 15th ACM Multimedia Systems Conference, taking place for the first time in Italy, in the city of Bari.MMSys is a premier conference dedicated to the exciting and multidisciplinary field of multimedia, with a specific focus on its systems and applications. The conference provides a platform for researchers from both academia and industry to share their latest findings in the multimedia systems research area. Many international researchers, practitioners, engineers, and students from academia, industry, standardization bodies, and government agencies join the MMSys conference each year.
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0412-3
ER  - 

TY  - BOOK
TI  - HAI '22: Proceedings of the 10th international conference on human-agent interaction
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9323-2
ER  - 

TY  - BOOK
TI  - IVA '23: Proceedings of the 23rd ACM international conference on intelligent virtual agents
AB  - This volume contains the papers presented at the 23nd International Conference on Intelligent Virtual Agents (IVA 2023) located in Würzburg, Germany, from 19. to 22.09.2023.
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 978-1-4503-9994-4
ER  - 

TY  - BOOK
TI  - NordiCHI '24: Proceedings of the 13th nordic conference on human-computer interaction
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0966-1
ER  - 

TY  - BOOK
TI  - ICMI '22: Proceedings of the 2022 international conference on multimodal interaction
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9390-4
ER  - 

TY  - BOOK
TI  - DIS '25: Proceedings of the 2025 ACM designing interactive systems conference
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1485-6
ER  - 

TY  - BOOK
TI  - CSCW '17: Proceedings of the 2017 ACM conference on computer supported cooperative work and social computing
AB  - Welcome to CSCW 2017, the ACM 2017 Conference on Computer Supported Cooperative Work and Social Computing! We are excited to welcome the CSCW community back to Portland, Oregon, where the second CSCW conference was held in 1988. Both Portland and CSCW have matured a great deal during the intervening 29 years. We hope that you will find that Portland provides a stimulating environment for our conference.CSCW is the premier venue for presenting research in the design and use of technologies that affect groups, organizations, communities, and networks. Bringing together top researchers and practitioners from academia and industry, CSCW explores the technical, social, material, and theoretical challenges of designing technology to support collaborative work and life activities. CSCW welcomes a diverse range of topics and research methodologies. Studies often involve the development and application of novel technologies and/or ethnographic studies that inform design practice or theory. The mission of the conference is to share research that advances the state of human knowledge and improves both the design of systems and the ways they are used. The diversity of work in our conference program reflects the diversity of technology use in people's work, social, and civic lives as well as the geographic and cultural diversity of contributors.As many of you know, CSCW follows a rigorous "revise and resubmit" review process that uses peer review to improve submitted papers while maintaining a high-quality threshold for final acceptance. We also help prepare the next generation of reviewers with a mentorship program in which students review papers under the guidance of an experienced reviewer. This year we have the largest CSCW program ever. We had 530 submitted papers and 183 were accepted for presentation at the conference. The program also includes 4 papers published in ACM Transactions on Human- Computer Interaction (TOCHI). In addition, we will feature 14 workshops, 56 posters, 12 demos, and 3 panels.Lili Cheng of Microsoft Research will open the conference, speaking on "Conversational AI &amp; Lessons Learned." Our closing plenary will feature Jorge Cham, the creator of PhD Comics, who will talk about, "The Science Gap." We also welcome Paul Luff and Christian Heath from King's College as the recipients of this year's CSCW Lasting Impact award for their influential 1998 paper, "Mobility in Collaboration."
CY  - New York, NY, USA
DA  - 2017///
PY  - 2017
PB  - Association for Computing Machinery
SN  - 978-1-4503-4335-0
ER  - 

TY  - BOOK
TI  - CSCW companion '24: Companion publication of the 2024 conference on computer-supported cooperative work and social computing
AB  - Welcome to the 27th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW 2024). This year's conference is particularly special, as it marks the first time CSCW to be held in Latin America - a highly anticipated milestone for our Latin American community. We are excited to gather in San Jose, Costa Rica, and host a hybrid event that allows remote participation from community members worldwide.As in previous years, CSCW 2024 brings together a variety of disciplines, from system design to critical analysis, to propose, examine, and reimagine technologies that support groups and communities. As our discipline evolves, new topics continuously emerge and are embraced by our community. This year, we see an emphasis on issues centered around AI, including explainability, fairness, and AI-human collaboration. At the same time, our long-standing concerns remain well represented, including work on group dynamics and decision-making, social media, inclusive and culturally aware design, co-design with marginalized communities, and the creation of socially responsible tools. This year, we invited 387 PACM-HCI, TSC, and TOCHI papers to be presented alongside a diverse lineup of workshops, posters, demos, SIGs, panels, and the doctoral consortium. Below are the numbers of reviewed and accepted submissions for each track featured in this conference companion.
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1114-5
ER  - 

TY  - BOOK
TI  - The handbook of multimodal-multisensor interfaces: Language processing, software, commercialization, and emerging directions
A3  - Oviatt, Sharon
A3  - Schuller, Björn
A3  - Cohen, Philip R.
A3  - Sonntag, Daniel
A3  - Potamianos, Gerasimos
A3  - Krüger, Antonio
AB  - The Handbook of Multimodal-Multisensor Interfaces provides the first authoritative resource on what has become the dominant paradigm for new computer interfaces—user input involving new media (speech, multi-touch, hand and body gestures, facial expressions, writing) embedded in multimodal-multisensor interfaces.This three-volume handbook is written by international experts and pioneers in the field. It provides a textbook, reference, and technology roadmap for professionals working in this and related areas.This third volume focuses on state-of-the-art multimodal language and dialogue processing, including semantic integration of modalities. The development of increasingly expressive embodied agents and robots has become an active test-bed for coordinating multimodal dialogue input and output, including processing of language and nonverbal communication. In addition, major application areas are featured for commercializing multimodal-multisensor systems, including automotive, robotic, manufacturing, machine translation, banking, communications, and others. These systems rely heavily on software tools, data resources, and international standards to facilitate their development. For insights into the future, emerging multimodal-multisensor technology trends are highlighted for medicine, robotics, interaction with smart spaces, and similar topics. Finally, this volume discusses the societal impact of more widespread adoption of these systems, such as privacy risks and how to mitigate them. The handbook chapters provide a number of walk-through examples of system design and processing, information on practical resources for developing and evaluating new systems, and terminology and tutorial support for mastering this emerging field. In the final section of this volume, experts exchange views on a timely and controversial challenge topic, and how they believe multimodal-multisensor interfaces need to be equipped to most effectively advance human performance during the next decade.
DA  - 2019///
PY  - 2019
PB  - Association for Computing Machinery and Morgan &amp; Claypool
SN  - 978-1-970001-75-4
ER  - 

TY  - BOOK
TI  - TAS '24: Proceedings of the second international symposium on trustworthy autonomous systems
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0989-0
ER  - 

TY  - BOOK
TI  - SA '14: SIGGRAPH asia 2014 mobile graphics and interactive applications
CY  - New York, NY, USA
DA  - 2014///
PY  - 2014
PB  - Association for Computing Machinery
SN  - 978-1-4503-1891-4
ER  - 

TY  - BOOK
TI  - ASSETS '23: Proceedings of the 25th international ACM SIGACCESS conference on computers and accessibility
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0220-4
ER  - 

TY  - BOOK
TI  - PETRA '24: Proceedings of the 17th international conference on pervasive technologies related to assistive environments
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1760-4
ER  - 

TY  - BOOK
TI  - Interacción '23: Proceedings of the XXIII international conference on human computer interaction
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0790-2
ER  - 

TY  - BOOK
TI  - ICMI '16: Proceedings of the 18th ACM international conference on multimodal interaction
CY  - New York, NY, USA
DA  - 2016///
PY  - 2016
PB  - Association for Computing Machinery
SN  - 978-1-4503-4556-9
ER  - 

TY  - BOOK
TI  - SVR '24: Proceedings of the 26th symposium on virtual and augmented reality
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0979-1
ER  - 

TY  - BOOK
TI  - ISEC '23: Proceedings of the 16th innovations in software engineering conference
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0064-4
ER  - 

TY  - BOOK
TI  - CHCHI '23: Proceedings of the eleventh international symposium of chinese CHI
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-1645-4
ER  - 

TY  - BOOK
TI  - MIG '23: Proceedings of the 16th ACM SIGGRAPH conference on motion, interaction and games
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0393-5
ER  - 

TY  - BOOK
TI  - The handbook on socially interactive agents: 20 years of research on embodied conversational agents, intelligent virtual agents, and social robotics volume 2: Interactivity, platforms, application
A3  - Lugrin, Birgit
A3  - Pelachaud, Catherine
A3  - Traum, David
AB  - The Handbook on Socially Interactive Agents provides a comprehensive overview of the research fields of Embodied Conversational Agents, Intelligent Virtual Agents, and Social Robotics. Socially Interactive Agents (SIAs), whether virtually or physically embodied, are autonomous agents that are able to perceive an environment including people or other agents, reason, and decide how to interact, and express attitudes such as emotions, engagement, or empathy. They are capable of interacting with people and each other in a socially intelligent manner using multimodal communicative behaviors with the goal to support humans in various domains.Written by international experts in their respective fields, the book summarizes research in the many important research communities pertinent for SIAs, while discussing current challenges and future directions. The handbook provides easy access to modeling and studying SIAs for researchers and students and aims at further bridging the gap between the research communities involved.In two volumes, the book clearly structures the vast body of research. The first volume starts by introducing what is involved in SIAs research, in particular research methodologies and ethical implications of developing SIAs. It further examines research on appearance and behavior, focusing on multimodality. Finally, social cognition for SIAs is investigated by different theoretical models and phenomena such as theory of mind or pro-sociality. The second volume starts with perspectives on interaction, examined from different angles such as interaction in social space, group interaction, or long-term interaction. It also includes an extensive overview summarizing research and systems of human-agent platforms and of some of the major application areas of SIAs such as education, aging support, autism or games.
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
ET  - 1
VL  - 48
PB  - Association for Computing Machinery
SN  - 978-1-4503-9896-1
ER  - 

TY  - BOOK
TI  - ICEMT '24: Proceedings of the 2024 8th international conference on education and multimedia technology
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1761-1
ER  - 

TY  - BOOK
TI  - ICETC '24: Proceedings of the 2024 16th international conference on education technology and computers
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1781-9
ER  - 

TY  - BOOK
TI  - C&amp;C '23: Proceedings of the 15th conference on creativity and cognition
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0180-1
ER  - 

TY  - BOOK
TI  - ICEMT '23: Proceedings of the 7th international conference on education and multimedia technology
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0914-2
ER  - 

TY  - BOOK
TI  - DSAI '24: Proceedings of the 11th international conference on software development and technologies for enhancing accessibility and fighting info-exclusion
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0729-2
ER  - 

TY  - BOOK
TI  - Mindtrek '23: Proceedings of the 26th international academic mindtrek conference
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0874-9
ER  - 

TY  - BOOK
TI  - IUI '23 companion: Companion proceedings of the 28th international conference on intelligent user interfaces
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0107-8
ER  - 

TY  - BOOK
TI  - HAI '24: Proceedings of the 12th international conference on human-agent interaction
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1178-7
ER  - 

TY  - BOOK
TI  - COMPASS '25: Proceedings of the 2025 ACM SIGCAS/SIGCHI conference on computing and sustainable societies
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1484-9
ER  - 

TY  - BOOK
TI  - SIGGRAPH '17: ACM SIGGRAPH 2017 talks
AB  - Talks highlight the latest developments before publication, present ideas that are still in progress, or showcase how computer graphics and interactive techniques are actually implemented and used, in graphics production or other fields. Talks take you behind the scenes and into the minds of SIGGRAPH 2017 creators in all areas of computer graphics and interactive techniques, including art, design, animation, visual effects, interactivity, research, and engineering.
CY  - New York, NY, USA
DA  - 2017///
PY  - 2017
PB  - Association for Computing Machinery
SN  - 978-1-4503-5008-2
ER  - 

TY  - BOOK
TI  - MMSys '23: Proceedings of the 14th ACM multimedia systems conference
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0148-1
ER  - 

TY  - BOOK
TI  - VINCI '23: Proceedings of the 16th international symposium on visual information communication and interaction
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0751-3
ER  - 

TY  - BOOK
TI  - SIGGRAPH conference papers '25: Proceedings of the special interest group on computer graphics and interactive techniques conference conference papers
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1540-2
ER  - 

TY  - BOOK
TI  - ADMIT '24: Proceedings of the 2024 3rd international conference on algorithms, data mining, and information technology
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1812-0
ER  - 

TY  - BOOK
TI  - ICCTA '22: Proceedings of the 2022 8th international conference on computer technology applications
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9622-6
ER  - 

TY  - BOOK
TI  - GoodIT '23: Proceedings of the 2023 ACM conference on information technology for social good
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0116-0
ER  - 

TY  - BOOK
TI  - EuroPLop '22: Proceedings of the 27th european conference on pattern languages of programs
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9594-6
ER  - 

TY  - BOOK
TI  - IDC '25: Proceedings of the 24th interaction design and children
CY  - New York, NY, USA
DA  - 2025///
PY  - 2025
PB  - Association for Computing Machinery
SN  - 979-8-4007-1473-3
ER  - 

TY  - BOOK
TI  - OzCHI '23: Proceedings of the 35th australian computer-human interaction conference
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-1707-9
ER  - 

TY  - BOOK
TI  - ISAIE '24: Proceedings of the 2024 international symposium on artificial intelligence for education
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0710-0
ER  - 

TY  - BOOK
TI  - TAS '23: Proceedings of the first international symposium on trustworthy autonomous systems
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0734-6
ER  - 

TY  - BOOK
TI  - PCI '22: Proceedings of the 26th pan-hellenic conference on informatics
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9854-1
ER  - 

TY  - BOOK
TI  - SA '23: SIGGRAPH asia 2023 conference papers
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
PB  - Association for Computing Machinery
SN  - 979-8-4007-0315-7
ER  - 

TY  - BOOK
TI  - MM '24: Proceedings of the 32nd ACM international conference on multimedia
AB  - We are delighted to welcome you to Melbourne, Australia for ACM Multimedia 2024, the 32nd ACM International Conference on Multimedia. ACM Multimedia is the premier international conference series in the area of multimedia within the field of computer science. Since 1993, ACM Multimedia has been bringing together worldwide researchers and practitioners from academia and industry to present their innovative research and to discuss recent advancements in multimedia.For the first time since the end of the COVID-19 pandemic, this year's conference returns to the Asia-Pacific region and resumes as a full-fledged, inperson event. With no travel restrictions or significant visa challenges, we are excited to once again experience the warmth of face-to-face gatherings, where we can reconnect with colleagues and friends.The enthusiasm and support from the community have been incredible. ACM Multimedia 2024 received over 4,300 main conference submissions, accepting more than 1,100 papers (please refer to the TPC Chairs' message for details). In addition, 10 Grand Challenges were selected from 22 submissions, 18 workshops from 30 submissions, and 8 tutorials from 13 proposals. We've prepared an exciting five-day program: workshops, grand challenges, and tutorials will be held on the 1st and 5th days, with the main conference occupying the middle three days. All accepted papers will be accessible online prior to the conference, and we are working to ensure proceedings are available through the ACM Digital Library around the conference period.This year's conference features three distinguished academic keynote speeches, several prestigious SIGMM award talks, a panel discussion on Generative AI in Multimedia, a refreshed Brave New Idea (BNI) session, and our inaugural industry program.The opening keynote will be delivered by Prof. Pascale Fung from HKUST, a Fellow of AAAI, ACL, and IEEE. Her talk will explore the pressing topic of Agents in the Large Language Model (LLM) Era. Prof. Judy Kay from the University of Sydney, a renowned expert in HCI, user modeling, and ubiquitous computing, will give the second keynote on how to empower individuals to harness and control their multimodal data. The final academic keynote will be presented by Prof. Jiebo Luo from the University of Rochester, a Fellow of ACM, AAAI, IEEE, SPIE, and IAPR, as well as a member of Academia Europaea and the US National Academy of Inventors. He will discuss leveraging LLMs as social multimedia analysis engines.This year, we continue using OpenReview to ensure an open and transparent review process. Thanks to the exceptional efforts of the technical program committee, every paper received at least three reviews before the review announcement. The BNI track has also revamped its review process to align with the main conference, promoting visionary papers. Additionally, we are excited to introduce the industry program to ACM Multimedia for the first time, featuring industry keynote speeches, expert talks, and demonstrations (please refer to the industry chairs' message for further details).We are also committed to making the conference inclusive and accessible. To support students with financial constraints, we have awarded travel grants to at least 25 students from the ACM Multimedia 2024 budget, with an additional 20+ students receiving SIGMM travel grants. Over 20 local students have also been recruited as volunteers, benefiting from complimentary registration. Furthermore, we have arranged childcare facilities to accommodate attendees with young children. A welcome reception will take place on the 2nd day of the conference, followed by a gala dinner on the 3rd day, featuring exciting cultural performances.We hope you find this year's program engaging and thought-provoking and that it offers valuable opportunities to exchange ideas with fellow researchers and practitioners from around the globe. We also encourage you to take time to explore the beautiful city of Melbourne and its surrounding regions.
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0686-8
ER  - 

TY  - BOOK
TI  - dg.o '24: Proceedings of the 25th annual international conference on digital government research
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-0988-3
ER  - 

TY  - BOOK
TI  - LAK '24: Proceedings of the 14th learning analytics and knowledge conference
CY  - New York, NY, USA
DA  - 2024///
PY  - 2024
PB  - Association for Computing Machinery
SN  - 979-8-4007-1618-8
ER  - 

TY  - BOOK
TI  - SenSys '22: Proceedings of the 20th ACM conference on embedded networked sensor systems
AB  - Welcome to ACM SenSys 2022, the 20th ACM Conference on Embedded Networked Sensor Systems, the premier computer systems conference focused on networked sensing systems and applications.
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
PB  - Association for Computing Machinery
SN  - 978-1-4503-9886-2
ER  - 

