TY  - JOUR
AB  - Remote collaboration systems have become increasingly important in tod
ay’s society, especially during times when physical distancing is advi
sed. Industry, research, and individuals face the challenging task of 
collaborating and networking over long distances. While video and tele
conferencing are already widespread, collaboration systems in augmente
d, virtual, and mixed reality are still a niche technology. We provide
 an overview of recent developments of synchronous remote collaboratio
n systems and create a taxonomy by dividing them into three main compo
nents that form such systems: Environment, Avatars, and Interaction. A
 thorough overview of existing systems is given, categorising their ma
in contributions to help researchers working in different fields by pr
oviding concise information about specific topics such as avatars, vir
tual environment, visualisation styles, and interaction. The focus of 
this work is clearly on synchronised collaboration from a distance. A 
total of 87 unique systems for remote collaboration are discussed, inc
luding more than 100 publications and 25 commercial systems.
AU  - Schäfer, Alexander
AU  - Reis, Gerd
AU  - Stricker, Didier
DA  - 2022/12//
PY  - 2022
DO  - 10.1145/3533376
ID  - 10.1145/3533376
IS  - 6
KW  - literature review
KW  - distant cooperation
KW  - remote assistance
KW  - collaboration
KW  - mixed reality
KW  - augmented reality
KW  - Virtual reality
SN  - 0360-0300
T2  - ACM Comput. Surv.
TI  - A Survey on Synchronous Augmented, Virtual, andMixed Reality Remote Co
llaboration Systems
UR  - https://doi.org/10.1145/3533376
VL  - 55
ER  - 
TY  - CONF
AB  - This paper introduces HoloBots, a mixed reality remote collaboration s
ystem that augments holographic telepresence with synchronized mobile 
robots. Beyond existing mixed reality telepresence, HoloBots lets remo
te users not only be visually and spatially present, but also physical
ly engage with local users and their environment. HoloBots allows the 
users to touch, grasp, manipulate, and interact with the remote physic
al environment as if they were co-located in the same shared space. We
 achieve this by synchronizing holographic user motion (Hololens 2 and
 Azure Kinect) with tabletop mobile robots (Sony Toio). Beyond the exi
sting physical telepresence, HoloBots contributes to an exploration of
 broader design space, such as object actuation, virtual hand physical
ization, world-in-miniature exploration, shared tangible interfaces, e
mbodied guidance, and haptic communication. We evaluate our system wit
h twelve participants by comparing it with hologram-only and robot-onl
y conditions. Both quantitative and qualitative results confirm that o
ur system significantly enhances the level of co-presence and shared e
xperience, compared to the other conditions.
AU  - Ihara, Keiichi
AU  - Faridan, Mehrad
AU  - Ichikawa, Ayumi
AU  - Kawaguchi, Ikkaku
AU  - Suzuki, Ryo
C1  - San Francisco, CA, USA
C3  - Proceedings of the 36th Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2023///
C2  - 2023
DO  - 10.1145/3586183.3606727
ID  - 10.1145/3586183.3606
KW  - Actuated Tangible UI;
KW  - Mixed Reality
KW  - Mobile Robots
KW  - Physical Telepresence
KW  - Remote Collaboration
PB  - Association for Computing Machinery
SN  - 9798400701320
T3  - UIST '23
TI  - HoloBots: Augmenting Holographic Telepresence with Mobile Robots for T
angible Remote Collaboration in Mixed Reality
UR  - https://doi.org/10.1145/3586183.3606727
ER  - 
TY  - JOUR
AB  - This article examines the attentional mechanism of in-person collabora
tion by means of System Dynamics-based simulations using an eye tracki
ng experiment. Three experimental conditions were tested: in-person co
llaboration, remote collaboration, and single user. We hypothesized th
at collaboration focuses users’ attention on key information facilitat
ing decision-making. Collaborating participants dwelt longer on key el
ements of the simulation than single users. Moreover, in-person collab
oration and single users yielded a strategy of decision-making similar
 to an optimal strategy. Finally, in-person collaboration was less cog
nitively demanding and of higher quality. The contribution of this art
icle is a deeper understanding of how in-person collaboration on a lar
ge display can help users focus their visual attention on the most imp
ortant areas. With this novel understanding, we believe collaborative 
systems designers will be better equipped to design more effective att
ention-guiding mechanisms in remote collaboration systems. The present
 work has the potential to advance the study of collaborative, interac
tive technologies.
AU  - Wisiecka, Katarzyna
AU  - Konishi, Yuumi
AU  - Krejtz, Krzysztof
AU  - Zolfaghari, Mahshid
AU  - Kopainsky, Birgit
AU  - Krejtz, Izabela
AU  - Koike, Hideki
AU  - Fjeld, Morten
DA  - 2023/9//
PY  - 2023
DO  - 10.1145/3581787
ID  - 10.1145/3581787
IS  - 5
KW  - natural resource management
KW  - eye tracking
KW  - collaboration
KW  - visual attention
KW  - System dynamics simulation
SN  - 1073-0516
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - Supporting Complex Decision-Making: Evidence from an Eye Tracking Stud
y on In-Person and Remote Collaboration
UR  - https://doi.org/10.1145/3581787
VL  - 30
ER  - 
TY  - JOUR
AB  - Current times are accelerating new technologies to provide high-qualit
y education for remote collaboration, as well as hands-on learning. Th
is is particularly important in the case of laboratory-based classes, 
which play an essential role in STEM education. In this paper, we intr
oduce ColabAR, a toolkit that uses physical proxies to manipulate virt
ual objects in Tangible Augmented Reality (TAR) laboratories. ColabAR 
introduces haptic-based customizable interaction techniques to promote
 remote collaboration between students. Our toolkit provides hardware 
and software that enable haptic feedback to improve user experience an
d promote collaboration during learning. Also, we present the architec
ture of our cloud platform for haptic interaction that supports inform
ation sharing between students in a TAR laboratory. We performed two u
ser studies (N=40) to test the effect of our toolkit in enriching loca
l and remote collaborative experiences. Finally, we demonstrated that 
our TAR laboratory enables students' performance (i.e., lab completion
 rate, lab scores) to be similar to their performance in an in-person 
laboratory.
AU  - Villanueva, Ana
AU  - Zhu, Zhengzhe
AU  - Liu, Ziyi
AU  - Wang, Feiyang
AU  - Chidambaram, Subramanian
AU  - Ramani, Karthik
DA  - 2022/4//
PY  - 2022
DO  - 10.1145/3512928
ID  - 10.1145/3512928
IS  - CSCW1
KW  - tangibles
KW  - remote
KW  - learning
KW  - laboratory
KW  - haptics
KW  - education
KW  - distance
KW  - collaboration
KW  - augmented reality
KW  - STEM
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - ColabAR: A Toolkit for Remote Collaboration in Tangible Augmented Real
ity Laboratories
UR  - https://doi.org/10.1145/3512928
VL  - 6
ER  - 
TY  - CONF
AB  - Augmented reality (AR) is poised to transform remote communication wit
h realistic user representations authentically simulating in-person in
teractions in one’s own environment. While increased avatar realism is
 beneficial in various social contexts, as it generally fosters social
 presence, its impact in intimate interactions is less clear, possibly
 creating discomfort. We explored how varying avatar realism affects s
ocial presence and comfort in AR across different social interactions.
 Realism preferences were established in an online survey (N=157), inf
orming our subsequent experiment (N=42). Participants engaged in remot
e AR collaboration and self-disclosure tasks with avatars ranging from
 abstract to realistic point-cloud. Quantitative and qualitative feedb
ack revealed that higher avatar realism generally enhances social pres
ence and comfort, though preferences can vary. The self-disclosure tas
k increased social presence but reduced comfort compared to the collab
oration task. This research provides an empirical analysis of avatar r
ealism, highlighting the benefits of realistic avatars in various scen
arios.
AU  - Kaiser, Jonah-Noël
AU  - Kimmel, Simon
AU  - Licht, Eva
AU  - Landwehr, Eric
AU  - Hemmert, Fabian
AU  - Heuten, Wilko
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713541
ID  - 10.1145/3706598.3713
KW  - augmented reality
KW  - social presence
KW  - user-representation
KW  - avatar realism
KW  - collaboration
KW  - self-disclosure
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Get Real With Me: Effects of Avatar Realism on Social Presence and Com
fort in Augmented Reality Remote Collaboration and Self-Disclosure
UR  - https://doi.org/10.1145/3706598.3713541
ER  - 
TY  - CONF
AB  - Collaborative coding environments foster learning, social skills, comp
utational thinking training, and supportive relationships. In the cont
ext of inclusive education, these environments have the potential to p
romote inclusive learning activities for children with mixed-visual ab
ilities. However, there is limited research focusing on remote collabo
rative environments, despite the opportunity to design new modes of ac
cess and control of content to promote more equitable learning experie
nces. We investigated the tradeoffs between remote and co-located coll
aboration through a tangible coding kit. We asked ten pairs of mixed-v
isual ability children to collaborate in an interdependent and asymmet
ric coding game. We contribute insights on six dimensions - effectiven
ess, computational thinking, accessibility, communication, cooperation
, and engagement - and reflect on differences, challenges, and advanta
ges between collaborative settings related to communication, workspace
 awareness, and computational thinking training. Lastly, we discuss de
sign opportunities of tangibles, audio, roles, and tasks to create inc
lusive learning activities in remote and co-located settings.
AU  - Rocha, Filipa
AU  - Correia, Filipa
AU  - Neto, Isabel
AU  - Pires, Ana Cristina
AU  - Guerreiro, João
AU  - Guerreiro, Tiago
AU  - Nicolau, Hugo
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI Conference on Human Factors in Computing S
ystems
DA  - 2023///
C2  - 2023
DO  - 10.1145/3544548.3581261
ID  - 10.1145/3544548.3581
KW  - Accessible
KW  - Children
KW  - Collaboration
KW  - Computational thinking
KW  - Mixed-visual ability
KW  - Robot
KW  - Tangible
KW  - Visually impaired
PB  - Association for Computing Machinery
SN  - 9781450394215
T3  - CHI '23
TI  - Coding Together: On Co-located and Remote Collaboration between Childr
en with Mixed-Visual Abilities
UR  - https://doi.org/10.1145/3544548.3581261
ER  - 
TY  - CONF
AB  - Drones are increasingly used to support humanitarian crises and events
 that involve dangerous or costly tasks. While drones have great poten
tial for remote collaborative work and aerial telepresence, existing d
rone technology is limited in its support for synchronous collaboratio
n among multiple remote users. Through three design iterations and eva
luations, we prototyped Squadrone, a novel aerial telepresence platfor
m that supports synchronous mid-air collaboration among multiple remot
e users. We present our design and report results from evaluating our 
iterations with 13 participants in 3 different collaboration configura
tions. Our first design iteration validates the basic functionality of
 the platform. Then, we establish the effectiveness of collaboration u
sing a 360-degree shared aerial display. Finally, we simulate a type o
f search task in an open environment to see if collaborative teleprese
nce impacts members’ participation. The results validate some initial 
goals for Squadrone and are used to reflect back on a recent teleprese
nce design framework.
AU  - Sabet, Mehrnaz
AU  - Orand, Mania
AU  - W. McDonald, David
C1  - Yokohama, Japan
C3  - Proceedings of the 2021 CHI Conference on Human Factors in Computing S
ystems
DA  - 2021///
C2  - 2021
DO  - 10.1145/3411764.3445041
ID  - 10.1145/3411764.3445
KW  - User Interface
KW  - UAV
KW  - Telepresence
KW  - Remote collaboration
KW  - Quadcopters
KW  - Drones
KW  - Collaborative work
KW  - Collaborative remote control
PB  - Association for Computing Machinery
SN  - 9781450380966
T3  - CHI '21
TI  - Designing Telepresence Drones to Support Synchronous, Mid-air Remote C
ollaboration: An Exploratory Study
UR  - https://doi.org/10.1145/3411764.3445041
ER  - 
TY  - CONF
AB  - We designed a necklace-style device named HapticPointer for presenting
 a direction as pointing cues in remote collaboration tasks. The devic
e has 16 vibration motors placed along a line of flexible string. Our 
vibration algorithm represents horizontal and vertical directions by c
hanging the position and intensity of each vibration. In our experimen
t, participants attempted to find a specific target, and the accuracy 
of successful trials reached 90.65%. Moreover, the participants found 
the targets in 6 seconds on average. Furthermore, our user study impli
es that the device can simulates the sensation of walking together. It
 is assumed that the sensation improves engagement between the local a
nd remote users.
AU  - Matsuda, Akira
AU  - Nozawa, Kazunori
AU  - Takata, Kazuki
AU  - Izumihara, Atsushi
AU  - Rekimoto, Jun
C1  - Kaiserslautern, Germany
C3  - Proceedings of the Augmented Humans International Conference
DA  - 2020///
C2  - 2020
DO  - 10.1145/3384657.3384777
ID  - 10.1145/3384657.3384
KW  - wearable device
KW  - telepresence
KW  - remote collaboration
KW  - haptic feedback
PB  - Association for Computing Machinery
SN  - 9781450376037
T3  - AHs '20
TI  - HapticPointer: A Neck-worn Device that Presents Direction by Vibrotact
ile Feedback for Remote Collaboration Tasks
UR  - https://doi.org/10.1145/3384657.3384777
ER  - 
TY  - CONF
AB  - In this work, we analyse the effect of network parameters on the judge
d usability of a collaborative virtual environment. Participants were 
trained to find the exit of a virtual maze by a trainer, which guided 
the exploration of the virtual space. An extensive experimental evalua
tion was conducted by simulating a series of operational parameters (n
etwork bandwidth and latency) to assess the reported effectiveness of 
the training. An objective similarity metric based on processing time 
per test was also defined and used, as well as subjective user's evalu
ations. Further, we have successfully correlated subjective evaluation
 and objective measure by computing the correlation values and showing
 how the two values co-vary.
AU  - Rodrigues, Maria Andréia Formico
AU  - Chaves, Ricardo Régis Cavalcante
C1  - Perth, Australia
C3  - Proceedings of the 5th International Conference on Computer Graphics a
nd Interactive Techniques in Australia and Southeast Asia
DA  - 2007///
C2  - 2007
DO  - 10.1145/1321261.1321296
ID  - 10.1145/1321261.1321
KW  - training
KW  - performance analysis
KW  - collaborative virtual environment system
PB  - Association for Computing Machinery
SN  - 9781595939128
SP  - 195-202
T3  - GRAPHITE '07
TI  - Performance and user based analysis of a collaborative virtual environ
ment system
UR  - https://doi.org/10.1145/1321261.1321296
ER  - 
TY  - CONF
AB  - Personal vehicles such as the Segway have been actively used for secur
ity patrols or supervision of construction sites, because of their mob
ility capabilities. In the current study, we proposed a vehicle-ride s
ensation sharing system enabling a rider to remotely collaborate with 
a driver, and to receive both 3D visual perception and vibro-vestibula
r sensation. We developed a prototype personal vehicle system with two
 360° cameras attached to the Segway with a stabilizer to capture ster
eoscopic 3D images and send them to each eye of a head-mounted display
 worn by a remotely collaborating rider. We also developed a prototype
 of vibro-vestibular display by modifying a conventional wheelchair wi
th a simple lightweight mechanism for actuation and vibration by two D
C motors. In our presentation algorithm, each wheel of the wheelchair 
is accelerated or decelerated proportionally to the acceleration of ea
ch wheel of the Segway. When the velocity of each wheel was almost con
stant and the acceleration was nearly zero, the wheelchair slowly move
d to the initial position, with movement that the rider could not perc
eive, to keep the wheelchair accelerating or decelerating in a limited
 space.
AU  - Yem, Vibol
AU  - Nashiki, Reon
AU  - Morita, Tsubasa
AU  - Miyashita, Fumiya
AU  - Amemiya, Tomohiro
AU  - Ikei, Yasushi
C1  - Brisbane, QLD, Australia
C3  - SIGGRAPH Asia 2019 Emerging Technologies
DA  - 2019///
C2  - 2019
DO  - 10.1145/3355049.3360540
ID  - 10.1145/3355049.3360
KW  - vibro-vestibular feedback
KW  - telepresence
KW  - stereoscopic 3D image
KW  - ride sensation sharing
KW  - collaboration
PB  - Association for Computing Machinery
SN  - 9781450369428
SP  - 53-54
T3  - SA '19
TI  - TwinCam Go: Proposal of Vehicle-Ride Sensation Sharing with Stereoscop
ic 3D Visual Perception and Vibro-Vestibular Feedback for Immersive Re
mote Collaboration
UR  - https://doi.org/10.1145/3355049.3360540
ER  - 
TY  - JOUR
AB  - Collaborative virtual environments (CVEs) enable two or more people, s
eparated in the real world, to share the same virtual “space.” They ca
n be used for many purposes, from teleconferencing to training people 
to perform assembly tasks. Unfortunately, the effectiveness of CVEs is
 compromised by one major problem: the delay that exists in the networ
ks linking users together. Whilst we have a good understanding, especi
ally in the visual modality, of how users are affected by delayed feed
back from their own actions, little research has systematically examin
ed how users are affected by delayed feedback from other people, parti
cularly in environments that support haptic (force) feedback. The curr
ent study addresses this issue by quantifying how increasing levels of
 latency affect visual and haptic feedback in a collaborative target a
cquisition task. Our results demonstrate that haptic feedback in parti
cular is very sensitive to low levels of delay. Whilst latency affects
 visual feedback from 50 ms, it impacts on haptic task performance 25 
ms earlier, and causes the haptic measures of performance deterioratio
n to rise far more steeply than visual. The “impact-perceive-adapt” mo
del of user performance, which considers the interaction between perfo
rmance measures, perception of latency, and the breakdown of perceptio
n of immediate causality, is proposed as an explanation for the observ
ed pattern of performance.
AU  - Jay, Caroline
AU  - Glencross, Mashhuda
AU  - Hubbold, Roger
DA  - 2007/8//
PY  - 2007
DO  - 10.1145/1275511.1275514
ID  - 10.1145/1275511.1275
IS  - 2
KW  - virtual environments
KW  - latency
KW  - distributed collaboration
KW  - Haptics
SN  - 1073-0516
SP  - 8-es
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - Modeling the effects of delayed haptic and visual feedback in a collab
orative virtual environment
UR  - https://doi.org/10.1145/1275511.1275514
VL  - 14
ER  - 
TY  - CONF
AB  - Remote collaboration is becoming more prevalent, yet it often struggle
s with effectively conveying the spatial orientation of a remote parti
cipant. We introduce an innovative communication method that enables u
sers to share their head direction. While traditional methods like wri
tten text and spoken language suit most situations, new approaches are
 necessary for scenarios lacking sufficient visual or auditory cues. F
or instance, how can hearing-impaired individuals share directional in
formation during a remote collaborative game? This research presents a
n interactive system that induces head rotation based on the other use
r’s head direction, allowing users to grasp each other’s intended dire
ction intuitively. This system improves communication by offering an a
dditional means to share directional cues, especially in settings wher
e visual and auditory cues are inadequate.
AU  - Li, Wanhui
AU  - Nakamura, Takuto
AU  - Zhang, Qing
AU  - Rekimoto, Jun
C1  - Trier, Germany
C3  - Proceedings of the 2024 ACM Symposium on Spatial User Interaction
DA  - 2024///
C2  - 2024
DO  - 10.1145/3677386.3688878
ID  - 10.1145/3677386.3688
KW  - Body Sharing
KW  - Hanger Reflex
KW  - Remote Collaboration
KW  - Synchronous Rotation
PB  - Association for Computing Machinery
SN  - 9798400710889
T3  - SUI '24
TI  - Real-Time Bidirectional Head Rotation Sharing for Collaborative Intera
ction Enhancement
UR  - https://doi.org/10.1145/3677386.3688878
ER  - 
TY  - JOUR
AB  - This paper presents a systematic review of haptic network protocols, i
n the context of the Metaverse. With the increasing integration of hap
tic technologies into applications like remote collaboration and robot
ic surgery, the need for reliable, low-latency data transmission has i
ntensified. This work provides a comprehensive analysis of existing ha
ptic protocols and frameworks, focusing on their development, implemen
tation, and the methods employed to optimize Quality of Service (QoS) 
parameters such as latency, delay, packet loss, jitter, throughput, an
d bandwidth. By examining the strengths and limitations of these proto
cols in real-time applications, this paper identifies critical areas f
or improvement and suggests future directions, including the potential
 for incorporating machine learning (ML) and artificial intelligence (
AI) to enable next-generation haptic communication suited for high-dem
and environments like the Metaverse.
AU  - Faisal, Mohd
AU  - Martinez-Velazquez, Roberto Alejandro
AU  - Laamarti, Fedwa
AU  - Al Osman, Hussein
AU  - El Saddik, Abdulmotaleb
DA  - 2025/8//
PY  - 2025
DO  - 10.1145/3759459
ID  - 10.1145/3759459
KW  - Haptic
KW  - Protocol
KW  - Network
KW  - Communication
KW  - Data Integration Frameworks
KW  - Real-Time
KW  - Data Transmission
KW  - Quality of Service (QoS)
KW  - Latency
KW  - Delay
KW  - Packet Loss
KW  - Jitter
KW  - Throughput
KW  - Bandwidth
KW  - Quality of Experience (QoE)
KW  - Metaverse
KW  - Tactile Internet
KW  - Systematic Review
N1  - Just Accepted
SN  - 1551-6857
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
TI  - Haptic Network Protocols: A Comprehensive Review and Directions for Ne
xt-Gen Metaverse Applications
UR  - https://doi.org/10.1145/3759459
ER  - 
TY  - CONF
AB  - Augmented reality annotations and virtual scene navigation add new dim
ensions to remote collaboration. In this paper, we present a touchscre
en interface for creating freehand drawings as world-stabilized annota
tions and for virtually navigating a scene reconstructed live in 3D, a
ll in the context of live remote collaboration. Two main focuses of th
is work are (1) automatically inferring depth for 2D drawings in 3D sp
ace, for which we evaluate four possible alternatives, and (2) gesture
-based virtual navigation designed specifically to incorporate constra
ints arising from partially modeled remote scenes. We evaluate these e
lements via qualitative user studies, which in addition provide insigh
ts regarding the design of individual visual feedback elements and the
 need to visualize the direction of drawings.
AU  - Gauglitz, Steffen
AU  - Nuernberger, Benjamin
AU  - Turk, Matthew
AU  - Höllerer, Tobias
C1  - Edinburgh, Scotland
C3  - Proceedings of the 20th ACM Symposium on Virtual Reality Software and 
Technology
DA  - 2014///
C2  - 2014
DO  - 10.1145/2671015.2671016
ID  - 10.1145/2671015.2671
KW  - video-mediated communication
KW  - touch
KW  - telepresence
KW  - gesture recognition
KW  - depth interpretation
KW  - augmented reality
KW  - CSCW
PB  - Association for Computing Machinery
SN  - 9781450332538
SP  - 197-205
T3  - VRST '14
TI  - In touch with the remote world: remote collaboration with augmented re
ality drawings and virtual navigation
UR  - https://doi.org/10.1145/2671015.2671016
ER  - 
TY  - CONF
AU  - Brave, Scott
AU  - Ishii, Hiroshi
AU  - Dahley, Andrew
C1  - Seattle, Washington, USA
C3  - Proceedings of the 1998 ACM Conference on Computer Supported Cooperati
ve Work
DA  - 1998///
C2  - 1998
DO  - 10.1145/289444.289491
ID  - 10.1145/289444.28949
KW  - telemanipulation
KW  - tangble interfaces
KW  - physical presence
KW  - haptic interfaces
KW  - force-feedback
PB  - Association for Computing Machinery
SN  - 1581130090
SP  - 169-178
T3  - CSCW '98
TI  - Tangible interfaces for remote collaboration and communication
UR  - https://doi.org/10.1145/289444.289491
ER  - 
TY  - JOUR
AB  - The rising interest in creating versatile robots to handle multiple ta
sks in various environments, with humans interacting through immersive
 interfaces. This survey provides a comprehensive review of extended r
eality (XR) applications in remote human–robot interaction (HRI). We d
eveloped a systematic search strategy based on the PRISMA methodology,
 focusing on peer-reviewed publications that demonstrate practical imp
lementations of XR in remote robot control, real robot system deployme
nt, and HRI applications, we analyzed research published between Janua
ry 2013 and December 2023. From the initial 2,561 articles, 100 met ou
r inclusion criteria were included. We categorized and summarized the 
domain in detail, delving into the methods used in these articles to a
chieve intuitive and effective remote HRI, highlighting user experienc
e enhancement and interaction designs. This survey identifies research
 opportunities, particularly emphasizes that future researchers should
 explore the potential of XR, such as exploring multimodal enhancement
 techniques that seamlessly integrate visual, haptic, and auditory fee
dback for more intuitive teleoperation. Our analysis reveals that whil
e XR shows promising potential in remote HRI, there are significant ga
ps, such as user-centered design. This survey provides a framework for
 understanding the current state of XR-based remote HRI, establishing 
a foundation for future research.
AU  - Wang, Xian
AU  - Shen, Luyao
AU  - Lee, Lik-Hang
DA  - 2025/6//
PY  - 2025
DO  - 10.1145/3730574
ID  - 10.1145/3730574
IS  - 11
KW  - Human-robot interaction
KW  - extended reality
KW  - virtual reality
KW  - augmented reality
KW  - teleoperation
KW  - remote collaboration
SN  - 0360-0300
T2  - ACM Comput. Surv.
TI  - A Systematic Review of XR-Enabled Remote Human-Robot Interaction Syste
ms
UR  - https://doi.org/10.1145/3730574
VL  - 57
ER  - 
TY  - CONF
AB  - For remote collaboration, it is essential to intuitively grasp the sit
uation and spatial location. However, the difficulty in grasping infor
mation about the remote user’s orientation can hinder remote communica
tion. For example, if a remote user turns his or her head to the right
 to operate a device on the right, and this sensation cannot be shared
, the image sent by the remote user suddenly appears to flow laterally
, and it will lose the positional relationship like Figure 1 (left). T
herefore, we propose a device using the ”hanger reflex” to experience 
the sensation of head rotation intuitively. The ”hanger reflex” is a p
henomenon in which the head turns unconsciously when a wire hanger is 
placed on the head. It has been verified that the sensation of turning
 is produced by the distribution of pressure exerted by a device worn 
on the head. This research aims to construct a mechanism to verify its
 effectiveness for telecommunication that can unconsciously experience
 the remote user’s rotation sensation using the hanger reflex phenomen
on. An inertial measurement unit(IMU) grasps the remote user’s rotatio
n information like Figure 1 (right).
AU  - Li, Wanhui
AU  - Nakamura, Takuto
AU  - Rekimoto, Jun
C1  - Bend, OR, USA
C3  - Adjunct Proceedings of the 35th Annual ACM Symposium on User Interface
 Software and Technology
DA  - 2022///
C2  - 2022
DO  - 10.1145/3526114.3558700
ID  - 10.1145/3526114.3558
KW  - Synchronous Rotation
KW  - Remote Collaboration
KW  - Positional Relationship
KW  - Hanger Reflex
PB  - Association for Computing Machinery
SN  - 9781450393218
T3  - UIST '22 Adjunct
TI  - RemoconHanger: Making Head Rotation in Remote Person using the Hanger 
Reflex
UR  - https://doi.org/10.1145/3526114.3558700
ER  - 
TY  - CONF
AB  - Remote collaboration is a challenge for physical product designers, an
d especially limits the mutual communication of the “thinking through 
prototyping” approach. Inspired by the NURBSforms and self-shape sensi
ng technologies, we investigate how to support remote co-design with a
 conceptual modular shape-changing interface toolkit. By using stop-mo
tion videos and low-fi non-electronic prototypes as probes, the concep
t was evaluated through on-line questionnaires and workshops. The resu
lt shows its potential especially in the exploration phase of remote c
o-design.
AU  - Ye, Huizhong
AU  - Janssen, Charlaine
AU  - Noordman, Daan
AU  - Liang, Rong-Hao
C1  - Daejeon, Republic of Korea
C3  - Proceedings of the Sixteenth International Conference on Tangible, Emb
edded, and Embodied Interaction
DA  - 2022///
C2  - 2022
DO  - 10.1145/3490149.3505563
ID  - 10.1145/3490149.3505
KW  - Remote collaboration
KW  - modular
KW  - prototyping
KW  - shape memory alloys
KW  - shape-changing
KW  - toolkit
PB  - Association for Computing Machinery
SN  - 9781450391474
T3  - TEI '22
TI  - Understanding How to Support Remote Co-Design with a Conceptual Modula
r Shape-Changing Interface Toolkit
UR  - https://doi.org/10.1145/3490149.3505563
ER  - 
TY  - CONF
AB  - We propose a new approach to Physical Telepresence, based on shared wo
rkspaces with the ability to capture and remotely render the shapes of
 people and objects. In this paper, we describe the concept of shape t
ransmission, and propose interaction techniques to manipulate remote p
hysical objects and physical renderings of shared digital content. We 
investigate how the representation of user's body parts can be altered
 to amplify their capabilities for teleoperation. We also describe the
 details of building and testing prototype Physical Telepresence works
paces based on shape displays. A preliminary evaluation shows how user
s are able to manipulate remote objects, and we report on our observat
ions of several different manipulation techniques that highlight the e
xpressive nature of our system.
AU  - Leithinger, Daniel
AU  - Follmer, Sean
AU  - Olwal, Alex
AU  - Ishii, Hiroshi
C1  - Honolulu, Hawaii, USA
C3  - Proceedings of the 27th Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2014///
C2  - 2014
DO  - 10.1145/2642918.2647377
ID  - 10.1145/2642918.2647
KW  - teleoperation
KW  - shape-changing user interfaces
KW  - shape displays
KW  - physical telepresence
KW  - actuated tangible interfaces
PB  - Association for Computing Machinery
SN  - 9781450330695
SP  - 461-470
T3  - UIST '14
TI  - Physical telepresence: shape capture and display for embodied, compute
r-mediated remote collaboration
UR  - https://doi.org/10.1145/2642918.2647377
ER  - 
TY  - CONF
AB  - Virtual Reality (VR) has significantly enhanced the visualization of m
olecular structures, offering an intuitive and immersive experience. H
owever, immersive collaborative virtual environments, despite their be
nefits that can come close to physical co-location, often lack crucial
 non-verbal communication cues such as gaze awareness, essential for e
nriching face-to-face collaboration. This research introduces GazeMolV
R, a tool based on the UnityMol software that enables a remote pair to
 collaboratively explore and discuss a protein’s structure and functio
n within a VR environment. It incorporates bi-directional eye-gaze cue
s through four distinct representations—GazePoint, GazeArrow, GazeSpot
light, and GazeTrail—to enhance mutual awareness of visual focus durin
g discussions. We conducted two user studies to evaluate GazeMolVR. Th
e first aimed to identify the most suitable gaze visualization for dis
cussing proteins depicted in cartoon, ball-and-stick, and surface mode
ls. The second compared the effects of bi-directional gaze sharing dur
ing collaborative discussions to a scenario without gaze sharing, espe
cially in the field of structural biology. Study results showed a pref
erence for GazeTrail with cartoon and ball-and-stick models, and GazeS
potlight for the surface model. Additionally, sharing bi-directional e
ye-gaze cues significantly enhanced collaborative discussions compared
 to not using gaze cues.
AU  - Darbar, Rajkumar
AU  - Santuz, Hubert
AU  - Taly, Antoine
AU  - Baaden, Marc
C1  -  
C3  - Proceedings of the International Conference on Mobile and Ubiquitous M
ultimedia
DA  - 2024///
C2  - 2024
DO  - 10.1145/3701571.3701599
ID  - 10.1145/3701571.3701
KW  - Molecular Visualization
KW  - Virtual Reality (VR)
KW  - Augmented Reality (AR)
KW  - Remote Collaboration
KW  - Eye-Gaze
KW  - Scientific Data Visualization.
PB  - Association for Computing Machinery
SN  - 9798400712838
SP  - 7-23
T3  - MUM '24
TI  - GazeMolVR: Sharing Eye-Gaze Cues in a Collaborative VR Environment for
 Molecular Visualization
UR  - https://doi.org/10.1145/3701571.3701599
ER  - 
TY  - CONF
AB  - Molecular modeling is an important research area, helping scientists d
evelop new drugs against diseases such as AIDS and cancer. Prior studi
es have demonstrated that immersive virtual environments have unique a
dvantages over desktop systems in visualizing molecular models. Howeve
r, exploration and interaction in existing molecular modeling virtual 
environments is often limited to a single user, lacking strong support
 for collaboration. In addition, scientists are often reluctant to ado
pt these systems because of their lack of availability and high cost. 
We propose an affordable immersive system that allows biologists and c
hemists to manipulate molecular models via natural gestures, receive a
nd visualize real-time feedback from a molecular dynamics simulator, a
llow the sharing of customized views, and provide support for both loc
al and remote collaborative research.
AU  - Chastine, Jeffrey W.
AU  - Brooks, Jeremy C.
AU  - Zhu, Ying
AU  - Owen, G. Scott
AU  - Harrison, Robert W.
AU  - Weber, Irene T.
C1  - Monterey, CA, USA
C3  - Proceedings of the ACM Symposium on Virtual Reality Software and Techn
ology
DA  - 2005///
C2  - 2005
DO  - 10.1145/1101616.1101620
ID  - 10.1145/1101616.1101
KW  - virtual environments
KW  - shaders
KW  - molecular modeling
KW  - interaction techniques
KW  - collaboration
KW  - augmented reality
PB  - Association for Computing Machinery
SN  - 1595930981
SP  - 8-15
T3  - VRST '05
TI  - AMMP-Vis: a collaborative virtual environment for molecular modeling
UR  - https://doi.org/10.1145/1101616.1101620
ER  - 
TY  - CONF
AB  - The computer has become an essential tool for collaboration between re
mote users and group work. But, for different reasons, current systems
 do not take advantage of all the possibilities of current computers a
nd user interfaces for creating a more efficient, natural and enjoyabl
e working environment. We are developing a system, Legible +, which tr
y to solve what we consider are the most important flaws in remote com
munication, including a set of features that is not present in other l
ong distance communication environments. Legible+ provides an integrat
ed environment, with software and hardware device, for the collaborati
ve document creation through the internet, the resource management and
 document distribution. Our system take advantages of new interface te
chnologies while also remains compatible with standard computer hardwa
re.
AU  - Pelaez, Mariano Perez
AU  - Fujii, Toshiya
AU  - Nam, Wonsuk
AU  - Yachiune, Masaki
AU  - Choh, Ikuro
C1  - Seoul, Korea
C3  - Proceedings of the 2nd International Conference on Interaction Science
s: Information Technology, Culture and Human
DA  - 2009///
C2  - 2009
DO  - 10.1145/1655925.1656028
ID  - 10.1145/1655925.1656
KW  - user interface
KW  - resource management
KW  - online collaboration
KW  - design
KW  - computer support
PB  - Association for Computing Machinery
SN  - 9781605587103
SP  - 568-570
T3  - ICIS '09
TI  - Legible+: integrated system for remote collaboration through document 
creation
UR  - https://doi.org/10.1145/1655925.1656028
ER  - 
TY  - CONF
AB  - Our project combines immersive VR, multitouch AR, real-time volumetric
 capture, motion capture, robotically-actuated tangible interfaces at 
multiple scales, and live coding, in service of a human-centric way of
 collaborating. Participants bring their unique talents and preference
s to collaboratively tackle complex problems in a shared mixed reality
 world.
AU  - Wang, Keru
AU  - Wang, Zhu
AU  - Rosenberg, Karl
AU  - He, Zhenyi
AU  - Yoo, Dong Woo
AU  - Christopher, Un Joo
AU  - Perlin, Ken
C1  - Vancouver, BC, Canada
C3  - ACM SIGGRAPH 2022 Immersive Pavilion
DA  - 2022///
C2  - 2022
DO  - 10.1145/3532834.3536216
ID  - 10.1145/3532834.3536
KW  - tangible interface
KW  - remote collaboration
KW  - Mixed reality
PB  - Association for Computing Machinery
SN  - 9781450393690
T3  - SIGGRAPH '22
TI  - Mixed Reality Collaboration for Complementary Working Styles
UR  - https://doi.org/10.1145/3532834.3536216
ER  - 
TY  - CONF
AB  - Although Augmented Reality (AR) has been touted as the future of surge
ry, its contribution to distributed collaboration such as in surgical 
teleconsulting has not been articulated. We propose AR-Head Mounted Di
splays (AR-HMD) to tackle two previously-identified challenges: operat
ing surgeons needing to view and interact with imaging systems that re
side away from the operative field, and, their lack of gesturing tools
 to point and annotate on the shared images and physical environment. 
We report on a controlled lab experiment where 12 expert gynecology su
rgeons perform a tumor localisation task guided by a remote radiologis
t (confederate) via an AR-HMD. We find that bringing the shared images
 to the place of work reduces the need for clarifications and provides
 opportunistic access to information when required, and, that pointing
 and annotating provides opportunities to further support verbal instr
uction in deictic communication. Our results inform the design of intr
aoperative AR-HMD systems for surgical telecollaboration.
AU  - Maria, Sophie
AU  - Mentis, Helena M.
AU  - Canlorbe, Geoffroy
AU  - Avellino, Ignacio
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI Conference on Human Factors in Computing S
ystems
DA  - 2023///
C2  - 2023
DO  - 10.1145/3544548.3580714
ID  - 10.1145/3544548.3580
KW  - augmented reality
KW  - remote collaboration
KW  - teleconsulting
PB  - Association for Computing Machinery
SN  - 9781450394215
T3  - CHI '23
TI  - Supporting Collaborative Discussions In Surgical Teleconsulting Throug
h Augmented Reality Head Mounted Displays
UR  - https://doi.org/10.1145/3544548.3580714
ER  - 
TY  - CONF
AB  - Designating targets, such as elementary primitives (e.g., vertices, ed
ges and faces) or complex objects (e.g., 3D objects and structures), t
o a partner in Collaborative Virtual Environments is a real challenge 
in different applications. In fact, the communication constraints in s
uch environments limit the understanding of the partner's actions, whi
ch lead to wrong selections and thus to conflicting actions. Beyond th
ese limitations, applications providing complex data to manipulate, su
ch as molecular environments, introduce additional constraints which l
imit the perception and access to the partner's working space. This pa
per proposes a remote designation procedure linked with an haptic attr
action model for molecular deformation tasks, we propose to guide phys
ically the partner to the designated atom. Experimental results showed
 a significant improvement in performance and efficiency for the diffe
rent steps of collaborative tasks (i.e., designation/selection of atom
s and deformation of structures). Moreover, this haptic guidance metho
d enables more accurate selections of atoms for the partner.
AU  - Girard, Adrien
AU  - Auvray, Malika
AU  - Ammi, Mehdi
C1  - Vancouver, British Columbia, Canada
C3  - Proceedings of the ACM Symposium on Applied Perception
DA  - 2014///
C2  - 2014
DO  - 10.1145/2628257.2628262
ID  - 10.1145/2628257.2628
KW  - haptic feedback
KW  - collaborative virtual environment
PB  - Association for Computing Machinery
SN  - 9781450330091
SP  - 31-37
T3  - SAP '14
TI  - Collaborative metaphor for haptic designation in complex 3D environmen
ts
UR  - https://doi.org/10.1145/2628257.2628262
ER  - 
TY  - CONF
AB  - The emerging haptic technology has introduced new media perceptions an
d also increased the immersive experiences of end-users. To date, nove
l haptic-audio-visual environments and their Quality of Experience (Qo
E) assessments are still challenging issues. In this work, we investig
ate the haptic-visual interaction QoE in virtual as well as real-world
 environments. First, we establish a haptic-visual interaction platfor
m based on a balance ball Virtual Reality (VR) game scene and a haptic
-visual interaction platform with data-glove-assisted remote control. 
Second, we conduct subjective tests to qualitatively and quantitativel
y analyze the impacts of system-related, user-related and task-related
 factors on QoE evaluation. Third, we propose learning-based QoE model
s to effectively evaluate the user-perceived QoE in haptic-visual inte
raction. In the future work, we aim to focus on the improvement of the
 two established platforms, with the addition of audio-related influen
cing factors and more haptic feedback, and optimizing the proposed QoE
 model for further improvement of haptic-audio-visual interaction appl
ications.
AU  - Fang, Ying
C1  - Ottawa ON, Canada
C3  - Proceedings of the 31st ACM International Conference on Multimedia
DA  - 2023///
C2  - 2023
DO  - 10.1145/3581783.3613437
ID  - 10.1145/3581783.3613
KW  - haptic
KW  - immersion
KW  - multimedia interaction
KW  - quality of experience
PB  - Association for Computing Machinery
SN  - 9798400701085
SP  - 9350-9354
T3  - MM '23
TI  - Haptic-aware Interaction: Design and Evaluation
UR  - https://doi.org/10.1145/3581783.3613437
ER  - 
TY  - CONF
AB  - We present ChameleonControl, a real-human teleoperation system for sca
lable remote instruction in hands-on classrooms. In contrast to existi
ng video or AR/VR-based remote hands-on education, ChameleonControl us
es a real human as a surrogate of a remote instructor. Building on exi
sting human-based telepresence approaches, we contribute a novel metho
d to teleoperate a human surrogate through synchronized mixed reality 
hand gestural navigation and verbal communication. By overlaying the r
emote instructor’s virtual hands in the local user’s MR view, the remo
te instructor can guide and control the local user as if they were phy
sically present. This allows the local user/surrogate to synchronize t
heir hand movements and gestures with the remote instructor, effective
ly teleoperating a real human. We deploy and evaluate our system in cl
assrooms of physiotherapy training, as well as other application domai
ns such as mechanical assembly, sign language and cooking lessons. The
 study results confirm that our approach can increase engagement and t
he sense of co-presence, showing potential for the future of remote ha
nds-on classrooms.
AU  - Faridan, Mehrad
AU  - Kumari, Bheesha
AU  - Suzuki, Ryo
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI Conference on Human Factors in Computing S
ystems
DA  - 2023///
C2  - 2023
DO  - 10.1145/3544548.3581381
ID  - 10.1145/3544548.3581
KW  - Hands-on Training
KW  - Human Surrogates
KW  - Mixed Reality
KW  - Remote Collaboration
KW  - Remote Guidance
KW  - Telepresence
KW  - Visual Cue
PB  - Association for Computing Machinery
SN  - 9781450394215
T3  - CHI '23
TI  - ChameleonControl: Teleoperating Real Human Surrogates through Mixed Re
ality Gestural Guidance for Remote Hands-on Classrooms
UR  - https://doi.org/10.1145/3544548.3581381
ER  - 
TY  - CONF
AB  - We present GazeTorch, a novel interface that provides gaze awareness d
uring remote collaboration on physical tasks. GazeTorch uses a spotlig
ht to display gaze information of the remote helper on the physical ta
sk space of the worker. We conducted a preliminary user study to evalu
ate user's subjective opinion on the quality of collaboration, using G
azeTorch and a camera-only setup. Our preliminary results suggest that
 the participants felt GazeTorch made collaboration easier, made refer
encing and identifying of objects effortless, and improved the worker'
s confidence that the task was completed accurately. We conclude by pr
esenting some novel application scenarios for the concept of augmentin
g real-time gaze information in the physical world.
AU  - Akkil, Deepak
AU  - James, Jobin Mathew
AU  - Isokoski, Poika
AU  - Kangas, Jari
C1  - San Jose, California, USA
C3  - Proceedings of the 2016 CHI Conference Extended Abstracts on Human Fac
tors in Computing Systems
DA  - 2016///
C2  - 2016
DO  - 10.1145/2851581.2892459
ID  - 10.1145/2851581.2892
KW  - remote collaboration
KW  - gaze sharing
KW  - augmentation
PB  - Association for Computing Machinery
SN  - 9781450340823
SP  - 1151-1158
T3  - CHI EA '16
TI  - GazeTorch: Enabling Gaze Awareness in Collaborative Physical Tasks
UR  - https://doi.org/10.1145/2851581.2892459
ER  - 
TY  - CONF
AB  - Virtual Reality (VR) remote collaboration is becoming more and more re
levant in a wide range of scenarios, such as remote assistance or grou
p work. A way to enhance the user experience is using haptic props tha
t make virtual objects graspable. But physical objects are only presen
t in one location and cannot be manipulated directly by remote users. 
We explore different strategies to handle ownership of virtual objects
 enhanced by haptic props. In particular, two strategies of handling o
bject ownership – SingleOwnership and SharedOwnership. SingleOwnership
 restricts virtual objects to local haptic props, while SharedOwnershi
p allows collaborators to take over ownership of virtual objects using
 local haptic props. We study both strategies for a collaborative puzz
le task regarding their influence on performance and user behavior. Ou
r findings show that SingleOwnership increases communication and enhan
ced with virtual instructions, results in higher task completion times
. SharedOwnership is less reliant on verbal communication and faster, 
but there is less social interaction between the collaborators.
AU  - Auda, Jonas
AU  - Busse, Leon
AU  - Pfeuffer, Ken
AU  - Gruenefeld, Uwe
AU  - Rivu, Radiah
AU  - Alt, Florian
AU  - Schneegass, Stefan
C1  - Virtual Event, USA
C3  - Proceedings of the 2021 ACM Symposium on Spatial User Interaction
DA  - 2021///
C2  - 2021
DO  - 10.1145/3485279.3485287
ID  - 10.1145/3485279.3485
KW  - Virtual Reality
KW  - Interaction Techniques
KW  - Haptic Props
KW  - Collaboration
PB  - Association for Computing Machinery
SN  - 9781450390910
T3  - SUI '21
TI  - I’m in Control! Transferring Object Ownership Between Remote Users wit
h Haptic Props in Virtual Reality
UR  - https://doi.org/10.1145/3485279.3485287
ER  - 
TY  - CONF
AB  - Today, remote collaboration techniques between field workers and remot
ely located experts mainly focus on traditional communication channels
, such as voice- or video-conferencing. Those systems may not be suita
ble in every situation or the communication gets cumbersome if both pa
rties do not share a common ground. In this paper, we explore three su
pporting communication channels based on audio, visual, and tactile cu
es. We built a prototypical application implementing those cues and ev
aluated them in a user study. Based on the user feedback, we report fi
rst insights for building remote assistance systems utilizing addition
al cues.
AU  - Günther, Sebastian
AU  - Kratz, Sven
AU  - Avrahami, Daniel
AU  - Mühlhäuser, Max
C1  - Corfu, Greece
C3  - Proceedings of the 11th PErvasive Technologies Related to Assistive En
vironments Conference
DA  - 2018///
C2  - 2018
DO  - 10.1145/3197768.3201568
ID  - 10.1145/3197768.3201
KW  - Vibrotactile Feedback
KW  - Spatial Guidance
KW  - Remote Collaboration
KW  - Navigation
KW  - Haptics
KW  - Augmented Reality
KW  - Audio Cues
KW  - Assistive Technology
KW  - 3D-Space
PB  - Association for Computing Machinery
SN  - 9781450363907
SP  - 339-344
T3  - PETRA '18
TI  - Exploring Audio, Visual, and Tactile Cues for Synchronous Remote Assis
tance
UR  - https://doi.org/10.1145/3197768.3201568
ER  - 
TY  - CONF
AB  - Remotely operated robotic systems have gained importance in executing 
tasks in complex and challenging environments which are difficult to a
utomate. This paper focuses on developing reference hardware and softw
are architectures for haptic-based teleoperation under various physica
l and network conditions. The system consists of a 6-DOF haptic device
 as the leader and a 6-DOF robotic manipulator as the follower. The co
ntrol architecture used for teleoperation is Jacobian inverse control,
 which enables the follower to follow the leader when commanded. The p
erformance of the proposed architecture is determined in terms of the 
error between current and commanded motion for different input velocit
ies, communication delays in different network configurations, and the
 stable haptic force feedback at the haptic end.
AU  - Kumar, Deepak
AU  - Sharma, Aayush D.
AU  - Rebeiro, John
AU  - Bhardwaj, Amit
AU  - Shah, Suril
C1  - Ropar, India
C3  - Proceedings of the 2023 6th International Conference on Advances in Ro
botics
DA  - 2023///
C2  - 2023
DO  - 10.1145/3610419.3610470
ID  - 10.1145/3610419.3610
KW  - Haptic
KW  - Teleoperation
KW  - communication
PB  - Association for Computing Machinery
SN  - 9781450399807
T3  - AIR '23
TI  - Investigating Teleoperation of UR5 Robot Using Haptic Device for Diffe
rent Network Configuration
UR  - https://doi.org/10.1145/3610419.3610470
ER  - 
TY  - CONF
AB  - Cake customization services allow clients to collaboratively personali
ze cakes with pastry chefs. However, remote (e.g., email) and in-perso
n co-design sessions are prone to miscommunication, due to natural res
trictions in visualizing cake size, decoration, and celebration contex
t. This paper presents the design, implementation, and expert evaluati
on of a social VR application (CakeVR) that allows a client to remotel
y co-design cakes with a pastry chef, through real-time realistic 3D v
isualizations. Drawing on expert semi-structured interviews (4 clients
, 5 pastry chefs), we distill and incorporate 8 design requirements in
to our CakeVR prototype. We evaluate CakeVR with 10 experts (6 clients
, 4 pastry chefs) using cognitive walkthroughs, and find that it suppo
rts ideation and decision making through intuitive size manipulation, 
color/flavor selection, decoration design, and custom celebration them
e fitting. Our findings provide recommendations for enabling co-design
 in social VR and highlight CakeVR’s potential to transform product de
sign communication through remote interactive and immersive co-design.

AU  - Mei, Yanni
AU  - Li, Jie
AU  - Ridder, Huib
AU  - Cesar, Pablo
C1  - Yokohama, Japan
C3  - Proceedings of the 2021 CHI Conference on Human Factors in Computing S
ystems
DA  - 2021///
C2  - 2021
DO  - 10.1145/3411764.3445503
ID  - 10.1145/3411764.3445
KW  - Social Virtual Reality
KW  - Remote Collaboration
KW  - Co-design
KW  - Cake Design
PB  - Association for Computing Machinery
SN  - 9781450380966
T3  - CHI '21
TI  - CakeVR: A Social Virtual Reality (VR) Tool for Co-designing Cakes
UR  - https://doi.org/10.1145/3411764.3445503
ER  - 
TY  - CONF
AB  - Augmented and virtual reality headsets, collectively referred to as ex
tended reality (XR), can alter, augment, or even replace our reality. 
While these headsets have made impressive strides in audio-visual imme
rsion over the past half-century, XR interactions remain almost comple
tely absent of appropriately expressive tactile sensations. At present
, even mainstream consumer systems rely on vibrotactile haptic actuato
rs in the controllers, which are inherently limited to clicks and buzz
es — an exceedingly limited range of expressivity with which to repres
ent the rich tactile world.Realizing the holistic promise of XR requir
es full-body haptic immersion, just as much as it requires full audio-
visual immersion. To frame critical design considerations in haptics r
esearch, I propose an immersion-practicality tradeoff model. These com
peting objectives underscore the inherent tension between providing ri
ch sensory feedback (often e.g. costly, bulky), while maintaining cons
umer feasibility and usability (e.g., low cost, easy to use). Under th
is framework, I sought to identify and build Pareto-efficient haptic s
ystems where the haptic approach is aligned with humans’ sensorimotor 
system. I present three published projects that embody my design appro
ach with tactile haptics to different regions of the body. My proposed
 future work extends this framework to the other major dimensions of h
aptics (kinesthetic/force feedback). These systems serve as probes int
o my research approach and advance the vision of practical, immersive,
 full-body haptics.
AU  - Shen, Vivian
C1  -  
C3  - Proceedings of the Extended Abstracts of the CHI Conference on Human F
actors in Computing Systems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706599.3707606
ID  - 10.1145/3706599.3707
PB  - Association for Computing Machinery
SN  - 9798400713958
T3  - CHI EA '25
TI  - Sensorimotor-Aligned Design for Pareto-Efficient Haptic Immersion in X
R
UR  - https://doi.org/10.1145/3706599.3707606
ER  - 
TY  - CONF
AB  - LocalAnesthesiaVRis a virtual reality training system for dental anest
hesia, a clinical procedure every dentist must be competent with, and 
one that is particularly challenging to master throughout the demandin
g dental curriculum. This unique VR-based system provides learners wit
h visual, auditory and haptic feedback enabling experiential learning 
in pre-clinical education.
AU  - Grandhi, Uttam
AU  - Opazo, Cristián
C1  - Virtual Event, USA
C3  - ACM SIGGRAPH 2021 Educators Forum
DA  - 2021///
C2  - 2021
DO  - 10.1145/3450549.3464411
ID  - 10.1145/3450549.3464
KW  - simulation
KW  - remote collaboration
KW  - oral surgery
KW  - interfaces
KW  - haptics
KW  - hand tracking
KW  - experiential learning
KW  - education
KW  - dentistry
KW  - assessment.
KW  - anesthesia
KW  - anatomy
KW  - analytics
KW  - Virtual reality
KW  - Oculus
KW  - HCI
PB  - Association for Computing Machinery
SN  - 9781450383639
T3  - SIGGRAPH '21
TI  - LocalAnesthesiaVR
UR  - https://doi.org/10.1145/3450549.3464411
ER  - 
TY  - CONF
AB  - Dedicated handheld controllers facilitate haptic experiences of virtua
l objects in mixed reality (MR). However, as mobile MR becomes more pr
evalent, we observe the emergence of controller-free MR interactions. 
To retain immersive haptic experiences, we explore the use of mobile d
evices as a substitute for specialised MR controller. In an explorator
y gesture elicitation study (n = 18), we examined users’ (1) intuitive
 hand gestures performed with prospective mobile devices and (2) prefe
rences for real-time haptic feedback when exploring haptic object prop
erties. Our results reveal three haptic exploration modes for the mobi
le device, as an object, hand substitute, or as an additional tool, an
d emphasise the benefits of incorporating the device’s unique physical
 features into the object interaction. This work expands the design po
ssibilities using mobile devices for tangible object interaction, guid
ing the future design of mobile devices for haptic MR experiences.
AU  - Stellmacher, Carolin
AU  - Mathis, Florian
AU  - Weiss, Yannick
AU  - Loerakker, Meagan B.
AU  - Wagener, Nadine
AU  - Schöning, Johannes
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI Conference on Human Factors in Computing S
ystems
DA  - 2024///
C2  - 2024
DO  - 10.1145/3613904.3642176
ID  - 10.1145/3613904.3642
KW  - gesture elicitation
KW  - haptic exploration
KW  - haptic feedback
KW  - haptic interfaces
KW  - mixed reality
KW  - mobile gestures
KW  - mobile phones
PB  - Association for Computing Machinery
SN  - 9798400703300
T3  - CHI '24
TI  - Exploring Mobile Devices as Haptic Interfaces for Mixed Reality
UR  - https://doi.org/10.1145/3613904.3642176
ER  - 
TY  - CONF
AB  - Designing vibrotactile experiences collaboratively requires communicat
ing using multiple senses. This is challenging in remote scenarios as 
designers need to effectively express and communicate their intention 
while iteratively building and refining experiences, ideally in real-t
ime. We formulate design considerations for collaborative haptic desig
n tools, and propose CollabJam, a collaborative prototyping suite enab
ling remote synchronous design of vibrotactile experiences for on-body
 applications. We first outline CollabJam’s features and present a tec
hnical evaluation. Second, we use CollabJam to understand communicatio
n and design patterns used during haptic experience design. We perform
ed an in-depth design evaluation spanning four sessions in which four 
pairs of participants designed and reviewed vibrotactile experiences r
emotely. A qualitative content analysis revealed how multi-sensory com
munication is essential to convey ideas, how stimulating the tactile s
ense can interfere with personal boundaries, and how freely placing ac
tuators on the skin can provide both benefits and challenges.
AU  - Wittchen, Dennis
AU  - Ramian, Alexander
AU  - Sabnis, Nihar
AU  - Böhme, Richard
AU  - Chlebowski, Christopher
AU  - Freitag, Georg
AU  - Fruchard, Bruno
AU  - Degraen, Donald
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713469
ID  - 10.1145/3706598.3713
KW  - vibrotactile design
KW  - vibrotactile patterns
KW  - tacton
KW  - collaborative design
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - CollabJam: Studying Collaborative Haptic Experience Design for On-Body
 Vibrotactile Patterns
UR  - https://doi.org/10.1145/3706598.3713469
ER  - 
TY  - CONF
AB  - Virtual Reality (VR) is gaining attention in various domains such as e
ntertainment, industry, mental healthcare and VR training. Al- though 
most of these use-cases are still limited to single-user tasks, a lot 
of applications are heavily depending on multi-user collaboration. Exi
sting multi-user VR systems are most often created in a classic server
-client architecture, however, which induces unpredictable network beh
aviour which can affect the end-user's Quality-of-Experience (QoE) and
 performance. In addition, the interaction methods in these systems ar
e often constrained to either traditional VR controllers or very use-c
ase specific interaction methods, such that general purpose haptic glo
ves form a somewhat under-explored part of literature. Therefore, we (
i) present a networked, distributed multi-user VR system with synchron
ization of environments over a low-bandwidth networked connection. In 
addition, we (ii) enhance the experience by adding haptic gloves to th
e system, which we compare to the traditional VR controllers in a subj
ective experiment. As a proof-of-concept, a use case is implemented in
 which two users have to prepare and bake a virtual pizza. The results
 show that high framerates (&gt; 90 Frames Per Second (FPS)) can be ob
tained while keeping network throughput to a minimum ( &lt; 1 Mbps). T
he accompanying user study shows that haptic gloves are preferred when
 immersiveness is the main emphasis of the virtual environment, while 
controllers are more suited when performance is in the center of atten
tion. In objective terms, the applicability of haptic feedback is high
ly dependent on the task at hand.
AU  - Van Damme, Sam
AU  - Velde, Fangio
AU  - Sameri, Mohammad Javad
AU  - De Turck, Filip
AU  - Vega, Maria Torres
C1  - Ottawa ON, Canada
C3  - Proceedings of the 2nd International Workshop on Interactive EXtended 
Reality
DA  - 2023///
C2  - 2023
DO  - 10.1145/3607546.3616804
ID  - 10.1145/3607546.3616
KW  - virtual reality (vr)
KW  - quality-of-experience (qoe)
KW  - multi-user
KW  - haptic feedback
KW  - collaborative vr
PB  - Association for Computing Machinery
SN  - 9798400702808
SP  - 11-19
T3  - IXR '23
TI  - A Haptic-enabled, Distributed and Networked Immersive System for Multi
-User Collaborative Virtual Reality
UR  - https://doi.org/10.1145/3607546.3616804
ER  - 
TY  - CONF
AB  - Although the absence of bodily contact in Long-Distance Relationships 
(LDRs) often results in emotional distress, the design of haptic inter
actions has the potential to address these challenges by fostering int
imacy and emotional connection. We explore how long-distance couples p
erceive the role of bodily contact in their daily lives and their pers
pectives on using haptic technologies for remote communication. Throug
h in-depth interviews with 12 individuals who have been in LDRs and a 
thematic analysis, we 1) identify empirical evidence of how remote hap
tic interactions can support intimate relationships, 2) propose a desi
gn framework and 3) present a design case, Onni, a haptic interface th
at illustrates the framework’s application. Our findings may inform fu
ture design and research on how haptic technologies can be used to enh
ance emotional well-being and connectedness in LDRs.
AU  - Yang, Mengshi
AU  - Hu, Ruochen
C1  -  
C3  - Proceedings of the Extended Abstracts of the CHI Conference on Human F
actors in Computing Systems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706599.3719945
ID  - 10.1145/3706599.3719
KW  - Haptic interaction
KW  - Affective haptics
KW  - Long-distance relationships
KW  - Social interactions
KW  - Biometric synchronization
KW  - Physical telepresence
KW  - Affective computing
PB  - Association for Computing Machinery
SN  - 9798400713958
T3  - CHI EA '25
TI  - "Overlapping Our Worlds": Designing Biometric-Based Haptic Interaction
s to Enhance Synchrony in Long-Distance Relationships
UR  - https://doi.org/10.1145/3706599.3719945
ER  - 
TY  - CONF
AB  - Virtual reality can help realize mediated social experiences where dis
tance disappears and we interact as richly with those around the world
 as we do with those in the same room. The design of social virtual ex
periences presents a challenge for remotely located users with room-sc
ale setups like those afforded by recent commodity virtual reality dev
ices. Since users inhabit different physical spaces that may not be th
e same size, a mapping to a shared virtual space is needed for creatin
g experiences that allow everyone to use real walking for locomotion. 
We designed three mapping techniques that enable users from diverse ro
om-scale setups to interact together in virtual reality. Results from 
our user study (N = 26) show that our mapping techniques positively in
fluence the perceived degree of togetherness and copresence while the 
size of each user's tracked space influences individual presence.
AU  - Sra, Misha
AU  - Mottelson, Aske
AU  - Maes, Pattie
C1  - Hong Kong, China
C3  - Proceedings of the 2018 Designing Interactive Systems Conference
DA  - 2018///
C2  - 2018
DO  - 10.1145/3196709.3196788
ID  - 10.1145/3196709.3196
KW  - virtual reality
KW  - social
KW  - room-scale vr
KW  - remote collaboration
KW  - embodiment
KW  - dancing
PB  - Association for Computing Machinery
SN  - 9781450351980
SP  - 85-97
T3  - DIS '18
TI  - Your Place and Mine: Designing a Shared VR Experience for Remotely Loc
ated Users
UR  - https://doi.org/10.1145/3196709.3196788
ER  - 
TY  - CONF
AB  - Providing kinesthetic force-feedback for human-scale interactions is c
hallenging due to the relatively large forces needed. Therefore, robot
ic actuators are predominantly used to deliver this kind of haptic fee
dback; however, they offer limited flexibility and spatial resolution.
 In this work, we introduce HapticPuppet, a drone-based force-feedback
 interface which can exert multidirectional forces onto the human body
. This can be achieved by attaching strings to different parts of the 
human body such as fingers, hands or ankles, which can then be affixed
 to multiple coordinated drones - puppeteering the user. HapticPuppet 
opens up a wide range of potential applications in virtual, augmented 
and mixed reality, exercising, physiotherapy, remote collaboration as 
well as haptic guidance.
AU  - Feick, Martin
AU  - Tang, Anthony
AU  - Krüger, Antonio
C1  - Bend, OR, USA
C3  - Adjunct Proceedings of the 35th Annual ACM Symposium on User Interface
 Software and Technology
DA  - 2022///
C2  - 2022
DO  - 10.1145/3526114.3558694
ID  - 10.1145/3526114.3558
KW  - VR
KW  - Haptics
KW  - Drones
KW  - Directional Kinesthetic Force-Feedback
KW  - AR
PB  - Association for Computing Machinery
SN  - 9781450393218
T3  - UIST '22 Adjunct
TI  - HapticPuppet: A Kinesthetic Mid-air Multidirectional Force-Feedback Dr
one-based Interface
UR  - https://doi.org/10.1145/3526114.3558694
ER  - 
TY  - CONF
AB  - Virtual reality (VR) expands opportunities for social interaction, yet
 its heavy reliance on visual cues can limit social engagement and hin
der immersive experiences in visually overwhelming situations. To expl
ore alternative social cues beyond the visual domain, we verified the 
potential of haptic cues for social identification in VR by examining 
the effects of haptic pattern similarity on social perceptions. Unique
 haptic patterns were assigned to participants and virtual agents for 
identification, while the similarity of haptic patterns was manipulate
d (same, similar, distinct). The results demonstrated that participant
s maintained closer interpersonal distances and reported higher senses
 of belonging, social connection, and comfort toward agents as the sim
ilarity of patterns increased. Our findings validate the potential of 
haptic patterns in social identification and provide scientific eviden
ce that homophily extends beyond the visual domain to the haptic domai
n. We also suggest a novel haptic-based methodology for conveying rela
tionship information and enhancing social VR experiences.
AU  - Jang, Hyuckjin
AU  - Lee, Jeongmi
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3714264
ID  - 10.1145/3706598.3714
KW  - Haptic Pattern Similarity
KW  - Social Perception
KW  - Interpersonal Distance
KW  - Multidimensional Scaling
KW  - Virtual Reality
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Birds of a Rhythm: The Effects of Haptic Pattern Similarity on People'
s Social Perceptions in Virtual Reality
UR  - https://doi.org/10.1145/3706598.3714264
ER  - 
TY  - CONF
AB  - While traditional interfaces in human-computer interaction mainly rely
 on vision and audio, haptics becomes more and more important. Haptics
 cannot only increase the user experience and make technology more imm
ersive, it can also transmit information that is hard to interpret onl
y through vision and audio, such as the softness of a surface or other
 material properties. In this workshop, we aim at discussing how we co
uld interact with technology if haptics is strongly supported and whic
h novel research areas could emerge.
AU  - Wolf, Katrin
AU  - Kurzweg, Marco
AU  - Weiss, Yannick
AU  - Brewster, Stephen
AU  - Schmidt, Albrecht
C1  - Frascati, Rome, Italy
C3  - Proceedings of the 2022 International Conference on Advanced Visual In
terfaces
DA  - 2022///
C2  - 2022
DO  - 10.1145/3531073.3535260
ID  - 10.1145/3531073.3535
KW  - haptic feedback
KW  - interaction
KW  - interfaces
KW  - visual feedback
PB  - Association for Computing Machinery
SN  - 9781450397193
T3  - AVI '22
TI  - Visuo-Haptic Interaction
UR  - https://doi.org/10.1145/3531073.3535260
ER  - 
TY  - CONF
AB  - The digitalized world comes with increasing Internet capabilities, all
owing to connect persons over distance easier than ever before. Video 
conferencing and similar online applications create great benefits bri
nging people who physically cannot spend as much time as they want vir
tually together. However, such remote experiences can also tend to los
e the feeling of traditional experiences. People lack direct visual pr
esence and no haptic feedback is available. In this paper, we tackle t
his problem by introducing our system called CheckMate. We combine Aug
mented Reality and capacitive 3D printed objects that can be sensed on
 an interactive surface to enable remote interaction while providing t
he same tangible experience as in co-located scenarios. As a proof-of-
concept, we implemented a sample application based on the traditional 
chess game.
AU  - Günther, Sebastian
AU  - Müller, Florian
AU  - Schmitz, Martin
AU  - Riemann, Jan
AU  - Dezfuli, Niloofar
AU  - Funk, Markus
AU  - Schön, Dominik
AU  - Mühlhäuser, Max
C1  - Montreal QC, Canada
C3  - Extended Abstracts of the 2018 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2018///
C2  - 2018
DO  - 10.1145/3170427.3188647
ID  - 10.1145/3170427.3188
KW  - 3d fabrication
KW  - augmented reality
KW  - chess
KW  - mixed reality
KW  - remote collaboration
KW  - tabletops
KW  - tangibles
PB  - Association for Computing Machinery
SN  - 9781450356213
SP  - 1-6
T3  - CHI EA '18
TI  - CheckMate: Exploring a Tangible Augmented Reality Interface for Remote
 Interaction
UR  - https://doi.org/10.1145/3170427.3188647
ER  - 
TY  - CONF
AB  - Sandplay is an effective psychotherapy for mental retreatment, and man
y people prefer to engage in sandplay in Virtual Reality (VR) due to i
ts convenience. Haptic perception of physical objects and miniatures e
nhances the realism and immersion in VR. Previous studies have rendere
d sizes by exerting pressure on the user’s fingertips or employing tan
gible, shape-changing devices. However, these interfaces are limited b
y the physical shapes they can assume, making it difficult to simulate
 objects that grow larger or smaller than the interface. Motivated by 
literature on visual-haptic illusions, this work aims to convey the ha
ptic sensation of a virtual object’s shape to the user by exploring th
e relationships between the haptic feedback from real objects and thei
r visual renderings in VR. Our study focuses on the confirmation and a
djustment ratios for different virtual object sizes. The results show 
that the likelihood of participants confirming the correct size of vir
tual cubes decreases as the object size increases, requiring more adju
stments for larger objects. This research provides valuable insights i
nto the relationships between haptic sensations and visual inputs, con
tributing to the understanding of visual-haptic illusions in VR enviro
nments.
AU  - Zheng, Wenqi
AU  - Xiong, Dawei
AU  - Li, Junwei
AU  - Jiang, Jiajun
AU  - Weng, Cekai
AU  - Zhou, Jinni
AU  - Fan, Mingming
C1  -  
C3  - Proceedings of the 17th International Symposium on Visual Information 
Communication and Interaction
DA  - 2024///
C2  - 2024
DO  - 10.1145/3678698.3678706
ID  - 10.1145/3678698.3678
KW  - visual-haptic illusion
KW  - cross-modal integration
KW  - perceptual illusion
PB  - Association for Computing Machinery
SN  - 9798400709678
T3  - VINCI '24
TI  - Investigating Size Congruency Between the Visual Perception of a VR Ob
ject and the Haptic Perception of Its Physical World Agent
UR  - https://doi.org/10.1145/3678698.3678706
ER  - 
TY  - JOUR
AB  - We present ANISMA, a software and hardware toolkit to prototype on-ski
n haptic devices that generate skin deformation stimuli like pressure,
 stretch, and motion using shape-memory alloys (SMAs). Our toolkit emb
eds expert knowledge that makes SMA spring actuators more accessible t
o human–computer interaction (HCI) researchers. Using our software too
l, users can design different actuator layouts, program their spatio-t
emporal actuation and preview the resulting deformation behavior to ve
rify a design at an early stage. Our toolkit allows exporting the actu
ator layout and 3D printing it directly on skin adhesive. To test diff
erent actuation sequences on the skin, a user can connect the SMA actu
ators to our customized driver board and reprogram them using our visu
al programming interface. We report a technical analysis, verify the p
erceptibility of essential ANISMA skin deformation devices with 8 part
icipants, and evaluate ANISMA regarding its usability and supported cr
eativity with 12 HCI researchers in a creative design task.
AU  - Messerschmidt, Moritz Alexander
AU  - Muthukumarana, Sachith
AU  - Hamdan, Nur Al-Huda
AU  - Wagner, Adrian
AU  - Zhang, Haimo
AU  - Borchers, Jan
AU  - Nanayakkara, Suranga Chandima
DA  - 2022/1//
PY  - 2022
DO  - 10.1145/3490497
ID  - 10.1145/3490497
IS  - 3
KW  - hardware
KW  - software
KW  - prototyping
KW  - programming
KW  - fabrication
KW  - design
KW  - deformation
KW  - skin
KW  - SMA
KW  - shape-memory alloy
KW  - authoring
KW  - toolkit
KW  - tactile
KW  - Haptic
SN  - 1073-0516
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - ANISMA: A Prototyping Toolkit to Explore Haptic Skin Deformation Appli
cations Using Shape-Memory Alloys
UR  - https://doi.org/10.1145/3490497
VL  - 29
ER  - 
TY  - CONF
AB  - In this paper we describe a prototype wearable interface that shares a
 user's first person view and their current emotional state with a rem
ote user in order to create a shared emotional experience. A user eval
uation was conducted to explore which interface cues best helped a rem
ote user understand what the local user was feeling. The results showe
d simple visual cues provided a significantly enhanced experience over
 no cues at all, or a more detailed data representation.
AU  - Ayyagari, Sudhanshu S.D.P.
AU  - Gupta, Kunal
AU  - Tait, Matt
AU  - Billinghurst, Mark
C1  - Seoul, Republic of Korea
C3  - Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Hu
man Factors in Computing Systems
DA  - 2015///
C2  - 2015
DO  - 10.1145/2702613.2732839
ID  - 10.1145/2702613.2732
KW  - wearables
KW  - remote collaboration
KW  - emotional interfaces
PB  - Association for Computing Machinery
SN  - 9781450331463
SP  - 2007-2012
T3  - CHI EA '15
TI  - CoSense: Creating Shared Emotional Experiences
UR  - https://doi.org/10.1145/2702613.2732839
ER  - 
TY  - CONF
AB  - By means of vibrotactile and force feedback, i.e., haptics, users are 
given the sensation of touching and manipulating virtual objects in in
teractive Extended Reality (XR) environments. However, research toward
s the influence of this feedback on the users' perception and performa
nce in interactive XR is currently still scarce. In this work, we pres
ent an experimental evaluation of the effects of haptic feedback in in
teractive immersive applications. By means of a Projected Augmented Re
ality (PAR) setup, users were asked to interact with a projected envir
onment by completing three different tasks based on finger-tracking an
d in the presence of visual latency. Evaluations were performed both s
ubjectively (questionnaire) and objectively (i.e. duration and accurac
y). We found out that while haptic feedback does not enhance the perfo
rmance for simple tasks, it substantially improves it for more complex
 ones. This effect is more evident in presence of network degradation,
 such as latency. However, the subjective questionnaires showed a gene
ral skepticism about the potential of incorporating haptic information
 into immersive applications. As such, we believe that this paper prov
ides an important contribution toward the understanding and assessment
 of the influence of haptic technology in interactive immersive system
s.
AU  - Van Damme, Sam
AU  - Legrand, Nicolas
AU  - Heyse, Joris
AU  - De Backere, Femke
AU  - De Turck, Filip
AU  - Vega, Maria Torres
C1  - Lisboa, Portugal
C3  - Proceedings of the 1st Workshop on Interactive EXtended Reality
DA  - 2022///
C2  - 2022
DO  - 10.1145/3552483.3556456
ID  - 10.1145/3552483.3556
KW  - visual latency
KW  - user performance
KW  - user perception
KW  - projected augmented reality
KW  - interactive extended reality
KW  - haptic feedback
PB  - Association for Computing Machinery
SN  - 9781450395014
SP  - 11-18
T3  - IXR '22
TI  - Effects of Haptic Feedback on User Perception and Performance in Inter
active Projected Augmented Reality
UR  - https://doi.org/10.1145/3552483.3556456
ER  - 
TY  - CONF
AB  - We propose a new classification of the human-to-human communication du
ring the use of immersive teleoperation interfaces based on real-life 
examples. While a large body of research is concerned with communicati
on in collaborative virtual environments (CVEs), less research focuses
 on cases where only one of two communicating users is immersed in a v
irtual or remote environment. Furthermore, we identify the unmediated 
communication between co-located users of an immersive teleoperation i
nterface as another conceptually important – but usually neglected – c
ase. To cover these scenarios, one of the dimensions of the proposed c
lassification is the level of copresence of the communicating users. F
urther dimensions are the virtuality of the immersive environment, the
 virtual transport of the immersed user(s), the communication channel,
 and the mediation of the communication. We find that an extension of 
the proposed classification to real environments can offer useful refe
rence cases. Using this extended classification not only allows us to 
discuss and understand differences and similarities of various forms o
f communication in a more systematic way, but it also provides guideli
nes and reference cases for the design of immersive teleoperation inte
rfaces that support human-to-human communication.
AU  - Kraus, Martin
AU  - Kibsgaard, Martin
C1  - Laval, France
C3  - Proceedings of the 2015 Virtual Reality International Conference
DA  - 2015///
C2  - 2015
DO  - 10.1145/2806173.2806198
ID  - 10.1145/2806173.2806
KW  - virtual reality
KW  - teleoperation
KW  - shared virtual space
KW  - presence
KW  - immersion
KW  - human-to-human communication
KW  - computer-mediated communication
KW  - collaborative virtual environment
KW  - collaboration
KW  - augmented reality
KW  - Telepresence
PB  - Association for Computing Machinery
SN  - 9781450333139
T3  - VRIC '15
TI  - A Classification of Human-to-Human Communication during the Use of Imm
ersive Teleoperation Interfaces
UR  - https://doi.org/10.1145/2806173.2806198
ER  - 
TY  - JOUR
AB  - The importance of remote collaboration grows in an interconnected worl
d as the reasons to avoid travel increase. The spatial rendering and c
ollaboration capabilities of virtual and augmented reality systems are
 well suited for tasks such as support or training. Users can take a s
hared perspective to build a common understanding. Also, users may eng
age in face-to-face cooperation to support interpersonal communication
. However, a shared perspective and face-to-face collaboration are bot
h desirable but naturally exclude each other. We place all users at th
e same location to provide a shared perspective. To avoid overlapping 
body parts, the avatars of the other connected users are shifted to th
e side. A redirected body pose modification corrects the resulting inc
onsistencies. The implemented system is compared to a baseline of two 
users standing in the same location and working with overlapping avata
rs. The results of a user study show that the proposed modifications p
rovide an easy to use, efficient collaboration and yield higher co-pre
sence and the feeling of teamwork. Applying redirection techniques to 
other users opens up novel ways to increase social presence for local 
or remote collaboration.
AU  - Hoppe, Adrian H.
AU  - Camp, Florian
AU  - Stiefelhagen, Rainer
DA  - 2021/1//
PY  - 2021
DO  - 10.1145/3432950
ID  - 10.1145/3432950
IS  - CSCW3
KW  - virtual reality
KW  - social redirection
KW  - social presence
KW  - shared perspective
KW  - redirected interaction
KW  - avatar modification
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - ShiSha: Enabling Shared Perspective With Face-to-Face Collaboration Us
ing Redirected Avatars in Virtual Reality
UR  - https://doi.org/10.1145/3432950
VL  - 4
ER  - 
TY  - CONF
AB  - HapticBots introduces a novel encountered-type haptic approach for Vir
tual Reality (VR) based on multiple tabletop-size shape-changing robot
s. These robots move on a tabletop and change their height and orienta
tion to haptically render various surfaces and objects on-demand. Comp
ared to previous encountered-type haptic approaches like shape display
s or robotic arms, our proposed approach has an advantage in deployabi
lity, scalability, and generalizability—these robots can be easily dep
loyed due to their compact form factor. They can support multiple conc
urrent touch points in a large area thanks to the distributed nature o
f the robots. We propose and evaluate a novel set of interactions enab
led by these robots which include: 1) rendering haptics for VR objects
 by providing just-in-time touch-points on the user’s hand, 2) simulat
ing continuous surfaces with the concurrent height and position change
, and 3) enabling the user to pick up and move VR objects through gras
pable proxy objects. Finally, we demonstrate HapticBots with various a
pplications, including remote collaboration, education and training, d
esign and 3D modeling, and gaming and entertainment.
AU  - Suzuki, Ryo
AU  - Ofek, Eyal
AU  - Sinclair, Mike
AU  - Leithinger, Daniel
AU  - Gonzalez-Franco, Mar
C1  - Virtual Event, USA
C3  - Adjunct Proceedings of the 34th Annual ACM Symposium on User Interface
 Software and Technology
DA  - 2021///
C2  - 2021
DO  - 10.1145/3474349.3480202
ID  - 10.1145/3474349.3480
KW  - virtual reality
KW  - tabletop mobile robots
KW  - swarm user interfaces
KW  - encountered-type haptics
PB  - Association for Computing Machinery
SN  - 9781450386555
SP  - 131-133
T3  - UIST '21 Adjunct
TI  - Demonstrating HapticBots: Distributed Encountered-type Haptics for VR 
with Multiple Shape-changing Mobile Robots
UR  - https://doi.org/10.1145/3474349.3480202
ER  - 
TY  - CONF
AB  - We present a portable 12x16 taxel haptic display optimized to rapidly 
display dynamic graphical information. Each taxel changes state (up/do
wn) in under 5 milliseconds, allowing the entire display of 192 indepe
ndent taxels to be refreshed in under 2 seconds. The user uses his sen
se of fine touch to explore the 7-inch display. We demonstrate applica
tions in serious gaming (tactile Pong for the visually impaired), remo
te collaboration between sighted and visually-impaired users (remote u
ser draws in real-time on the local haptic display), and navigation sc
enarios. Information can be displayed as a series of static relief ima
ges, or as a static image with moving or vibrating taxels. For the nav
igation task, the outline of a room and furniture is shown first as a 
static relief, the path to be followed is added as a moving taxels, an
d the user location is shown as a vibrating taxel. The taxels latch in
 both up and down states, leading to low power consumption.
AU  - Zarate, Juan Jose
AU  - Gudozhnik, Olexandr
AU  - Ruch, Anthony Sébastien
AU  - Shea, Herbert
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI Conference Extended Abstracts on Human Fac
tors in Computing Systems
DA  - 2017///
C2  - 2017
DO  - 10.1145/3027063.3052957
ID  - 10.1145/3027063.3052
KW  - taxel array
KW  - serious gaming
KW  - haptic display
KW  - electromagnetic actuators
PB  - Association for Computing Machinery
SN  - 9781450346566
SP  - 349-352
T3  - CHI EA '17
TI  - Keep in Touch: Portable Haptic Display with 192 High Speed Taxels
UR  - https://doi.org/10.1145/3027063.3052957
ER  - 
TY  - CONF
AB  - Annotating and proof-reading documents are common tasks. Digital annot
ation tools provide easily searchable annotations and facilitate shari
ng documents and remote collaboration with others. On the other hand, 
advantages of paper, such as creative freedom and intuitive use, can g
et lost when annotating digitally. There is a large amount of research
 indicating that paper outperforms digital annotation tools in task ti
me, error recall and task load. However, most research in this field i
s rather old and does not take into consideration increasing screen re
solution and performance, as well as better input techniques in modern
 devices. We present three user studies comparing different annotation
 media in the context of proof-reading tasks. We found that annotating
 on paper is still faster and less stressful than with a PC or tablet 
computer, but the difference is significantly smaller with a state-of-
the-art device. We did not find a difference in error recall, but the 
used medium has a strong influence on how users annotate.
AU  - Schmid, Andreas
AU  - Sautmann, Marie
AU  - Wittmann, Vera
AU  - Kaindl, Florian
AU  - Schauhuber, Philipp
AU  - Gottschalk, Philipp
AU  - Wimmer, Raphael
C1  - Rapperswil, Switzerland
C3  - Proceedings of Mensch Und Computer 2023
DA  - 2023///
C2  - 2023
DO  - 10.1145/3603555.3603572
ID  - 10.1145/3603555.3603
KW  - annotaion
KW  - digitalization
KW  - proof-reading
PB  - Association for Computing Machinery
SN  - 9798400707711
SP  - 277-288
T3  - MuC '23
TI  - Influence of Annotation Media on Proof-Reading Tasks
UR  - https://doi.org/10.1145/3603555.3603572
ER  - 
TY  - CONF
AB  - HapticBots introduces a novel encountered-type haptic approach for Vir
tual Reality (VR) based on multiple tabletop-size shape-changing robot
s. These robots move on a tabletop and change their height and orienta
tion to haptically render various surfaces and objects on-demand. Comp
ared to previous encountered-type haptic approaches like shape display
s or robotic arms, our proposed approach has an advantage in deployabi
lity, scalability, and generalizability—these robots can be easily dep
loyed due to their compact form factor. They can support multiple conc
urrent touch points in a large area thanks to the distributed nature o
f the robots. We propose and evaluate a novel set of interactions enab
led by these robots which include: 1) rendering haptics for VR objects
 by providing just-in-time touch-points on the user’s hand, 2) simulat
ing continuous surfaces with the concurrent height and position change
, and 3) enabling the user to pick up and move VR objects through gras
pable proxy objects. Finally, we demonstrate HapticBots with various a
pplications, including remote collaboration, education and training, d
esign and 3D modeling, and gaming and entertainment.
AU  - Suzuki, Ryo
AU  - Ofek, Eyal
AU  - Sinclair, Mike
AU  - Leithinger, Daniel
AU  - Gonzalez-Franco, Mar
C1  - Virtual Event, USA
C3  - The 34th Annual ACM Symposium on User Interface Software and Technolog
y
DA  - 2021///
C2  - 2021
DO  - 10.1145/3472749.3474821
ID  - 10.1145/3472749.3474
KW  - virtual reality
KW  - tabletop mobile robots
KW  - swarm user interfaces
KW  - encountered-type haptics
PB  - Association for Computing Machinery
SN  - 9781450386357
SP  - 1269-1281
T3  - UIST '21
TI  - HapticBots: Distributed Encountered-type Haptics for VR with Multiple 
Shape-changing Mobile Robots
UR  - https://doi.org/10.1145/3472749.3474821
ER  - 
TY  - JOUR
AB  - Collaborative Virtual Environments (CVE) have shown potential to be an
 effective social skill training platform for children with Autism Spe
ctrum Disorders (ASD) to learn and practice collaborative and communic
ation skills through peer interactions. However, most existing CVE sys
tems require that appropriately matched partners be available at the s
ame time to promote interaction, which limits their applicability to s
ome community settings due to scheduling constraints. A second shortco
ming of these more naturalistic peer-based designs is the intensive re
sources required to manually code the unrestricted conversations that 
occurred during the peer-based interactions. To preserve the benefits 
of CVE-based platforms and mitigate some of the resource limitations r
elated to peer availability, we developed an Intelligent Collaborative
 Haptic-Gripper System (INC-Hg). This system provides an intelligent a
gent partner who can understand, communicate, and haptically interact 
with the user, without requiring the presence of another human peer. T
he INC-Hg operates in real time and thus is able to perform collaborat
ive training tasks at any time and at the user's pace. INC-Hg can also
 record the real-time data regarding spoken language and task performa
nce, thereby greatly reducing the resource burden of communication and
 interaction performance analysis. A preliminary usability study with 
10 participants with ASD (ages 8–12 years) indicated that the system c
ould classify the participant's utterances into five classes with an a
ccuracy of 70.34%, which suggested the potential of INC-Hg to automati
cally recognize and analyze conversational content. The results also i
ndicated high accuracies of the agent to initiate a conversation (97.5
6%) and respond to the participants (86.52%), suggesting the capabilit
y of the agent to conduct proper conversations with the participants. 
Compared to the results of human-to-human collaborative tasks, the hum
an-to-agent mode achieved higher average collaborative operation ratio
 (61% compared to 40%) and comparable average frequencies for Initiati
ons and Responses among the participants with ASD. These results offer
 preliminary support as well as areas of improvement regarding the age
nt's ability to respond to participants, work with participants to com
plete tasks, engage in back-and-forth conversations, and support the p
otential of the agent to be a useful partner for individuals with ASD 
completing CVE tasks.
AU  - Zhao, Huan
AU  - Zaini Amat, Ashwaq
AU  - Migovich, Miroslava
AU  - Swanson, Amy
AU  - Weitlauf, Amy S.
AU  - Warren, Zachary
AU  - Sarkar, Nilanjan
DA  - 2022/3//
PY  - 2022
DO  - 10.1145/3487606
ID  - 10.1145/3487606
IS  - 1
KW  - haptic interaction
KW  - collaborative virtual environments
KW  - social interaction
KW  - conversational agent
KW  - AI techniques
KW  - Autism Spectrum Disorders
SN  - 1936-7228
T2  - ACM Trans. Access. Comput.
TI  - INC-Hg: An Intelligent Collaborative Haptic-Gripper Virtual Reality Sy
stem
UR  - https://doi.org/10.1145/3487606
VL  - 15
ER  - 
TY  - CONF
AB  - We introduce TwinSpace, a flexible software infrastructure for combini
ng interactive workspaces and collaborative virtual worlds. Its design
 is grounded in the need to support deep connectivity and flexible map
pings between virtual and real spaces to effectively support collabora
tion. This is achieved through a robust connectivity layer linking het
erogeneous collections of physical and virtual devices and services, a
nd a centralized service to manage and control mappings between physic
al and virtual. In this paper we motivate and present the architecture
 of TwinSpace, discuss our experiences and lessons learned in building
 a generic framework for collaborative cross-reality, and illustrate t
he architecture using two implemented examples that highlight its flex
ibility and range, and its support for rapid prototyping.
AU  - Reilly, Derek F.
AU  - Rouzati, Hafez
AU  - Wu, Andy
AU  - Hwang, Jee Yeon
AU  - Brudvik, Jeremy
AU  - Edwards, W. Keith
C1  - New York, New York, USA
C3  - Proceedings of the 23nd Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2010///
C2  - 2010
DO  - 10.1145/1866029.1866050
ID  - 10.1145/1866029.1866
KW  - virtual world
KW  - tuplespace
KW  - smart room
KW  - rdf
KW  - ontology
KW  - interactive room
KW  - cross-reality
KW  - collaborative virtual environment
PB  - Association for Computing Machinery
SN  - 9781450302715
SP  - 119-128
T3  - UIST '10
TI  - TwinSpace: an infrastructure for cross-reality team spaces
UR  - https://doi.org/10.1145/1866029.1866050
ER  - 
TY  - CONF
AB  - Research on distributed collaboration has predominantly focused on sha
red electronic media. We have found, as other researchers have, that u
sers often have good reason to want to work with physical media. Yet t
hey would still like to collaborate with each other. A fundamental ten
sion exists in the design of systems to support remote collaboration w
hen the interaction primitives are physical: physical objects live in 
one place. We have designed and implemented a remote collaboration sys
tem where users can still use physical objects. We introduce an intera
ction paradigm where objects that are physical in one space are electr
onic in the other space, and vice versa. Our distributed system is des
igned for two groups, with multiple users at each end. Our tangible ap
proach is the first system to enable simultaneous, multi-input across 
locations. We have implemented this system as an extension to the Desi
gners' Outpost[5].
AU  - Klemmer, Scott
AU  - Everitt, Katherine
C1  - Minneapolis, Minnesota, USA
C3  - CHI '02 Extended Abstracts on Human Factors in Computing Systems
DA  - 2002///
C2  - 2002
DO  - 10.1145/506443.506644
ID  - 10.1145/506443.50664
KW  - tangible
KW  - shared workspace
KW  - remote collaboration
KW  - CSCW
PB  - Association for Computing Machinery
SN  - 1581134541
SP  - 878-879
T3  - CHI EA '02
TI  - Bridging physical and electronic media for distributed design collabor
ation
UR  - https://doi.org/10.1145/506443.506644
ER  - 
TY  - CONF
AB  - Experiencing virtual environments is often limited to abstract interac
tions with objects. Physical proxies allow users to feel virtual objec
ts, but are often inaccessible. We present the VoxelHap toolkit which 
enables users to construct highly functional proxy objects using Voxel
s and Plates. Voxels are blocks with special functionalities that form
 the core of each physical proxy. Plates increase a proxy’s haptic res
olution, such as its shape, texture or weight. Beyond providing physic
al capabilities to realize haptic sensations, VoxelHap utilizes VR ill
usion techniques to expand its haptic resolution. We evaluated the cap
abilities of the VoxelHap toolkit through the construction of a range 
of fully functional proxies across a variety of use cases and applicat
ions. In two experiments with 24 participants, we investigate a subset
 of the constructed proxies, studying how they compare to a traditiona
l VR controller. First, we investigated VoxelHap’s combined haptic fee
dback and second, the trade-offs of using ShapePlates. Our findings sh
ow that VoxelHap’s proxies outperform traditional controllers and were
 favored by participants.
AU  - Feick, Martin
AU  - Biyikli, Cihan
AU  - Gani, Kiran
AU  - Wittig, Anton
AU  - Tang, Anthony
AU  - Krüger, Antonio
C1  - San Francisco, CA, USA
C3  - Proceedings of the 36th Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2023///
C2  - 2023
DO  - 10.1145/3586183.3606722
ID  - 10.1145/3586183.3606
KW  - Virtual Reality
KW  - haptics
KW  - kinesthetic
KW  - reconfigurable
KW  - tactile
KW  - toolkit
PB  - Association for Computing Machinery
SN  - 9798400701320
T3  - UIST '23
TI  - VoxelHap: A Toolkit for Constructing Proxies Providing Tactile and Kin
esthetic Haptic Feedback in Virtual Reality
UR  - https://doi.org/10.1145/3586183.3606722
ER  - 
TY  - CONF
AB  - Technologies for notating music pose usage barriers to blind and visua
lly impaired musicians requiring many to overcome a significant learni
ng curve and/or rely on complicated tool chains with limited screen re
ader support. To address a need for accessible music notation software
, we present SoundCells, a browser-based system designed to make music
 notation easy, intuitive, and accessible to screen reader users, and 
output music in audio, print, and braille formats. We share findings f
rom a co-design process, in which two experienced musicians used Sound
Cells for two months guided by four remote meetings, and from a Design
 Probe, in which five other musicians tried SoundCells with a screen r
eader and reflected on its usability and accessibility in the context 
of their current practices. Finally, we discuss design recommendations
 relevant to a broader ecosystem of creative technologies, including h
ow text-editing and multi-modal output capabilities could be extended 
and improved, how SoundCells' current design facilitated remote collab
oration between sighted researchers and blind musicians, and future op
portunities for learning and sharing music on the web.
AU  - Payne, William
AU  - Ahmed, Fabiha
AU  - Gardell, Michael
AU  - DuBois, R. Luke
AU  - Hurst, Amy
C1  - Lyon, France
C3  - Proceedings of the 19th International Web for All Conference
DA  - 2022///
C2  - 2022
DO  - 10.1145/3493612.3520462
ID  - 10.1145/3493612.3520
KW  - visual impairments
KW  - music technology
KW  - music notation
KW  - co-design
KW  - braille
KW  - accessibility
PB  - Association for Computing Machinery
SN  - 9781450391702
T3  - W4A '22
TI  - SoundCells: designing a browser-based music technology for braille and
 print notation
UR  - https://doi.org/10.1145/3493612.3520462
ER  - 
TY  - CONF
AB  - Networked collaborative virtual reality systems have been proposed for
 surgical education. They allow an instructor to teach a student using
 a shared virtual model, even if separated by distance. For these syst
ems to be accepted within the surgical community there must be a compe
lling body of evidence that demonstrates that learning occurs in the t
raining environment, and is transferable to the operating theatre. We 
have developed a networked multisensory virtual reality system for tea
ching surgery of the temporal bone and conducted a training transfer t
rial. To augment the quantitative analysis of the results, we have per
formed a qualitative analysis of the transcripts of videotapes of the 
learning phase of the trial, using techniques from Conversation Analys
is. In this short paper we present a single case study that convincing
ly demonstrates that learning occurred within the instruction phase of
 the trial.
AU  - Hutchins, Matthew
AU  - Stevenson, Duncan
AU  - Gunn, Chris
AU  - Krumpholz, Alexander
AU  - Pyman, Brian
AU  - O'Leary, Stephen
C1  - Canberra, Australia
C3  - Proceedings of the 17th Australia Conference on Computer-Human Interac
tion: Citizens Online: Considerations for Today and the Future
DA  - 2005///
C2  - 2005
ID  - 10.5555/1108368.1108
KW  - collaborative virtual environment
KW  - conversation analysis
KW  - evaluation
KW  - surgical simulation
PB  - Computer-Human Interaction Special Interest Group (CHISIG) of Australi
a
SN  - 1595932224
SP  - 1-4
T3  - OZCHI '05
TI  - "I think i can see it now!": evidence of learning in video transcripts
 of a collaborative virtual reality surgical training trial
ER  - 
TY  - CONF
AB  - Virtual embodiment has become popular for enhancing virtual interactio
n in terms of sharing object information. A user can control a charact
er or object in a virtual environment to provide immersive interactive
 experience. However, one of the limitations for the virtual interacti
ons was the incapability to receive feedback apart from visual hints. 
In this demonstration, we present using servo motor and Galvanic Vesti
bular Stimulation to provide feedback from a virtual interaction. Our 
technique transforms information of the virtual objects (e.g.: weight)
 into haptic and proprioceptive feedback that stimulates different sen
sations to a user. We present the user experience to the attendees of 
SIGGRAPH 2020 through a live demonstration in a virtual environment co
ntrolled using a virtual robotic arm.
AU  - Teo, Theophilus
AU  - Nakamura, Fumihiko
AU  - Sugimoto, Maki
AU  - Verhulst, Adrien
AU  - A. Lee, Gun
AU  - Billinghurst, Mark
AU  - Adcock, Matt
C1  - Virtual Event, USA
C3  - ACM SIGGRAPH 2020 Emerging Technologies
DA  - 2020///
C2  - 2020
DO  - 10.1145/3388534.3407288
ID  - 10.1145/3388534.3407
KW  - Proprioceptive feedback
KW  - Human Augmentation
KW  - Haptic Feedback
PB  - Association for Computing Machinery
SN  - 9781450379670
T3  - SIGGRAPH '20
TI  - Feel it: Using Proprioceptive and Haptic Feedback for Interaction with
 Virtual Embodiment
UR  - https://doi.org/10.1145/3388534.3407288
ER  - 
TY  - CONF
AB  - Advancing virtual reality technologies are enabling real-time virtual-
face to virtual-face communication. Hand tracking systems that are int
egrated into Head-Mounted Displays (HMD) enable users to directly inte
ract with their environments and with each other using their hands as 
opposed to using controllers. Due to the novelties of these technologi
es our understanding of how they impact our interactions is limited. I
n this paper, we investigate the consequences of using different inter
action control systems, hand tracking or controllers, when interacting
 with others in a virtual environment. We design and implement NASA’s 
Survival on the Moon teamwork evaluation exercise in virtual reality (
VR) and test for effects with and without allowing verbal communicatio
n. We evaluate social presence, perceived comprehension, team cohesion
, group synergy, task workload, as well as task performance and durati
on. Our findings reveal that audio communication significantly enhance
s social presence, perceived comprehension, and team cohesion, but it 
also increases effort workload and negatively impacts group synergy. T
he choice of interaction control systems has limited impact on various
 aspects of virtual collaboration in this scenario, although participa
nts using hand tracking reported lower effort workload, while particip
ants using controllers reported lower mental workload in the absence o
f audio.
AU  - Adkins, Alex
AU  - Canales, Ryan
AU  - Jörg, Sophie
C1  - Trier, Germany
C3  - Proceedings of the 30th ACM Symposium on Virtual Reality Software and 
Technology
DA  - 2024///
C2  - 2024
DO  - 10.1145/3641825.3687718
ID  - 10.1145/3641825.3687
KW  - Communication
KW  - avatars
KW  - collaboration
KW  - gestures
PB  - Association for Computing Machinery
SN  - 9798400705359
T3  - VRST '24
TI  - Hands or Controllers? How Input Devices and Audio Impact Collaborative
 Virtual Reality
UR  - https://doi.org/10.1145/3641825.3687718
ER  - 
TY  - CONF
AB  - In this paper, we present a new application framework aimed to support
 distributed synchronous collaboration using multitouch interaction. T
he framework supports 2D and 3D virtual workspaces that enable two or 
more users to collaboratively or cooperatively manipulate shared objec
ts with multitouch interfaces. We present two applications developed w
ith the aim to explore 2D/3D immersive collaborative environments with
 multitouch interaction. We also present our experience and preliminar
y results in designing, developing and integrating these applications 
on educational settings.
AU  - Ardaiz, Oscar
AU  - Arroyo, Ernesto
AU  - Righi, Valeria
AU  - Galimany, Oriol
AU  - Blat, Josep
C1  - Berlin, Germany
C3  - Proceedings of the 2nd ACM SIGCHI Symposium on Engineering Interactive
 Computing Systems
DA  - 2010///
C2  - 2010
DO  - 10.1145/1822018.1822055
ID  - 10.1145/1822018.1822
KW  - remote collaboration
KW  - multitouch interaction
KW  - distributed virtual environment
PB  - Association for Computing Machinery
SN  - 9781450300834
SP  - 235-240
T3  - EICS '10
TI  - Virtual collaborative environments with distributed multitouch support

UR  - https://doi.org/10.1145/1822018.1822055
ER  - 
TY  - CONF
AB  - In this paper we showcase an integrative approach for our actuated Tan
gible Active Objects (TAOs), that demonstrates distributed collaborati
on support to become a versatile and comprehensive dynamic user interf
ace with multi-modal feedback. We incorporated physical actuation, vis
ual projection in 2D and 3D, and vibro-tactile feedback. We demonstrat
e this approach in a furniture placing scenario where the users can in
teractively change the furniture model represented by each TAO using a
 dial-based tangible actuated menu. We demonstrate virtual constraints
 between our TAOs to automatically maintain spatial relations.
AU  - Riedenklau, Eckard
AU  - Hermann, Thomas
AU  - Ritter, Helge
C1  - Kingston, Ontario, Canada
C3  - Proceedings of the Sixth International Conference on Tangible, Embedde
d and Embodied Interaction
DA  - 2012///
C2  - 2012
DO  - 10.1145/2148131.2148167
ID  - 10.1145/2148131.2148
KW  - virtual constraints
KW  - tangible interaction
KW  - remote collaboration
KW  - multimodal feedback
KW  - mixed-reality
KW  - actuated tangible objects
PB  - Association for Computing Machinery
SN  - 9781450311748
SP  - 169-174
T3  - TEI '12
TI  - An integrated multi-modal actuated tangible user interface for distrib
uted collaborative planning
UR  - https://doi.org/10.1145/2148131.2148167
ER  - 
TY  - JOUR
AB  - This article proposes an empirical method for inferring causal directi
ons in multidimensional Quality of Experience (QoE) in multimedia comm
unications, noting that causation in QoE is perceptual. As an example 
for modeling framework, we pick up a Bayesian structural equation mode
l (SEM) previously built for haptic audiovisual interactive communicat
ions. The SEM includes three constructs (Audiovisual quality, Haptic q
uality, and User experience quality), which are latent variables each 
representing a group of observed variables with similar characteristic
s. In the SEM, the causal directions of the constructs were assumed by
 resorting to the domain knowledge. This article aims at proposing a m
ethodology for inferring causal directions of constructs in general by
 verifying the assumption of causal directions in the SEM through thei
r observed data alone. For that purpose, we compare six SEMs each with
 different causal directions of constructs, one of which is the one fr
om the domain knowledge. The proposed method is based on QoE predictio
n by a Bayesian approach with Markov chain Monte Carlo (MCMC) simulati
on. Setting observed scores to the indicators of exogenous variables i
n each SEM, we predict values of all the indicators; we then assess th
e mean square error (MSE) between predicted QoE and mean opinion score
 (MOS) from observed scores and estimate the probability distribution 
of the MSE in each SEM. We can compare any two SEMs to find which is m
ore plausible by examining the probability that the MSE for one SEM is
 smaller than or equal to that for the other. These probabilities are 
estimated with MCMC simulation. The method indicates that the causal d
irections thus inferred for the haptic audiovisual interactive communi
cations adequately support the original ones drawn from the domain kno
wledge. In addition, we demonstrate that QoE can behave like the “impa
ct-perceive-adapt” model of the effects of delayed haptic and visual f
eedback on performance in a collaborative environment, which Jay, Glen
cross, and Hubbold proposed in 2007, and that it accompanies reversal 
of plausible causal directions like a flip–flop.
AU  - Tasaka, Shuji
DA  - 2022/1//
PY  - 2022
DO  - 10.1145/3473986
ID  - 10.1145/3473986
IS  - 1
KW  - OpenBUGS
KW  - MCMC
KW  - haptic–audiovisual interactive communications
KW  - Bayesian modeling
KW  - latent variables
KW  - construct
KW  - SEM
KW  - causation
KW  - media synchronization
KW  - Quality of Experience (QoE)
KW  - Causal inference
SN  - 1551-6857
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
TI  - An Empirical Method for Causal Inference of Constructs for QoE in Hapt
ic–Audiovisual Communications
UR  - https://doi.org/10.1145/3473986
VL  - 18
ER  - 
TY  - CONF
AB  - The mining industry is interested in tele-operation systems to remove 
mining operators from hazardous or inconvenient environments without l
osing efficiency. Technologies to enhance the operator's experience ar
e advancing but there is a lack of evidence supporting the extent to w
hich these emerging technologies positively affect user experience. In
 this paper, we describe three applications that make use of networked
 virtual and mixed reality. These prototype systems each represent a s
tep towards new VR based technologies that will increase the efficienc
y and safety of the mining industry.
AU  - Bednarz, Tomasz
AU  - James, Craig
AU  - Caris, Con
AU  - Haustein, Kerstin
AU  - Adcock, Matt
AU  - Gunn, Chris
C1  - Hong Kong, China
C3  - Proceedings of the 10th International Conference on Virtual Reality Co
ntinuum and Its Applications in Industry
DA  - 2011///
C2  - 2011
DO  - 10.1145/2087756.2087845
ID  - 10.1145/2087756.2087
KW  - virtual reality
KW  - tele-operation
KW  - remote control
KW  - remote collaboration
KW  - presence
KW  - measures
PB  - Association for Computing Machinery
SN  - 9781450310604
SP  - 459-462
T3  - VRCAI '11
TI  - Applications of networked virtual reality for tele-operation and tele-
assistance systems in the mining industry
UR  - https://doi.org/10.1145/2087756.2087845
ER  - 
TY  - CONF
AB  - Over the last decades, E-learning has gained a lot of popularity and e
nabled students to learn in front of their computers using Internet-ba
sed learning systems rather than physically attending lectures. Those 
E-learning systems are different from traditional learning and do not 
fully immerse the student in the learning environment. Thus, we propos
e Teachyverse, an immersive VR lecture hall that combines e-learning, 
traditional learning, and remote collaboration. Teachyverse immerses t
he student in a virtual lecture hall. A proof-of-concept study shows t
hat students perceive lectures in Teachyverse as fun and would like to
 use Teachyverse as a further E-Learning option.
AU  - Marky, Karola
AU  - Müller, Florian
AU  - Funk, Markus
AU  - Geiß, Alexander
AU  - Günther, Sebastian
AU  - Schmitz, Martin
AU  - Riemann, Jan
AU  - Mühlhäuser, Max
C1  - Hamburg, Germany
C3  - Proceedings of Mensch Und Computer 2019
DA  - 2019///
C2  - 2019
DO  - 10.1145/3340764.3344917
ID  - 10.1145/3340764.3344
KW  - Virtual Reality
KW  - Virtual Lecture
KW  - Lecture halls
KW  - E-Learning
PB  - Association for Computing Machinery
SN  - 9781450371988
SP  - 831-834
T3  - MuC '19
TI  - Teachyverse: Collaborative E-Learning in Virtual Reality Lecture Halls

UR  - https://doi.org/10.1145/3340764.3344917
ER  - 
TY  - CONF
AB  - This sketch describes a collaborative virtual environment application 
involving haptic interaction over long Internet distances. We have dev
eloped algorithms to accommodate significant latency for certain appli
cations, notably in the medical domain. The results have shown that we
 can manipulate simulated human body organs, as well as guide each oth
er's 'hands' (and shake hands!) over 22,000 km.
AU  - Gunn, Chris
AU  - Hutchins, Matthew
AU  - Adcock, Matt
AU  - Hawkins, Rhys
C1  - San Diego, California
C3  - ACM SIGGRAPH 2003 Sketches &amp; Applications
DA  - 2003///
C2  - 2003
DO  - 10.1145/965400.965495
ID  - 10.1145/965400.96549
PB  - Association for Computing Machinery
SN  - 9781450374668
SP  - 1
T3  - SIGGRAPH '03
TI  - Trans-world haptic collaboration
UR  - https://doi.org/10.1145/965400.965495
ER  - 
TY  - CONF
AB  - We built a Collaborative Virtual Environment (CVE) allowing one person
, the 'visitor' to be digitally transported to a remote destination to
 interact with local people there. This included full body tracking, v
ibrotactile feedback and voice. This allowed interactions in the same 
CVE between multiple people situated in different physical remote loca
tions. This system was used for an experiment to study whether the con
veyance of touch has an impact on the willingness of participants embo
died in the CVE to sing in public.In a first experimental condition, t
he experimenter virtually touched the avatar of the participants on th
e shoulder, producing vibrotactile feedback. In another condition usin
g the identical physical setup, the vibrotactile displays were not act
ivated, so that they would not feel the touch. Our hypothesis was that
 the tactile touch condition would produce a greater likelihood of com
pliance with the request to sing. In a second part we examined the hyp
othesis that people might be more willing to sing (execute an embarras
sing task) in a CVE, because of the anonymity provided by virtual real
ity. Hence we carried out a similar study in physical reality.The resu
lts suggest that the tactile intervention had no effect on the sensati
ons of body ownership, presence or the behaviours of the participants,
 in spite of the finding that the sensation of touch itself was effect
ively realised. Moreover we found an overall similarity in responses b
etween the VR and real conditions.
AU  - Bourdin, Pierre
AU  - Sanahuja, Josep Maria Tomàs
AU  - Moya, Carlota Crusafon
AU  - Haggard, Patrick
AU  - Slater, Mel
C1  - Singapore
C3  - Proceedings of the 19th ACM Symposium on Virtual Reality Software and 
Technology
DA  - 2013///
C2  - 2013
DO  - 10.1145/2503713.2503724
ID  - 10.1145/2503713.2503
KW  - social touch
KW  - presence
KW  - haptic interaction
KW  - embodiment
KW  - collaborative virtual environments
PB  - Association for Computing Machinery
SN  - 9781450323796
SP  - 123-132
T3  - VRST '13
TI  - Persuading people in a remote destination to sing by beaming there
UR  - https://doi.org/10.1145/2503713.2503724
ER  - 
TY  - CONF
AB  - Spatial cues are an important element of navigating people in physical
/virtual spaces. In terms of spatial navigation, integrating vision wi
th other modalities, such as haptics, can guide users more effectively
. Haptic cues are presented on the body parts that are sensitive to st
imuli such as hands and a head. The head is reported to be superior to
 the body for spatial directional perception. In this paper, we propos
e Virtual Whiskers, a spatial directional guidance technique by haptic
 stimulation of the cheeks using tiny robot arms attached to a Head-Mo
unted Display (HMD). We deploy photo reflective sensors attached to th
e tip of 2 robotic arms to detect the distance between the tip and the
 cheek surface. Using the robot arms, we stimulate a point on the chee
k obtained by calculating an intersection between the cheek surface an
d the target direction. We experimentally investigated how accurately 
participants identify the target direction provided by our guidance me
thod. We evaluated an error between the actual target direction and th
e participant’s pointed direction. The experimental result shows that 
our method achieves the average absolute directional error of 2.76 deg
rees in the azimuthal plane and 7.32 degrees in the elevation plane. W
e also conducted a spatial guidance experiment to evaluate task perfor
mance in a target search task. We compared the condition of only visio
n and vision with haptics for task completion time. The average of tas
k completion time in visual-only condition was M=12.45 s, SD=14.51 s, 
and visual with haptic condition resulted in M=6.91 s, SD=5.48 s. Stat
istical test revealed a significant difference in task completion time
 between the visual condition and the visual+haptic condition.
AU  - Nakamura, Fumihiko
AU  - Verhulst, Adrien
AU  - Sakurada, Kuniharu
AU  - Sugimoto, Maki
C1  - Rovaniemi, Finland
C3  - Proceedings of the Augmented Humans International Conference 2021
DA  - 2021///
C2  - 2021
DO  - 10.1145/3458709.3458987
ID  - 10.1145/3458709.3458
KW  - virtual reality
KW  - spatial guidance
KW  - robot arm
KW  - facial haptics
PB  - Association for Computing Machinery
SN  - 9781450384285
SP  - 141-151
T3  - AHs '21
TI  - Virtual Whiskers: Spatial Directional Guidance using Cheek Haptic Stim
ulation in a Virtual Environment
UR  - https://doi.org/10.1145/3458709.3458987
ER  - 
TY  - CONF
AB  - Collaborative multi-user Augmented Reality (AR) applications pose seri
ous challenges to the underlying network infrastructure due to their a
ll-to-all communication pattern. The Named Data Networking (NDN) parad
igm can be a crucial enabler of these applications operated in extreme
ly large scale in terms of users, amount of content, and network size.
 The inherent multicast support together with a carefully designed nam
ing scheme can provide the efficient network operation, while the infl
ated Forwarding Information Base (FIB) tables of typical NDN routers c
an be compressed by powerful algorithms to make the concept feasible.I
n this demonstration, we showcase an AR application supporting remote 
collaboration for a large number of users. The software stack of our p
roof-of-concept prototype leverages open source tools, such as ChronoS
ync, NDN Forwarding Daemon (NFD), Named Data Link State Routing Protoc
ol (NLSR), and in order to validate the feasibility of the concept, we
 established a flexible NDN test environment based on Docker container
s, real Android clients and emulated users. The framework enables star
ting arbitrary NDN topologies with predefined FIB contents and to emul
ate thousands of users. During the live demo, we can show the current 
network status and relevant performance metrics, such as end-to-end ap
plication latency, crucial for AR applications.
AU  - Dóka, János
AU  - Nagy, Bálint György
AU  - Rehman, Muhammad Atif Ur
AU  - Kim, Dong-Hak
AU  - Kim, Byung-Seo
AU  - Toka, László
AU  - Sonkoly, Balázs
C1  - Virtual event
C3  - Proceedings of the SIGCOMM '20 Poster and Demo Sessions
DA  - 2021///
C2  - 2021
DO  - 10.1145/3405837.3411386
ID  - 10.1145/3405837.3411
KW  - augmented reality
KW  - named data networking
KW  - scalability
PB  - Association for Computing Machinery
SN  - 9781450380485
SP  - 44-45
T3  - SIGCOMM '20
TI  - AR over NDN: augmented reality applications and the rise of informatio
n centric networking
UR  - https://doi.org/10.1145/3405837.3411386
ER  - 
TY  - CONF
AB  - As virtual reality (VR) usage becomes more popular, one of the issues,
 among others, which still prevents VR from being used in a more ubiqu
itous manner is spatial awareness, unlike augmented reality (AR). Gene
rally, there are two forms of such an awareness; recognizing the envir
onment and recognizing other people around us. We propose face2faceVR;
 an easy to use implementation of AR tracking to assist VR towards rec
ognizing other nearby VR users. The contribution of this work are the 
following; 1) it is compatible with mobile VR technology that already 
caters towards a wider adoption, 2) it does not require a networked or
 shared virtual environment, and 3) it is an inexpensive implementatio
n without any additional peripherals or hardware.
AU  - Pai, Yun Suen
AU  - Isogai, Megumi
AU  - Ochi, Daisuke
AU  - Kimata, Hideaki
AU  - Kunze, Kai
C1  - Maui, Hawaii
C3  - Proceedings of the 2017 ACM International Joint Conference on Pervasiv
e and Ubiquitous Computing and Proceedings of the 2017 ACM Internation
al Symposium on Wearable Computers
DA  - 2017///
C2  - 2017
DO  - 10.1145/3123024.3123155
ID  - 10.1145/3123024.3123
KW  - virtual reality
KW  - ubiquitous VR
KW  - spatial awareness
KW  - augmented reality
PB  - Association for Computing Machinery
SN  - 9781450351904
SP  - 173-176
T3  - UbiComp '17
TI  - face2faceVR: using AR to assist VR in ubiquitous environment usage
UR  - https://doi.org/10.1145/3123024.3123155
ER  - 
TY  - CONF
AB  - With recent developments in 3D display interfaces, which are now capab
le of delivering rich and immersive visual experiences, a need has ari
sen to develop haptic-feedback technologies that can seamlessly be int
egrated with such displays – in order to maintain the sense of visual 
realism during interactions and to enable multimodal user experiences.
 We present an approach to augmenting conventional and 3D displays wit
h free-space haptic feedback capabilities via a large number of closel
y-spaced air-vortex-ring generators mounted along the periphery of the
 display. We then present our ongoing work on building an open-source 
system based on this approach that uses 16 vortex-ring generators, and
 show how it could serve as a multimodal interactive interface, as a r
esearch tool, and as a novel platform for creative expressions.
AU  - Shtarbanov, Ali
AU  - Bove Jr., V. Michael
C1  - Montreal QC, Canada
C3  - Extended Abstracts of the 2018 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2018///
C2  - 2018
DO  - 10.1145/3170427.3188622
ID  - 10.1145/3170427.3188
KW  - 3d displays
KW  - air-vortex rings
KW  - haptic feedback
KW  - methods
KW  - multimodal interfaces
KW  - tactile feedback
PB  - Association for Computing Machinery
SN  - 9781450356213
SP  - 1-6
T3  - CHI EA '18
TI  - Free-Space Haptic Feedback for 3D Displays via Air-Vortex Rings
UR  - https://doi.org/10.1145/3170427.3188622
ER  - 
TY  - CONF
AB  - Although the necessity and importance of exercise support for the elde
rly people is largely recognized, the lack of skilled and adequate ins
tructors often limits such activities physically. Remote exercise syst
ems can be a solution for this problem because they may be able to sup
port exercise activities even when instructors and participants are in
 separate locations. However, when simply using normal video-conferenc
ing systems, instructors and participants have difficulty understandin
g each side's situation, particularly during guided physical actions. 
In addition, remote exercise systems cannot support the adjustment of 
the position of each user, a task that is quite naturally performed in
 normal exercise activities. Our system, called CASPER, solves these p
roblems by proposing a mirror-like image composition method in which a
ll the participants and the instructor are shown on the same screen so
 that both sides can understand the situation clearly. We also introdu
ce an airy haptic device to remotely send tactile feedback for further
 enhancing sensations. In this paper, we describe the system design an
d its evaluation. The evaluation confirms that our system could effect
ively allow users to perform exercise activities even at remote locati
ons.
AU  - Kadomura, Azusa
AU  - Matsuda, Akira
AU  - Rekimoto, Jun
C1  - Geneva, Switzerland
C3  - Proceedings of the 7th Augmented Human International Conference 2016
DA  - 2016///
C2  - 2016
DO  - 10.1145/2875194.2875197
ID  - 10.1145/2875194.2875
KW  - Telepresence
KW  - Rehabilitation
KW  - Haptic
KW  - Fitness
KW  - Exercise
KW  - Elderly people
KW  - Airy feedback
PB  - Association for Computing Machinery
SN  - 9781450336802
T3  - AH '16
TI  - CASPER: A Haptic Enhanced Telepresence Exercise System for Elderly Peo
ple
UR  - https://doi.org/10.1145/2875194.2875197
ER  - 
TY  - CONF
AB  - Passive haptic proxy objects allow for rich tangible interaction, and 
this is especially true in VR applications. However, this requires use
rs to have many physical objects at hand. Our paper proposes robotic a
ssembly at run-time of low-resolution haptic proxies for tangible inte
raction and virtual reality. These assembled physical proxy objects ar
e composed of magnetically attached blocks which are assembled by a sm
all multi robot system, specifically Zooids. We explore the design of 
the basic building blocks and illustrate two approaches to assembling 
physical proxies: using multirobot systems to (1) self-assemble into s
tructures and (2) assemble 2.5D structure with passive blocks of vario
us heights. The success rate and completion time are evaluated for bot
h approaches. Finally, we demonstrate the potential of assembled proxy
 objects for tangible interaction and virtual reality through a set of
 demonstrations.
AU  - Zhao, Yiwei
AU  - Kim, Lawrence H.
AU  - Wang, Ye
AU  - Le Goc, Mathieu
AU  - Follmer, Sean
C1  - Brighton, United Kingdom
C3  - Proceedings of the 2017 ACM International Conference on Interactive Su
rfaces and Spaces
DA  - 2017///
C2  - 2017
DO  - 10.1145/3132272.3134143
ID  - 10.1145/3132272.3134
KW  - Tangible Virtual Reality
KW  - Self-Assembly
KW  - Robotic Assembly
KW  - Passive Haptics
KW  - Haptics
KW  - Haptic Proxy Objects
PB  - Association for Computing Machinery
SN  - 9781450346917
SP  - 82-91
T3  - ISS '17
TI  - Robotic Assembly of Haptic Proxy Objects for Tangible Interaction and 
Virtual Reality
UR  - https://doi.org/10.1145/3132272.3134143
ER  - 
TY  - CONF
AB  - The preservation of cultural heritage, as mandated by the United Natio
ns Sustainable Development Goals (SDGs), is integral to sustainable ur
ban development. This paper focuses on the Dragon Boat Festival, a pro
minent event in Chinese cultural heritage, and proposes leveraging Vir
tual Reality (VR), to enhance its preservation and accessibility. Trad
itionally, participation in the festival's dragon boat races was limit
ed to elite athletes, excluding broader demographics. Our proposed sol
ution, named MetaDragonBoat, enables virtual participation in dragon b
oat racing, offering immersive experiences that replicate physical exe
rtion through a cultural journey. Thus, we build a digital twin of a u
niversity campus located in a region with a rich dragon boat racing tr
adition. Coupled with three paddling techniques that are enabled by ei
ther commercial controllers or physical paddle controllers with haptic
 feedback, diversified users can engage in realistic rowing experience
s. Our results demonstrate that by integrating resistance into the pad
dle controls, users could simulate the physical effort of dragon boat 
racing, promoting a deeper understanding and appreciation of this cult
ural heritage.
AU  - He, Wei
AU  - Li, Xiang
AU  - Xu, Shengtian
AU  - Chen, Yuzheng
AU  - Sio, Chan-In
AU  - Kan, Ge Lin
AU  - Lee, Lik-Hang
C1  - Melbourne VIC, Australia
C3  - Proceedings of the 32nd ACM International Conference on Multimedia
DA  - 2024///
C2  - 2024
DO  - 10.1145/3664647.3681078
ID  - 10.1145/3664647.3681
KW  - culture
KW  - exergame
KW  - haptic simulator
KW  - metaverse
PB  - Association for Computing Machinery
SN  - 9798400706868
SP  - 6335-6344
T3  - MM '24
TI  - MetaDragonBoat: Exploring Paddling Techniques of Virtual Dragon Boatin
g in a Metaverse Campus
UR  - https://doi.org/10.1145/3664647.3681078
ER  - 
TY  - CONF
AB  - In this work, we utilize visuo-haptic illusions to improve the perceiv
ed performance of encountered-type haptic devices, specifically shape 
displays, in virtual reality. Shape displays are matrices of actuated 
pins that travel vertically to render physical shapes; however, they h
ave limitations such as low resolution, small display size, and low pi
n speed. To address these limitations, we employ illusions such as red
irection, scaling, and retargeting that take advantage of the visual d
ominance effect, the idea that vision often dominates when senses conf
lict. Our evaluation of these techniques suggests that redirecting slo
ped lines with angles less than 40 degrees onto a horizontal line is a
n effective technique for increasing the perceived resolution of the d
isplay. Scaling up the virtual object onto the shape display by a fact
or less than 1.8x can also increase the perceived resolution. Finally,
 using vertical redirection a perceived 3x speed increase can be achie
ved.
AU  - Abtahi, Parastoo
AU  - Follmer, Sean
C1  - Montreal QC, Canada
C3  - Proceedings of the 2018 CHI Conference on Human Factors in Computing S
ystems
DA  - 2018///
C2  - 2018
DO  - 10.1145/3173574.3173724
ID  - 10.1145/3173574.3173
KW  - virtual reality
KW  - shape displays
KW  - perception
KW  - illusion
KW  - haptics
PB  - Association for Computing Machinery
SN  - 9781450356206
SP  - 1-13
T3  - CHI '18
TI  - Visuo-Haptic Illusions for Improving the Perceived Performance of Shap
e Displays
UR  - https://doi.org/10.1145/3173574.3173724
ER  - 
TY  - CONF
AB  - This paper describes a study of remote collaboration between people in
 a shared virtual environment. Seventeen subjects were recruited at Un
iversity College London, who worked with a confederate at University o
f North Carolina Chapel Hill. Each pair was required to negotiate the 
task of handling an object together, and moving a few metres into a bu
ilding. The DIVE system was used throughout, and the network support w
as Internet-2. This was an observational study to examine the extent t
o which such collaboration was possible, to explore the limitations of
 DIVE within this context, and to examine the relationship between sev
eral variables such as co-presence and task performance. The results s
uggest that although the task is possible under this framework, it cou
ld only be achieved by various software tricks within the DIVE framewo
rk. A new Virtual Environment system is required that has better knowl
edge of network performance, and that supports shared object manipulat
ion across a network. The participant-study suggests that co-presence,
 the sense of being together with another person, was significantly an
d positively correlated with task performance.
AU  - Mortensen, J.
AU  - Vinayagamoorthy, V.
AU  - Slater, M.
AU  - Steed, A.
AU  - Lok, B.
AU  - Whitton, M. C.
C1  - Barcelona, Spain
C3  - Proceedings of the Workshop on Virtual Environments 2002
DA  - 2002///
C2  - 2002
ID  - 10.5555/509709.50972
KW  - collaborative virtual environments
KW  - internet-2
KW  - presence
KW  - virtual reality
PB  - Eurographics Association
SN  - 1581135351
SP  - 93-101
T3  - EGVE '02
TI  - Collaboration in tele-immersive environments
ER  - 
TY  - JOUR
AB  - Computer-assisted systems can provide efficient and engaging ASD inter
vention environments for children with Autism Spectrum Disorder (ASD).
 However, most existing computer-assisted systems target only one skil
l deficit (e.g., social conversation skills) and ignore the importance
 of other areas, such as motor skills, that could also impact social i
nteraction. This focus on a single domain may hinder the generalizabil
ity of learned skills to real-world scenarios, because the targeted te
aching strategies do not reflect that real-world tasks often involve m
ore than one skill domain. The work presented in this article seeks to
 bridge this gap by developing a Collaborative Haptic-gripper virtual 
skill training system (C-Hg). This system includes individual and coll
aborative games that provide opportunities for simultaneously practici
ng both fine motor skills (hand movement and grip control skills) as w
ell as social skills (communication and collaboration) and investigati
ng how they relate to each other. We conducted a usability study with 
10 children with ASD and 10 Typically Developing (TD) children (8–12 y
ears), who used C-Hg to play a series of individual and collaborative 
games requiring differing levels of motor and communication skill. Res
ults revealed that participant performance significantly improved in b
oth individual and collaborative fine motor skill training tasks, incl
uding significant improvements in collaborative manipulations between 
partners. Participants with ASD were found to conduct more collaborati
ve manipulations and initiate more conversations with their partners i
n the post collaborative tasks, suggesting more active collaboration a
nd communication of participants with ASD in the collaborative tasks. 
Results support the potential of our C-Hg system for simultaneously im
proving fine motor and social skills, with implications for impacts of
 improved fine motor skills on social outcomes.
AU  - Zhao, Huan
AU  - Amat, Ashwaq Zaini
AU  - Migovich, Miroslava
AU  - Swanson, Amy
AU  - Weitlauf, Amy S.
AU  - Warren, Zachary
AU  - Sarkar, Nilanjan
DA  - 2021/7//
PY  - 2021
DO  - 10.1145/3459608
ID  - 10.1145/3459608
IS  - 2
SN  - 1936-7228
T2  - ACM Trans. Access. Comput.
TI  - C-Hg: A Collaborative Haptic-Gripper Fine Motor Skill Training System 
for Children with Autism Spectrum Disorder
UR  - https://doi.org/10.1145/3459608
VL  - 14
ER  - 
TY  - CONF
AB  - La formation par compagnonnage permet aux novices d’acquérir des compé
tences sous la supervision d’experts qui utilisent diverses modalités 
de communication. Cependant, reproduire ce modèle dans des simulateurs
 immersifs reste un défi, notamment pour assurer une communication eff
icace entre experts et novices. Notre étude explore l’impact de la com
munication multimodale expert-novice pour transmettre des instructions
 sur l’amplitude des mouvements dans une tâche de manipulation d’outil
s en environnement immersif. Les résultats révèlent que la combinaison
 des modalités visuelle-haptique améliore la précision, la vitesse et 
la qualité des mouvements. De plus, la combinaison verbale-visuelle-ha
ptique renforce le sentiment de présence et de coprésence, et l’expéri
ence d’apprentissage. Ces résultats suggèrent que la combinaison visue
lle-haptique est optimale pour améliorer les performances des novices,
 et que l’intégration de la modalité verbale améliore l’expérience uti
lisateur. Ces conclusions ouvrent de nouvelles perspectives pour améli
orer l’acquisition de gestes techniques par compagnonnage en réalité v
irtuelle grâce à la communication multimodale.
AU  - Simon, Cassandre
AU  - Hacene, Manel Boukli
AU  - Lebrun, Flavien
AU  - Otmane, Samir
AU  - Chellali, Amine
C1  - Paris, France
C3  - Proceedings of the 35th Conference on l'Interaction Humain-Machine
DA  - 2024///
C2  - 2024
DO  - 10.1145/3649792.3649793
ID  - 10.1145/3649792.3649
KW  - Apprentissage des gestes
KW  - Formation par compagnonnage
KW  - Interactions multimodale
KW  - Mentorship
KW  - Multimodal interactions
KW  - Skill learning
PB  - Association for Computing Machinery
SN  - 9798400718113
T3  - IHM '24
TI  - Influence of multimodal instructions on learning tool manipulation ski
lls through mentoring in an immersive environment: Influence des instr
uctions multimodales sur l’apprentissage par compagnonnage des compéte
nces de manipulation d’outil dans un environnement immersif
UR  - https://doi.org/10.1145/3649792.3649793
ER  - 
TY  - CONF
AB  - We present the architecture, technology and experimental applications 
of a real-time, multi-site, interactive and collaborative environment 
called Distributed Immersive Performance (DIP). The objective of DIP i
s to develop the technology for live, interactive musical performances
 in which the participants - subsets of musicians, the conductor and t
he audience - are in different physical locations and are interconnect
ed by very high fidelity multichannel audio and video links. DIP is a 
specific realization of broader immersive technology - the creation of
 the complete aural and visual ambience that places a person or a grou
p of people in a virtual space where they can experience events occurr
ing at a remote site or communicate naturally regardless of their loca
tion. The DIP experimental system has interaction sites and servers in
 different locations on the USC campus and at several partners, includ
ing the New World Symphony of Miami Beach, FL. The sites have differen
t types of equipment to test the effects of video and audio fidelity o
n the ease of use and functionality for different applications. Many s
ites have high-definition (HD) video or digital video (DV) quality ima
ges projected onto wide screen wall displays completely integrated wit
h an immersive audio reproduction system for a seamless, fully three-d
imensional aural environment with the correct spatial sound localizati
on for participants. The system is capable of storage and playback of 
the many streams of synchronized audio and video data (immersidata), a
nd utilizes novel protocols for the low-latency, seamless, synchronize
d real-time delivery of immersidata over local area networks and wide-
area networks such as Internet2. We discuss several recent interactive
 experiments using the system and many technical challenges common to 
the DIP scenario and a broader range of applications. These challenges
 include: (1). low latency continuous media (CM) stream transmission, 
synchronization and data loss management; (2). low latency, real-time 
video and multichannel immersive audio acquisition and rendering; (3).
 real-time continuous media stream recording, storage, playback; (4). 
human factors studies: psychophysical, perceptual, artistic, performan
ce evaluation; (5). robust integration of all these technical areas in
to a seamless presentation to the participants.
AU  - Sawchuk, A. A.
AU  - Chew, E.
AU  - Zimmermann, R.
AU  - Papadopoulos, C.
AU  - Kyriakakis, C.
C1  - Berkeley, California
C3  - Proceedings of the 2003 ACM SIGMM Workshop on Experiential Telepresenc
e
DA  - 2003///
C2  - 2003
DO  - 10.1145/982484.982506
ID  - 10.1145/982484.98250
KW  - remote collaboration
KW  - real-time interaction
KW  - music performance
KW  - information interfaces and presentation
PB  - Association for Computing Machinery
SN  - 1581137753
SP  - 110-120
T3  - ETP '03
TI  - From remote media immersion to Distributed Immersive Performance
UR  - https://doi.org/10.1145/982484.982506
ER  - 
TY  - CONF
AB  - Touch is an important part of human communication. Through handshakes,
 hugs and a myriad of personal gestures, we convey our emotions and ex
press our feelings. However, how such interactions can be achieved ove
r distance remains a relatively unexplored area of research. To begin 
to rectify this we present the description of a system that enables on
e user to reach out and touch another distant user and for both to fee
l the resultant physical contact. In this initial exploration, we focu
s on the practical feasibility of this idea, and describe the technica
l components required.
AU  - Cha, Jongeun
AU  - Oakley, Ian
AU  - Lee, Junhun
AU  - Ryu, Jeha
C1  - Christchurch, New Zealand
C3  - Proceedings of the 2005 International Conference on Augmented Tele-Exi
stence
DA  - 2005///
C2  - 2005
DO  - 10.1145/1152399.1152444
ID  - 10.1145/1152399.1152
KW  - haptic
KW  - communication
KW  - augmented reality
PB  - Association for Computing Machinery
SN  - 0473106574
SP  - 241-242
T3  - ICAT '05
TI  - An AR system for haptic communication
UR  - https://doi.org/10.1145/1152399.1152444
ER  - 
TY  - JOUR
AB  - This paper presents MetaTwin, a collaborative platform that enables se
amless synchronization between physical and virtual realms for co-exis
ting Extended Reality (XR) experiences. MetaTwin employs a hybrid dece
ntralized server architecture to synchronize user interactions and env
ironments within a shared space, allowing users to collaborate and soc
ialize across physical locations while experiencing the convergence of
 real and virtual spaces. Integrated IoT devices act as both physical 
and virtual entities, supporting shared control and enabling resource 
sharing, such as presentation slides and music. We detail the configur
ation and deployability of MetaTwin as a solution for XR collaboration
. To evaluate performance and feasibility, we compared MetaTwin with a
n existing XR platform and conducted an ablation study to identify the
 benefits and limitations of our approach. Additionally, a user study 
investigates the impact of spatial and temporal synchronization offset
s on collaboration quality. Our findings inform the development of ope
rational guidelines for future collaborative XR platforms.
AU  - Bhardwaj, Ayush
AU  - Pratap, Ashish
AU  - Carrizales, Edilberto F.
AU  - Ko, Dongbeom
AU  - Kang, Sungjoo
AU  - Kim, Jin Ryong
DA  - 2025/9//
PY  - 2025
DO  - 10.1145/3749533
ID  - 10.1145/3749533
IS  - 3
KW  - Collaborative Virtual Environments
KW  - Digital Twin
KW  - Metaverse
KW  - XR Collaborative Platform
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
TI  - MetaTwin: A Collaborative XR Platform for Seamless Physical-Virtual Sy
nchronization
UR  - https://doi.org/10.1145/3749533
VL  - 9
ER  - 
TY  - CONF
AB  - Recent Virtual Reality (VR) systems render highly immersive visual exp
eriences, yet currently lack tactile feedback for feeling virtual obje
cts with our hands and bodies. Shape Displays offer solid tangible int
eraction but have not been integrated with VR or have been restricted 
to desktop-scale workspaces. This work represents a fusion of mobile r
obotics, haptic props, and shape-display technology and commercial Vir
tual Reality to overcome these limitations. We present Mediate, a semi
-autonomous mobile shape-display that locally renders 3D physical geom
etry co-located with room-sized virtual environments as a conceptual s
tep towards large-scale tangible interaction in Virtual Reality. We co
mpare this "dynamic just-in-time mockup" concept to other haptic parad
igms and discuss future applications and interaction scenarios.
AU  - Fitzgerald, Daniel
AU  - Ishii, Hiroshi
C1  - Montreal QC, Canada
C3  - Extended Abstracts of the 2018 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2018///
C2  - 2018
DO  - 10.1145/3170427.3188472
ID  - 10.1145/3170427.3188
KW  - hand
KW  - haptic
KW  - pin display
KW  - robotic
KW  - robotic graphics
KW  - shape display
KW  - tangible interface
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450356213
SP  - 1-6
T3  - CHI EA '18
TI  - Mediate: A Spatial Tangible Interface for Mixed Reality
UR  - https://doi.org/10.1145/3170427.3188472
ER  - 
TY  - CONF
AB  - Motivation – To study haptic communication in collaborative virtual en
vironments.Research approach – An experimental study was conducted, in
 which 60 students were asked to perform in dyads a shared manual task
 after a training period.Findings/Design – The results show that hapti
c communication can influence the common frame of reference developmen
t in a shared manual task.Research limitations/Implications – Deeper v
erbalization analyses are needed to evaluate the common frame of refer
ence development.Originality/Value – This study highlights haptic inte
ractions importance when designing virtual environment that support sh
ared manual tasks.Take away message – Haptic communication, combined w
ith visual and verbal communication, enriches interactions in collabor
ative virtual environments.
AU  - Chellali, Amine
AU  - Dumas, Cédric
AU  - Milleville, Isabelle
C1  - Delft, Netherlands
C3  - Proceedings of the 28th Annual European Conference on Cognitive Ergono
mics
DA  - 2010///
C2  - 2010
DO  - 10.1145/1962300.1962319
ID  - 10.1145/1962300.1962
KW  - human interactions
KW  - haptic communication
KW  - common frame of reference
KW  - collaborative virtual environments
PB  - Association for Computing Machinery
SN  - 9781605589466
SP  - 83-90
T3  - ECCE '10
TI  - Haptic communication to enhance collaboration in virtual environments
UR  - https://doi.org/10.1145/1962300.1962319
ER  - 
TY  - CONF
AB  - Multimedia systems and applications have recently started to integrate
 the sense of touch and force feedback in the human-computer interacti
on. Surprisingly, measuring the quality of experience when haptic moda
lity is incorporated in a graphical user interface has received limite
d attention from the research community. In this paper, we propose a t
axonomy for measuring the quality of experience of a haptic user inter
face (HUI) applications. Furthermore, the taxonomy is modeled using a 
mathematical model. Finally, the proposed model is evaluated using two
 HUI-based applications: the haptic learning system and the haptic ena
bled UML CASE tool. The performance evaluation demonstrated that the p
roposed model is capable of reflecting the user estimation of the appl
ications.
AU  - Hamam, Abdelwahab
AU  - Eid, Mohamad
AU  - El Saddik, Abdulmotaleb
AU  - Georganas, Nicolas D.
C1  - Quebec City, Canada
C3  - Proceedings of the 2008 Ambi-Sys Workshop on Haptic User Interfaces in
 Ambient Media Systems
DA  - 2008///
C2  - 2008
ID  - 10.5555/1413907.1413
KW  - quality of experience
KW  - haptic user interface
KW  - haptic perception
PB  - ICST (Institute for Computer Sciences, Social-Informatics
T3  - HAS '08
TI  - A quality of experience model for haptic user interfaces
ER  - 
TY  - CONF
AB  - Augmented Reality as an interactive real-time technology combining rea
l and virtual objects in a real 3D space carries enormous educational 
potential. We describe a project (ARISE: Augmented Reality in School E
nvironments) that aims to realise this potential by developing a colla
borative, robust and affordable Augmented Reality learning platform fo
r schools. The learning affordances of Augmented Reality are discussed
, and an educational application is described that supports remote col
laboration between students in a shared 3D workspace, where students f
rom different countries present, discuss and manipulate virtual object
s relating to their local culture. The evaluation of the application i
s based on a distributed summer school project involving students from
 two European countries. In addition to more conventional evaluation a
pproaches, special requirements for evaluating remote collaboration in
 a shared Augmented Reality workspace have been met with a customised 
approach involving synchronised video observations in both locations w
ith subsequent editing of the material into and a single screen giving
 a comprehensive overview of the collaboration from both ends. The res
ults of the evaluation study are currently being analysed, but prelimi
nary findings suggest that the Augmented Reality learning platform has
 been well received by students and teachers, and is well suited for r
emote collaborative learning.
AU  - Pemberton, Lyn
AU  - Winter, Marcus
C1  - Rhodes, Greece
C3  - Proceedings of the 9th International Conference on Computer Supported 
Collaborative Learning - Volume 2
DA  - 2009///
C2  - 2009
ID  - 10.5555/1599503.1599
PB  - International Society of the Learning Sciences
SN  - 9781409285984
SP  - 109-111
T3  - CSCL'09
TI  - Collaborative augmented reality in schools
ER  - 
TY  - CONF
AB  - Improving telepresence for children expands educational opportunities 
and connects faraway family. Yet, research about child-centered physic
al telepresence systems (tangible interfaces for telepresence) remains
 sparse, despite established benefits of tangible interaction for chil
dren. To address this gap, we collaborated with child designers (ages 
8-12) over 2-years of online/1-year of hybrid participatory design. To
gether, we adapted one approach to physical telepresence (tabletop rob
ots) for child users. Using a case study methodology, we explore how o
ur tabletop telepresence robot platform influenced children’s connecti
ons with one another over the 3-year study. In our analysis, we compar
e four vignettes representing cooperation/conflict between children wh
ile using the platform; centering theories of ownership, collaboration
, and co-design roles. Through this exploration of children’s interper
sonal dynamics while using the platform, we uncover four key features 
of tabletop telepresence robots for children: (1) Anonymous Robot Cont
rol (2) Robot/Material Distribution, (3) Robot Form/Size, and (4) Robo
t Stewardship.
AU  - Hunt, Casey Lee
AU  - Sun, Kaiwen
AU  - Dhuliawala, Zahra
AU  - Tsukiyama, Fumi
AU  - Druin, Allison
AU  - Huynh, Amanda
AU  - Leithinger, Daniel
AU  - Yip, Jason
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713746
ID  - 10.1145/3706598.3713
KW  - Physical telepresence; Actuated tangible user interfaces; Hybrid colla
boration; Online Collaboration; Participatory design; Children
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Children using Tabletop Telepresence Robots for Collaboration: A Longi
tudinal Case Study of Hybrid and Online Intergenerational Participator
y Design
UR  - https://doi.org/10.1145/3706598.3713746
ER  - 
TY  - CONF
AB  - This paper describes a simulation of a collaborative task in a shared 
virtual environment — two users carrying a shared object (a stretcher)
 in a complex chemical plant. The implementation includes a haptic int
erface for each user, so that forces transmitted through the stretcher
 from one user to the other can be experienced. Preliminary experiment
s show that the addition of haptic feedback significantly enhances the
 sense of sharing and each user's perception of the actions of the oth
er user. The implementation is described, and some conclusions about t
he value of haptics, and plans for future work are given.
AU  - Hubbold, Roger J.
C1  - Barcelona, Spain
C3  - Proceedings of the Workshop on Virtual Environments 2002
DA  - 2002///
C2  - 2002
ID  - 10.5555/509709.50971
KW  - collaborative virtual environments
KW  - force feedback
KW  - haptics
KW  - shared virtual environments
PB  - Eurographics Association
SN  - 1581135351
SP  - 7-12
T3  - EGVE '02
TI  - Collaborative stretcher carrying: a case study
ER  - 
TY  - CONF
AB  - In this paper, we describe a multimedia system for learning handwritin
g and pronunciation of alphabet letters or characters in different lan
guages. This system provides haptic, audio and visual information acco
rding to the desired letter or character chosen by a user. Letters or 
characters from the Arabic, English, French, Japanese, and Spanish lan
guages have been considered, although the system utilizes an XML-based
 schema to easily introduce new characters from another language.Three
 different modes of learning can be chosen in terms of haptic informat
ion: full guidance, partial guidance and a no guidance mode (no haptic
 feedback). The full guidance guides the user to follow a pre-recorded
 letter trajectory; whereas in partial guidance, a user can freely fol
low a letter-drawing path, but if the user deviates significantly, the
 system automatically brings him/her back to the optimal displayed pat
h. The no guidance mode allows users to perform letter handwriting wit
h only visual information. This system guides users to write a charact
er, in a similar way as a teacher holds a student.s hand. Moreover, th
e character trajectory is displayed as the user is performing it. The 
results of this system evaluation show its potential as a virtual tool
 for learning handwriting.
AU  - Eid, Mohamad A.
AU  - Mansour, Mohamed
AU  - El Saddik, Abdulmotaleb H.
AU  - Iglesias, Rosa
C1  - Augsburg, Bavaria, Germany
C3  - Proceedings of the International Workshop on Educational Multimedia an
d Multimedia Education
DA  - 2007///
C2  - 2007
DO  - 10.1145/1290144.1290161
ID  - 10.1145/1290144.1290
KW  - virtual teaching
KW  - multimedia
KW  - haptics
KW  - haptic playback
KW  - education
PB  - Association for Computing Machinery
SN  - 9781595937834
SP  - 103-108
T3  - Emme '07
TI  - A haptic multimedia handwriting learning system
UR  - https://doi.org/10.1145/1290144.1290161
ER  - 
TY  - CONF
AB  - Extended Reality (XR) has proven effective in reducing cognitive load,
 enhancing spatial perception, and improving decision-making within me
chanical engineering environments. However, hardware and software limi
tations have slowed its widespread adoption in industrial manufacturin
g. In particular, there is a notable gap in enabling non-programming s
takeholders to create immersive, process-oriented experiences from CAD
 models for use in design meetings. Futhermore, the cost of traditiona
l XR development workflows is proving prohibitive with respect to indu
stry-wide implementation. This paper details the design, implementatio
n, and evaluation of a no-code workflow that enables the creation of V
irtual Reality (VR) experiences from CAD models for early-stage design
 reviews. Although developed to meet the rigorous requirements of equi
pment design engineering, the underlying philosophy is adaptable to ot
her manufacturing domains working with CAD data. By integrating an ent
erprise-grade CAD-to-mesh translation tool with a freely available, cr
oss-platform XR Software Development Kit, we have developed a reusable
 VR software container that allows CAD models to be imported without a
ny programming expertise. Documented no-code instructions and pre-prog
rammed XR components simplify the creation of VR-based Equipment Desig
n Review (VR-EDR) experiences. Our research demonstrates that transfor
ming industrial equipment design reviews using XR is feasible and effi
cient when supported by a container-based software solution and contex
t-specific no-code guidelines, as validated through continuous qualita
tive assessments.
AU  - Sharma, Sahir
AU  - Keighrey, Conor
AU  - Gilligan, Shane
AU  - Lardner, James
AU  - Murray, Niall
C1  -  
C3  - Proceedings of the 2025 ACM International Conference on Interactive Me
dia Experiences
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706370.3727860
ID  - 10.1145/3706370.3727
KW  - Virtual Reality
KW  - Reusable software
KW  - Experience Creation
KW  - Technology Adoption
KW  - Equipment Design Review
KW  - Immersive Design Assessments
KW  - Thematic Analysis
PB  - Association for Computing Machinery
SN  - 9798400713910
SP  - 30-48
T3  - IMX '25
TI  - Transforming Design Reviews with XR: A No-Code Media Experience Creati
on Strategy for Manufacturing Design
UR  - https://doi.org/10.1145/3706370.3727860
ER  - 
TY  - CONF
AB  - In the research community, Collaborative Virtual Environment (CVE) dev
elopers usually refer to the terms awareness and feedback as something
 necessary to maintain a fluent collaboration when highly interactive 
task have to be performed. However, it is remarkable that few studies 
address the effect that including special kind of awareness has on the
 task performance and the user experience.This paper proposes how to f
ace the implementation of awareness in order to be taken into account 
early in the development of a CVE. In addition, it is also described a
n experiment that was carried out to evaluate the effect of providing 
some visual cues, showing that users tend to make more mistakes when t
hey are not provided.
AU  - Garcı́a, Arturo S.
AU  - Molina, José P.
AU  - Martı́nez, Diego
AU  - González, Pascual
C1  - Singapore
C3  - Proceedings of The 7th ACM SIGGRAPH International Conference on Virtua
l-Reality Continuum and Its Applications in Industry
DA  - 2008///
C2  - 2008
DO  - 10.1145/1477862.1477904
ID  - 10.1145/1477862.1477
KW  - feedback
KW  - collaborative virtual environments
KW  - awareness
KW  - CSCW
PB  - Association for Computing Machinery
SN  - 9781605583358
T3  - VRCAI '08
TI  - Enhancing collaborative manipulation through the use of feedback and a
wareness in CVEs
UR  - https://doi.org/10.1145/1477862.1477904
ER  - 
TY  - CONF
AB  - Motivation – To design virtual environments that support collaborative
 activities.Research approach – An experimental approach in which 44 s
tudents were asked to work in pairs to reconstruct five 3D figures.Fin
dings/Design – The results show that including a contextual clue in vi
rtual environments improves collaboration between operators.Research l
imitations – Further investigative work must be carried out to extract
 accurate female collaboration profiles.Originality/Value – The result
s enable three collaboration profiles to be identified. They also allo
w the extraction of some characteristics of a contextual clue which ca
n be added to a virtual environment to improve collaboration.Take away
 message – The contents of a collaborative virtual environment influen
ces the way that users collaborate.
AU  - Chellali, Amine
AU  - Milleville-Pennel, Isabelle
AU  - Dumas, Cédric
C1  - Funchal, Portugal
C3  - Proceedings of the 15th European Conference on Cognitive Ergonomics: T
he Ergonomics of Cool Interaction
DA  - 2008///
C2  - 2008
DO  - 10.1145/1473018.1473045
ID  - 10.1145/1473018.1473
KW  - virtual environment
KW  - common frame of reference
KW  - collaboration
KW  - 3D interface
PB  - Association for Computing Machinery
SN  - 9781605583990
T3  - ECCE '08
TI  - Elaboration of a common frame of reference in collaborative virtual en
vironments
UR  - https://doi.org/10.1145/1473018.1473045
ER  - 
TY  - CONF
AB  - In VR environments, free movement in real space enhances immersion but
 increases the risk of collisions with real-world obstacles. Prior sol
utions investigated using substitute obstacles with context-related di
gital objects in VR but often treat all obstacles uniformly without co
nsidering their varying levels of risk. This oversight might result in
 reduced awareness for high-risk obstacles and a missed opportunity to
 utilize low-risk objects to enhance haptic feedback and interactivity
 in VR. In this study, we propose Chameleon, a system that classifies 
real-world obstacles by their varying risk levels and substitutes them
 with context-related virtual objects in VR. The substitutions are des
igned to align with the obstacles’ real-world risk levels to ensure bo
th safety and immersion. A preliminary heuristic evaluation assessed t
he usability of using visual textures to implicitly represent obstacle
 risk levels.
AU  - Yu, Yichen
AU  - Jin, Qiao
C1  -  
C3  - Proceedings of the Extended Abstracts of the CHI Conference on Human F
actors in Computing Systems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706599.3719779
ID  - 10.1145/3706599.3719
KW  - Virtual Reality
KW  - Obstacle Avoidance
KW  - Cross-reality System
KW  - Safety
PB  - Association for Computing Machinery
SN  - 9798400713958
T3  - CHI EA '25
TI  - Chameleon: Unobtrusive Substitution of Real-World Obstacles in VR with
 Risk-Level-Aware Adaptation
UR  - https://doi.org/10.1145/3706599.3719779
ER  - 
TY  - CONF
AB  - Presence is a defining element of virtual reality (VR), but it is also
 increasingly used when assessing mixed reality (MR) experiences. The 
increased interest in measuring presence in MR and recent works underp
inning the specific nature of presence in MR raise the question of the
 current state and practice of assessing presence in MR. To address th
is question, we present an analysis of more than 320 studies that repo
rt on presence measurements in MR. Our analysis showed that questionna
ires are the dominant measurement but also identify problematic trends
 that stem from the lack of a generally agreed-upon concept or measure
ment for presence in MR. More specifically, we show that using measure
ments that are not validated in MR or custom questionnaires limiting t
he comparability of results is commonplace and could contribute to a l
ooming replication crisis in an increasingly relevant field.
AU  - Tran, Tanh Quang
AU  - Langlotz, Tobias
AU  - Regenbrecht, Holger
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI Conference on Human Factors in Computing S
ystems
DA  - 2024///
C2  - 2024
DO  - 10.1145/3613904.3642383
ID  - 10.1145/3613904.3642
KW  - Augmented Reality
KW  - Extended Reality
KW  - Mixed Reality
KW  - Sense of Presence
KW  - Spatial Presence
KW  - Virtual Reality
PB  - Association for Computing Machinery
SN  - 9798400703300
T3  - CHI '24
TI  - A Survey On Measuring Presence in Mixed Reality
UR  - https://doi.org/10.1145/3613904.3642383
ER  - 
TY  - CONF
AB  - Paper prototyping presents a low-entry barrier method to engaging yout
h in interaction design. Purely paper-based designs leave a large gap 
between ideation and implementation. Paper Playground is a prototyping
 tool that connects physical and virtual papers with JavaScript progra
ms, enabling the creation of multimodal prototypes in both face-to-fac
e and virtual settings. Paper Playground is being designed and develop
ed through iterative co-design activities including youth and adults. 
Here we present findings from remote co-design sessions with youth, in
vestigating what affordances the participants requested from a multimo
dal prototyping tool. We reflect on the co-designers desires and remar
ks on paper use for interactive project design, remote collaborative u
se, and extensibility for physical computing.
AU  - Fiedler, Brett L
AU  - Smith, Taliesin L.
AU  - Greenberg, Jesse
AU  - Eisenberg, Ann
AU  - Moore, Emily B.
C1  - Delft, Netherlands
C3  - Proceedings of the 23rd Annual ACM Interaction Design and Children Con
ference
DA  - 2024///
C2  - 2024
DO  - 10.1145/3628516.3659400
ID  - 10.1145/3628516.3659
KW  - co-design
KW  - interactive design
KW  - web design
KW  - web interactives
PB  - Association for Computing Machinery
SN  - 9798400704420
SP  - 818-822
T3  - IDC '24
TI  - Insights from Youth Co-designers on Remote Multimodal Prototyping with
 Paper Playground
UR  - https://doi.org/10.1145/3628516.3659400
ER  - 
TY  - CONF
AU  - Teh, James Keng Soon
AU  - Kato, Daishi
AU  - Kunieda, Kazuo
AU  - Yamada, Keiji
C1  - Los Angeles, California
C3  - ACM SIGGRAPH 2008 New Tech Demos
DA  - 2008///
C2  - 2008
DO  - 10.1145/1401615.1401653
ID  - 10.1145/1401615.1401
PB  - Association for Computing Machinery
SN  - 9781450378475
T3  - SIGGRAPH '08
TI  - The programming of robots by haptic means
UR  - https://doi.org/10.1145/1401615.1401653
ER  - 
TY  - CONF
AB  - This paper describes a pilot study that investigates how a multi-touch
 system can support remote collaboration within the clothing design an
d manufacturing industries. We first examine and discuss the existing 
collaboration processes and issues found in the day-to-day operations 
of the clothing industry. To further refine our understanding of what 
forms of collaboration are important when discussing design and manufa
cturing techniques, we conducted an ethnographic study with fashion de
sign students. Based on this background research, we designed, develop
ed and evaluated a multi-touch gestural prototype interface. We conclu
de with reflections on whether collocated natural interactions can be 
extended remotely via technology.
AU  - Yang, Jason
AU  - Dekker, Andrew
AU  - Muhlberger, Ralf
AU  - Viller, Stephen
C1  - Melbourne, Australia
C3  - Proceedings of the 21st Annual Conference of the Australian Computer-H
uman Interaction Special Interest Group: Design: Open 24/7
DA  - 2009///
C2  - 2009
DO  - 10.1145/1738826.1738895
ID  - 10.1145/1738826.1738
KW  - user-centred design
KW  - tangible interface
KW  - observation
KW  - multi-touch
KW  - gestural interface
KW  - collaboration
PB  - Association for Computing Machinery
SN  - 9781605588544
SP  - 353-356
T3  - OZCHI '09
TI  - Exploring virtual representations of physical artefacts in a multi-tou
ch clothing design collaboration system
UR  - https://doi.org/10.1145/1738826.1738895
ER  - 
TY  - CONF
AB  - Children’s online co-design has become prevalent since COVID-19. Howev
er, related research focuses on insights gained across several shorter
-term projects, rather than longitudinal investigations. To explore lo
ngitudinal co-design online, we engaged in participatory design with c
hildren (ages 8 - 12) for 20 sessions in two years on a single project
: an online collaboration platform with tabletop telepresence robots. 
We found that (1) the online technology space required children to pla
y a role as technology managers and troubleshooters, (2) the home sett
ing shaped online social dynamics, and (3) providing children the abil
ity to choose their design techniques prevented gridlock from situatio
nal uncertainties. We discuss how each finding resulted from interplay
 between our long-term technology design and online co-design processe
s. We then present insights about the future of online co-design, a co
nceptual model for longitudinal co-design online, and describe opportu
nities for further longitudinal online co-design research to generate 
new methods, techniques, and theories.
AU  - Hunt, Casey Lee
AU  - Sun, Kaiwen
AU  - Dhuliawala, Zahra
AU  - Tsukiyama, Fumi
AU  - Matkovic, Iva
AU  - Schwemler, Zachary
AU  - Wolf, Anastasia
AU  - Zhang, Zihao
AU  - Druin, Allison
AU  - Huynh, Amanda
AU  - Leithinger, Daniel
AU  - Yip, Jason
C1  - Chicago, IL, USA
C3  - Proceedings of the 22nd Annual ACM Interaction Design and Children Con
ference
DA  - 2023///
C2  - 2023
DO  - 10.1145/3585088.3589359
ID  - 10.1145/3585088.3589
KW  - Actuated tangible user interfaces
KW  - Children
KW  - Design methods
KW  - Participatory design
KW  - Physical telepresence
PB  - Association for Computing Machinery
SN  - 9798400701313
SP  - 52-67
T3  - IDC '23
TI  - Designing Together, Miles Apart: A Longitudinal Tabletop Telepresence 
Adventure in Online Co-Design with Children
UR  - https://doi.org/10.1145/3585088.3589359
ER  - 
TY  - CONF
AB  - The tactile sensation of textiles is critical in determining the comfo
rt of clothing. For remote use, such as online shopping, users cannot 
physically touch the textile of clothes, making it difficult to evalua
te its tactile sensation. Tactile sensing and actuation devices are re
quired to transmit the tactile sensation of textiles. The sensing devi
ce needs to recognize different garments, even with hand-held sensors.
 In addition, the existing actuation device can only present a limited
 number of known patterns and cannot transmit unknown tactile sensatio
ns of textiles. To address these issues, we propose Telextiles, an int
erface that can remotely transmit tactile sensations of textiles by cr
eating a latent space that reflects the proximity of textiles through 
contrastive self-supervised learning. We confirm that textiles with si
milar tactile features are located close to each other in the latent s
pace through a two-dimensional plot. We then compress the latent featu
res for known textile samples into the 1D distance and apply the 16 te
xtile samples to the rollers in the order of the distance. The roller 
is rotated to select the textile with the closest feature if an unknow
n textile is detected.
AU  - Kitagishi, Takekazu
AU  - Hiroi, Yuichi
AU  - Watanabe, Yuna
AU  - Itoh, Yuta
AU  - Rekimoto, Jun
C1  - San Francisco, CA, USA
C3  - Proceedings of the 36th Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2023///
C2  - 2023
DO  - 10.1145/3586183.3606764
ID  - 10.1145/3586183.3606
KW  - Haptic feedback
KW  - Machine learning
KW  - Passive haptic feedback
KW  - Self supervised learning
KW  - Tactile Display
KW  - Tactile perception
KW  - Texture
KW  - Texture perception
KW  - Texture recognition
PB  - Association for Computing Machinery
SN  - 9798400701320
T3  - UIST '23
TI  - Telextiles: End-to-end Remote Transmission of Fabric Tactile Sensation

UR  - https://doi.org/10.1145/3586183.3606764
ER  - 
TY  - CONF
AB  - Mobile and handheld devices have become platforms to support remote co
llaboration. But, their small form-factor may impact the effectiveness
 of the visual feedback channel often used to help users maintain an a
wareness of their partner's activities during synchronous collaborativ
e tasks. We investigated how visual and tactile feedback affects colla
boration on mobile devices, with emphasis on spatial coordination in a
 shared workspace. From two user studies, our results highlight differ
ent benefits of each feedback channel in collaborative handheld system
s. Visual feedback can provide precise spatial information for collabo
rators, but degrades collaboration when the feedback is occluded, and 
sometimes can distract the user's attention. Spatial tactile feedback 
can reduce the overload of information in visual space and gently guid
es the user's attention to an area of interest. Our results also show 
that visual and tactile feedback can complement each other, and system
s using both feedback channels can support better spatial coordination
 than systems using only one form of feedback.
AU  - Yatani, Koji
AU  - Gergle, Darren
AU  - Truong, Khai
C1  - Seattle, Washington, USA
C3  - Proceedings of the ACM 2012 Conference on Computer Supported Cooperati
ve Work
DA  - 2012///
C2  - 2012
DO  - 10.1145/2145204.2145305
ID  - 10.1145/2145204.2145
KW  - visual feedback
KW  - touch screen
KW  - tactile feedback
KW  - spatial coordination
KW  - mobile/handheld devices
KW  - collaboration
PB  - Association for Computing Machinery
SN  - 9781450310864
SP  - 661-670
T3  - CSCW '12
TI  - Investigating effects of visual and tactile feedback on spatial coordi
nation in collaborative handheld systems
UR  - https://doi.org/10.1145/2145204.2145305
ER  - 
TY  - CONF
AB  - We introduce InflatableBots, shape-changing inflatable robots for larg
e-scale encountered-type haptics in VR. Unlike traditional inflatable 
shape displays, which are immobile and limited in interaction areas, o
ur approach combines mobile robots with fan-based inflatable structure
s. This enables safe, scalable, and deployable haptic interactions on 
a large scale. We developed three coordinated inflatable mobile robots
, each of which consists of an omni-directional mobile base and a reel
-based inflatable structure. The robot can simultaneously change its h
eight and position rapidly (horizontal: 58.5 cm/sec, vertical: 10.4 cm
/sec, from 40 cm to 200 cm), which allows for quick and dynamic haptic
 rendering of multiple touch points to simulate various body-scale obj
ects and surfaces in real-time across large spaces (3.5 m x 2.5 m). We
 evaluated our system with a user study (N = 12), which confirms the u
nique advantages in safety, deployability, and large-scale interactabi
lity to significantly improve realism in VR experiences.
AU  - Gomi, Ryota
AU  - Suzuki, Ryo
AU  - Takashima, Kazuki
AU  - Fujita, Kazuyuki
AU  - Kitamura, Yoshifumi
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI Conference on Human Factors in Computing S
ystems
DA  - 2024///
C2  - 2024
DO  - 10.1145/3613904.3642069
ID  - 10.1145/3613904.3642
KW  - Encountered-Type Haptics
KW  - Haptics
KW  - Inflatables
KW  - Mobile Robots
KW  - Shape-Changing Interfaces
KW  - Virtual Reality
PB  - Association for Computing Machinery
SN  - 9798400703300
T3  - CHI '24
TI  - InflatableBots: Inflatable Shape-Changing Mobile Robots for Large-Scal
e Encountered-Type Haptics in VR
UR  - https://doi.org/10.1145/3613904.3642069
ER  - 
TY  - JOUR
AB  - As extended reality (XR) systems become increasingly available, XR-bas
ed remote instruction is being adopted for diverse purposes in profess
ional settings such as surgery and field servicing. Hobbyists have bee
n well-studied in HCI and may similarly benefit from remote skill-shar
ing. However, little is known about how XR technologies might support 
expert-novice collaboration for skilled hobby activities. This paper e
xamines the potential and limitations of XR to connect experts and nov
ices for one such activity: gardening. Through two studies involving 2
7 expert and novice gardeners, we designed prototypes to understand 1)
 practitioner perceptions of XR and remote skill-sharing in the garden
 and 2) what kinds of interactions can be supported in XR for expert-n
ovice groups. We discuss design opportunities and challenges for XR sy
stems in supporting informal connecting interactions and meaningful se
nsory interactions with a remote environment during skill-sharing.
AU  - Maddali, Hanuma Teja
AU  - Irlitti, Andrew
AU  - Lazar, Amanda
DA  - 2022/11//
PY  - 2022
DO  - 10.1145/3555211
ID  - 10.1145/3555211
IS  - CSCW2
KW  - skilled hobbies
KW  - skill-sharing
KW  - gardening
KW  - extended reality
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Probing the Potential of Extended Reality to Connect Experts and Novic
es in the Garden
UR  - https://doi.org/10.1145/3555211
VL  - 6
ER  - 
TY  - CONF
AB  - We introduce Tangible Message Bubbles, a new composition and communica
tion tool that invites youngsters to express and record their everyday
 expressions, play with these original recordings, and share these per
sonal creations with their friends and family. We present a design rat
ionale that focuses on supporting both co-located and remote collabora
tion, and on balancing play with tool design. Results from pilot evalu
ations with our initial prototypes informed us with ways to leverage t
he physical properties of the toys and support playful exploration of 
children's recorded video messages for sharing.
AU  - Ryokai, Kimiko
AU  - Raffle, Hayes
AU  - Brooks, Andy
C1  - Boston, MA, USA
C3  - CHI '09 Extended Abstracts on Human Factors in Computing Systems
DA  - 2009///
C2  - 2009
DO  - 10.1145/1520340.1520706
ID  - 10.1145/1520340.1520
KW  - toys
KW  - tangible
KW  - communication tools
KW  - children
PB  - Association for Computing Machinery
SN  - 9781605582474
SP  - 4597-4602
T3  - CHI EA '09
TI  - Tangible message bubbles for children's communication and play
UR  - https://doi.org/10.1145/1520340.1520706
ER  - 
TY  - CONF
AB  - An approach is presented for realizing an order-of-magnitude improveme
nt in spatial accuracy for voxel-based 6-DOF haptics. It trades consta
nt-time performance for greater spatial accuracy. This helps to make 6
-DOF haptics applicable to extraordinarily complex real-world task sim
ulations, which often admit no other known solution short of physical 
mockup. A reduction of haptic fidelity is tactically incurred but simu
ltaneously mitigated by augmenting standard voxel-sampling methodology
 with distance fields, temporal coherence, and culling of redundant po
lyhedral surface interactions. This is applied to large-scale haptic s
cenarios involving multiple moving objects and to collaborative virtua
l environments.
AU  - McNeely, William A.
AU  - Puterbaugh, Kevin D.
AU  - Troy, James J.
C1  - Los Angeles, California
C3  - ACM SIGGRAPH 2005 Courses
DA  - 2005///
C2  - 2005
DO  - 10.1145/1198555.1198606
ID  - 10.1145/1198555.1198
KW  - voxel sampling
KW  - physically based modeling
KW  - haptics
KW  - collision detection
KW  - collaborative virtual environments
PB  - Association for Computing Machinery
SN  - 9781450378338
SP  - 50-es
T3  - SIGGRAPH '05
TI  - Advances in voxel-based 6-DOF haptic rendering
UR  - https://doi.org/10.1145/1198555.1198606
ER  - 
TY  - CONF
AB  - One challenge of providing guidance for search tasks consists in guidi
ng the user’s visual attention to certain objects in a potentially lar
ge search space. Previous work has tried to guide the user’s attention
 by providing visual, audio, or haptic cues. The state-of-the-art meth
ods either provide hints pointing towards the approximate direction of
 the target location for a fast but less accurate search or require th
e user to perform a fine-grained search from the beginning for a preci
se yet less efficient search. To combine the advantage of both methods
, we propose an interaction concept called Two-Step Gaze Guidance. The
 first-step guidance focuses on quick guidance toward the approximate 
direction, and the second-step guidance focuses on fine-grained guidan
ce toward the exact location of the target. A between-subject study (N
 = 69) with five conditions was carried out to compare the two-step ga
ze guidance method with the single-step gaze guidance method. Results 
revealed that the proposed method outperformed the single-step gaze gu
idance method. More precisely, the introduction of Two-Step Gaze Guida
nce slightly improves the searching accuracy, and the use of spatial a
udio as the first-step guidance significantly helps in enhancing the s
earching efficiency. Our results also indicated several design suggest
ions for designing gaze guidance methods.
AU  - Kwok, Tiffany C.K.
AU  - Kiefer, Peter
AU  - Raubal, Martin
C1  - Bengaluru, India
C3  - Proceedings of the 2022 International Conference on Multimodal Interac
tion
DA  - 2022///
C2  - 2022
DO  - 10.1145/3536221.3556612
ID  - 10.1145/3536221.3556
KW  - non-visual guidance
KW  - haptic feedback
KW  - gaze-guidance
KW  - audio feedback
PB  - Association for Computing Machinery
SN  - 9781450393904
SP  - 299-309
T3  - ICMI '22
TI  - Two-Step Gaze Guidance
UR  - https://doi.org/10.1145/3536221.3556612
ER  - 
TY  - CONF
AB  - Immersive telecommunication is a new challenging field that enables a 
user to share a virtual space with remote participants. The main objec
tive is to offer rich communication modalities, as similar as those us
ed in the face-to-face meetings like gestures, gaze awareness, realist
ic images, and correct sound direction. Moreover, full body interactio
n with physics simulation is presented as a natural interface. As a re
sult, the user can be immersed and has interaction with virtual object
s including remote participants. This would overcome the limitations b
oth of the conventional video-based telecommunication and also the VR-
based collaborative virtual environment approaches.
AU  - Lee, Sang-Yup
AU  - Kim, Ig-Jae
AU  - Ahn, Sang C.
AU  - Lim, Myo-Taeg
AU  - Kim, Hyoung-Gon
C1  - Christchurch, New Zealand
C3  - Proceedings of the 2005 International Conference on Augmented Tele-Exi
stence
DA  - 2005///
C2  - 2005
DO  - 10.1145/1152399.1152411
ID  - 10.1145/1152399.1152
KW  - telepresences
KW  - mixed reality
KW  - 3D video avatar
PB  - Association for Computing Machinery
SN  - 0473106574
SP  - 56-61
T3  - ICAT '05
TI  - Toward immersive telecommunication: 3D video avatar with physical inte
raction
UR  - https://doi.org/10.1145/1152399.1152411
ER  - 
TY  - CONF
AB  - Collaborating across dissimilar, distributed spaces presents numerous 
challenges for computer-aided spatial communication. Mixed reality (MR
) can blend selected surfaces, allowing collaborators to work in blend
ed f-formations (facing formations), even when their workstations are 
physically misaligned. Since collaboration often involves more than ju
st participant pairs, this research examines how we might scale MR exp
eriences for large-group collaboration. To do so, this study recruited
 collaboration designers (CDs) to evaluate and reimagine MR for large-
scale collaboration. These CDs were engaged in a four-part user study 
that involved a technology probe, a semi-structured interview, a specu
lative low-fidelity prototyping activity and a validation session. The
 outcomes of this paper contribute (1) a set of collaboration design p
rinciples to inspire future computer-supported collaborative work, (2)
 eight collaboration patterns for blended f-formations and collaborati
on at scale and (3) theoretical implications for f-formations and spac
e-place relationships. As a result, this work creates a blueprint for 
scaling collaboration across distributed spaces.
AU  - Wong, Emily
AU  - Sánchez Esquivel, Juan
AU  - Leiva, Germán
AU  - Grønbæk, Jens Emil Sloth
AU  - Velloso, Eduardo
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI Conference on Human Factors in Computing S
ystems
DA  - 2024///
C2  - 2024
DO  - 10.1145/3613904.3642502
ID  - 10.1145/3613904.3642
KW  - collaboration
KW  - f-formations
KW  - mixed reality
KW  - scale
KW  - space and place
PB  - Association for Computing Machinery
SN  - 9798400703300
T3  - CHI '24
TI  - Practice-informed Patterns for Organising Large Groups in Distributed 
Mixed Reality Collaboration
UR  - https://doi.org/10.1145/3613904.3642502
ER  - 
TY  - CONF
AB  - Drawing as an activity aids problem solving, collaboration, and presen
tation in design, science, and engineering and artistic creativity as 
well as expression in the arts. Unfortunately, blind, and partially si
ghted learners still lack an inclusive and effective drawing tool, eve
n in the digital age. In response, this research aims to explore what 
an effective drawing tool for blind and partially sighted individuals 
(BPSI) would be. Raised-line drawing kits aim to provide this, but in 
prior work, our usability tests of raised line graphics with blind and
 partially sighted participants rated the raised line graphics that we
 tested as barely comprehensible relative to 3D models, which they rat
ed as highly comprehensible. Semi-structured interviews with our parti
cipants afterward suggest that they found 3D models to be more compreh
ensible because these are consistent with haptic principles of percept
ion whereas conventions of raised line graphics, such as a line repres
enting a surface edge, replicate visual cues of source images and ther
eby violate haptic principles of perception. Therefore, we hypothesize
 that a drawing tool for blind and partially sighted drawers could be 
effective by recruiting affordances of 3D models. Through co-design se
ssions conducted during the Covid-19 pandemic with blind and partially
 sighted drawers (BPSD), we prototyped a tangible 3D model constructio
n kit for non-visual haptic drawing with a digital interface to a 3D v
irtual environment. Our current investigation of user needs is informi
ng us of our ongoing iterative development of an accessible 3D scannin
g application that is enabling blind and partially sighted individuals
 to build and scan in 3D models constructed from a more flexible range
 of materials beyond what was possible with our previous prototype.
AU  - Kamat, Mitali
AU  - Uribe Quevedo, Alvaro
AU  - Coppin, Peter
C1  - Daejeon, Republic of Korea
C3  - Proceedings of the Sixteenth International Conference on Tangible, Emb
edded, and Embodied Interaction
DA  - 2022///
C2  - 2022
DO  - 10.1145/3490149.3505580
ID  - 10.1145/3490149.3505
KW  - 3D Drawing
KW  - Blind and Partially Sighted
KW  - Haptic Drawing
KW  - Tangible User Interface
PB  - Association for Computing Machinery
SN  - 9781450391474
T3  - TEI '22
TI  - Tangible Construction Kit for Blind and Partially Sighted Drawers: Co-
Designing a cross-sensory 3D interface with blind and partially sighte
d drawers during Covid-19
UR  - https://doi.org/10.1145/3490149.3505580
ER  - 
TY  - CONF
AB  - In the real-time demo, we demonstrate how to create a musical performa
nce using juggling movement as an instrument. We have equipped jugglin
g balls with accelerometers, gyroscopes, and WiFi sensors. The system 
measures acceleration and rotation in a small HW footprint, allowing u
s to map various events to music. We provide hardware and software pla
tforms to ease the creation of real-time live performances for artists
 and researchers alike. A movement-driven controller can be used to cr
eate music, trigger media or lights in theater performances, serve as 
a lighting console or VR controller, or track performance in sports or
 scientific experiments. We provide OSC and MIDI APIs that are widely 
used in before mentioned fields.
AU  - Leischner, Vojtěch Žák
AU  - Husa, Pavel
C1  - Los Angeles, CA, USA
C3  - ACM SIGGRAPH 2023 Real-Time Live!
DA  - 2023///
C2  - 2023
DO  - 10.1145/3588430.3597246
ID  - 10.1145/3588430.3597
KW  - synthetizer
KW  - synesthesia
KW  - spatial audio
KW  - sonification
KW  - realtime
KW  - postdigital
KW  - performance
KW  - musical instrument
KW  - music performance
KW  - movement
KW  - juggling
KW  - haptic interface
KW  - demo
KW  - OSC
KW  - MIDI
PB  - Association for Computing Machinery
SN  - 9798400701580
T3  - SIGGRAPH '23
TI  - DJuggling: Sonification of expressive movement performance
UR  - https://doi.org/10.1145/3588430.3597246
ER  - 
TY  - CONF
AB  - In lifelog data search, despite automatic supports for identifying rel
evant pieces of information, the processes of inputting queries and fi
ltering information from the generated results still heavily rely on h
uman searchers.With the rapid increase in volume of such data, these t
asks could become both mentally and physically tedious for an individu
al to perform. In this paper, we present CollaXRSearch, a collaborativ
e virtual reality (VR) information retrieval system, which we aim to u
se for participating at the Lifelog Search Challenge 2024. This is a c
ollaborative virtual reality system based on a heterogeneous setup of 
VR headsets, mobile devices and public displays. Its purpose is to fac
ilitate coordination between teammates in terms of inputting and explo
ration operations in lifelog search.For efficiently providing textual 
query input and filtering, this system utilizes an interface which can
 be operated on a personal computer or a mobile device. Search results
 returned by the engine will be displayed in a VR environment where a 
user wearing a VR headset can explore to identify suitable items. To r
educe the workload for the VR user during the searching process, we em
ploys collaborative VR interface designs on a large physical display w
hich enable he/she to communicate findings on the search results to th
e rest of the team. In this paper, we describe the conceptual interfac
e and interaction designs of aforementioned setup.
AU  - Ly, Duy-Nam
AU  - Duong-Le, Dinh-Thuan
AU  - Vuong, Gia Huy
AU  - Ho, Van-Son
AU  - Ninh, Van-Tu
AU  - Tran, Minh-Triet
AU  - Le, Khanh-Duy
C1  - Phuket, Thailand
C3  - Proceedings of the 7th Annual ACM Workshop on the Lifelog Search Chall
enge
DA  - 2024///
C2  - 2024
DO  - 10.1145/3643489.3661125
ID  - 10.1145/3643489.3661
KW  - lifelog
KW  - interactive retrieval
KW  - VR
KW  - collaborative interface
KW  - heterogeneous system
PB  - Association for Computing Machinery
SN  - 9798400705502
SP  - 76-81
T3  - LSC '24
TI  - CollaXRSearch: A Collaborative Virtual Reality System for Lifelog Retr
ieval
UR  - https://doi.org/10.1145/3643489.3661125
ER  - 
TY  - JOUR
AB  - In the study presented here, two haptic and visual applications for le
arning geometrical concepts in group work in primary school have been 
designed and evaluated. The aim was to support collaborative learning 
among sighted and visually impaired pupils. The first application is a
 static flattened 3D environment that supports learning to distinguish
 between angles by means of a 3D haptic device providing touch feedbac
k. The second application is a dynamic 3D environment that supports le
arning of spatial geometry. The scene is a room with a box containing 
geometrical objects, which pupils can pick up and move around. The app
lications were evaluated in four schools with groups of two sighted an
d one visually impaired pupil. The results showed the support for the 
visually impaired pupil and for the collaboration to be satisfying. A 
shared understanding of the workspace could be achieved, as long as th
e virtual environment did not contain movable objects. Verbal communic
ation was crucial for the work process but haptic guiding to some exte
nt substituted communication about direction. When it comes to joint a
ction between visually impaired and sighted pupils a number of interes
ting problems were identified when the dynamic and static virtual envi
ronments were compared. These problems require further investigation. 
The study extends prior work in the areas of assistive technology and 
multimodal communication by evaluating functions for joint haptic mani
pulation in the unique setting of group work in primary school.
AU  - Moll, Jonas
AU  - Pysander, Eva-Lotta Sallnäs
DA  - 2013/7//
PY  - 2013
DO  - 10.1145/2493171.2493172
ID  - 10.1145/2493171.2493
IS  - 4
SN  - 1936-7228
T2  - ACM Trans. Access. Comput.
TI  - A Haptic Tool for Group Work on Geometrical Concepts Engaging Blind an
d Sighted Pupils
UR  - https://doi.org/10.1145/2493171.2493172
VL  - 4
ER  - 
TY  - BOOK
CY  - Online, CA, USA
DA  - 2022///
PY  - 2022
ID  - 10.1145/3565970
PB  - Association for Computing Machinery
SN  - 9781450399487
TI  - SUI '22: Proceedings of the 2022 ACM Symposium on Spatial User Interac
tion
ER  - 
TY  - JOUR
AB  - Immersive technologies such as Virtual Reality (VR) and Augmented Real
ity (AR) empower users to experience digital realities. Known as disti
nct technology classes, the lines between them are becoming increasing
ly blurry with recent technological advancements. New systems enable u
sers to interact across technology classes or transition between them—
referred to as cross-reality systems. Nevertheless, these systems are 
not well understood. Hence, in this article, we conducted a scoping li
terature review to classify and analyze cross-reality systems proposed
 in previous work. First, we define these systems by distinguishing th
ree different types. Thereafter, we compile a literature corpus of 306
 relevant publications, analyze the proposed systems, and present a co
mprehensive classification, including research topics, involved enviro
nments, and transition types. Based on the gathered literature, we ext
ract nine guiding principles that can inform the development of cross-
reality systems. We conclude with research challenges and opportunitie
s.
AU  - Auda, Jonas
AU  - Gruenefeld, Uwe
AU  - Faltaous, Sarah
AU  - Mayer, Sven
AU  - Schneegass, Stefan
DA  - 2023/10//
PY  - 2023
DO  - 10.1145/3616536
ID  - 10.1145/3616536
IS  - 4
KW  - collaboration
KW  - bystander inclusion
KW  - transitional interfaces
KW  - virtual reality
KW  - augmented virtuality
KW  - augmented reality
KW  - reality-virtuality continuum
KW  - Cross-reality systems
SN  - 0360-0300
T2  - ACM Comput. Surv.
TI  - A Scoping Survey on Cross-reality Systems
UR  - https://doi.org/10.1145/3616536
VL  - 56
ER  - 
TY  - CONF
AB  - Blind users rely on keyboards and assistive technologies like screen r
eaders to interact with user interface (UI) elements. In modern applic
ations with complex UI hierarchies, navigating to different UI element
s poses a significant accessibility challenge. Users must listen to sc
reen reader audio descriptions and press relevant keyboard keys one at
 a time. This paper introduces Wheeler, a novel three-wheeled, mouse-s
haped stationary input device, to address this issue. Informed by part
icipatory sessions, Wheeler enables blind users to navigate up to thre
e hierarchical levels in an app independently using three wheels inste
ad of navigating just one level at a time using a keyboard. The three 
wheels also offer versatility, allowing users to repurpose them for ot
her tasks, such as 2D cursor manipulation. A study with 12 blind users
 indicates a significant reduction (40%) in navigation time compared t
o using a keyboard. Further, a diary study with our blind co-author hi
ghlights Wheeler’s additional benefits, such as accessing UI elements 
with partial metadata and facilitating mixed-ability collaboration.
AU  - Islam, Md Touhidul
AU  - Sojib, Noushad
AU  - Kabir, Imran
AU  - Amit, Ashiqur Rahman
AU  - Amin, Mohammad Ruhul
AU  - Billah, Syed Masum
C1  - Pittsburgh, PA, USA
C3  - Proceedings of the 37th Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2024///
C2  - 2024
DO  - 10.1145/3654777.3676396
ID  - 10.1145/3654777.3676
KW  - Non-visual interaction
KW  - blind
KW  - haptics
KW  - input device
KW  - mouse
KW  - multi-wheel
KW  - rotational input
KW  - vision impairments.
PB  - Association for Computing Machinery
SN  - 9798400706288
T3  - UIST '24
TI  - Wheeler: A Three-Wheeled Input Device for Usable, Efficient, and Versa
tile Non-Visual Interaction
UR  - https://doi.org/10.1145/3654777.3676396
ER  - 
TY  - CONF
AB  - This article examined how different time and task management informati
on widgets affect time perception across modalities. In mentally deman
ding office environments, effective countdown representations are cruc
ial for enhancing temporal awareness and productivity. We developed Ti
ckSens, a set of information widgets with different modalities, and co
nducted a within-subjects experiment with 30 participants to evaluate 
the five types of time perception modes: visual, auditory, haptic, as 
well as the blank and the timer modes. Our assessment focused on the t
echnology acceptance, cognitive performance and emotional responses. R
esults indicated that compared to the blank and the timer modes, the u
se of modalities significantly improved the cognitive performance and 
positive emotional responses, and was better received by participants.
 The visual mode had the best task performance, while the auditory fee
dback was effective in boosting focus and the haptic mode significantl
y enhances user acceptance. The study revealed varied user preferences
 that enlightened the integration of these widgets into office.
AU  - Li, Zengrui
AU  - Shi, Di
AU  - Gao, Qijun
AU  - Chen, Yichen
AU  - Wang, Nanyi
AU  - Ren, Xipei
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713270
ID  - 10.1145/3706598.3713
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Effects of Information Widgets on Time Perception during Mentally Dema
nding Tasks
UR  - https://doi.org/10.1145/3706598.3713270
ER  - 
TY  - JOUR
AB  - How can we trigger the process of digital embodiment and corporeality 
in human-robot collaboration through extended reality and digitally en
hanced environments?
AU  - Mitterberger, Daniela
DA  - 2022/10//
PY  - 2022
DO  - 10.1145/3558196
ID  - 10.1145/3558196
IS  - 1
SN  - 1528-4972
SP  - 48-53
T2  - XRDS
TI  - Augmented human, extended machine: extended reality systems for roboti
c fabrication in architecture, engineering, and construction
UR  - https://doi.org/10.1145/3558196
VL  - 29
ER  - 
TY  - CONF
AB  - Surgery is primarily taught through mentoring, where an expert mentor 
supervises a mentee performing surgery, taking over when necessary. Te
lementoring systems aim to provide mentees with access to remote mento
rs, but the physical distance between mentors and mentees poses unique
 challenges to surgical training. We investigate the underlying needs 
leading to takeovers in onsite mentoring and assess mentors’ ability t
o fulfill address these needs remotely using existing telestration too
ls, namely pointers and drawings on shared views. Through interviews a
nd workshops with expert surgeons, we find that (1) mentors take over 
to convey gestures related to instrument placement, tissue displacemen
t, force, and movement, (2) mentors gather information about location 
of tissue, equipment, and instruments, as well as gesture constraints,
 and (3) surgeons judge telestration insufficient for these needs. Bas
ed on this gap between onsite mentoring practices and telementoring to
ols, we discuss novel tools to address these needs and their evaluatio
n.
AU  - Lambert, Solène
AU  - Voros, Sandrine
AU  - Canlorbe, Geoffroy
AU  - Troccaz, Jocelyne
AU  - Avellino, Ignacio
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI Conference on Human Factors in Computing S
ystems
DA  - 2024///
C2  - 2024
DO  - 10.1145/3613904.3641978
ID  - 10.1145/3613904.3641
KW  - gestures
KW  - remote instruction
KW  - surgical telementoring
KW  - takeovers
PB  - Association for Computing Machinery
SN  - 9798400703300
T3  - CHI '24
TI  - Understanding Takeovers and Telestration in Laparoscopic Surgery to In
form Telementoring System Design
UR  - https://doi.org/10.1145/3613904.3641978
ER  - 
TY  - JOUR
AB  - An experimental study of interaction in a collaborative desktop virtua
l environment is described. The aim of the experiment was to investiga
te if added haptic force feedback in such an environment affects perce
ived virtual presence, perceived social presence, perceived task perfo
rmance, and task performance. A between-group design was employed, whe
re seven pairs of subjects used an interface with graphic representati
on of the environment, audio connection, and haptic force feedback. Se
ven other pairs of subjects used an interface without haptic force fee
dback, but with identical features otherwise. The PHANToM, a one-point
 haptic device, was used for the haptic force feedback, and a program 
especially developed for the purpose provided the virtual environment.
 The program enables for two individuals placed in different locations
 to simultaneously feel and manipulate dynamic objects in a shared des
ktop virtual environment. Results show that haptic force feedback sign
ificantly improves task performance, perceived task performance, and p
ereceived virtual presence in the collaborative distributed environmen
t. The results suggest that haptic force feedback increases perceived 
social presence, but the difference is not significant.
AU  - Sallnäs, Eva-Lotta
AU  - Rassmus-Gröhn, Kirsten
AU  - Sjöström, Calle
DA  - 2000/12//
PY  - 2000
DO  - 10.1145/365058.365086
ID  - 10.1145/365058.36508
IS  - 4
KW  - presence
KW  - haptic force feedback
KW  - distributed collaboration
SN  - 1073-0516
SP  - 461-476
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - Supporting presence in collaborative environments by haptic force feed
back
UR  - https://doi.org/10.1145/365058.365086
VL  - 7
ER  - 
TY  - JOUR
AU  - ElSayed, Neven
AU  - Veas, Eduardo
AU  - Schmalstieg, Dieter
DA  - 2024/1//
PY  - 2024
DO  - 10.1145/3633521
ID  - 10.1145/3633521
IS  - 1
SN  - 1072-5520
SP  - 48-55
T2  - Interactions
TI  - Agents of MASK: Mobile Analytics from Situated Knowledge
UR  - https://doi.org/10.1145/3633521
VL  - 31
ER  - 
TY  - CONF
AB  - Collaborative Mixed Reality (MR) enables embodied meetings for distrib
uted collaborators working across a variety of locations. However, pro
viding a coherent experience for all users regardless of the spatial c
onfigurations of their respective physical environments is a central c
hallenge. We present the Spatial Heterogeneity Framework, which breaks
 the problem into four core components: the activity zones, heterogene
ity ladder, blended proxemics, and MR solutions matrix. We explain the
 interplay between these components, demonstrating their interconnecti
vity via a case study. Our framework enables researchers to navigate d
ifferences and trade-offs between solutions for distributed MR collabo
ration. It also supports designers to think about the role of space, t
echnology, and social behaviours in MR collaboration. Ultimately, our 
contributions advance the field by conceptualising the challenges of s
patial heterogeneity and strategies to overcome them.
AU  - Wong, Emily
AU  - Genay, Adélaı̈de
AU  - Grønbæk, Jens Emil Sloth
AU  - Velloso, Eduardo
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3714033
ID  - 10.1145/3706598.3714
KW  - Mixed Reality
KW  - Distributed Collaboration
KW  - Proxemics
KW  - Spatial Heterogeneity
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Spatial Heterogeneity in Distributed Mixed Reality Collaboration
UR  - https://doi.org/10.1145/3706598.3714033
ER  - 
TY  - CONF
AB  - Mirror surfaces can be used as information displays in smart homes and
 even for augmented reality (AR). The big advantage is the seamless in
tegration of the visual output into the user’s natural environment. Ho
wever, user input poses a challenge. On the one hand, touch input woul
d make the mirror dirty. On the other hand, mid-air gestures have prov
en to be less accurate, slower and more error-prone. We propose the us
e of an AR user interface (UI): Interactive UI elements are visible “o
n the other side of the mirror” and can be pressed by the user’s refle
ction. We built a functional prototype and investigated whether this i
s a viable option for interacting with mirrors. In a pilot study, we c
ompared the interaction with UI elements placed on three different pla
nes relative to the mirror surface: Behind the mirror (reflection), on
 the mirror (touch) and in front of the mirror (hologram).
AU  - Rigling, Sebastian
AU  - Avdić, Ševal
AU  - Özver, Muhammed Enes
AU  - Sedlmair, Michael
C1  -  
C3  - Proceedings of the Extended Abstracts of the CHI Conference on Human F
actors in Computing Systems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706599.3719930
ID  - 10.1145/3706599.3719
KW  - augmented reality
KW  - mirror
KW  - interaction
PB  - Association for Computing Machinery
SN  - 9798400713958
T3  - CHI EA '25
TI  - Reverse Vampire UI: Reflecting on AR Interaction with Smart Mirrors
UR  - https://doi.org/10.1145/3706599.3719930
ER  - 
TY  - CONF
AB  - This study explores the computational modeling of social touch in a co
operative multi-agent reinforcement learning (MARL) setting. Inspired 
by research on social allostasis and affective neurobiology, we implem
ent a novel model of social touch in artificial agents within a cooper
ative game setting, where interoception-inspired internal states are m
odulated by eating and agent-to-agent contact. A memory-augmented Prox
imal Policy Optimization (PPO) is used to explore and exploit social t
ouch for cooperative reward optimization and internal state regulation
. Our paradigm reveals that agents trained with modulatory social touc
h achieve better game performance, even in environments where touch is
 ineffective. We observe an evolution of touch behavior from frequent 
exploration to selective usage, showing better internal-state regulati
on and adaptability to heterogeneous starting conditions between agent
s. The findings demonstrate how interactive systems might incorporate 
non-verbal communication cues to enhance cooperation, with implication
s for designing more intuitive human-AI and robot-robot collaborative 
systems.
AU  - Ozdemir, Yagmur Idil
AU  - Gatti, Elia
C1  -  
C3  - Proceedings of the Extended Abstracts of the CHI Conference on Human F
actors in Computing Systems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706599.3720216
ID  - 10.1145/3706599.3720
KW  - Cooperation
KW  - Multi-agent Reinforcement Learning
KW  - Social Allostasis
KW  - Affective Neuroscience
KW  - Embodied Cognition
KW  - Social Touch
KW  - Haptics
KW  - HCI
PB  - Association for Computing Machinery
SN  - 9798400713958
T3  - CHI EA '25
TI  - Social Touch as an Allostatic Tool in Cooperative Multi-Agent Reinforc
ement Learning
UR  - https://doi.org/10.1145/3706599.3720216
ER  - 
TY  - CONF
AB  - Virtual Reality (VR) interfaces often rely on linear ray-casting for o
bject selection but struggle with precision in dense or occluded envir
onments. This late-breaking work introduces an optimized dual-layered 
selection mechanism combining dynamic Bézier Curves, controlled via fi
nger gestures, with on-body interaction surfaces to enhance precision 
and immersion. Bézier Curves offer fine-grained control and flexibilit
y in complex scenarios, while on-body surfaces project nearby virtual 
objects onto the user’s forearm, leveraging proprioception and tactile
 feedback. A preliminary qualitative study (N = 24) compared two inter
action paradigms (Bézier Curve vs. Linear Ray) and two interaction med
ia (On-body vs. Mid-air). Participants praised the Bézier Curve’s abil
ity to target occluded objects but noted the physical demand. On-body 
interactions were favored for their immersive qualities, while mid-air
 interactions were appreciated for maintaining focus on the virtual sc
ene. These findings highlight the importance of balancing ease of lear
ning and precise control when designing VR selection techniques, openi
ng avenues for further exploration of curve-based and on-body interact
ions in dense virtual environments.
AU  - Li, Xiang
AU  - Kristensson, Per Ola
C1  -  
C3  - Proceedings of the Extended Abstracts of the CHI Conference on Human F
actors in Computing Systems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706599.3719908
ID  - 10.1145/3706599.3719
KW  - Object Selection
KW  - Bézier Curve
KW  - On-Body Interaction
KW  - Disambiguation
KW  - Virtual Reality
KW  - Mixed Reality
PB  - Association for Computing Machinery
SN  - 9798400713958
T3  - CHI EA '25
TI  - Optimizing Curve-Based Selection with On-Body Surfaces in Virtual Envi
ronments
UR  - https://doi.org/10.1145/3706599.3719908
ER  - 
TY  - CONF
AB  - Computer networks have grown considerably over the past decade. Faster
 and cheaper Internet connections have brought millions of PCs into a 
domain where rich content and fast downloads have become a necessity. 
New technology such as haptics must integrate into the existing infras
tructures if it is to be considered a viable resource. As with visual 
and audio that preceded it, haptics too will find its home on the Inte
rnet. This research investigates the problems inherent in networks tha
t haptic technology must overcome to make the step from a fascinating 
technology to a practical one.
AU  - Lambeth, Benjamin M.
AU  - LaPlant, James
AU  - Clapan, Elena
AU  - Hamza-Lup, Felix G.
C1  - Clemson, South Carolina
C3  - Proceedings of the 47th Annual ACM Southeast Conference
DA  - 2009///
C2  - 2009
DO  - 10.1145/1566445.1566527
ID  - 10.1145/1566445.1566
KW  - collaborative virtual environments
KW  - haptics
KW  - network delays
PB  - Association for Computing Machinery
SN  - 9781605584218
T3  - ACMSE '09
TI  - The effects of network delay on task performance in a visual-haptic co
llaborative environment
UR  - https://doi.org/10.1145/1566445.1566527
ER  - 
TY  - CONF
AB  - While simulation-based FABO (foreign body airway obstruction) emergenc
y training has been common practice for medical professional, few stud
ies have investigated the needs of the public first responders. To und
erstand design trends, gaps and opportunities for simulation-based fir
st aid training in this context, researchers conducted a scoping revie
w across four databases and this process yielded 19 eligible papers th
at shared the design and application of simulation-based education in 
the FABO setting. Through this analysis, we understand the state-of-ar
t in simulation content themes, design considerations and technologies
 discussed in these papers, identifying key research opportunities and
 challenges for the future. Dominant design strategies include (1) ski
ll acquisition and decision making, (2) interactive procedure guidance
, and (3) evaluation of the learning outcome. Key underlying design co
nsiderations are immersion and presence, as well as preparation emotio
n for the real-world scenes. Notably, knowledge retention, cognitive l
oad, holistic scenarios, multi-sensory interaction are ought to be str
essed for future layperson centred FABO simulation.
AU  - Wang, Jiaxi
AU  - Yoo, Soojeong
C1  -  
C3  - Proceedings of the Extended Abstracts of the CHI Conference on Human F
actors in Computing Systems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706599.3719741
ID  - 10.1145/3706599.3719
KW  - virtual reality
KW  - mixed reality
KW  - simulation
KW  - pediatric airways
KW  - airway emergencies
KW  - medical education
KW  - choking
KW  - airway obstruction
KW  - first-aid
PB  - Association for Computing Machinery
SN  - 9798400713958
T3  - CHI EA '25
TI  - Simulation-based FABO first-aid Education: A Scoping Review
UR  - https://doi.org/10.1145/3706599.3719741
ER  - 
TY  - JOUR
AB  - Research in human-robot collaboration explores aspects of using intera
ction modalities and their effect on human perception. Particular atte
ntion is paid to intent communication, which is essential for successf
ul interaction and collaboration. This work investigates the effect of
 using audio, visual, and haptic feedback on intent communication in a
 human-robot collaboration task where the collaborators do not share a
 direct line of sight. A user study was conducted in virtual reality w
ith 20 participants. Qualitative and quantitative feedback was collect
ed from all participants. When compared with a baseline of no feedback
 given to the participants, results show that using visual feedback ha
d a significant impact on task efficiency, user experience, and cognit
ive load. Audio feedback was slightly less impactful, while haptic fee
dback had a divisive effect. Multimodal feedback combining the three m
odalities showed the highest impact compared to the individual modalit
ies, leading to the highest task efficiency and user experience, and t
he lowest cognitive load.
AU  - Kassem, Khaled
AU  - Ungerböck, Tobias
AU  - Wintersberger, Philipp
AU  - Michahelles, Florian
DA  - 2022/9//
PY  - 2022
DO  - 10.1145/3546731
ID  - 10.1145/3546731
IS  - MHCI
KW  - human-robot collaboration
KW  - human-robot interaction
KW  - robotics
KW  - user studies
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - What Is Happening Behind The Wall? Towards a Better Understanding of a
 Hidden Robot's Intent By Multimodal Cues
UR  - https://doi.org/10.1145/3546731
VL  - 6
ER  - 
TY  - CONF
AB  - Accessing auditory information remains challenging for DHH individuals
 in real-world situations and multiplayer VR interactions. To improve 
this, we investigated caption designs that specialize in the needs of 
DHH users in multiplayer VR settings. First, we conducted three co-des
ign workshops with DHH participants, social workers, and designers to 
gather insights into the specific needs of design directions for DHH u
sers in the context of a room escape game in VR. We further refined ou
r designs with 13 DHH users to determine the most preferred features. 
Based on this, we developed VRCaptions, a caption prototype for DHH us
ers to better experience multiplayer conversations in VR. We lastly in
vited two mixed-hearing groups to participate in the VR room escape ga
me with our VRCaptions to validate. The results demonstrate that VRCap
tions can enhance the ability of DHH participants to access informatio
n and reduce the barrier to communication in VR.
AU  - Xie, Tianze
AU  - Zhang, Xuesong
AU  - Huang, Feiyu
AU  - Liu, Di
AU  - An, Pengcheng
AU  - Je, Seungwoo
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3714186
ID  - 10.1145/3706598.3714
KW  - Accessibility
KW  - Communication
KW  - Virtual Reality
KW  - Deaf and Hard of Hearing
KW  - Caption Design
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - VRCaptions: Design Captions for DHH Users in Multiplayer Communication
 in VR
UR  - https://doi.org/10.1145/3706598.3714186
ER  - 
TY  - JOUR
AB  - Extended reality (XR) is rapidly advancing and poised to revolutionize
 content creation and consumption. In XR, users integrate various sens
ory inputs to form a cohesive perception of the virtual environment. T
his survey reviews the state-of-the-art in XR streaming, focusing on m
ultiple paradigms. To begin, we define XR and introduce various XR hea
dsets along with their multimodal interaction methods to provide a fou
ndational understanding. We then analyze XR traffic characteristics to
 highlight the unique data transmission requirements. We also explore 
factors that influence the quality of experience in XR systems, aiming
 to identify key elements for enhancing user satisfaction. Following t
his, we present visual attention-based optimization methods for XR str
eaming to improve efficiency and performance. Finally, we examine curr
ent applications and highlight challenges to provide insights into ong
oing and future developments of XR.
AU  - Wang, Haopeng
AU  - Dong, Haiwei
AU  - El Saddik, Abdulmotaleb
DA  - 2025/7//
PY  - 2025
DO  - 10.1145/3721292
ID  - 10.1145/3721292
IS  - 7
KW  - eXtended Reality
KW  - Virtual Reality
KW  - Augmented Reality
KW  - Mixed Reality
KW  - XR Streaming
KW  - Deep Learning
SN  - 1551-6857
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
TI  - Immersive Multimedia Communication: State-of-the-Art on Extended Reali
ty Streaming
UR  - https://doi.org/10.1145/3721292
VL  - 21
ER  - 
TY  - CONF
AB  - Distributed collaboration in Mixed Reality (MR) promises to revolution
ise how people connect across different physical environments, offerin
g experiences akin to face-to-face interactions. However, previous wor
k has mostly focused on enabling this vision in overly simplified sett
ings such as with only two users interacting in identical distributed 
environments. Scaling current systems to work with large groups and fo
r common real-life scenarios is a persistent challenge that requires a
ddressing multiple tensions. We identified six challenges: 1) supporti
ng locally congruent actions from heterogeneous remote spaces, 2) comm
unicating accurate user behaviours through virtual representation inst
ead of physical bodies, 3) facilitating organic group interactions wit
hin limited physical space, 4) maintaining conversational dynamics eve
n in asynchronous exchanges, 5) providing equal access to physical obj
ects for all participants, and 6) enabling efficient task switching wi
thin a complex ecology of applications, devices, and accessibility nee
ds. This workshop aims to gather researchers and practitioners to expl
ore actionable strategies for resolving these challenges. Through a mi
x of presentations, hands-on activities, and group discussions, partic
ipants will generate new ideas and develop a research agenda to articu
late the future of MR collaboration systems. The workshop outcomes wil
l include a list of concrete next steps for the community to bring dis
tributed MR collaboration at scale.
AU  - Genay, Adélaı̈de
AU  - Syiem, Brandon Victor
AU  - Wong, Emily
AU  - Feuchtner, Tiare
AU  - Knibbe, Jarrod
AU  - Grønbæk, Jens Emil Sloth
AU  - Velloso, Eduardo
C1  -  
C3  - Proceedings of the Extended Abstracts of the CHI Conference on Human F
actors in Computing Systems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706599.3706722
ID  - 10.1145/3706599.3706
KW  - Mixed Reality
KW  - Collaboration
KW  - Human-Computer Interaction
KW  - Distributed Systems
PB  - Association for Computing Machinery
SN  - 9798400713958
T3  - CHI EA '25
TI  - Scaling Distributed Collaboration in Mixed Reality
UR  - https://doi.org/10.1145/3706599.3706722
ER  - 
TY  - CONF
AB  - The interactive augmentation of musical instruments to foster self-exp
ressiveness and learning has a rich history. Over the past decades, th
e incorporation of interactive technologies into musical instruments e
merged into a new research field requiring strong collaboration betwee
n different disciplines. The workshop "Intelligent Music Interfaces" c
overs a wide range of musical research subjects and directions, includ
ing (a) current challenges in musical learning, (b) prototyping for im
provements, (c) new means of musical expression, and (d) evaluation of
 the solutions.
AU  - Deja, Jordan Aiko
AU  - Eska, Bettina
AU  - Shrestha, Snehesh
AU  - Hoppe, Matthias
AU  - Karolus, Jakob
AU  - Kosch, Thomas
AU  - Matviienko, Andrii
AU  - Weiß, Andreas
AU  - Marky, Karola
C1  - Glasgow, United Kingdom
C3  - Proceedings of the Augmented Humans International Conference 2023
DA  - 2023///
C2  - 2023
DO  - 10.1145/3582700.3582731
ID  - 10.1145/3582700.3582
KW  - Artistic Performance
KW  - Augmented Instruments
KW  - Music Interfaces
KW  - Musical Instruments
KW  - Self-Expression
PB  - Association for Computing Machinery
SN  - 9781450399845
SP  - 379-383
T3  - AHs '23
TI  - Intelligent Music Interfaces: When Interactive Assistance and Augmenta
tion Meet Musical Instruments
UR  - https://doi.org/10.1145/3582700.3582731
ER  - 
TY  - CONF
AB  - While extended reality (XR) has gained traction in entertainment, its 
application in knowledge work remains limited. This is partially due t
o challenges of existing interaction methods on facilitating prolonged
, high-precision operations without fatiguing the user. Previous resea
rch suggests that a "cane" shaped design may mitigate these issues by 
providing ergonomic arm support. However, designs exploring this confi
guration are lacking. We present CaneXR, a cane-based controller with 
ergonomic arm support that provides controls with five degrees of free
dom and operates a 3D cursor in the 3D space for object manipulation. 
We conducted a pilot study on its usability and received positive feed
back on the adoption of support. Based on the results, we presented im
provement opportunities to iterate on this prototype and expand its su
pporting features.
AU  - Zhang, Yaying
AU  - Li, Ziming
AU  - Shi, Rongkai
AU  - Jones, Brennan
AU  - Liang, Hai-Ning
C1  -  
C3  - Proceedings of the Extended Abstracts of the CHI Conference on Human F
actors in Computing Systems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706599.3720121
ID  - 10.1145/3706599.3720
KW  - Tangible User Interface
KW  - Extended Reality
KW  - Cane Stick
KW  - Device Form Factor
KW  - Handheld Device
KW  - Ergonomic
KW  - Dynamic Arm Support
KW  - Knowledge Work
PB  - Association for Computing Machinery
SN  - 9798400713958
T3  - CHI EA '25
TI  - CaneXR: Building a Cane-Based XR Controller for Knowledge Work
UR  - https://doi.org/10.1145/3706599.3720121
ER  - 
TY  - CONF
AB  - Sketching is a physical activity: moving a stylus to create marks on p
aper or screen, from mind to visual output. But sketching can also tra
nslate to the virtual space. When we sketch collaboratively, we look f
or cues, exchange ideas, and annotate work via mark-making or comment.
 The digital medium has evolved to explore the potentials of sketching
 online, and this Special Interest Group aims to bring together resear
chers and practitioners interested in Sketching in HCI to explore the 
new virtual landscape of sketching, popularised by the constraints of 
the current world situation. We invite you to join our virtual group, 
discuss and share sketches, query the existing state-of-the-art, and h
elp pave the way for the development of this medium in the virtual spa
ce with your imagery and ideation.
AU  - Sturdee, Miriam
AU  - Lewis, Makayla
AU  - Spiel, Katta
AU  - Priego, Ernesto
AU  - Fernández Camporro, Marina
AU  - Hoang, Thuong
C1  - Yokohama, Japan
C3  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2021///
C2  - 2021
DO  - 10.1145/3411763.3450401
ID  - 10.1145/3411763.3450
KW  - collaboration
KW  - drawing
KW  - sketching
KW  - visual thinking
KW  - visualisation
PB  - Association for Computing Machinery
SN  - 9781450380959
T3  - CHI EA '21
TI  - SketCHI 4.0: Hands-On Special Interest Group on Remote Sketching in HC
I
UR  - https://doi.org/10.1145/3411763.3450401
ER  - 
TY  - CONF
AB  - Visual impairment can profoundly impact well-being and social advancem
ent. Current solutions for accessing graphical information fail to pro
vide an affordable, user-friendly collaborative platform for visually 
impaired and sighted people to work together. Therefore, sighted users
 tend to have low expectations from visually impaired people while wor
king in a team. Hence, visually impaired people feel discouraged to pa
rticipate in a mixed population collaborative environment. Consequentl
y, their generative capabilities remain devalued. In this paper, we pr
opose an audio-haptic enabled tool (Drawxi) for free-form sketching an
d sharing simple diagrams (processes, workflows, ideas, perspectives, 
etc.). It provides a common platform for visually-impaired and sighted
 people to work together by communicating each other's ideas visually.
 Thus, enabling the discovery of generative capabilities in a hands-on
 way. We relied upon participatory research methods (Contextual inquir
y, Co-Design) involving visually impaired participants throughout the 
design process. We evaluated our proposed design through usability tes
ting which revealed that collaboration between visually impaired and s
ighted people benefits from the use of common tools and platforms. The
reby, enhancing the degree of their participation in a collaborative e
nvironment and quality of co-creation activities.
AU  - Chiplunkar, Suraj
AU  - Maini, Anany
AU  - Ram, Dinesh
AU  - Zheng, Zixuan
AU  - Zheng, Yaxin
C1  - Glasgow, Scotland Uk
C3  - Extended Abstracts of the 2019 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2019///
C2  - 2019
DO  - 10.1145/3290607.3309696
ID  - 10.1145/3290607.3309
KW  - accessibility
KW  - collaboration
KW  - diagrams
KW  - drawing tool
KW  - gestural
KW  - haptic feedback
KW  - inclusive design
KW  - multi-modal
KW  - touch device
KW  - visual impairment
PB  - Association for Computing Machinery
SN  - 9781450359719
SP  - 1-6
T3  - CHI EA '19
TI  - Drawxi: An Accessible Drawing Tool for Collaboration
UR  - https://doi.org/10.1145/3290607.3309696
ER  - 
TY  - CONF
AB  - Over time, numerous multimodal eXtended Reality (XR) user studies have
 been conducted in laboratory environments, with participants fulfilli
ng tasks under the guidance of a researcher. Although generalizable re
sults contributed to increase the maturity of the field, it is also pa
ramount to address the ecological validity of evaluations outside the 
laboratory. Despite real-world scenarios being clearly challenging, su
ccessful in-situ and remote deployment has become realistic to address
 a broad variety of research questions, thus, expanding participants’ 
sample to more specific target users, considering multi-modal constrai
nts not reflected in controlled laboratory settings and other benefits
. In this paper, a set of multimodal XR experiments conducted outside 
the laboratory are described (e.g., industrial field studies, remote c
ollaborative tasks, longitudinal rehabilitation exercises). Then, a li
st of lessons learned is reported, illustrating challenges, and opport
unities, aiming to increase the level of awareness of the research com
munity and facilitate performing further evaluations.
AU  - Marques, Bernardo
AU  - Silva, Samuel
AU  - Maio, Rafael
AU  - Alves, João
AU  - Ferreira, Carlos
AU  - Dias, Paulo
AU  - Santos, Beatriz Sousa
C1  - Paris, France
C3  - Proceedings of the 25th International Conference on Multimodal Interac
tion
DA  - 2023///
C2  - 2023
DO  - 10.1145/3577190.3614134
ID  - 10.1145/3577190.3614
KW  - Ecological Validity
KW  - Lessons Learned
KW  - Multimodal Interaction
KW  - Outside the Laboratory
KW  - User Evaluation
KW  - eXtended Reality
PB  - Association for Computing Machinery
SN  - 9798400700552
SP  - 234-242
T3  - ICMI '23
TI  - Evaluating Outside the Box: Lessons Learned on eXtended Reality Multi-
modal Experiments Beyond the Laboratory
UR  - https://doi.org/10.1145/3577190.3614134
ER  - 
TY  - CONF
AB  - Networked haptic virtual environments (NHVEs) are those in which multi
ple users collaborate and experience force feedback at the same time. 
The robustness of such systems needs to be tested under various networ
k conditions that closely mirror the Internet. Previously, we had prop
osed three virtual coupling schemes to maintain position coherency in 
a NHVE, which were tested using constant and then time-varying delays 
using the actual Internet through UDP packet reflectors. In this paper
 we present the results of comparing performance of the virtual coupli
ng schemes for a time varying delay emulated using the popular network
 emulator NIST Net, with delay conditions that existed during our real
 Internet experiment to Italy. UDP was used for haptic data communicat
ion because of the high transmission rate requirements for NHVEs. Expe
riments were conducted for three fixed packet transmission rates of 10
00, 500 and 100 Hz, and their performance compared using an independen
t-samples t-test to the data obtained using the Internet. Locally, the
 haptic update rate was maintained at 1000 Hz during the experiments. 
Our results show that the NIST Net was a suitable emulator for testing
 with lower packet transmission rates. At the transmission rate of 100
0 Hz the performance of the virtual coupling schemes were significantl
y different from that of the actual Internet experiment.
AU  - Sankaranarayanan, Ganesh
AU  - Hannaford, Blake
C1  - Athens, Greece
C3  - Proceedings of the 1st International Conference on Robot Communication
 and Coordination
DA  - 2007///
C2  - 2007
ID  - 10.5555/1377868.1377
PB  - IEEE Press
SN  - 9789639799080
T3  - RoboComm '07
TI  - Comparison of performance of virtual coupling schemes for haptic colla
boration using real and emulated internet connections
ER  - 
TY  - CONF
AB  - The interactive augmentation of musical instruments to foster self-exp
ression and learning has a rich history. Over the past decades, incorp
orating interactive technologies into musical instruments has emerged 
as a research field requiring strong collaboration between disciplines
. The workshop “Intelligent Music Interfaces” covers a wide range of m
usical research subjects and directions, including (a) current challen
ges in musical learning, (b) prototyping for improvements, (c) new mea
ns of musical expression, and (d) evaluation of the solutions.
AU  - Kosch, Thomas
AU  - Weiß, Andreas
AU  - Deja, Jordan Aiko
AU  - Shrestha, Snehesh
AU  - Hoppe, Matthias
AU  - Matviienko, Andrii
AU  - Marky, Karola
C1  - Melbourne, VIC, Australia
C3  - Proceedings of the Augmented Humans International Conference 2024
DA  - 2024///
C2  - 2024
DO  - 10.1145/3652920.3653039
ID  - 10.1145/3652920.3653
KW  - Augmented Instruments
KW  - Music Interfaces
KW  - Musical Instruments
KW  - Self-Expression
PB  - Association for Computing Machinery
SN  - 9798400709807
SP  - 327-330
T3  - AHs '24
TI  - Intelligent Music Interfaces: When Interactive Assistance and Adaptive
 Augmentation Meet Musical Instruments
UR  - https://doi.org/10.1145/3652920.3653039
ER  - 
TY  - CONF
AB  - We have developed the ”Hand Shaking Model,” an application of Tangible
-3D, which is a new type of remote communication interface, another ex
ample of which is the haptic 3D video phone. In this paper, we explain
 the Hand Shaking Model application, which allows users to shake hands
 with remote users, one example of Tangible-3D.
AU  - Ozawa, Shiro
AU  - Abe, Takao
AU  - Ogawa, Takuya
AU  - Ogawara, Masanori
AU  - Hirano, Mitsusnori
AU  - Tanaka, Kazuhiko
C1  - Florence, Italy
C3  - CHI '08 Extended Abstracts on Human Factors in Computing Systems
DA  - 2008///
C2  - 2008
DO  - 10.1145/1358628.1358674
ID  - 10.1145/1358628.1358
KW  - 3d
KW  - communication
KW  - haptic
KW  - tangible
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781605580128
SP  - 2303-2308
T3  - CHI EA '08
TI  - Tangible-3d: hand shaking model
UR  - https://doi.org/10.1145/1358628.1358674
ER  - 
TY  - CONF
AB  - Social virtual reality (VR) has become one of the most popular forms o
f VR. However, despite years of research on how VR interventions can b
e useful as diagnostic or therapeutic tools for neurodivergent (ND) us
ers, there has been little examination of how accessible social VR may
 be for such ND individuals. In this paper, we describe an ongoing use
r study with participants who self-identify with both autism and ADHD 
(AuDHD) and also self-identify with facing frequent challenges with so
cial interaction. So far, we have recruited four AuDHD participants; w
e had each participant briefly explore a world on a popular commercial
 social VR platform and then reflect on this experience afterward in a
 longer interview section. Through this process, we uncovered various 
accessibility challenges in social VR, such as difficulties with navig
ating social norms or managing certain sensory inputs. We also noted i
deas on potential accommodations, like a text-based prompt system that
 can suggest “appropriate” conversation responses. Our work outlines o
pportunities to improve the accessibility of social VR for an often-ov
erlooked user group.
AU  - Collins, Jazmin
AU  - Ko, Woojin
AU  - Shende, Tanisha
AU  - Lin, Sharon Y
AU  - Jiang, Lucy
AU  - Stevenson Won, Andrea
AU  - Azenkot, Shiri
C1  - St. John's, NL, Canada
C3  - Proceedings of the 26th International ACM SIGACCESS Conference on Comp
uters and Accessibility
DA  - 2024///
C2  - 2024
DO  - 10.1145/3663548.3687134
ID  - 10.1145/3663548.3687
KW  - ADHD
KW  - VR
KW  - accessibility
KW  - autism
KW  - neurodivergence
PB  - Association for Computing Machinery
SN  - 9798400706776
T3  - ASSETS '24
TI  - Exploring the Accessibility of Social Virtual Reality for People with 
ADHD and Autism: Preliminary Insights
UR  - https://doi.org/10.1145/3663548.3687134
ER  - 
TY  - CONF
AB  - Behaviour in virtual environments might be informed by our experiences
 in physical environments, but virtual environments are not constraine
d by the same physical, perceptual, or social cues. Instead of replica
ting the properties of physical spaces, one can create virtual experie
nces that diverge from reality by dynamically manipulating environment
al, aural, and social properties. This paper explores digital proxemic
s, which describe how we use space in virtual environments and how the
 presence of others influences our behaviours, interactions, and movem
ents. First, we frame the open challenges of digital proxemics in term
s of activity, social signals, audio design, and environment. We explo
re a subset of these challenges through an evaluation that compares tw
o audio designs and two displays with different social signal affordan
ces: head-mounted display (HMD) versus desktop PC. We use quantitative
 methods using instrumented tracking to analyse behaviour, demonstrati
ng how personal space, proximity, and attention compare between deskto
p PC and HMDs.
AU  - Williamson, Julie R.
AU  - O'Hagan, Joseph
AU  - Guerra-Gomez, John Alexis
AU  - Williamson, John H
AU  - Cesar, Pablo
AU  - Shamma, David A.
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI Conference on Human Factors in Computing S
ystems
DA  - 2022///
C2  - 2022
DO  - 10.1145/3491102.3517594
ID  - 10.1145/3491102.3517
KW  - Digital Proxemics
KW  - Quantitative Methods.
KW  - Social Signal Processing
KW  - Virtual Environments
PB  - Association for Computing Machinery
SN  - 9781450391573
T3  - CHI '22
TI  - Digital Proxemics: Designing Social and Collaborative Interaction in V
irtual Environments
UR  - https://doi.org/10.1145/3491102.3517594
ER  - 
TY  - CONF
AB  - Mastering the guitar requires regular exercise to develop new skills a
nd maintain existing abilities. We present Let’s Frets - a modular gui
tar support system that provides visual guidance through LEDs that are
 integrated into a capacitive fretboard to support the practice of cho
rds, scales, melodies, and exercises. Additional feedback is provided 
through a 3D-printed fretboard that senses the finger positions throug
h capacitive sensing. We envision Let’s Frets as an integrated guitar 
support system that raises the awareness of guitarists about their pla
ying styles, their training progress, the composition of new pieces, a
nd facilitating remote collaborations between teachers as well as guit
ar students. This interactivity demonstrates Let’s Frets with an augme
nted fretboard and supporting software that runs on a mobile device.
AU  - Marky, Karola
AU  - Weiß, Andreas
AU  - Müller, Florian
AU  - Schmitz, Martin
AU  - Mühlhäuser, Max
AU  - Kosch, Thomas
C1  - Yokohama, Japan
C3  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2021///
C2  - 2021
DO  - 10.1145/3411763.3451536
ID  - 10.1145/3411763.3451
KW  - capacitive sensing
KW  - musical instruments
KW  - support setup
PB  - Association for Computing Machinery
SN  - 9781450380959
T3  - CHI EA '21
TI  - Let’s Frets! Mastering Guitar Playing with Capacitive Sensing and Visu
al Guidance
UR  - https://doi.org/10.1145/3411763.3451536
ER  - 
TY  - CONF
AB  - The interactive augmentation of musical instruments to foster self-exp
ressiveness and learning has a rich history. Over the past decades, th
e incorporation of interactive technologies into musical instruments e
merged into a new research field requiring strong collaboration betwee
n different disciplines. The workshop ”Intelligent Music Interfaces” c
onsequently covers a wide range of musical research subjects and direc
tions, including (a) current challenges in musical learning, (b) proto
typing for improvements, (c) new means of musical expression, and (d) 
evaluation of the solutions.
AU  - Marky, Karola
AU  - Kilian, Annika
AU  - Weiß, Andreas
AU  - Karolus, Jakob
AU  - Hoppe, Matthias
AU  - Wozniak, Pawel W.
AU  - Mühlhäuser, Max
AU  - Kosch, Thomas
C1  - New Orleans, LA, USA
C3  - Extended Abstracts of the 2022 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2022///
C2  - 2022
DO  - 10.1145/3491101.3503743
ID  - 10.1145/3491101.3503
KW  - Artistic Performance
KW  - Augmented Instruments
KW  - Music Interfaces
KW  - Musical Instruments
KW  - Self-Expression
PB  - Association for Computing Machinery
SN  - 9781450391566
T3  - CHI EA '22
TI  - Intelligent Music Interfaces: When Interactive Assistance and Augmenta
tion Meet Musical Instruments
UR  - https://doi.org/10.1145/3491101.3503743
ER  - 
TY  - CONF
AB  - In this paper, we present the results of an experimental study aiming 
to explore the collaborative user experience in an immersive virtual e
nvironment. We designed and implemented an application that enables us
ers to collaboratively design a spatial layout using head-mounted VR d
isplays and hand tracking devices. With a strong emphasis on the relat
ionship between spatial interaction and communication, we assert that 
a shared-view virtual environment allows collaborative articulation of
 spatial design problems and improves communication between designers.
 Our study combines qualitative and quantitative methods to test the u
sability of the proposed system, and to determine the aspects of spati
al communication in virtual environments.
AU  - Zaman, Cagri Hakan
AU  - Yakhina, Asiya
AU  - Casalegno, Federico
C1  - Bandung, Indonesia
C3  - Proceedings of the International HCI and UX Conference in Indonesia
DA  - 2015///
C2  - 2015
DO  - 10.1145/2742032.2742034
ID  - 10.1145/2742032.2742
KW  - collaborative design
KW  - embodied communication
KW  - gestural interaction
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450333344
SP  - 10-17
T3  - CHIuXiD '15
TI  - nRoom: an immersive virtual environment for collaborative spatial desi
gn
UR  - https://doi.org/10.1145/2742032.2742034
ER  - 
TY  - JOUR
AB  - Investigating virtual environments has become an increasingly interest
ing research topic for engineers, computer and cognitive scientists, a
nd psychologists. Although there have been several recent studies focu
sed on the development of multimodal virtual environments (VEs) to stu
dy human-machine interactions, less attention has been paid to human-h
uman and human-machine interactions in shared virtual environments (SV
Es), and to our knowledge, no attention paid at all to what extent the
 addition of haptic communication between people would contribute to t
he shared experience. We have developed a multimodal shared virtual en
vironment and performed a set of experiments with human subjects to st
udy the role of haptic feedback in collaborative tasks and whether hap
tic communication through force feedback can facilitate a sense of bei
ng and collaborating with a remote partner. The study concerns a scena
rio where two participants at remote sites must cooperate to perform a
 joint task in an SVE. The goals of the study are (1) to assess the im
pact of force feedback on task performance, (2) to better understand t
he role of haptic communication in human-human interactions, (3) to st
udy the impact of touch on the subjective sense of collaborating with 
a human as reported by the participants based on what they could see a
nd feel, and (4) to investigate if gender, personality, or emotional e
xperiences of users can affect haptic communication in SVEs. The outco
mes of this research can have a powerful impact on the development of 
next-generation human-computer interfaces and network protocols that i
ntegrate touch and force feedback technology into the internet, develo
pment of protocols and techniques for collaborative teleoperation such
 as hazardous material removal, space station.
AU  - Basdogan, Cagatay
AU  - Ho, Chih-Hao
AU  - Srinivasan, Mandayam A.
AU  - Slater, Mel
DA  - 2000/12//
PY  - 2000
DO  - 10.1145/365058.365082
ID  - 10.1145/365058.36508
IS  - 4
KW  - copresence
KW  - force feedback devices
KW  - haptic interaction
KW  - shared virtual environments
SN  - 1073-0516
SP  - 443-460
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - An experimental study on the role of touch in shared virtual environme
nts
UR  - https://doi.org/10.1145/365058.365082
VL  - 7
ER  - 
TY  - CONF
AB  - Industry 5.0 represents a paradigm shift initiated by the European Com
mission, which emphasizes human-centricity, sustainability, and resili
ence in industrial settings. This novel paradigm underscores the impor
tance of giving a central role to humans in every process entailed in 
the implementation of advanced technologies into work and industrial s
cenarios. By following this view, in this work, we present a novel hum
an-centric framework integrating Digital Twins (DTs) and Augmented Rea
lity (AR) within a manufacturing setting, focusing on a design and eva
luation process that facilitates seamless interaction between humans a
nd machines. This work contributes to the ongoing discourse on Industr
y 5.0 by offering a twofold yet integrated perspective on humans and n
ovel industrial technologies, providing insights into the transformati
ve potential of integrating AR and DT technologies within industrial s
ettings. From a technical perspective, the framework’s hardware and so
ftware specifications, design principles, and technical implementation
 are elucidated, followed by an evaluation of its responsiveness and s
patial accuracy. Results demonstrate the framework’s efficacy in provi
ding real-time monitoring and control of robotic systems. Parallely, t
he potential impacts of our AR-based digital twin systems on human lab
or and work routines are discussed, providing a more human-based persp
ective to complement the technical one.
AU  - Grego, Giovanni
AU  - Nenna, Federica
AU  - Gamberini, Luciano
C1  - Crete, Greece
C3  - Proceedings of the 17th International Conference on PErvasive Technolo
gies Related to Assistive Environments
DA  - 2024///
C2  - 2024
DO  - 10.1145/3652037.3663946
ID  - 10.1145/3652037.3663
KW  - Digital Twin
KW  - Extended Reality
KW  - Human-Computer Interaction
KW  - Manufacturing
KW  - Pervasive Devices
KW  - Robotics
PB  - Association for Computing Machinery
SN  - 9798400717604
SP  - 456-462
T3  - PETRA '24
TI  - Enhancing Human-Machine Interactions: A Novel Framework for AR-Based D
igital Twin Systems in Industrial Environments
UR  - https://doi.org/10.1145/3652037.3663946
ER  - 
TY  - CONF
AB  - VTubing, the practice of live streaming using virtual avatars, has gai
ned worldwide popularity among streamers seeking to maintain anonymity
. While previous research has primarily focused on the social and cult
ural aspects of VTubing, there is a noticeable lack of studies examini
ng the practical challenges VTubers face in creating and operating the
ir avatars. To address this gap, we surveyed VTubers’ equipment and ex
panded the live-streaming design space by introducing six new dimensio
ns related to avatar creation and control. Additionally, we conducted 
interviews with 16 professional VTubers to comprehensively explore the
ir practices, strategies, and challenges throughout the VTubing proces
s. Our findings reveal that VTubers face significant burdens compared 
to real-person streamers due to fragmented tools and the multi-tasking
 nature of VTubing, leading to unique workarounds. Finally, we summari
ze these challenges and propose design opportunities to improve the ef
fectiveness and efficiency of VTubing.
AU  - Kim, Daye
AU  - Lee, Sebin
AU  - Jun, Yoonseo
AU  - Shin, Yujin
AU  - Lee, Jungjin
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3714107
ID  - 10.1145/3706598.3714
KW  - VTuber
KW  - VTubing equipment
KW  - live streaming
KW  - design space
KW  - virtual avatar
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - VTuber's Atelier: The Design Space, Challenges, and Opportunities for 
VTubing
UR  - https://doi.org/10.1145/3706598.3714107
ER  - 
TY  - CONF
AB  - The rapid evolution of Extended Reality (XR) technologies—encompassing
 Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR)—
has paved the way for richer and more immersive user experiences. Conc
urrently, the emergence of Large Language Models (LLMs), such as GPT-4
, has unlocked new opportunities to enhance interactions within XR env
ironments. This paper presents the first comprehensive review addressi
ng the underexplored synergy between XR and LLMs, examining how the in
tegration of these technologies can augment various aspects of human a
wareness: spatial, situational, social, and self-awareness. By systema
tically analyzing 135 papers, we synthesize and categorize the researc
h field into seven dimensions: 1) diverse application domains, 2) type
s of human awareness expanded, 3) interaction paradigms between users 
and systems, 4) effects of LLMs in XR, 5) practices for effectively in
tegrating LLMs into XR environments, and 6) evaluation metrics. We als
o discuss remaining challenges and propose future research focusing on
 ethical awareness.
AU  - Tang, Yiliu
AU  - Situ, Jason
AU  - Cui, Andrea Yaoyun
AU  - Wu, Mengke
AU  - Huang, Yun
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3714224
ID  - 10.1145/3706598.3714
KW  - Extended Reality
KW  - Large Language Models
KW  - Scoping Review
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - LLM Integration in Extended Reality: A Comprehensive Review of Current
 Trends, Challenges, and Future Perspectives
UR  - https://doi.org/10.1145/3706598.3714224
ER  - 
TY  - CONF
AB  - In this study we compared collaboration on a puzzle-solving task carri
ed out by two persons in a virtual and a real environment. The task, p
utting together a cube consisting of different coloured blocks in a 'R
ubiks' cubetype puzzle, was performed both in a shared virtual environ
ment (VE) setting, using a Cave-type virtual reality (VR) system netwo
rked with a desktop VR system, and with cardboard coloured blocks in a
n equivalent real setting. The aims of the study were to investigate c
ollaboration, leadership and performance in the two settings. We found
 that the participants contributed unequally to the task in the VE, an
d also differences in collaboration between the virtual and the real s
etting.
AU  - Wideström, Josef
AU  - Axelsson, Ann-Sofie
AU  - Schroeder, Ralph
AU  - Nilsson, Alexander
AU  - Heldal, Ilona
AU  - Abelin, Åsa
C1  - San Francisco, California, USA
C3  - Proceedings of the Third International Conference on Collaborative Vir
tual Environments
DA  - 2000///
C2  - 2000
DO  - 10.1145/351006.351035
ID  - 10.1145/351006.35103
KW  - co-presence
KW  - collaboration
KW  - leadership
KW  - presence
KW  - virtual environments
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 1581133030
SP  - 165-171
T3  - CVE '00
TI  - The collaborative cube puzzle: a comparison of virtual and real enviro
nments
UR  - https://doi.org/10.1145/351006.351035
ER  - 
TY  - CONF
AB  - Remote tutoring has gained significant traction due to technological a
dvances, primarily relying on video-conferencing tools. However, these
 tools are not specifically designed for tutoring. Positive tutoring e
xperiences rely on interaction with and immediate feedback from the tu
tor. Moreover, traditional methods like writing, reading, and drawing 
in physical spaces enhance learning outcomes. Integrating these method
s with physical materials and digital remote guidance could improve re
mote learning experiences. A technology that enables this integration 
is spatial augmented reality (SAR), which utilizes projection to integ
rate digital content into the physical world. This work introduces a S
patial Augmented Reality (SAR) remote tutoring tool that enables augme
nted annotations and projected video streams. We conducted a between-s
ubject lab study (N=18) comparing learning experiences in remote tutor
ing between standard video conferencing tools and the introduced Spati
al Augmented Reality (SAR) tool. Qualitative analysis revealed the Spa
tial Augmented Reality (SAR) system’s benefits over video conferencing
, specifically immediate feedback, in-situ annotations, improved inter
activity, and enhanced social presence.
AU  - Wittig, Nick
AU  - Drey, Tobias
AU  - Wettig, Theresa
AU  - Auda, Jonas
AU  - Koelle, Marion
AU  - Goedicke, David
AU  - Schneegass, Stefan
C1  -  
C3  - Proceedings of the International Conference on Mobile and Ubiquitous M
ultimedia
DA  - 2024///
C2  - 2024
DO  - 10.1145/3701571.3701577
ID  - 10.1145/3701571.3701
KW  - spatial augmented reality
KW  - augmented surfaces
KW  - remote tutoring
KW  - education
PB  - Association for Computing Machinery
SN  - 9798400712838
SP  - 255-263
T3  - MUM '24
TI  - LeARn at Home: Comparing Augmented Reality and Video Conferencing Remo
te Tutoring
UR  - https://doi.org/10.1145/3701571.3701577
ER  - 
TY  - CONF
AB  - This paper introduces TRANS-DOCK, a docking system for pin-based shape
 displays that enhances their interaction capabilities for both the ou
tput and input. By simply interchanging the transducer module, compose
d of passive mechanical structures, to be docked on a shape display, u
sers can selectively switch between different configurations including
 display sizes, resolutions, and even motion modalities to allow pins 
moving in a linear motion to rotate, bend and inflate. We introduce a 
design space consisting of several mechanical elements and enabled int
eraction capabilities. We then explain the implementation of the docki
ng system and transducer design components. Our implementation include
s providing the limitations and characteristics of each motion transmi
ssion method as design guidelines. A number of transducer examples are
 then shown to demonstrate the range of interactivity and application 
space achieved with the approach of TRANS-DOCK. Potential use cases to
 take advantage of the interchangeability of our approach are discusse
d. Through this paper we intend to expand expressibility, adaptability
 and customizability of a single shape display for dynamic physical in
teraction. By converting arrays of linear motion to several types of d
ynamic motion in an adaptable and flexible manner, we advance shape di
splays to enable versatile embodied interactions.
AU  - Nakagaki, Ken
AU  - Liu, Yingda (Roger)
AU  - Nelson-Arzuaga, Chloe
AU  - Ishii, Hiroshi
C1  - Sydney NSW, Australia
C3  - Proceedings of the Fourteenth International Conference on Tangible, Em
bedded, and Embodied Interaction
DA  - 2020///
C2  - 2020
DO  - 10.1145/3374920.3374933
ID  - 10.1145/3374920.3374
KW  - mechanical transducers
KW  - pin-based shape display
KW  - shape changing interfaces
PB  - Association for Computing Machinery
SN  - 9781450361071
SP  - 131-142
T3  - TEI '20
TI  - TRANS-DOCK: Expanding the Interactivity of Pin-based Shape Displays by
 Docking Mechanical Transducers
UR  - https://doi.org/10.1145/3374920.3374933
ER  - 
TY  - CONF
AB  - The objective of the proposed application is the development of a new 
interactive application for the simulation of Ancient Greek Technology
 works, with the use of advanced virtual reality and computer vision t
echnologies. In order to achieve these objectives haptic interaction m
echanisms and a gesture recognition system were implemented in a virtu
al environment platform. A novel collision detection method was develo
ped and virtual reality agents were used in order to achieve the desir
ed results. The developed system was evaluated by real users and concl
usions were drawn concerning the potentiality of the proposed applicat
ion.
AU  - Nikolakis, G.
AU  - Tzovaras, D.
AU  - Malassiotis, S.
AU  - Strintzis, M. G.
C1  - Oudenaarde, Belgium
C3  - Proceedings of the 5th International Conference on Virtual Reality, Ar
chaeology and Intelligent Cultural Heritage
DA  - 2004///
C2  - 2004
ID  - 10.5555/2384368.2384
PB  - Eurographics Association
SN  - 3905673185
SP  - 261-270
T3  - VAST'04
TI  - Simulation of ancient technology works using haptic interaction and ge
sture recognition
ER  - 
TY  - CONF
AB  - We introduce a model for supporting collaborative work between people 
that are physically close to each other. We call this model Single Dis
play Groupware (SDG). In this paper, we describe the model, comparing 
it to more traditional remote collaboration, We describe the requireme
nts that SDG places on computer technology, and our understanding of t
he benefits and costs of SDG systems. Finally, we describe a prototype
 SDG system that we built and the results of a usability test we ran w
ith 60 elementary school children.
AU  - Stewart, Jason
AU  - Bederson, Benjamin B.
AU  - Druin, Allison
C1  - Pittsburgh, Pennsylvania, USA
C3  - Proceedings of the SIGCHI Conference on Human Factors in Computing Sys
tems
DA  - 1999///
C2  - 1999
DO  - 10.1145/302979.303064
ID  - 10.1145/302979.30306
KW  - CSCW
KW  - KidPad
KW  - Pad++
KW  - children
KW  - educational applications
KW  - input devices
KW  - single display groupware
PB  - Association for Computing Machinery
SN  - 0201485591
SP  - 286-293
T3  - CHI '99
TI  - Single display groupware: a model for co-present collaboration
UR  - https://doi.org/10.1145/302979.303064
ER  - 
TY  - CONF
AB  - This paper contributes to a taxonomy of augmented reality and robotics
 based on a survey of 460 research papers. Augmented and mixed reality
 (AR/MR) have emerged as a new way to enhance human-robot interaction 
(HRI) and robotic interfaces (e.g., actuated and shape-changing interf
aces). Recently, an increasing number of studies in HCI, HRI, and robo
tics have demonstrated how AR enables better interactions between peop
le and robots. However, often research remains focused on individual e
xplorations and key design strategies, and research questions are rare
ly analyzed systematically. In this paper, we synthesize and categoriz
e this research field in the following dimensions: 1) approaches to au
gmenting reality; 2) characteristics of robots; 3) purposes and benefi
ts; 4) classification of presented information; 5) design components a
nd strategies for visual augmentation; 6) interaction techniques and m
odalities; 7) application domains; and 8) evaluation strategies. We fo
rmulate key challenges and opportunities to guide and inform future re
search in AR and robotics.
AU  - Suzuki, Ryo
AU  - Karim, Adnan
AU  - Xia, Tian
AU  - Hedayati, Hooman
AU  - Marquardt, Nicolai
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI Conference on Human Factors in Computing S
ystems
DA  - 2022///
C2  - 2022
DO  - 10.1145/3491102.3517719
ID  - 10.1145/3491102.3517
KW  - AR-HRI
KW  - VAM-HRI
KW  - actuated tangible UI
KW  - augmented reality
KW  - human-robot interaction
KW  - mixed reality
KW  - robotics
KW  - shape-changing UI
PB  - Association for Computing Machinery
SN  - 9781450391573
T3  - CHI '22
TI  - Augmented Reality and Robotics: A Survey and Taxonomy for AR-enhanced 
Human-Robot Interaction and Robotic Interfaces
UR  - https://doi.org/10.1145/3491102.3517719
ER  - 
TY  - CONF
AB  - During the past year we've all spent many hours on videoconference cal
ls, sometimes more than was comfortable. While CHI might not have anti
cipated a viral-driven surge in videoconferencing, online meetings has
 been a topic of CHI research for the past 25 years. This is a good ti
me to assess how well our research has matched what this natural exper
iment is telling us. What did we get right? And what did the field get
 wrong? The panel, comprised of people who directly witnessed much of 
this history, will reflect on these questions. We don't expect all to 
agree with each panelist's conclusions, and we will invite reactions a
nd contributions from the audience as well..
AU  - Russell, Daniel
AU  - Neustaedter, Carman
AU  - Tang, John
AU  - Judge, Tejinder
AU  - Olson, Gary
C1  - Yokohama, Japan
C3  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2021///
C2  - 2021
DO  - 10.1145/3411763.3450398
ID  - 10.1145/3411763.3450
KW  - CSCW
KW  - meeting fatigue
KW  - videoconference
PB  - Association for Computing Machinery
SN  - 9781450380959
T3  - CHI EA '21
TI  - Videoconferencing in the Age of COVID: How Well Has It Worked Out?
UR  - https://doi.org/10.1145/3411763.3450398
ER  - 
TY  - CONF
AB  - Many features of materials can be experienced through tactile cues, ev
en using one's feet. For example, one can easily distinguish between m
oss and stone without looking at the ground. However, this type of mat
erial experience is largely not supported in AR and VR applications. W
e present bARefoot, a prototype shoe providing tactile impulses tightl
y coupled to motor actions. This enables generating virtual material e
xperiences such as compliance, elasticity, or friction. To explore the
 parameter space of such sensorimotor coupled vibrations, we present a
 design tool enabling rapid design of virtual materials. We report ini
tial explorations to increase understanding of how parameters can be o
ptimized for generating compliance, and to examine the effect of dynam
ic parameters on material experiences. Finally, we present a series of
 use cases that demonstrate the potential of bARefoot for VR and AR.
AU  - Strohmeier, Paul
AU  - Güngör, Seref
AU  - Herres, Luis
AU  - Gudea, Dennis
AU  - Fruchard, Bruno
AU  - Steimle, Jürgen
C1  - Virtual Event, USA
C3  - Proceedings of the 33rd Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2020///
C2  - 2020
DO  - 10.1145/3379337.3415828
ID  - 10.1145/3379337.3415
KW  - wearable computing
KW  - virtual reality
KW  - shoes
KW  - material experiences
KW  - haptic rendering
KW  - haptic feedback
KW  - body-based interaction
KW  - augmented reality
PB  - Association for Computing Machinery
SN  - 9781450375146
SP  - 579-593
T3  - UIST '20
TI  - bARefoot: Generating Virtual Materials using Motion Coupled Vibration 
in Shoes
UR  - https://doi.org/10.1145/3379337.3415828
ER  - 
TY  - CONF
AB  - Visual cues are essential in computer-mediated communication. It is es
pecially important when communication happens in a collaboration scena
rio that requires focusing several users’ attention on a specific obje
ct among other similar ones. This paper explores the effect of visual 
cues on pointing tasks in co-located Augmented Reality (AR) collaborat
ion. A user study (N = 32, 16 pairs) was conducted to compare two type
s of visual cues: Pointing Line (PL) and Moving Track (MT). Both are h
ead-based visual techniques. Through a series of collaborative pointin
g tasks on objects with different states (static and dynamic) and dens
ity levels (low, medium and high), the results showed that PL was bett
er on task performance and usability, but MT was rated higher on socia
l presence and user preference. Based on our results, some design impl
ications are provided for pointing tasks in co-located AR collaboratio
n.
AU  - Chen, Lei
AU  - Liu, Yilin
AU  - Li, Yue
AU  - Yu, Lingyun
AU  - Gao, BoYu
AU  - Caon, Maurizio
AU  - Yue, Yong
AU  - Liang, Hai-Ning
C1  - Virtual Event, USA
C3  - Proceedings of the 2021 ACM Symposium on Spatial User Interaction
DA  - 2021///
C2  - 2021
DO  - 10.1145/3485279.3485297
ID  - 10.1145/3485279.3485
KW  - Visual cues
KW  - Pointing Tasks
KW  - Co-located collaboration
KW  - Augmented Reality
PB  - Association for Computing Machinery
SN  - 9781450390910
T3  - SUI '21
TI  - Effect of Visual Cues on Pointing Tasks in Co-located Augmented Realit
y Collaboration
UR  - https://doi.org/10.1145/3485279.3485297
ER  - 
TY  - CONF
AB  - RoomShift is a room-scale dynamic haptic environment for virtual reali
ty, using a small swarm of robots that can move furniture. RoomShift c
onsists of nine shape-changing robots: Roombas with mechanical scissor
 lifts. These robots drive beneath a piece of furniture to lift, move 
and place it. By augmenting virtual scenes with physical objects, user
s can sit on, lean against, place and otherwise interact with furnitur
e with their whole body; just as in the real world. When the virtual s
cene changes or users navigate within it, the swarm of robots dynamica
lly reconfigures the physical environment to match the virtual content
. We describe the hardware and software implementation, applications i
n virtual tours and architectural design and interaction techniques.
AU  - Suzuki, Ryo
AU  - Hedayati, Hooman
AU  - Zheng, Clement
AU  - Bohn, James L.
AU  - Szafir, Daniel
AU  - Do, Ellen Yi-Luen
AU  - Gross, Mark D.
AU  - Leithinger, Daniel
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI Conference on Human Factors in Computing S
ystems
DA  - 2020///
C2  - 2020
DO  - 10.1145/3313831.3376523
ID  - 10.1145/3313831.3376
KW  - haptic interfaces
KW  - room-scale haptics
KW  - swarm robots
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450367080
SP  - 1-11
T3  - CHI '20
TI  - RoomShift: Room-scale Dynamic Haptics for VR with Furniture-moving Swa
rm Robots
UR  - https://doi.org/10.1145/3313831.3376523
ER  - 
TY  - CONF
AB  - Sustainability is a challenge for society that circular economy tries 
to tackle. The metaverse, as an emerging technology that incorporates 
digital twins and simulation in an immersive virtual environment, has 
not been thoroughly investigated in connection to circular economy. Th
us, the purpose of this study is to summarize the potentials and barri
ers of the use of the metaverse for circular economy. By conducting a 
structured literature review, this paper categorizes the findings into
 dimensions that are important for both the metaverse and circular eco
nomy. A variety of potentials and barriers that cover different perspe
ctives important for businesses aiming to comply with circular economy
 principles is discovered. The findings include potentials and barrier
s in several areas, like the access to the metaverse, connected costs,
 data, knowledge transfer, collaboration, innovation, product design, 
production planning, training of employees, and transportation. The re
sults can be used to promote the implementation of circular economy pr
inciples.
AU  - Kunert, Julia
AU  - Valk, Hendrik
AU  - Scheerer, Hannah
AU  - Hoppe, Christoph
C1  - Orlando, Florida, USA
C3  - Proceedings of the Winter Simulation Conference
DA  - 2025///
C2  - 2025
ID  - 10.5555/3712729.3712
PB  - IEEE Press
SN  - 9798331534202
SP  - 3034-3045
T3  - WSC '24
TI  - Potentials and Barriers of the Metaverse for Circular Economy
ER  - 
TY  - CONF
AB  - This paper explores the realm of telematic performance practice, inter
connecting geographically disparate locations and performers through t
elecommunication technologies. Specifically, we focus on networked mul
timedia mixing and advance the field within the framework of third-wav
e human-computer interaction, emphasizing embodied interaction. Along 
with a detailed introduction of our Novel Interface for Multimedial Ex
ploration, the NEXUS, we provide insights into our first use-case scen
ario, employing the NEXUS-NIME within a telematic performance context.
 Adapting and expanding on existing examples of dimension spaces, we i
ntroduce a novel Dimension Space for Phenomenologically Situated Inter
action, which accounts for situated embodiment. It is employed in a di
mension space analysis comparing the NEXUS with historical interfaces 
for networked musical and multimedial expression that incorporate mult
imodal interactions through tangible user interfaces. In doing so we d
emonstrate the NEXUS’s role as a transformative multi-user tool and bu
ndle of NIMEs, shifting sound engineering practices from one of transp
arency and social fidelity to one of hypermediacy, risk and respons-ab
ility. Drawing on concepts from feminist new materialism and posthuman
ism, the NEXUS opens new avenues for rendering-capable, for exploring 
complex interdependencies between human and non-human actors becoming-
with in telematic ecosystems.
AU  - Walter, Hannah
AU  - Larrieux, Eric
AU  - Torche, Robert
AU  - Spindler, Cedric
AU  - Müller, Patrick
C1  - Milan, Italy
C3  - Proceedings of the 19th International Audio Mostly Conference: Explora
tions in Sonic Cultures
DA  - 2024///
C2  - 2024
DO  - 10.1145/3678299.3678323
ID  - 10.1145/3678299.3678
KW  - Human-Computer Interaction
KW  - New Interfaces for Musical Expression
KW  - Telematic performance
KW  - digital augmentation
KW  - digital musical instrument
KW  - dimension space analysis
KW  - embedded systems
KW  - embodied interaction
KW  - extended reality
KW  - feminist new materialism.
KW  - mixed reality
KW  - networked multimedia mixing
KW  - posthumanism
KW  - responsive environments
KW  - sonic interaction design
KW  - tangible user interfaces
PB  - Association for Computing Machinery
SN  - 9798400709685
SP  - 245-259
T3  - AM '24
TI  - NEXUS: A Tangible Multi-User Sensor-Based Telematic Novel Mixing-Inter
face for Multimedial Exploration
UR  - https://doi.org/10.1145/3678299.3678323
ER  - 
TY  - JOUR
AB  - The development of novel computer interfaces has led to the possibilit
y of integrating inputs from multiple individuals into a single avatar
, fostering collaboration by combining skills and sharing the cognitiv
e load. However, the collaboration dynamic and its effectiveness may v
ary depending on the individuals involved. Particularly in scenarios w
here two individuals remotely control a robotic avatar without the pos
sibility of direct communication, understanding each other’s character
istics can result in enhanced performance. To achieve this, it is esse
ntial to ascertain if individuals can discern their partner’s characte
ristics within the merged embodiment. This paper investigates the accu
racy with which participants can distinguish between two different col
laborating partners (one attempting to lead and one attempting to foll
ow) when sharing control of a robot arm during a block pick-and-place 
task. The results suggested that participants who changed their roles 
according to the different roles of the two partners achieved the high
est discrimination rates. Furthermore, participants changed their move
ments through the trials, adapting their actions to their preferred ap
proach. This research provides insights into the factors determining i
ndividuals’ ability to understand partner characteristics during contr
ol of collaborative avatars.
AU  - Hashiura, Kenta
AU  - Hagiwara, Takayoshi
AU  - Barbareschi, Giulia
AU  - Wakisaka, Sohei
AU  - Minamizawa, Kouta
DA  - 2024/11//
PY  - 2024
DO  - 10.1145/3698237
ID  - 10.1145/3698237
IS  - 4
KW  - shared experience
KW  - cybernetic avatar
KW  - shared avatar
KW  - collaborative avatar
KW  - perceptual discrimination
KW  - Joint Action
SN  - 1544-3558
T2  - ACM Trans. Appl. Percept.
TI  - “Together with Who?” Recognizing Partners during Collaborative Avatar 
Manipulation
UR  - https://doi.org/10.1145/3698237
VL  - 21
ER  - 
TY  - JOUR
AB  - In Mixed Reality (MR), users can collaborate efficiently by creating p
ersonalized layouts that incorporate both personal and shared virtual 
objects. Unlike in the real world, personal objects in MR are only vis
ible to their owner. This makes them susceptible to occlusions from sh
ared objects of other users, who remain unaware of their existence. Th
us, achieving unobstructed layouts in collaborative MR settings requir
es knowledge of where others have placed their personal objects. In th
is paper, we assessed the effects of three visualizations, and a basel
ine without any visualization, on occlusions and user perceptions. Our
 study involved 16 dyads (N=32) who engaged in a series of collaborati
ve sorting tasks. Results indicate that the choice of visualization si
gnificantly impacts both occlusion and perception, emphasizing the nee
d for effective visualizations to enhance collaborative MR experiences
. We conclude with design recommendations for multi-user MR systems to
 better accommodate both personal and shared interfaces simultaneously
.
AU  - Khan, Talha
AU  - Lindlbauer, David
DA  - 2024/10//
PY  - 2024
DO  - 10.1145/3698126
ID  - 10.1145/3698126
IS  - ISS
KW  - Augmented Reality
KW  - Collaboration
KW  - Mixed Reality
KW  - Personal Interfaces
KW  - Visualization
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Don’t Block My Stuff: Fostering Personal Object Awareness in Multi-use
r Mixed Reality Environments
UR  - https://doi.org/10.1145/3698126
VL  - 8
ER  - 
TY  - CONF
AB  - This paper proposes a summarized analyses for volumetric video streami
ng use cases and its applicability for immersive extended reality appl
ications. It also closely evaluates and illustrates the usability of s
tandardized technologies for one of the use cases, i.e., real-time fit
ness training between remote participants.
AU  - Fasogbon, Peter
AU  - Bisht, Surarshan
AU  - Kernen, Jaakko
AU  - Budak, Ugurcan
AU  - Ilola, Lauri
AU  - Kondrad, Lukasz
C1  - Tokyo, Japan
C3  - Proceedings of the 2024 8th International Conference on Education and 
Multimedia Technology
DA  - 2024///
C2  - 2024
DO  - 10.1145/3678726.3678754
ID  - 10.1145/3678726.3678
KW  - Augmented Reality (AR)
KW  - Extended Reality (XR)
KW  - HMD
KW  - Metaverse
KW  - Virtual Reality (VR)
KW  - Volumetric Video
PB  - Association for Computing Machinery
SN  - 9798400717611
SP  - 1-8
T3  - ICEMT '24
TI  - Volumetric Video Use Cases for XR Immersive Streaming
UR  - https://doi.org/10.1145/3678726.3678754
ER  - 
TY  - CONF
AB  - Virtual Reality experiences and games present believable virtual envir
onments based on graphical quality, spatial audio, and interactivity. 
The interaction with in-game characters, controlled by computers (agen
ts) or humans (avatars), is an important part of VR experiences. Pre-c
aptured motion sequences increase the visual humanoid resemblance. How
ever, this still precludes realistic social interactions (eye contact,
 imitation of body language), particularly for agents. We aim to make 
social interaction more realistic via social touch. Social touch is no
n-verbal, conveys feelings and signals (coexistence, closure, intimacy
). In our research, we created an artificial hand to apply social touc
h in a repeatable and controlled fashion to investigate its effect on 
the perceived human-likeness of avatars and agents. Our results show t
hat social touch is effective to further blur the boundary between com
puter- and human-controlled virtual characters and contributes to expe
riences that closely resemble human-to-human interactions.
AU  - Hoppe, Matthias
AU  - Rossmy, Beat
AU  - Neumann, Daniel Peter
AU  - Streuber, Stephan
AU  - Schmidt, Albrecht
AU  - Machulla, Tonja-Katrin
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI Conference on Human Factors in Computing S
ystems
DA  - 2020///
C2  - 2020
DO  - 10.1145/3313831.3376719
ID  - 10.1145/3313831.3376
KW  - agency
KW  - human-likeness
KW  - social touch
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450367080
SP  - 1-11
T3  - CHI '20
TI  - A Human Touch: Social Touch Increases the Perceived Human-likeness of 
Agents in Virtual Reality
UR  - https://doi.org/10.1145/3313831.3376719
ER  - 
TY  - JOUR
AB  - Teleconferencing is poised to become one of the most frequent use case
s of immersive platforms, since it supports high levels of presence an
d embodiment in collaborative settings. On desktop and mobile platform
s, teleconferencing solutions are already among the most popular apps 
and accumulate significant usage time—not least due to the pandemic or
 as a desirable substitute for air travel or commuting.In this paper, 
we present ViGather, an immersive teleconferencing system that integra
tes users of all platform types into a joint experience via equal repr
esentation and a first-person experience. ViGather renders all partici
pants as embodied avatars in one shared scene to establish co-presence
 and elicit natural behavior during collocated conversations, includin
g nonverbal communication cues such as eye contact between participant
s as well as body language such as turning one's body to another perso
n or using hand gestures to emphasize parts of a conversation during t
he virtual hangout. Since each user embodies an avatar and experiences
 situated meetings from an egocentric perspective no matter the device
 they join from, ViGather alleviates potential concerns about self-per
ception and appearance while mitigating potential 'Zoom fatigue', as u
sers' self-views are not shown. For participants in Mixed Reality, our
 system leverages the rich sensing and reconstruction capabilities of 
today's headsets. For users of tablets, laptops, or PCs, ViGather reco
nstructs the user's pose from the device's front-facing camera, estima
tes eye contact with other participants, and relates these non-verbal 
cues to immediate avatar animations in the shared scene.Our evaluation
 compared participants' behavior and impressions while videoconferenci
ng in groups of four inside ViGather with those in Meta Horizon as a b
aseline for a social VR setting. Participants who participated on trad
itional screen devices (e.g., laptops and desktops) using ViGather rep
orted a significantly higher sense of physical, spatial, and self-pres
ence than when using Horizon, while all perceived similar levels of ac
tive social presence when using Virtual Reality headsets. Our follow-u
p study confirmed the importance of representing users on traditional 
screen devices as reconstructed avatars for perceiving self-presence.
AU  - Qiu, Huajian
AU  - Streli, Paul
AU  - Luong, Tiffany
AU  - Gebhardt, Christoph
AU  - Holz, Christian
DA  - 2023/9//
PY  - 2023
DO  - 10.1145/3604279
ID  - 10.1145/3604279
IS  - MHCI
KW  - avatars
KW  - co-presence
KW  - collaboration
KW  - cross-platform
KW  - embodied presence
KW  - immersive social interaction
KW  - mixed reality
KW  - social VR
KW  - teleconferencing
KW  - video conferencing
KW  - virtual reality
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - ViGather: Inclusive Virtual Conferencing with a Joint Experience Acros
s Traditional Screen Devices and Mixed Reality Headsets
UR  - https://doi.org/10.1145/3604279
VL  - 7
ER  - 
TY  - CONF
AB  - We present TactJam, an end-to-end suite for creating and sharing low f
idelity prototypes of on-body vibrotactile feedback. With TactJam, des
igners can create, record and share vibrotactile patterns online. This
 opens up new ways of collaboratively designing vibrotactile patterns 
both in collocated as well as in remote settings. We evaluate TactJam 
in a two-part distributed online workshop, exploring the design of on-
body tactons. Participants were able to successfully use TactJam to le
arn about tacton design. We present an overview of mappings between ta
ctons and their associated concepts before comparing the results of ta
ctons created using solely a GUI and tactons created through experimen
ting with placements directly on the body. Conducting both parts of th
e workshop separately highlighted the importance of designing directly
 with bodies: less implicit assumptions were made, and designs were gu
ided by personal experience. We reflect on these results and close on 
deliberations for the future development of TactJam.
AU  - Wittchen, Dennis
AU  - Spiel, Katta
AU  - Fruchard, Bruno
AU  - Degraen, Donald
AU  - Schneider, Oliver
AU  - Freitag, Georg
AU  - Strohmeier, Paul
C1  - Daejeon, Republic of Korea
C3  - Proceedings of the Sixteenth International Conference on Tangible, Emb
edded, and Embodied Interaction
DA  - 2022///
C2  - 2022
DO  - 10.1145/3490149.3501307
ID  - 10.1145/3490149.3501
KW  - collaborative sketching
KW  - embodied design
KW  - embodied interaction
KW  - on-body design
KW  - tactile feedback
KW  - tactile prototyping
KW  - tactons
KW  - vibrotactile feedback
PB  - Association for Computing Machinery
SN  - 9781450391474
T3  - TEI '22
TI  - TactJam: An End-to-End Prototyping Suite for Collaborative Design of O
n-Body Vibrotactile Feedback
UR  - https://doi.org/10.1145/3490149.3501307
ER  - 
TY  - CONF
AB  - Traditional spatial hypertext systems, predominantly limited to two-di
mensional (2D) interfaces, offer limited support for addressing long d
ebated inherent problems such as orientation difficulties and navigati
on in large information spaces. In this context, we present opportunit
ies from interdisciplinary fields such as immersive analytics (IA) and
 embodied cognition that may mitigate some of these challenges. Howeve
r, while some research has explored the extension of spatial hypertext
 to three dimensions, there is a lack of discussion on recent advances
 in virtual reality technologies and related fields, and their potenti
al impact on immersive spatial hypertext systems. This paper addresses
 this gap by exploring the integration of immersive technologies into 
spatial hypertext systems, proposing a novel approach to enhance user 
engagement and comprehension through three-dimensional (3D) environmen
ts and multisensory interaction.
AU  - Eidloth, Lisa
AU  - Atzenbeck, Claus
AU  - Pfeiffer, Thies
C1  - Poznan, Poland
C3  - Proceedings of the 7th Workshop on Human Factors in Hypertext
DA  - 2024///
C2  - 2024
DO  - 10.1145/3679058.3688632
ID  - 10.1145/3679058.3688
KW  - extended reality
KW  - hypertext
KW  - immersiveness
KW  - information exploration
KW  - knowledge
KW  - spatial hypertext
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9798400711206
T3  - HUMAN '24
TI  - Stepping into the Unknown: Immersive Spatial Hypertext
UR  - https://doi.org/10.1145/3679058.3688632
ER  - 
TY  - CONF
AB  - In Social Virtual Reality (SVR), mediated social communication blends 
with simulated virtual environments and bodies. However, little is kno
wn about how these social and physical (or embodied) affordances inter
sect in user experiences. We bridge this research gap by applying phen
omenological analysis to SVR user interviews to reveal embodiment in S
VR based on their lived experiences. We contribute empirical evidence 
to the concept of “collective embodiment,” described as a mutually mai
ntained feeling of embodiment that SVR provides beyond individual expe
riences and avatar-related sensations. This involves intertwined sense
s of agency, location, and appearance influenced by the presence and a
ctions of others in the virtual environment. We also observed SVR user
s’ difficulties controlling avatar visual representations and communic
ation or social functions. This research uncovers the multifaceted nat
ure of collective embodiment in SVR, offering insights into its social
 dynamics, design, and user experience implications.
AU  - Kukshinov, Eugene
AU  - Nacke, Lennart E.
C1  -  
C3  - Proceedings of the 2025 ACM International Conference on Interactive Me
dia Experiences
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706370.3727895
ID  - 10.1145/3706370.3727
KW  - Sense of Embodiment
KW  - Social VR
KW  - Avatars
KW  - Social Interaction
KW  - Presence
KW  - Phenomenological Analysis.
PB  - Association for Computing Machinery
SN  - 9798400713910
SP  - 187-199
T3  - IMX '25
TI  - Collective Embodiment, or the Social Nature of the Sense of Embodiment
 in Social VR
UR  - https://doi.org/10.1145/3706370.3727895
ER  - 
TY  - CONF
AB  - This paper presents a framework for developing Intelligent, Interactiv
e, and Immersive Storytelling systems for vocational training by impro
ving task performance. We present a systematic framework that can be u
sed to personalize training for a worker in a factory environment. We 
also present a system implementation that builds upon the vIIIS framew
ork and also describes the design decisions made throughout the system
. In this paper, we focus on improving a user’s episodic and working m
emory by employing picture sequence and object sorting tasks taken fro
m the NIH toolbox and presenting an intelligent Augmented Reality syst
em. A major advantage of using an intelligent and interactive system u
sing storytelling is that the training can be curated towards each spe
cific user, thereby enhancing the learning outcome based on individual
 needs.
AU  - Doolani, Sanika
AU  - Wessels, Callen
AU  - Makedon, Fillia
C1  - Corfu, Greece
C3  - Proceedings of the 14th PErvasive Technologies Related to Assistive En
vironments Conference
DA  - 2021///
C2  - 2021
DO  - 10.1145/3453892.3461631
ID  - 10.1145/3453892.3461
KW  - Augmented Reality
KW  - Immersive Storytelling
KW  - Reinforcement Learning
KW  - Vocational Training
PB  - Association for Computing Machinery
SN  - 9781450387927
SP  - 527-533
T3  - PETRA '21
TI  - vIIIS: A Vocational Intelligent Interactive Immersive Storytelling Fra
mework to Support Task Performance
UR  - https://doi.org/10.1145/3453892.3461631
ER  - 
TY  - CONF
AB  - Outdoor activities, such as traveling and sightseeing, become challeng
ing to realize when individuals are geographically distant. This paper
 introduces Syn-Leap, a symmetrical wearable telepresence system desig
ned to allow multiple users to explore outdoor settings while mutually
 sharing their environments. With Syn-Leap, users wear a 360° camera a
nd AR glasses, allowing them to share their environment through video 
streaming while simultaneously viewing the videos of other users while
 walking outdoors. To investigate the experiences and communication ge
nerated by this system, we conducted a field study in Kyoto, Japan, fo
cusing on tourism scenarios. The results revealed that participants co
uld achieve a sense of walking together by seamlessly switching betwee
n exploring their own environment and viewing the video feeds of other
 users, occasionally overlaying the AR content from other users onto t
heir own environment.
AU  - Yazaki, Takeru
AU  - Watanabe, Yuna
AU  - Kong, Lingrong
AU  - Inami, Masahiko
C1  - Vienna, Austria
C3  - Proceedings of the 22nd International Conference on Mobile and Ubiquit
ous Multimedia
DA  - 2023///
C2  - 2023
DO  - 10.1145/3626705.3627772
ID  - 10.1145/3626705.3627
KW  - Augmented Reality
KW  - Remote Communication
KW  - Research through Design
KW  - Telepresence
PB  - Association for Computing Machinery
SN  - 9798400709210
SP  - 353-365
T3  - MUM '23
TI  - Design and Field Study of Syn-Leap: A Symmetric Telepresence System fo
r Immersion Switching and Walking Across Multiple Locations
UR  - https://doi.org/10.1145/3626705.3627772
ER  - 
TY  - CONF
AB  - Immersive media is becoming increasingly common in day-to-day scenario
s: from extended reality systems to multimodal interfaces. Such ubiqui
ty opens an opportunity for building more inclusive environments for u
sers with disabilities (permanent, temporary, or situational) by eithe
r introducing immersive and multimodal elements into existing applicat
ions, or designing and creating immersive applications with inclusivit
y in mind. Thus the aim of this workshop is to create a discussion pla
tform on intersections between the fields of immersive media, accessib
ility, and human-computer interaction, outline the key current and fut
ure problems of immersive inclusive design, and define a set of method
ologies for design and evaluation of immersive systems from inclusivit
y perspective.
AU  - Ryskeldiev, Bektur
AU  - Ochiai, Yoichi
AU  - Kusano, Koki
AU  - Li, Jie
AU  - Saraiji, Yamen
AU  - Kunze, Kai
AU  - Billinghurst, Mark
AU  - Nanayakkara, Suranga
AU  - Sugano, Yusuke
AU  - Honda, Tatsuya
C1  - Yokohama, Japan
C3  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2021///
C2  - 2021
DO  - 10.1145/3411763.3441322
ID  - 10.1145/3411763.3441
KW  - accessibility
KW  - artificial intelligence
KW  - assistive technology
KW  - augmented human
KW  - augmented reality
KW  - collaborative technology
KW  - extended reality
KW  - human-computer interaction
KW  - inclusive design
KW  - internet of things
KW  - mixed reality
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450380959
T3  - CHI EA '21
TI  - Immersive Inclusivity at CHI: Design and Creation of Inclusive User In
teractions Through Immersive Media
UR  - https://doi.org/10.1145/3411763.3441322
ER  - 
TY  - CONF
AB  - Social Virtual Reality (VR) presents a promising avenue for older adul
ts to connect with others and engage in collaborative activities remot
ely. However, many social VR experiences focus on individual tasks, re
ducing opportunities for meaningful social interaction. To investigate
 the potential of VR to enhance engagement with other participants, th
is paper explores two modes of coupling: (i) loosely coupled, where pa
rticipants focus on their individual tasks within a collaborative sett
ing, and (ii) tightly coupled, where participants need to rely on each
 other’s assistance to complete their tasks. We conducted a user study
 with 20 older adults to evaluate how these modes affect task performa
nce and engagement. Results show that the tightly coupled mode, focuse
d on collaboration, increases engagement, while the loosely coupled mo
de, centers on individual tasks, improves performance in time and atte
mpts. We provide guidelines for collaborative VR applications to enhan
ce social engagement and interaction among older adults.
AU  - Vo, Thuan T
AU  - Das, Satabdi
AU  - Noroozi, Shamim
AU  - Dang, Lakshay
AU  - Sin, Jaisie
AU  - Boger, Jennifer N
AU  - Jakobi, Jennifer
AU  - Hasan, Khalad
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713345
ID  - 10.1145/3706598.3713
KW  - Collaborative Game
KW  - Loosely Coupled Collaboration
KW  - Tightly Coupled Collaboration
KW  - Healthy Aging
KW  - Older Adults
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Exploring the Effects of Social VR Coupling Modes on Engagement and Ta
sk Performance for Older Adults
UR  - https://doi.org/10.1145/3706598.3713345
ER  - 
TY  - CONF
AB  - Complex actuators in a small form factor are essential for dynamic int
erfaces. In this paper, we propose ConeAct, a cone-shaped actuator tha
t can extend, contract, and bend in multiple directions to support ric
h expression in dynamic materials. A key benefit of our actuator is th
at it is self-contained and portable as the whole system. We designed 
our actuator’s structure to be multistable to hold its shape passively
, while we control its transition between states using active material
s, i.e., shape memory alloys. We present the design space by showcasin
g our actuator module as part of self-rolling robots, reconfigurable d
eployable structures, volumetric shape-changing objects and tactile di
splays. To assist users in designing such structures, we present an in
teractive editor including simulation to design such interactive capab
ilities.
AU  - Lin, Yuyu
AU  - Gonzalez, Jesse T
AU  - Cui, Zhitong
AU  - Banka, Yash Rajeev
AU  - Ion, Alexandra
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI Conference on Human Factors in Computing S
ystems
DA  - 2024///
C2  - 2024
DO  - 10.1145/3613904.3642949
ID  - 10.1145/3613904.3642
KW  - Dynamic materials
KW  - Fabrication
KW  - Programmable Matter
PB  - Association for Computing Machinery
SN  - 9798400703300
T3  - CHI '24
TI  - ConeAct: A Multistable Actuator for Dynamic Materials
UR  - https://doi.org/10.1145/3613904.3642949
ER  - 
TY  - CONF
AB  - Collaborative immersive virtual environments allow the behavior of one
 user to be observed by other users. In particular, behavior of users 
in such an environment is represented by each user possessing a self-a
vatar, a digital representation of themself. In this study we examined
 dyadic interactions in a collaborative immersive virtual environment 
when both users were present in the same physical space. This collocat
ion in physical space allows for physical interaction between users as
 well as virtual interaction. In the context of a common physical gest
ure, high fiving, we examined the question of whether the form of the 
self-avatar was important, and whether collocation in the physical wor
ld provided benefits or not. We find that the form of the avatar is im
portant but that physical collocation is not. These results reinforce 
the growing body of evidence that indicates that having a full-body av
atar in a virtual environment provides benefits, and these results are
 significant because they demonstrate this in the context of a dyadic 
interaction.
AU  - Young, Mary K.
AU  - Rieser, John J.
AU  - Bodenheimer, Bobby
C1  - Tübingen, Germany
C3  - Proceedings of the ACM SIGGRAPH Symposium on Applied Perception
DA  - 2015///
C2  - 2015
DO  - 10.1145/2804408.2804410
ID  - 10.1145/2804408.2804
KW  - head-mounted displays
KW  - virtual avatar
KW  - virtual environments
KW  - virtual reality (VR)
PB  - Association for Computing Machinery
SN  - 9781450338127
SP  - 119-126
T3  - SAP '15
TI  - Dyadic interactions with avatars in immersive virtual environments: hi
gh fiving
UR  - https://doi.org/10.1145/2804408.2804410
ER  - 
TY  - CONF
AB  - As social-mediated interaction is becoming increasingly important and 
multi-modal, even expanding into virtual reality and physical telepres
ence with robotic avatars, new challenges emerge. For instance, video 
calls have become the norm and it is increasingly common that people e
xperience a form of asymmetry, such as not being heard or seen by thei
r communication partners online due to connection issues. Previous res
earch has not yet extensively explored the effect on social interactio
n. In this study, 61 Dyads, i.e. 122 adults, played a quiz-like game u
sing a video-conferencing platform and evaluated the quality of their 
social interaction by measuring five sub-scales of social presence. Th
e Dyads had either symmetrical access to social cues (both only audio,
 or both audio and video) or asymmetrical access (one partner receivin
g only audio, the other audio and video). Our results showed that in t
he case of asymmetrical access, the party receiving more modalities, i
.e. audio and video from the other, felt significantly less connected 
than their partner. We discuss these results in relation to the Media 
Richness Theory (MRT) and the Hyperpersonal Model: in asymmetry, more 
modalities or cues will not necessarily increase feeling socially conn
ected, in opposition to what was predicted by MRT. We hypothesize that
 participants sending fewer cues compensate by increasing the richness
 of their expressions and that the interaction shifts towards an equiv
alent richness for both participants.
AU  - Sallaberry, Camille
AU  - Englebienne, Gwenn
AU  - Van Erp, Jan
AU  - Evers, Vanessa
C1  - Paris, France
C3  - Proceedings of the 25th International Conference on Multimodal Interac
tion
DA  - 2023///
C2  - 2023
DO  - 10.1145/3577190.3614168
ID  - 10.1145/3577190.3614
KW  - "Mediated Communication
KW  - Asymmetry
KW  - Social Computing
KW  - Social Interaction
KW  - Social Presence
KW  - Social Signals"
KW  - Video-Conference
PB  - Association for Computing Machinery
SN  - 9798400700552
SP  - 465-469
T3  - ICMI '23
TI  - Out of Sight,... How Asymmetry in Video-Conference Affects Social Inte
raction
UR  - https://doi.org/10.1145/3577190.3614168
ER  - 
TY  - CONF
AB  - Generating referring expressions is a task that has received a great d
eal of attention in the natural-language generation community, with an
 increasing amount of recent effort targeted at the generation of mult
imodal referring expressions. However, most implemented systems tend t
o assume very little shared knowledge between the speaker and the hear
er, and therefore must generate fully-elaborated linguistic references
. Some systems do include a representation of the physical context or 
the dialogue context; however, other sources of contextual information
 are not normally used. Also, the generated references normally consis
t only of language and, possibly, deictic pointing gestures.When refer
ring to objects in the context of a task-based interaction involving j
ointly manipulating objects, a much richer notion of context is availa
ble, which permits a wider range of referring options. In particular, 
when conversational partners cooperate on a mutual task in a shared en
vironment, objects can be made accessible simply by manipulating them 
as part of the task. We demonstrate that such expressions are common i
n a corpus of human-human dialogues based on constructing virtual obje
cts, and then describe how this type of reference can be incorporated 
into the output of a humanoid robot that engages in similar joint cons
truction dialogues with a human partner.
AU  - Foster, Mary Ellen
AU  - Bard, Ellen Gurman
AU  - Guhe, Markus
AU  - Hill, Robin L.
AU  - Oberlander, Jon
AU  - Knoll, Alois
C1  - Amsterdam, The Netherlands
C3  - Proceedings of the 3rd ACM/IEEE International Conference on Human Robo
t Interaction
DA  - 2008///
C2  - 2008
DO  - 10.1145/1349822.1349861
ID  - 10.1145/1349822.1349
KW  - multimodal dialogue
KW  - referring expressions
PB  - Association for Computing Machinery
SN  - 9781605580173
SP  - 295-302
T3  - HRI '08
TI  - The roles of haptic-ostensive referring expressions in cooperative, ta
sk-based human-robot dialogue
UR  - https://doi.org/10.1145/1349822.1349861
ER  - 
TY  - CONF
AB  - Virtual Reality (VR) headsets can open opportunities for users to acco
mplish complex tasks on large virtual displays using compact and porta
ble devices. However, interacting with such large virtual displays usi
ng existing interaction techniques might cause fatigue, especially for
 precise manipulation tasks, due to the lack of physical surfaces. To 
deal with this issue, we explored the design of VXSlate, an interactio
n technique that uses a large virtual display as an expansion of a tab
let. We combined a user’s head movements as tracked by the VR headset,
 and touch interaction on the tablet. Using VXSlate, a user head movem
ents positions a virtual representation of the tablet together with th
e user’s hand, on the large virtual display. This allows the user to p
erform fine-tuned multi-touch content manipulations. In a user study w
ith seventeen participants, we investigated the effects of VXSlate on 
users in problem-solving tasks involving content manipulations at diff
erent levels of difficulty, such as translation, rotation, scaling, an
d sketching. As a baseline for comparison, off-the-shelf touch-control
ler interactions were used. Overall, VXSlate allowed participants to c
omplete the task with completion times and accuracy that are comparabl
e to touch-controller interactions. After an interval of use, VXSlate 
significantly reduced users’ time to perform scaling tasks in content 
manipulations, as well as reducing perceived effort. We reflected on t
he advantages and disadvantages of VXSlate in content manipulation on 
large virtual displays and explored further applications within the VX
Slate design space.
AU  - Le, Khanh-Duy
AU  - Tran, Tanh Quang
AU  - Chlasta, Karol
AU  - Krejtz, Krzysztof
AU  - Fjeld, Morten
AU  - Kunz, Andreas
C1  - Virtual Event, USA
C3  - Proceedings of the 2021 ACM Designing Interactive Systems Conference
DA  - 2021///
C2  - 2021
DO  - 10.1145/3461778.3462076
ID  - 10.1145/3461778.3462
KW  - VR
KW  - head movements
KW  - mobile device
KW  - touch interaction
KW  - virtual large displays
PB  - Association for Computing Machinery
SN  - 9781450384766
SP  - 283-297
T3  - DIS '21
TI  - VXSlate: Exploring Combination of Head Movements and Mobile Touch for 
Large Virtual Display Interaction
UR  - https://doi.org/10.1145/3461778.3462076
ER  - 
TY  - CONF
AB  - Extended Reality (XR) technologies are still lacking appropriate inter
action methods that enable users to seamlessly switch between differen
t XR devices and degrees of virtuality. Addressing this gap, we presen
t Move’n’Hold Pro – a set of consistent object manipulation techniques
 that are available for Mixed Reality handheld displays (MR-HHDs) as w
ell as for Mixed and Virtual Reality head-mounted displays (MR-/VR-HMD
s). Move’n’Hold Pro extends MR- and VR-HMDs with a tablet controller t
hat implements object manipulation methods proposed by latest research
 on MR-HHD-UIs. Thereby, users can combine tablet movement and periphe
ral touch to translate or rotate virtual objects through direct or con
tinuous manipulations. In our evaluation, comparing Move’n’Hold Pro to
 a State of the Art system, Move’n’Hold Pro was rated as the preferred
 system and to be easier to relearn. Furthermore, Move’n’Hold Pro redu
ced cognitive efforts, improved usability, and provided more cross-dev
ice benefits.
AU  - Memmesheimer, Vera Marie
AU  - Klingshirn, Kai Jonas
AU  - Herold, Cindy
AU  - Ravani, Bahram
AU  - Ebert, Achim
C1  - Paris, France
C3  - Proceedings of the European Conference on Cognitive Ergonomics 2024
DA  - 2024///
C2  - 2024
DO  - 10.1145/3673805.3673814
ID  - 10.1145/3673805.3673
KW  - Augmented Reality
KW  - Extended Reality
KW  - Handheld displays
KW  - Head-mounted Displays
KW  - Interaction Technique
KW  - Mixed Reality
KW  - Spatial Interaction
KW  - User Interface
KW  - Virtual Reality
PB  - Association for Computing Machinery
SN  - 9798400718243
T3  - ECCE '24
TI  - Move'n'Hold Pro: Consistent Spatial Interaction Techniques for Object 
Manipulation with Handheld and Head-mounted Displays in Extended Reali
ty
UR  - https://doi.org/10.1145/3673805.3673814
ER  - 
TY  - CONF
AB  - Due to the lack of a universally accepted definition for the term “vir
tual twin”, there are varying degrees of similarity between physical p
rototypes and their virtual counterparts across different research pap
ers. This variability complicates the comparison of results from these
 papers. To bridge this gap, we introduce the Scale of Virtual Twin’s 
Similarity (SVS), a questionnaire intended to quantify the similarity 
between a virtual twin and its physical counterpart in simple environm
ents in terms of visual fidelity, physical fidelity, environmental fid
elity, and functional fidelity. This paper describes the development p
rocess of the SVS questionnaire items and provides an initial evaluati
on through two between-subjects user studies to validate the items und
er the categories of visual and functional fidelity. Additionally, we 
discuss the way to apply it in research and development settings.
AU  - Zhang, Xuesong
AU  - Simeone, Adalberto L.
C1  - Trier, Germany
C3  - Proceedings of the 2024 ACM Symposium on Spatial User Interaction
DA  - 2024///
C2  - 2024
DO  - 10.1145/3677386.3682100
ID  - 10.1145/3677386.3682
KW  - Evaluation
KW  - Fidelity
KW  - Questionnaire
KW  - Similarity
KW  - Virtual twin
PB  - Association for Computing Machinery
SN  - 9798400710889
T3  - SUI '24
TI  - Construction of SVS: Scale of Virtual Twin's Similarity to Physical Co
unterpart in Simple Environments
UR  - https://doi.org/10.1145/3677386.3682100
ER  - 
TY  - CONF
AB  - Television has long since been a uni-directional medium. However, when
 TV is used for educational purposes, like in edutainment shows, inter
activity could enhance the learning benefit for the viewer. In recent 
years, AR has been increasingly explored in HCI research to enable int
eraction among viewers as well as viewers and hosts. Yet, how to imple
ment this collaborative AR (CoAR) experience remains an open research 
question. This paper explores four approaches to asynchronous collabor
ation based on the Cognitive Apprenticeship Model: scaffolding, coachi
ng, modeling, and collaborating. We developed a pilot show for a ficti
onal edutainment series and evaluated the concept with two TV experts.
 In a wizard-of-oz study, we test our AR prototype with eight users an
d evaluate the perception of the four collaboration styles. The AR-enh
anced edutainment concept was well-received by the participants, and t
he coaching collaboration style was perceived as favorable and could p
ossibly be combined with the modeling style.
AU  - Bouquet, Elizabeth
AU  - Von Der Au, Simon
AU  - Schneegass, Christina
AU  - Alt, Florian
C1  - Stockholm, Sweden
C3  - Proceedings of the 2024 ACM International Conference on Interactive Me
dia Experiences
DA  - 2024///
C2  - 2024
DO  - 10.1145/3639701.3656320
ID  - 10.1145/3639701.3656
KW  - AR
KW  - collaboration
KW  - edutainment
KW  - interactive television
KW  - mobile
PB  - Association for Computing Machinery
SN  - 9798400705038
SP  - 231-245
T3  - IMX '24
TI  - CoAR-TV: Design and Evaluation of Asynchronous Collaboration in AR-Sup
ported TV Experiences
UR  - https://doi.org/10.1145/3639701.3656320
ER  - 
TY  - CONF
AB  - The author discusses telematic wearable music, recounting the design a
nd evolution of improvised techniques and approaches in a remotely tau
ght course offered to undergraduates. This new contribution to interac
tive interfaces for remote ensembles is musically motivated and inclus
ive for non-specialists who apply musical instincts they discover thro
ugh participation. Students are introduced to wearable ”Internet of Th
ings” (IoT) computing, synthesis, and sound design, with the goal of d
eveloping rich, movement responsive, individually and/or collectively 
playable wearable instruments. The course facilitates practice-situate
d investigation of accessible, agile, and inexpensive modes of distrib
uted creativity in musical interaction through experiential inquiry an
d tinkering. Telematic wearable music aspires to enact shared, situate
d spaces and less ocularcentric modes of learning through embodied son
ic telepresence, emphasizing and enhancing embodied participation in s
ynchronous remote learning.
AU  - Thorn, Seth
C1  - virtual/Trento, Italy
C3  - Proceedings of the 16th International Audio Mostly Conference
DA  - 2021///
C2  - 2021
DO  - 10.1145/3478384.3478386
ID  - 10.1145/3478384.3478
KW  - Internet of Things
KW  - distance learning
KW  - distributed creativity
KW  - music
KW  - remote ensembles
KW  - telematic music
KW  - wearables
PB  - Association for Computing Machinery
SN  - 9781450385695
SP  - 188-195
T3  - AM '21
TI  - Telematic Wearable Music: Remote Ensembles and Inclusive Embodied Educ
ation
UR  - https://doi.org/10.1145/3478384.3478386
ER  - 
TY  - JOUR
AB  - Whiteboard collaboration in virtual reality (VR) is an important task 
in collaborative virtual environments. The current research mainly rel
ies on the use of controllers or dedicated pens but additional devices
 will cause inconvenience to users. Bare-hand writing offers rich coll
aborative semantics through natural gestures but remains underexplored
. This paper addresses challenges and solutions for bare-hand whiteboa
rd collaboration. We analyze the input process and identify key challe
nges in determining pen-drop, writing, and pen-lift intentions while m
aintaining user control over their avatar. Our approach addresses two 
VR scenarios: one without and one with physical planes. The method for
 the first case is called Air-writing, which dynamically adjusts the d
istance between the avatar's torso and the virtual whiteboard during t
he processes of pen-drop and pen-lift to ensure a consistent writing e
xperience in VR. The method for the second case is called Physical-wri
ting, which allows users to write smoothly with passive haptic feedbac
k and physical constraints provided by the real surface by remapping t
he whiteboard in VR with a plane in reality. A comprehensive user stud
y is conducted to evaluate communication efficiency, input accuracy, c
ollaboration efficiency, and user experience of the two methods. The e
xperimental results indicate that bare-hand interaction improves commu
nication efficiency by 8% over controllers and performs similarly to r
eal-world whiteboard collaboration. The Physical-writing method also d
emonstrates higher accuracy and user satisfaction compared to the Air-
writing method.
AU  - Liu, Guangtian
AU  - Su, Haonan
AU  - Wang, Jingyu
AU  - Qi, Qi
AU  - Sun, Haifeng
AU  - Zhuang, Zirui
AU  - Ren, Pengfei
AU  - Liao, Jianxin
DA  - 2025/5//
PY  - 2025
DO  - 10.1145/3711092
ID  - 10.1145/3711092
IS  - 2
KW  - bare-hand whiteboard collaboration
KW  - virtual reality
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Towards Bare-Hand Interaction for Whiteboard Collaboration in Virtual 
Reality
UR  - https://doi.org/10.1145/3711092
VL  - 9
ER  - 
TY  - CONF
AB  - Robot-mediated telepresence promises to facilitate effective social in
teraction between remote teleoperators and on-site users. However, dis
parities between the robot’s form and the teleoperator’s representatio
n cause perceptual conflict in on-site users, degrading interaction qu
ality. We introduce AvatARoid, a novel design that bridges this embodi
ment gap by superimposing the teleoperator’s motion-mapped AR avatar o
verlay on a humanoid. We evaluated our design in a mixed-method study 
(n=48) using an immersive simulation where participants interacted wit
h a confederate teleoperator, presented in either (a) a humanoid robot
, (b) a humanoid robot with video, or (c) AvatARoid. Results suggest A
vatARoid significantly improved teleoperator embodiment for on-site us
ers, particularly enhancing co-location, and control perceptions, and 
providing richer non-verbal gestures. In contrast, video and baseline 
conditions often resulted in a pronounced disconnect between the teleo
perator and the robot for on-site users. Our study offers new insights
 into designing novel teleoperator representations to promote social i
nteraction in robot-mediated telepresence.
AU  - Ghimire, Amit
AU  - Hou, Anova
AU  - Kim, Ig-Jae
AU  - Yoon, Dongwook
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713812
ID  - 10.1145/3706598.3713
KW  - AvatARoid
KW  - telepresence
KW  - robot
KW  - humanoid
KW  - embodiment
KW  - avatar
KW  - AR overlay
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - AvatARoid: A Motion-Mapped AR Overlay to Bridge the Embodiment Gap Bet
ween Robots and Teleoperators in Robot-Mediated Telepresence
UR  - https://doi.org/10.1145/3706598.3713812
ER  - 
TY  - JOUR
AB  - Many instructors in computing and HCI disciplines use hands-on activit
ies for teaching and training new skills. Beyond simply teaching hands
-on skills like sketching and programming, instructors also use these 
activities so students can acquire tacit skills. Yet, current video-co
nferencing technologies may not effectively support hands-on activitie
s in online teaching contexts. To develop an understanding of the inad
equacies of current video-conferencing technologies for hands-on activ
ities, we conducted 15 interviews with university-level instructors wh
o had quickly pivoted their use of hands-on activities to an online co
ntext during the early part of the COVID-19 pandemic. Based on our ana
lysis, we uncovered four pedagogical goals that instructors have when 
using hands-on activities online and how instructors were unable to ad
equately address them due to the technological limitations of current 
video-conferencing tools. Our work provides empirical data about the c
hallenges that many instructors experienced, and in so doing, the peda
gogical goals we identify provide new requirements for video-conferenc
ing systems to better support hands-on activities.
AU  - Labrie, Audrey
AU  - Mok, Terrance
AU  - Tang, Anthony
AU  - Lui, Michelle
AU  - Oehlberg, Lora
AU  - Poretski, Lev
DA  - 2022/1//
PY  - 2022
DO  - 10.1145/3492829
ID  - 10.1145/3492829
IS  - GROUP
KW  - hands-on activities
KW  - online teaching
KW  - remote instruction
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Toward Video-Conferencing Tools for Hands-On Activities in Online Teac
hing
UR  - https://doi.org/10.1145/3492829
VL  - 6
ER  - 
TY  - JOUR
AB  - In recent years, the making phenomenon has shown great potential in pe
rsonal design and fabrication capabilities using modern fabrication to
ols (e.g., 3D printers, laser cutters, CNC machines), personal electro
nics (e.g., Arduino, Raspberry Pi, sensors), and related crafting tech
niques. With this trend of making, people have also engaged in develop
ing a wide variety of assistive devices (e.g., prostheses, orthotics),
 adaptations (e.g., cane-hanger/cup-holder for wheelchairs), and suppo
rt systems (e.g., tactile braille maps). While there are some successf
ul projects, substantive gaps remain between current traction and over
all potential in the field of making and accessibility. To better unde
rstand the relationship between people with disabilities and making an
d identify the types of ecosystems involved in these overlapping areas
 of research, we conducted a systematic literature review on design-re
lated ACM conferences between January 2010 and December 2023. Our anal
ysis highlights the concentration of research across diverse communiti
es, adaptations for accessible making, and the utilization of maker to
ols for the development of assistive devices. We also highlight trendi
ng design, development, and evaluation methodologies adopted to suppor
t collaboration between stakeholders with mixed abilities. Based on th
e findings of this systematic literature review, we critically reflect
 on the gaps and provide recommendations for future researchers and pr
actitioners in this growing field.
AU  - Sarwar, Saquib
AU  - Wilson, David
DA  - 2025/5//
PY  - 2025
DO  - 10.1145/3726530
ID  - 10.1145/3726530
IS  - 2
KW  - Personal Fabrication
KW  - Accessibility
KW  - Assistive technology
KW  - Making
SN  - 1936-7228
T2  - ACM Trans. Access. Comput.
TI  - Making and Accessibility: A Systematic Literature Review on the Multil
ayered Dimensions of Accessible Making
UR  - https://doi.org/10.1145/3726530
VL  - 18
ER  - 
TY  - CONF
AB  - In this paper, we introduce Physica, a tangible physics simulation sys
tem and approach based on tabletop mobile robots. In Physica, each tab
letop robot can physically represent distinct simulated objects that a
re controlled through an underlying physics simulation, such as gravit
ational force, molecular movement, and spring force. It aims to bring 
the benefits of tangible and haptic interaction into explorable physic
s learning, which was traditionally only available on screen-based int
erfaces. The system utilizes off-the-shelf mobile robots (Sony Toio) a
nd an open-source physics simulation tool (Teilchen). Built on top of 
them, we implement the interaction software pipeline that consists of 
1) an event detector to reflect tangible interaction by users, and 2) 
target speed control to minimize the gap between the robot motion and 
simulated moving objects. To present the potential for physics educati
on, we demonstrate various application scenarios that illustrate diffe
rent forms of learning using Physica. In our user study, we investigat
e the effect and the potential of our approach through a perception st
udy and interviews with physics educators.
AU  - Li, Jiatong
AU  - Suzuki, Ryo
AU  - Nakagaki, Ken
C1  - Pittsburgh, PA, USA
C3  - Proceedings of the 2023 ACM Designing Interactive Systems Conference
DA  - 2023///
C2  - 2023
DO  - 10.1145/3563657.3596037
ID  - 10.1145/3563657.3596
KW  - Actuated Tangible UIs
KW  - Physics Simulation
KW  - Swarm UIs
PB  - Association for Computing Machinery
SN  - 9781450398930
SP  - 1485-1499
T3  - DIS '23
TI  - Physica: Interactive Tangible Physics Simulation based on Tabletop Mob
ile Robots Towards Explorable Physics Education
UR  - https://doi.org/10.1145/3563657.3596037
ER  - 
TY  - CONF
AB  - Cross-reality systems empower users to transition along the reality-vi
rtuality continuum or collaborate with others experiencing different m
anifestations of it. However, prototyping these systems is challenging
, as it requires sophisticated technical skills, time, and often expen
sive hardware. We present VRception, a concept and toolkit for quick a
nd easy prototyping of cross-reality systems. By simulating all levels
 of the reality-virtuality continuum entirely in Virtual Reality, our 
concept overcomes the asynchronicity of realities, eliminating technic
al obstacles. Our VRception Toolkit leverages this concept to allow ra
pid prototyping of cross-reality systems and easy remixing of elements
 from all continuum levels. We replicated six cross-reality papers usi
ng our toolkit and presented them to their authors. Interviews with th
em revealed that our toolkit sufficiently replicates their core functi
onalities and allows quick iterations. Additionally, remote participan
ts used our toolkit in pairs to collaboratively implement prototypes i
n about eight minutes that they would have otherwise expected to take 
days.
AU  - Gruenefeld, Uwe
AU  - Auda, Jonas
AU  - Mathis, Florian
AU  - Schneegass, Stefan
AU  - Khamis, Mohamed
AU  - Gugenheimer, Jan
AU  - Mayer, Sven
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI Conference on Human Factors in Computing S
ystems
DA  - 2022///
C2  - 2022
DO  - 10.1145/3491102.3501821
ID  - 10.1145/3491102.3501
KW  - Augmented Reality
KW  - Cross-Reality Systems
KW  - Prototyping
KW  - Transitional Interfaces
KW  - Virtual Reality
PB  - Association for Computing Machinery
SN  - 9781450391573
T3  - CHI '22
TI  - VRception: Rapid Prototyping of Cross-Reality Systems in Virtual Reali
ty
UR  - https://doi.org/10.1145/3491102.3501821
ER  - 
TY  - CONF
AB  - This paper presents a comprehensive Systematization of Knowledge on ta
ngible privacy and security interfaces (TaPSI). Tangible interfaces pr
ovide physical forms for digital interactions. They can offer signific
ant benefits for privacy and security applications by making complex a
nd abstract security concepts more intuitive, comprehensible, and enga
ging. Through a literature survey, we collected and analyzed 80 public
ations. We identified terminology used in these publications and addre
ssed usable privacy and security domains, contributions, applied metho
ds, implementation details, and opportunities or challenges inherent t
o TaPSI. Based on our findings, we define TaPSI and propose the TaPSI 
Research Framework, which guides future research by offering insights 
into when and how to conduct research on privacy and security involvin
g TaPSI as well as a design space of TaPSI.
AU  - Delgado Rodriguez, Sarah
AU  - Windl, Maximiliane
AU  - Alt, Florian
AU  - Marky, Karola
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713968
ID  - 10.1145/3706598.3713
KW  - tangible privacy
KW  - tangible security
KW  - tangible interface
KW  - TaPSI
KW  - framework
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - The TaPSI Research Framework - A Systematization of Knowledge on Tangi
ble Privacy and Security Interfaces
UR  - https://doi.org/10.1145/3706598.3713968
ER  - 
TY  - CONF
AB  - This paper reports that the time-domain accuracy of bare-hand interact
ions in HMD-based Augmented Reality can be improved by using finger co
ntact: touching a finger with another or tapping one's own hand. The a
ctivation of input can be precisely defined by the moment of finger co
ntact, allowing the user to perform the input precisely at the desired
 moment. Finger contact is better suited to the user's mental model, a
nd natural tactile feedback from the fingertip also benefits the user 
with the self-perception of the input. The experimental results reveal
ed that using finger contact is the preferred method of input that inc
reases the time-domain accuracy and enables the user to be aware of th
e moment the input is activated.
AU  - Oh, Seo Young
AU  - Yoon, Boram
AU  - Kim, Hyung-il
AU  - Woo, Woontack
C1  - Honolulu, HI, USA
C3  - Extended Abstracts of the 2020 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2020///
C2  - 2020
DO  - 10.1145/3334480.3383098
ID  - 10.1145/3334480.3383
KW  - 3d gesture interaction
KW  - augmented reality
KW  - finger contact
KW  - passive haptic feedback
KW  - time-domain input accuracy
PB  - Association for Computing Machinery
SN  - 9781450368193
SP  - 1-8
T3  - CHI EA '20
TI  - Finger Contact in Gesture Interaction Improves Time-domain Input Accur
acy in HMD-based Augmented Reality
UR  - https://doi.org/10.1145/3334480.3383098
ER  - 
TY  - BOOK
CY  - Trier, Germany
DA  - 2024///
PY  - 2024
ID  - 10.1145/3641825
PB  - Association for Computing Machinery
SN  - 9798400705359
TI  - VRST '24: Proceedings of the 30th ACM Symposium on Virtual Reality Sof
tware and Technology
ER  - 
TY  - JOUR
AB  - The focus of this article is on the adoption of immersive and haptic s
imulators for training of medical residents in a surgical process call
ed Less Invasive Stabilization System (LISS) plating surgery. LISS sur
gery is an orthopedic surgical procedure to treat fractures of the fem
ur bone. Development of such simulators is a complex task which involv
es multiple systems, technologies, and human experts. Emerging Next Ge
neration Internet technologies were used to develop the standalone on-
line haptic-based simulator accessible to the students 24/7. A standal
one immersive surgical simulator was also developed using HTC Vive. Ex
pert surgeons played an important role in developing the simulator sys
tem; use cases of the target surgical processes were built using a mod
eling language called the engineering Enterprise Modeling Language (eE
ML). A detailed study presenting the comparison between the haptic-bas
ed simulator and the immersive simulator has been also presented. The 
outcomes of this study underscore the potential of using such simulato
rs in surgical training.
AU  - Cecil, J.
AU  - Gupta, Avinash
AU  - Pirela-Cruz, M.
AU  - Ramanathan, Parmesh
DA  - 2018/8//
PY  - 2018
DO  - 10.1145/3232678
ID  - 10.1145/3232678
IS  - 3
KW  - orthopedic surgery
KW  - medical simulation
KW  - immersive simulator
KW  - Virtual reality
KW  - Next Generation Internet technologies
SN  - 1551-6857
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
TI  - A Network-Based Virtual Reality Simulation Training Approach for Ortho
pedic Surgery
UR  - https://doi.org/10.1145/3232678
VL  - 14
ER  - 
TY  - CONF
AB  - As physical distances between people have increased due to the pandemi
c, some of the most popular and widespread ways to ‘connect’ people re
motely, namely audio/video calling and texting, are able to satisfy th
e auditory and visual sensories but fall short on a very crucial front
- being able to communicate the intimate feeling of touch. In this pap
er we looked at some of the explorations done in the field of touch an
d haptics. We propose an affective interaction method called ”Touch-ti
ng” that shares the feeling of touch remotely. To achieve this, we des
igned and prototyped a device which replicates the feeling of a finger
 sliding across the skin.
AU  - V M, Lokesh Kumar
AU  - Shandilya, Jribh
AU  - Gahlot, Arshiya
C1  - Virtual Event, India
C3  - Proceedings of the 12th Indian Conference on Human-Computer Interactio
n
DA  - 2022///
C2  - 2022
DO  - 10.1145/3506469.3506478
ID  - 10.1145/3506469.3506
KW  - Affective Interaction
KW  - Haptics
KW  - Remote Touch
KW  - Tactile Feedback
PB  - Association for Computing Machinery
SN  - 9781450396073
SP  - 69-72
T3  - IndiaHCI '21
TI  - Touch-ting: Sharing Touches Remotely Using Tangible Computing
UR  - https://doi.org/10.1145/3506469.3506478
ER  - 
TY  - CONF
AB  - With advances in immersive displays and gesture tracking technologies,
 many novel interfaces for musical and visual expression have been dev
eloped, which often explore combinations of audio and visual productio
ns. One category of such interfaces is musical drawing, in which artis
ts simultaneously produce both visual and sonic content. Since it deal
s with two different sensory channels, one of the main problematic is 
to find the right balance between the sonic and the visual aspects of 
a project. In this article, we regroup the existing 2D and 3D musical 
drawing projects and we propose a set of dimensions that can be used t
o describe them, namely: Expression Orientation, Required Expertise, C
ollaboration, Visual Replay Value, Audio Replay Value, Modifications, 
Mapping Flexibility, Mapping Structure and Degree of Immersion. Using 
these dimensions, we analyse the design choices, discuss technological
 and technical constraints, and establish perspectives for future work
.
AU  - Gruy, Esther
AU  - Berthaut, Florent
C1  - Milan, Italy
C3  - Proceedings of the 19th International Audio Mostly Conference: Explora
tions in Sonic Cultures
DA  - 2024///
C2  - 2024
DO  - 10.1145/3678299.3678317
ID  - 10.1145/3678299.3678
KW  - 2D drawing
KW  - 3D drawing
KW  - Audio-visual interfaces
KW  - Human computer interaction
KW  - Music
KW  - Sonification
PB  - Association for Computing Machinery
SN  - 9798400709685
SP  - 181-188
T3  - AM '24
TI  - Musical Drawing in 2D and 3D: Dimensions and Perspectives
UR  - https://doi.org/10.1145/3678299.3678317
ER  - 
TY  - CONF
AB  - This paper presents a proof-of-concept study conducted to analyze the 
effect of simple diotic vs. spatial, position-dynamic binaural synthes
is on social presence in VR, in comparison with face-to-face communica
tion in the real world, for a sample two-party scenario. A conversatio
nal task with shared visual reference was realized. The collected data
 includes questionnaires for direct assessment, tracking data, and aud
io and video recordings of the individual participants’ sessions for i
ndirect evaluation. While tendencies for improvements with binaural ov
er diotic presentation can be observed, no significant difference in s
ocial presence was found for the considered scenario. The gestural ana
lysis revealed that participants used the same amount and type of gest
ures in face-to-face as in VR, highlighting the importance of non-verb
al behavior in communication. As part of the research, an end-to-end f
ramework for conducting communication studies and analysis has been de
veloped.
AU  - Immohr, Felix
AU  - Rendle, Gareth
AU  - Neidhardt, Annika
AU  - Göring, Steve
AU  - Ramachandra Rao, Rakesh Rao
AU  - Arevalo Arboleda, Stephanie
AU  - Froehlich, Bernd
AU  - Raake, Alexander
C1  - Nantes, France
C3  - Proceedings of the 2023 ACM International Conference on Interactive Me
dia Experiences
DA  - 2023///
C2  - 2023
DO  - 10.1145/3573381.3596458
ID  - 10.1145/3573381.3596
KW  - communication
KW  - social presence
KW  - spatial audio
KW  - user behavior
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9798400700286
SP  - 209-215
T3  - IMX '23
TI  - Proof-of-Concept Study to Evaluate the Impact of Spatial Audio on Soci
al Presence and User Behavior in Multi-Modal VR Communication
UR  - https://doi.org/10.1145/3573381.3596458
ER  - 
TY  - CONF
AB  - Human visual attention is susceptible to social influences. In educati
on, peer effects impact student learning, but their precise role in mo
dulating attention remains unclear. To this end, we have developed an 
online education system that provides visual feedback to students base
d on the area of interest sharing of peer students’ gaze patterns. Our
 experiment (N=311) suggested that although peer attention manipulated
 students’ gaze, individuals adapted their viewing strategies rather t
han always mirroring peer focus. Furthermore, intentionally guiding st
udents’ gaze along the lecture pace did not always improve learning ou
tcomes. Instead, students able to adaptively adjust their focus based 
on personal needs showed enhanced performance. These findings elucidat
e how peer visual attention shapes students’ gaze patterns, deepening 
understanding of peer influence on learning. They also offer insights 
into designing adaptive online learning interventions leveraging peer 
attention modelling to optimize student attentiveness and learning suc
cess.
AU  - Xu, Songlin
AU  - Hu, Dongyin
AU  - Wang, Ru
AU  - Zhang, Xinyu
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713480
ID  - 10.1145/3706598.3713
KW  - Student Behavioral Intervention
KW  - Peer Effect
KW  - Gaze Sharing
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - PeerEdu: Bootstrapping Online Learning Behaviors via Asynchronous Area
 of Interest Sharing from Peer Gaze
UR  - https://doi.org/10.1145/3706598.3713480
ER  - 
TY  - CONF
AB  - ABSTRACTStrengthening telepresence for children can improve their educ
ational and socio-emotional outcomes. Meanwhile, understanding how chi
ldren conceptualize new technologies supports designers to create enga
ging and intuitive interactions for them. In this pictorial, we explor
e children's relationship to a promising and emerging approach to tele
presence-tabletop robots. We analyze metaphors children used to descri
be a tabletop telepresence robot platform during 2-years (100 hours) o
f online participatory design with this technology. We use illustratio
ns to convey and contextualize how children imagined the tabletop tele
presence robots. We find that children used three categories of metaph
or in their imaginings: (1) robot capabilities (magic/fragile), (2) ro
bot roles (competitive/play-acting/creative), (3) robot agency (remote
 controlled/autonomous). We discuss these metaphors in the context of 
existing child-robot interaction, tangible interaction, and telepresen
ce literature. Finally, we contribute the theoretical framework of a ‘
metaphor sandwich’ to describe children's use of mixed metaphors durin
g high engagement with the tabletop telepresence robots.
AU  - Hunt, Casey Lee
AU  - Sun, Kaiwen
AU  - Tseng, Kaitlyn
AU  - Balasubramaniyam, Priyanka
AU  - Druin, Allison
AU  - Huynh, Amanda
AU  - Leithinger, Daniel
AU  - Yip, Jason
C1  - Delft, Netherlands
C3  - Proceedings of the 23rd Annual ACM Interaction Design and Children Con
ference
DA  - 2024///
C2  - 2024
DO  - 10.1145/3628516.3656272
ID  - 10.1145/3628516.3656
PB  - Association for Computing Machinery
SN  - 9798400704420
SP  - 173-188
T3  - IDC '24
TI  - Making a Metaphor Sandwich: Analyzing Children's use of Metaphor Durin
g Tabletop Telepresence Robot Supported Participatory Design
UR  - https://doi.org/10.1145/3628516.3656272
ER  - 
TY  - JOUR
AB  - Introductory coding environments have been used in early education to 
promote computational thinking, supporting the development of cognitiv
e, critical, and social skills. Many environments focus on individual 
use, which has limited benefits compared to collaborative learning. In
 this paper, we present the results of a 10-session study at a local p
rimary school engaging eleven children with visual impairments and thr
ee inclusive education teachers in collaborative programming activitie
s. Based on participants' behavior, reactions, and feedback, we contri
bute an improved understanding of collaborative design in educational 
settings, focusing on the impact of Goals, Workspace, Interdependence,
 and Shared Awareness. Our main findings outline how collaboration dyn
amics can be shaped by asymmetric tasks, workspace proximity, and grou
p awareness. We further discuss factors that led to a lack of investme
nt in the shared goal and instances of unbalanced collaboration, refle
cting on challenges and opportunities for designing collaborative incl
usive coding kits.
AU  - Rocha, Filipa
AU  - Gonçalves, David
AU  - Pires, Ana Cristina
AU  - Nicolau, Hugo
AU  - Guerreiro, Tiago
DA  - 2025/5//
PY  - 2025
DO  - 10.1145/3710971
ID  - 10.1145/3710971
IS  - 2
KW  - accessible
KW  - children
KW  - collaboration
KW  - computational thinking
KW  - mixed-visual ability
KW  - robot
KW  - tangible
KW  - visually impaired
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Exploring Collaboration in Programming Activities with Children with V
isual Impairments: a 10-Session Study in a School Setting
UR  - https://doi.org/10.1145/3710971
VL  - 9
ER  - 
TY  - JOUR
AB  - Shared Augmented Reality (Shared AR) is an emerging technology that en
ables multiple users to interact synchronously within a collocated AR 
environment. Yet, there is limited research on the group interactions 
and dynamics in Shared AR, particularly in the context of gaming. To a
ddress this gap, we investigate Shared AR group interactions using a p
hone-based Shared AR mobile game called Urban Legends. Through in-situ
 observations, focus groups, and one-on-one interviews with 22 partici
pants, we examine how users collaborate and communicate within the gam
e. Our findings reveal that while verbal communication predominates, n
on-verbal cues are often overlooked by collocated participants, and us
ers initially struggle to recognize the expansive virtual space and th
e need for physical movement. Over time, users adapt to the hybrid env
ironment, demonstrating increasing spatial awareness and more dynamic 
collaboration. Based on these insights, we present a suite of design r
ecommendations for enhancing spatial awareness, supporting multi-modal
 communication, and fostering engaging group dynamics in future Shared
 AR applications.
AU  - Xu, Jiangnan
AU  - Luna, Sanzida Mojib
AU  - Tigwell, Garreth W.
AU  - Lalone, Nicolas
AU  - Saker, Michael
AU  - Laato, Samuli
AU  - Dunham, John
AU  - Wang, Yihong
AU  - Chamberlain, Alan
AU  - Papangelis, Konstantinos
DA  - 2025/8//
PY  - 2025
DO  - 10.1145/3749841
ID  - 10.1145/3749841
KW  - Contextual Inquiry
KW  - Group Dynamics
KW  - Shared AR
KW  - Social Interaction
KW  - Spatial Computing
KW  - Social AR
KW  - Social XR
N1  - Just Accepted
SN  - 1073-0516
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - Understanding the Interplay Between the Digital and the Physical in Sh
ared Augmented Reality Gaming: Probing through Urban Legends
UR  - https://doi.org/10.1145/3749841
ER  - 
TY  - CONF
AB  - We introduce Datamancer, a wearable device enabling bimanual gesture i
nteraction across multi-display ubiquitous analytics environments. Dat
amancer addresses the gap in gesture-based interaction within data vis
ualization settings, where current methods are often constrained by li
mited interaction spaces or the need for installing bulky tracking set
ups. Datamancer integrates a finger-mounted pinhole camera and a chest
-mounted gesture sensor, allowing seamless selection and manipulation 
of visualizations on distributed displays. By pointing to a display, u
sers can acquire the display and engage in various interactions, such 
as panning, zooming, and selection, using both hands. Our contribution
s include (1) an investigation of the design space of gestural interac
tion for physical ubiquitous analytics environments; (2) a prototype i
mplementation of the Datamancer system that realizes this model; and (
3) an evaluation of the prototype through demonstration of application
 scenarios, an expert review, and a user study.
AU  - Patnaik, Biswaksen
AU  - Borowski, Marcel
AU  - Peng, Huaishu
AU  - Klokmose, Clemens Nylandsted
AU  - Elmqvist, Niklas
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713123
ID  - 10.1145/3706598.3713
KW  - Gestural interaction
KW  - ubiquitous analytics
KW  - immersive analytics
KW  - Augmented Reality
KW  - visualizations
KW  - situated analytics.
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Datamancer: Bimanual Gesture Interaction in Multi-Display Ubiquitous A
nalytics Environments
UR  - https://doi.org/10.1145/3706598.3713123
ER  - 
TY  - JOUR
AB  - When beginners play the piano, the activity of the forearm muscles ten
ds to be greater than that of experts because beginners move their fin
gers with more force than necessary. Reducing forearm muscle activity 
is important for pianists to prevent fatigue and injury. However, it i
s difficult for beginners to learn how to do so by themselves. We prop
ose using electrical muscle stimulation (EMS) to teach beginners how t
o reduce this muscle activity while playing a tremolo: a rapid alterna
tion between two notes. Since experts use wrist rotation efficiently w
hen playing tremolos, we propose an EMS-based support system that appl
ies EMS not to muscles that are relevant to moving the fingers but to 
the supinator and pronator teres muscles, which are involved in wrist 
rotation. We conducted a user study with 16 beginners to investigate h
ow the forearm muscle activity on the extensor pollicis longus and dig
itorum muscles changed when using our EMS-based support system. We div
ided the participants into two groups: an experimental group who pract
iced by themselves with EMS and a control group who practiced by thems
elves without EMS and then practiced with instruction. When practicing
 by themselves, practicing with EMS was more effective than that witho
ut EMS; the activity levels of the extensor pollicis longus and digito
rum muscles were significantly lower with EMS, and the participants fe
lt less fatigue when playing tremolos. By comparing the improvement in
 reducing muscle activity between practicing with EMS and practicing w
ith instruction, there was no significant difference. The results sugg
est that our EMS-based support system can reduce target muscle activit
y by applying EMS to other muscles to teach beginners how to move limb
s efficiently.
AU  - Niijima, Arinobu
AU  - Takeda, Toki
AU  - Tanaka, Kentaro
AU  - Aoki, Ryosuke
AU  - Koike, Yukio
DA  - 2021/9//
PY  - 2021
DO  - 10.1145/3478110
ID  - 10.1145/3478110
IS  - 3
KW  - electrical muscle stimulation
KW  - electromyography
KW  - muscle activity
KW  - piano
KW  - tremolo
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
TI  - Reducing Muscle Activity when Playing Tremolo by Using Electrical Musc
le Stimulation to Learn Efficient Motor Skills
UR  - https://doi.org/10.1145/3478110
VL  - 5
ER  - 
TY  - CONF
AB  - Collaborative mobile augmented reality (MAR) has emerged as a promisin
g tool in the field of education. This technology enables multiple use
rs to interact with digital content overlaid on the physical world thr
ough their mobile devices. Collaborative MAR combined with tangible el
ements enhances learning by integrating physical objects that can be m
anipulated and interacted with in the augmented reality environment, p
roviding a hands-on and immersive educational experience. This study e
xplores the impact of tangible mobile augmented reality on collaborati
on and object manipulation. Our goal is to understand how mobile devic
es’ manipulation affects collocated students' collaboration in tangibl
e MAR in terms of ease of use and collaboration. The study involves pa
rticipants working in pairs to facilitate collaboration through a MAR 
game for developing the computational thinking skills of primary schoo
l students. Our goal is to compare the perceived behaviors and interac
tions that emerged in two distinct MAR settings: (1) Stand-mounted dev
ice condition, where the device is fixed on a mobile stand, and (2) Ha
nd-held device condition, where the device is held by one of the team'
s players. The same task is simulated in both settings to allow for di
rect comparison. The results of this study can help inform the design 
and development of future MAR systems and provide insights into the po
tential benefits and challenges in terms of collaboration and object m
anipulation.
AU  - Gardeli, Anna
AU  - Vosinakis, Spyros
C1  - Athens, Greece
C3  - Proceedings of the 2nd International Conference of the ACM Greek SIGCH
I Chapter
DA  - 2023///
C2  - 2023
DO  - 10.1145/3609987.3610004
ID  - 10.1145/3609987.3610
PB  - Association for Computing Machinery
SN  - 9798400708886
T3  - CHIGREECE '23
TI  - Exploring the co-manipulation of physical and virtual objects in tangi
ble mobile augmented reality for collaborative learning
UR  - https://doi.org/10.1145/3609987.3610004
ER  - 
TY  - CONF
AU  - Noma, Haruo
AU  - Miyasato, Tsutomu
AU  - Kishino, Fumio
C1  - Vancouver, British Columbia, Canada
C3  - Proceedings of the SIGCHI Conference on Human Factors in Computing Sys
tems
DA  - 1996///
C2  - 1996
DO  - 10.1145/238386.238454
ID  - 10.1145/238386.23845
KW  - force display
KW  - haptic sensation
KW  - palmtop display
KW  - teleconference
KW  - user interface
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 0897917774
SP  - 126-133
T3  - CHI '96
TI  - A palmtop display for dextrous manipulation with haptic sensation
UR  - https://doi.org/10.1145/238386.238454
ER  - 
TY  - CONF
AB  - AirConstellations supports a unique semi-fixed style of cross-device i
nteractions via multiple self-spatially-aware armatures to which users
 can easily attach (or detach) tablets and other devices. In particula
r, AirConstellations affords highly flexible and dynamic device format
ions where the users can bring multiple devices together in-air&nbsp;—
&nbsp;with 2–5 armatures poseable in 7DoF within the same workspace&nb
sp;—&nbsp;to suit the demands of their current task, social situation,
 app scenario, or mobility needs. This affords an interaction metaphor
 where relative orientation, proximity, attaching (or detaching) devic
es, and continuous movement into and out of ad-hoc ensembles can drive
 context-sensitive interactions. Yet all devices remain self-stable in
 useful configurations even when released in mid-air. We explore flexi
ble physical arrangement, feedforward of transition options, and layer
ing of devices in-air across a variety of multi-device app scenarios. 
These include video conferencing with flexible arrangement of the pers
on-space of multiple remote participants around a shared task-space, l
ayered and tiled device formations with overview+detail and shared-to-
personal transitions, and flexible composition of UI panels and tool p
alettes across devices for productivity applications. A preliminary in
terview study highlights user reactions to AirConstellations, such as 
for minimally disruptive device formations, easier physical transition
s, and balancing ”seeing and being seen” in remote work.
AU  - Marquardt, Nicolai
AU  - Henry Riche, Nathalie
AU  - Holz, Christian
AU  - Romat, Hugo
AU  - Pahud, Michel
AU  - Brudy, Frederik
AU  - Ledo, David
AU  - Park, Chunjong
AU  - Nicholas, Molly Jane
AU  - Seyed, Teddy
AU  - Ofek, Eyal
AU  - Lee, Bongshin
AU  - Buxton, William A.S.
AU  - Hinckley, Ken
C1  - Virtual Event, USA
C3  - The 34th Annual ACM Symposium on User Interface Software and Technolog
y
DA  - 2021///
C2  - 2021
DO  - 10.1145/3472749.3474820
ID  - 10.1145/3472749.3474
KW  - SurfaceFleet
KW  - cross-device computing
KW  - cross-device tracking
KW  - device ecologies
KW  - device formations
KW  - interaction techniques
KW  - multi-device
KW  - platform
KW  - semi-fixed workspaces
PB  - Association for Computing Machinery
SN  - 9781450386357
SP  - 1252-1268
T3  - UIST '21
TI  - AirConstellations: In-Air Device Formations for Cross-Device Interacti
on via Multiple Spatially-Aware Armatures
UR  - https://doi.org/10.1145/3472749.3474820
ER  - 
TY  - CONF
AB  - The film industry exerts significant economic and cultural influence, 
and its rapid development is contingent upon the expertise of industry
 professionals, underscoring the critical importance of film-shooting 
education. However, this process typically necessitates multiple pract
ice in complex professional venues using expensive equipment, presenti
ng a significant obstacle for ordinary learners who struggle to access
 such training environments. Despite VR technology has already shown i
ts potential in education, existing research has not addressed the cru
cial learning component of replicating the shooting process. Moreover,
 the limited functionality of traditional controllers hinder the fulfi
llment of the educational requirements. Therefore, we developed VActio
n VR system, combining high-fidelity virtual environments with a custo
m-designed controller to simulate the real-world camera operation expe
rience. The system’s lightweight design ensures cost-effective and eff
icient deployment. Experiment results demonstrated that VAction signif
icantly outperforms traditional methods in both practice effectiveness
 and user experience, indicating its potential and usefulness in film-
shooting education.
AU  - Wang, Shaocong
AU  - Qu, Che
AU  - Yu, Minjing
AU  - Zhou, Chao
AU  - Wang, Yuntao
AU  - Wen, Yu-Hui
AU  - Shi, Yuanchun
AU  - Liu, Yong-Jin
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3714217
ID  - 10.1145/3706598.3714
KW  - Film Production Education
KW  - Virtual Reality
KW  - Training System
KW  - Interaction Design
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - VAction: A Lightweight and Integrated VR Training System for Authentic
 Film-Shooting Experience
UR  - https://doi.org/10.1145/3706598.3714217
ER  - 
TY  - CONF
AB  - Team closeness provides the foundations of trust and communication, co
ntributing to teams’ success and viability. However, newcomers often s
truggle to be included in a team since incumbents tend to interact mor
e with other existing members. Previous research suggests that online 
communication technologies can help team inclusion by mitigating membe
rs’ perceived differences. In this study, we test how virtual reality 
(VR) can promote team closeness when forming teams. We conducted a bet
ween-subject experiment with teams working in-person and VR, where two
 members interacted first, and then a third member was added later to 
conduct a hidden-profile task. Participants evaluated how close they f
elt with their teammates after the task was completed. Our results sho
w that VR newcomers felt closer to the incumbents than in-person newco
mers. However, incumbents’ closeness to newcomers did not vary across 
conditions. We discuss the implications of these findings and offer su
ggestions for how VR can promote inclusion.
AU  - Fernandez-Espinosa, Mariana
AU  - Clouse, Kara
AU  - Sellars, Dylan
AU  - Tong, Danny
AU  - Bsales, Michael
AU  - Alcindor, Sophonie
AU  - Hubbard, Timothy D
AU  - Villano, Michael
AU  - Gómez-Zará, Diego
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3714127
ID  - 10.1145/3706598.3714
KW  - Familiarity Bias
KW  - Newcomers
KW  - Team Formation
KW  - Team Inclusion
KW  - Virtual Reality
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Breaking the Familiarity Bias: Employing Virtual Reality Environments 
to Enhance Team Formation and Inclusion
UR  - https://doi.org/10.1145/3706598.3714127
ER  - 
TY  - CONF
AB  - We present an immersive Virtural Reality (VR) experience developed thr
ough a unique combination of technologies including an actuated hardwa
re rig; a physics model with a responsive control routine; and an inte
ractive 3D gamelike experience. Specifically, this paper introduces a 
physics-based communication framework that allows force-driven interac
tion to be conveyed to a user through a physics-based proxy. Because t
he framework is generic and extendable, the application supports a var
iety of interaction modes, constrained by the limitations of the physi
cal full-body haptic rig. To showcase the technology, we highlight the
 experience of riding locomoting robots and vehicles placed in an imme
rsive VR setting.
AU  - Zordan, Victor
AU  - Welter, John
AU  - Hindlekar, Saurabh
AU  - Smith, J. Emerson
AU  - Mckay, W. Garrett
AU  - Lowe, Kunta
AU  - Marti, Carlos
AU  - Taylor, R. Austin
C1  - Barcelona, Spain
C3  - Proceedings of the 10th International Conference on Motion in Games
DA  - 2017///
C2  - 2017
DO  - 10.1145/3136457.3136468
ID  - 10.1145/3136457.3136
KW  - motion simulator
KW  - physics-based animation
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450355414
T3  - MIG '17
TI  - MechVR: a physics-based proxy for locomotion and interaction in a virt
ual environment
UR  - https://doi.org/10.1145/3136457.3136468
ER  - 
TY  - CONF
AB  - Effective communication is a key factor in social and professional con
texts which involve sharing the skills and actions of more than one pe
rson. This research proposes a novel system to enable full body sharin
g over a remotely operated wearable system, allowing one person to div
e into someone's else body. "Fusion" enables body surrogacy by sharing
 the same point of view of two-person: a surrogate and an operator, an
d it extends the limbs mobility and actions of the operator using two 
robotic arms mounted on the surrogate body. These arms can be used ind
ependently of the surrogate arms for collaborative scenarios or can be
 linked to surrogate's arms to be used in remote assisting and support
ing scenarios. Using Fusion, we realize three levels of bodily driven 
communication: Direct, Enforced, and Induced. We demonstrate through t
his system the possibilities of truly embodying and transferring our b
ody actions from one person to another, realizing true body communicat
ion.
AU  - Saraiji, MHD Yamen
AU  - Sasaki, Tomoya
AU  - Matsumura, Reo
AU  - Minamizawa, Kouta
AU  - Inami, Masahiko
C1  - Vancouver, British Columbia, Canada
C3  - ACM SIGGRAPH 2018 Emerging Technologies
DA  - 2018///
C2  - 2018
DO  - 10.1145/3214907.3214912
ID  - 10.1145/3214907.3214
KW  - body scheme alternation
KW  - collaborative systems
KW  - surrogacy
PB  - Association for Computing Machinery
SN  - 9781450358101
T3  - SIGGRAPH '18
TI  - Fusion: full body surrogacy for collaborative communication
UR  - https://doi.org/10.1145/3214907.3214912
ER  - 
TY  - CONF
AB  - Pair-learning is beneficial for learning outcome, motivation, and soci
al presence, and so is virtual reality (VR) by increasing immersion, e
ngagement, motivation, and interest of students. Nevertheless, there i
s a research gap if the benefits of pair-learning and VR can be combin
ed. Furthermore, it is not clear which influence it has if only one or
 both peers use VR. To investigate these aspects, we implemented two t
ypes of VR pair-learning systems, a symmetric system with both peers u
sing VR and an asymmetric system with one using a tablet. In a user st
udy (N=46), the symmetric system statistically significantly provided 
higher presence, immersion, player experience, and lower intrinsic cog
nitive load, which are all important for learning. Symmetric and asymm
etric systems performed equally well regarding learning outcome, highl
ighting that both are valuable learning systems. We used these finding
s to define guidelines on how to design co-located VR pair-learning ap
plications, including characteristics for symmetric and asymmetric sys
tems.
AU  - Drey, Tobias
AU  - Albus, Patrick
AU  - Kinderen, Simon
AU  - Milo, Maximilian
AU  - Segschneider, Thilo
AU  - Chanzab, Linda
AU  - Rietzler, Michael
AU  - Seufert, Tina
AU  - Rukzio, Enrico
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI Conference on Human Factors in Computing S
ystems
DA  - 2022///
C2  - 2022
DO  - 10.1145/3491102.3517641
ID  - 10.1145/3491102.3517
KW  - collaborative learning
KW  - pair-learning
KW  - signaling
KW  - symmetric and asymmetric system
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450391573
T3  - CHI '22
TI  - Towards Collaborative Learning in Virtual Reality: A Comparison of Co-
Located Symmetric and Asymmetric Pair-Learning
UR  - https://doi.org/10.1145/3491102.3517641
ER  - 
TY  - CONF
AB  - Modern augmented reality (AR) devices with advanced display and sensin
g capabilities pose significant privacy risks to users and bystanders.
 While previous context-aware adaptations focused on usability and erg
onomics, we explore the design space of privacy-driven adaptations tha
t allow users to meet their dynamic needs. These techniques offer gran
ular control over AR sensing capabilities across various AR input, out
put, and interaction modalities, aiming to minimize degradations to th
e user experience. Through an elicitation study with 10 AR researchers
, we derive 62 privacy-focused adaptation techniques that preserve key
 AR functionalities and classify them into system-driven, user-driven,
 and mixed-initiative approaches to create an adaptation catalog. We a
lso contribute a visualization tool that helps AR developers navigate 
the design space, validating its effectiveness in design workshops wit
h six AR developers. Our findings indicate that the tool allowed devel
opers to discover new techniques, evaluate tradeoffs, and make informe
d decisions that balance usability and privacy concerns in AR design.
AU  - Rajaram, Shwetha
AU  - Peralta, Macarena
AU  - Johnson, Janet G.
AU  - Nebeling, Michael
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713320
ID  - 10.1145/3706598.3713
KW  - elicitation studies
KW  - threat modeling
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Exploring the Design Space of Privacy-Driven Adaptation Techniques for
 Future Augmented Reality Interfaces
UR  - https://doi.org/10.1145/3706598.3713320
ER  - 
TY  - JOUR
AB  - Assembly procedures are a common task in several domains of applicatio
n. Augmented Reality (AR) has been considered as having great potentia
l in assisting users while performing such tasks. However, poor intera
ction design and lack of studies, often results in complex and hard to
 use AR systems. This paper considers three different interaction meth
ods for assembly procedures (Touch gestures in a mobile device; Mobile
 Device movements; 3D Controllers and See-through HMD). It also descri
bes a controlled experiment aimed at comparing acceptance and usabilit
y between these methods in an assembly task using Lego blocks. The mai
n conclusions are that participants were faster using the 3D controlle
rs and Video see-through HMD. Participants also preferred the HMD cond
ition, even though some reported light symptoms of nausea, sickness an
d/or disorientation, probably due to limited resolution of the HMD cam
eras used in the video see-through setting and some latency issues. In
 addition, although some research claims that manipulation of virtual 
objects with movements of the mobile device can be considered as natur
al, this condition was the least preferred by the participants.
AU  - Marques, Bernardo
AU  - Alves, João
AU  - Neves, Miguel
AU  - Justo, Inês
AU  - Santos, André
AU  - Rainho, Raquel
AU  - Maio, Rafael
AU  - Costa, Dany
AU  - Ferreira, Carlos
AU  - Dias, Paulo
AU  - Santos, Beatriz Sousa
DA  - 2020/11//
PY  - 2020
DO  - 10.1145/3427324
ID  - 10.1145/3427324
IS  - ISS
KW  - user study
KW  - touch gestures
KW  - mid-air gestures
KW  - interaction
KW  - device movement
KW  - controllers
KW  - augmented reality
KW  - assembly guidance
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Interaction with Virtual Content using Augmented Reality: A User Study
 in Assembly Procedures
UR  - https://doi.org/10.1145/3427324
VL  - 4
ER  - 
TY  - CONF
AB  - Designing in an environment of Virtual Reality is a field that gains g
round. Although more and more applications are constantly released, th
e majority of designers have not yet been introduced into Virtual Real
ity. A widely used tool for designing is Rhino which has been released
 by McNeel and Rhino Developer encourages the users to create plug-ins
 for custom use of the software. In parallel, Meta's developing tools 
offer their users the chance to customize their own applications. Towa
rds the direction of Virtual Reality integration, both have already re
leased new products for their users. RhinoVR is an open source plug-in
 for Rhino, while at the same time Meta provides Oculus hardware and p
latform solutions for users to turn their concept into reality. What i
s yet to be developed is a model that encourages the customization of 
a VR design platform, focusing mainly on developing a personalized too
lbox for designing.
AU  - Drampalou, Georgia
AU  - Kourniatis, Nikolaos
AU  - Voyiatzis, Ioannis
C1  - Athens, Greece
C3  - Proceedings of the 26th Pan-Hellenic Conference on Informatics
DA  - 2023///
C2  - 2023
DO  - 10.1145/3575879.3575960
ID  - 10.1145/3575879.3575
KW  - Oculus Quest 2
KW  - OpenVR API
KW  - Rhino Developer
KW  - VR Design
KW  - cross-platform.NET plug-in SDK
PB  - Association for Computing Machinery
SN  - 9781450398541
SP  - 14-20
T3  - PCI '22
TI  - Customized toolbox in VR Design
UR  - https://doi.org/10.1145/3575879.3575960
ER  - 
TY  - CONF
AB  - Virtual Reality enables users to explore content whose physics are onl
y limited by our creativity. Such limitless environments provide us wi
th many opportunities to explore innovative ways to support productivi
ty and collaboration. We present Spacetime, a scene editing tool built
 from the ground up to explore the novel interaction techniques that e
mpower single user interaction while maintaining fluid multi-user coll
aboration in immersive virtual environment. We achieve this by introdu
cing three novel interaction concepts: the Container, a new interactio
n primitive that supports a rich set of object manipulation and enviro
nmental navigation techniques, Parallel Objects, which enables paralle
l manipulation of objects to resolve interaction conflicts and support
 design workflows, and Avatar Objects, which supports interaction amon
g multiple users while maintaining an individual users' agency. Evalua
ted by professional Virtual Reality designers, Spacetime supports powe
rful individual and fluid collaborative workflows.
AU  - Xia, Haijun
AU  - Herscher, Sebastian
AU  - Perlin, Ken
AU  - Wigdor, Daniel
C1  - Berlin, Germany
C3  - Proceedings of the 31st Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2018///
C2  - 2018
DO  - 10.1145/3242587.3242597
ID  - 10.1145/3242587.3242
KW  - computer-supported collaborative work
KW  - interaction techniques
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450359481
SP  - 853-866
T3  - UIST '18
TI  - Spacetime: Enabling Fluid Individual and Collaborative Editing in Virt
ual Reality
UR  - https://doi.org/10.1145/3242587.3242597
ER  - 
TY  - BOOK
AB  - The SIGGRAPH Asia Symposium on Mobile Graphics and Interactive Applica
tions will offer attendees the opportunity to explore the opportunitie
s and challenges of mobile applications relevant to the global graphic
s community.The program will cover the development, technology, and ma
rketing of mobile graphics and interactive applications. It will espec
ially highlight novel uses of graphics and interactivity on mobile dev
ices. Attendees can expect to be exposed to the latest in mobile graph
ics and interactive applications through expert keynote talks, paper p
resentations, panel discussions, industry case studies, and hands-on d
emonstrations.
CY  - Macau
DA  - 2016///
PY  - 2016
ID  - 10.1145/2999508
PB  - Association for Computing Machinery
SN  - 9781450345514
TI  - SA '16: SIGGRAPH ASIA 2016 Mobile Graphics and Interactive Application
s
ER  - 
TY  - CONF
AB  - This paper details the design, implementation and an initial evaluatio
n of a collaborative platform named OptoBridge, which is aimed at enha
ncing remote guidance and skill acquisition for spatially distributed 
users. OptoBridge integrates augmented reality (AR), gesture interacti
on with video mediated communication and is preliminarily applied to t
he experimental teaching of the adjustment task with Michelson interfe
rometer. An exploratory study has been conducted to qualitatively and 
quantitatively evaluate the extent to which different viewpoints affec
t the student's sense of presence, task performance, learning outcomes
 and subjective feelings in the remote collaborative augmented environ
ment. 16 students from local universities have participated in the eva
luation. The result shows the influence of two different viewpoints an
d indicates that OptoBridge can effectively support remote guidance an
d enhance the collaborators' experience.
AU  - Sun, Hongling
AU  - Liu, Yue
AU  - Zhang, Zhenliang
AU  - Liu, Xiaoxu
AU  - Wang, Yongtian
C1  - Montreal, QC, Canada
C3  - Proceedings of the Sixth International Symposium of Chinese CHI
DA  - 2018///
C2  - 2018
DO  - 10.1145/3202667.3202676
ID  - 10.1145/3202667.3202
KW  - AR
KW  - Viewpoint
KW  - gesture interaction
KW  - remote guidance
PB  - Association for Computing Machinery
SN  - 9781450365086
SP  - 64-70
T3  - ChineseCHI '18
TI  - Employing Different Viewpoints for Remote Guidance in a Collaborative 
Augmented Environment
UR  - https://doi.org/10.1145/3202667.3202676
ER  - 
TY  - JOUR
AB  - Software practitioners use various methods in Requirements Engineering
 (RE) to elicit, analyze, and specify the requirements of enterprise p
roducts. The methods impact the final product characteristics and infl
uence product delivery. Ad-hoc usage of the methods by software practi
tioners can lead to inconsistency and ambiguity in the product. With t
he notable rise in enterprise products, games, and so forth across var
ious domains, Virtual Reality (VR) has become an essential technology 
for the future. The methods adopted for RE for developing VR products 
requires a detailed study. This article presents a mapping study on RE
 methods prescribed and used for developing VR applications including 
requirements elicitation, requirements analysis, and requirements spec
ification. Our study provides insights into the use of such methods in
 the VR community and suggests using specific RE methods in various fi
elds of interest. We also discuss future directions in RE for VR produ
cts.
AU  - Karre, Sai Anirudh
AU  - Reddy, Y. Raghu
AU  - Mittal, Raghav
DA  - 2024/4//
PY  - 2024
DO  - 10.1145/3649595
ID  - 10.1145/3649595
IS  - 4
KW  - Software requirements
KW  - requirements elicitation
KW  - virtual reality
KW  - industrial practices
SN  - 1049-331X
T2  - ACM Trans. Softw. Eng. Methodol.
TI  - RE Methods for Virtual Reality Software Product Development: A Mapping
 Study
UR  - https://doi.org/10.1145/3649595
VL  - 33
ER  - 
TY  - BOOK
AB  - Interactive technology has been one of the most important inseparable 
wheels of SIGGRAPH Asia, and the Emerging Technologies program plays a
 vital role in driving the research communities all over the world to 
pursue technological innovations that has a great impact on our everyd
ay life.This year, the Emerging Technologies program presents a broad 
scope of topics, reflecting the innovation of interactive technologies
 and a maturation of the field as it expands to include interactive vi
sualization and other graphics-related technologies.Be fascinated by h
ands-on demonstrations that expand the limits of current display techn
ologies, and exciting new hardware that enable sophisticated and nuanc
ed user input, innovative interaction techniques that enable more comp
lex interaction with application data and functionality, as well as ex
cellent examples of haptics developed to support multi-/cross-modality
 scenarios.
CY  - Bangkok, Thailand
DA  - 2017///
PY  - 2017
ID  - 10.1145/3132818
PB  - Association for Computing Machinery
SN  - 9781450354042
TI  - SA '17: SIGGRAPH Asia 2017 Emerging Technologies
ER  - 
TY  - CONF
AB  - Software practitioners use various requirement elicitation methods to 
produce a well-defined product. These methods impact the software prod
uct’s eventual traits and target a particular audience segment. Virtua
l Reality(VR) products are no different from this influence. With the 
notable rise in product offerings across various domains, VR has becom
e an essential technology for the future. Nevertheless, the type of me
thods practiced for requirement elicitation still has not been thoroug
hly studied. This paper presents a mapping study on requirement elicit
ation methods practiced by VR practitioners in academia and industry. 
We consolidated our observations based on their popularity in the prac
titioner community. Further, we present our insights on the necessary 
and sufficient conditions to conduct VR requirement elicitation using 
the identified methods to benefit the VR practitioner community.
AU  - Karre, Sai Anirudh
AU  - Mittal, Raghav
AU  - Reddy, Raghu
C1  - Allahabad, India
C3  - Proceedings of the 16th Innovations in Software Engineering Conference

DA  - 2023///
C2  - 2023
DO  - 10.1145/3578527.3578536
ID  - 10.1145/3578527.3578
KW  - Virtual Reality
KW  - Software requirements
KW  - Requirement elicitation
KW  - Industrial practices
PB  - Association for Computing Machinery
SN  - 9798400700644
T3  - ISEC '23
TI  - Requirements Elicitation for Virtual Reality Products - A Mapping Stud
y
UR  - https://doi.org/10.1145/3578527.3578536
ER  - 
TY  - BOOK
AB  - Following the success of Virtual and Augmented Reality at previous SIG
GRAPH Asia series, the Virtual and Augmented Reality (VR/AR) program a
t SIGGRAPH Asia 2018 provides an opportunity to explore emerging media
 and cutting edge technologies in virtual, augmented, and mixed realit
y. The SIGGRAPH Asia VR AR offers a highly visible and interactive ven
ue to take a deep dive into these emerging digital media and interacti
ve technologies.
CY  - Tokyo, Japan
DA  - 2018///
PY  - 2018
ID  - 10.1145/3275495
PB  - Association for Computing Machinery
SN  - 9781450360289
TI  - SA '18: SIGGRAPH Asia 2018 Virtual &amp; Augmented Reality
ER  - 
TY  - CONF
AB  - The rising occurrence of natural and human-made disasters emphasises t
he urgent need for effective training of medical first responders (MFR
s). Virtual Reality (VR) has recently been used to enhance traditional
 MFR training. However, to ensure that VR training improves disaster p
reparedness, it is not only crucial for MFR stakeholders to actively p
articipate in the design process. It may also be beneficial to place t
he co-design process in VR so that novice co-designers establish a pro
found, hands-on understanding of VR as a training tool. Thus, we intro
duce the Collaborative Scenario Builder (CSB), a prototype for MFRs wi
thout technical and designerly expertise with which to co-design scena
rios for virtual simulation training in VR. An evaluation with 33 MFR 
participants indicates that CSB is usable and provides participants wi
th an embodied understanding of VR, leading to new perspectives in the
ir collaborative design considerations. Thus, CSB contributes to a co-
design workflow with MFR co-designers that ensures that created VR tra
ining tools are needed and beneficial for MFRs so that they can provid
e better aid to people in the face of disasters.
AU  - Nguyen, Quynh
AU  - Pretolesi, Daniele
AU  - Gallhuber, Katja
C1  - Lisbon, Portugal
C3  - Proceedings of the 2023 ACM Conference on Information Technology for S
ocial Good
DA  - 2023///
C2  - 2023
DO  - 10.1145/3582515.3609553
ID  - 10.1145/3582515.3609
KW  - Co-Design
KW  - Medical First Responders
KW  - Virtual Reality
KW  - Virtual Simulation Training
PB  - Association for Computing Machinery
SN  - 9798400701160
SP  - 342-350
T3  - GoodIT '23
TI  - Collaborative Scenario Builder: A VR Co-Design Tool for Medical First 
Responders
UR  - https://doi.org/10.1145/3582515.3609553
ER  - 
TY  - BOOK
CY  - Guangzhou, China
DA  - 2022///
PY  - 2022
ID  - 10.1145/3565698
PB  - Association for Computing Machinery
SN  - 9781450398695
TI  - Chinese CHI '22: Proceedings of the Tenth International Symposium of C
hinese CHI
ER  - 
TY  - CONF
AB  - The collaborative design process is intrinsically complicated and dyna
mic, and researchers have long been exploring how to enhance efficienc
y in this process. As Artificial Intelligence technology evolves, it h
as been widely used as a design tool and exhibited the potential as a 
design collaborator. Nevertheless, problems concerning how designers s
hould communicate with AI in collaborative design remain unsolved. To 
address this research gap, we referred to how designers communicate fl
uently in human-human design collaboration, and found awareness to be 
an important ability for facilitating communication by understanding t
heir collaborators and current situation. However, previous research m
ainly studied and supported human awareness, the possible impact AI aw
areness would bring to the human-AI collaborative design process, and 
the way to realize AI awareness remain unknown. In this study, we expl
ored how AI awareness will impact human-AI collaboration through a Wiz
ard-of-Oz experiment. Both quantitative and qualitative results suppor
ted that enabling AI to have awareness can enhance the communication f
luidity between human and AI, thus enhancing collaboration efficiency.
 We further discussed the results and concluded design implications fo
r future human-AI collaborative design systems.
AU  - Cheng, Zhuoyi
AU  - Chen, Pei
AU  - Song, Wenzheng
AU  - Zhang, Hongbo
AU  - Li, Zhuoshu
AU  - Sun, Lingyun
C1  -  
C3  - Proceedings of the 30th International Conference on Intelligent User I
nterfaces
DA  - 2025///
C2  - 2025
DO  - 10.1145/3708359.3712162
ID  - 10.1145/3708359.3712
KW  - Human-AI collaboration
KW  - Design collaboration
KW  - Generative AI
KW  - AI Awareness
KW  - Human-AI communication
PB  - Association for Computing Machinery
SN  - 9798400713064
SP  - 157-172
T3  - IUI '25
TI  - An Exploratory Study on How AI Awareness Impacts Human-AI Design Colla
boration
UR  - https://doi.org/10.1145/3708359.3712162
ER  - 
TY  - CONF
AB  - The human face and eyes provide crucial conversational cues about a pe
rson’s focus of attention. In virtual reality applications, avatar fac
es are typically simplified, and eye movements often neglected. This p
aper explores how VR users perceive the look-at direction of other ava
tars and estimates the range within which an avatar’s averted gaze goe
s unnoticed. Through two-alternative forced choice experiments, we inv
estigate different gaze offsets to quantify thresholds for perceived g
aze aversion across three conditions: gaze side (left/right), stimulus
 duration, and avatar distance. Additionally, we assess the impact of 
averted gaze on social presence during interactions with an embodied c
onversational agent in a social game. A user study (N=40) revealed tha
t social presence is significantly affected by averted gaze when notic
ed, and that detection thresholds are particularly impacted by stimuli
 duration and interactions between side and distance. Our findings pro
vide a foundation for understanding gaze perception in social virtual 
reality.
AU  - Schott, Ephraim
AU  - López Garcı́a, Irene
AU  - Semple, Lauren August
AU  - Froehlich, Bernd
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3714041
ID  - 10.1145/3706598.3714
KW  - virtual reality
KW  - gaze direction
KW  - gaze perception
KW  - averted gaze
KW  - threshold detection
KW  - embodied conversational agents
KW  - avatar redirection
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - Estimating Detection Thresholds of Being Looked at in Virtual Reality 
for Avatar Redirection
UR  - https://doi.org/10.1145/3706598.3714041
ER  - 
TY  - CONF
AB  - We propose a novel interface concept in which interactive systems dire
ctly manipulate the user's head orientation. We implement this using e
lectrical-muscle-stimulation (EMS) of the neck muscles, which turns th
e head around its yaw (left/right) and pitch (up/down) axis. As the fi
rst exploration of EMS for head actuation, we characterized which musc
les can be robustly actuated. Second, we evaluated the accuracy of our
 system for actuating participants' head orientation towards static ta
rgets and trajectories. Third, we demonstrated how it enables interact
ions not possible before by building a range of applications, such as 
(1) synchronizing head orientations of two users, which enables a user
 to communicate head nods to another user while listening to music, an
d (2) directly changing the user's head orientation to locate objects 
in AR. Finally, in our second study, participants felt that our head a
ctuation contributed positively to their experience in four distinct a
pplications.
AU  - Tanaka, Yudai
AU  - Nishida, Jun
AU  - Lopes, Pedro
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI Conference on Human Factors in Computing S
ystems
DA  - 2022///
C2  - 2022
DO  - 10.1145/3491102.3501910
ID  - 10.1145/3491102.3501
KW  - Augmented Reality
KW  - Electrical Muscle Stimulation
KW  - Haptics
KW  - Virtual Reality
PB  - Association for Computing Machinery
SN  - 9781450391573
T3  - CHI '22
TI  - Electrical Head Actuation: Enabling Interactive Systems to Directly Ma
nipulate Head Orientation
UR  - https://doi.org/10.1145/3491102.3501910
ER  - 
TY  - CONF
AB  - Many nonspeaking autistic individuals rely on Communication and Regula
tion Partners (CRPs) to develop spelling-based communication using phy
sical letterboards, but this support is often geographically inaccessi
ble. We developed a remote presence system using Augmented Reality (AR
) to enable immersive, collaborative spelling instruction. The system 
features holographic letterboards and fully embodied avatars with real
-time head and hand tracking, allowing remote interaction between stud
ents and CRPs. In a study with 18 nonspeaking autistic participants, 1
5 (83%) successfully completed avatar-supported sessions. Interaction 
was higher, and participants reported a preference for the avatar cond
ition over voice-only support. These findings demonstrate the feasibil
ity of avatar-based AR telepresence for remote communication training.
 The system provides a demonstration of AR-supported interaction desig
ned with nonspeaking autistic individuals—an underrepresented group in
 HCI—and offers design insights for inclusive telepresence technologie
s that address geographic and accessibility barriers.
AU  - Dow, Travis
AU  - Pratishtha, Pratishtha
AU  - Alabood, Lorans
AU  - Jaswal, Vikram K.
AU  - Krishnamurthy, Diwakar
C1  -  
C3  - Proceedings of the 2025 ACM Designing Interactive Systems Conference
DA  - 2025///
C2  - 2025
DO  - 10.1145/3715336.3735807
ID  - 10.1145/3715336.3735
KW  - Augmented Reality
KW  - Mixed Reality
KW  - Nonspeaking Autistic People
KW  - Assistive Technology
KW  - Accessibility
PB  - Association for Computing Machinery
SN  - 9798400714856
SP  - 423-440
T3  - DIS '25
TI  - AR-Based Embodied Avatar Assistance for Nonspeaking Autistic People? D
esign and Feasibility Study
UR  - https://doi.org/10.1145/3715336.3735807
ER  - 
TY  - CONF
AB  - In recent years, the inclusion of persons with visual impairments (PVI
) is taking tremendous steps, especially with regards to group meeting
s. However, a significant part of communication is conveyed through no
n-verbal communication which is commonly inaccessible, such as deictic
 pointing gestures or the mimics and body language of participants. In
 this vision paper, we present an overview of our project MAPVI. MAPVI
 proposes new technologies on making meetings more accessible for PVIs
. Therefore, we explore which relevant information has to be tracked a
nd how those can be sensed for the users. Finally, those captured info
rmation get translated into a multitude of haptic feedback to make the
m accessible.
AU  - Gunther, Sebastian
AU  - Koutny, Reinhard
AU  - Dhingra, Naina
AU  - Funk, Markus
AU  - Hirt, Christian
AU  - Miesenberger, Klaus
AU  - Mühlhäuser, Max
AU  - Kunz, Andreas
C1  - Rhodes, Greece
C3  - Proceedings of the 12th ACM International Conference on PErvasive Tech
nologies Related to Assistive Environments
DA  - 2019///
C2  - 2019
DO  - 10.1145/3316782.3322747
ID  - 10.1145/3316782.3322
KW  - meetings
KW  - machine learning
KW  - haptics
KW  - assistive technologies
PB  - Association for Computing Machinery
SN  - 9781450362320
SP  - 343-352
T3  - PETRA '19
TI  - MAPVI: meeting accessibility for persons with visual impairments
UR  - https://doi.org/10.1145/3316782.3322747
ER  - 
TY  - CONF
AB  - This paper presents TAPE, a tangible augmented previsualization enviro
nment for filmmaking. Using tangible interfaces and augmented reality 
technology, TAPE combines physical props and virtual elements, allowin
g users to manipulate and position objects within and beyond a tableto
p space to visualize and refine their film concepts. The paper describ
es the overall design of the TAPE system and presents key features of 
the integration of TUI and AR technology. The system was evaluated in 
a between-subjects user study with film professionals and students, de
monstrating its potential to enhance the creative process and facilita
te collaboration.
AU  - Fei, Guangzheng
AU  - Liu, Dake
C1  - Denpasar, Bali, Indonesia
C3  - Proceedings of the Eleventh International Symposium of Chinese CHI
DA  - 2024///
C2  - 2024
DO  - 10.1145/3629606.3629629
ID  - 10.1145/3629606.3629
KW  - Augmented Reality
KW  - Filmmaking
KW  - Previsualization
KW  - Tangible User Interface
PB  - Association for Computing Machinery
SN  - 9798400716454
SP  - 251-262
T3  - CHCHI '23
TI  - TAPE: Tangible Augmented Previz Environment for Filmmaking
UR  - https://doi.org/10.1145/3629606.3629629
ER  - 
TY  - CONF
AB  - Competitive esports is a growing worldwide phenomenon now rivaling tra
ditional sports, with over 450 million views and 1 billion US dollars 
in revenue each year. For comparison, Major League Baseball has 500 mi
llion views and 10 billion in revenue, FIFA Soccer 900 million and 1.6
 billion. Despite this significant popularity, much of the world remai
ns unaware of esports — and in particular, research on and for esports
 is still extremely scarce compared to esports’ impact and potential. 
The Esports and High Performance HCI (EHPHCI) workshop will begin addr
essing that research gap. In esports, athletes compete through the com
puter interface. Because this interface can make the difference betwee
n winning and losing, esports athletes are among the most expert compu
ter interface users in the world, as other athletes are experts in usi
ng balls and shoes in traditional sports. The premise of this workshop
 is that people will apply esports technology broadly, improving perfo
rmance in a wide range of human activity. The workshop will gather exp
erts in engineering, human factors, psychology, design and the social 
and health sciences to discuss this deeply multidisciplinary enterpris
e.
AU  - Watson, Benjamin
AU  - Spjut, Josef
AU  - Kim, Joohwan
AU  - Listman, Jennifer
AU  - Kim, Sunjun
AU  - Wimmer, Raphael
AU  - Putrino, David
AU  - Lee, Byungjoo
C1  - Yokohama, Japan
C3  - Extended Abstracts of the 2021 CHI Conference on Human Factors in Comp
uting Systems
DA  - 2021///
C2  - 2021
DO  - 10.1145/3411763.3441313
ID  - 10.1145/3411763.3441
KW  - esports
KW  - expert interaction techniques
KW  - expert users
PB  - Association for Computing Machinery
SN  - 9781450380959
T3  - CHI EA '21
TI  - Esports and High Performance HCI
UR  - https://doi.org/10.1145/3411763.3441313
ER  - 
TY  - JOUR
AB  - Beyond the pandemic, organizations need to recognize what digital asse
ts, interactions, and communication processes reap the most benefits f
rom virtual reality.
AU  - Torro, Osku
AU  - Jalo, Henri
AU  - Pirkkalainen, Henri
DA  - 2021/9//
PY  - 2021
DO  - 10.1145/3440868
ID  - 10.1145/3440868
IS  - 10
SN  - 0001-0782
SP  - 48-55
T2  - Commun. ACM
TI  - Six reasons why virtual reality is a game-changing computing and commu
nication platform for organizations
UR  - https://doi.org/10.1145/3440868
VL  - 64
ER  - 
TY  - JOUR
AB  - Natural gestures are crucial for mid-air interaction, but predicting a
nd managing muscle fatigue is challenging. Existing torque-based model
s are limited in their ability to model above-shoulder interactions an
d to account for fatigue recovery. We introduce a new hybrid model, NI
CER, which combines a torque-based approach with a new term derived fr
om the empirical measurement of muscle contraction and a recovery fact
or to account for decreasing fatigue during rest. We evaluated NICER i
n a mid-air selection task using two interaction methods with differen
t degrees of perceived fatigue. Results show that NICER can accurately
 model above-shoulder interactions as well as reflect fatigue recovery
 during rest periods. Moreover, both interaction methods show a strong
er correlation with subjective fatigue measurement (ρ = 0.978/0.976) t
han a previous model, Cumulative Fatigue (ρ = 0.966/0.923), confirming
 that NICER is a powerful analytical tool to predict fatigue across a 
variety of gesture-based interactive applications.
AU  - Li, Yi
AU  - Tag, Benjamin
AU  - Dai, Shaozhang
AU  - Crowther, Robert
AU  - Dwyer, Tim
AU  - Irani, Pourang
AU  - Ens, Barrett
DA  - 2024/7//
PY  - 2024
DO  - 10.1145/3658230
ID  - 10.1145/3658230
IS  - 4
KW  - mid-air interactions
KW  - interaction design
KW  - endurance
KW  - shoulder fatigue
KW  - consumed endurance
KW  - cumulative fatigue
KW  - ergonomics
SN  - 0730-0301
T2  - ACM Trans. Graph.
TI  - NICER: A New and Improved Consumed Endurance and Recovery Metric to Qu
antify Muscle Fatigue of Mid-Air Interactions
UR  - https://doi.org/10.1145/3658230
VL  - 43
ER  - 
TY  - CONF
AB  - Human trust is a psycho-physiological state that is difficult to measu
re, yet is becoming increasingly important for the design of human-com
puter interactions. This paper explores if human trust can be measured
 using physiological measures when interacting with a computer interfa
ce, and how it correlates with cognitive load. In this work, we presen
t a pilot study in Virtual Reality (VR) that uses a multi-sensory appr
oach of Electroencephalography (EEG), galvanic skin response (GSR), an
d Heart Rate Variability (HRV) to measure trust with a virtual agent a
nd explore the correlation between trust and cognitive load. The goal 
of this study is twofold; 1) to determine the relationship between bio
signals, or physiological signals with trust and cognitive load, and 2
) to introduce a pilot study in VR based on cognitive load level to ev
aluate trust. Even though we could not report any significant main eff
ect or interaction of cognitive load and trust from the physiological 
signal, we found that in low cognitive load tasks, EEG alpha band powe
r reflects trustworthiness on the agent. Moreover, cognitive load of t
he user decreases when the agent is accurate regardless of task’s cogn
itive load. This could be possible because of small sample size, tasks
 not stressful enough to induce high cognitive load due to lab study a
nd comfortable environment or timestamp synchronisation error due to f
using data from various physiological sensors with different sample ra
te.
AU  - Gupta, Kunal
AU  - Hajika, Ryo
AU  - Pai, Yun Suen
AU  - Duenser, Andreas
AU  - Lochner, Martin
AU  - Billinghurst, Mark
C1  - Parramatta, NSW, Australia
C3  - Proceedings of the 25th ACM Symposium on Virtual Reality Software and 
Technology
DA  - 2019///
C2  - 2019
DO  - 10.1145/3359996.3364276
ID  - 10.1145/3359996.3364
KW  - Cognitive Load
KW  - Physiological signals
KW  - Trust
KW  - Virtual Assistant
KW  - Virtual Reality
PB  - Association for Computing Machinery
SN  - 9781450370011
T3  - VRST '19
TI  - In AI We Trust: Investigating the Relationship between Biosignals, Tru
st and Cognitive Load in VR
UR  - https://doi.org/10.1145/3359996.3364276
ER  - 
TY  - CONF
AB  - Despite the spread of technologies in the physical world and the norma
lization of virtual experiences, non-verbal communication with radical
ly non-anthropomorphic avatars remains an underexplored frontier. We p
resent an interaction system in which two participants must learn to c
ommunicate with each other non-verbally through a digital filter that 
morphs their appearance. In a collaborative escape room, the Visitor m
ust teach a non-anthropomorphic physical robot to play, while the Cont
roller, in a different location, embodies the robot with an altered pe
rception of the environment and the Visitor’s companion in VR. This st
udy addresses the design of the activity, the robot, and the virtual e
nvironment, with a focus on how the Visitor’s morphology is translated
 in VR. Results show that participants were able to develop emergent a
nd effective communication strategies, with the Controller naturally e
mbodying its avatar’s narrative, making this system a promising testbe
d for future research on human-technology interaction, entertainment, 
and embodiment.
AU  - Espositi, Federico
AU  - Vetere, Maurizio
AU  - Bonarini, Andrea
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3713428
ID  - 10.1145/3706598.3713
KW  - Collaboration ; Computer Mediated Communication ; Embodied Interaction
 ; Entertainment ; User Experience Design ; Virtual/Augmented Reality 
; Robot ; Artifact or System ; Empirical study that tells us about how
 people use a system ; Empirical study that tells us about people ; Ar
t ; Interaction Design ; Lab Study ; Prototyping/Implementation ; Qual
itative Methods ; Quantitative Methods
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - From Alien to Ally: Exploring Non-Verbal Communication with Non-Anthro
pomorphic Avatars in a Collaborative Escape-Room
UR  - https://doi.org/10.1145/3706598.3713428
ER  - 
TY  - CONF
AB  - Sand painting is a highly aesthetic and valuable form of art but often
 constrained by the need for specific equipment and the associated lea
rning curve. To address these challenges, we developed a VR sand paint
ing system, SandTouch, offering an immersive and intuitive sand painti
ng experience that closely mirrors the interaction with physical sand.
 Leveraging advanced gesture recognition technology, SandTouch allows 
users to create intricate sand art in a virtual environment, capturing
 the fine sensations of real sand manipulation along with realistic so
und feedback. The integration of AI agent further enhances the experie
nce by intelligently interpreting users’ creative intentions based on 
real-time interactions, offering contextually relevant artistic sugges
tions. Comprehensive evaluations have demonstrated a significant incre
ase in user engagement and immersion. Furthermore, the realistic sound
 feedback enhances emotional relief and deepens the painting experienc
e.
AU  - Liu, Long
AU  - Ren, Junbin
AU  - Fan, Zeyuan
AU  - Li, Chenhui
AU  - He, Gaoqi
AU  - Wang, Changbo
AU  - Gao, Yang
AU  - Li, Chen
C1  -  
C3  - Proceedings of the 2025 CHI Conference on Human Factors in Computing S
ystems
DA  - 2025///
C2  - 2025
DO  - 10.1145/3706598.3714275
ID  - 10.1145/3706598.3714
KW  - Sand Painting
KW  - Virtual Reality
KW  - AI-Guidance
KW  - Emotional Relief
PB  - Association for Computing Machinery
SN  - 9798400713941
T3  - CHI '25
TI  - SandTouch: Empowering Virtual Sand Art in VR with AI Guidance and Emot
ional Relief
UR  - https://doi.org/10.1145/3706598.3714275
ER  - 
TY  - CONF
AB  - Mixed reality (augmented and virtual reality) technology continues to 
find its way into the industry. Nevertheless, prototypes and island so
lutions are developed in companies, which are not embedded in the corp
orate strategy. This paper presents a systematic approach for finding 
and developing use cases accompanied by a strategic implementation and
 evaluation process to integrate mixed reality in the industry. Sustai
nability aspects like energy and resource efficiency, possible reducti
on of the ecological footprint, and sustainable solutions for lasting 
and vision-based use in companies are considered. Within several use c
ases with 20 industry partners in the following areas are developed: 1
) novel forms of space-independent collaboration (e.g., collaborative 
work by integrating real-time 3D depth information of the real environ
ment and visualization of and interaction with real-time production da
ta) and 2) XR-supported training and learning methods (e.g., parameter
izable and adaptive training scenarios, roll-out of training content f
or several participants and integration of gamification mechanisms). A
dditionally, the methodology for a sustainability assessment, technolo
gy acceptance, and a multi-criteria evaluation are shown, and first re
sults are discussed.
AU  - Holly, Fabian
AU  - Zigart, Tanja
AU  - Maurer, Martina
AU  - Wolfartsberger, Josef
AU  - Brunnhofer, Magdalena
AU  - Sorko, Sabrina Romina
AU  - Moser, Thomas
AU  - Schlager, Alexander
C1  - Vienna, Austria
C3  - Proceedings of the 2022 8th International Conference on Computer Techn
ology Applications
DA  - 2022///
C2  - 2022
DO  - 10.1145/3543712.3543729
ID  - 10.1145/3543712.3543
KW  - Industry Use Cases
KW  - Mixed Reality
KW  - Sustainability
PB  - Association for Computing Machinery
SN  - 9781450396226
SP  - 128-134
T3  - ICCTA '22
TI  - Gaining Impact with Mixed Reality in Industry – A Sustainable Approach

UR  - https://doi.org/10.1145/3543712.3543729
ER  - 
TY  - CONF
AB  - Recent advances in consumer virtual reality (VR) technology have made 
it easy to accurately capture users' motions over room-sized areas all
owing natural locomotion for navigation in VR. While this helps create
 a stronger match between proprioceptive information from human body m
ovements for enhancing immersion and reducing motion sickness, it intr
oduces a few challenges. Walking is only possible within virtual envir
onments (VEs) that fit inside the boundaries of the tracked physical s
pace which for most users is quite small. Within this space the potent
ial for colliding with physical objects around the play area is high. 
Additionally, only limited haptic feedback is available. In this paper
, I focus on the problem of variations in the size and shape of each u
ser's tracked physical space for multiplayer interactions. As part of 
the constrained physical space problem, I also present an automated sy
stem for steering the user away from play area boundaries using Galvan
ic Vestibular Stimulation (GVS). In my thesis, I will build techniques
 to enable the system to intelligently apply redirection and GVS-based
 steering as users explore virtual environments of arbitrary sizes.
AU  - Sra, Misha
C1  - Tokyo, Japan
C3  - Adjunct Proceedings of the 29th Annual ACM Symposium on User Interface
 Software and Technology
DA  - 2016///
C2  - 2016
DO  - 10.1145/2984751.2984788
ID  - 10.1145/2984751.2984
KW  - virtual reality
KW  - tracking
KW  - obstacle avoidance
KW  - natural locomotion
KW  - head-mounted displays
KW  - games
KW  - galvanic vestibular stimulation
KW  - asymmetric design
KW  - 3d mapping
PB  - Association for Computing Machinery
SN  - 9781450345316
SP  - 29-32
T3  - UIST '16 Adjunct
TI  - Asymmetric Design Approach and Collision Avoidance Techniques For Room
-scale Multiplayer Virtual Reality
UR  - https://doi.org/10.1145/2984751.2984788
ER  - 
TY  - CONF
AB  - This paper introduces Video2MR, a mixed reality system that automatica
lly generates 3D sports and exercise instructions from 2D videos. Mixe
d reality instructions have great potential for physical training, but
 existing works require substantial time and cost to create these 3D e
xperiences. Video2MR overcomes this limitation by transforming arbitra
ry instructional videos available online into MR 3D avatars with AI-en
abled motion capture (DeepMotion). Then, it automatically enhances the
 avatar motion through the following augmentation techniques: 1) contr
asting and highlighting differences between the user and avatar postur
es, 2) visualizing key trajectories and movements of specific body par
ts, 3) manipulation of time and speed using body motion, and 4) spatia
lly repositioning avatars for different perspectives. Developed on Hol
olens 2 and Azure Kinect, we showcase various use cases, including yog
a, dancing, soccer, tennis, and other physical exercises. The study re
sults confirm that Video2MR provides more engaging and playful learnin
g experiences, compared to existing 2D video instructions.
AU  - Ihara, Keiichi
AU  - Monteiro, Kyzyl
AU  - Faridan, Mehrad
AU  - Kazi, Rubaiat Habib
AU  - Suzuki, Ryo
C1  -  
C3  - Proceedings of the 30th International Conference on Intelligent User I
nterfaces
DA  - 2025///
C2  - 2025
DO  - 10.1145/3708359.3712159
ID  - 10.1145/3708359.3712
KW  - Mixed Reality; Sports and Exercises; Videos; Motion Capture; Avatar; A
utomated Generation
PB  - Association for Computing Machinery
SN  - 9798400713064
SP  - 1548-1563
T3  - IUI '25
TI  - Video2MR: Automatically Generating Mixed Reality 3D Instructions by Au
gmenting Extracted Motion from 2D Videos
UR  - https://doi.org/10.1145/3708359.3712159
ER  - 
TY  - JOUR
AB  - In this paper we contribute a literature review and organization frame
work for classifying the collaboration needs and features that should 
be considered when designing headset-based augmented reality (AR) expe
riences for collocated settings. In recent years augmented reality tec
hnology has been experiencing significant growth through the emergence
 of headsets that allow gestural interaction, and AR designers are inc
reasingly interested in using this technology to enhance collaborative
 activities in a variety of physical environments. However, collaborat
ive AR applications need to contain features that enhance collaboratio
n and satisfy needs that are present during the group activities. When
 AR designers lack an understanding of what collaborators need during 
an interaction, or what features have already been designed to solve t
hose needs, then AR creators will spend time redesigning features that
 have already been created, or worse, create applications that do not 
contain necessary features. While much work has been done on designing
 virtual reality (VR) collaborative environments, AR environments are 
a relatively newer design space, and designers are lacking a comprehen
sive framework for describing needs that arise during collaborative ac
tivities and the features that could be designed into AR applications 
to satisfy those needs. In this paper we contribute a literature revie
w of 92 papers in the areas of augmented reality and virtual reality, 
and we contribute a list of design features and needs that are helpful
 to consider when designing for headset-based collaborative AR experie
nces.
AU  - Radu, Iulian
AU  - Joy, Tugce
AU  - Bowman, Yiran
AU  - Bott, Ian
AU  - Schneider, Bertrand
DA  - 2021/4//
PY  - 2021
DO  - 10.1145/3449243
ID  - 10.1145/3449243
IS  - CSCW1
KW  - augmented reality
KW  - collaboration taxonomies
KW  - collaborative virtual environments
KW  - virtual reality
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - A Survey of Needs and Features for Augmented Reality Collaborations in
 Collocated Spaces
UR  - https://doi.org/10.1145/3449243
VL  - 5
ER  - 
TY  - CONF
AB  - Geological fieldwork forms an integral part of science discovery, expl
oration, and learning in many geoscientific domains. Yet, there are ba
rriers that can hinder its practice. To address this, prior research h
as investigated immersive geovisualisations, however, there is no cons
ensus on the types of interaction tools and techniques that should be 
used. We have conducted a literature review of 31 papers and present t
he visualisation environments, interaction tools and techniques, and e
valuation methods from this last decade. We found a lack of establishe
d taxonomy for visualisation environments; an absence of thorough repo
rts on interaction tools and techniques; and a lack of use of relevant
 human-computer interaction (HCI) theories and user-centered approache
s. This review contributes towards the development of a design framewo
rk as we propose a basic taxonomy; demonstrate the need for holistic r
ecords of user interactions; and highlight the need for HCI evaluation
 methods. Addressing these gaps will facilitate future innovation in t
he emerging field of immersive geovisualisations.
AU  - Gallagher, Cael
AU  - Turkay, Selen
AU  - Brown, Ross Andrew
C1  - Melbourne, VIC, Australia
C3  - Proceedings of the 33rd Australian Conference on Human-Computer Intera
ction
DA  - 2022///
C2  - 2022
DO  - 10.1145/3520495.3520511
ID  - 10.1145/3520495.3520
KW  - geovisualisation
KW  - virtual environments
KW  - virtual field trips
PB  - Association for Computing Machinery
SN  - 9781450395984
SP  - 307-326
T3  - OzCHI '21
TI  - Towards Designing Immersive Geovisualisations: Literature Review and R
ecommendations for Future Research
UR  - https://doi.org/10.1145/3520495.3520511
ER  - 
TY  - BOOK
AB  - The SIGGRAPH Asia Symposium on Mobile Graphics and Interactive Applica
tions will offer attendees the opportunity to explore the opportunitie
s and challenges of mobile applications relevant to the global graphic
s community.The program will cover the development, technology, and ma
rketing of mobile graphics and interactive applications. It will espec
ially highlight novel uses of graphics and interactivity on mobile dev
ices. Attendees can expect to be exposed to the latest in mobile graph
ics and interactive applications through expert keynote talks, paper p
resentations, panel discussions, industry case studies, and hands-on d
emonstrations.
CY  - Bangkok, Thailand
DA  - 2017///
PY  - 2017
ID  - 10.1145/3132787
PB  - Association for Computing Machinery
SN  - 9781450354103
TI  - SA '17: SIGGRAPH Asia 2017 Mobile Graphics &amp; Interactive Applicati
ons
ER  - 
TY  - CONF
AB  - Physical distance presents a challenge for building and maintaining re
lationships. With recent work showing the effectiveness of both visual
 and haptic feedback in supporting interpersonal touch over a distance
, such technologies look to bridge this gap and improve existing commu
nication technologies. In this project, we explore the potential role 
of shape-shifting displays for doing so. We present two prototypes, on
e using linear slide potentiometers and the other using linear actuato
rs, that incorporate these forms of feedback to facilitate mediated so
cial touch. We present the benefits and drawbacks of each system, and 
conclude that, for a system focused on collaboration and synchronous c
ommunication, linear actuators may be better suited due to their load 
capacity and precision.
AU  - Pallarino, Timothy
AU  - Free, Aaron
AU  - Mutuc, Katrina
AU  - Yarosh, Svetlana
C1  - San Francisco, California, USA
C3  - Proceedings of the 19th ACM Conference on Computer Supported Cooperati
ve Work and Social Computing Companion
DA  - 2016///
C2  - 2016
DO  - 10.1145/2818052.2869124
ID  - 10.1145/2818052.2869
KW  - HP Sprout
KW  - Mediated Social Touch
KW  - Remote Communication
KW  - Shape-Shifting Displays
PB  - Association for Computing Machinery
SN  - 9781450339506
SP  - 361-364
T3  - CSCW '16 Companion
TI  - Feeling Distance: An Investigation of Mediated Social Touch Prototypes

UR  - https://doi.org/10.1145/2818052.2869124
ER  - 
TY  - JOUR
AB  - This work explored how users’ sensitivity to offsets in their avatars’
 virtual hands changes as they gain exposure to virtual reality. We co
nducted an experiment using a two-alternative forced choice (2-AFC) de
sign over the course of 4 weeks, split into four sessions. The trials 
in each session had a variety of eight offset distances paired with ei
ght offset directions (across a two-dimensional plane). While we did n
ot find evidence that users became more sensitive to the offsets over 
time, we did find evidence of behavioral changes. Specifically, partic
ipants’ head–hand coordination and completion time varied significantl
y as the sessions went on. We discuss the implications of both results
 and how they could influence our understanding of long-term calibrati
on for perception-action coordination in virtual environments.
AU  - Kohm, Kristopher
AU  - Porter, John
AU  - Robb, Andrew
DA  - 2022/11//
PY  - 2022
DO  - 10.1145/3561055
ID  - 10.1145/3561055
IS  - 4
KW  - Body awareness
KW  - hand offsets
KW  - calibration
KW  - longitudinal
SN  - 1544-3558
T2  - ACM Trans. Appl. Percept.
TI  - Sensitivity to Hand Offsets and Related Behavior in Virtual Environmen
ts over Time
UR  - https://doi.org/10.1145/3561055
VL  - 19
ER  - 
TY  - CONF
AB  - Interacting with the touchscreen of a mobile phone in virtual reality 
(VR) is challenging because users cannot see their fingers when aiming
 for targets. We propose using two mirrors reflecting the front camera
 of the phone and a purpose-built deep neural network to infer the 3D 
position of fingertips above the screen. Network training is self-supe
rvised after only a few hundred initial labelled images and does not r
equire any external sensor. The inferred fingertip positions can be us
ed to control different hand models and objects in VR. Controlled expe
riments evaluate tracking performance for single-finger touch input, a
nd compare several 3D hand representations with a flat 2D overlay used
 in previous work. The results confirm the suitability of our fingerti
p tracker to aid precise tapping of small targets on the phone screen 
and provide insights about the effect of various hand representations 
on control and presence. Finally, we provide several application examp
les showing how 3D fingertip input can complement and extend phone-bas
ed touch interaction in VR.
AU  - Matulic, Fabrice
AU  - Kashima, Taiga
AU  - Beker, Deniz
AU  - Suzuo, Daichi
AU  - Fujiwara, Hiroshi
AU  - Vogel, Daniel
C1  - Halifax, NS, Canada
C3  - Proceedings of the 50th Graphics Interface Conference
DA  - 2024///
C2  - 2024
DO  - 10.1145/3670947.3670961
ID  - 10.1145/3670947.3670
KW  - hand pose estimation
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9798400718281
T3  - GI '24
TI  - Above-Screen Fingertip Tracking and Hand Representation for Precise To
uch Input with a Phone in Virtual Reality
UR  - https://doi.org/10.1145/3670947.3670961
ER  - 
TY  - CONF
AB  - Three worlds are integral to our daily life: the real world, virtual w
orld, and remote world. In the paper, there is proposed coexistent spa
ce where networked users can communicate, interact, and collaborate to
gether by exchanging 4D+ sensation, human intension, and emotion. The 
4D+ sensation includes 3D vision, 3D sound, force and torque, touch, a
nd movements. The coexistent space is generated by seamless integratio
n of real, virtual, and remote worlds while networked users experience
 the feeling of coexistence through 4D+ bi-directional interaction. In
itial software framework and experimental results for interaction betw
een multiple remote users are shown successfully.
AU  - You, Bum-Jae
AU  - Kwon, Jounghuem R.
AU  - Nam, Sang-Hun
AU  - Lee, Jung-Jea
AU  - Lee, Kwang-Kyu
AU  - Yeom, Kiwon
C1  - Shenzhen, China
C3  - SIGGRAPH Asia 2014 Autonomous Virtual Humans and Social Robot for Tele
presence
DA  - 2014///
C2  - 2014
DO  - 10.1145/2668956.2668957
ID  - 10.1145/2668956.2668
KW  - constant time
KW  - global illumination
KW  - radiosity
PB  - Association for Computing Machinery
SN  - 9781450332439
T3  - SA '14
TI  - Coexistent space: toward seamless integration of real, virtual, and re
mote worlds for 4D+ interpersonal interaction and collaboration
UR  - https://doi.org/10.1145/2668956.2668957
ER  - 
TY  - BOOK
CY  - Parramatta, NSW, Australia
DA  - 2019///
PY  - 2019
ID  - 10.1145/3359996
PB  - Association for Computing Machinery
SN  - 9781450370011
TI  - VRST '19: Proceedings of the 25th ACM Symposium on Virtual Reality Sof
tware and Technology
ER  - 
TY  - JOUR
AB  - When developing XR applications for Industry 4.0, it is important to c
onsider the integration of visual displays, hardware components, and m
ultimodal interaction techniques that are compatible with the entire s
ystem. The potential use of multimodal interactions in industrial appl
ications has been recognized as a significant factor in enhancing huma
ns’ ability to perform tasks and make informed decisions. To offer a c
omprehensive analysis of the current advancements in industrial XR, th
is review presents a structured tutorial that provides answers to the 
following research questions: (R.Q.1) What are the similarities and di
fferences between XR technologies, including augmented reality (AR), m
ixed reality (MR), Augmented Virtuality (AV), and virtual reality (VR)
 under Industry 4.0 consideration? (R.Q.2) What types of visual displa
ys and hardware devices are needed to present XR for Industry 4.0? (R.
Q.3) How did the multimodal interaction in XR perceive and relate to I
ndustry 4.0? (R.Q.4) How have modern adaptations of XR technologies de
alt with the theme of Industry 4.0? (R.Q.5) How can XR technologies in
 Industry 4.0 develop their services and usages to be more solution-in
clusive? This review showcases various instances that demonstrate XR’s
 potential to transform how humans interact with the physical world in
 Industry 4.0. These advancements can increase productivity, reduce co
sts, and enhance safety.
AU  - Alhakamy, A’aeshah
DA  - 2024/4//
PY  - 2024
DO  - 10.1145/3652595
ID  - 10.1145/3652595
IS  - 9
KW  - Extended reality (XR)
KW  - augmented reality (AR)
KW  - virtual reality (VR)
KW  - mixed reality (MR)
KW  - and augmented virtuality (AV)
KW  - 4IR
KW  - Industry 4.0
SN  - 0360-0300
T2  - ACM Comput. Surv.
TI  - Extended Reality (XR) Toward Building Immersive Solutions: The Key to 
Unlocking Industry 4.0
UR  - https://doi.org/10.1145/3652595
VL  - 56
ER  - 
TY  - JOUR
AB  - Mixed reality enables users to immerse themselves in high-workload int
eraction spaces like office work scenarios. We envision physiologicall
y adaptive systems that can move users into different mixed reality ma
nifestations, to improve their focus on the primary task. However, it 
is unclear which manifestation is most conducive for high productivity
 and engagement. In this work, we evaluate whether physiological indic
ators for engagement can be discriminated for different manifestations
. For this, we engaged participants in a typing task in three differen
t mixed reality manifestations (augmented reality, augmented virtualit
y, virtual reality) and monitored physiological correlates (EEG, ECG, 
and eye tracking) of users' engagement and workload. We found that use
rs achieved best typing performances in augmented reality and augmente
d virtuality. At the same time, physiological engagement peaked in aug
mented virtuality, while workload decreased. We conclude that augmente
d virtuality strikes a good balance between the different manifestatio
ns, as it facilitates displaying the physical keyboard for improved ty
ping performance and, at the same time, allows one to block out the re
al world, removing many real-world distractors.
AU  - Chiossi, Francesco
AU  - El Khaoudi, Yassmine
AU  - Ou, Changkun
AU  - Sidenmark, Ludwig
AU  - Zaky, Abdelrahman
AU  - Feuchtner, Tiare
AU  - Mayer, Sven
DA  - 2024/10//
PY  - 2024
DO  - 10.1145/3698142
ID  - 10.1145/3698142
IS  - ISS
KW  - Augmented Reality
KW  - Augmented Virtuality
KW  - Electroencephalography
KW  - Engagement
KW  - Eye Tracking
KW  - Mixed Reality
KW  - Physiological Computing
KW  - Virtual Reality
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Evaluating Typing Performance in Different Mixed Reality Manifestation
s using Physiological Features
UR  - https://doi.org/10.1145/3698142
VL  - 8
ER  - 
TY  - CONF
AB  - The human brain’s plasticity allows for the integration of artificial 
body parts into the human body. Leveraging this, embodied systems real
ize intuitive interactions with the environment. We introduce a novel 
concept: embodied swarm robots. Swarm robots constitute a collective o
f robots working in harmony to achieve a common objective, in our case
, serving as functional body parts. Embodied swarm robots can dynamica
lly alter their shape, density, and the correspondences between body p
arts and individual robots. We contribute an investigation of the infl
uence on embodiment of swarm robot-specific factors derived from these
 characteristics, focusing on a hand. Our paper is the first to examin
e these factors through virtual reality (VR) and real-world robot stud
ies to provide essential design considerations and applications of emb
odied swarm robots. Through quantitative and qualitative analysis, we 
identified a system configuration to achieve the embodiment of swarm r
obots.
AU  - Ichihashi, Sosuke
AU  - Kuroki, So
AU  - Nishimura, Mai
AU  - Kasaura, Kazumi
AU  - Hiraki, Takefumi
AU  - Tanaka, Kazutoshi
AU  - Yoshida, Shigeo
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2024 CHI Conference on Human Factors in Computing S
ystems
DA  - 2024///
C2  - 2024
DO  - 10.1145/3613904.3642870
ID  - 10.1145/3613904.3642
KW  - embodiment
KW  - swarm robotics
KW  - tangible interaction
PB  - Association for Computing Machinery
SN  - 9798400703300
T3  - CHI '24
TI  - Swarm Body: Embodied Swarm Robots
UR  - https://doi.org/10.1145/3613904.3642870
ER  - 
TY  - CONF
AB  - E-Learning, Blended Learning, Massive Online Courses, Distributed Lear
ning, Webinars Hybrid Events and video conferencing are topics treated
 for decades. Technology-wise, many opportunities were taken and chanc
es were used. However, in many situations, work places, universities a
nd institutions, lectures, courses, trainings, workshops or informativ
e events were still primarily held on-site. All of them, with their sp
ecific advantages and disadvantages (e.g., personal contact, networkin
g vs. time loss, ecological footprint, etc.). First with the Corona Pa
ndemic and the subsequent measures, all foremost the lockdown situatio
ns worldwide, remote working, learning and video conferencing experien
ced a dramatic boost. The option of preferring on-site, personal meeti
ngs vanished completely. Due to this profound change in collaborative 
that had to become common overnight, people were forced to face and ad
apt to available technologies. The latter, on the other side, also evo
lved quickly to provide more and more features to improve collaboratio
n, usability and privacy. Formats for lectures, courses, workshops and
 collaboration also had to be adapted quickly. The problem was that al
l stakeholders, both lecturers as well as learners could not that easi
ly change their habits, ways of teaching and learning, interacting, an
d – not to forget – their didactic concept, methods and materials. A 1
:1 transformation was impossible since different technical background 
knowledge as well as very different technical and spatial conditions l
ead to great imbalance in quality of teaching, interaction, use of tec
hnology and practicability. In order to address these uncertainties, t
his work provides a basic set of suggestions for lecturers in form of 
a pattern collection for setting up educational online courses regardi
ng several aspects like common sense, technology and rules of the game
. Since patterns are technology-agnostic and formulated for a broad au
dience with different professional backgrounds, they qualify as univer
sal format and at the same time keep the validity of time. Even after 
almost three years with COVID-19, there is still struggle with technol
ogy adaption and format generation. The formulated patterns are based 
on interviews with experts that worked as lecturers, a larger-scale su
rvey including the results from 63 online questionnaires and one focus
 group. The resulting set of 19 guidelines was then reformulated as pa
tterns in a mid-high maturity state with the perspective of being furt
her supported by new findings and practical experience. The pattern co
llection is linked to a process model for evolving pattern libraries f
rom previous work.
AU  - Reiners, René
AU  - Jayhooni, Sam
C1  - Irsee, Germany
C3  - Proceedings of the 27th European Conference on Pattern Languages of Pr
ograms
DA  - 2023///
C2  - 2023
DO  - 10.1145/3551902.3551978
ID  - 10.1145/3551902.3551
PB  - Association for Computing Machinery
SN  - 9781450395946
T3  - EuroPLop '22
TI  - Evolving Pattern Candidates for Setting Up Educational Online Seminars
: - Findings from the COVID-19 Pandemic -
UR  - https://doi.org/10.1145/3551902.3551978
ER  - 
TY  - CONF
AB  - This paper takes the Bloom's Taxonomy, more specifically the Revised B
loom's Taxonomy, as a baseline for learning objective and curriculum d
esign adopted by generations of teachers and instructors in their prac
tice. On the backdrop of recent findings and persistent principles of 
learning design, the authors employ narrative theory and its notion of
 linguistic statements to propose a collaborative approach to curricul
um design using an interactive and card-based method. The conceptual n
otions of the Learning Objective Design Deck are illustrated and impor
tant arguments for the use of a card deck in context of learning objec
tive design workshops are presented. The methodical tool aimed at educ
ators and instructional designers is comprised of a canvas and a card 
deck that can be used in both physical, in form of an actual card deck
, and digital formats, e.g. on collaborative synchronous digital white
board solutions. The authors will discuss the current state of their m
ethodological design, perspectives on formalisation for implementation
 in software and present initial results form a workshop conducted wit
h domain experts to reflect on areas for improvement and further resea
rch. The paper concludes with a contextualisation of the method in rel
ation to other learning design tools in development by the authors tha
t integrate the narratively driven learning experience design approach
 to conceptualise a framework and modelling language for learning expe
rience design that can be extended to a software-based approach for le
arning activity or even learning unit design.
AU  - Recke, Moritz Philip
AU  - Perna, Stefano
C1  - Portsmouth, United Kingdom
C3  - Proceedings of the 7th International Conference on E-Society, e-Learni
ng and e-Technologies
DA  - 2021///
C2  - 2021
DO  - 10.1145/3477282.3477286
ID  - 10.1145/3477282.3477
KW  - Learning objectives
KW  - card-based participatory design
KW  - course design
KW  - modelling language
PB  - Association for Computing Machinery
SN  - 9781450376846
SP  - 19-25
T3  - ICSLT '21
TI  - A Card-Based Learning Objective Design Method for Collaborative Curric
ulum Design
UR  - https://doi.org/10.1145/3477282.3477286
ER  - 
TY  - CONF
AB  - Relief is an actuated tabletop display, which is able to render and an
imate three-dimensional shapes with a malleable surface. It allows use
rs to experience and form digital models like geographical terrain in 
an intuitive manner. The tabletop surface is actuated by an array of 1
20 motorized pins, which are controlled with a low-cost, scalable plat
form built upon open-source hardware and software tools. Each pin can 
be addressed individually and senses user input like pulling and pushi
ng.
AU  - Leithinger, Daniel
AU  - Ishii, Hiroshi
C1  - Cambridge, Massachusetts, USA
C3  - Proceedings of the Fourth International Conference on Tangible, Embedd
ed, and Embodied Interaction
DA  - 2010///
C2  - 2010
DO  - 10.1145/1709886.1709928
ID  - 10.1145/1709886.1709
KW  - haptic display
KW  - pin array
KW  - relief interface
KW  - shape display
KW  - tangible input
PB  - Association for Computing Machinery
SN  - 9781605588414
SP  - 221-222
T3  - TEI '10
TI  - Relief: a scalable actuated shape display
UR  - https://doi.org/10.1145/1709886.1709928
ER  - 
TY  - JOUR
AB  - Virtual co-cooking gained visibility during the COVID-19 pandemic due 
to the increasing use of communication technology for social activitie
s. However, available videoconferencing platforms are not well designe
d to support virtual co-cooking. Therefore, we explored this practice 
and the underlying design space and derived guidelines for current vid
eoconferencing interfaces to better meet virtual cook-along enthusiast
s' needs. For this, we first observed three remote cook-along sessions
 and then conducted semi-structured interviews, resulting in 12 requir
ements and 4 requirements themes culminating in 20 features divided in
to four dimensions: planning, enabling, co-presence, and food interact
ion. In the second phase, each feature was evaluated by 14 participant
s using the Kano questionnaire, followed by structured interviews. Thi
s resulted in six design implications related to automation, hands-fre
e interactions, privacy, preserving memories, eliminating stress, and 
encouraging conjoint activities. This research provides insights and p
erspectives on the evolving landscape of technology-mediated social in
teractions and collaborative practices, and how to design for them.
AU  - Weber, Philip
AU  - Costa, Lucas Andrade da
AU  - Ludwig, Thomas
DA  - 2025/1//
PY  - 2025
DO  - 10.1145/3701185
ID  - 10.1145/3701185
IS  - 1
KW  - collaborative practices
KW  - human-food interaction
KW  - remote social experience
KW  - videoconferencing platforms
KW  - virtual co-cooking
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Bridging Distances through Virtual Cook-Along Sessions: Exploring the 
Design Space of Collaborative Remote Cooking Experiences
UR  - https://doi.org/10.1145/3701185
VL  - 9
ER  - 
TY  - JOUR
AB  - We have built haptic interfaces featuring smartphones and tablets that
 use magnetometerderived orientation sensing to modulate virtual displ
ays, especially spatial sound, allowing, for instance, each side of a 
karaoke recording to be separately steered around a periphonic display
. Embedding such devices into a spinnable affordance allows a "spinnin
g plate"- style interface, a novel interaction technique. Either stati
c (pointing) or dynamic (spinning) modes can be used to control "whirl
ed" multimodal display, including a rotary motion platform, panoramic 
movies, and the positions of avatars in virtual environments.
AU  - Cohen, Michael
AU  - Ranaweera, Rasika
AU  - Ito, Hayato
AU  - Endo, Shun
AU  - Holesch, Sascha
AU  - Villegasc, Julián
DA  - 2013/2//
PY  - 2013
DO  - 10.1145/2436196.2436199
ID  - 10.1145/2436196.2436
IS  - 4
SN  - 1559-1662
SP  - 4-5
T2  - SIGMOBILE Mob. Comput. Commun. Rev.
TI  - "Twin Spin": steering karaoke (or anything else) with smartphone wands
 deployable as spinnable affordances
UR  - https://doi.org/10.1145/2436196.2436199
VL  - 16
ER  - 
TY  - CONF
AB  - The rise of IoT-ready devices is supported through well-established we
b concepts for communication and analytics, but interaction yet remain
s in the world of web browsers and screen-based 2D interaction during 
times of tablet and smartphone popularity. Transforming IoT interactio
n concepts into 3D for future exploitation with head-worn XR devices i
s a difficult task due to the lack of support and continued disengagem
ent of game engines used in XR development. In this work, we present a
n approach to overcome this limitation, tightly including web technolo
gy into a 3D game engine. Our work leverages the versatility of web co
ncepts to create immersive and scalable web applications in XR, withou
t the need for deep-tech know-how about XR concepts or tiring customiz
ation work. We describe the methodology and tools in detail and provid
e some exemplary XR applications.
AU  - Fleck, Philipp
AU  - Schmalstieg, Dieter
AU  - Arth, Clemens
C1  - Virtual Event, Republic of Korea
C3  - Proceedings of the 25th International Conference on 3D Web Technology
DA  - 2020///
C2  - 2020
DO  - 10.1145/3424616.3424691
ID  - 10.1145/3424616.3424
KW  - XR
KW  - Web browser
KW  - Web app
KW  - IoT
KW  - 3D Engines
PB  - Association for Computing Machinery
SN  - 9781450381697
T3  - Web3D '20
TI  - Creating IoT-ready XR-WebApps with Unity3D
UR  - https://doi.org/10.1145/3424616.3424691
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3711496
PB  - Association for Computing Machinery
SN  - 9798400710186
TI  - ICVRT '24: Proceedings of the 2024 International Conference on Virtual
 Reality Technology
ER  - 
TY  - JOUR
AB  - to create an integrated space. We consider an MR configuration in whic
h collocated collaborators work around a tabletop display, while remot
e collaborators wear an HMD to interact with a connected virtual envir
onment that gives a 3D perspective, and consider the impact of varying
 degrees of view congruence with their collaborators. In a within-subj
ects study with 18 groups of 3, groups completed task scenarios involv
ing 3D object manipulation around a physical-virtual mapped tabletop. 
We compare a synchronized Tabletop display baseline and two MR conditi
ons with different levels of view congruence: Fishtank and Hover. Fish
tank has a high degree of congruence as it shares a top-down perspecti
ve of the 3D objects with the tabletop collaborators. The Hover condit
ion has less view congruence since 3D content hovers front of the remo
te collaborator above the table. The MR conditions yielded higher self
-reported awareness and co-presence than the Tabletop condition for bo
th collocated and remote participants. Remote collaborators significan
tly preferred the MR conditions for manipulating shared 3D models and 
communicating with their collaborators. Our findings illustrate streng
ths and weaknesses of both MR techniques but show that more participan
ts preferred the less-congruent Hover condition overall. Reasons inclu
de that it facilitated interaction and viewing 3D objects.
AU  - Salimian, Hossein
AU  - Brooks, Stephen
AU  - Reilly, Derek
DA  - 2019/11//
PY  - 2019
DO  - 10.1145/3359207
ID  - 10.1145/3359207
IS  - CSCW
KW  - 3D interaction
KW  - CSCW
KW  - awareness
KW  - co-presence
KW  - collaboration
KW  - mixed presence
KW  - virtual reality
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - MP Remix: Relaxed WYSIWIS Immersive Interfaces for Mixed Presence Coll
aboration With 3D Content
UR  - https://doi.org/10.1145/3359207
VL  - 3
ER  - 
TY  - CONF
AB  - This work presents PITAS, a thin-sheet robotic material composed of a 
reversible phase transition actuating layer and a heating/sensing laye
r. The synthetic sheet material enables non-expert makers to create sh
ape-changing devices that can locally or remotely convey physical info
rmation such as shape, color, texture and temperature changes. PITAS s
heets can be manipulated into various 2D shapes or 3D geometries using
 subtractive fabrication methods such as laser, vinyl, or manual cutti
ng or an optional additive 3D printing method for creating 3D objects.
 After describing the design of PITAS, this paper also describes a stu
dy conducted with thirteen makers to gauge the accessibility, design s
pace, and limitations encountered when PITAS is used as a soft robotic
 material while designing physical information communication devices. 
Lastly, this work reports on the results of a mechanical and electrica
l evaluation of PITAS and presents application examples to demonstrate
 its utility.
AU  - Cheng, Tingyu
AU  - Park, Jung Wook
AU  - Li, Jiachen
AU  - Ramey, Charles
AU  - Lin, Hongnan
AU  - Abowd, Gregory D.
AU  - Brum Medeiros, Carolina
AU  - Oh, HyunJoo
AU  - Giordano, Marcello
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI Conference on Human Factors in Computing S
ystems
DA  - 2022///
C2  - 2022
DO  - 10.1145/3491102.3517532
ID  - 10.1145/3491102.3517
KW  - phase transition actuator
KW  - physical telecommunication
KW  - shape-changing interface
PB  - Association for Computing Machinery
SN  - 9781450391573
T3  - CHI '22
TI  - PITAS: Sensing and Actuating Embedded Robotic Sheet for Physical Infor
mation Communication
UR  - https://doi.org/10.1145/3491102.3517532
ER  - 
TY  - CONF
AB  - Video communication using head-mounted cameras could be useful to medi
ate shared activities and support collaboration. Growing popularity of
 wearable gaze trackers presents an opportunity to add gaze informatio
n on the egocentric video. We hypothesized three potential benefits of
 gaze-augmented egocentric video to support collaborative scenarios: s
upport deictic referencing, enable grounding in communication, and ena
ble better awareness of the collaborator's intentions. Previous resear
ch on using egocentric videos for real-world collaborative tasks has f
ailed to show clear benefits of gaze point visualization. We designed 
a study, deconstructing a collaborative car navigation scenario, to sp
ecifically target the value of gaze-augmented video for intention pred
iction. Our results show that viewers of gaze-augmented video could pr
edict the direction taken by a driver at a four-way intersection more 
accurately and more confidently than a viewer of the same video withou
t the superimposed gaze point. Our study demonstrates that gaze augmen
tation can be useful and encourages further study in real-world collab
orative scenarios.
AU  - Akkil, Deepak
AU  - Isokoski, Poika
C1  - San Jose, California, USA
C3  - Proceedings of the 2016 CHI Conference on Human Factors in Computing S
ystems
DA  - 2016///
C2  - 2016
DO  - 10.1145/2858036.2858127
ID  - 10.1145/2858036.2858
KW  - gaze tracking
KW  - intention prediction
KW  - video-based collaboration
KW  - wearable computing
PB  - Association for Computing Machinery
SN  - 9781450333627
SP  - 1573-1584
T3  - CHI '16
TI  - Gaze Augmentation in Egocentric Video Improves Awareness of Intention
UR  - https://doi.org/10.1145/2858036.2858127
ER  - 
TY  - CONF
AB  - We have developed a gestural controller for a multimodal client suite 
using a sudden motion sensor (SMS) deployed with many modern laptop co
mputers. Interpreted commands inferred from the SMS accelerometer can 
be used to adjust position—orientation and location—of egocentric pers
pectives and exocentric avatars to control panoramic browsing and spat
ialized sound, adjusting the lateralization, directionalization, and s
patialization of musical and audio channels.
AU  - Cohen, Michael
C1  - Singapore
C3  - Proceedings of The 7th ACM SIGGRAPH International Conference on Virtua
l-Reality Continuum and Its Applications in Industry
DA  - 2008///
C2  - 2008
DO  - 10.1145/1477862.1477911
ID  - 10.1145/1477862.1477
KW  - ambient information systems
KW  - calm technology
KW  - haptic interface
KW  - interactive networked media
KW  - multimodal interaction
PB  - Association for Computing Machinery
SN  - 9781605583358
T3  - VRCAI '08
TI  - Integration of laptop sudden motion sensor as accelerometric control f
or virtual environments
UR  - https://doi.org/10.1145/1477862.1477911
ER  - 
TY  - CONF
AB  - Immersive Learning (iL) is known as a recent area of research that use
s three-dimensional virtual environments and multi-sensory devices, al
so known as immersive technologies, to support the improvement of lear
ning outcomes. This work aims to obtain evidence of theoretical and te
chnological aspects of iL from the Symposium on Virtual and Augmented 
Reality (SVR) publications. A Systematic Literature Mapping protocol w
as developed and executed in order to select the primary studies to pe
rform the analysis and data extraction. 76 primary studies helped to a
nswer the research questions. A large part of the contributions by the
 SVR community are virtual environments that support education in the 
health area. In addition, some gaps and research opportunities were id
entified: virtual environments that serve audiences with special needs
; development frameworks that consider pedagogical aspects and the use
 of biometric measures to support the validation of improved learning 
outcomes.
AU  - Fernandes, Filipe
AU  - Castro, Diego
AU  - Werner, Claudia
C1  - Virtual Event, Brazil
C3  - Proceedings of the 23rd Symposium on Virtual and Augmented Reality
DA  - 2022///
C2  - 2022
DO  - 10.1145/3488162.3488163
ID  - 10.1145/3488162.3488
KW  - Immersive Learning
KW  - Symposium on Virtual and Augmented Reality
KW  - Systematic Mapping Study
PB  - Association for Computing Machinery
SN  - 9781450395526
SP  - 1-13
T3  - SVR '21
TI  - A Systematic Mapping Literature of Immersive Learning from SVR Publica
tions
UR  - https://doi.org/10.1145/3488162.3488163
ER  - 
TY  - CONF
AB  - Remotely instructing and guiding users in physical tasks has offered p
romise across a wide variety of domains. While it has been the subject
 of many research projects, current approaches are often limited in th
e communication bandwidth (lacking context, spatial information) or in
teractivity (unidirectional, asynchronous) between the expert and the 
learner. Systems that use Mixed-Reality systems for this purpose have 
rigid configurations for the expert and the learner. We explore the de
sign space of bi-directional mixed-reality telepresence systems for te
aching physical tasks, and present Loki, a novel system which explores
 the various dimensions of this space. Loki leverages video, audio and
 spatial capture along with mixed-reality presentation methods to allo
w users to explore and annotate the local and remote environments, and
 record and review their own performance as well as their peer's. The 
system design of Loki also enables easy transitions between different 
configurations within the explored design space. We validate its utili
ty through a varied set of scenarios and a qualitative user study.
AU  - Thoravi Kumaravel, Balasaravanan
AU  - Anderson, Fraser
AU  - Fitzmaurice, George
AU  - Hartmann, Bjoern
AU  - Grossman, Tovi
C1  - New Orleans, LA, USA
C3  - Proceedings of the 32nd Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2019///
C2  - 2019
DO  - 10.1145/3332165.3347872
ID  - 10.1145/3332165.3347
KW  - learning
KW  - mixed reality
KW  - physical tasks
KW  - remote guidance
PB  - Association for Computing Machinery
SN  - 9781450368162
SP  - 161-174
T3  - UIST '19
TI  - Loki: Facilitating Remote Instruction of Physical Tasks Using Bi-Direc
tional Mixed-Reality Telepresence
UR  - https://doi.org/10.1145/3332165.3347872
ER  - 
TY  - CONF
AB  - We have built haptic interfaces featuring smartphones that use magneto
meter-derived orientation sensing to modulate virtual displays. Embedd
ing such devices into swinging a ordances allows a "poi"-style interfa
ce, whirling tethered devices, for a novel interaction technique. Dyna
mic twirling can be used to control multimodal displays - including po
sitions of sources &amp; sinks in spatial sound, subjects (avatars) &a
mp; objects in virtual environments, and object movies ("turnos") &amp
; panoramas ("panos") in image-based renderings. This "practically pan
oramic" multimodal interface can be enjoyed in an appropriate spot as 
location-based entertainment, locative media for cross-platform, "mobi
le ambient" experience.
AU  - Cohen, Michael
C1  - San Francisco, California, USA
C3  - Proceedings of the 14th International Conference on Human-Computer Int
eraction with Mobile Devices and Services Companion
DA  - 2012///
C2  - 2012
DO  - 10.1145/2371664.2371709
ID  - 10.1145/2371664.2371
KW  - cross-platform "ambient mobile" interface
KW  - locative
KW  - multimodal
KW  - practically panoramic interface
KW  - situated panorama
PB  - Association for Computing Machinery
SN  - 9781450314435
SP  - 199-202
T3  - MobileHCI '12
TI  - POI Poi: point-of-interest poi for multimodal tethered whirling
UR  - https://doi.org/10.1145/2371664.2371709
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3706370
PB  - Association for Computing Machinery
SN  - 9798400713910
TI  - IMX '25: Proceedings of the 2025 ACM International Conference on Inter
active Media Experiences
ER  - 
TY  - JOUR
AB  - A central challenge of social computing research is to enable people t
o communicate expressively with each other remotely. Augmented reality
 has great promise for expressive communication since it enables commu
nication beyond texts and photos and towards immersive experiences ren
dered in recipients' physical environments. Little research, however, 
has explored AR's potential for everyday interpersonal communication. 
In this work, we prototype an AR messaging system, ARwand, to understa
nd people's behaviors and perceptions around communicating with friend
s via AR messaging. We present our findings under four themes observed
 from a user study with 24 participants, including the types of immers
ive messages people choose to send to each other, which factors contri
bute to a sense of immersiveness, and what concerns arise over this ne
w form of messaging. We discuss important implications of our findings
 on the design of future immersive communication systems.
AU  - Lee, Kyungjun
AU  - Li, Hong
AU  - Wellyanto, Muhammad Rizky
AU  - Tham, Yu Jiang
AU  - Monroy-Hernández, Andrés
AU  - Liu, Fannie
AU  - Smith, Brian A.
AU  - Vaish, Rajan
DA  - 2023/4//
PY  - 2023
DO  - 10.1145/3579483
ID  - 10.1145/3579483
IS  - CSCW1
KW  - AR
KW  - experience crafting
KW  - immersive communication
KW  - messaging
KW  - smartglasses
KW  - smartphones
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Exploring Immersive Interpersonal Communication via AR
UR  - https://doi.org/10.1145/3579483
VL  - 7
ER  - 
TY  - CONF
AB  - Finger gesture recognition is gaining great research interest for wear
able device interactions such as smartwatches and AR/VR headsets. In t
his paper, we propose a hands-free fine-grained finger gesture recogni
tion system AO-Finger based on acoustic-optic sensor fusing. Specifica
lly, we design a wristband with a modified stethoscope microphone and 
two high-speed optic motion sensors to capture signals generated from 
finger movements. We propose a set of natural, inconspicuous and effor
tless micro finger gestures that can be reliably detected from the com
plementary signals from both sensors. We design a multi-modal CNN-Tran
sformer model for fast gesture recognition (flick/pinch/tap), and a fi
nger swipe contact detection model to enable fine-grained swipe gestur
e tracking. We built a prototype which achieves an overall accuracy of
 94.83% in detecting fast gestures and enables fine-grained continuous
 swipe gestures tracking. AO-Finger is practical for use as a wearable
 device and ready to be integrated into existing wrist-worn devices su
ch as smartwatches.
AU  - Xu, Chenhan
AU  - Zhou, Bing
AU  - Krishnan, Gurunandan
AU  - Nayar, Shree
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI Conference on Human Factors in Computing S
ystems
DA  - 2023///
C2  - 2023
DO  - 10.1145/3544548.3581264
ID  - 10.1145/3544548.3581
PB  - Association for Computing Machinery
SN  - 9781450394215
T3  - CHI '23
TI  - AO-Finger: Hands-free Fine-grained Finger Gesture Recognition via Acou
stic-Optic Sensor Fusing
UR  - https://doi.org/10.1145/3544548.3581264
ER  - 
TY  - CONF
AB  - This paper presents ongoing work that intends to simplify the introduc
tion of everyday applications to interactive tabletops. SLAP Widgets b
ring tangible general-purpose widgets to tabletops while providing the
 flexibility of on-screen controls. Madgets maintain consistency betwe
en physical controls and their digital state. BendDesk represents our 
vision of a multi-touch enabled office environment. Our pattern langua
ge captures knowledge for the design of interactive tabletops. For eac
h project, we describe its technical background, present the current s
tate of research, and discuss future work.
AU  - Weiss, Malte
C1  - New York, New York, USA
C3  - Adjunct Proceedings of the 23nd Annual ACM Symposium on User Interface
 Software and Technology
DA  - 2010///
C2  - 2010
DO  - 10.1145/1866218.1866227
ID  - 10.1145/1866218.1866
KW  - actuation
KW  - applications
KW  - curved surface
KW  - haptic feedback
KW  - interactive tabletops
KW  - tangible user interfaces
PB  - Association for Computing Machinery
SN  - 9781450304627
SP  - 375-378
T3  - UIST '10
TI  - Bringing everyday applications to interactive surfaces
UR  - https://doi.org/10.1145/1866218.1866227
ER  - 
TY  - CONF
AB  - Welcome and OverviewVisualisation and Visual AnalyticsIntroduction to 
Immersive AnalyticsComputing Beyond the DesktopCollaboration
AU  - Engelke, Ulrich
AU  - Cordeil, Maxime
AU  - Cunningham, Andrew
AU  - Ens, Barrett
C1  - Brisbane, Queensland, Australia
C3  - SIGGRAPH Asia 2019 Courses
DA  - 2019///
C2  - 2019
DO  - 10.1145/3355047.3359391
ID  - 10.1145/3355047.3359
PB  - Association for Computing Machinery
SN  - 9781450369411
T3  - SA '19
TI  - Immersive analytics
UR  - https://doi.org/10.1145/3355047.3359391
ER  - 
TY  - JOUR
AB  - A panel at ACM Multimedia 2012 addressed research successes in the pas
t 20 years. While the panel focused on the past, this article discusse
s successes since the ACM SIGMM 2003 Retreat and suggests research dir
ections in the next ten years. While significant progress has been mad
e, more research is required to allow multimedia to impact our everyda
y computing environment. The importance of hardware changes on future 
research directions is discussed. We believe ubiquitous computing—mean
ing abundant computation and network bandwidth—should be applied in no
vel ways to solve multimedia grand challenges and continue the IT revo
lution of the past century.
AU  - Rowe, Lawrence A.
DA  - 2013/10//
PY  - 2013
DO  - 10.1145/2490825
ID  - 10.1145/2490825
IS  - 1s
KW  - Multimedia research directions
SN  - 1551-6857
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
TI  - Looking forward 10 years to multimedia successes
UR  - https://doi.org/10.1145/2490825
VL  - 9
ER  - 
TY  - CONF
AB  - We present preliminary findings from sharing and augmenting facial exp
ression in cooperative social Virtual Reality (VR) games. We implement
ed a prototype system for capturing and sharing facial expression betw
een VR players through their avatar. We describe our current prototype
 system and how it could be assimilated into a system for enhancing so
cial VR experience. Two social VR games were created for a preliminary
 study. We discuss our findings from our pilots, potential games for t
his system, and future directions for this research.
AU  - Hart, Jonathon D.
AU  - Piumsomboon, Thammathip
AU  - Lawrence, Louise
AU  - Lee, Gun A.
AU  - Smith, Ross T.
AU  - Billinghurst, Mark
C1  - Melbourne, VIC, Australia
C3  - Proceedings of the 2018 Annual Symposium on Computer-Human Interaction
 in Play Companion Extended Abstracts
DA  - 2018///
C2  - 2018
DO  - 10.1145/3270316.3271543
ID  - 10.1145/3270316.3271
KW  - virtual reality
KW  - facial expression
KW  - emotion sharing
KW  - emotion augmentation
KW  - computer games.
PB  - Association for Computing Machinery
SN  - 9781450359689
SP  - 453-460
T3  - CHI PLAY '18 Extended Abstracts
TI  - Emotion Sharing and Augmentation in Cooperative Virtual Reality Games
UR  - https://doi.org/10.1145/3270316.3271543
ER  - 
TY  - BOOK
CY  - Stockholm, Sweden
DA  - 2024///
PY  - 2024
ID  - 10.1145/3672406
PB  - Association for Computing Machinery
SN  - 9798400717949
TI  - IMXw '24: Proceedings of the 2024 ACM International Conference on Inte
ractive Media Experiences Workshops
ER  - 
TY  - CONF
AB  - Our everyday technologies could have appeared terrifying to our ancest
ors: instantaneous disembodied communication, access to knowledge, obj
ects with ‘intelligence’ that talk to us (and each other). Black boxes
 and intangible entities are omnipresent in our homes and lives withou
t our necessarily understanding the hidden flows of data, unknown agen
das, imaginary clouds, and mysterious rules that govern them. Have hum
anity's ways of relating to the unknown throughout history gone away, 
or have they perhaps transmuted into new forms? In an ongoing project,
 we have inventoried examples, encounters and reflections on contempor
ary technology, framed through the perspective of the haunted, spectra
l and otherworldly. In this paper, we excerpt this collection to illus
trate the value and opportunity of an unfamiliar, disquieting perspect
ive in helping to frame the frictions, beliefs and myths that are emer
ging around interactions with everyday technologies. We posit and demo
nstrate ‘spooky technology’ as an accessible framework to reflect and 
respond to our increasingly entangled relationships with technology.
AU  - Byrne, Daragh
AU  - Lockton, Dan
AU  - Hu, Meijie
AU  - Luong, Miranda
AU  - Ranade, Anuprita
AU  - Escarcha, Karen
AU  - Giesa, Katherine
AU  - Huang, Yiwei
AU  - Yochum, Catherine
AU  - Robertson, Gordon
AU  - Yeung, Lisa (Yip Yan)
AU  - Cruz, Matthew
AU  - Danner, Christi
AU  - Wang, Elizabeth
AU  - Khurana, Malika
AU  - Chen, Zhenfang
AU  - Heyison, Alexander
AU  - Fu, Yixiao
C1  - Virtual Event, Australia
C3  - Proceedings of the 2022 ACM Designing Interactive Systems Conference
DA  - 2022///
C2  - 2022
DO  - 10.1145/3532106.3533547
ID  - 10.1145/3532106.3533
KW  - Research through design
KW  - disembodied interaction
KW  - entanglement HCI
KW  - everyday tech
KW  - hauntology
KW  - invisible
KW  - numinous
KW  - otherworldly
KW  - spooky
PB  - Association for Computing Machinery
SN  - 9781450393584
SP  - 759-775
T3  - DIS '22
TI  - Spooky Technology: The ethereal and otherworldly as a resource for des
ign
UR  - https://doi.org/10.1145/3532106.3533547
ER  - 
TY  - CONF
AB  - Human-AI co-creativity involves humans and AI collaborating on a share
d creative product as partners. In a creative collaboration, communica
tion is an essential component among collaborators. In many existing c
o-creative systems, users can communicate with the AI, usually using b
uttons or sliders. Typically, the AI in co-creative systems cannot com
municate back to humans, limiting their potential to be perceived as p
artners rather than just a tool. This paper presents a study with 38 p
articipants to explore the impact of two interaction designs, with and
 without AI-to-human communication, on user engagement, collaborative 
experience and user perception of a co-creative AI. The study involves
 user interaction with two prototypes of a co-creative system that con
tributes sketches as design inspirations during a design task. The res
ults show improved collaborative experience and user engagement with t
he system incorporating AI-to-human communication. Users perceive co-c
reative AI as more reliable, personal, and intelligent when the AI com
municates to users. The findings can be used to design effective co-cr
eative systems, and the insights can be transferred to other fields in
volving human-AI interaction and collaboration.
AU  - Rezwana, Jeba
AU  - Maher, Mary Lou
C1  - Venice, Italy
C3  - Proceedings of the 14th Conference on Creativity and Cognition
DA  - 2022///
C2  - 2022
DO  - 10.1145/3527927.3532789
ID  - 10.1145/3527927.3532
KW  - AI to human Communication
KW  - Co-creativity
KW  - Human-AI Communication
KW  - Human-AI Creative Collaboration
KW  - Interaction design
PB  - Association for Computing Machinery
SN  - 9781450393270
SP  - 38-48
T3  - C&amp;C '22
TI  - Understanding User Perceptions, Collaborative Experience and User Enga
gement in Different Human-AI Interaction Designs for Co-Creative Syste
ms
UR  - https://doi.org/10.1145/3527927.3532789
ER  - 
TY  - CONF
AB  - Many shape-changing interfaces use an array of actuated rods to create
 a display surface; each rod working as a pixel. However, this approac
h only supports pixel height manipulation and cannot produce more radi
cal shape changes of each pixel (and thus of the display). Examples of
 such changes include non-horizontal pixels, pixels that overhang othe
r pixels, or variable gaps between pixels. We present a concept for co
mposing shape-changing interfaces by vertically stacking tilt-enabled 
modules. Together, stacking and tilting allow us to create a more dive
rse range of display surfaces than using arrays. We demonstrate this c
oncept through TiltStacks, a shape-changing prototype built using stac
ked linear actuators and displays. Each tiltable module provides three
 degrees of freedom (z-movement, roll, and pitch); two more degrees of
 freedom are added through stacking modules (i.e., planar x- and y-mov
ement).
AU  - Tiab, John
AU  - Boring, Sebastian
AU  - Strohmeier, Paul
AU  - Markussen, Anders
AU  - Alexander, Jason
AU  - Hornbæk, Kasper
C1  - Castiglione della Pescaia, Grosseto, Italy
C3  - Proceedings of the 2018 International Conference on Advanced Visual In
terfaces
DA  - 2018///
C2  - 2018
DO  - 10.1145/3206505.3206530
ID  - 10.1145/3206505.3206
KW  - compositional concept
KW  - shape-changing interfaces
KW  - stacking
KW  - tilting
PB  - Association for Computing Machinery
SN  - 9781450356169
T3  - AVI '18
TI  - Tiltstacks: composing shape-changing interfaces using tilting and stac
king of modules
UR  - https://doi.org/10.1145/3206505.3206530
ER  - 
TY  - CONF
AB  - Recent emerging technologies in graphics computation, computer vision,
 tracking techniques, and display hardware have been accelerating tran
sferring augmented reality (AR) applications to wider, realistic use s
cenarios. While AR technologies are maturing, studying appropriate int
eractions for AR becomes equally significant. Driven by this strong ne
ed, in this paper we focus on discussing advance interactions for crea
ting, manipulating, and authoring virtual contents in an intuitive man
ner. We propose to investigate AR interactions for traditional casual 
applications such as visualizing contents within context, and for comp
lex situations including In-Situ 3D modeling using AR. From our previo
us works, multi-modal wearable inputs, 3D interactions around mobile d
evices, and context aware touch inputs have been explored for differen
t applications. Moreover, my on-going research projects and future res
earch directions are structured in the later sections of the paper.
AU  - Huo, Ke
C1  - Yokohama, Japan
C3  - Proceedings of the Eleventh International Conference on Tangible, Embe
dded, and Embodied Interaction
DA  - 2017///
C2  - 2017
DO  - 10.1145/3024969.3025044
ID  - 10.1145/3024969.3025
KW  - 3d interaction
KW  - augmented reality
KW  - mixed reality
KW  - sketch-based 3d modeling
KW  - tangible interaction
PB  - Association for Computing Machinery
SN  - 9781450346764
SP  - 725-728
T3  - TEI '17
TI  - Exploring Advance Interactions for Augmented Reality: From Casual Acti
vities to In-Situ 3D Modeling
UR  - https://doi.org/10.1145/3024969.3025044
ER  - 
TY  - CONF
AB  - Industrial designers have a tangible working style. However, compared 
to digital data, physical mockups are difficult to copy and share over
 distance. They require a lot of physical space, and earlier versions 
are lost once they are modified. In this paper, we introduce Catch-Up 
360, a tool designed for sharing physical mockups over distance to gai
n feedback from remote located designers, and compare current models w
ith earlier versions. Summarizing, our approach provides a simple, int
uitive, and tangible UI that supports the use of lightweight, web-base
d clients by using remote manipulation of the physical objects.
AU  - Perteneder, Florian
AU  - Grossauer, Eva-Maria
AU  - Xu, Yan
AU  - Haller, Michael
C1  - Stanford, California, USA
C3  - Proceedings of the Ninth International Conference on Tangible, Embedde
d, and Embodied Interaction
DA  - 2015///
C2  - 2015
DO  - 10.1145/2677199.2680564
ID  - 10.1145/2677199.2680
KW  - history
KW  - industrial design
KW  - physical mockups
KW  - sharing objects
KW  - tangible user interface
PB  - Association for Computing Machinery
SN  - 9781450333054
SP  - 105-108
T3  - TEI '15
TI  - Catch-Up 360: Digital Benefits for Physical Artifacts
UR  - https://doi.org/10.1145/2677199.2680564
ER  - 
TY  - JOUR
AB  - Gastroenterological endoscopic surgery needs complex surgical skills s
uch as a sensation of body movement and manipulation of the endoscope 
that is hard to be explained verbally. Prior research reported that en
doscopic surgery is one of the most challenging surgery to teach. Thus
, surgeons need long-term practice to master the skills. To support le
arning such skills, we developed a surgical scene replay system. First
, we surveyed 12 surgeons to reveal the reason for the difficulty and 
elicited three requirements for our system: (1) provide multiple video
s that include an endoscope, a fluoroscopy, and hand manipulation for 
the endoscope to observe the surgery from multiple aspects; (2) visual
ize an experts' gaze position to understand experts' intention of hand
 manipulation, and (3) enlarge the size of the gazed video to inform l
earners where they should pay attention to. Our user study with the sy
stem indicates that participants could understand the experts' intenti
ons and tacit knowledge easier than the existing video materials.
AU  - Matsuda, Akira
AU  - Okuzono, Toru
AU  - Nakamura, Hiromi
AU  - Kuzuoka, Hideaki
AU  - Rekimoto, Jun
DA  - 2021/5//
PY  - 2021
DO  - 10.1145/3461726
ID  - 10.1145/3461726
IS  - EICS
KW  - gastroenterological endoscopic surgery
KW  - gaze
KW  - multiple videos
KW  - skill learning
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - A Surgical Scene Replay System for Learning Gastroenterological Endosc
opic Surgery Skill by Multiple Synchronized-Video and Gaze Representat
ion
UR  - https://doi.org/10.1145/3461726
VL  - 5
ER  - 
TY  - JOUR
AB  - Augmented virtual reality (AVR) takes portions of the physical world i
nto the VR world to enable VR users to access physical objects. State-
of-the-art solutions mainly focus on extracting and showing physical o
bjects in the VR world. In this work, we go beyond previous solutions 
and propose a novel approach to realize AVR. We first analyze the phys
ical environment in the user's egocentric view through depth sensing a
nd deep learning, then acquire the layout and geometry of the surround
ing objects, and further explore their affordances. Based on the above
 information, we create visual guidance (hollowed guiding path) and hy
brid user interfaces (augmented physical notepad, LR finger slider, an
d LRRL finger slider) to augment the AVR interaction. Empirical evalua
tions showed that the participants responded positively to our AVR tec
hniques.
AU  - Tian, Yang
AU  - Fu, Chi-Wing
AU  - Zhao, Shengdong
AU  - Li, Ruihui
AU  - Tang, Xiao
AU  - Hu, Xiaowei
AU  - Heng, Pheng-Ann
DA  - 2019/9//
PY  - 2019
DO  - 10.1145/3351263
ID  - 10.1145/3351263
IS  - 3
KW  - visual tool
KW  - visual guidance
KW  - virtual reality
KW  - scene analysis
KW  - egocentric view
KW  - depth sensing
KW  - deep learning
KW  - augmented VR interaction
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
TI  - Enhancing Augmented VR Interaction via Egocentric Scene Analysis
UR  - https://doi.org/10.1145/3351263
VL  - 3
ER  - 
TY  - CONF
AB  - This paper is a summation of a decade of support for X3D, human-comput
er Interaction, and networked graphics that occurred at the Networked 
Media Laboratory, Communications Research Centre, Canada.
AU  - Stewart, John A.
AU  - Dumoulin, Sarah
AU  - Noël, Sylvie
C1  - Los Angeles, California
C3  - Proceedings of the 15th International Conference on Web 3D Technology
DA  - 2010///
C2  - 2010
DO  - 10.1145/1836049.1836054
ID  - 10.1145/1836049.1836
KW  - CRC
KW  - FreeWRL
KW  - NML
KW  - X3D
KW  - multicast
KW  - peer to peer
KW  - shared virtual worlds
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450302098
SP  - 27-34
T3  - Web3D '10
TI  - A decade of NML networked graphics
UR  - https://doi.org/10.1145/1836049.1836054
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3721257
PB  - Association for Computing Machinery
SN  - 9798400715518
TI  - SIGGRAPH '25: ACM SIGGRAPH 2025 Emerging Technologies
ER  - 
TY  - CONF
AB  - In the physical world, teammates develop situation awareness about eac
h other's location, status, and actions through cues such as gaze dire
ction and ambient noise. To support situation awareness, distributed m
ultiplayer games provide awareness cues - information that games autom
atically make available to players to support cooperative gameplay. Th
e design of awareness cues can be extremely complex, impacting how pla
yers experience games and work with teammates. Despite the importance 
of awareness cues, designers have little beyond experiential knowledge
 to guide their design. In this work, we describe a design framework f
or awareness cues, providing insight into what information they provid
e, how they communicate this information, and how design choices can i
mpact play experience. Our research, based on a grounded theory analys
is of current games, is the first to provide a characterization of awa
reness cues, providing a palette for game designers to improve design 
practice and a starting point for deeper research into collaborative p
lay.
AU  - Wuertz, Jason
AU  - Alharthi, Sultan A.
AU  - Hamilton, William A.
AU  - Bateman, Scott
AU  - Gutwin, Carl
AU  - Tang, Anthony
AU  - Toups Dugas, Phoebe O.
AU  - Hammer, Jessica
C1  - Montreal QC, Canada
C3  - Proceedings of the 2018 CHI Conference on Human Factors in Computing S
ystems
DA  - 2018///
C2  - 2018
DO  - 10.1145/3173574.3173817
ID  - 10.1145/3173574.3173
KW  - awareness cues
KW  - distributed multiplayer games
KW  - game design
KW  - situation awareness
KW  - workspace awareness
PB  - Association for Computing Machinery
SN  - 9781450356206
SP  - 1-14
T3  - CHI '18
TI  - A Design Framework for Awareness Cues in Distributed Multiplayer Games

UR  - https://doi.org/10.1145/3173574.3173817
ER  - 
TY  - BOOK
CY  - Tsukuba, Japan
DA  - 2022///
PY  - 2022
ID  - 10.1145/3562939
PB  - Association for Computing Machinery
SN  - 9781450398893
TI  - VRST '22: Proceedings of the 28th ACM Symposium on Virtual Reality Sof
tware and Technology
ER  - 
TY  - BOOK
CY  - Pittsburgh, PA, USA
DA  - 2023///
PY  - 2023
ID  - 10.1145/3626485
PB  - Association for Computing Machinery
SN  - 9798400704253
TI  - ISS Companion '23: Companion Proceedings of the 2023 Conference on Int
eractive Surfaces and Spaces
ER  - 
TY  - CONF
AB  - Modern reservoir engineering is dependent on 3D visualization tools. H
owever, as we argue in this paper, the current tools used in this doma
in are not completely aligned with the reservoir engineer's interactiv
e needs, and do not address fundamental user issues, such as collabora
tion. We base our work on a set of observations of reservoir engineers
, and their unique interactive tasks and needs. We present insightful 
knowledge of the domain, and follow with a prototype for an interactiv
e reservoir visualization system, on the Microsoft Surface. We conclud
e by presenting a design critique we performed using our prototype, an
d reflecting on the impact we believe tabletop interaction will have o
n the domain of reservoir engineering.
AU  - Sultanum, Nicole
AU  - Sharlin, Ehud
AU  - Sousa, Mario Costa
AU  - Miranda-Filho, Daniel N.
AU  - Eastick, Rob
C1  - Saarbrücken, Germany
C3  - ACM International Conference on Interactive Tabletops and Surfaces
DA  - 2010///
C2  - 2010
DO  - 10.1145/1936652.1936671
ID  - 10.1145/1936652.1936
KW  - collaboration
KW  - reservoir engineering
KW  - tabletop
KW  - tangible user interface
KW  - visualization system
PB  - Association for Computing Machinery
SN  - 9781450303996
SP  - 105-108
T3  - ITS '10
TI  - Touching the depths: introducing tabletop interaction to reservoir eng
ineering
UR  - https://doi.org/10.1145/1936652.1936671
ER  - 
TY  - CONF
AB  - Many teamwork tasks require a close coupling between the interactions 
of members of a team. For example, intention and opinion must be commu
nicated, while synchronously manipulating shared artefacts. In face-to
-face interaction this communication and manipulation is seamless. Tra
nsferring the straightforwardness of such collaboration onto remote lo
cated teams is technologically challenging. This survey paper explains
 why immersive collaborative virtual environments (CVE) suit such task
s. The effectiveness of application of this technology depends on a co
mplex set of factors that determine the efficiency of collaboration. W
e examine these factors and their interrelationships within the framew
ork of a taxonomy focussed on supporting closely-coupled collaboration
 using immersive CVEs. In particular we compare the impact of display 
configurations from distinct aspects within the interaction metaphors:
 look-in, reach-in and step-in.
AU  - Otto, Oliver
AU  - Roberts, Dave
AU  - Wolff, Robin
C1  - Hong Kong, China
C3  - Proceedings of the 2006 ACM International Conference on Virtual Realit
y Continuum and Its Applications
DA  - 2006///
C2  - 2006
DO  - 10.1145/1128923.1128947
ID  - 10.1145/1128923.1128
KW  - closely-coupled collaboration
KW  - immersive CVEs
KW  - object interaction
PB  - Association for Computing Machinery
SN  - 1595933247
SP  - 145-154
T3  - VRCIA '06
TI  - A review on effective closely-coupled collaboration using immersive CV
E's
UR  - https://doi.org/10.1145/1128923.1128947
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3681756
PB  - Association for Computing Machinery
SN  - 9798400711381
TI  - SA '24: SIGGRAPH Asia 2024 Posters
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3737821
PB  - Association for Computing Machinery
SN  - 9798400719707
TI  - MobileHCI '25 Adjunct: Adjunct Proceedings of the 27th International C
onference on Mobile Human-Computer Interaction
ER  - 
TY  - CONF
AB  - Vision-based 3D pose estimation has substantial potential in hand-obje
ct interaction applications and requires user-specified datasets to ac
hieve robust performance. We propose ARnnotate, an Augmented Reality (
AR) interface enabling end-users to create custom data using a hand-tr
acking-capable AR device. Unlike other dataset collection strategies, 
ARnnotate first guides a user to manipulate a virtual bounding box and
 records its poses and the user’s hand joint positions as the labels. 
By leveraging the spatial awareness of AR, the user manipulates the co
rresponding physical object while following the in-situ AR animation o
f the bounding box and hand model, while ARnnotate captures the user’s
 first-person view as the images of the dataset. A 12-participant user
 study was conducted, and the results proved the system’s usability in
 terms of the spatial accuracy of the labels, the satisfactory perform
ance of the deep neural networks trained with the data collected by AR
nnotate, and the users’ subjective feedback.
AU  - Qian, Xun
AU  - He, Fengming
AU  - Hu, Xiyun
AU  - Wang, Tianyi
AU  - Ramani, Karthik
C1  - Bend, OR, USA
C3  - Proceedings of the 35th Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2022///
C2  - 2022
DO  - 10.1145/3526113.3545663
ID  - 10.1145/3526113.3545
KW  - Hand-Object Interaction
KW  - Dataset Collection
KW  - Augmented Reality
KW  - 3D Pose Estimation
PB  - Association for Computing Machinery
SN  - 9781450393201
T3  - UIST '22
TI  - ARnnotate: An Augmented Reality Interface for Collecting Custom Datase
t of 3D Hand-Object Interaction Pose Estimation
UR  - https://doi.org/10.1145/3526113.3545663
ER  - 
TY  - BOOK
CY  - Athens, Greece
DA  - 2023///
PY  - 2023
ID  - 10.1145/3565066
PB  - Association for Computing Machinery
SN  - 9781450399241
TI  - MobileHCI '23 Companion: Proceedings of the 25th International Confere
nce on Mobile Human-Computer Interaction
ER  - 
TY  - CONF
AB  - New technologies for autism focus on the training of either social ski
lls or motor skills, but not both. Such a dichotomy omits a wide range
 of joint action tasks that require the coordination of two persons (e
.g. moving a heavy furniture). The training of these physical tasks pe
rformed in dyad has great potential to foster inclusiveness while havi
ng an impact on both social and motor skills. In this paper, we presen
t the design of a tangible and virtual interactive system for the trai
ning of children with Autism Spectrum Disorder (ASD) in performing joi
nt actions. The proposed system is composed of a virtual character pro
jected onto a surface on which a tangible object is magnetized: both t
he user and the virtual character hold the object, thus simulating a j
oint action. We report and discuss preliminary results of a field trai
ning study, which shows the potential of the interactive system.
AU  - Giraud, Tom
AU  - Ravenet, Brian
AU  - Tai Dang, Chi
AU  - Nadel, Jacqueline
AU  - Prigent, Elise
AU  - Poli, Gael
AU  - Andre, Elisabeth
AU  - Martin, Jean-claude
C1  - Salzburg, Austria
C3  - Proceedings of the Fifteenth International Conference on Tangible, Emb
edded, and Embodied Interaction
DA  - 2021///
C2  - 2021
DO  - 10.1145/3430524.3440646
ID  - 10.1145/3430524.3440
KW  - Joint action
KW  - autism
KW  - tangible interaction
KW  - virtual agent
PB  - Association for Computing Machinery
SN  - 9781450382137
T3  - TEI '21
TI  - “Can you help me move this over there?”: training children with ASD to
 joint action through tangible interaction and virtual agent
UR  - https://doi.org/10.1145/3430524.3440646
ER  - 
TY  - CONF
AB  - We are a mother and son who have been using a pair of simple, self-bui
ld communication devices to maintain a feeling of connection while sep
arated by over 5,000 miles. The devices, called Light Touch, only allo
w us to send one another slowly-fading, coloured lights, yet we have b
een surprised by how much our ongoing interaction with them means to u
s. This paper contributes an autoethnographical account of our experie
nces over the last two years, including our initial experiences with t
he devices, and focusing on various aspects of our day-to-day use. Bas
ed on our observations, we discuss the features that have proven impor
tant in mediating our feelings of connection. We point out, however, t
hat their success is contingent on our context of use and the nature o
f our bond, and suggest that simple systems like Light Touch may suppo
rt emotional communication, but only if they are well-matched to setti
ngs and relationships.
AU  - Gaver, William
AU  - Gaver, Frances
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI Conference on Human Factors in Computing S
ystems
DA  - 2023///
C2  - 2023
DO  - 10.1145/3544548.3580807
ID  - 10.1145/3544548.3580
KW  - IoT
KW  - autobiographical design
KW  - autoethnography
KW  - emotional communication
KW  - open source
KW  - research through design
KW  - self-build
PB  - Association for Computing Machinery
SN  - 9781450394215
T3  - CHI '23
TI  - Living with Light Touch: An Autoethnography of a Simple Communication 
Device in Long-Term Use
UR  - https://doi.org/10.1145/3544548.3580807
ER  - 
TY  - CONF
AB  - We have proposed novel tactile display that presents high-fidelity tac
tile information by achieving a very wide frequency bandwidth. The sys
tem is composed of one or two speakers. Users hold the speakers betwee
n their hands while the speakers vibrate the air between the speakers 
and their palms. The user feels suction or pushing pressure on their p
alms from the air. Due to the very wide frequency range (1 Hz and belo
w to 1 kHz and above), users can feel a variety of sensations. Further
more, due to the indirect drive of the palm through the air, users fee
l uniform pressure without any feeling of the edges or shapes of hard 
contactors, which are necessary for an ordinary haptic interface to co
nvey high frequency signals. In this paper, we introduce three applica
tion ideas by using this display that enable us to experience rich tac
tile expressions. We also show some pilot studies to realize these ide
as, first implementations of them and result of exhibition.
AU  - Hashimoto, Yuki
AU  - Nakata, Satsuki
AU  - Kajimoto, Hiroyuki
C1  - Athens, Greece
C3  - Proceedings of the International Conference on Advances in Computer En
tertainment Technology
DA  - 2009///
C2  - 2009
DO  - 10.1145/1690388.1690410
ID  - 10.1145/1690388.1690
KW  - air pressure
KW  - emotion
KW  - hi-fi
KW  - palm
KW  - speaker
KW  - tactile sensation
PB  - Association for Computing Machinery
SN  - 9781605588643
SP  - 124-131
T3  - ACE '09
TI  - Novel tactile display for emotional tactile experience
UR  - https://doi.org/10.1145/1690388.1690410
ER  - 
TY  - CONF
AB  - Social Virtual Reality (VR) is growing for remote socialization and co
llaboration. However, current social VR applications are not accessibl
e to people with visual impairments (PVI) due to their focus on visual
 experiences. We aim to facilitate social VR accessibility by enhancin
g PVI’s peripheral awareness of surrounding avatar dynamics. We design
ed VRBubble, an audio-based VR technique that provides surrounding ava
tar information based on social distances. Based on Hall’s proxemic th
eory, VRBubble divides the social space with three Bubbles—Intimate, C
onversation, and Social Bubble—generating spatial audio feedback to di
stinguish avatars in different bubbles and provide suitable avatar inf
ormation. We provide three audio alternatives: earcons, verbal notific
ations, and real-world sound effects. PVI can select and combine their
 preferred feedback alternatives for different avatars, bubbles, and s
ocial contexts. We evaluated VRBubble and an audio beacon baseline wit
h 12 PVI in a navigation and a conversation context. We found that VRB
ubble significantly enhanced participants’ avatar awareness during nav
igation and enabled avatar identification in both contexts. However, V
RBubble was shown to be more distracting in crowded environments.
AU  - Ji, Tiger F.
AU  - Cochran, Brianna
AU  - Zhao, Yuhang
C1  - Athens, Greece
C3  - Proceedings of the 24th International ACM SIGACCESS Conference on Comp
uters and Accessibility
DA  - 2022///
C2  - 2022
DO  - 10.1145/3517428.3544821
ID  - 10.1145/3517428.3544
KW  - audio feedback
KW  - proxemics
KW  - social virtual reality
KW  - visual impairments
PB  - Association for Computing Machinery
SN  - 9781450392587
T3  - ASSETS '22
TI  - VRBubble: Enhancing Peripheral Awareness of Avatars for People with Vi
sual Impairments in Social Virtual Reality
UR  - https://doi.org/10.1145/3517428.3544821
ER  - 
TY  - CONF
AB  - Creativity is an important part of children’s education. Tangible User
 Interfaces&nbsp;(TUIs) provide new possibilities for creative learnin
g. In this review, we gave an overview of recent studies that supporte
d children’s creative learning using TUIs. Results showed that TUIs ha
d many advantages, such as they (1)&nbsp;were novice-friendly, (2)&nbs
p;supported children’s cognitive process and development, (3)&nbsp;pro
moted their initiatives, (4)&nbsp;enabled them to think outside the bo
x, and (5)&nbsp;encouraged communication and collaboration in an authe
ntic context. Meanwhile, we summarized previous work’s three main limi
tations: First, most of the studies did not have a long-term experimen
tal verification with sufficient sample size and objective evaluation;
 Second, some TUI designs lacked a balance of abstractness, openness, 
richness, and complexity; Finally, the use of TUIs had little consider
ation of the teacher’s role. Therefore, further research should focus 
more on the trans-disciplinary nature of TUIs for creative learning an
d leverage collaboration between human-computer interaction researcher
s and school teachers.
AU  - Liang, Meng
AU  - Li, Yanhong
AU  - Weber, Thomas
AU  - Hussmann, Heinrich
C1  - Virtual Event, Italy
C3  - Proceedings of the 13th Conference on Creativity and Cognition
DA  - 2021///
C2  - 2021
DO  - 10.1145/3450741.3465262
ID  - 10.1145/3450741.3465
KW  - TUI
KW  - children
KW  - creative learning
KW  - review
KW  - tangible interaction
KW  - tangible user interface
PB  - Association for Computing Machinery
SN  - 9781450383769
T3  - C&amp;C '21
TI  - Tangible Interaction for Children’s Creative Learning: A Review
UR  - https://doi.org/10.1145/3450741.3465262
ER  - 
TY  - JOUR
AB  - Artificial intelligence including deep learning and 3D reconstruction 
methods is changing the daily life of people. Now, an unmanned aerial 
vehicle that can move freely in the air and avoid harsh ground conditi
ons has been commonly adopted as a suitable tool for 3D reconstruction
. The traditional 3D reconstruction mission based on drones usually co
nsists of two steps: image collection and offline post-processing. But
 there are two problems: one is the uncertainty of whether all parts o
f the target object are covered, and another is the tedious post-proce
ssing time. Inspired by modern deep learning methods, we build a telex
istence drone system with an onboard deep learning computation module 
and a wireless data transmission module that perform incremental real-
time dense reconstruction of urban cities by itself. Two technical con
tributions are proposed to solve the preceding issues. First, based on
 the popular depth fusion surface reconstruction framework, we combine
 it with a visual-inertial odometry estimator that integrates the iner
tial measurement unit and allows for robust camera tracking as well as
 high-accuracy online 3D scan. Second, the capability of real-time 3D 
reconstruction enables a new rendering technique that can visualize th
e reconstructed geometry of the target as navigation guidance in the H
MD. Therefore, it turns the traditional path-planning-based modeling p
rocess into an interactive one, leading to a higher level of scan comp
leteness. The experiments in the simulation system and our real protot
ype demonstrate an improved quality of the 3D model using our artifici
al intelligence leveraged drone system.
AU  - Zhang, Di
AU  - Xu, Feng
AU  - Pun, Chi-Man
AU  - Yang, Yang
AU  - Lan, Rushi
AU  - Wang, Liejun
AU  - Li, Yujie
AU  - Gao, Hao
DA  - 2021/9//
PY  - 2021
DO  - 10.1145/3458930
ID  - 10.1145/3458930
IS  - 1
KW  - 3D reconstruction
KW  - virtual reality
KW  - unmanned aerial vehicle
KW  - telexistence
KW  - human-robot-interaction
SN  - 1533-5399
T2  - ACM Trans. Internet Technol.
TI  - Virtual Reality Aided High-Quality 3D Reconstruction by Remote Drones
UR  - https://doi.org/10.1145/3458930
VL  - 22
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3721245
PB  - Association for Computing Machinery
SN  - 9798400715471
TI  - SIGGRAPH Immersive Pavilion '25: Proceedings of the Special Interest G
roup on Computer Graphics and Interactive Techniques Conference Immers
ive Pavilion
ER  - 
TY  - JOUR
AB  - The metaverse presents an emerging creative expression and collaborati
on frontier where generative artificial intelligence (GenAI) can play 
a pivotal role with its ability to generate multimodal content from si
mple prompts. These prompts allow the metaverse to interact with GenAI
, where context information, instructions, input data, or even output 
indications constituting the prompt can come from within the metaverse
. However, their integration poses challenges regarding interoperabili
ty, lack of standards, scalability, and maintaining a high-quality use
r experience. This article explores how GenAI can productively assist 
in enhancing creativity within the contexts of the metaverse and unloc
k new opportunities. We provide a technical, in-depth overview of the 
different generative models for image, video, audio, and 3D content wi
thin the metaverse environments. We also explore the bottlenecks, oppo
rtunities, and innovative applications of GenAI from the perspectives 
of end users, developers, service providers, and AI researchers. This 
survey commences by highlighting the potential of GenAI for enhancing 
the metaverse experience through dynamic content generation to populat
e massive virtual worlds. Subsequently, we shed light on the ongoing r
esearch practices and trends in multimodal content generation, enhanci
ng realism and creativity and alleviating bottlenecks related to stand
ardization, computational cost, privacy, and safety. Last, we share in
sights into promising research directions toward the integration of Ge
nAI with the metaverse for creative enhancement, improved immersion, a
nd innovative interactive applications.
AU  - El Saddik, Abdulmotaleb
AU  - Ahmad, Jamil
AU  - Khan, Mustaqeem
AU  - Abouzahir, Saad
AU  - Gueaieb, Wail
DA  - 2025/7//
PY  - 2025
DO  - 10.1145/3713075
ID  - 10.1145/3713075
IS  - 7
KW  - Generative AI
KW  - Metaverse
KW  - Diffusion Models
KW  - Generative Adversarial Networks
KW  - Multimodal
KW  - Content Generation
SN  - 1551-6857
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
TI  - Unleashing Creativity in the Metaverse: Generative AI and Multimodal C
ontent
UR  - https://doi.org/10.1145/3713075
VL  - 21
ER  - 
TY  - BOOK
AB  - The LSC workshops are participation workshops, where participants writ
e and present an academic paper describing their prototype lifelog ret
rieval system, and then take part in a live interactive search competi
tion. Consequently, the workshop is highly interactive and challenging
 for participants.
CY  - Phuket, Thailand
DA  - 2024///
PY  - 2024
ID  - 10.1145/3643489
PB  - Association for Computing Machinery
SN  - 9798400705502
TI  - LSC '24: Proceedings of the 7th Annual ACM Workshop on the Lifelog Sea
rch Challenge
ER  - 
TY  - CONF
AB  - In this paper, we introduce the design and implementation of TempoStri
ng, an easy-to-use tool which assists children with music creation. It
 provides such a fun and novel platform by allowing children to "draw"
 music on a canvas and then edit it using a rope. The main contributio
n of our work is the novel access which allows children to "paint" mus
ic on a canvas and then edit using a rope.
AU  - He, Liang
AU  - Li, Guang
AU  - Zhang, Yang
AU  - Wang, Danli
AU  - Wang, Hongan
C1  - Pittsburgh, Pennsylvania
C3  - Proceedings of the 2012 ACM Conference on Ubiquitous Computing
DA  - 2012///
C2  - 2012
DO  - 10.1145/2370216.2370345
ID  - 10.1145/2370216.2370
KW  - children
KW  - music creation
KW  - rope interaction
KW  - tangible interface
KW  - visual and audio feedback
PB  - Association for Computing Machinery
SN  - 9781450312240
SP  - 643-644
T3  - UbiComp '12
TI  - TempoString: a tangible tool for children's music creation
UR  - https://doi.org/10.1145/2370216.2370345
ER  - 
TY  - CONF
AB  - This paper presents a systematic literature review on collaborative te
chnologies for children with special needs in ACM Digital Library. The
 aim of the review is to (1) reveal the current state of the art, (2) 
identify the types of technologies and contexts of use, the demographi
cs and special needs of the target group, and the methodological appro
aches and theoretical groundings, and (3) define a future research age
nda. The results of the systematic literature review show that collabo
rative technologies for children with special needs are increasingly g
aining attention, mostly involve tangible and/or embodied interaction,
 and are often developed for use in the classroom. The target group th
at is most represented are boys between 6 to 12 years with Autism Spec
trum Disorder. The results further show a wide range of evaluation cri
teria for measuring collaboration, an interchanging use of theoretical
 concepts and a lack of definitions for the concept collaboration, and
 a need for more demographically diverse studies.
AU  - Baykal, Gökçe Elif
AU  - Van Mechelen, Maarten
AU  - Eriksson, Eva
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI Conference on Human Factors in Computing S
ystems
DA  - 2020///
C2  - 2020
DO  - 10.1145/3313831.3376291
ID  - 10.1145/3313831.3376
KW  - cci
KW  - collaboration
KW  - collaborative learning
KW  - collaborative technologies
KW  - special need
KW  - systematic literature review
PB  - Association for Computing Machinery
SN  - 9781450367080
SP  - 1-13
T3  - CHI '20
TI  - Collaborative Technologies for Children with Special Needs: A Systemat
ic Literature Review
UR  - https://doi.org/10.1145/3313831.3376291
ER  - 
TY  - CONF
AB  - Musical Instrument Digital Interface (midi) is a standard for music de
vice communication. Midi allows the exchange of information (pitch, ve
locity, duration of sound, and so on) between electronic instruments a
nd computers. Spatial sound is one of the ways to express sound and mu
sic, and also an important feature of virtual reality. By means of usi
ng spatial sound in virtual reality, the immersiveness of a user is en
hanced. In this research, we explore control of spatial sound using th
e Yamaha Tenori-On and the University of Aizu Business Innovation Cent
er (ubic) 3d Theater speaker array. This project explores the spatiali
zation of music, by mapping Tenori-On performances and sound localizat
ion in a single operation, allowing the notes to freely move around th
e room.
AU  - Sasamoto, Yuya
AU  - Villegas, Julı́an
AU  - Cohen, Michael
C1  - Aizu-Wakamatsu, Japan
C3  - Proceedings of the 13th International Conference on Humans and Compute
rs
DA  - 2010///
C2  - 2010
ID  - 10.5555/1994486.1994
PB  - University of Aizu Press
SP  - 62-65
T3  - HC '10
TI  - Spatial sound control with the Yamaha Tenori-On
ER  - 
TY  - CONF
AB  - Sharing full immersive experience in real-time has been the one of ult
imate goals of telecommunication. Possible application can include var
ious applications such as entertainment, sports viewing, education, so
cial network and professional assistance. Recent head-worn wearable ca
mera enables to shoot the first person video, however, view of angle i
s limited with the head direction of the person who is wearing, and al
so captured video is shaky that makes us dizzy. We propose JackIn Head
, an immersive experience sharing system with wearable camera headgear
 that provides 360 degrees spherical images of the user's surrounding 
environment. JackIn Head system performs spherical video stabilization
 and transmits it to other users, so that they are able to view shared
 video comfortably and also look around at the scene from a different 
view angle independently from the first person. In this note, we expla
in the overview of the JackIn Head system implementation, stabilizatio
n and viewing experience.
AU  - Kasahara, Shunichi
AU  - Rekimoto, Jun
C1  - Kobe, Japan
C3  - SIGGRAPH Asia 2015 Emerging Technologies
DA  - 2015///
C2  - 2015
DO  - 10.1145/2818466.2818486
ID  - 10.1145/2818466.2818
KW  - wearable computer
KW  - first person view streaming
KW  - 360 degrees spherical image
PB  - Association for Computing Machinery
SN  - 9781450339254
T3  - SA '15
TI  - JackIn head: an immersive human-human telepresence system
UR  - https://doi.org/10.1145/2818466.2818486
ER  - 
TY  - CONF
AB  - Interactive technologies offer novel opportunities for physically exte
nding our bodies, with the most prominent examples being prosthetics a
long with systems emerging from the wearables community. However, most
 such systems appear to focus on instrumental benefits, missing out on
 the opportunity to use bodily extensions for play and its associated 
benefits (including a lower adoption barrier and the potential to reve
al a broader understanding of such technologies). To begin understandi
ng the design of playful bodily extensions, we interviewed five design
ers of bodily extensions that have been showcased in prestigious acade
mic venues or turned into commercial products. Here we present themes 
and actionable advice from these interviews for the design of playful 
bodily extensions through a thematic analysis. Our work aims to suppor
t the design of future playful bodily extensions while promoting the e
xperiential qualities of bodily extension design, with the ultimate go
al of bringing more playful experiences to people’s lives.
AU  - Buruk, Oğuz 'Oz'
AU  - Matjeka, Louise Petersen
AU  - Mueller, Florian ‘Floyd’
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI Conference on Human Factors in Computing S
ystems
DA  - 2023///
C2  - 2023
DO  - 10.1145/3544548.3581165
ID  - 10.1145/3544548.3581
KW  - Bodily Extensions
KW  - Cyborg
KW  - Expert Interviews
KW  - Games
KW  - Play
KW  - Posthuman
KW  - Thematic Analysis
KW  - Transhuman
KW  - Wearables
PB  - Association for Computing Machinery
SN  - 9781450394215
T3  - CHI '23
TI  - Towards Designing Playful Bodily Extensions: Learning from Expert Inte
rviews
UR  - https://doi.org/10.1145/3544548.3581165
ER  - 
TY  - CONF
AB  - To illuminate the alignment between mixed reality juggling toys and am
bidextrous vactors twirling a projection of those toys, roomware light
ing control is deployed to show the modeled position of a virtual came
ra spinning around each player, even while the affordances are whirled
. "Tworlds" is a mixed reality multimodal toy using twirled juggling-s
tyle affordances built using mobile devices— smartphones, phablets, &a
mp; tablets— to modulate various displays, including 3D models and, no
w, environmental lighting. A unique feature of the projection is the p
reservation of logical alignment even when the virtual camera moves co
ntinuously around an avatar between frontal and dorsal views in an "in
spection gesture," phase-locked rotation and revolution (like the face
 of the moon pointing at the Earth). For example, a right-handed user 
would prefer to see their self-identified puppet holding an affordance
 in the right hand for dorsal (tethered) views, but would rather see t
he puppet switch hands for a frontal (mirrored) perspective. Because t
he projected phase of the toy must be modulated in order to preserve s
uch visual correspondence, even while the prop is being whirled, and t
o elucidate the inspection gesture, we use networked lighting (Philips
 Hue Wi-Fi networked bulbs) to indicate the position of the virtual ca
mera. Even though a toy might be twirled too fast for such lights to t
rack in the real world, so that only computer graphic "eye candy" effe
cts are practical, the speed of the orbiting of the virtual camera can
 be adjusted to accommodate even sluggish lighting switching.
AU  - Cohen, Michael
AU  - Ranaweera, Rasika
AU  - Ryskeldiev, Bektur
AU  - Oyama, Tomohiro
AU  - Hashimoto, Aya
AU  - Tsukida, Naoki
AU  - Miyaji, Toshimune
C1  - Shenzhen, China
C3  - SIGGRAPH Asia 2014 Mobile Graphics and Interactive Applications
DA  - 2014///
C2  - 2014
DO  - 10.1145/2669062.2669080
ID  - 10.1145/2669062.2669
KW  - cross-platform multimodal interface
KW  - exertion interface
KW  - mobile-ambient transmedia
KW  - practically panoramic
KW  - whole body interaction
PB  - Association for Computing Machinery
SN  - 9781450318914
T3  - SA '14
TI  - Multimodal mobile-ambient transmedial twirling with environmental ligh
ting to complement fluid perspective with phase-perturbed affordance p
rojection
UR  - https://doi.org/10.1145/2669062.2669080
ER  - 
TY  - CONF
AB  - We present Embodied Axes, a controller which supports selection operat
ions for 3D imagery and data visualisations in Augmented Reality. The 
device is an embodied representation of a 3D data space – each of its 
three orthogonal arms corresponds to a data axis or domain specific fr
ame of reference. Each axis is composed of a pair of tangible, actuate
d range sliders for precise data selection, and rotary encoding knobs 
for additional parameter tuning or menu navigation. The motor actuated
 sliders support alignment to positions of significant values within t
he data, or coordination with other input: e.g., mid-air gestures in t
he data space, touch gestures on the surface below the data, or anothe
r Embodied Axes device supporting multi-user scenarios. We conducted e
xpert enquiries in medical imaging which provided formative feedback o
n domain tasks and refinements to the design. Additionally, a controll
ed user study was performed and found that the Embodied Axes was overa
ll more accurate than conventional tracked controllers for selection t
asks.
AU  - Cordeil, Maxime
AU  - Bach, Benjamin
AU  - Cunningham, Andrew
AU  - Montoya, Bastian
AU  - Smith, Ross T.
AU  - Thomas, Bruce H.
AU  - Dwyer, Tim
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI Conference on Human Factors in Computing S
ystems
DA  - 2020///
C2  - 2020
DO  - 10.1145/3313831.3376613
ID  - 10.1145/3313831.3376
KW  - 3d visualisation
KW  - actuation
KW  - augmented reality
KW  - device
KW  - tangible interaction
PB  - Association for Computing Machinery
SN  - 9781450367080
SP  - 1-12
T3  - CHI '20
TI  - Embodied Axes: Tangible, Actuated Interaction for 3D Augmented Reality
 Data Spaces
UR  - https://doi.org/10.1145/3313831.3376613
ER  - 
TY  - CONF
AB  - In this paper, we present a novel collaboration tool, OmniGlobeVR, whi
ch is an asymmetric system that supports communication and collaborati
on between a VR user (occupant) and multiple non-VR users (designers) 
across the virtual and physical platform. OmniGlobeVR allows designer(
s) to explore the VR space from any point of view using two view modes
: a 360° first-person mode and a third-person mode. In addition, a sha
red gaze awareness cue is provided to further enhance communication be
tween the occupant and the designer(s). Finally, the system has a face
 window feature that allows designer(s) to share their facial expressi
ons and upper body view with the occupant for exchanging and expressin
g information using nonverbal cues. We conducted a user study to evalu
ate the OmniGlobeVR, comparing three conditions: (1) first-person mode
 with the face window, (2) first-person mode with a solid window, and 
(3) third-person mode with the face window. We found that the first-pe
rson mode with the face window required significantly less mental effo
rt, and provided better spatial presence, usability, and understanding
 of the partner's focus. We discuss the design implications of these r
esults and directions for future research.
AU  - Li, Zhengqing
AU  - Teo, Theophilus
AU  - Chan, Liwei
AU  - Lee, Gun
AU  - Adcock, Matt
AU  - Billinghurst, Mark
AU  - Koike, Hideki
C1  - Eindhoven, Netherlands
C3  - Proceedings of the 2020 ACM Designing Interactive Systems Conference
DA  - 2020///
C2  - 2020
DO  - 10.1145/3357236.3395429
ID  - 10.1145/3357236.3395
KW  - 360-degree camera
KW  - collaboration
KW  - communication
KW  - mixed reality
KW  - spherical display
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450369749
SP  - 615-625
T3  - DIS '20
TI  - OmniGlobeVR: A Collaborative 360-Degree Communication System for VR
UR  - https://doi.org/10.1145/3357236.3395429
ER  - 
TY  - JOUR
AB  - Interactive tabletops offer unique collaborative features, particularl
y their size, geometry, orientation and, more importantly, the ability
 to support multi-user interaction. Although previous efforts were mad
e to make interactive tabletops accessible to blind people, the potent
ial to use them in collaborative activities remains unexplored. In thi
s paper, we present the design and implementation of a multi-user audi
tory display for interactive tabletops, supporting three feedback mode
s that vary on how much information about the partners' actions is con
veyed. We conducted a user study with ten blind people to assess the e
ffect of feedback modes on workspace awareness and task performance. F
urthermore, we analyze the type of awareness information exchanged and
 the emergent collaboration strategies. Finally, we provide implicatio
ns for the design of future tabletop collaborative tools for blind use
rs.
AU  - Mendes, Daniel
AU  - Reis, Sofia
AU  - Guerreiro, João
AU  - Nicolau, Hugo
DA  - 2020/11//
PY  - 2020
DO  - 10.1145/3427325
ID  - 10.1145/3427325
IS  - ISS
KW  - tabletop
KW  - screen reader
KW  - collaboration
KW  - blind
KW  - awareness
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Collaborative Tabletops for Blind People: The Effect of Auditory Desig
n on Workspace Awareness
UR  - https://doi.org/10.1145/3427325
VL  - 4
ER  - 
TY  - CONF
AB  - Through videoconferencing, people search to interact and communicate w
ith their remote friends or family as they were together in the same p
lace. The influence of form variables such as screen size has been mai
nly investigated on the sense of physical presence (presence as transp
ortation) in virtual environment and in television area, but less atte
ntion has been paid to how these factors can influence the sense of co
-presence in videoconferencing. In addition, preferred viewing distanc
e is well known to be a key parameter in order to convey a sense of pr
esence and enjoyment when people watch television, but there is curren
tly no data regarding preferred viewing distance in videoconferencing.
 This paper presents a user study which explores the influence of scre
en size on the participant's sense of co-presence and on their preferr
ed viewing distance. The main results of this study revealed that user
s preferred to get closer to the screen when they communicated in vide
oconferencing than when they watched TV program. Our study suggests th
at screen size has an effect on the preferred viewing distance and on 
the participant's sense of co-presence, with higher scores of co-prese
nce with larger screen.
AU  - Dagonneau, Virginie
AU  - Martin, Elise
AU  - Cosquer, Mathilde
C1  - Laval, France
C3  - Proceedings of the 2014 Virtual Reality International Conference
DA  - 2014///
C2  - 2014
DO  - 10.1145/2617841.2620717
ID  - 10.1145/2617841.2620
KW  - co-presence
KW  - collaboration
KW  - communication
KW  - field of view
KW  - screen size
KW  - videoconferencing
KW  - viewing distance
PB  - Association for Computing Machinery
SN  - 9781450326261
T3  - VRIC '14
TI  - Collaborating &amp; being together: influence of screen size and viewi
ng distance during video communication
UR  - https://doi.org/10.1145/2617841.2620717
ER  - 
TY  - CONF
AB  - Construct3D is a three-dimensional geometric construction tool specifi
cally designed for mathematics and geometry education. It is based on 
the mobile collaborative augmented reality system "Studierstube." We d
escribe our efforts in developing a system for the improvement of spat
ial abilities and maximization of transfer of learning. In order to su
pport various teacher-student interaction scenarios we implemented fle
xible methods for context and user dependent rendering of parts of the
 construction. Together with hybrid hardware setups they allow the use
 of Construct3D in today's classrooms and provide a test bed for futur
e evaluations. Means of application and integration in mathematics and
 geometry education at the high school, as well as the university, lev
el are being discussed. Anecdotal evidence supports our claim that Con
struct3D is easy to learn, encourages experimentation with geometric c
onstructions, and improves spatial skills.
AU  - Kaufmann, Hannes
AU  - Schmalstieg, Dieter
C1  - San Antonio, Texas
C3  - ACM SIGGRAPH 2002 Conference Abstracts and Applications
DA  - 2002///
C2  - 2002
DO  - 10.1145/1242073.1242086
ID  - 10.1145/1242073.1242
KW  - augmented reality
KW  - geometry education
KW  - mathematics education
KW  - spatial intelligence
PB  - Association for Computing Machinery
SN  - 1581135254
SP  - 37-41
T3  - SIGGRAPH '02
TI  - Mathematics and geometry education with collaborative augmented realit
y
UR  - https://doi.org/10.1145/1242073.1242086
ER  - 
TY  - CONF
AB  - This paper investigates time-delay effects of the human social interac
tion to understand how human can adapt to the time delay, which will b
e required in software agents to establish a harmonic interaction with
 human. We performed the minimal experiments of social interaction cal
led perceptual crossing experiments with time delay. Our result shows 
that the social interaction breaks down when the total amount of time 
delay is given more than about one second. However, the interaction br
eaks more easily when the time delay is given to both participants tha
n to either participant.
AU  - Iizuka, Hiroyuki
AU  - Saitoh, Sohtaroh
AU  - Marocco, Davide
AU  - Yamamoto, Masahito
C1  - Daegu, Kyungpook, Republic of Korea
C3  - Proceedings of the 3rd International Conference on Human-Agent Interac
tion
DA  - 2015///
C2  - 2015
DO  - 10.1145/2814940.2814979
ID  - 10.1145/2814940.2814
KW  - minimal approach
KW  - perceptual crossing experiment
KW  - social interaction
KW  - time delay
PB  - Association for Computing Machinery
SN  - 9781450335270
SP  - 217-219
T3  - HAI '15
TI  - Time Delay Effect on Social Interaction Dynamics
UR  - https://doi.org/10.1145/2814940.2814979
ER  - 
TY  - CONF
AB  - The design space of social drones, where autonomous flyers operate in 
close proximity to human users or bystanders, is distinct from use cas
es involving a remote human operator and/or an uninhabited environment
; and warrants foregrounding human-centered design concerns. Recently,
 research on social drones has followed a trend of rapid growth. This 
paper consolidates the current state of the art in human-centered desi
gn knowledge about social drones through a review of relevant studies,
 scaffolded by a descriptive framework of design knowledge creation. O
ur analysis identified three high-level themes that sketch out knowled
ge clusters in the literature, and twelve design concerns which unpack
 how various dimensions of drone aesthetics and behavior relate to per
tinent human responses. These results have the potential to inform and
 expedite future research and practice, by supporting readers in defin
ing and situating their future contributions. The materials and result
s of our analysis are also published in an open online repository that
 intends to serve as a living hub for a community of researchers and d
esigners working with social drones.
AU  - Baytas, Mehmet Aydin
AU  - Çay, Damla
AU  - Zhang, Yuchong
AU  - Obaid, Mohammad
AU  - Yantaç, Asim Evren
AU  - Fjeld, Morten
C1  - Glasgow, Scotland Uk
C3  - Proceedings of the 2019 CHI Conference on Human Factors in Computing S
ystems
DA  - 2019///
C2  - 2019
DO  - 10.1145/3290605.3300480
ID  - 10.1145/3290605.3300
KW  - autonomous agents
KW  - design knowledge
KW  - drone design
KW  - drones
KW  - empirical studies
KW  - human-drone interaction
KW  - social drones
KW  - user studies
PB  - Association for Computing Machinery
SN  - 9781450359702
SP  - 1-13
T3  - CHI '19
TI  - The Design of Social Drones: A Review of Studies on Autonomous Flyers 
in Inhabited Environments
UR  - https://doi.org/10.1145/3290605.3300480
ER  - 
TY  - CONF
AB  - Past research recognized that paper has many advantages over digital d
evices, such as affordability, tangibility, and flexibility. Paper, ho
wever, also lacks many of the functionalities available in digital tec
hnologies, such as access to online resources and the ability to displ
ay interactive content. Prior research therefore identified opportunit
ies for fusing the two mediums into a combined interface. This work pr
esents a literature review on this form of innovation - technologies t
hat bridge the paper-digital gap. First, we synthesize an understandin
g of paper and its relationship with digital devices through the lens 
of past works. Then, we outline the state-of-the-art for paper-digital
 interfaces and highlight possible use cases and implementation approa
ches. Last, we discuss design considerations and future work for devel
oping paper-digital interfaces. Our work may be beneficial for HCI res
earchers interested in the development of hybrid paper-digital interfa
ces, and more broadly in embedding digital functionalities in everyday
 objects.
AU  - Han, Feng
AU  - Cheng, Yifei
AU  - Strachan, Megan
AU  - Ma, Xiaojuan
C1  - Virtual Event, USA
C3  - Proceedings of the 2021 ACM Designing Interactive Systems Conference
DA  - 2021///
C2  - 2021
DO  - 10.1145/3461778.3462059
ID  - 10.1145/3461778.3462
KW  - paper interfaces
KW  - paper computing
KW  - interactive paper
PB  - Association for Computing Machinery
SN  - 9781450384766
SP  - 1087-1100
T3  - DIS '21
TI  - Hybrid Paper-Digital Interfaces: A Systematic Literature Review
UR  - https://doi.org/10.1145/3461778.3462059
ER  - 
TY  - CONF
AB  - A primary goal of augmented reality (AR) is to seamlessly embed virtua
l content into a real environment. There are many factors that can aff
ect the perceived physicality and co-presence of virtual entities, inc
luding the hardware capabilities, the fidelity of the virtual behavior
s, and sensory feedback associated with the interactions. In this pape
r, we present a study investigating participants’ perceptions and beha
viors during a time-limited search task in close proximity with virtua
l entities in AR. In particular, we analyze the effects of (i) visual 
conflicts in the periphery of an optical see-through head-mounted disp
lay, a Microsoft HoloLens, (ii) overall lighting in the physical envir
onment, and (iii) multimodal feedback based on vibrotactile transducer
s mounted on a physical platform. Our results show significant benefit
s of vibrotactile feedback and reduced peripheral lighting for spatial
 and social presence, and engagement. We discuss implications of these
 effects for AR applications.
AU  - Richards, Kendra
AU  - Mahalanobis, Nikhil
AU  - Kim, Kangsoo
AU  - Schubert, Ryan
AU  - Lee, Myungho
AU  - Daher, Salam
AU  - Norouzi, Nahal
AU  - Hochreiter, Jason
AU  - Bruder, Gerd
AU  - Welch, Greg
C1  - New Orleans, LA, USA
C3  - Symposium on Spatial User Interaction
DA  - 2019///
C2  - 2019
DO  - 10.1145/3357251.3357585
ID  - 10.1145/3357251.3357
KW  - Augmented Reality
KW  - Field of View
KW  - Multimodal Feedback
KW  - Search Task
PB  - Association for Computing Machinery
SN  - 9781450369756
T3  - SUI '19
TI  - Analysis of Peripheral Vision and Vibrotactile Feedback During Proxima
l Search Tasks with Dynamic Virtual Entities in Augmented Reality
UR  - https://doi.org/10.1145/3357251.3357585
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3689050
PB  - Association for Computing Machinery
SN  - 9798400711978
TI  - TEI '25: Proceedings of the Nineteenth International Conference on Tan
gible, Embedded, and Embodied Interaction
ER  - 
TY  - BOOK
CY  - Christchurch, New Zealand
DA  - 2023///
PY  - 2023
ID  - 10.1145/3611659
PB  - Association for Computing Machinery
SN  - 9798400703287
TI  - VRST '23: Proceedings of the 29th ACM Symposium on Virtual Reality Sof
tware and Technology
ER  - 
TY  - CONF
AB  - Yo–Yo Machines are playful communication devices designed to help peop
le feel socially connected while physically separated. We designed the
m to reach as many people as possible, both to make a positive impact 
during the COVID-19 pandemic and to assess a self-build approach to ci
rculating research products and the appeal of peripheral and expressiv
e communication devices. A portfolio of four distinct designs, based o
n over 30 years of research, were made available for people to make by
 following simple online instructions (yoyomachines.io). Each involves
 connecting a pair of identical devices over the internet to allow sim
ple communication at a distance. This paper describes our motivation f
or the project, previous work in the area, the design of the devices, 
supporting website and publicity, and how users have made and used Yo-
Yo Machines. Finally, we reflect on what we learned about peripheral a
nd expressive communication devices and implications for the self-buil
d approach.
AU  - Gaver, William
AU  - Boucher, Andy
AU  - Brown, Dean
AU  - Chatting, David
AU  - Matsuda, Naho
AU  - Ovalle, Liliana
AU  - Sheen, Andy
AU  - Vanis, Michail
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI Conference on Human Factors in Computing S
ystems
DA  - 2022///
C2  - 2022
DO  - 10.1145/3491102.3517547
ID  - 10.1145/3491102.3517
KW  - IoT
KW  - design research
KW  - open source
KW  - peripheral and expressive communication
KW  - research through design
KW  - self-build
PB  - Association for Computing Machinery
SN  - 9781450391573
T3  - CHI '22
TI  - Yo–Yo Machines: Self-Build Devices that Support Social Connections Dur
ing the Pandemic
UR  - https://doi.org/10.1145/3491102.3517547
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3708359
PB  - Association for Computing Machinery
SN  - 9798400713064
TI  - IUI '25: Proceedings of the 30th International Conference on Intellige
nt User Interfaces
ER  - 
TY  - JOUR
AB  - Mobile Augmented Reality (MAR) integrates computer-generated virtual o
bjects with physical environments for mobile devices. MAR systems enab
le users to interact with MAR devices, such as smartphones and head-wo
rn wearables, and perform seamless transitions from the physical world
 to a mixed world with digital entities. These MAR systems support use
r experiences using MAR devices to provide universal access to digital
 content. Over the past 20 years, several MAR systems have been develo
ped, however, the studies and design of MAR frameworks have not yet be
en systematically reviewed from the perspective of user-centric design
. This article presents the first effort of surveying existing MAR fra
meworks (count: 37) and further discusses the latest studies on MAR th
rough a top-down approach: (1) MAR applications; (2) MAR visualisation
 techniques adaptive to user mobility and contexts; (3) systematic eva
luation of MAR frameworks, including supported platforms and correspon
ding features such as tracking, feature extraction, and sensing capabi
lities; (4) and underlying machine learning approaches supporting inte
lligent operations within MAR systems. Finally, we summarise the devel
opment of emerging research fields and the current state-of-the-art an
d discuss the important open challenges and possible theoretical and t
echnical directions. This survey aims to benefit both researchers and 
MAR system developers alike.
AU  - Cao, Jacky
AU  - Lam, Kit-Yung
AU  - Lee, Lik-Hang
AU  - Liu, Xiaoli
AU  - Hui, Pan
AU  - Su, Xiang
DA  - 2023/1//
PY  - 2023
DO  - 10.1145/3557999
ID  - 10.1145/3557999
IS  - 9
KW  - Mobile augmented reality
KW  - user interactions
KW  - development framework
KW  - artificial intelligence
KW  - metaverse
SN  - 0360-0300
T2  - ACM Comput. Surv.
TI  - Mobile Augmented Reality: User Interfaces, Frameworks, and Intelligenc
e
UR  - https://doi.org/10.1145/3557999
VL  - 55
ER  - 
TY  - CHAP
AB  - This book investigates multiple facets of the emerging discipline of T
angible, Embodied, and Embedded Interaction (TEI). This is a story of 
atoms and bits. We explore the interweaving of the physical and digita
l, toward understanding some of their wildly varying hybrid forms and 
behaviors. Spanning conceptual, philosophical, cognitive, design, and 
technical aspects of interaction, this book charts both history and as
pirations for the future of TEI. We examine and celebrate diverse trai
lblazing works, and provide wide-ranging conceptual and pragmatic tool
s toward weaving the animating fires of computation and technology int
o evocative tangible forms. We also chart a path forward for TEI engag
ement with broader societal and sustainability challenges that will pr
ofoundly (re)shape our children’s and grandchildren’s futures. We invi
te you all to join this quest.
CY  - New York, NY, USA
ID  - 10.1145/3544564.3544
PB  - Association for Computing Machinery
PY  - 2022
SN  - 9781450397698
T2  - Weaving Fire into Form: Aspirations for Tangible and Embodied Interact
ion
TI  - Paths Forward: Aspirations for TEI
UR  - https://doi.org/10.1145/3544564.3544577
ER  - 
TY  - CONF
AB  - The hardware research and development communities have invested heavil
y in tools and materials that facilitate the design and prototyping of
 electronic devices. Numerous easy-to-access and easy-to-use tools hav
e streamlined the prototyping of interactive and embedded devices for 
experts and led to a remarkable growth in non-expert builders. However
, there has been little exploration of challenges associated with movi
ng beyond a prototype and creating hundreds or thousands of exact repl
icas - a process that is still challenging for many. We interviewed 25
 individuals with experience taking prototype hardware devices into lo
w volume production. We systematically investigated the common issues 
faced and mitigation strategies adopted. We present our findings in fo
ur main categories: (1) gaps in technical knowledge; (2) gaps in non-t
echnical knowledge; (3) minimum viable rigor in manufacturing preparat
ion; and (4) building relationships and a professional network. Our st
udy unearthed several opportunities for new tools and processes to sup
port the transition beyond a working prototype to cost effective low-v
olume manufacturing. These would complement the aforementioned tools a
nd materials that support design and prototyping.
AU  - Khurana, Rushil
AU  - Hodges, Steve
C1  - Honolulu, HI, USA
C3  - Proceedings of the 2020 CHI Conference on Human Factors in Computing S
ystems
DA  - 2020///
C2  - 2020
DO  - 10.1145/3313831.3376761
ID  - 10.1145/3313831.3376
KW  - hardware device realization
KW  - long tail hardware
KW  - low volume electronics manufacturing
KW  - productization
PB  - Association for Computing Machinery
SN  - 9781450367080
SP  - 1-11
T3  - CHI '20
TI  - Beyond the Prototype: Understanding the Challenge of Scaling Hardware 
Device Production
UR  - https://doi.org/10.1145/3313831.3376761
ER  - 
TY  - BOOK
AB  - Throughout the week at SIGGRAPH 2017, attendees explore the fascinatin
g potential of real-time immersion in tomorrow's virtual and augmented
 realities for exploring new modes of communication, interaction, and 
in powering real-world applications in health, art, education, and gam
ing. Installations include:•Artistic and scientific installations•Noma
dic (untethered) VR•Collaborative and multi-person experiences•Games a
nd themed-entertainment•Unique interactive techniques
CY  - Los Angeles, California
DA  - 2017///
PY  - 2017
ID  - 10.1145/3089269
PB  - Association for Computing Machinery
SN  - 9781450350136
TI  - SIGGRAPH '17: ACM SIGGRAPH 2017 VR Village
ER  - 
TY  - CONF
AB  - We rely on our sight when manipulating objects. When objects are occlu
ded, manipulation becomes difficult. Such occluded objects can be show
n via augmented reality to re-enable visual guidance. However, it is u
nclear how to do so to best support object manipulation. We compare fo
ur views of occluded objects and their effect on performance and satis
faction across a set of everyday manipulation tasks of varying complex
ity. The best performing views were a see-through view and a displaced
 3D view. The former enabled participants to observe the manipulated o
bject through the occluder, while the latter showed the 3D view of the
 manipulated object offset from the object's real location. The worst 
performing view showed remote imagery from a simulated hand-mounted ca
mera. Our results suggest that alignment of virtual objects with their
 real-world location is less important than an appropriate point-of-vi
ew and view stability.
AU  - Lilija, Klemen
AU  - Pohl, Henning
AU  - Boring, Sebastian
AU  - Hornbæk, Kasper
C1  - Glasgow, Scotland Uk
C3  - Proceedings of the 2019 CHI Conference on Human Factors in Computing S
ystems
DA  - 2019///
C2  - 2019
DO  - 10.1145/3290605.3300676
ID  - 10.1145/3290605.3300
KW  - augmented reality
KW  - finger-camera
KW  - manipulation task
PB  - Association for Computing Machinery
SN  - 9781450359702
SP  - 1-12
T3  - CHI '19
TI  - Augmented Reality Views for Occluded Interaction
UR  - https://doi.org/10.1145/3290605.3300676
ER  - 
TY  - BOOK
CY  - Trier, Germany
DA  - 2024///
PY  - 2024
ID  - 10.1145/3677386
PB  - Association for Computing Machinery
SN  - 9798400710889
TI  - SUI '24: Proceedings of the 2024 ACM Symposium on Spatial User Interac
tion
ER  - 
TY  - CONF
AB  - We present Remixed Reality, a novel form of mixed reality. In contrast
 to classical mixed reality approaches where users see a direct view o
r video feed of their environment, with Remixed Reality they see a liv
e 3D reconstruction, gathered from multiple external depth cameras. Th
is approach enables changing the environment as easily as geometry can
 be changed in virtual reality, while allowing users to view and inter
act with the actual physical world as they would in augmented reality.
 We characterize a taxonomy of manipulations that are possible with Re
mixed Reality: spatial changes such as erasing objects; appearance cha
nges such as changing textures; temporal changes such as pausing time;
 and viewpoint changes that allow users to see the world from differen
t points without changing their physical location. We contribute a met
hod that uses an underlying voxel grid holding information like visibi
lity and transformations, which is applied to live geometry in real ti
me.
AU  - Lindlbauer, David
AU  - Wilson, Andy D.
C1  - Montreal QC, Canada
C3  - Proceedings of the 2018 CHI Conference on Human Factors in Computing S
ystems
DA  - 2018///
C2  - 2018
DO  - 10.1145/3173574.3173703
ID  - 10.1145/3173574.3173
KW  - augmented reality
KW  - remixed reality
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450356206
SP  - 1-13
T3  - CHI '18
TI  - Remixed Reality: Manipulating Space and Time in Augmented Reality
UR  - https://doi.org/10.1145/3173574.3173703
ER  - 
TY  - CONF
AB  - Existing 2D e-commerce internet websites provide users with only relat
ively simple, browser-based interface to access available products and
 services. These websites often lack in the emulation of real-life hum
an representative which is an important factor in establishing consume
r's trust. 3D e-commerce environments with 3D virtual space and human-
like avatar facilitating the sale of real-world products may add the h
uman factor to the shopping experience and might therefore enhance the
 relation of social trust in these environments. This paper explains t
he concept of 3D e-commerce environments and their roles in increasing
 consumer's trust and in enhancing e-business profitability.
AU  - Nassiri, Nasser
C1  - Fortaleza, Ceara, Brazil
C3  - Proceedings of the 2008 ACM Symposium on Applied Computing
DA  - 2008///
C2  - 2008
DO  - 10.1145/1363686.1364028
ID  - 10.1145/1363686.1364
KW  - 3D e-commerce environment
KW  - appearance
KW  - touch
KW  - trust
PB  - Association for Computing Machinery
SN  - 9781595937537
SP  - 1463-1466
T3  - SAC '08
TI  - Increasing trust through the use of 3d e-commerce environment
UR  - https://doi.org/10.1145/1363686.1364028
ER  - 
TY  - CONF
AB  - The future of the cockpit is undeniably tactile. To make this vision b
ecome a reality, several usability issues must be first addressed, bei
ng the most important one the eyes-free interaction. In fact, differen
t ways of interaction (tactile, physical) will coexist, and it is para
mount to identify those elements in the cockpit that can become tactil
e and those that must remain as tangible (i.e. physical) ones. This wo
rk intends to analyze the current situation and the requirements from 
the point of view of Human-Machine Interaction. In this regard, we pro
pose a new approach that, leading to the concept of "tangibilisation o
f the cockpit", can facilitate the coexistence between tactile and phy
sical actuators in the cockpit. We believe that this approach will fos
ter and inspire the development of a tangible cockpit in the near futu
re.
AU  - Castillo, Juan Angel Lorenzo del
AU  - Couture, Nadine
C1  - Paris, France
C3  - Proceedings of the International Conference on Human-Computer Interact
ion in Aerospace
DA  - 2016///
C2  - 2016
DO  - 10.1145/2950112.2964582
ID  - 10.1145/2950112.2964
KW  - aircraft
KW  - cockpit
KW  - human centered design
KW  - tactile
KW  - tangible
PB  - Association for Computing Machinery
SN  - 9781450344067
T3  - HCI-Aero '16
TI  - The aircraft of the future: towards the tangible cockpit
UR  - https://doi.org/10.1145/2950112.2964582
ER  - 
TY  - CONF
AB  - Recent research in the area of immersive analytics demonstrated the ut
ility of head-mounted augmented reality devices for visual data analys
is. However, it can be challenging to use the by default supported mid
-air gestures to interact with visualizations in augmented reality (e.
g. due to limited precision). Touch-based interaction (e.g. via mobile
 devices) can compensate for these drawbacks, but is limited to two-di
mensional input. In this work we present STREAM: Spatially-aware Table
ts combined with Augmented Reality Head-Mounted Displays for the multi
modal interaction with 3D visualizations. We developed a novel eyes-fr
ee interaction concept for the seamless transition between the tablet 
and the augmented reality environment. A user study reveals that parti
cipants appreciated the novel interaction concept, indicating the pote
ntial for spatially-aware tablets in augmented reality. Based on our f
indings, we provide design insights to foster the application of spati
ally-aware touch devices in augmented reality and research implication
s indicating areas that need further investigation.
AU  - Hubenschmid, Sebastian
AU  - Zagermann, Johannes
AU  - Butscher, Simon
AU  - Reiterer, Harald
C1  - Yokohama, Japan
C3  - Proceedings of the 2021 CHI Conference on Human Factors in Computing S
ystems
DA  - 2021///
C2  - 2021
DO  - 10.1145/3411764.3445298
ID  - 10.1145/3411764.3445
KW  - augmented reality
KW  - immersive analytics
KW  - mobile devices
KW  - multimodal interaction
KW  - visualizations
PB  - Association for Computing Machinery
SN  - 9781450380966
T3  - CHI '21
TI  - STREAM: Exploring the Combination of Spatially-Aware Tablets with Augm
ented Reality Head-Mounted Displays for Immersive Analytics
UR  - https://doi.org/10.1145/3411764.3445298
ER  - 
TY  - CONF
AB  - The feeling of presence of virtual entities is an important objective 
in virtual reality, teleconferencing, augmented reality, exposure ther
apy and video games. Presence creates emotional involvement and suppor
ts intuitive and efficient interactions. As a feeling, presence is mos
tly measured via subjective questionnaire, but its validity is dispute
d. We introduce a new method to measure the contribution of several te
chnical parameters toward presence. Its robustness stems from asking p
articipant to rank contrasts rather than asking absolute values, and f
rom the statistical analysis of repeated answers. We implemented this 
method in a user study where virtual entities were created with a hand
held perspective corrected display. We evaluated the impact on two vir
tual entities' presence of four important parameters of digital visual
 stimuli: resolution, latency, frame rate and jitter. Results suggest 
that jitter and frame rate are critical for presence but not latency, 
and resolution depends on the explored entity.
AU  - Louis, Thibault
AU  - Troccaz, Jocelyne
AU  - Rochet-Capellan, Amélie
AU  - Bérard, François
C1  - Daejeon, Republic of Korea
C3  - Proceedings of the 2019 ACM International Conference on Interactive Su
rfaces and Spaces
DA  - 2019///
C2  - 2019
DO  - 10.1145/3343055.3359710
ID  - 10.1145/3343055.3359
KW  - user study
KW  - spatial augmented reality
KW  - presence
KW  - hpcd
PB  - Association for Computing Machinery
SN  - 9781450368919
SP  - 5-16
T3  - ISS '19
TI  - Is it Real? Measuring the Effect of Resolution, Latency, Frame rate an
d Jitter on the Presence of Virtual Entities
UR  - https://doi.org/10.1145/3343055.3359710
ER  - 
TY  - CONF
AB  - Photoportals build on digital photography as a unifying metaphor for r
eference-based interaction in 3D virtual environments. Virtual photos 
and videos serve as threedimensional references to objects, places, mo
ments in time and activities of users. Our Photoportals also provide a
ccess to intermediate or alternative versions of a scenario and allow 
the review of recorded task sequences that include life-size represent
ations of the captured users. We propose to exploit such references to
 structure collaborative activities of collocated and remote users. Ph
otoportals offer additional access points for multiple users and encou
rage mutual support through the preparation and provision of reference
s for manipulation and navigation tasks. They support the pattern of t
erritoriality with configurable space representations that can be used
 for private interaction, as well as be shared and exchanged with othe
rs.
AU  - Kunert, André
AU  - Kulik, Alexander
AU  - Beck, Stephan
AU  - Froehlich, Bernd
C1  - Baltimore, Maryland, USA
C3  - Proceedings of the 17th ACM Conference on Computer Supported Cooperati
ve Work &amp; Social Computing
DA  - 2014///
C2  - 2014
DO  - 10.1145/2531602.2531727
ID  - 10.1145/2531602.2531
KW  - 3d interaction
KW  - 3d user interfaces
KW  - collaborative virtual environments
KW  - interactive systems
KW  - multi-user interaction
PB  - Association for Computing Machinery
SN  - 9781450325400
SP  - 1388-1399
T3  - CSCW '14
TI  - Photoportals: shared references in space and time
UR  - https://doi.org/10.1145/2531602.2531727
ER  - 
TY  - BOOK
CY  - Rapperswil, Switzerland
DA  - 2023///
PY  - 2023
ID  - 10.1145/3603555
PB  - Association for Computing Machinery
SN  - 9798400707711
TI  - MuC '23: Proceedings of Mensch und Computer 2023
ER  - 
TY  - CONF
AU  - Chapin, William L.
AU  - Lacey, Timothy A.
AU  - Leifer, Larry
C1  - Boston, Massachusetts, USA
C3  - Conference Companion on Human Factors in Computing Systems
DA  - 1994///
C2  - 1994
DO  - 10.1145/259963.260001
ID  - 10.1145/259963.26000
PB  - Association for Computing Machinery
SN  - 0897916514
SP  - 33-34
T3  - CHI '94
TI  - DesignSpace: a manual interaction environment for computer aided desig
n
UR  - https://doi.org/10.1145/259963.260001
ER  - 
TY  - CONF
AU  - Chapin, William L.
AU  - Lacey, Timothy A.
AU  - Leifer, Larry
C1  - Boston, Massachusetts, USA
C3  - Conference Companion on Human Factors in Computing Systems
DA  - 1994///
C2  - 1994
DO  - 10.1145/259963.260018
ID  - 10.1145/259963.26001
PB  - Association for Computing Machinery
SN  - 0897916514
SP  - 47-48
T3  - CHI '94
TI  - DesignSpace: a manual interaction environment for computer-aided desig
n
UR  - https://doi.org/10.1145/259963.260018
ER  - 
TY  - JOUR
AB  - A multimedia approach to the diffusion, communication, and exploitatio
n of Cultural Heritage (CH) is a well-established trend worldwide. Sev
eral studies demonstrate that the use of new and combined media enhanc
es how culture is experienced. The benefit is in terms of both number 
of people who can have access to knowledge and the quality of the diff
usion of the knowledge itself. In this regard, CH uses augmented-, vir
tual-, and mixed-reality technologies for different purposes, includin
g education, exhibition enhancement, exploration, reconstruction, and 
virtual museums. These technologies enable user-centred presentation a
nd make cultural heritage digitally accessible, especially when physic
al access is constrained. A number of surveys of these emerging techno
logies have been conducted; however, they are either not domain specif
ic or lack a holistic perspective in that they do not cover all the as
pects of the technology. A review of these technologies from a cultura
l heritage perspective is therefore warranted. Accordingly, our articl
e surveys the state-of-the-art in augmented-, virtual-, and mixed-real
ity systems as a whole and from a cultural heritage perspective. In ad
dition, we identify specific application areas in digital cultural her
itage and make suggestions as to which technology is most appropriate 
in each case. Finally, the article predicts future research directions
 for augmented and virtual reality, with a particular focus on interac
tion interfaces and explores the implications for the cultural heritag
e domain.
AU  - Bekele, Mafkereseb Kassahun
AU  - Pierdicca, Roberto
AU  - Frontoni, Emanuele
AU  - Malinverni, Eva Savina
AU  - Gain, James
DA  - 2018/3//
PY  - 2018
DO  - 10.1145/3145534
ID  - 10.1145/3145534
IS  - 2
KW  - Cultural heritage
KW  - augmented reality
KW  - mixed reality
KW  - virtual reality
SN  - 1556-4673
T2  - J. Comput. Cult. Herit.
TI  - A Survey of Augmented, Virtual, and Mixed Reality for Cultural Heritag
e
UR  - https://doi.org/10.1145/3145534
VL  - 11
ER  - 
TY  - CONF
AB  - We present a novel, paired, wearable system for combining the kinesthe
tic experiences of two persons. These devices allow users to sense and
 combine muscle contraction and joint rigidity bi-directionally. This 
is achieved through kinesthetic channels based on electromyogram (EMG)
 measurement and electrical muscle stimulation (EMS). We developed a p
air of wearable kinesthetic input-output (I/O) devices called bioSync 
that uses specially designed electrodes to perform biosignal measureme
nt and stimulation simultaneously on the same electrodes.In a user stu
dy, participants successfully evaluated the strength of their partners
' muscle contractions while exerting their own muscles. We confirmed t
hat the pair of devices could help participants synchronize their hand
 movements through tapping, without visual and auditory feedback. The 
proposed interpersonal kinesthetic communication system can be used to
 enhance interactions such as clinical gait rehabilitation and sports 
training, and facilitate sharing of physical experiences with Parkinso
n's patients, thereby enhancing understanding of the physical challeng
es they face in daily life.
AU  - Nishida, Jun
AU  - Suzuki, Kenji
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI Conference on Human Factors in Computing S
ystems
DA  - 2017///
C2  - 2017
DO  - 10.1145/3025453.3025829
ID  - 10.1145/3025453.3025
KW  - blending kinesthetic experience
KW  - electrical muscle stimulation
KW  - electromyogram signals
KW  - rehabilitation
PB  - Association for Computing Machinery
SN  - 9781450346559
SP  - 3316-3327
T3  - CHI '17
TI  - bioSync: A Paired Wearable Device for Blending Kinesthetic Experience
UR  - https://doi.org/10.1145/3025453.3025829
ER  - 
TY  - CONF
AB  - We describe a novel dynamic method for collaborative virtual environme
nts designed for mobile devices and evaluated in a mobile context. Par
ticipants interacted in pairs remotely and through touch while walking
 in three different feedback conditions: 1) visual, 2) audio-tactile, 
3) spatial audio-tactile. Results showed the visual baseline system pr
ovided higher shared awareness, efficiency and a strong learning effec
t. However, and although very challenging, the eyes-free systems still
 offered the ability to build joint awareness in remote collaborative 
environments, particularly the spatial audio one. These results help u
s better understand the potential of different feedback mechanisms in 
the design of future mobile collaborative environments.
AU  - Trendafilov, Dari
AU  - Vazquez-Alvarez, Yolanda
AU  - Lemmelä, Saija
AU  - Murray-Smith, Roderick
C1  - Stockholm, Sweden
C3  - Proceedings of the 13th International Conference on Human Computer Int
eraction with Mobile Devices and Services
DA  - 2011///
C2  - 2011
DO  - 10.1145/2037373.2037447
ID  - 10.1145/2037373.2037
KW  - collaborative virtual environments
KW  - mobile shared interaction
KW  - social presence
KW  - spatial audio
KW  - tactile
PB  - Association for Computing Machinery
SN  - 9781450305419
SP  - 499-502
T3  - MobileHCI '11
TI  - "Can we work this out?": an evaluation of remote collaborative interac
tion in a mobile shared environment
UR  - https://doi.org/10.1145/2037373.2037447
ER  - 
TY  - JOUR
AB  - A large number of studies highlight the importance of regulation in co
llaborative learning (CL). Nevertheless, only some studies describe ho
w to get or support pupils to learn to regulate group work in school. 
In this context, we aim to understand if a specifically designed tangi
ble environment can promote a regulated collaboration process during a
 face-to-face activity in school. Therefore, we conducted a 2-year des
ign-based research (DBR) study. This article describes the DBR cycles 
in detail, and the steps we have executed to develop, test, implement,
 and evaluate a set of tangible artifacts called Collective attention 
led by a Mediated environment (CalMe). First, we identified three spec
ific dimensions that interfere with CL in the classroom: team building
 and collective decision-making, task regulation awareness, and over-s
olicitation limitation. Second, we proposed design choices leading to 
the first iteration of a CalMe device that meets these needs. We then 
assessed usability and acceptability before the pedagogical validation
 steps. Third, through a pilot study, we evaluated the pedagogical pot
ential of the second iteration of the CalMe device in a real context o
f use in an elementary school class. We collected and analyzed data fr
om surveys, focus groups, log data, and video recordings through all t
he steps. Moreover, to allow for duplication of the study, we propose 
and detail our methodological approach. This study shows an empirical 
example of a DBR process that allows responding as closely as possible
 to the needs of both pupils and teachers. This work also provides inp
ut to teachers regarding a better understanding of collaborative probl
em-solving activities. Although there is still room for improvement on
 specific dimensions related to task regulation, such as better manage
ment of ambient noise or work tempo, the results indicate that the Cal
Me device allows for a regulated collaboration process in schools. It 
shows an human–computer interaction design process that can be an exam
ple of how to influence classroom activities through technology to pro
mote positive CL experiences.
AU  - Bertolo, David
AU  - Faedda, Stéphane
AU  - Olry, Alexis
AU  - Veytizou, Julien
AU  - Vivian, Robin
AU  - Fleck, Stéphanie
DA  - 2025/4//
PY  - 2025
DO  - 10.1145/3685273
ID  - 10.1145/3685273
IS  - 2
KW  - Face-to-face collaborative learning
KW  - Team and task regulation
KW  - Design-based research
KW  - Tangible interfaces
KW  - Learning experience
KW  - K-12
SN  - 1073-0516
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - CalMe: A Tangible Environment to Enhance Pupils Group Work Regulation
UR  - https://doi.org/10.1145/3685273
VL  - 32
ER  - 
TY  - CONF
AB  - This article proposes to study the role of Collaborative Virtual Envir
onments for the search of residues in molecular environments. This res
earch highlights involved working strategies according the type and co
ntext of the task and shows some constraints and conflicting actions t
hat may occur during closely coupled collaboration.
AU  - Simard, J.
AU  - Ammi, M.
AU  - Auvray, M.
C1  - Hong Kong
C3  - Proceedings of the 17th ACM Symposium on Virtual Reality Software and 
Technology
DA  - 2010///
C2  - 2010
DO  - 10.1145/1889863.1889904
ID  - 10.1145/1889863.1889
PB  - Association for Computing Machinery
SN  - 9781450304412
SP  - 181-182
T3  - VRST '10
TI  - Closely coupled collaboration for search tasks
UR  - https://doi.org/10.1145/1889863.1889904
ER  - 
TY  - BOOK
CY  - Pittsburgh, PA, USA
DA  - 2024///
PY  - 2024
ID  - 10.1145/3654777
PB  - Association for Computing Machinery
SN  - 9798400706288
TI  - UIST '24: Proceedings of the 37th Annual ACM Symposium on User Interfa
ce Software and Technology
ER  - 
TY  - CONF
AB  - In the continuation of the 3D data production work made by the WDCAH, 
the use of virtual reality tools allows archaeologists to carry out an
alysis and understanding research about their sites. In this paper, we
 focus on the virtual reality services proposed to archaeologists in t
he WDCAH, through the example of two archaeological sites, the Temple 
de Mars in Corseul and the Cairn of Carn Island.
AU  - Barreau, Jean-Baptiste
AU  - Gaugne, Ronan
AU  - Bernard, Yann
AU  - Le Cloirec, Gaétan
AU  - Gouranton, Valérie
C1  - Laval, France
C3  - Proceedings of the 2014 Virtual Reality International Conference
DA  - 2014///
C2  - 2014
DO  - 10.1145/2617841.2617845
ID  - 10.1145/2617841.2617
KW  - archaeology
KW  - digital heritage
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450326261
T3  - VRIC '14
TI  - Virtual reality tools for the west digital conservatory of archaeologi
cal heritage
UR  - https://doi.org/10.1145/2617841.2617845
ER  - 
TY  - BOOK
CY  - Poznan, Poland
DA  - 2024///
PY  - 2024
ID  - 10.1145/3679058
PB  - Association for Computing Machinery
SN  - 9798400711206
TI  - HUMAN '24: Proceedings of the 7th Workshop on Human Factors in Hyperte
xt
ER  - 
TY  - JOUR
AB  - Interaction frameworks are the tools of choice for researchers and UI 
designers when prototyping new and original interaction techniques. Bu
t with little knowledge about actual needs, these frameworks provide i
ncomplete support that restricts, slows down or even prevents the expl
oration of new ideas. In this context, researchers resort to hacking m
ethods, creating code that lacks robustness beyond experiments, combin
ing libraries of different levels and paradigms, and eventually limiti
ng the dissemination and reproducibility of their work. To better unde
rstand this problem, we interviewed 9 HCI researchers and conducted an
 online survey. From the results we give an overview of the criteria f
or choosing frameworks, the problems often met with them, and the "tri
cks" used as solutions. Then we propose three design principles to bet
ter support prototyping for research in UI frameworks: (i) duplicate s
ingular elements (e.g. mouse, caret) to foster opportunities for exten
sions, (ii) accumulate rather than replace to keep a history of change
s, and (iii) defer the execution of predefined behaviors to enable the
ir monitoring and replacement.
AU  - Raffaillac, Thibault
AU  - Huot, Stéphane
DA  - 2022/6//
PY  - 2022
DO  - 10.1145/3532209
ID  - 10.1145/3532209
IS  - EICS
KW  - design principles
KW  - hacking
KW  - interaction frameworks
KW  - interaction techniques
KW  - interviews
KW  - online survey
KW  - prototyping
KW  - toolkits
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - What do Researchers Need when Implementing Novel Interaction Technique
s?
UR  - https://doi.org/10.1145/3532209
VL  - 6
ER  - 
TY  - BOOK
CY  - Paris, France
DA  - 2024///
PY  - 2024
ID  - 10.1145/3649792
PB  - Association for Computing Machinery
SN  - 9798400718113
TI  - IHM '24: Proceedings of the 35th Conference on l'Interaction Humain-Ma
chine
ER  - 
TY  - CONF
AB  - Consumer social virtual reality (VR) applications have recently starte
d to enable social interactions at a distance. Yet it is still relativ
ely unknown if and to what extent such applications provide meaningful
 social experiences in cases where in-person leisure activities are no
t feasible. To explore this, we developed a custom social VR applicati
on and conducted an exploratory lab study with 25 dyads in which we co
mpared an in-person and a virtual version of a co-located multiplayer 
scenario. Our mixed-methods analysis revealed that both scenarios crea
ted a socially rich atmosphere and strengthened the social closeness b
etween players. However, the lack of facial animations, limited body l
anguage, and a low field of view led to VR’s main social experiential 
limitations: a reduced mutual awareness and emotional understanding co
mpared to the in-person scenario. We derive implications for social VR
 design and research as well as game user research.
AU  - Sykownik, Philipp
AU  - Karaosmanoglu, Sukran
AU  - Emmerich, Katharina
AU  - Steinicke, Frank
AU  - Masuch, Maic
C1  - Hamburg, Germany
C3  - Proceedings of the 2023 CHI Conference on Human Factors in Computing S
ystems
DA  - 2023///
C2  - 2023
DO  - 10.1145/3544548.3581230
ID  - 10.1145/3544548.3581
KW  - multiplayer games
KW  - player experience
KW  - social interaction
KW  - social presence
KW  - social virtual reality
PB  - Association for Computing Machinery
SN  - 9781450394215
T3  - CHI '23
TI  - VR Almost There: Simulating Co-located Multiplayer Experiences in Soci
al Virtual Reality
UR  - https://doi.org/10.1145/3544548.3581230
ER  - 
TY  - CONF
AB  - T(ether) is a spatially-aware display system for multi-user, collabora
tive manipulation and animation of virtual 3D objects. The handheld di
splay acts as a window into virtual reality, providing users with a pe
rspective view of 3D data. T(ether) tracks users' heads, hands, finger
s and pinching, in addition to a handheld touch screen, to enable rich
 interaction with the virtual scene. We introduce gestural interaction
 techniques that exploit proprioception to adapt the UI based on the h
and's position above, behind or on the surface of the display. These s
patial interactions use a tangible frame of reference to help users ma
nipulate and animate the model in addition to controlling environment 
properties. We report on initial user observations from an experiment 
for 3D modeling, which indicate T(ether)'s potential for embodied view
port control and 3D modeling interactions.
AU  - Lakatos, David
AU  - Blackshaw, Matthew
AU  - Olwal, Alex
AU  - Barryte, Zachary
AU  - Perlin, Ken
AU  - Ishii, Hiroshi
C1  - Honolulu, Hawaii, USA
C3  - Proceedings of the 2nd ACM Symposium on Spatial User Interaction
DA  - 2014///
C2  - 2014
DO  - 10.1145/2659766.2659785
ID  - 10.1145/2659766.2659
KW  - 3D modeling
KW  - 3D user interfaces
KW  - VR
KW  - collaborative
KW  - gestural interaction
KW  - multi-user
KW  - spatially-aware displays
PB  - Association for Computing Machinery
SN  - 9781450328203
SP  - 90-93
T3  - SUI '14
TI  - T(ether): spatially-aware handhelds, gestures and proprioception for m
ulti-user 3D modeling and animation
UR  - https://doi.org/10.1145/2659766.2659785
ER  - 
TY  - CONF
AB  - Currently, "walkable" virtual reality (VR) is achieved by dedicating a
 room-sized space for VR activities, which is not shared with non-HMD 
users engaged in their own activities. To achieve the goal of allowing
 shared use of space for all users while overcoming the obvious diffic
ulty of integrating use with those immersed in a VR experience, we pre
sent ShareSpace, a system that allows external users to communicate th
eir needs for physical space to those wearing an HMD and immersed in t
heir VR experience. ShareSpace works by allowing external users to pla
ce "shields" in the virtual environment by using a set of physical shi
eld tools. A pad visualizer helps this process by allowing external us
ers to examine the arrangement of virtual shields. We also discuss int
eraction techniques that minimize the interference between the respect
ive activities of the HMD wearers and the other users of the same phys
ical space. To evaluate our design, a user study was conducted to coll
ect user feedback from participants in four trial scenarios. The resul
ts indicate that our ShareSpace system allows users to perform their r
espective activities with improved engagement and safety. In addition,
 this study shows that while the HMD users did perceive a considerable
 degree of interference due to the internal visual indications from th
e ShareSpace system, they were still more engaged in their VR experien
ce than when interrupted by direct external physical interference init
iated by external users.
AU  - Yang, Keng-Ta
AU  - Wang, Chiu-Hsuan
AU  - Chan, Liwei
C1  - Berlin, Germany
C3  - Proceedings of the 31st Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2018///
C2  - 2018
DO  - 10.1145/3242587.3242630
ID  - 10.1145/3242587.3242
KW  - virtual reality
KW  - shared use of physical space
KW  - external users experience
PB  - Association for Computing Machinery
SN  - 9781450359481
SP  - 499-509
T3  - UIST '18
TI  - ShareSpace: Facilitating Shared Use of the Physical Space by both VR H
ead-Mounted Display and External Users
UR  - https://doi.org/10.1145/3242587.3242630
ER  - 
TY  - CONF
AB  - Poultry.Internet leverages on the reach of the Internet to connect hum
ans and pets at different locations. This system has a tangible interf
ace encompassing both visual and tactile modes of communication. It al
lows humans to interact remotely with pets anytime, anywhere. The pet 
owner views the real time movement of the pet in the form of a pet dol
l sitting on a mechanical positioning system. Meanwhile, the real pet 
wears a special jacket, which is able to reproduce the touching sensat
ion. The pet owner can tangibly touch the pet doll, sending touch sign
als to the pet far away. Also, the pet owner receives a haptic feedbac
k from the movement of the pet.
AU  - Teh, Keng Soon
AU  - Lee, Shang Ping
AU  - Cheok, Adrian David
C1  - Montréal, Québec, Canada
C3  - CHI '06 Extended Abstracts on Human Factors in Computing Systems
DA  - 2006///
C2  - 2006
DO  - 10.1145/1125451.1125505
ID  - 10.1145/1125451.1125
KW  - haptics
KW  - human-pet interaction
KW  - tangible interaction
KW  - wearable computing
PB  - Association for Computing Machinery
SN  - 1595932984
SP  - 251-254
T3  - CHI EA '06
TI  - Poultry.Internet: a remote human-pet interaction system
UR  - https://doi.org/10.1145/1125451.1125505
ER  - 
TY  - CONF
AB  - Digital pen systems, originally designed to digitize annotations made 
on physical paper, are evolving to permit a wider variety of applicati
ons. Although the type and quality of pen feedback (e.g., haptic, audi
o, and visual) have a huge impact on advancing the digital pen technol
ogy, dynamic visual feedback has yet to be fully investigated. In para
llel, miniature projectors are an emerging technology with the potenti
al to enhance visual feedback for small mobile computing devices. In t
his paper we present the PenLight system, which is a testbed to explor
e the interaction design space and its accompanying interaction techni
ques in a digital pen embedded with a spatially-aware miniature projec
tor. Using our prototype, that simulates a miniature projection (via a
 standard video projector), we visually augment paper documents, givin
g the user immediate access to additional information and computationa
l tools. We also show how virtual ink can be managed in single and mul
ti-user environments to aid collaboration and data management. User ev
aluation with professional architects indicated promise of our propose
d techniques and their potential utility in the paper-intensive domain
 of architecture.
AU  - Song, Hyunyoung
AU  - Grossman, Tovi
AU  - Fitzmaurice, George
AU  - Guimbretiere, François
AU  - Khan, Azam
AU  - Attar, Ramtin
AU  - Kurtenbach, Gordon
C1  - Boston, MA, USA
C3  - Proceedings of the SIGCHI Conference on Human Factors in Computing Sys
tems
DA  - 2009///
C2  - 2009
DO  - 10.1145/1518701.1518726
ID  - 10.1145/1518701.1518
KW  - digital pen input
KW  - mobile projector
KW  - multi-layer interaction
KW  - spatially-aware display
PB  - Association for Computing Machinery
SN  - 9781605582467
SP  - 143-152
T3  - CHI '09
TI  - PenLight: combining a mobile projector and a digital pen for dynamic v
isual overlay
UR  - https://doi.org/10.1145/1518701.1518726
ER  - 
TY  - JOUR
AB  - As the variety of possible interactions with virtual reality (VR) cont
inues to expand, researchers need a way to relate these interactions t
o users' needs and goals in ways that advance understanding. Existing 
efforts have focused mainly on the symmetric use of technology, which 
excludes a rising form of interaction known as asymmetric VR, in which
 co-located participants use different interfaces to interact with a s
hared environment. There must be a clear path to creating asymmetric V
R systems that are rooted in previous work from several fields, as the
se systems have use cases in education, hybrid reality teams (using VR
 and other technologies to interact online and face to face), accessib
ility, as well as entertainment. Currently, there is no systematic way
 to characterize 1) how a system may be asymmetric, 2) how the differe
nt mediation technology and affordances within asymmetric VR support (
or do not support) users' goals, and 3) the relationships and collabor
ative capabilities between users of these different technologies. In t
his paper, the authors use a scoping review to explore relevant concep
tual frameworks for asymmetric interaction, mediation technology, and 
computer supported cooperative work to clarify the dimensions of asymm
etry and synthesize the literature into a Composite framework for Asym
metric VR (CAVR). The paper concludes with suggestions of ways to test
 and expand the framework in order to guide future research as it iden
tifies the most-beneficial interaction paradigms for co-located asymme
tric VR.
AU  - Ouverson, Kaitlyn M.
AU  - Gilbert, Stephen B.
DA  - 2021/4//
PY  - 2021
DO  - 10.1145/3449079
ID  - 10.1145/3449079
IS  - CSCW1
KW  - asymmetric vr
KW  - collaboration
KW  - conceptual frameworks
KW  - extended reality (xr)
KW  - mixed reality (mr)
KW  - workspace awareness
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - A Composite Framework of Co-located Asymmetric Virtual Reality
UR  - https://doi.org/10.1145/3449079
VL  - 5
ER  - 
TY  - BOOK
CY  - Kobe, Japan
DA  - 2015///
PY  - 2015
ID  - 10.1145/2818427
PB  - Association for Computing Machinery
SN  - 9781450339285
TI  - SA '15: SIGGRAPH Asia 2015 Mobile Graphics and Interactive Application
s
ER  - 
TY  - CONF
AB  - Virtual Reality (VR) users often need to work with other users, who ob
serve them outside of VR using an external display. Communication betw
een them is difficult; the VR user cannot see the external user's gest
ures, and the external user cannot see VR scene elements outside of th
e VR user's view. We carried out formative interviews with experts to 
understand these asymmetrical interactions and identify their goals an
d challenges. From this, we identify high-level system design goals to
 facilitate asymmetrical interactions and a corresponding space of imp
lementation approaches based on the level of programmatic access to a 
VR application. We present TransceiVR, a system that utilizes VR platf
orm APIs to enable asymmetric communication interfaces for third-party
 applications without requiring source code access. TransceiVR allows 
external users to explore the VR scene spatially or temporally, to ann
otate elements in the VR scene at correct depths, and to discuss via a
 shared static virtual display. An initial co-located user evaluation 
with 10 pairs shows that our system makes asymmetric collaborations in
 VR more effective and successful in terms of task time, error rate, a
nd task load index. An informal evaluation with a remote expert gives 
additional insight on utility of features for real world tasks.
AU  - Thoravi Kumaravel, Balasaravanan
AU  - Nguyen, Cuong
AU  - DiVerdi, Stephen
AU  - Hartmann, Bjoern
C1  - Virtual Event, USA
C3  - Proceedings of the 33rd Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2020///
C2  - 2020
DO  - 10.1145/3379337.3415827
ID  - 10.1145/3379337.3415
KW  - virtual reality
KW  - collaboration
KW  - asymmetric interactions
PB  - Association for Computing Machinery
SN  - 9781450375146
SP  - 182-195
T3  - UIST '20
TI  - TransceiVR: Bridging Asymmetrical Communication Between VR Users and E
xternal Collaborators
UR  - https://doi.org/10.1145/3379337.3415827
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3731406
PB  - Association for Computing Machinery
SN  - 9798400718663
TI  - EICS '25 Companion: Companion Proceedings of the 17th ACM SIGCHI Sympo
sium on Engineering Interactive Computing Systems
ER  - 
TY  - CONF
AB  - For people with visual impairments, tactile graphics are an important 
means to learn and explore information. However, raised line tactile g
raphics created with traditional materials such as embossing are stati
c. While available refreshable displays can dynamically change the con
tent, they are still too expensive for many users, and are limited in 
size. These factors limit wide-spread adoption and the representation 
of large graphics or data sets. In this paper, we present FluxMaker, a
n inexpensive scalable system that renders dynamic information on top 
of static tactile graphics with movable tactile markers. These dynamic
 tactile markers can be easily reconfigured and used to annotate stati
c raised line tactile graphics, including maps, graphs, and diagrams. 
We developed a hardware prototype that actuates magnetic tactile marke
rs driven by low-cost and scalable electromagnetic coil arrays, which 
can be fabricated with standard printed circuit board manufacturing. W
e evaluate our prototype with six participants with visual impairments
 and found positive results across four application areas: location fi
nding or navigating on tactile maps, data analysis, and physicalizatio
n, feature identification for tactile graphics, and drawing support. T
he user study confirms advantages in application domains such as educa
tion and data exploration.
AU  - Suzuki, Ryo
AU  - Stangl, Abigale
AU  - Gross, Mark D.
AU  - Yeh, Tom
C1  - Baltimore, Maryland, USA
C3  - Proceedings of the 19th International ACM SIGACCESS Conference on Comp
uters and Accessibility
DA  - 2017///
C2  - 2017
DO  - 10.1145/3132525.3132548
ID  - 10.1145/3132525.3132
KW  - dynamic tactile markers
KW  - interactive tactile graphics
KW  - tangible interfaces
KW  - visual impairment
PB  - Association for Computing Machinery
SN  - 9781450349260
SP  - 190-199
T3  - ASSETS '17
TI  - FluxMarker: Enhancing Tactile Graphics with Dynamic Tactile Markers
UR  - https://doi.org/10.1145/3132525.3132548
ER  - 
TY  - JOUR
AU  - Campbell, Marisa
DA  - 2001/1//
PY  - 2001
DO  - 10.1145/356978.356981
ID  - 10.1145/356978.35698
IS  - 1
SN  - 1072-5520
SP  - 11-17
T2  - Interactions
TI  - Research alerts
UR  - https://doi.org/10.1145/356978.356981
VL  - 8
ER  - 
TY  - CONF
AB  - It is becoming increasingly more common for people to own botha smartp
hone and a tablet, providing a design opportunity to leverage the comb
ination of these two formfactors. Our work aims to explore this by: a)
 defining the design space of distributed input and output solutions t
hat rely on and benefit from phone–tablet collaboration, both physical
ly and digitally; andb) reveal the idiosyncrasies of each particular d
evice combination via interactive prototypes. Our research provides ac
tionable insight in this emerging area by defining a design space, sug
gesting a developer's framework and implementing prototypical applicat
ionsin such areas as distributed information display, distributed cont
rol and various configurations of these. For each of these, we present
 several example techniques and demonstrate an application that combin
essuch techniques.
AU  - Piazza, Tommaso
AU  - Fjeld, Morten
AU  - Ramos, Gonzalo
AU  - Yantac, AsimEvren
AU  - Zhao, Shengdong
C1  - Bangalore, India
C3  - Proceedings of the 11th Asia Pacific Conference on Computer Human Inte
raction
DA  - 2013///
C2  - 2013
DO  - 10.1145/2525194.2525205
ID  - 10.1145/2525194.2525
KW  - PDA
KW  - content
KW  - context-aware computing
KW  - design
KW  - device
KW  - human factors
KW  - mobile
KW  - screen
KW  - smartphone
KW  - tablet
PB  - Association for Computing Machinery
SN  - 9781450322539
SP  - 63-72
T3  - APCHI '13
TI  - Holy smartphones and tablets, Batman! mobile interaction's dynamic duo

UR  - https://doi.org/10.1145/2525194.2525205
ER  - 
TY  - BOOK
CY  - Shenzhen, China
DA  - 2014///
PY  - 2014
ID  - 10.1145/2668956
PB  - Association for Computing Machinery
SN  - 9781450332439
TI  - SA '14: SIGGRAPH Asia 2014 Autonomous Virtual Humans and Social Robot 
for Telepresence
ER  - 
TY  - BOOK
CY  - San Francisco, CA, USA
DA  - 2023///
PY  - 2023
ID  - 10.1145/3586183
PB  - Association for Computing Machinery
SN  - 9798400701320
TI  - UIST '23: Proceedings of the 36th Annual ACM Symposium on User Interfa
ce Software and Technology
ER  - 
TY  - CONF
AB  - Current low-tech Orientation &amp; Mobility (O&amp;M) tools for visual
ly impaired people, e.g. tactile maps, possess limitations. Interactiv
e accessible maps have been developed to overcome these. However, most
 of them are limited to exploration of existing maps, and have remaine
d in laboratories. Using a participatory design approach, we have work
ed closely with 15 visually impaired students and 3 O&amp;M instructor
s over 6 months. We iteratively designed and developed an augmented re
ality map destined at use in O&amp;M classes in special education cent
ers. This prototype combines projection, audio output and use of tacti
le tokens, and thus allows both map exploration and construction by lo
w vision and blind people. Our user study demonstrated that all studen
ts were able to successfully use the prototype, and showed a high user
 satisfaction. A second phase with 22 international special education 
teachers allowed us to gain more qualitative insights. This work shows
 that augmented reality has potential for improving the access to educ
ation for visually impaired people.
AU  - Albouys-Perrois, Jérémy
AU  - Laviole, Jérémy
AU  - Briant, Carine
AU  - Brock, Anke M.
C1  - Montreal QC, Canada
C3  - Proceedings of the 2018 CHI Conference on Human Factors in Computing S
ystems
DA  - 2018///
C2  - 2018
DO  - 10.1145/3173574.3174203
ID  - 10.1145/3173574.3174
KW  - accessibility
KW  - augmented reality
KW  - geographic maps
KW  - participatory design
KW  - visual impairment
PB  - Association for Computing Machinery
SN  - 9781450356206
SP  - 1-14
T3  - CHI '18
TI  - Towards a Multisensory Augmented Reality Map for Blind and Low Vision 
People: a Participatory Design Approach
UR  - https://doi.org/10.1145/3173574.3174203
ER  - 
TY  - CONF
AB  - We present an approach to alter the perceived appearance of physical o
bjects by controlling their surrounding space. Many real-world objects
 cannot easily be equipped with displays or actuators in order to chan
ge their shape. While common approaches such as projection mapping ena
ble changing the appearance of objects without modifying them, certain
 surface properties (e.g. highly reflective or transparent surfaces) c
an make employing these techniques difficult. In this work, we present
 a conceptual design exploration on how the appearance of an object ca
n be changed by solely altering the space around it, rather than the o
bject itself. In a proof-of-concept implementation, we place objects o
nto a tabletop display and track them together with users to display p
erspective-corrected 3D graphics for augmentation. This enables contro
lling properties such as the perceived size, color, or shape of object
s. We characterize the design space of our approach and demonstrate po
tential applications. For example, we change the contour of a wallet t
o notify users when their bank account is debited. We envision our app
roach to gain in importance with increasing ubiquity of display surfac
es.
AU  - Lindlbauer, David
AU  - Mueller, Jörg
AU  - Alexa, Marc
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI Conference on Human Factors in Computing S
ystems
DA  - 2017///
C2  - 2017
DO  - 10.1145/3025453.3025795
ID  - 10.1145/3025453.3025
KW  - dynamic appearance
KW  - augmented reality
PB  - Association for Computing Machinery
SN  - 9781450346559
SP  - 3954-3965
T3  - CHI '17
TI  - Changing the Appearance of Real-World Objects By Modifying Their Surro
undings
UR  - https://doi.org/10.1145/3025453.3025795
ER  - 
TY  - CONF
AB  - Although many progresses have been accomplished in multimodal interact
ion, most researchers still treat each modality such as vision and spe
ech, separately. They integrate the results at the application stage. 
This is because the roles of multiple modalities and their interaction
s continue to be quantified and precisely understood. However, there a
re many remaining issues in combining each modality individually. This
 paper will highlight the main vision problems based on our review for
 multimodal applications. This review paper will give an overview of t
he Augmented Reality (AR) technologies which are contributing in most 
of recent multimodal applications. We cluster vision techniques accord
ing to the natural human senses such as face, gesture, and speech that
 are frequently used in multimodal applications. The main contribution
 of this paper is to consolidate some of the main issues and approache
s in vision-based technique, and to study some of the applications in 
AR that have been developed within the context of multimodal interacti
on. We conclude this paper with the future directions.
AU  - Ismail, Ajune Wanis
AU  - Billinghurst, Mark
AU  - Sunar, Mohd Shahrizal
C1  - Tokyo, AA, Japan
C3  - Proceedings of the 8th International Symposium on Visual Information C
ommunication and Interaction
DA  - 2015///
C2  - 2015
DO  - 10.1145/2801040.2801058
ID  - 10.1145/2801040.2801
KW  - Augmented Reality
KW  - Multimodal Interaction
KW  - Vision Technique
PB  - Association for Computing Machinery
SN  - 9781450334822
SP  - 75-82
T3  - VINCI '15
TI  - Vision-Based Technique and Issues for Multimodal Interaction in Augmen
ted Reality
UR  - https://doi.org/10.1145/2801040.2801058
ER  - 
TY  - JOUR
AB  - Exploring communication dynamics in digital social spaces such as mass
ively multiplayer online games and 2D/3D virtual worlds has been a lon
g standing concern in HCI and CSCW. As online social spaces evolve tow
ards more natural embodied interaction, it is important to explore how
 non-verbal communication can be supported in more nuanced ways in the
se spaces and introduce new social interaction consequences. In this p
aper we especially focus on understanding novel non-verbal communicati
on in social virtual reality (VR). We report findings of two empirical
 studies. Study 1 collected observational data to explore the types of
 non-verbal interactions being used naturally in social VR. Study 2 wa
s an interview study (N=30) that investigated people's perceptions of 
non-verbal communication in social VR as well as the resulting interac
tion outcomes. This study helps address the limitations in prior liter
ature on non-verbal communication dynamics in online social spaces. Ou
r findings on what makes non-verbal communication in social VR unique 
and socially desirable extend our current understandings of the role o
f non-verbal communication in social interaction. We also highlight po
tential design implications that aim at better supporting non-verbal c
ommunication in social VR.
AU  - Maloney, Divine
AU  - Freeman, Guo
AU  - Wohn, Donghee Yvette
DA  - 2020/10//
PY  - 2020
DO  - 10.1145/3415246
ID  - 10.1145/3415246
IS  - CSCW2
KW  - computer-mediated communication
KW  - non-verbal communication
KW  - online social spaces
KW  - social dynamics
KW  - social virtual reality
KW  - social vr
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - "Talking without a Voice": Understanding Non-verbal Communication in S
ocial Virtual Reality
UR  - https://doi.org/10.1145/3415246
VL  - 4
ER  - 
TY  - JOUR
AB  - This paper presents the development and evaluation of the use of virtu
al reality technology, together with appropriately adapted exercises t
hrough an augmented reality interface, to create Virtual Exercise Envi
ronments (VEEs). These environments allow persons with lower body disa
bilities to exercise and train just like what people do in real world.
 The major aim of this research is an architecture to create virtual e
xercise environments for people with lower body disabilities, which ca
n make exercise more enjoyable and less repetitive. This paper present
s our current research on this architecture to facilitate participatio
n and adherence using a VEE as a prototype and common-off-the-shelf ha
rdware components.
AU  - Zhang, Shaojie
AU  - Banerjee, P. Pat
AU  - Luciano, Cristian
DA  - 2011/1//
PY  - 2011
DO  - 10.1145/1948954.1948964
ID  - 10.1145/1948954.1948
IS  - 99
SN  - 1558-2337
SP  - 55-59
T2  - SIGACCESS Access. Comput.
TI  - Immersive virtual exercise environment for people with lower body disa
bilities
UR  - https://doi.org/10.1145/1948954.1948964
ER  - 
TY  - CONF
AB  - This paper proposes a new communication system called RoCoS (Room-base
d Communication System) that allows multiple users to communicate with
 each other through their virtual 3D spaces called rooms located on th
e Internet. This system consists of two main sub-systems, i.e., 3D Mes
senger and Edit Tool. 3D Messenger provides multiple users with their 
collaborative operable and communicable environment on the Internet. E
dit Tool allows each user to create his/her own virtual 3D space, i.e.
, individual room, and to create any avatar represented as his/her own
 3D character used in 3D Messenger. Each room provided by 3D Messenger
 is regarded as 3D version of a web page because each room exists sepa
rately on its dedicated computer managed by its owner (Administrator) 
and the owner can edit, decorate and modify his/her room as he/she wan
ts using Edit tool. This paper describes details and clarifies the use
fulness of the system by showing its several functionalities and appli
cation examples.
AU  - Miyahara, Katsunori
AU  - Nakamura, Naoto
AU  - Okada, Yoshihiro
C1  - Athens, Greece
C3  - Proceedings of the International Conference on Advances in Computer En
tertainment Technology
DA  - 2009///
C2  - 2009
DO  - 10.1145/1690388.1690390
ID  - 10.1145/1690388.1690
KW  - collaborative environment
KW  - distributed virtual space
KW  - human interface
KW  - peer-to-peer
KW  - software component
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781605588643
SP  - 3-10
T3  - ACE '09
TI  - RoCoS: room-based communication system and its aspect as development t
ool for 3D entertainment applications
UR  - https://doi.org/10.1145/1690388.1690390
ER  - 
TY  - CONF
AB  - VR has received increased attention as an educational tool and many ar
gue it is destined to influence educational practices, especially with
 the emergence of the Metaverse. Most prior research on educational VR
 reports on applications or systems designed for specified educational
 or training objectives. However, it is also crucial to understand cur
rent practices and attitudes across disciplines, having a holistic vie
w to extend the body of knowledge in terms of VR adoption in an authen
tic setting. Taking a higher-level perception of people in different r
oles, we conducted a qualitative analysis based on 23 interviews with 
major stakeholders and a series of participatory design workshops with
 instructors and students. We identified the stakeholders who need to 
be considered for using VR in higher education, and highlighted the ch
allenges and opportunities critical for VR current and potential pract
ices in the university classroom. Finally, we discussed the design imp
lications based on our findings. This study contributes a detailed des
cription of current perceptions and considerations from a multi-stakeh
older perspective, providing new empirical insights for designing nove
l VR and HCI technologies in higher education.
AU  - Jin, Qiao
AU  - Liu, Yu
AU  - Yarosh, Svetlana
AU  - Han, Bo
AU  - Qian, Feng
C1  - New Orleans, LA, USA
C3  - Proceedings of the 2022 CHI Conference on Human Factors in Computing S
ystems
DA  - 2022///
C2  - 2022
DO  - 10.1145/3491102.3517542
ID  - 10.1145/3491102.3517
KW  - Virtual Reality
KW  - collaboration
KW  - educational VR
KW  - higher education
KW  - multi-stakeholder
KW  - social VR
PB  - Association for Computing Machinery
SN  - 9781450391573
T3  - CHI '22
TI  - How Will VR Enter University Classrooms? Multi-stakeholders Investigat
ion of VR in Higher Education
UR  - https://doi.org/10.1145/3491102.3517542
ER  - 
TY  - CONF
AB  - This paper presents a new form of remote active tangible interactions 
built with the Display-based Measurement and Control System. A prototy
pe system was constructed to demonstrate the concepts of coupled remot
e tangible objects on rear projected tabletop displays. A user evaluat
ion measuring social presence for two users performing a furniture pla
cement task was performed, to determine a difference between this new 
system and a traditional mouse.
AU  - Richter, Jan
AU  - Thomas, Bruce H.
AU  - Sugimoto, Maki
AU  - Inami, Masahiko
C1  - Baton Rouge, Louisiana
C3  - Proceedings of the 1st International Conference on Tangible and Embedd
ed Interaction
DA  - 2007///
C2  - 2007
DO  - 10.1145/1226969.1226977
ID  - 10.1145/1226969.1226
KW  - tangible user interfaces
KW  - remote interfaces
KW  - evaluation
PB  - Association for Computing Machinery
SN  - 9781595936196
SP  - 39-42
T3  - TEI '07
TI  - Remote active tangible interactions
UR  - https://doi.org/10.1145/1226969.1226977
ER  - 
TY  - JOUR
AB  - The development of novel shape-changing or actuated tabletop tangible 
interfaces opens new perspectives for the design of physical and dynam
ic maps, especially for visually impaired (VI) users. Such maps would 
allow non-visual haptic exploration with advanced functions, such as p
anning and zooming. In this study, we designed an actuated tangible ta
bletop interface, called BotMap, allowing the exploration of geographi
c data through non-visual panning and zooming. In BotMap, small robots
 represent landmarks and move to their correct position whenever the m
ap is refreshed. Users can interact with the robots to retrieve the na
mes of the landmarks they represent. We designed two interfaces, named
 Keyboard and Sliders, which enable users to pan and zoom. Two evaluat
ions were conducted with, respectively, ten blindfolded and eight VI p
articipants. Results show that both interfaces were usable, with a sli
ght advantage for the Keyboard interface in terms of navigation perfor
mance and map comprehension, and that, even when many panning and zoom
ing operations were required, VI participants were able to understand 
the maps. Most participants managed to accurately reconstruct maps aft
er exploration. Finally, we observed three VI people using the system 
and performing a classical task consisting in finding the more appropr
iate itinerary for a journey.
AU  - Ducasse, Julie
AU  - Macé, Marc
AU  - Oriola, Bernard
AU  - Jouffrais, Christophe
DA  - 2018/9//
PY  - 2018
DO  - 10.1145/3204460
ID  - 10.1145/3204460
IS  - 4
KW  - Visual impairment
KW  - actuated interface
KW  - interactive map
KW  - non-visual interaction
KW  - pan
KW  - tactile map
KW  - tangible interaction
KW  - tangible user interface
KW  - zoom
SN  - 1073-0516
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - BotMap: Non-Visual Panning and Zooming with an Actuated Tabletop Tangi
ble Interface
UR  - https://doi.org/10.1145/3204460
VL  - 25
ER  - 
TY  - BOOK
CY  - Corfu, Greece
DA  - 2023///
PY  - 2023
ID  - 10.1145/3594806
PB  - Association for Computing Machinery
SN  - 9798400700699
TI  - PETRA '23: Proceedings of the 16th International Conference on PErvasi
ve Technologies Related to Assistive Environments
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3701571
PB  - Association for Computing Machinery
SN  - 9798400712838
TI  - MUM '24: Proceedings of the International Conference on Mobile and Ubi
quitous Multimedia
ER  - 
TY  - BOOK
CY  - Evry-Courcouronnes, France
DA  - 2022///
PY  - 2022
ID  - 10.1145/3564533
PB  - Association for Computing Machinery
SN  - 9781450399142
TI  - Web3D '22: Proceedings of the 27th International Conference on 3D Web 
Technology
ER  - 
TY  - CONF
AB  - We present a system for the actuation of tangible magnetic widgets (Ma
dgets) on interactive tabletops. Our system combines electromagnetic a
ctuation with fiber optic tracking to move and operate physical contro
ls. The presented mechanism supports actuating complex tangibles that 
consist of multiple parts. A grid of optical fibers transmits marker p
ositions past our actuation hardware to cameras below the table. We in
troduce a visual tracking algorithm that is able to detect objects and
 touches from the strongly sub-sampled video input of that grid. Six s
ample Madgets illustrate the capabilities of our approach, ranging fro
m tangential movement and height actuation to inductive power transfer
. Madgets combine the benefits of passive, untethered, and translucent
 tangibles with the ability to actuate them with multiple degrees of f
reedom.
AU  - Weiss, Malte
AU  - Schwarz, Florian
AU  - Jakubowski, Simon
AU  - Borchers, Jan
C1  - New York, New York, USA
C3  - Proceedings of the 23nd Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2010///
C2  - 2010
DO  - 10.1145/1866029.1866075
ID  - 10.1145/1866029.1866
KW  - actuation
KW  - multi-touch
KW  - tabletop interaction
KW  - tangible user interfaces
KW  - widgets
PB  - Association for Computing Machinery
SN  - 9781450302715
SP  - 293-302
T3  - UIST '10
TI  - Madgets: actuating widgets on interactive tabletops
UR  - https://doi.org/10.1145/1866029.1866075
ER  - 
TY  - CONF
AB  - Art education plays a central role in early childhood development, and
 museum outreach programs can significantly enhance art education expe
riences for K-2 learners in schools. Increased demand for remote learn
ing environments where students and teachers are not co-located has fo
rced educational contexts to adopt technology-mediated learning. Howev
er, little research has investigated how technology can integrate muse
um content into fully remote, K-2 school art education. We elicited de
sign requirements for K-2 art education platforms in a needs assessmen
t study through surveys (N = 22) and interviews (N = 4) with educators
. We created a typology of existing platforms, which we evaluated agai
nst these requirements. We identified a key unmet need for students to
 receive feedback on their fine motor skills, and, in response, we cre
ated a prototype system with interactive scissors called Chameleon Cli
ppers. We demonstrate its potential to provide this feedback through p
reliminary user tests with 4–7-year-old children (N=12).
AU  - Mansi, Gennie
AU  - Kim, Sue Reon
AU  - Roberts, Jessica
C1  - Braga, Portugal
C3  - Proceedings of the 21st Annual ACM Interaction Design and Children Con
ference
DA  - 2022///
C2  - 2022
DO  - 10.1145/3501712.3529731
ID  - 10.1145/3501712.3529
KW  - Art Education
KW  - Distance learning
KW  - K-2
PB  - Association for Computing Machinery
SN  - 9781450391979
SP  - 150-184
T3  - IDC '22
TI  - Ready, Set, Art: Technology Needs and Tools for Remote K-2 Art Educati
on
UR  - https://doi.org/10.1145/3501712.3529731
ER  - 
TY  - CONF
AB  - The combined use of sound and image has a rich history, from audiovisu
al artworks to research exploring the potential of data visualization 
and sonification. However, we lack standard tools or guidelines for au
diovisual (AV) interaction design, particularly for live performance. 
We propose the AVUI (AudioVisual User Interface), where sound and imag
e are used together in a cohesive way in the interface; and an enablin
g technology, the ofxAVUI toolkit. AVUI guidelines and ofxAVUI were de
veloped in a three-stage process, together with AV producers: 1) parti
cipatory design activities; 2) prototype development; 3) encapsulation
 of prototype as a plug-in, evaluation, and roll out. Best practices i
dentified include: reconfigurable interfaces and mappings; object-orie
nted packaging of AV and UI; diverse sound visualization; flexible med
ia manipulation and management. The toolkit and a mobile app developed
 using it have been released as open-source. Guidelines and toolkit de
monstrate the potential of AVUI and offer designers a convenient frame
work for AV interaction design.
AU  - Correia, Nuno N.
AU  - Tanaka, Atau
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI Conference on Human Factors in Computing S
ystems
DA  - 2017///
C2  - 2017
DO  - 10.1145/3025453.3026042
ID  - 10.1145/3025453.3026
KW  - audiovisual
KW  - crossmodal interaction
KW  - hackathons
KW  - interaction design
KW  - interface builder
KW  - participatory design
KW  - prototyping
KW  - toolkit
KW  - user interface
PB  - Association for Computing Machinery
SN  - 9781450346559
SP  - 1093-1104
T3  - CHI '17
TI  - AVUI: Designing a Toolkit for Audiovisual Interfaces
UR  - https://doi.org/10.1145/3025453.3026042
ER  - 
TY  - CONF
AB  - Communicating spatial information by pointing is ubiquitous in human i
nteractions. With the growing use of head-mounted cameras for collabor
ative purposes, it is important to assess how accurately viewers of th
e resulting egocentric videos can interpret pointing acts. We conducte
d an experiment to compare the accuracy of interpreting four different
 pointing techniques: hand pointing, head pointing, gaze pointing and 
hand+gaze pointing. Our results suggest that superimposing the gaze in
formation on the egocentric video can enable viewers to determine poin
ting targets more accurately and more confidently. Hand pointing perfo
rmed best when the pointing target was straight ahead and head pointin
g was the least preferred in terms of ease of interpretation. Our resu
lts can inform the design of collaborative applications that make use 
of the egocentric view.
AU  - Akkil, Deepak
AU  - Isokoski, Poika
C1  - Heidelberg, Germany
C3  - Proceedings of the 2016 ACM International Joint Conference on Pervasiv
e and Ubiquitous Computing
DA  - 2016///
C2  - 2016
DO  - 10.1145/2971648.2971687
ID  - 10.1145/2971648.2971
KW  - accuracy of spatial referencing
KW  - collaboration
KW  - egocentric video
KW  - gaze augmentation
KW  - pointing
PB  - Association for Computing Machinery
SN  - 9781450344616
SP  - 262-273
T3  - UbiComp '16
TI  - Accuracy of interpreting pointing gestures in egocentric view
UR  - https://doi.org/10.1145/2971648.2971687
ER  - 
TY  - BOOK
CY  - Lisbon, Portugal
DA  - 2022///
PY  - 2022
ID  - 10.1145/3568444
PB  - Association for Computing Machinery
SN  - 9781450398206
TI  - MUM '22: Proceedings of the 21st International Conference on Mobile an
d Ubiquitous Multimedia
ER  - 
TY  - CONF
AB  - Animating virtual characters is a complex task, which requires profess
ional animators and performers, expensive motion capture systems, or c
onsiderable amounts of time to generate convincing results. In this pa
per we introduce the SmurVEbox, which is a cost-effective animating sy
stem that encompasses many important aspects of animating virtual char
acters by providing a novel shared user experience. SmurVEbox is a col
laborative environment for generating character animations in real tim
e, which has the potential to enhance the computer animation process. 
Our setup allows animators and performers to cooperate on the same vir
tual animation sequence in real time. Performers are able to communica
te with the animator in the real space while simultaneously perceiving
 the effects of their actions on the virtual character in the virtual 
space. The animator can refine actions of a performer in real time so 
that both collaborate together on the same animation of a virtual char
acter. We describe the setup and present a simple application.
AU  - Beimler, Rüdiger
AU  - Bruder, Gerd
AU  - Steinicke, Frank
C1  - Laval, France
C3  - Proceedings of the Virtual Reality International Conference: Laval Vir
tual
DA  - 2013///
C2  - 2013
DO  - 10.1145/2466816.2466818
ID  - 10.1145/2466816.2466
KW  - character animation
KW  - collaborative environment
KW  - computer animation
KW  - computer graphics
KW  - motion capture
KW  - multi-touch
KW  - real-time
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450318754
T3  - VRIC '13
TI  - SmurVEbox: a smart multi-user real-time virtual environment for genera
ting character animations
UR  - https://doi.org/10.1145/2466816.2466818
ER  - 
TY  - BOOK
AB  - Changing the Human ExperienceSIGGRAPH 2018 showcases emerging technolo
gies that are exponentially expanding our human experience. The intern
et of things, the quantitative self, and immersive technologies have m
atured, and the new data systems that support these innovations make w
ay for more invention and interconnectedness.A variety of new research
 at SIGGRAPH 2018 will be showcased, including work focused on persona
l vicissitude; new products and systems to surround us in comfort and 
function; and new technologies designed to change the way we will appr
oach sports, games and active watching.
CY  - Vancouver, British Columbia, Canada
DA  - 2018///
PY  - 2018
ID  - 10.1145/3214907
PB  - Association for Computing Machinery
SN  - 9781450358101
TI  - SIGGRAPH '18: ACM SIGGRAPH 2018 Emerging Technologies
ER  - 
TY  - JOUR
AB  - Telehaptic applications involve delay-sensitive multimedia communicati
on between remote locations with distinct Quality of Service (QoS) req
uirements for different media components. These QoS constraints pose a
 variety of challenges, especially when the communication occurs over 
a shared network, with unknown and time-varying cross-traffic. In this
 work, we propose a transport layer congestion control protocol for te
lehaptic applications operating over shared networks, termed as Dynami
c Packetization Module (DPM). DPM is a lossless, network-aware protoco
l that tunes the telehaptic packetization rate based on the level of c
ongestion in the network. To monitor the network congestion, we devise
 a novel network feedback module, which communicates the end-to-end de
lays encountered by the telehaptic packets to the respective transmitt
ers with negligible overhead. Via extensive simulations, we show that 
DPM meets the QoS requirements of telehaptic applications over a wide 
range of network cross-traffic conditions. We also report qualitative 
results of a real-time telepottery experiment with several human subje
cts, which reveal that DPM preserves the quality of telehaptic activit
y even under heavily congested network scenarios. Finally, we compare 
the performance of DPM with several previously proposed telehaptic com
munication protocols and demonstrate that DPM outperforms these protoc
ols.
AU  - Gokhale, Vineet
AU  - Nair, Jayakrishnan
AU  - Chaudhuri, Subhasis
DA  - 2017/3//
PY  - 2017
DO  - 10.1145/3052821
ID  - 10.1145/3052821
IS  - 2
KW  - QoS
KW  - Telehaptic communication
KW  - congestion control
KW  - dynamic rate adaptation
KW  - multimedia
KW  - transport layer
SN  - 1551-6857
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
TI  - Congestion Control for Network-Aware Telehaptic Communication
UR  - https://doi.org/10.1145/3052821
VL  - 13
ER  - 
TY  - CONF
AB  - Although generic usability heuristics lists have been popular with res
earchers and practitioners, emerging new technologies have called for 
more specific heuristics. One of these heuristics was proposed by Sutc
liffe and Gault in 2004 [37]. This paper examines research which has c
ited these heuristics with the aim to see how it has been exploited. T
he results showed that a fifth of the papers citing the heuristics hav
e used the heuristics fully or partly, and that researchers have adapt
ed it to their current needs. Following this result we proposed that a
 patchwork of heuristics might be more useful than a single list. We e
valuated a crisis management training simulator using the virtual real
ity heuristics and discussed how the outcome of the evaluation fitted 
the patchwork.
AU  - Hvannberg, Ebba Thora
AU  - Halldórsdóttir, Gyda
AU  - Rudinsky, Jan
C1  - Copenhagen, Denmark
C3  - Proceedings of the 7th Nordic Conference on Human-Computer Interaction
: Making Sense Through Design
DA  - 2012///
C2  - 2012
DO  - 10.1145/2399016.2399065
ID  - 10.1145/2399016.2399
KW  - crisis management training
KW  - heuristics evaluation
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450314824
SP  - 308-317
T3  - NordiCHI '12
TI  - Exploitation of heuristics for virtual environments
UR  - https://doi.org/10.1145/2399016.2399065
ER  - 
TY  - CONF
AB  - We investigate how spatial layout in public environments like workplac
es, fairs, or conferences influences a user's VR experience. In partic
ular, we compare environments in which an HMD user is (a) surrounded b
y other people, (b) physically separated by a barrier, or (c) in a sep
arate room. In contrast to lab environments, users in public environme
nts are affected by physical threats (for example, other people in the
 space running into them) but also cognitive threats (for example, not
 knowing, what happens in the real world), as known from research on p
roxemics or social facilitation. We contribute an extensive discussion
 of the factors influencing a user's VR experience in public. Based on
 this we conducted a between-subject design user study (N=58) to under
stand the differences between the three environments. As a result, we 
present implications regarding (1) spatial layout, (2) behavior of the
 VR system operator, and (3) the VR experience that helps both HCI res
earchers as well as practitioners to enhance users' VR experience in p
ublic environments.
AU  - Mai, Christian
AU  - Wiltzius, Tim
AU  - Alt, Florian
AU  - Hußmann, Heinrich
C1  - Oslo, Norway
C3  - Proceedings of the 10th Nordic Conference on Human-Computer Interactio
n
DA  - 2018///
C2  - 2018
DO  - 10.1145/3240167.3240200
ID  - 10.1145/3240167.3240
KW  - head-mounted displays
KW  - public spaces
KW  - user experience
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450364379
SP  - 286-298
T3  - NordiCHI '18
TI  - Feeling alone in public: investigating the influence of spatial layout
 on users' VR experience
UR  - https://doi.org/10.1145/3240167.3240200
ER  - 
TY  - CONF
AB  - This paper describes a computer aided design tool for mechanical engin
eering applications, combining component assembly simulation, the mode
lling of rigid and flexible bodies and haptic interaction in a multi-u
ser distributed virtual environment. It presents the research challeng
es encountered, and an architecture designed to address these.
AU  - Marsh, J.
AU  - Glencross, M.
AU  - Pettifer, S.
AU  - Hubbold, R. J.
AU  - Cook, J.
AU  - Daubrenet, S.
C1  - Singapore
C3  - Proceedings of the 2004 ACM SIGGRAPH International Conference on Virtu
al Reality Continuum and Its Applications in Industry
DA  - 2004///
C2  - 2004
DO  - 10.1145/1044588.1044672
ID  - 10.1145/1044588.1044
PB  - Association for Computing Machinery
SN  - 1581138849
SP  - 386-389
T3  - VRCAI '04
TI  - Minimising latency and maintaining consistency in distributed virtual 
prototyping
UR  - https://doi.org/10.1145/1044588.1044672
ER  - 
TY  - BOOK
CY  - Bend, OR, USA
DA  - 2022///
PY  - 2022
ID  - 10.1145/3526114
PB  - Association for Computing Machinery
SN  - 9781450393218
TI  - UIST '22 Adjunct: Adjunct Proceedings of the 35th Annual ACM Symposium
 on User Interface Software and Technology
ER  - 
TY  - CONF
AB  - This paper responds to a 2014 paper by Liu et al seeking a quantifiabl
e thematic core to CHI. As an alternative, I argue that CHI should str
ategically avoid the search for such a core, instead seeking its ident
ity as a mode of responding and contributing to other disciplines.
AU  - Blackwell, Alan F.
C1  - Seoul, Republic of Korea
C3  - Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Hu
man Factors in Computing Systems
DA  - 2015///
C2  - 2015
DO  - 10.1145/2702613.2732505
ID  - 10.1145/2702613.2732
KW  - collaboration
KW  - innovation
KW  - interdisciplinarity
PB  - Association for Computing Machinery
SN  - 9781450331463
SP  - 503-516
T3  - CHI EA '15
TI  - HCI as an Inter-Discipline
UR  - https://doi.org/10.1145/2702613.2732505
ER  - 
TY  - CONF
AB  - Human-Centered Computing (HCC) is a set of methodologies that apply to
 any field that uses computers, in any form, in applications in which 
humans directly interact with devices or systems that use computer tec
hnologies. In this paper, we give an overview of HCC from a Multimedia
 perspective. We describe what we consider to be the three main areas 
of Human-Centered Multimedia (HCM): media production, analysis, and in
teraction. In addition, we identify the core characteristics of HCM, d
escribe example applications, and propose a research agenda for HCM.
AU  - Jaimes, Alejandro
AU  - Sebe, Nicu
AU  - Gatica-Perez, Daniel
C1  - Santa Barbara, CA, USA
C3  - Proceedings of the 14th ACM International Conference on Multimedia
DA  - 2006///
C2  - 2006
DO  - 10.1145/1180639.1180829
ID  - 10.1145/1180639.1180
KW  - human-centered computing
KW  - multimedia
KW  - multimodal
PB  - Association for Computing Machinery
SN  - 1595934472
SP  - 855-864
T3  - MM '06
TI  - Human-centered computing: a multimedia perspective
UR  - https://doi.org/10.1145/1180639.1180829
ER  - 
TY  - CONF
AB  - With the varied use of games, the need to measure player's involvement
 has become prominent. Several studies aimed to quantify users' involv
ement. However, none of these studies presented a robust framework to 
measure the player's involvement in games nor considered player types 
as a factor. In this paper, a framework to quantify automatically the 
players' involvement in games is presented. This framework consists of
 three levels and each level includes criteria to evaluate three aspec
ts of 3D games: (1) application level, (2) usage level, and (3) conten
t level. Additionally, the framework's criteria considers player types
 proposed by Bartle. To validate the results of the framework, player 
involvement was estimated manually on a case-by-case basis by three ex
perienced evaluators. The manual estimation was then compared with the
 automatically generated-quantified result produced by the framework. 
The comparison revealed a significant match.
AU  - Hanna, Nader
AU  - Richards, Deborah
AU  - Hitchens, Michael
AU  - Jacobson, Michael J.
C1  - Newcastle, NSW, Australia
C3  - Proceedings of the 2014 Conference on Interactive Entertainment
DA  - 2014///
C2  - 2014
DO  - 10.1145/2677758.2677763
ID  - 10.1145/2677758.2677
KW  - Framework
KW  - Game
KW  - Objective Measurement
KW  - Player Types
KW  - Player's Involvement
KW  - Quantification
PB  - Association for Computing Machinery
SN  - 9781450327909
SP  - 1-10
T3  - IE2014
TI  - Towards Quantifying Player's Involvement in 3D Games Based-on Player T
ypes
UR  - https://doi.org/10.1145/2677758.2677763
ER  - 
TY  - CONF
AB  - Current desktop workspace environments consist of a vertical area (e.g
., a screen with a virtual desktop) and a horizontal area (e.g., the p
hysical desk). Daily working activities benefit from different intrins
ic properties of both of these areas. However, both areas are distinct
 from each other, making data exchange between them cumbersome. Theref
ore, we present Curve, a novel interactive desktop environment, which 
combines advantages of vertical and horizontal working areas using a c
ontinous curved connection. This connection offers new ways of direct 
multi-touch interaction and new ways of information visualization. We 
describe our basic design, the ergonomic adaptions we made, and discus
s technical challenges we met and expect to meet while building and co
nfiguring the system.
AU  - Wimmer, Raphael
AU  - Hennecke, Fabian
AU  - Schulz, Florian
AU  - Boring, Sebastian
AU  - Butz, Andreas
AU  - Hußmann, Heinrich
C1  - Reykjavik, Iceland
C3  - Proceedings of the 6th Nordic Conference on Human-Computer Interaction
: Extending Boundaries
DA  - 2010///
C2  - 2010
DO  - 10.1145/1868914.1868977
ID  - 10.1145/1868914.1868
KW  - curve
KW  - digital desks
KW  - direct-touch
KW  - ergonomics
KW  - interactive surfaces
KW  - tabletop interfaces
KW  - workplace
PB  - Association for Computing Machinery
SN  - 9781605589343
SP  - 561-570
T3  - NordiCHI '10
TI  - Curve: revisiting the digital desk
UR  - https://doi.org/10.1145/1868914.1868977
ER  - 
TY  - CONF
AB  - In this paper we propose the concept of Synthetic Space - architectura
l space fused with the properties of digital bits. Past efforts at int
egrating digital technology into architectural space have generally as
sumed architecture to be a stable, invariant background onto which lay
ers of digital information/devices/services can be overlaid. In Synthe
tic Space, however, this stability is instead superseded by the capric
ious plasticity of digital data. For future inhabitants of Synthetic S
pace, transforming the makeup of the surrounding built environment wil
l be a trivial, effortless task, equivalent to changing the wallpaper 
image on a modern-day PC or smartphone.
AU  - Takeuchi, Yuichiro
C1  - Austin, Texas, USA
C3  - CHI '12 Extended Abstracts on Human Factors in Computing Systems
DA  - 2012///
C2  - 2012
DO  - 10.1145/2212776.2212803
ID  - 10.1145/2212776.2212
KW  - digitizing architecture
KW  - habitable bits
KW  - synthetic space
PB  - Association for Computing Machinery
SN  - 9781450310161
SP  - 251-260
T3  - CHI EA '12
TI  - Synthetic space: inhabiting binaries
UR  - https://doi.org/10.1145/2212776.2212803
ER  - 
TY  - JOUR
AB  - The evaluation of scientific collaboratories has lagged behind their d
evelopment. Do the capabilities afforded by collaboratories outweigh t
heir disadvantages? To evaluate a scientific collaboratory system, we 
conducted a repeated-measures controlled experiment that compared the 
outcomes and process of scientific work completed by 20 pairs of parti
cipants (upper level undergraduate science students) working face-to-f
ace and remotely. We collected scientific outcomes (graded lab reports
) to investigate the quality of scientific work, post-questionnaire da
ta to measure the adoptability of the system, and post-interviews to u
nderstand the participants' views of doing science under both conditio
ns. We hypothesized that study participants would be less effective, r
eport more difficulty, and be less favorably inclined to adopt the sys
tem when collaborating remotely. Contrary to expectations, the quantit
ative data showed no statistically significant differences with respec
t to effectiveness and adoption.The qualitative data helped explain th
is null result: participants reported advantages and disadvantages wor
king under both conditions and developed work-arounds to cope with the
 perceived disadvantages of collaborating remotely. While the data ana
lysis produced null results, considered as a whole, the analysis leads
 us to conclude there is positive potential for the development and ad
option of scientific collaboratory systems.
AU  - Sonnenwald, Diane H.
AU  - Whitton, Mary C.
AU  - Maglaughlin, Kelly L.
DA  - 2003/6//
PY  - 2003
DO  - 10.1145/772047.772051
ID  - 10.1145/772047.77205
IS  - 2
KW  - Scientific collaboratory
KW  - collaboration
KW  - controlled experiment
KW  - geographically-distributed work
KW  - nanoscience
SN  - 1073-0516
SP  - 150-176
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - Evaluating a scientific collaboratory: Results of a controlled experim
ent
UR  - https://doi.org/10.1145/772047.772051
VL  - 10
ER  - 
TY  - CONF
AB  - We introduce a customizable, reusable actuated tangible user interface
 object: ACTO. Its modular design allows quick adaptations for differe
nt scenarios and setups on tabletops, making otherwise integral parts 
like the actuation mechanism or the physical configuration interchange
able. Drawing on the resources of well-established maker communities m
akes prototyping especially quick and easy. This allows the exploratio
n of new concepts without the need to redesign the whole system, which
 qualifies it as an ideal research and education platform for tangible
 user interfaces. We present a detailed description of the hardware an
d software architecture of our system. Several implemented example con
figurations and application scenarios demonstrate the capabilities of 
the platform.
AU  - Vonach, Emanuel
AU  - Gerstweiler, Georg
AU  - Kaufmann, Hannes
C1  - Dresden, Germany
C3  - Proceedings of the Ninth ACM International Conference on Interactive T
abletops and Surfaces
DA  - 2014///
C2  - 2014
DO  - 10.1145/2669485.2669522
ID  - 10.1145/2669485.2669
KW  - actuation
KW  - haptics
KW  - physical control
KW  - prototyping platform
KW  - tabletop interaction
KW  - tangible user interfaces
KW  - widgets
PB  - Association for Computing Machinery
SN  - 9781450325875
SP  - 259-268
T3  - ITS '14
TI  - ACTO: A Modular Actuated Tangible User Interface Object
UR  - https://doi.org/10.1145/2669485.2669522
ER  - 
TY  - CONF
AB  - In this paper we discuss the scenario of Petroleum Engineering project
s of Petrobras, a large Brazilian governmental oil &amp; gas company. 
Based on this scenario, we propose a set of application requirements a
nd system architecture to guide the construction of a Collaborative En
gineering Environment (CEE) for assisting the control and execution of
 large and complex industrial projects in oil and gas industry. The en
vironment is composed by the integration of three different technologi
es of distributed group work: Workflow Management System (WfMS), Multi
media Collaborative System (MMCS) and Collaborative Virtual Environmen
ts (CVE).
AU  - Santos, Ismael H. F.
AU  - Göbel, Martin
AU  - Raposo, Alberto B.
AU  - Gattass, Marcelo
C1  - Singapore
C3  - Proceedings of the 2004 ACM SIGGRAPH International Conference on Virtu
al Reality Continuum and Its Applications in Industry
DA  - 2004///
C2  - 2004
DO  - 10.1145/1044588.1044609
ID  - 10.1145/1044588.1044
KW  - collaborative engineering
KW  - collaborative virtual environments
KW  - workflow systems
PB  - Association for Computing Machinery
SN  - 1581138849
SP  - 112-119
T3  - VRCAI '04
TI  - A multimedia workflow-based collaborative engineering environment for 
oil &amp; gas industry
UR  - https://doi.org/10.1145/1044588.1044609
ER  - 
TY  - CONF
AB  - This paper introduces swarm user interfaces, a new class of human-comp
uter interfaces comprised of many autonomous robots that handle both d
isplay and interaction. We describe the design of Zooids, an open-sour
ce open-hardware platform for developing tabletop swarm interfaces. Th
e platform consists of a collection of custom-designed wheeled micro r
obots each 2.6 cm in diameter, a radio base-station, a high-speed DLP 
structured light projector for optical tracking, and a software framew
ork for application development and control. We illustrate the potenti
al of tabletop swarm user interfaces through a set of application scen
arios developed with Zooids, and discuss general design considerations
 unique to swarm user interfaces.
AU  - Le Goc, Mathieu
AU  - Kim, Lawrence H.
AU  - Parsaei, Ali
AU  - Fekete, Jean-Daniel
AU  - Dragicevic, Pierre
AU  - Follmer, Sean
C1  - Tokyo, Japan
C3  - Proceedings of the 29th Annual Symposium on User Interface Software an
d Technology
DA  - 2016///
C2  - 2016
DO  - 10.1145/2984511.2984547
ID  - 10.1145/2984511.2984
KW  - swarm user interfaces
KW  - tangible user interfaces
PB  - Association for Computing Machinery
SN  - 9781450341899
SP  - 97-109
T3  - UIST '16
TI  - Zooids: Building Blocks for Swarm User Interfaces
UR  - https://doi.org/10.1145/2984511.2984547
ER  - 
TY  - CONF
AB  - Physical construction and assembly tasks are often carried out by grou
ps of collocated workers, and they can be difficult to coordinate. Gro
up members must spend time deciding how to split up the task, how to a
ssign subtasks to each other, and in what order subtasks should be com
pleted. Informed by an observational study examining group coordinatio
n challenges, we built a task distribution system called WeBuild. Our 
custom algorithm dynamically assigns subtasks to workers in a group, t
aking into account factors such as the dependencies between subtasks a
nd the skills of each group member. Each worker views personalized ste
p-by-step instructions on a mobile phone, while a dashboard visualizes
 the entire process. An initial study found that WeBuild reduced the s
tart-up time needed to coordinate and begin a task, and provides direc
tion for future research to build on toward improving group efficiency
 and coordination for complex tasks.
AU  - Fraser, C. Ailie
AU  - Grossman, Tovi
AU  - Fitzmaurice, George
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI Conference on Human Factors in Computing S
ystems
DA  - 2017///
C2  - 2017
DO  - 10.1145/3025453.3026036
ID  - 10.1145/3025453.3026
KW  - assembly instructions
KW  - collaboration
KW  - coordination
KW  - task distribution
PB  - Association for Computing Machinery
SN  - 9781450346559
SP  - 1817-1830
T3  - CHI '17
TI  - WeBuild: Automatically Distributing Assembly Tasks Among Collocated Wo
rkers to Improve Coordination
UR  - https://doi.org/10.1145/3025453.3026036
ER  - 
TY  - CONF
AB  - Due to their simplicity and flexibility, digital pen-and-paper solutio
ns have a promising potential to become a part of our daily work. Unfo
rtunately, they lack dynamic visual feedback and thereby restrain adva
nced digital functionalities. In this paper, we investigate new forms 
of paper-integrated feedback, which build on emerging paper-based elec
tronics and novel thin-film display technologies. Our approach focuses
 on illuminated elements, which are seamlessly integrated into standar
d paper. For that, we introduce an extended design space for paper-int
egrated illuminations. As a major contribution, we present a systemati
c feedback repertoire for real-world applications including feedback c
omponents for innovative paper interaction tasks in five categories. F
urthermore, we contribute a fully-functional research platform includi
ng a paper-controller, digital pen and illuminated, digitally controll
ed papers that demonstrate the feasibility of our techniques. Finally,
 we report on six interviews, where experts rated our approach as intu
itive and very usable for various applications, in particular educatio
nal ones.
AU  - Klamka, Konstantin
AU  - Dachselt, Raimund
C1  - Denver, Colorado, USA
C3  - Proceedings of the 2017 CHI Conference on Human Factors in Computing S
ystems
DA  - 2017///
C2  - 2017
DO  - 10.1145/3025453.3025525
ID  - 10.1145/3025453.3025
KW  - anoto
KW  - augmented paper
KW  - digital pen and paper
KW  - electro-luminescence
KW  - pen interaction
KW  - thin-film display
KW  - visual feedback
PB  - Association for Computing Machinery
SN  - 9781450346559
SP  - 5605-5618
T3  - CHI '17
TI  - IllumiPaper: Illuminated Interactive Paper
UR  - https://doi.org/10.1145/3025453.3025525
ER  - 
TY  - CONF
AB  - In the BEAMING project we have been extending the scope of collaborati
ve mixed reality to include the representation of users in multiple mo
dalities, including augmented reality, situated displays and robots. A
 single user (a visitor) uses a high-end virtual reality system (the t
ransporter) to be virtually teleported to a real remote location (the 
destination). The visitor may be tracked in several ways including emo
tion and motion capture. We reconstruct the destination and the people
 within it (the locals). In achieving this scenario, BEAMING has integ
rated many heterogeneous systems. In this paper, we describe the desig
n and key implementation choices in the Beaming Scene Service (BSS), w
hich allows the various processes to coordinate their behaviour. The c
ore of the system is a light-weight shared object repository that allo
ws loose coupling between processes with very different requirements (
e.g. embedded control systems through to mobile apps). The system was 
also extended to support the notion of presence awareness. We demonstr
ate two complex applications built with the BSS.
AU  - Oyekoya, Oyewole
AU  - Stone, Ran
AU  - Steptoe, William
AU  - Alkurdi, Laith
AU  - Klare, Stefan
AU  - Peer, Angelika
AU  - Weyrich, Tim
AU  - Cohen, Benjamin
AU  - Tecchia, Franco
AU  - Steed, Anthony
C1  - Singapore
C3  - Proceedings of the 19th ACM Symposium on Virtual Reality Software and 
Technology
DA  - 2013///
C2  - 2013
DO  - 10.1145/2503713.2503732
ID  - 10.1145/2503713.2503
KW  - interoperability
KW  - mixed reality
KW  - presence
KW  - telepresence
KW  - telerobotics
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450323796
SP  - 165-174
T3  - VRST '13
TI  - Supporting interoperability and presence awareness in collaborative mi
xed reality environments
UR  - https://doi.org/10.1145/2503713.2503732
ER  - 
TY  - CONF
AB  - Tangible user interfaces (TUIs) provide physical form to digital infor
mation and computation, facilitating the direct manipulation of bits. 
Our goal in TUI development is to empower collaboration, learning, and
 design by using digital technology and at the same time taking advant
age of human abilities to grasp and manipulate physical objects and ma
terials. This paper discusses a model of TUI, key properties, genres, 
applications, and summarizes the contributions made by the Tangible Me
dia Group and other researchers since the publication of the first Tan
gible Bits paper at CHI 1997. http://tangible.media.mit.edu/
AU  - Ishii, Hiroshi
C1  - Bonn, Germany
C3  - Proceedings of the 2nd International Conference on Tangible and Embedd
ed Interaction
DA  - 2008///
C2  - 2008
DO  - 10.1145/1347390.1347392
ID  - 10.1145/1347390.1347
KW  - ambient media
KW  - augmented reality
KW  - interaction design
KW  - tangible user interfaces
KW  - ubiquitous computing
PB  - Association for Computing Machinery
SN  - 9781605580043
SP  - xv-xxv
T3  - TEI '08
TI  - Tangible bits: beyond pixels
UR  - https://doi.org/10.1145/1347390.1347392
ER  - 
TY  - CONF
AU  - Azuma, Ronald
C1  - Los Angeles, CA
C3  - ACM SIGGRAPH 2004 Course Notes
DA  - 2004///
C2  - 2004
DO  - 10.1145/1103900.1103926
ID  - 10.1145/1103900.1103
PB  - Association for Computing Machinery
SN  - 9781450378017
SP  - 26-es
T3  - SIGGRAPH '04
TI  - Overview of augmented reality
UR  - https://doi.org/10.1145/1103900.1103926
ER  - 
TY  - BOOK
CY  - Vancouver, BC, Canada
DA  - 2023///
PY  - 2023
ID  - 10.1145/3592834
PB  - Association for Computing Machinery
SN  - 9798400701894
TI  - MMVE '23: Proceedings of the 15th International Workshop on Immersive 
Mixed and Virtual Environment Systems
ER  - 
TY  - CONF
AB  - Rope-based games such as jump rope, tug-of-war, and kite-flying promot
e physical activity and social interaction among people of all ages an
d especially in children during the development of their coordination 
skills and physical fitness. Our RopePlus system builds on those tradi
tional games by enabling players to participate remotely through inter
acting with ropes that connect physical and virtual spaces. The RopePl
us platform is centered around the rope as a tangible interface with v
arious hardware extensions to allow for multiple playing modes. In thi
s paper, we present two games that have been implemented in detail: a 
kite-flying game called Multi-Fly and a jump-rope game called Multi-Ju
mp. Our work aims to expand tangible interface gaming to real time soc
ial playing environments.
AU  - Yao, Lining
AU  - Dasgupta, Sayamindu
AU  - Cheng, Nadia
AU  - Spingarn-Koff, Jason
AU  - Rudakevych, Ostap
AU  - Ishii, Hiroshi
C1  - Vancouver, BC, Canada
C3  - CHI '11 Extended Abstracts on Human Factors in Computing Systems
DA  - 2011///
C2  - 2011
DO  - 10.1145/1979742.1979611
ID  - 10.1145/1979742.1979
KW  - athletic interaction
KW  - computer supported cooperative play
KW  - enhanced reality
KW  - exertion interface
KW  - kinesthetic interaction
KW  - remote playing
KW  - social game
KW  - tangible interface
PB  - Association for Computing Machinery
SN  - 9781450302685
SP  - 223-232
T3  - CHI EA '11
TI  - RopePlus: bridging distances with social and kinesthetic rope games
UR  - https://doi.org/10.1145/1979742.1979611
ER  - 
TY  - JOUR
AB  - Atmosphere - the sensorial qualities of a space, shaped by the composi
tion of light, sound, objects, people, etc. - has remarkable influence
 on our experiences and behavior. Manipulating it has been shown to be
 powerful, affecting cognitive performance, mood and even physiology, 
our work envisions and implements a smart office prototype, capable of
 digitally transforming its atmosphere - creating what we call Mediate
d Atmospheres (MA) - using computationally controlled lighting, video 
projection and sound. Additionally, we equipped this space with a modu
lar real-time data collection infrastructure, integrating a set of bio
signal sensors. Through a user study (N=29) we demonstrate MA's effect
s on occupants’ ability to focus and to recover from a stressful situa
tion. Our evaluation is based on subjective measurements of perception
, as well as objective measurements, extracted from recordings of hear
t rate variability and facial features. We compare multiple signal pro
cessing approaches for quantifying changes in occupant physiological s
tate. Our findings show that MA significantly (p&lt;0.05) affect occup
ants’ perception as well as physiological response, which encouragingl
y correlate with occupants’ perception. Our findings is a first step t
owards personalized control of the ambient atmosphere to support wellb
eing and productivity.
AU  - Zhao, Nan
AU  - Azaria, Asaph
AU  - Paradiso, Joseph A.
DA  - 2017/6//
PY  - 2017
DO  - 10.1145/3090096
ID  - 10.1145/3090096
IS  - 2
KW  - Wellbeing
KW  - Ubiquitous Computing
KW  - Smart Office
KW  - Restoration
KW  - Productivity
KW  - Perception
KW  - Multimodal
KW  - Mediated Atmospheres
KW  - Heart Rate Variability
KW  - Face Tracking
KW  - Augmented Reality
KW  - Adaptive Building
T2  - Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
TI  - Mediated Atmospheres: A Multimodal Mediated Work Environment
UR  - https://doi.org/10.1145/3090096
VL  - 1
ER  - 
TY  - CONF
AB  - As collaborative environments evolve beyond the desktop, we see the em
ergence of a new class of augmented collaborative spaces that employ v
arious devices and technologies to merge electronic information with p
hysical space to support collaboration, both local and remote. To be e
ffective, such spaces should give people the flexibility to combine th
eir individual resources with the resources available in the space, wh
ile presenting appropriate information, taking into account the larger
 process within which a collaborative activity takes place. This deman
ds richer ways of capturing content and actions, new ways of presentin
g multimodal information, and developing an architecture and infrastru
cture that unifies individuals, spaces, and processes to facilitate co
llaboration. Our work in steerable interfaces represents a first step 
in this direction.
AU  - Pingali, Gopal
AU  - Sukaviriya, Noi
C1  - Berkeley, California
C3  - Proceedings of the 2003 ACM SIGMM Workshop on Experiential Telepresenc
e
DA  - 2003///
C2  - 2003
DO  - 10.1145/982484.982487
ID  - 10.1145/982484.98248
KW  - action capture
KW  - business process modeling
KW  - conferencing
KW  - context modeling
KW  - interaction
KW  - interfaces
KW  - meetings
KW  - pervasive systems
KW  - presentation systems
KW  - ubiquitous computing
PB  - Association for Computing Machinery
SN  - 1581137753
SP  - 13-20
T3  - ETP '03
TI  - Augmented collaborative spaces
UR  - https://doi.org/10.1145/982484.982487
ER  - 
TY  - CONF
AB  - The question that this panel wishes to explore is: What are the future
 visualization trends and requirements for the oil and gas industry to
 efficiently handle and explore the ever-increasing volume and variety
 of available data?It has been proven many times that 3D visualization
 helps to reduce the risk in the search for, and development of, oil a
nd gas resources and has been generally acknowledged to be an indispen
sable technology for the oil and gas industry. The role of the geoscie
ntist is to combine his/her geological and geophysical expertise with 
the wide variety of data to find these natural resources and minimize 
the risk in the search for nature resources at the same time. The vari
ety and size of the data makes the requirements unique in the visualiz
ation field: The data volumes that must be visualized range from a few
 megabytes to over 100 gigabytes. Multiple kinds of data and interpret
ation must be overlaid on the visualization. Multiple models of the su
bsurface are possible. Multiple specialized visualization software too
ls are available for the geoscientist to use.Combining the right visua
lization tools with the right data can reduce exploration risk and mak
e the geoscientist a productive explorationist. This panel will explor
e the trends that are anticipated to meet the future needs of the Oil 
and Gas industry.
AU  - Evans, Francine
AU  - Volz, William
AU  - Dorn, Geoffrey
AU  - Fröhlich, Bernd
AU  - Roberts, David M
C1  - Boston, Massachusetts
C3  - Proceedings of the Conference on Visualization '02
DA  - 2002///
C2  - 2002
ID  - 10.5555/602099.60220
PB  - IEEE Computer Society
SN  - 0780374983
SP  - 567-570
T3  - VIS '02
TI  - Future trends in oil and gas visualization
ER  - 
TY  - CONF
AB  - Quality control and resource optimization are challenging problems in 
3D tele-immersive (3DTI) environments due to their large scale, multi-
stream dependencies and dynamic peer (viewer) behavior. Such systems a
re also prone to performance degradation due to undesired behavior in 
the event of drastic demand changes, such as view change and large-sca
le simultaneous viewer arrivals or departures. Therefore, it is crucia
l to localize undesired behavior inside the system and re-organize the
 streaming overlay structures accordingly. Doing this accurately for a
 large scale is even more challenging and it requires to capture all e
vents effecting the data plan and control plan of the system. Moreover
, to do this, we need to understand the desired behavior of the applic
ation first, which is defined by the dependency patterns of performanc
e and configuration metadata at each participating peers. To assist th
at, we propose a learning framework that discovers metadata dependency
 patterns from the time series metadata and uses an online profiler to
 detect undesired behavior of the system during run-time. Such univers
al protocol also enables the prediction of large scale performance deg
radation due to irregular dependencies. Finally an adaptation is propo
sed that reallocates the resources and rearranges overlay structures t
o overcome the undesired behavior. In summary, our goal is to provide 
a universal session monitoring and management framework for complex mu
lti-stream 3DTI environments to support large number of concurrent vie
wers. We consider the difficulty in overlay construction, collecting m
etadata, answering queries, learning patterns, detecting undesired beh
avior at the participating peers and finally overlay adaptation consid
ering multi-stream dependencies.
AU  - Arefin, Ahsan
C1  - Scottsdale, Arizona, USA
C3  - Proceedings of the 19th ACM International Conference on Multimedia
DA  - 2011///
C2  - 2011
DO  - 10.1145/2072298.2072489
ID  - 10.1145/2072298.2072
KW  - adaptation
KW  - learning
KW  - monitoring
KW  - resource allocation
KW  - streaming
PB  - Association for Computing Machinery
SN  - 9781450306164
SP  - 849-852
T3  - MM '11
TI  - Session management of correlated multi-stream 3D tele-immersive enviro
nments
UR  - https://doi.org/10.1145/2072298.2072489
ER  - 
TY  - JOUR
AB  - Meetings are often seen solely as a site of collective work. However, 
as McGrath has noted, groups are concerned with much more than collect
ive work. In this study we examine how individuals experience meetings
, and ask what they do, why they do it, and how they feel about it. Ou
r study focuses on recurring meetings, both because recurring meetings
 are an ordinary aspect of organization life, and because their routin
e nature lends them a casual character that distinguishes them from on
e-time, issue-focused meetings. This paper analyzes accounts of 19 mee
tings and examines how various peripheral activities – side-talk, side
-tracking, multi-tasking, pre- and post-meeting talk – have positive e
ffects, as well as negative ones. We argue that viewing recurring meet
ings as a confluence of individual and collective aims suggests new ap
proaches for designing technology that supports both meetings and part
icipants.
AU  - Niemantsverdriet, Karin
AU  - Erickson, Thomas
DA  - 2017/12//
PY  - 2017
DO  - 10.1145/3134719
ID  - 10.1145/3134719
IS  - CSCW
KW  - interruptions
KW  - meeting support technology
KW  - multi-tasking
KW  - recurring meetings
KW  - remote communication
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Recurring Meetings: An Experiential Account of Repeating Meetings in a
 Large Organization
UR  - https://doi.org/10.1145/3134719
VL  - 1
ER  - 
TY  - CONF
AB  - In this paper, we investigate pointing as a lightweight form of gestur
al interaction in cars. In a pre-study, we show the technical feasibil
ity of reliable pointing detection with a depth camera by achieving a 
recognition rate of 96% in the lab. In a subsequent in-situ study, we 
let drivers point to objects inside and outside of the car while drivi
ng through a city. In three usage scenarios, we studied how this influ
enced their driving objectively, as well as subjectively. Distraction 
from the driving task was compensated by a regulation of driving speed
 and did not have a negative influence on driving behaviour. Our parti
cipants considered pointing a desirable interaction technique in compa
rison to current controller-based interaction and identified a number 
of additional promising use cases for pointing in the car.
AU  - Rümelin, Sonja
AU  - Marouane, Chadly
AU  - Butz, Andreas
C1  - Eindhoven, Netherlands
C3  - Proceedings of the 5th International Conference on Automotive User Int
erfaces and Interactive Vehicular Applications
DA  - 2013///
C2  - 2013
DO  - 10.1145/2516540.2516556
ID  - 10.1145/2516540.2516
KW  - camera-based tracking
KW  - gesture interaction
KW  - pointing
PB  - Association for Computing Machinery
SN  - 9781450324786
SP  - 40-47
T3  - AutomotiveUI '13
TI  - Free-hand pointing for identification and interaction with distant obj
ects
UR  - https://doi.org/10.1145/2516540.2516556
ER  - 
TY  - CONF
AB  - Given the importance of our non-human companions, do we not want to ex
tend social media to our nonhuman co-species? If "human computer inter
faces" should be designed for "Anyone. Anywhere." (the theme of CHI 20
01), then why not for all species? Recent pioneering efforts have show
n that computer mediated interactions between humans and dogs, cats, c
hickens, cows, hamsters, and other species are technically possible. T
hese efforts excite the imagination and challenge our understanding th
e basic nature of computer mediated interaction.
AU  - McGrath, Robert E.
C1  - Boston, MA, USA
C3  - CHI '09 Extended Abstracts on Human Factors in Computing Systems
DA  - 2009///
C2  - 2009
DO  - 10.1145/1520340.1520357
ID  - 10.1145/1520340.1520
KW  - computer-non-human interfaces
KW  - cross-species interaction
KW  - species-appropriate interfaces
PB  - Association for Computing Machinery
SN  - 9781605582474
SP  - 2529-2534
T3  - CHI EA '09
TI  - Species-appropriate computer mediated interaction
UR  - https://doi.org/10.1145/1520340.1520357
ER  - 
TY  - CONF
AB  - This paper presents a new type of human-computer interface called Pico
 (Physical Intervention in Computational Optimization) based on mechan
ical constraints that combines some of the tactile feedback and afford
ances of mechanical systems with the abstract computational power of m
odern computers. The interface is based on a tabletop interaction surf
ace that can sense and move small objects on top of it. The positions 
of these physical objects represent and control parameters inside a so
ftware application, such as a system for optimizing the configuration 
of radio towers in a cellular telephone network. The computer autonomo
usly attempts to optimize the network, moving the objects on the table
 as it changes their corresponding parameters in software. As these ob
jects move, the user can constrain their motion with his or her hands,
 or many other kinds of physical objects. The interface provides ample
 opportunities for improvisation by allowing the user to employ a rich
 variety of everyday physical objects as mechanical constraints. This 
approach leverages the user's mechanical intuition for how objects res
pond to physical forces. As well, it allows the user to balance the nu
merical optimization performed by the computer with other goals that a
re difficult to quantify. Subjects in an evaluation were more effectiv
e at solving a complex spatial layout problem using this system than w
ith either of two alternative interfaces that did not feature actuatio
n.
AU  - Patten, James
AU  - Ishii, Hiroshi
C1  - San Jose, California, USA
C3  - Proceedings of the SIGCHI Conference on Human Factors in Computing Sys
tems
DA  - 2007///
C2  - 2007
DO  - 10.1145/1240624.1240746
ID  - 10.1145/1240624.1240
KW  - actuation
KW  - improvisation
KW  - interactive surface
KW  - physical interaction
KW  - tangible interfaces
PB  - Association for Computing Machinery
SN  - 9781595935939
SP  - 809-818
T3  - CHI '07
TI  - Mechanical constraints as computational constraints in tabletop tangib
le interfaces
UR  - https://doi.org/10.1145/1240624.1240746
ER  - 
TY  - JOUR
AU  - Ishii, Hiroshi
AU  - Lakatos, Dávid
AU  - Bonanni, Leonardo
AU  - Labrune, Jean-Baptiste
DA  - 2012/1//
PY  - 2012
DO  - 10.1145/2065327.2065337
ID  - 10.1145/2065327.2065
IS  - 1
SN  - 1072-5520
SP  - 38-51
T2  - Interactions
TI  - Radical atoms: beyond tangible bits, toward transformable materials
UR  - https://doi.org/10.1145/2065327.2065337
VL  - 19
ER  - 
TY  - BOOK
AB  - Welcome to CHIWORK 2025, the 4th Annual Symposium on Human-Computer In
teraction for Work to be held at Centrum Wiskunde &amp; Informatica (C
WI) in Amsterdam, The Netherlands.CHIWORK is the annual symposium that
 aims to grow our understanding of how Human-Computer Interaction (HCI
) will support work in the future. Advances in Computing technology ar
e rapidly changing the way we work. Human-computer interaction (HCI) i
s a critical aspect of this ongoing change, as a way to support worker
s in successfully navigating fast-paced changes in working environment
s, which might include novel computing devices, new sensing and work(e
r) wellbeing and performance measurement techniques, interacting with 
AI agents, and the new roles for people in work environments where aut
omation is increasing.
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3729176
PB  - Association for Computing Machinery
SN  - 9798400713842
TI  - CHIWORK '25: Proceedings of the 4th Annual Symposium on Human-Computer
 Interaction for Work
ER  - 
TY  - BOOK
CY  - Vancouver, BC, Canada
DA  - 2024///
PY  - 2024
ID  - 10.1145/3696762
PB  - Association for Computing Machinery
SN  - 9798400712784
TI  - ISS Companion '24: Companion Proceedings of the 2024 Conference on Int
eractive Surfaces and Spaces
ER  - 
TY  - CONF
AB  - In recent years, digital storytelling has demonstrated powerful pedago
gical functions by improving creativity, collaboration and intimacy am
ong young children. Saturated with digital media technologies in their
 daily lives, the young generation demands natural interactive learnin
g environments which offer multimodalities of feedback and meaningful 
immersive learning experiences. Virtual puppetry assisted storytelling
 system for young children, which utilises depth motion sensing techno
logy and gesture control as the Human-Computer Interaction (HCI) metho
d, has been proved to provide natural interactive learning experience 
for single player. In this paper, we designed and developed a novel sy
stem that allows multiple players to narrate, and most importantly, to
 interact with other characters and interactive virtual items in the v
irtual environment. We have conducted one user experiment with four yo
ung children for pedagogical evaluation and another user experiment wi
th five postgraduate students for system evaluation. Our user study sh
ows this novel digital storytelling system has great potential to stim
ulate learning abilities of young children through collaboration tasks
.
AU  - Liang, Hui
AU  - Chang, Jian
AU  - Deng, Shujie
AU  - Chen, Can
AU  - Tong, Ruofeng
AU  - Zhang, Jianjun
C1  - Kobe, Japan
C3  - Proceedings of the 14th ACM SIGGRAPH International Conference on Virtu
al Reality Continuum and Its Applications in Industry
DA  - 2015///
C2  - 2015
DO  - 10.1145/2817675.2817680
ID  - 10.1145/2817675.2817
KW  - children learning
KW  - gesture-based control
KW  - interactive storytelling
KW  - virtual puppetry
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781450339407
SP  - 63-72
T3  - VRCAI '15
TI  - Exploitation of novel multiplayer gesture-based interaction and virtua
l puppetry for digital storytelling to develop children's narrative sk
ills
UR  - https://doi.org/10.1145/2817675.2817680
ER  - 
TY  - CONF
AB  - Uneven knowledge distribution is often an issue in remote support syst
ems, creating the occasional need for additional information layers th
at extend beyond plain videoconference and shared workspaces. This pap
er introduces SEMarbeta, a remote support system designed for car driv
ers in need of help from an office-bound professional expert. We intro
duce a design concept and its technical implementation using low-cost 
hardware and techniques inspired by augmented reality research. In thi
s setup, the driver uses a portable Android tablet PC while the expert
 mechanic uses a stationary computer equipped with a video camera capt
uring his gestures and sketches. Hence, verbal instructions can be com
bined with supportive gestures and sketches added by the expert mechan
ic to the car's video display. To validate this concept, we carried ou
t a user study involving two typical automotive repair tasks: checking
 engine oil and examining fuses. Based on these tasks and following a 
between-group (drivers and expert mechanics) design, we compared voice
-only with additional sketch- and gesture-overlay on video screenshots
 measuring objective and perceived quality of help. Results indicate t
hat sketch- and gesture-overlay can benefit remote car support in typi
cal breakdown situations.
AU  - Chen, Sicheng
AU  - Chen, Miao
AU  - Kunz, Andreas
AU  - Yantaç, Asim Evren
AU  - Bergmark, Mathias
AU  - Sundin, Anders
AU  - Fjeld, Morten
C1  - Stuttgart, Germany
C3  - Proceedings of the 4th Augmented Human International Conference
DA  - 2013///
C2  - 2013
DO  - 10.1145/2459236.2459249
ID  - 10.1145/2459236.2459
KW  - AR
KW  - automotive
KW  - handheld computer
KW  - mobile
KW  - remote support
KW  - user study
PB  - Association for Computing Machinery
SN  - 9781450319041
SP  - 69-76
T3  - AH '13
TI  - SEMarbeta: mobile sketch-gesture-video remote support for car drivers
UR  - https://doi.org/10.1145/2459236.2459249
ER  - 
TY  - BOOK
CY  - Guimarães, Portugal
DA  - 2024///
PY  - 2024
ID  - 10.1145/3665318
PB  - Association for Computing Machinery
SN  - 9798400706899
TI  - Web3D '24: Proceedings of the 29th International ACM Conference on 3D 
Web Technology
ER  - 
TY  - JOUR
AB  - The livestreaming industry in China is gaining greater traction than i
ts European and North American counterparts and has a profound impact 
on the stakeholders' online and offline lives. An emerging genre of li
vestreaming that has become increasingly popular in China is outdoor l
ivestreaming. With outdoor livestreams, streamers broadcast outdoor ac
tivities, travel, or socialize with passersby in outdoor settings, oft
en for 6 or more hours, and viewers watch such streams for hours each 
day. However, given that professionally produced content about travel 
and outdoor activities are not very popular, it is currently unknown w
hat makes this category of livestreams so engaging and how these techn
iques can be applied to other content or genres. Thus, we conducted a 
mixed methods study consisting of a survey (N=287) and interviews (N =
 20) to understand how viewers watch and engage with outdoor livestrea
ms in China. The data revealed that outdoor livestreams encompass many
 categories of content, environments and passersby behaviors create ch
allenges and uncertainty for viewers and streamers, and viewers watch 
livestreams for surprising lengths of time (e.g., sometimes more than 
5 continuous hours). We also gained insights into how live commenting 
and virtual gifting encourage engagement. Lastly, we detail how the be
haviors of dedicated fans and casual viewers differ and provide implic
ations for the design of livestreaming services that support outdoor a
ctivities.
AU  - Lu, Zhicong
AU  - Annett, Michelle
AU  - Wigdor, Daniel
DA  - 2019/11//
PY  - 2019
DO  - 10.1145/3359127
ID  - 10.1145/3359127
IS  - CSCW
KW  - livestreaming
KW  - outdoor activities
KW  - social media
KW  - user engagement
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Vicariously Experiencing it all Without Going Outside: A Study of Outd
oor Livestreaming in China
UR  - https://doi.org/10.1145/3359127
VL  - 3
ER  - 
TY  - BOOK
CY  - TROYES, France
DA  - 2023///
PY  - 2023
ID  - 10.1145/3583961
PB  - Association for Computing Machinery
SN  - 9781450398244
TI  - IHM '23: Proceedings of the 34th Conference on l'Interaction Humain-Ma
chine
ER  - 
TY  - CONF
AU  - Ressler, Sandy
AU  - Antonishek, Brian
AU  - Wang, Qiming
AU  - Godil, Afzal
C1  - Paderbon, Germany
C3  - Proceedings of the Sixth International Conference on 3D Web Technology

DA  - 2001///
C2  - 2001
DO  - 10.1145/363361.363383
ID  - 10.1145/363361.36338
KW  - VRML
KW  - device control
KW  - tangible reality
KW  - user interfaces
KW  - virtual environments
PB  - Association for Computing Machinery
SN  - 1581133391
SP  - 93-100
T3  - Web3D '01
TI  - Integrating active tangible devices with a synthetic environment for c
ollaborative engineering
UR  - https://doi.org/10.1145/363361.363383
ER  - 
TY  - CONF
AB  - Existing methods for cyber learning mathematics and geometry are restr
icted to a limited class of geometric objects, most of which are prede
fined in the system. Besides, no existing methods emphasize the geomet
ric meaning of mathematic functions. Our research aims at improving le
arners' three-dimensional spatial abilities by providing an intuitive 
and efficient environment for learning mathematics and geometry, speci
fically, the geometric meaning of mathematic functions. We propose a n
ew 3D web learning environment that does not restrict to a list of pre
defined primitive geometric objects, allows the learner to interactive
ly create objects by defining their properties using analytical functi
ons, and immerses the learner into the environment. The object propert
ies, including geometry, visual appearance and physical properties, ar
e created in their own coordinate domains and then assembled together 
to define a virtual shape. The shape definition is eventually a functi
on scripts that can be rendered on any suitable graphics system. We ha
ve implemented our software using the function-based extension of the 
Virtual Reality Modeling Language (VRML) and Extensible 3D (X3D).
AU  - Lai, Danbo
AU  - Sourin, Alexei
C1  - Hong Kong, China
C3  - Proceedings of the 10th International Conference on Virtual Reality Co
ntinuum and Its Applications in Industry
DA  - 2011///
C2  - 2011
DO  - 10.1145/2087756.2087856
ID  - 10.1145/2087756.2087
KW  - 3D web
KW  - shape modeling
KW  - shared virtual reality
PB  - Association for Computing Machinery
SN  - 9781450310604
SP  - 519-526
T3  - VRCAI '11
TI  - Visual immersive mathematics in 3D web
UR  - https://doi.org/10.1145/2087756.2087856
ER  - 
TY  - CONF
AB  - Augmented Reality (AR) is a rapidly growing field in information and c
ommunication technologies, drawing increasing numbers of professionals
. Higher education institutions, however, are struggling to keep abrea
st of its development and to train specialists quickly, providing few 
courses which sufficiently align with the needs of industry. In additi
on to this, the field is developing so rapidly that existing courses s
truggle to keep pace. They also often focus too narrowly on specifics 
to allow for the building of the formative foundations of AR education
. This paper aims to address this need by proposing a blueprint curric
ulum in Computer Science Education for teaching AR in universities at 
two levels, foundations and advanced. To begin, we survey the state of
 the art, identifying common needs and problems in existing courses wh
ich focus on AR. We then detail a skills framework comprised of 12 gro
ups of skills suitable to meet industry needs, and built upon it two m
odel lesson plans for a foundation and an advanced course. We conclude
 with a discussion of assessment techniques and curricular design opti
ons of embedding such coursework into existing academic programs and a
 forecast of the future of this academic field.
AU  - Fominykh, Mikhail
AU  - Wild, Fridolin
AU  - Klamma, Ralf
AU  - Billinghurst, Mark
AU  - Costiner, Lisandra S.
AU  - Karsakov, Andrey
AU  - Mangina, Eleni
AU  - Molka-Danielsen, Judith
AU  - Pollock, Ian
AU  - Preda, Marius
AU  - Smolic, Aljosa
C1  - Trondheim, Norway
C3  - Proceedings of the Working Group Reports on Innovation and Technology 
in Computer Science Education
DA  - 2020///
C2  - 2020
DO  - 10.1145/3437800.3439205
ID  - 10.1145/3437800.3439
KW  - software engineering
KW  - curriculum
KW  - augmented reality
PB  - Association for Computing Machinery
SN  - 9781450382939
SP  - 131-149
T3  - ITiCSE-WGR '20
TI  - Model Augmented Reality Curriculum
UR  - https://doi.org/10.1145/3437800.3439205
ER  - 
TY  - CHAP
AU  - Sonntag, Daniel
ID  - 10.1145/3233795.3233
PB  - Association for Computing Machinery
PY  - 2019
SN  - 9781970001754
SP  - 423-476
T2  - The Handbook of Multimodal-Multisensor Interfaces: Language Processing
, Software, Commercialization, and Emerging Directions
TI  - Medical and health systems
UR  - https://doi.org/10.1145/3233795.3233808
ER  - 
TY  - JOUR
AB  - It is important to learn from the past as we endeavor into this unchar
ted territory of mobile, human-to-human, one-to-one telepresence for i
nterpersonal use. With the ever-increasing access to live-streaming ca
meras, we are now at the cusp of being able to create novel, immersive
, and interpersonal telepresence activities that have the potential to
 change how humans interact with one another on a daily basis. Due to 
its novelty, there are likely socio-technical gaps between the needs o
f users and the technical specifications of the prototypes that are cu
rrently being designed to support the complex social interactions of h
uman-to-human telepresence. Therefore, in this paper, we use a socio-t
echnical lens to conduct a systematic literature review of 52 peer-rev
iewed articles of early work in this space. Overall, we found that whi
le progress has been made to address the social needs of those involve
d in one-to-one telepresence scenarios, there are discontinuities with
in the existing literature that need to be addressed, particularly wit
h the way we attempt to measure and quantify human-centered outcomes w
ith unvalidated instruments. We also found that the social needs of on
-site users have been neglected, as in many articles the user was mere
ly treated as a surrogate, or reported feeling socially awkward or uns
afe, due to the conspicuous nature of the body-worn technology in publ
ic environments. These findings are prevalent, even as researchers con
sider adding to this body-worn burden in an attempt to improve the rec
eiving users' sense of immersion and presence. To preserve the benefic
ial nature of telepresence interaction while ensuring that all users' 
needs are met, researchers should endeavor to further understand the d
ynamics of the relationship between all parties in the remote environm
ent. Our paper creates a future research agenda that emphasizes the im
portance of ensuring that all parties involved feel comfortable in the
ir role during interpersonal telepresence interactions.
AU  - Pfeil, Kevin P.
AU  - Chatlani, Neeraj
AU  - LaViola, Joseph J.
AU  - Wisniewski, Pamela
DA  - 2021/4//
PY  - 2021
DO  - 10.1145/3449194
ID  - 10.1145/3449194
IS  - CSCW1
KW  - literature review
KW  - mobile
KW  - novel interaction
KW  - telepresence
T2  - Proc. ACM Hum.-Comput. Interact.
TI  - Bridging the Socio-Technical Gaps in Body-worn Interpersonal Live-Stre
aming Telepresence through a Critical Review of the Literature
UR  - https://doi.org/10.1145/3449194
VL  - 5
ER  - 
TY  - CONF
AB  - RobotPHONE is a Robotic User Interface (RUI) that uses robots as physi
cal avatars for interpersonal communication. Using RobotPHONE, users i
n remote locations can communicate shapes and motion with each other. 
In this paper we present the concept of RobotPHONE, and describe imple
mentations of two prototypes.
AU  - Sekiguchi, Dairoku
AU  - Inami, Masahiko
AU  - Tachi, Susumu
C1  - Seattle, Washington
C3  - CHI '01 Extended Abstracts on Human Factors in Computing Systems
DA  - 2001///
C2  - 2001
DO  - 10.1145/634067.634231
ID  - 10.1145/634067.63423
KW  - robot
KW  - physical avatar
KW  - interpersonal communication
KW  - interface
KW  - bilateral servo
KW  - RUI
PB  - Association for Computing Machinery
SN  - 1581133405
SP  - 277-278
T3  - CHI EA '01
TI  - RobotPHONE: RUI for interpersonal communication
UR  - https://doi.org/10.1145/634067.634231
ER  - 
TY  - CONF
AB  - We describe the design of ComTouch, a device that augments remote voic
e communication with touch, by converting hand pressure into vibration
al intensity between users in real-time. The goal of this work is to e
nrich inter-personal communication by complementing voice with a tacti
le channel. We present preliminary user studies performed on 24 people
 to observe possible uses of the tactile channel when used in conjunct
ion with audio. By recording and examining both audio and tactile data
, we found strong relationships between the two communication channels
. Our studies show that users developed an encoding system similar to 
that of Morse code, as well as three original uses: emphasis, mimicry,
 and turn-taking. We demonstrate the potential of the tactile channel 
to enhance the existing voice communication channel.
AU  - Chang, Angela
AU  - O'Modhrain, Sile
AU  - Jacob, Rob
AU  - Gunther, Eric
AU  - Ishii, Hiroshi
C1  - London, England
C3  - Proceedings of the 4th Conference on Designing Interactive Systems: Pr
ocesses, Practices, Methods, and Techniques
DA  - 2002///
C2  - 2002
DO  - 10.1145/778712.778755
ID  - 10.1145/778712.77875
KW  - communication
KW  - haptic interpersonal
KW  - remote communication
KW  - tactile communication
KW  - tangible telepresence
KW  - tangible user interface
KW  - touch-vibration mapping
KW  - vibrotactile
PB  - Association for Computing Machinery
SN  - 1581135157
SP  - 312-320
T3  - DIS '02
TI  - ComTouch: design of a vibrotactile communication device
UR  - https://doi.org/10.1145/778712.778755
ER  - 
TY  - BOOK
AB  - Welcome one and all to the 19th Annual ACM/IEEE International Conferen
ce on Human-Robot Interaction (HRI)!We are so pleased to re-welcome th
e HRI community to Boulder, Colorado, where HRI 2021 would have been h
eld, had the COVID pandemic not interfered. Following up on the succes
sful in-person conference held last year in Sweden, this year's theme 
is "HRI in the Real World," and focuses on advances that aim to bring 
human-robot interaction out of the lab and into everyday life.One aspe
ct of this that we are very excited about is the introduction of a rob
ot challenge to the conference activities, where teams from around the
 world will showcase their research and development via actual, intera
ctive robots in the "real world" of an academic conference. It is our 
hope that this feature will grow and develop over the coming years int
o a staple of the HRI conference.This year's HRI conference saw an imp
ressive surge in global interest, with 352 full paper submissions from
 around the world, marking a significant 40% increase compared to the 
previous year. These papers were categorized under relevant thematic s
ubcommittees and underwent a double-blind review process, a rebuttal p
hase, and selective shepherding by the HRI program committee. From thi
s process, 87 outstanding papers (24.7%) were chosen for full presenta
tion at the conference. Reflecting our joint sponsorship with IEEE and
 ACM, all accepted papers will be accessible in the ACM Digital Librar
y and IEEE Xplore.
CY  - Boulder, CO, USA
DA  - 2024///
PY  - 2024
ID  - 10.1145/3610978
PB  - Association for Computing Machinery
SN  - 9798400703232
TI  - HRI '24: Companion of the 2024 ACM/IEEE International Conference on Hu
man-Robot Interaction
ER  - 
TY  - CONF
AB  - Telepresence refers to a set of technologies that allow users to feel 
present at a distant location; telerobotics is a subfield of teleprese
nce. This paper presents the design and evaluation of a telepresence r
obot which allows for social expression. Our hypothesis is that a tele
robot that communicates more than simply audio or video but also expre
ssive gestures, body pose and proxemics, will allow for a more engagin
g and enjoyable interaction. An iterative design process of the MeBot 
platform is described in detail, as well as the design of supporting s
ystems and various control interfaces. We conducted a human subject st
udy where the effects of expressivity were measured. Our results show 
that a socially expressive robot was found to be more engaging and lik
able than a static one. It was also found that expressiveness contribu
tes to more psychological involvement and better cooperation.
AU  - Adalgeirsson, Sigurdur O.
AU  - Breazeal, Cynthia
C1  - Osaka, Japan
C3  - Proceedings of the 5th ACM/IEEE International Conference on Human-Robo
t Interaction
DA  - 2010///
C2  - 2010
ID  - 10.5555/1734454.1734
KW  - embodied videoconferencing
KW  - human robot interaction
KW  - robot-mediated communication
KW  - telepresence
PB  - IEEE Press
SN  - 9781424448937
SP  - 15-22
T3  - HRI '10
TI  - MeBot: a robotic platform for socially embodied presence
ER  - 
TY  - CONF
AB  - We present GaussBits, which is a system of the passive magnetic tangib
le designs that enables 3D tangible interactions in the near-surface s
pace of portable displays. When a thin magnetic sensor grid is attache
d to the back of the display, the 3D position and partial 3D orientati
on of the GaussBits can be resolved by the proposed bi-polar magnetic 
field tracking technique. This portable platform can therefore enrich 
tangible interactions by extending the design space to the near-surfac
e space. Since non-ferrous materials, such as the user's hand, do not 
occlude the magnetic field, interaction designers can freely incorpora
te a magnetic unit into an appropriately shaped non-ferrous object to 
exploit the metaphors of the real-world tasks, and users can freely ma
nipulate the GaussBits by hands or using other non-ferrous tools witho
ut causing interference. The presented example applications and the co
llected feedback from an explorative workshop revealed that this new a
pproach is widely applicable.
AU  - Liang, Rong-Hao
AU  - Cheng, Kai-Yin
AU  - Chan, Liwei
AU  - Peng, Chuan-Xhyuan
AU  - Chen, Mike Y.
AU  - Liang, Rung-Huei
AU  - Yang, De-Nian
AU  - Chen, Bing-Yu
C1  - Paris, France
C3  - Proceedings of the SIGCHI Conference on Human Factors in Computing Sys
tems
DA  - 2013///
C2  - 2013
DO  - 10.1145/2470654.2466185
ID  - 10.1145/2470654.2466
KW  - magnetism
KW  - near-surface tracking
KW  - occlusion-free
KW  - portable
KW  - tangible interactions
PB  - Association for Computing Machinery
SN  - 9781450318990
SP  - 1391-1400
T3  - CHI '13
TI  - GaussBits: magnetic tangible bits for portable and occlusion-free near
-surface interactions
UR  - https://doi.org/10.1145/2470654.2466185
ER  - 
TY  - BOOK
CY  - Pittsburgh, PA, USA
DA  - 2024///
PY  - 2024
ID  - 10.1145/3672539
PB  - Association for Computing Machinery
SN  - 9798400707186
TI  - UIST Adjunct '24: Adjunct Proceedings of the 37th Annual ACM Symposium
 on User Interface Software and Technology
ER  - 
TY  - BOOK
CY  - Sydney, NSW, Australia
DA  - 2023///
PY  - 2023
ID  - 10.1145/3607822
PB  - Association for Computing Machinery
SN  - 9798400702815
TI  - SUI '23: Proceedings of the 2023 ACM Symposium on Spatial User Interac
tion
ER  - 
TY  - CONF
AB  - Research on dialog systems has so far concentrated on interactions bet
ween a single user and a machine. In this paper we identify novel rese
arch directions arising from multi-party human computer interaction, i
.e. scenarios where several human participants interact with a dialog 
system.
AU  - Kirchhoff, Katrin
AU  - Ostendorf, Mari
C1  - Edmonton, Alberta, Canada
C3  - Proceedings of the HLT-NAACL 2003 Workshop on Research Directions in D
ialogue Processing - Volume 7
DA  - 2003///
C2  - 2003
DO  - 10.3115/1118927.1118930
ID  - 10.3115/1118927.1118
PB  - Association for Computational Linguistics
SP  - 7-9
T3  - HLT-NAACL-DIALOGUE '03
TI  - Directions for multi-party human-computer interaction research
UR  - https://doi.org/10.3115/1118927.1118930
ER  - 
TY  - CONF
AB  - I present a card brainstorming exercise that transforms a conceptual t
angible interaction framework into a tool for creative dialogue and di
scuss the experiences made in using it. Ten sessions with this card ga
me demonstrate the frameworks' versatility and utility. Observation an
d participant feedback highlight the value of a provocative question f
ormat and of the metaphor of a card game.
AU  - Hornecker, Eva
C1  - Cambridge, Massachusetts, USA
C3  - Proceedings of the Fourth International Conference on Tangible, Embedd
ed, and Embodied Interaction
DA  - 2010///
C2  - 2010
DO  - 10.1145/1709886.1709905
ID  - 10.1145/1709886.1709
KW  - analysis
KW  - creativity
KW  - design
KW  - embodied
KW  - ideation
KW  - tangible
PB  - Association for Computing Machinery
SN  - 9781605588414
SP  - 101-108
T3  - TEI '10
TI  - Creative idea exploration within the structure of a guiding framework:
 the card brainstorming game
UR  - https://doi.org/10.1145/1709886.1709905
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3678698
PB  - Association for Computing Machinery
SN  - 9798400709678
TI  - VINCI '24: Proceedings of the 17th International Symposium on Visual I
nformation Communication and Interaction
ER  - 
TY  - CONF
AB  - "The Multi-User Programming Pedagogy for Enhancing Traditional Study" 
(MUPPETS) system has been under development at RIT for the last three 
years. This multi-user environment is designed to allow students to de
velop visible 3D objects in Java within a game-world environment with 
minimal knowledge of graphics programming. Students can interact with 
these objects through an interface built into the system. (Technical a
spects of the MUPPETS system were previously published by the authors 
at CITC4) [1].In testing the usefulness of MUPPETS as a teaching tool,
 we have developed a series of course modules that use the environment
 as its programming environment. The existing "Programming for Informa
tion Technology III" course is the ideal place to perform an initial t
est of this nature, as students have some base familiarity with the Ja
va language but have not yet completed their undergraduate programming
 core. Students in this course have a final group programming project 
that we intend to use as the initial test, and develop further MUPPETS
 modules downwards towards the initial freshman experience.In the past
 students used a package called "Robocode", which is available from IB
M [2]. This project involved programming a virtual robot that could "f
ight" in an arena according to some agreed upon set of rules, which we
re developed both as part of the Robocode package and discussed and ag
reed upon in lecture. While the students enjoyed this project, the pro
liferation of available code on the Internet for the framework led to 
this project being removed from the course. We have implemented a vari
ant of "RoboCode" in MUPPETS that addresses the code availability issu
e and provides a more interesting and graphically rich environment for
 the students.This paper shall discuss the reasons for the implementat
ion, what we expect the students will gain from the use of MUPPETS bas
ed project, and possible methods of comparing this approach to the met
hods previously used in this course. Also discussed are additions to t
he MUPPETS system made to facilitate its classroom use including a re-
implementation of the Swing graphics classes such that 2D interfaces a
re available in 3D, and model loading and texturing tools that allow c
ustom robot creation and customization.
AU  - Bierre, Kevin J.
AU  - Phelps, Andrew M.
C1  - Salt Lake City, UT, USA
C3  - Proceedings of the 5th Conference on Information Technology Education
DA  - 2004///
C2  - 2004
DO  - 10.1145/1029533.1029564
ID  - 10.1145/1029533.1029
KW  - game programming
KW  - graphics
KW  - programming education
KW  - virtual worlds
PB  - Association for Computing Machinery
SN  - 1581139365
SP  - 122-127
T3  - CITC5 '04
TI  - The use of MUPPETS in an introductory java programming course
UR  - https://doi.org/10.1145/1029533.1029564
ER  - 
TY  - BOOK
CY  - Yokohama, Japan
DA  - 2021///
PY  - 2021
ID  - 10.1145/3411763
PB  - Association for Computing Machinery
SN  - 9781450380959
TI  - CHI EA '21: Extended Abstracts of the 2021 CHI Conference on Human Fac
tors in Computing Systems
ER  - 
TY  - BOOK
CY  - Nantes, France
DA  - 2023///
PY  - 2023
ID  - 10.1145/3573381
PB  - Association for Computing Machinery
SN  - 9798400700286
TI  - IMX '23: Proceedings of the 2023 ACM International Conference on Inter
active Media Experiences
ER  - 
TY  - CONF
AB  - We examine the design space of interaction techniques for very large w
all displays by drawing from existing theory and practice for reality-
based interfaces and whole-body interfaces. We also apply insights dra
wn from research in psychology about the human cognitive mechanisms th
at support sensorimotor operations in different coordinate spaces, as 
well as research in sociology examining how people manage coordination
 and privacy concerns in these spaces. Using guidelines obtained from 
these analyses, we designed and implemented a novel suite of body-cent
ric interaction techniques. These were integrated into a map browsing 
and editing application for a very large (5m×3m) wall display. The app
lication was then used to gather user feedback to guide the further de
velopment of the interaction techniques.
AU  - Shoemaker, Garth
AU  - Tsukitani, Takayuki
AU  - Kitamura, Yoshifumi
AU  - Booth, Kellogg S.
C1  - Reykjavik, Iceland
C3  - Proceedings of the 6th Nordic Conference on Human-Computer Interaction
: Extending Boundaries
DA  - 2010///
C2  - 2010
DO  - 10.1145/1868914.1868967
ID  - 10.1145/1868914.1868
KW  - reality-based interaction
KW  - proxemics
KW  - post-WIMP interfaces
KW  - multimodal
KW  - gesture-based interaction
KW  - embodied interaction
PB  - Association for Computing Machinery
SN  - 9781605589343
SP  - 463-472
T3  - NordiCHI '10
TI  - Body-centric interaction techniques for very large wall displays
UR  - https://doi.org/10.1145/1868914.1868967
ER  - 
TY  - CONF
AB  - Virtual reality (VR) systems utilize additional input and output chann
els in order to make interaction in virtual environments (VEs) more in
tuitive and to increase the user's immersion into the virtual world. W
hen developing VR applications, developers should be able to focus on 
modeling advanced interaction and system behavior instead of rendering
 issues. Many systems and tools for developing virtual reality applica
tions have been proposed to achieve this goal. However, no de facto st
andard is available. In this paper we present Virtual Reality VRS (VR2
S), a generic VR software system, which is an extension of the high-le
vel rendering system VRS. The system provides flexibility in terms of 
the rendering system and the user interface toolkit. Thus, with using 
VR2S rendering can be performed with several low-level rendering APIs 
such as OpenGL, Render-Man or ray-tracing systems, and the interface c
an be implemented by arbitrary user interface toolkits to support both
 desktop- and VR-based interaction. The proposed system meets the dema
nds of VR developers as well as users and has demonstrated its potenti
al in different planning and exploration applications.
AU  - Steinicke, Frank
AU  - Ropinski, Timo
AU  - Hinrichs, Klaus
C1  - Christchurch, New Zealand
C3  - Proceedings of the 2005 International Conference on Augmented Tele-Exi
stence
DA  - 2005///
C2  - 2005
DO  - 10.1145/1152399.1152440
ID  - 10.1145/1152399.1152
KW  - VR applications
KW  - VR interaction techniques
KW  - software architecture
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 0473106574
SP  - 220-227
T3  - ICAT '05
TI  - A generic virtual reality software system's architecture and applicati
on
UR  - https://doi.org/10.1145/1152399.1152440
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3721250
PB  - Association for Computing Machinery
SN  - 9798400715495
TI  - SIGGRAPH Posters '25: Proceedings of the Special Interest Group on Com
puter Graphics and Interactive Techniques Conference Posters
ER  - 
TY  - BOOK
CY  - Melbourne, Australia
DA  - 2024///
PY  - 2024
ID  - 10.1145/3657547
PB  - Association for Computing Machinery
SN  - 9798400709012
TI  - ICVARS '24: Proceedings of the 2024 8th International Conference on Vi
rtual and Augmented Reality Simulations
ER  - 
TY  - BOOK
CY  - Paris, France
DA  - 2024///
PY  - 2024
ID  - 10.1145/3673805
PB  - Association for Computing Machinery
SN  - 9798400718243
TI  - ECCE '24: Proceedings of the European Conference on Cognitive Ergonomi
cs 2024
ER  - 
TY  - CONF
AB  - Collaborative Virtual Environments allow multiple users to interact co
llaboratively while taking advantage of the perceptual richness that V
irtual Environments (VEs) provide. In this paper, we demonstrate empir
ically that increasing the level of immersion in a VE can have a benef
icial effect on the usability of that environment in a collaborative c
ontext. We present the results of a study in which we varied two immer
sive factors, stereo and head tracking, within the context of a two pe
rson collaborative task. Our results indicate that stereo can have a p
ositive effect on task performance; that different levels of immersion
 have effects that vary with gender; and that varying the level of imm
ersion has a pronounced effect on communication between users. These r
esults show that the level of immersion can play an important role in 
determining user performance on some collaborative tasks.
AU  - Narayan, Michael
AU  - Waugh, Leo
AU  - Zhang, Xiaoyu
AU  - Bafna, Pradyut
AU  - Bowman, Doug
C1  - Monterey, CA, USA
C3  - Proceedings of the ACM Symposium on Virtual Reality Software and Techn
ology
DA  - 2005///
C2  - 2005
DO  - 10.1145/1101616.1101632
ID  - 10.1145/1101616.1101
KW  - collaborative virtual environments
KW  - head tracking
KW  - immersion
KW  - stereo
PB  - Association for Computing Machinery
SN  - 1595930981
SP  - 78-81
T3  - VRST '05
TI  - Quantifying the benefits of immersion for collaboration in virtual env
ironments
UR  - https://doi.org/10.1145/1101616.1101632
ER  - 
TY  - CONF
AB  - We present an augmented reality application for mechanics education. I
t utilizes a recent physics engine developed for the PC gaming market 
to simulate physical experiments in the domain of mechanics in real ti
me. Students are enabled to actively build own experiments and study t
hem in a three-dimensional virtual world. A variety of tools are provi
ded to analyze forces, mass, paths and other properties of objects bef
ore, during and after experiments. Innovative teaching content is pres
ented that exploits the strengths of our immersive virtual environment
. PhysicsPlayground serves as an example of how current technologies c
an be combined to deliver a new quality in physics education.
AU  - Kaufmann, Hannes
AU  - Meyer, Bernd
C1  - Singapore
C3  - ACM SIGGRAPH ASIA 2008 Educators Programme
DA  - 2008///
C2  - 2008
DO  - 10.1145/1507713.1507717
ID  - 10.1145/1507713.1507
KW  - augmented reality
KW  - mechanics
KW  - physics education
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 9781605583884
T3  - SIGGRAPH Asia '08
TI  - Simulating educational physical experiments in augmented reality
UR  - https://doi.org/10.1145/1507713.1507717
ER  - 
TY  - BOOK
CY  - Athens, Greece
DA  - 2022///
PY  - 2022
ID  - 10.1145/3517428
PB  - Association for Computing Machinery
SN  - 9781450392587
TI  - ASSETS '22: Proceedings of the 24th International ACM SIGACCESS Confer
ence on Computers and Accessibility
ER  - 
TY  - BOOK
CY  - Minneapolis, MN, USA
DA  - 2023///
PY  - 2023
ID  - 10.1145/3584931
PB  - Association for Computing Machinery
SN  - 9798400701290
TI  - CSCW '23 Companion: Companion Publication of the 2023 Conference on Co
mputer Supported Cooperative Work and Social Computing
ER  - 
TY  - BOOK
CY  - Honolulu, HI, USA
DA  - 2024///
PY  - 2024
ID  - 10.1145/3613905
PB  - Association for Computing Machinery
SN  - 9798400703317
TI  - CHI EA '24: Extended Abstracts of the CHI Conference on Human Factors 
in Computing Systems
ER  - 
TY  - CONF
AB  - In our previous studies into web design, we found that pens, paper, wa
lls, and tables were often used for explaining, developing, and commun
icating ideas during the early phases of design. These wall-scale pape
r-based design practices inspired The Designers' Outpost, a tangible u
ser interface that combines the affordances of paper and large physica
l workspaces with the advantages of electronic media to support inform
ation design. With Outpost, users collaboratively author web site info
rmation architectures on an electronic whiteboard using physical media
 (Post-it notes and images), structuring and annotating that informati
on with electronic pens. This interaction is enabled by a touch-sensit
ive SMART Board augmented with a robust computer vision system, employ
ing a rear-mounted video camera for capturing movement and a front-mou
nted high-resolution camera for capturing ink. We conducted a particip
atory design study with fifteen professional web designers. The study 
validated that Outpost supports information architecture work practice
, and led to our adding support for fluid transitions to other tools.
AU  - Klemmer, Scott R.
AU  - Newman, Mark W.
AU  - Farrell, Ryan
AU  - Bilezikjian, Mark
AU  - Landay, James A.
C1  - Orlando, Florida
C3  - Proceedings of the 14th Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2001///
C2  - 2001
DO  - 10.1145/502348.502350
ID  - 10.1145/502348.50235
KW  - CSCW
KW  - Computer Vision
KW  - Informal Interfaces
KW  - Information Architecture
KW  - Sketching
KW  - Tangible Interfaces
KW  - Web Design
PB  - Association for Computing Machinery
SN  - 158113438X
SP  - 1-10
T3  - UIST '01
TI  - The designers' outpost: a tangible interface for collaborative web sit
e
UR  - https://doi.org/10.1145/502348.502350
ER  - 
TY  - CONF
AB  - This paper explores architectural support for interfaces combining pen
, paper, and PC. We show how the event-based approach common to GUIs c
an apply to augmented paper, and describe additions to address paper's
 distinguishing characteristics. To understand the developer experienc
e of this architecture, we deployed the toolkit to 17 student teams fo
r six weeks. Analysis of the developers' code provided insight into th
e appropriateness of events for paper UIs. The usage patterns we disti
lled informed a second iteration of the toolkit, which introduces tech
niques for integrating interactive and batched input handling, coordin
ating interactions across devices, and debugging paper applications. T
he study also revealed that programmers created gesture handlers by co
mposing simple ink measurements. This desire for informal interactions
 inspired us to include abstractions for recognition. This work has im
plications beyond paper - designers of graphical tools can examine API
 usage to inform iterative toolkit development.
AU  - Yeh, Ron B.
AU  - Paepcke, Andreas
AU  - Klemmer, Scott R.
C1  - Monterey, CA, USA
C3  - Proceedings of the 21st Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2008///
C2  - 2008
DO  - 10.1145/1449715.1449734
ID  - 10.1145/1449715.1449
KW  - augmented paper
KW  - device ensembles
KW  - evaluation
KW  - toolkits
PB  - Association for Computing Machinery
SN  - 9781595939753
SP  - 111-120
T3  - UIST '08
TI  - Iterative design and evaluation of an event architecture for pen-and-p
aper interfaces
UR  - https://doi.org/10.1145/1449715.1449734
ER  - 
TY  - BOOK
AB  - Interact with digital experiences that move beyond digital tradition, 
blur the boundaries between art and science, and transform social assu
mptions. See, learn, touch, and try the state of the art in human-comp
uter interaction and robotics. Emerging Technologies presents work fro
m many sub-disciplines of interactive techniques, with a special empha
sis on projects that explore science, high-resolution digital-cinema t
echnologies, and interactive art-science narratives.
CY  - Anaheim, California
DA  - 2016///
PY  - 2016
ID  - 10.1145/2929464
PB  - Association for Computing Machinery
SN  - 9781450343725
TI  - SIGGRAPH '16: ACM SIGGRAPH 2016 Emerging Technologies
ER  - 
TY  - CONF
AB  - This paper presents a new animated 3D graphical object manipulator to 
improve the visualisation of distributed window-based collaborative 3D
 applications. By applying animation techniques to the user interface,
 the experience of multi-user interaction may be enhanced. A major pro
blem associated with distributed collaborative 3D applications is that
 interactions among users may cause conflicts, and it may be difficult
 to convey what these conflicts are. In addition, there is a need for 
additional feedback when interacting with 3D objects in current workst
ation 3D virtual reality applications. A prototype application is pres
ented in the paper to demonstrate this new animated manipulator.
AU  - Davies, Matthew L.
AU  - Thomas, Bruce H.
C1  - Queensland, Australia
C3  - Proceedings of the 2nd Australasian Conference on User Interface
DA  - 2001///
C2  - 2001
ID  - 10.5555/545646.54566
KW  - 3D graphics
KW  - collaborative applications
KW  - distributed applications
KW  - graphical manipulators
PB  - IEEE Computer Society
SN  - 076950969X
SP  - 116-123
T3  - AUIC '01
TI  - An animated 3D manipulator for distributed collaborative window-based 
applications
ER  - 
TY  - BOOK
CY  - Denver, CO, USA
DA  - 2024///
PY  - 2024
ID  - 10.1145/3641234
PB  - Association for Computing Machinery
SN  - 9798400705168
TI  - SIGGRAPH '24: ACM SIGGRAPH 2024 Posters
ER  - 
TY  - BOOK
CY  - Milan, Italy
DA  - 2024///
PY  - 2024
ID  - 10.1145/3678299
PB  - Association for Computing Machinery
SN  - 9798400709685
TI  - AM '24: Proceedings of the 19th International Audio Mostly Conference:
 Explorations in Sonic Cultures
ER  - 
TY  - BOOK
CY  - Chicago, IL, USA
DA  - 2024///
PY  - 2024
ID  - 10.1145/3635636
PB  - Association for Computing Machinery
SN  - 9798400704857
TI  - C&amp;C '24: Proceedings of the 16th Conference on Creativity &amp; Co
gnition
ER  - 
TY  - BOOK
CY  - Hamburg, Germany
DA  - 2023///
PY  - 2023
ID  - 10.1145/3544549
PB  - Association for Computing Machinery
SN  - 9781450394222
TI  - CHI EA '23: Extended Abstracts of the 2023 CHI Conference on Human Fac
tors in Computing Systems
ER  - 
TY  - CONF
AB  - Mobile phones are an ideal platjorm for augmented reality. In this pap
er we describe how they also can be used to support face to face colla
borative AR applications. We have created a custom port of the ARToolK
it library to the Symbian mobile phone operating system and then devel
oped a sample collaborative AR game based on this. We describe the gam
e in detail and user feedback from people who have played it. We also 
provide general design guidelines that could he useful for others who 
are developing mobile phone collaborative AR applications.
AU  - Henrysson, Anders
AU  - Billinghurst, Mark
AU  - Ollila, Mark
C1  - USA
C3  - Proceedings of the 4th IEEE/ACM International Symposium on Mixed and A
ugmented Reality
DA  - 2005///
C2  - 2005
DO  - 10.1109/ISMAR.2005.32
ID  - 10.1109/ISMAR.2005.3
PB  - IEEE Computer Society
SN  - 0769524591
SP  - 80-89
T3  - ISMAR '05
TI  - Face to Face Collaborative AR on Mobile Phones
UR  - https://doi.org/10.1109/ISMAR.2005.32
ER  - 
TY  - CONF
AB  - Growing demand for ubiquitous and pervasive computing has triggered a 
sharp rise in handheld device usage. At the same time, dynamic multime
dia data has become accepted as core material which many important app
lications depend on, despite intensive costs in computation and resour
ces. This paper investigates the suitability and constraints of using 
handheld devices for such applications. We firstly analyse the capabil
ities and limitations of current models of handheld devices and advanc
ed features offered by next generation models. We then categorise thes
e applications and discuss the typical requirements of each class. Imp
ortant issues to be considered include data organisation and managemen
t, communication, and input and user interfaces. Finally, we briefly d
iscuss future outlook and identify remaining areas for research.
AU  - Pham, Binh
AU  - Wong, On
C1  - Singapore
C3  - Proceedings of the 2nd International Conference on Computer Graphics a
nd Interactive Techniques in Australasia and South East Asia
DA  - 2004///
C2  - 2004
DO  - 10.1145/988834.988856
ID  - 10.1145/988834.98885
KW  - multimedia
KW  - image processing
KW  - handheld devices
KW  - computer graphics
KW  - collaborative
PB  - Association for Computing Machinery
SN  - 1581138830
SP  - 123-130
T3  - GRAPHITE '04
TI  - Handheld devices for applications using dynamic multimedia data
UR  - https://doi.org/10.1145/988834.988856
ER  - 
TY  - BOOK
CY  - Hamburg, Germany
DA  - 2023///
PY  - 2023
ID  - 10.1145/3544548
PB  - Association for Computing Machinery
SN  - 9781450394215
TI  - CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Co
mputing Systems
ER  - 
TY  - CONF
AB  - In this paper, we present "PODIUM (POstech Distributed virtual Music e
nvironment)", a distributed virtual environment that allows users to p
articipate in a shared space and play music with other participants in
 a collaborative manner. In addition to playing virtual instruments, u
sers can communicate and interact in various ways to enhance the colla
boration and, thus, the quality of the music played together. Musical 
messages are generated note by note through interaction with the keybo
ard, mouse, and other devices, and transmitted through an IP-multicast
ing network among participants. In addition to such note-level informa
tion, additional messages for visualization, and interaction are suppo
rted. Real world based visualization has been chosen, against, for ins
tance, abstract music world based visualization, to promote "co-presen
ce" (e.g. recognize and interact with other players), which is deemed 
important for collaborative music production. In addition to the enter
tainment purpose, we hope that DVME will find great use in casual prac
tice sessions for even professional performers/orchestras/bands.Since 
even a slight interruption in the flow of the music or out - of-synch 
graphics and sound would dramatically decrease utility of the system, 
we employ various techniques to minimize the network delay. An adapted
 server-client architecture and UDP' s are used to ensure fast packet 
deliveries and reduce the data bottleneck problem. Time-critical messa
ges such as MIDI messages are multicasted among clients, and the less 
time-critical and infrequently updated messages are sent through the s
erver. Predefined animations of avatars are invoked by interpreting th
e musical messages. Using the latest graphics and sound processing har
dware, and by maintaining an appropriate scene complexity, and a frame
 rate sufficiently higher than the fastest note duration, the time con
straint for graphics and sound synchronization can be met. However, we
 expect the network delay could cause considerable problems when the s
ystem is scaled up for many users and processing simultaneous notes (f
or harmony). To assess the scalability, we carried out a performance a
nalysis of our system model to derive the maximum number of simultaneo
us participants. For example, according to our data, about 50 particip
ants should be able to play together without significant disruption, e
ach using one track with five simultaneous notes and for playing a mus
ical piece at a speed of 16 ticks per second in a typical PC/LAN envir
onment.In hopes of enhancing the feeling of "co-presence" among partic
ipants, a simple sound localization technique is used to compute panni
ng and relative volumes from positions and orientations of participant
s. This reduced sound localization model is used also in order to mini
mize the computational cost and the network traffic. Participants can 
send predefined messages by interacting with the keyboard, mouse, and 
other input devices. All of the predefined messages are mapped into si
mple avatar motions, such as playing various types of instruments (pla
yers), making applause (audience), and conducting gestures (conductors
). We believe that for coordinated music performance, indirect interac
tion will be the main interaction method, for example, exchanging part
icular gestures, signals, and voice commands to synchronize music, con
firming and reminding expression of the upcoming portion of the music,
 and just exchanging glances to enjoy each others' emotion. In this vi
ew, there would be mainly three groups of participants: conductor, pla
yers, and the audience, playing different roles, but creating co-prese
nce together through mutual recognition. We ran a simple experiment co
mparing the music performance of two groups of participants, one provi
ded with co-presence cues and the other without, and found no performa
nce edge by the group with the co-presence cues. Such a result can ser
ve as one guideline for building music-related VR applications.
AU  - Jung, Byungdae
AU  - Hwang, Jaein
AU  - Lee, Sangyoon
AU  - Kim, Gerard Jounghyun
AU  - Kim, Hyunbin
C1  - Seoul, Korea
C3  - Proceedings of the ACM Symposium on Virtual Reality Software and Techn
ology
DA  - 2000///
C2  - 2000
DO  - 10.1145/502390.502429
ID  - 10.1145/502390.50242
KW  - Virtual Music
KW  - Networked Virtual Reality
KW  - Interaction
KW  - Distributed Virtual Reality
KW  - Co-presence
PB  - Association for Computing Machinery
SN  - 1581133162
SP  - 206-211
T3  - VRST '00
TI  - Incorporating co-presence in distributed virtual music environment
UR  - https://doi.org/10.1145/502390.502429
ER  - 
TY  - CONF
AB  - Recently Augmented Reality (AR) technology has been used to develop th
e next generation collaborative interfaces. First results have shown t
he value of using AR for co-located tasks based on exocentric viewpoin
ts. In contrast, Virtual Reality (VR) seems to offer interesting advan
tages for immersive collaborative experiences with egocentric viewpoin
ts. In this paper we focus on a new area: a mixed collaboration betwee
n AR and VR environments. We present a new conceptual model of transit
ional interfaces that allow users to move between AR and VR viewpoints
. We then describe the results of a quantitative evaluation with an AR
 exocentric viewpoint and a VR egocentric viewpoint for a navigational
 task. We also conducted a second experiment on the impact of the rela
tionship between the interaction and visualization space in mixed coll
aboration. Results of these studies can provide a better understanding
 of how to design interfaces for multispace and transitional collabora
tion.
AU  - Grasset, Raphael
AU  - Lamb, Philip
AU  - Billinghurst, Mark
C1  - USA
C3  - Proceedings of the 4th IEEE/ACM International Symposium on Mixed and A
ugmented Reality
DA  - 2005///
C2  - 2005
DO  - 10.1109/ISMAR.2005.30
ID  - 10.1109/ISMAR.2005.3
PB  - IEEE Computer Society
SN  - 0769524591
SP  - 90-99
T3  - ISMAR '05
TI  - Evaluation of Mixed-Space Collaboration
UR  - https://doi.org/10.1109/ISMAR.2005.30
ER  - 
TY  - BOOK
CY  - Melbourne, VIC, Australia
DA  - 2024///
PY  - 2024
ID  - 10.1145/3652920
PB  - Association for Computing Machinery
SN  - 9798400709807
TI  - AHs '24: Proceedings of the Augmented Humans International Conference 
2024
ER  - 
TY  - JOUR
AB  - The ACM Multimedia Special Interest Group was created ten years ago. S
ince that time, researchers have solved a number of important problems
 related to media processing, multimedia databases, and distributed mu
ltimedia applications. A strategic retreat was organized as part of AC
M Multimedia 2003 to assess the current state of multimedia research a
nd suggest directions for future research. This report presents the re
commendations developed during the retreat. The major observation is t
hat research in the past decade has significantly advanced hardware an
d software support for distributed multimedia applications and that fu
ture research should focus on identifying and delivering applications 
that impact users in the real-world.The retreat suggested that the com
munity focus on solving three grand challenges: (1) make authoring com
plex multimedia titles as easy as using a word processor or drawing pr
ogram, (2) make interactions with remote people and environments nearl
y the same as interactions with local people and environments, and (3)
 make capturing, storing, finding, and using digital media an everyday
 occurrence in our computing environment. The focus of multimedia rese
archers should be on applications that incorporate correlated media, f
use data from different sources, and use context to improve applicatio
n performance.
AU  - Rowe, Lawrence A.
AU  - Jain, Ramesh
DA  - 2005/2//
PY  - 2005
DO  - 10.1145/1047936.1047938
ID  - 10.1145/1047936.1047
IS  - 1
KW  - Multimedia authoring
KW  - distributed collaboration
KW  - multimedia query
KW  - multimedia storage and indexing
KW  - tele-presence
SN  - 1551-6857
SP  - 3-13
T2  - ACM Trans. Multimedia Comput. Commun. Appl.
TI  - ACM SIGMM retreat report on future directions in multimedia research
UR  - https://doi.org/10.1145/1047936.1047938
VL  - 1
ER  - 
TY  - CONF
AB  - By sharing data regarding the sensations experienced by individuals, a
s well as by sharing their knowledge, we are readily able to communica
te with each other, and there are possibilities to further evolve this
 communication method. The different sensations experienced during vol
untary walking and enforced walking give us different feelings. Also, 
the number of individuals involved can create a different feeling when
 walking. Networked computer-assisted walking can support and enhance 
these different experiences. In this paper, we introduce another walki
ng style, the shared power-assisted voluntary walk, which is realized 
by a prototype networked locomotion system. This system can be used in
 tele-rehabilitation, which allows remote patients to share the sensat
ion of walking. Also, it can be used to teach a group of patients reha
bilitative walking. We developed two locomotion interfaces and connect
ed them via a network. We developed enforced and semi-voluntary walkin
g training systems using the shared walk environment and evaluated the
m with a series of experiments. operation integration process. In the 
second algorithm, thanks to deferred broadcast of operations to other 
sites, this process becomes even more simplified.
AU  - Yano, Hiroaki
AU  - Noma, Haruo
AU  - Iwata, Hiroo
AU  - Miyasato, Tsutomu
C1  - Philadelphia, Pennsylvania, USA
C3  - Proceedings of the 2000 ACM Conference on Computer Supported Cooperati
ve Work
DA  - 2000///
C2  - 2000
DO  - 10.1145/358916.358987
ID  - 10.1145/358916.35898
KW  - locomotion interface
KW  - rehabilitation
KW  - shared environment
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 1581132220
SP  - 163-170
T3  - CSCW '00
TI  - Shared walk environment using locomotion interfaces
UR  - https://doi.org/10.1145/358916.358987
ER  - 
TY  - BOOK
CY  - San Sebastian, Spain
DA  - 2023///
PY  - 2023
ID  - 10.1145/3611314
PB  - Association for Computing Machinery
SN  - 9798400703249
TI  - Web3D '23: Proceedings of the 28th International ACM Conference on 3D 
Web Technology
ER  - 
TY  - JOUR
AB  - The increasing number of people playing games on touch-screen mobile p
hones raises the question of whether touch behaviors reflect players’ 
emotional states. This prospect would not only be a valuable evaluatio
n indicator for game designers, but also for real-time personalization
 of the game experience. Psychology studies on acted touch behavior sh
ow the existence of discriminative affective profiles. In this article
, finger-stroke features during gameplay on an iPod were extracted and
 their discriminative power analyzed. Machine learning algorithms were
 used to build systems for automatically discriminating between four e
motional states (Excited, Relaxed, Frustrated, Bored), two levels of a
rousal and two levels of valence. Accuracy reached between 69% and 77%
 for the four emotional states, and higher results ( 89%) were obtaine
d for discriminating between two levels of arousal and two levels of v
alence. We conclude by discussing the factors relevant to the generali
zation of the results to applications other than games.
AU  - Gao, Yuan
AU  - Bianchi-Berthouze, Nadia
AU  - Meng, Hongying
DA  - 2012/12//
PY  - 2012
DO  - 10.1145/2395131.2395138
ID  - 10.1145/2395131.2395
IS  - 4
KW  - Automatic emotion recognition
KW  - affective touch
KW  - touch behavior
KW  - touch-based computer games
SN  - 1073-0516
T2  - ACM Trans. Comput.-Hum. Interact.
TI  - What Does Touch Tell Us about Emotions in Touchscreen-Based Gameplay?
UR  - https://doi.org/10.1145/2395131.2395138
VL  - 19
ER  - 
TY  - CONF
AB  - A passive wand tracked in 3D using computer vision techniques is explo
red as a new input mechanism for interacting with large displays. We d
emonstrate a variety of interaction techniques that exploit the afford
ances of the wand, resulting in an effective interface for large scale
 interaction. The lack of any buttons or other electronics on the wand
 presents a challenge that we address by developing a set of postures 
and gestures to track state and enable command input. We also describe
 the use of multiple wands, and posit designs for more complex wands i
n the future.
AU  - Cao, Xiang
AU  - Balakrishnan, Ravin
C1  - Vancouver, Canada
C3  - Proceedings of the 16th Annual ACM Symposium on User Interface Softwar
e and Technology
DA  - 2003///
C2  - 2003
DO  - 10.1145/964696.964716
ID  - 10.1145/964696.96471
KW  - buttonless input
KW  - gestures
KW  - input devices
KW  - interaction techniques
KW  - large displays
KW  - vision tracking
PB  - Association for Computing Machinery
SN  - 1581136366
SP  - 173-182
T3  - UIST '03
TI  - VisionWand: interaction techniques for large displays using a passive 
wand tracked in 3D
UR  - https://doi.org/10.1145/964696.964716
ER  - 
TY  - CONF
AB  - Although Augmented Reality technology was first developed over forty y
ears ago, there has been little survey work giving an overview of rece
nt research in the field. This paper reviews the ten-year development 
of the work presented at the ISMAR conference and its predecessors wit
h a particular focus on tracking, interaction and display research. It
 provides a roadmap for future augmented reality research which will b
e of great value to this relatively young field, and also for helping 
researchers decide which topics should be explored when they are begin
ning their own studies in the area.
AU  - Zhou, Feng
AU  - Duh, Henry Been-Lirn
AU  - Billinghurst, Mark
C1  - USA
C3  - Proceedings of the 7th IEEE/ACM International Symposium on Mixed and A
ugmented Reality
DA  - 2008///
C2  - 2008
DO  - 10.1109/ISMAR.2008.4637362
ID  - 10.1109/ISMAR.2008.4
PB  - IEEE Computer Society
SN  - 9781424428403
SP  - 193-202
T3  - ISMAR '08
TI  - Trends in augmented reality tracking, interaction and display: A revie
w of ten years of ISMAR
UR  - https://doi.org/10.1109/ISMAR.2008.4637362
ER  - 
TY  - BOOK
CY  - Athens, Greece
DA  - 2023///
PY  - 2023
ID  - 10.1145/3609987
PB  - Association for Computing Machinery
SN  - 9798400708886
TI  - CHIGREECE '23: Proceedings of the 2nd International Conference of the 
ACM Greek SIGCHI Chapter
ER  - 
TY  - BOOK
AB  - Welcome to UbiComp/ISWC 2024, the companion program of two premier con
ferences: The 2024 ACM International Joint Conference on Pervasive and
 Ubiquitous Computing (UbiComp 2024) and the 2024 International Sympos
ium on Wearable Computers (ISWC 2024). UbiComp and ISWC are premier in
terdisciplinary venues for international researchers, designers, devel
opers, practitioners and educators in the field to present and discuss
 novel and impactful research in interactive, mobile, wearable and ubi
quitous computing. The companion program has traditionally been a very
 important part of the UbiComp/ISWC conference series.UbiComp/ISWC 202
4 is held from October 5 to 9, 2024 in Melbourne, Australia. Originall
y, UbiComp/ISWC was scheduled to take place in Melbourne in 2021. Howe
ver, due to the significant impact of COVID-19, our community decided 
to postpone conferences taking place in their traditional form until l
ast year, when UbiComp took place as an in-person event in Mexico. Now
, in 2024 we look to consolidate the strength and ties in our communit
y by having another fully in-person event and hoping to welcome a new 
generation of researchers to meet and explore the wonderful people tha
t make up our community.
CY  - Melbourne VIC, Australia
DA  - 2024///
PY  - 2024
ID  - 10.1145/3675094
PB  - Association for Computing Machinery
SN  - 9798400710582
TI  - UbiComp '24: Companion of the 2024 on ACM International Joint Conferen
ce on Pervasive and Ubiquitous Computing
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3698061
PB  - Association for Computing Machinery
SN  - 9798400712890
TI  - C&amp;C '25: Proceedings of the 2025 Conference on Creativity and Cogn
ition
ER  - 
TY  - BOOK
CY  - Edinburgh, United Kingdom
DA  - 2023///
PY  - 2023
ID  - 10.1145/3616195
PB  - Association for Computing Machinery
SN  - 9798400708183
TI  - AM '23: Proceedings of the 18th International Audio Mostly Conference
ER  - 
TY  - JOUR
AU  - Pentland, Alex
DA  - 2000/3//
PY  - 2000
DO  - 10.1145/330534.330536
ID  - 10.1145/330534.33053
IS  - 3
SN  - 0001-0782
SP  - 35-44
T2  - Commun. ACM
TI  - Perceptual user interfaces: perceptual intelligence
UR  - https://doi.org/10.1145/330534.330536
VL  - 43
ER  - 
TY  - CONF
AB  - In this paper, we present a Human-Computer Interaction (HCI) design pa
ttern language that bundles existing knowledge on tabletop design and 
offers solutions to recurring problems. Our patterns enable not only d
evelopers, designers, and domain experts to improve their existing sys
tems and facilitate the design process of new systems, we also encoura
ge novice users to comprehend the variety of tabletop research and com
mercial products in this domain. We consider our language as a startin
g point to create a sustainable body of knowledge that will be extende
d and refined by the community.
AU  - Remy, Christian
AU  - Weiss, Malte
AU  - Ziefle, Martina
AU  - Borchers, Jan
C1  - Irsee, Germany
C3  - Proceedings of the 15th European Conference on Pattern Languages of Pr
ograms
DA  - 2010///
C2  - 2010
DO  - 10.1145/2328909.2328921
ID  - 10.1145/2328909.2328
KW  - HCI design patterns
KW  - guidelines
KW  - interactive tabletops
PB  - Association for Computing Machinery
SN  - 9781450302593
T3  - EuroPLoP '10
TI  - A pattern language for interactive tabletops in collaborative workspac
es
UR  - https://doi.org/10.1145/2328909.2328921
ER  - 
TY  - BOOK
CY  - Kaiserslautern, Germany
DA  - 2022///
PY  - 2022
ID  - 10.1145/3552327
PB  - Association for Computing Machinery
SN  - 9781450398084
TI  - ECCE '22: Proceedings of the 33rd European Conference on Cognitive Erg
onomics
ER  - 
TY  - BOOK
CY  - Aarhus, Denmark
DA  - 2022///
PY  - 2022
ID  - 10.1145/3547522
PB  - Association for Computing Machinery
SN  - 9781450394482
TI  - NordiCHI '22 Adjunct: Adjunct Proceedings of the 2022 Nordic Human-Com
puter Interaction Conference
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3715668
PB  - Association for Computing Machinery
SN  - 9798400714863
TI  - DIS '25 Companion: Companion Publication of the 2025 ACM Designing Int
eractive Systems Conference
ER  - 
TY  - BOOK
CY  - Darmstadt, Germany
DA  - 2022///
PY  - 2022
ID  - 10.1145/3543758
PB  - Association for Computing Machinery
SN  - 9781450396905
TI  - MuC '22: Proceedings of Mensch und Computer 2022
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3681758
PB  - Association for Computing Machinery
SN  - 9798400711404
TI  - SA '24: SIGGRAPH Asia 2024 Technical Communications
ER  - 
TY  - CONF
AU  - Peters, Ralph
AU  - Graeff, Andreas
AU  - Paul, Christian
C1  - Las Vegas, Nevada, USA
C3  - Proceedings of the 1997 Workshop on New Paradigms in Information Visua
lization and Manipulation
DA  - 1997///
C2  - 1997
DO  - 10.1145/275519.275535
ID  - 10.1145/275519.27553
KW  - architecture
KW  - cooperation
KW  - integration
KW  - software agents
KW  - usability
KW  - virtual collaborative environment
PB  - Association for Computing Machinery
SN  - 1581130511
SP  - 69-74
T3  - NPIV '97
TI  - Integrating agents into virtual worlds
UR  - https://doi.org/10.1145/275519.275535
ER  - 
TY  - BOOK
AB  - The world is becoming more malleable by the day, with new tools, appli
cations, and methods to create, craft, build, and share. At SIGGRAPH 2
015, the Studio focuses on disruptive practices in the world of conten
t creation. Along with a renewed emphasis on technology, it presents p
rojects from alternative fields that utilize and build new foundations
 in computer graphics - particularly those that extend beyond traditio
nal screens and into the physical world - including themed entertainme
nt, location-based installations, projection mapping, and advancements
 in augmented and virtual reality.
CY  - Los Angeles, California
DA  - 2015///
PY  - 2015
ID  - 10.1145/2785585
PB  - Association for Computing Machinery
SN  - 9781450336376
TI  - SIGGRAPH '15: SIGGRAPH 2015: Studio
ER  - 
TY  - CONF
AB  - The objective of this course is to provide an introduction to the issu
es that must be considered when building high-fidelity 3D engaging sha
red virtual environments. The principles of human perception guide imp
ortant development of algorithms and techniques in collaboration, grap
hical, auditory, and haptic rendering. We aim to show how human percep
tion is exploited to achieve realism in high fidelity environments wit
hin the constraints of available finite computational resources.In thi
s course we address the challenges faced when building such high-fidel
ity engaging shared virtual environments, especially those that facili
tate collaboration and intuitive interaction. We present real applicat
ions in which such high-fidelity is essential. With reference to these
, we illustrate the significant need for the combination of high-fidel
ity graphics in real time, better modes of interaction, and appropriat
e collaboration strategies.After introducing the concept of high-fidel
ity virtual environments and why these convey important information to
 the user, we cover the main issues in two parts linked by the common 
thread of exploiting human perception. First we explore perceptually d
riven techniques that can be employed to achieve high-fidelity graphic
al rendering in real-time, and how incorporating authentic lighting ef
fects helps to convey a sense of realism and scale in virtual re-const
ructions of historical sites.Secondly, we examine how intuitive intera
ction between participants, and with objects in the environment, also 
plays a key role in the overall experience. How perceptual methods can
 be used to guide interest management and distribution choices, is con
sidered with an emphasis on avoiding potential pitfalls when distribut
ing physically-based simulations. An analysis of real network conditio
ns and the implications of these for distribution strategies that faci
litate collaboration is presented. Furthermore, we describe technologi
es necessary to provide intuitive interaction in virtual environments,
 paying particular attention to engaging multiple sensory modalities, 
primarily through physically-based sound simulation and perceptually h
igh-fidelity haptic interaction.The combination of realism and intuiti
ve compelling interaction can lead to engaging virtual environments ca
pable of exhibiting skills transfer, an illusive goal of many virtual 
environment applications.
AU  - Glencross, Mashhuda
AU  - Chalmers, Alan G.
AU  - Lin, Ming C.
AU  - Otaduy, Miguel A.
AU  - Gutierrez, Diego
C1  - Boston, Massachusetts
C3  - ACM SIGGRAPH 2006 Courses
DA  - 2006///
C2  - 2006
DO  - 10.1145/1185657.1185814
ID  - 10.1145/1185657.1185
KW  - collaborative environments
KW  - haptics
KW  - high-fidelity rendering
KW  - human-computer interaction
KW  - multi-user
KW  - networked applications
KW  - perception
KW  - virtual reality
PB  - Association for Computing Machinery
SN  - 1595933646
SP  - 1-es
T3  - SIGGRAPH '06
TI  - Exploiting perception in high-fidelity virtual environments (Additiona
l presentations from the 24th course are available on the citation pag
e)
UR  - https://doi.org/10.1145/1185657.1185814
ER  - 
TY  - BOOK
CY  - Honolulu, HI, USA
DA  - 2024///
PY  - 2024
ID  - 10.1145/3613904
PB  - Association for Computing Machinery
SN  - 9798400703300
TI  - CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Co
mputing Systems
ER  - 
TY  - BOOK
CY  - Yokohama, Japan
DA  - 2021///
PY  - 2021
ID  - 10.1145/3411764
PB  - Association for Computing Machinery
SN  - 9781450380966
TI  - CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Co
mputing Systems
ER  - 
TY  - BOOK
CY  - Glasgow, United Kingdom
DA  - 2023///
PY  - 2023
ID  - 10.1145/3582700
PB  - Association for Computing Machinery
SN  - 9781450399845
TI  - AHs '23: Proceedings of the Augmented Humans International Conference 
2023
ER  - 
TY  - BOOK
CY  - Tampere, Finland
DA  - 2022///
PY  - 2022
ID  - 10.1145/3569219
PB  - Association for Computing Machinery
SN  - 9781450399555
TI  - Academic Mindtrek '22: Proceedings of the 25th International Academic 
Mindtrek Conference
ER  - 
TY  - BOOK
CY  - Karlsruhe, Germany
DA  - 2024///
PY  - 2024
ID  - 10.1145/3670653
PB  - Association for Computing Machinery
SN  - 9798400709982
TI  - MuC '24: Proceedings of Mensch und Computer 2024
ER  - 
TY  - CONF
AU  - Zimmerman, Thomas G.
AU  - Smith, Joshua R.
AU  - Paradiso, Joseph A.
AU  - Allport, David
AU  - Gershenfeld, Neil
C1  - Denver, Colorado, USA
C3  - Proceedings of the SIGCHI Conference on Human Factors in Computing Sys
tems
DA  - 1995///
C2  - 1995
DO  - 10.1145/223904.223940
ID  - 10.1145/223904.22394
PB  - ACM Press/Addison-Wesley Publishing Co.
SN  - 0201847051
SP  - 280-287
T3  - CHI '95
TI  - Applying electric field sensing to human-computer interfaces
UR  - https://doi.org/10.1145/223904.223940
ER  - 
TY  - BOOK
AB  - The SIGGRAPH Asia Symposium on Education program will be inviting expe
rts from both academia and the industry to present innovative research
, methods and positions about the teaching and integration of computer
 graphics and interactive techniques in all areas of learning.This yea
r's main conference theme is "The Celebration of Life and Technology."
 We view education as a natural part of the lifelong learning process.
 We wish to support the evolving integration of art and technology emb
raced by educators.As an international gathering of industry professio
nals and academics, the Symposium on Education will present perspectiv
es that appeal to a wide spectrum of interests. We will share educatio
nal strategies adopted in both industry and academia to make the learn
ing process more satisfying, productive, and meaningful.
CY  - Bangkok, Thailand
DA  - 2017///
PY  - 2017
ID  - 10.1145/3134368
PB  - Association for Computing Machinery
SN  - 9781450354097
TI  - SA '17: SIGGRAPH Asia 2017 Symposium on Education
ER  - 
TY  - BOOK
CY  - Aarhus, Denmark
DA  - 2022///
PY  - 2022
ID  - 10.1145/3546155
PB  - Association for Computing Machinery
SN  - 9781450396998
TI  - NordiCHI '22: Nordic Human-Computer Interaction Conference
ER  - 
TY  - BOOK
CY  - Paris, France
DA  - 2023///
PY  - 2023
ID  - 10.1145/3577190
PB  - Association for Computing Machinery
SN  - 9798400700552
TI  - ICMI '23: Proceedings of the 25th International Conference on Multimod
al Interaction
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3746237
PB  - Association for Computing Machinery
SN  - 9798400720383
TI  - Web3D '25: Proceedings of the 30th International Conference on 3D Web 
Technology
ER  - 
TY  - BOOK
CY  - Kobe, Japan
DA  - 2015///
PY  - 2015
ID  - 10.1145/2818466
PB  - Association for Computing Machinery
SN  - 9781450339254
TI  - SA '15: SIGGRAPH Asia 2015 Emerging Technologies
ER  - 
TY  - BOOK
CY  - Sydney, Australia
DA  - 2023///
PY  - 2023
ID  - 10.1145/3603421
PB  - Association for Computing Machinery
SN  - 9781450397469
TI  - ICVARS '23: Proceedings of the 2023 7th International Conference on Vi
rtual and Augmented Reality Simulations
ER  - 
TY  - CONF
AB  - Subjects such as electrostatics are difficult to teach in part because
 learners cannot draw analogies to personal experiences that provide m
etaphors. MaxwellWorld has been designed to allow students to explore 
electrostatic forces and fields, learn about the concept of electric p
otential, and "discover" the nature of electric flux. In formative ass
essments of MaxwellWorld's usability and learnability, students enjoye
d learning about electric fields and cited the 3-D representations, th
e interactivity, the ability to navigate to multiple perspectives, and
 the use of color as characteristics that were important to their lear
ning experience. Pre- and post-lesson evaluations show that students h
ad a greater understanding of the distribution of forces in an electri
c field, as well as representations such as test charge traces and fie
ld lines. Our studies also indicate that the three-dimensional nature 
of VR aids with learning and that the virtual reality experience is mo
re motivating for students than a comparable 2-D microworld.
AU  - Dede, Chris
AU  - Salzman, Marilyn C.
AU  - Loftin, R. Bowen
C1  - Evanston, Illinois
C3  - Proceedings of the 1996 International Conference on Learning Sciences
DA  - 1996///
C2  - 1996
ID  - 10.5555/1161135.1161
PB  - International Society of the Learning Sciences
SN  - 1880094231
SP  - 22-29
T3  - ICLS '96
TI  - MaxwellWorld: learning complex scientific concepts via immersion in vi
rtual reality
ER  - 
TY  - BOOK
CY  - Stanford, CA, USA
DA  - 2024///
PY  - 2024
ID  - 10.1145/3641308
PB  - Association for Computing Machinery
SN  - 9798400705205
TI  - AutomotiveUI '24 Adjunct: Adjunct Proceedings of the 16th Internationa
l Conference on Automotive User Interfaces and Interactive Vehicular A
pplications
ER  - 
TY  - BOOK
CY  - Uppsala, Sweden
DA  - 2024///
PY  - 2024
ID  - 10.1145/3677045
PB  - Association for Computing Machinery
SN  - 9798400709654
TI  - NordiCHI '24 Adjunct: Adjunct Proceedings of the 2024 Nordic Conferenc
e on Human-Computer Interaction
ER  - 
TY  - BOOK
CY  - Halifax, NS, Canada
DA  - 2024///
PY  - 2024
ID  - 10.1145/3670947
PB  - Association for Computing Machinery
SN  - 9798400718281
TI  - GI '24: Proceedings of the 50th Graphics Interface Conference
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3743049
PB  - Association for Computing Machinery
SN  - 9798400715822
TI  - MuC '25: Proceedings of the Mensch und Computer 2025
ER  - 
TY  - BOOK
CY  - Cambridge, United Kingdom
DA  - 2022///
PY  - 2022
ID  - 10.1145/3544793
PB  - Association for Computing Machinery
SN  - 9781450394239
TI  - UbiComp/ISWC '22 Adjunct: Adjunct Proceedings of the 2022 ACM Internat
ional Joint Conference on Pervasive and Ubiquitous Computing and the 2
022 ACM International Symposium on Wearable Computers
ER  - 
TY  - BOOK
CY  - Melbourne, VIC, Australia
DA  - 2024///
PY  - 2024
ID  - 10.1145/3640471
PB  - Association for Computing Machinery
SN  - 9798400705069
TI  - MobileHCI '24 Adjunct: Adjunct Proceedings of the 26th International C
onference on Mobile Human-Computer Interaction
ER  - 
TY  - BOOK
CY  - Vienna, Austria
DA  - 2023///
PY  - 2023
ID  - 10.1145/3626705
PB  - Association for Computing Machinery
SN  - 9798400709210
TI  - MUM '23: Proceedings of the 22nd International Conference on Mobile an
d Ubiquitous Multimedia
ER  - 
TY  - BOOK
CY  - Vancouver, BC, Canada
DA  - 2022///
PY  - 2022
ID  - 10.1145/3528575
PB  - Association for Computing Machinery
SN  - 9781450393416
TI  - MobileHCI '22: Adjunct Publication of the 24th International Conferenc
e on Human-Computer Interaction with Mobile Devices and Services
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3689236
PB  - Association for Computing Machinery
SN  - 9798400718137
TI  - ICCSIE '24: Proceedings of the 2024 9th International Conference on Cy
ber Security and Information Engineering
ER  - 
TY  - BOOK
CY  - Delft, Netherlands
DA  - 2024///
PY  - 2024
ID  - 10.1145/3628516
PB  - Association for Computing Machinery
SN  - 9798400704420
TI  - IDC '24: Proceedings of the 23rd Annual ACM Interaction Design and Chi
ldren Conference
ER  - 
TY  - BOOK
CY  - Cork, Ireland
DA  - 2024///
PY  - 2024
ID  - 10.1145/3623509
PB  - Association for Computing Machinery
SN  - 9798400704024
TI  - TEI '24: Proceedings of the Eighteenth International Conference on Tan
gible, Embedded, and Embodied Interaction
ER  - 
TY  - BOOK
CY  - Melbourne, VIC, Australia
DA  - 2021///
PY  - 2021
ID  - 10.1145/3520495
PB  - Association for Computing Machinery
SN  - 9781450395984
TI  - OzCHI '21: Proceedings of the 33rd Australian Conference on Human-Comp
uter Interaction
ER  - 
TY  - BOOK
CY  - St. John's, NL, Canada
DA  - 2024///
PY  - 2024
ID  - 10.1145/3663548
PB  - Association for Computing Machinery
SN  - 9798400706776
TI  - ASSETS '24: Proceedings of the 26th International ACM SIGACCESS Confer
ence on Computers and Accessibility
ER  - 
TY  - BOOK
CY  - Tampere, Finland
DA  - 2024///
PY  - 2024
ID  - 10.1145/3665463
PB  - Association for Computing Machinery
SN  - 9798400706929
TI  - CHI PLAY Companion '24: Companion Proceedings of the 2024 Annual Sympo
sium on Computer-Human Interaction in Play
ER  - 
TY  - BOOK
CY  - Paris, France
DA  - 2023///
PY  - 2023
ID  - 10.1145/3610661
PB  - Association for Computing Machinery
SN  - 9798400703218
TI  - ICMI '23 Companion: Companion Publication of the 25th International Co
nference on Multimodal Interaction
ER  - 
TY  - BOOK
CY  - Ropar, India
DA  - 2023///
PY  - 2023
ID  - 10.1145/3610419
PB  - Association for Computing Machinery
SN  - 9781450399807
TI  - AIR '23: Proceedings of the 2023 6th International Conference on Advan
ces in Robotics
ER  - 
TY  - BOOK
CY  - Stockholm, Sweden
DA  - 2024///
PY  - 2024
ID  - 10.1145/3639701
PB  - Association for Computing Machinery
SN  - 9798400705038
TI  - IMX '24: Proceedings of the 2024 ACM International Conference on Inter
active Media Experiences
ER  - 
TY  - BOOK
CY  - Rio Grande, Brazil
DA  - 2023///
PY  - 2023
ID  - 10.1145/3625008
PB  - Association for Computing Machinery
SN  - 9798400709432
TI  - SVR '23: Proceedings of the 25th Symposium on Virtual and Augmented Re
ality
ER  - 
TY  - BOOK
CY  - Chicago, IL, USA
DA  - 2023///
PY  - 2023
ID  - 10.1145/3585088
PB  - Association for Computing Machinery
SN  - 9798400701313
TI  - IDC '23: Proceedings of the 22nd Annual ACM Interaction Design and Chi
ldren Conference
ER  - 
TY  - BOOK
AB  - This book investigates multiple facets of the emerging discipline of T
angible, Embodied, and Embedded Interaction (TEI). This is a story of 
atoms and bits. We explore the interweaving of the physical and digita
l, toward understanding some of their wildly varying hybrid forms and 
behaviors. Spanning conceptual, philosophical, cognitive, design, and 
technical aspects of interaction, this book charts both history and as
pirations for the future of TEI. We examine and celebrate diverse trai
lblazing works, and provide wide-ranging conceptual and pragmatic tool
s toward weaving the animating fires of computation and technology int
o evocative tangible forms. We also chart a path forward for TEI engag
ement with broader societal and sustainability challenges that will pr
ofoundly (re)shape our children’s and grandchildren’s futures. We invi
te you all to join this quest.
AU  - Ullmer, Brygg
AU  - Shaer, Orit
AU  - Mazalek, Ali
AU  - Hummels, Caroline
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
ET  - 1
ID  - 10.1145/3544564
PB  - Association for Computing Machinery
SN  - 9781450397698
TI  - Weaving Fire into Form: Aspirations for Tangible and Embodied Interact
ion
VL  - 44
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3723498
PB  - Association for Computing Machinery
SN  - 9798400718564
TI  - FDG '25: Proceedings of the 20th International Conference on the Found
ations of Digital Games
ER  - 
TY  - BOOK
AB  - Posters are a convenient method for presenting in-progress research, s
tudent projects, and late-breaking work. Poster topics range from appl
ications of computer graphics to in-depth research in specific areas. 
New this year, SIGGRAPH posters will be presented on video monitors in
 an electronic format only. Poster authors meet and discuss their work
 with attendees during Poster Presentations.
CY  - Los Angeles, California
DA  - 2015///
PY  - 2015
ID  - 10.1145/2787626
PB  - Association for Computing Machinery
SN  - 9781450336321
TI  - SIGGRAPH '15: ACM SIGGRAPH 2015 Posters
ER  - 
TY  - BOOK
AB  - Dear MMSys 2024 Participants,On behalf of the organizers, we are very 
pleased to welcome you to the 15th ACM Multimedia Systems Conference, 
taking place for the first time in Italy, in the city of Bari.MMSys is
 a premier conference dedicated to the exciting and multidisciplinary 
field of multimedia, with a specific focus on its systems and applicat
ions. The conference provides a platform for researchers from both aca
demia and industry to share their latest findings in the multimedia sy
stems research area. Many international researchers, practitioners, en
gineers, and students from academia, industry, standardization bodies,
 and government agencies join the MMSys conference each year.
CY  - Bari, Italy
DA  - 2024///
PY  - 2024
ID  - 10.1145/3625468
PB  - Association for Computing Machinery
SN  - 9798400704123
TI  - MMSys '24: Proceedings of the 15th ACM Multimedia Systems Conference
ER  - 
TY  - BOOK
CY  - Christchurch, New Zealand
DA  - 2022///
PY  - 2022
ID  - 10.1145/3527188
PB  - Association for Computing Machinery
SN  - 9781450393232
TI  - HAI '22: Proceedings of the 10th International Conference on Human-Age
nt Interaction
ER  - 
TY  - BOOK
AB  - This volume contains the papers presented at the 23nd International Co
nference on Intelligent Virtual Agents (IVA 2023) located in Würzburg,
 Germany, from 19. to 22.09.2023.
CY  - Würzburg, Germany
DA  - 2023///
PY  - 2023
ID  - 10.1145/3570945
PB  - Association for Computing Machinery
SN  - 9781450399944
TI  - IVA '23: Proceedings of the 23rd ACM International Conference on Intel
ligent Virtual Agents
ER  - 
TY  - BOOK
CY  - Uppsala, Sweden
DA  - 2024///
PY  - 2024
ID  - 10.1145/3679318
PB  - Association for Computing Machinery
SN  - 9798400709661
TI  - NordiCHI '24: Proceedings of the 13th Nordic Conference on Human-Compu
ter Interaction
ER  - 
TY  - BOOK
CY  - Bengaluru, India
DA  - 2022///
PY  - 2022
ID  - 10.1145/3536221
PB  - Association for Computing Machinery
SN  - 9781450393904
TI  - ICMI '22: Proceedings of the 2022 International Conference on Multimod
al Interaction
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3715336
PB  - Association for Computing Machinery
SN  - 9798400714856
TI  - DIS '25: Proceedings of the 2025 ACM Designing Interactive Systems Con
ference
ER  - 
TY  - BOOK
AB  - Welcome to CSCW 2017, the ACM 2017 Conference on Computer Supported Co
operative Work and Social Computing! We are excited to welcome the CSC
W community back to Portland, Oregon, where the second CSCW conference
 was held in 1988. Both Portland and CSCW have matured a great deal du
ring the intervening 29 years. We hope that you will find that Portlan
d provides a stimulating environment for our conference.CSCW is the pr
emier venue for presenting research in the design and use of technolog
ies that affect groups, organizations, communities, and networks. Brin
ging together top researchers and practitioners from academia and indu
stry, CSCW explores the technical, social, material, and theoretical c
hallenges of designing technology to support collaborative work and li
fe activities. CSCW welcomes a diverse range of topics and research me
thodologies. Studies often involve the development and application of 
novel technologies and/or ethnographic studies that inform design prac
tice or theory. The mission of the conference is to share research tha
t advances the state of human knowledge and improves both the design o
f systems and the ways they are used. The diversity of work in our con
ference program reflects the diversity of technology use in people's w
ork, social, and civic lives as well as the geographic and cultural di
versity of contributors.As many of you know, CSCW follows a rigorous "
revise and resubmit" review process that uses peer review to improve s
ubmitted papers while maintaining a high-quality threshold for final a
cceptance. We also help prepare the next generation of reviewers with 
a mentorship program in which students review papers under the guidanc
e of an experienced reviewer. This year we have the largest CSCW progr
am ever. We had 530 submitted papers and 183 were accepted for present
ation at the conference. The program also includes 4 papers published 
in ACM Transactions on Human- Computer Interaction (TOCHI). In additio
n, we will feature 14 workshops, 56 posters, 12 demos, and 3 panels.Li
li Cheng of Microsoft Research will open the conference, speaking on "
Conversational AI &amp; Lessons Learned." Our closing plenary will fea
ture Jorge Cham, the creator of PhD Comics, who will talk about, "The 
Science Gap." We also welcome Paul Luff and Christian Heath from King'
s College as the recipients of this year's CSCW Lasting Impact award f
or their influential 1998 paper, "Mobility in Collaboration."
CY  - Portland, Oregon, USA
DA  - 2017///
PY  - 2017
ID  - 10.1145/2998181
PB  - Association for Computing Machinery
SN  - 9781450343350
TI  - CSCW '17: Proceedings of the 2017 ACM Conference on Computer Supported
 Cooperative Work and Social Computing
ER  - 
TY  - BOOK
AB  - Welcome to the 27th ACM Conference on Computer-Supported Cooperative W
ork and Social Computing (CSCW 2024). This year's conference is partic
ularly special, as it marks the first time CSCW to be held in Latin Am
erica - a highly anticipated milestone for our Latin American communit
y. We are excited to gather in San Jose, Costa Rica, and host a hybrid
 event that allows remote participation from community members worldwi
de.As in previous years, CSCW 2024 brings together a variety of discip
lines, from system design to critical analysis, to propose, examine, a
nd reimagine technologies that support groups and communities. As our 
discipline evolves, new topics continuously emerge and are embraced by
 our community. This year, we see an emphasis on issues centered aroun
d AI, including explainability, fairness, and AI-human collaboration. 
At the same time, our long-standing concerns remain well represented, 
including work on group dynamics and decision-making, social media, in
clusive and culturally aware design, co-design with marginalized commu
nities, and the creation of socially responsible tools. This year, we 
invited 387 PACM-HCI, TSC, and TOCHI papers to be presented alongside 
a diverse lineup of workshops, posters, demos, SIGs, panels, and the d
octoral consortium. Below are the numbers of reviewed and accepted sub
missions for each track featured in this conference companion.
CY  - San Jose, Costa Rica
DA  - 2024///
PY  - 2024
ID  - 10.1145/3678884
PB  - Association for Computing Machinery
SN  - 9798400711145
TI  - CSCW Companion '24: Companion Publication of the 2024 Conference on Co
mputer-Supported Cooperative Work and Social Computing
ER  - 
TY  - BOOK
A3  - Oviatt, Sharon
A3  - Schuller, Björn
A3  - Cohen, Philip R.
A3  - Sonntag, Daniel
A3  - Potamianos, Gerasimos
A3  - Krüger, Antonio
AB  - The Handbook of Multimodal-Multisensor Interfaces provides the first a
uthoritative resource on what has become the dominant paradigm for new
 computer interfaces—user input involving new media (speech, multi-tou
ch, hand and body gestures, facial expressions, writing) embedded in m
ultimodal-multisensor interfaces.This three-volume handbook is written
 by international experts and pioneers in the field. It provides a tex
tbook, reference, and technology roadmap for professionals working in 
this and related areas.This third volume focuses on state-of-the-art m
ultimodal language and dialogue processing, including semantic integra
tion of modalities. The development of increasingly expressive embodie
d agents and robots has become an active test-bed for coordinating mul
timodal dialogue input and output, including processing of language an
d nonverbal communication. In addition, major application areas are fe
atured for commercializing multimodal-multisensor systems, including a
utomotive, robotic, manufacturing, machine translation, banking, commu
nications, and others. These systems rely heavily on software tools, d
ata resources, and international standards to facilitate their develop
ment. For insights into the future, emerging multimodal-multisensor te
chnology trends are highlighted for medicine, robotics, interaction wi
th smart spaces, and similar topics. Finally, this volume discusses th
e societal impact of more widespread adoption of these systems, such a
s privacy risks and how to mitigate them. The handbook chapters provid
e a number of walk-through examples of system design and processing, i
nformation on practical resources for developing and evaluating new sy
stems, and terminology and tutorial support for mastering this emergin
g field. In the final section of this volume, experts exchange views o
n a timely and controversial challenge topic, and how they believe mul
timodal-multisensor interfaces need to be equipped to most effectively
 advance human performance during the next decade.
DA  - 2019///
PY  - 2019
ID  - 10.1145/3233795
PB  - Association for Computing Machinery
SN  - 9781970001754
TI  - The Handbook of Multimodal-Multisensor Interfaces: Language Processing
, Software, Commercialization, and Emerging Directions
ER  - 
TY  - BOOK
CY  - Austin, TX, USA
DA  - 2024///
PY  - 2024
ID  - 10.1145/3686038
PB  - Association for Computing Machinery
SN  - 9798400709890
TI  - TAS '24: Proceedings of the Second International Symposium on Trustwor
thy Autonomous Systems
ER  - 
TY  - BOOK
CY  - Shenzhen, China
DA  - 2014///
PY  - 2014
ID  - 10.1145/2669062
PB  - Association for Computing Machinery
SN  - 9781450318914
TI  - SA '14: SIGGRAPH Asia 2014 Mobile Graphics and Interactive Application
s
ER  - 
TY  - BOOK
CY  - New York, NY, USA
DA  - 2023///
PY  - 2023
ID  - 10.1145/3597638
PB  - Association for Computing Machinery
SN  - 9798400702204
TI  - ASSETS '23: Proceedings of the 25th International ACM SIGACCESS Confer
ence on Computers and Accessibility
ER  - 
TY  - BOOK
CY  - Crete, Greece
DA  - 2024///
PY  - 2024
ID  - 10.1145/3652037
PB  - Association for Computing Machinery
SN  - 9798400717604
TI  - PETRA '24: Proceedings of the 17th International Conference on PErvasi
ve Technologies Related to Assistive Environments
ER  - 
TY  - BOOK
CY  - Lleida, Spain
DA  - 2023///
PY  - 2023
ID  - 10.1145/3612783
PB  - Association for Computing Machinery
SN  - 9798400707902
TI  - Interacción '23: Proceedings of the XXIII International Conference on 
Human Computer Interaction
ER  - 
TY  - BOOK
CY  - Tokyo, Japan
DA  - 2016///
PY  - 2016
ID  - 10.1145/2993148
PB  - Association for Computing Machinery
SN  - 9781450345569
TI  - ICMI '16: Proceedings of the 18th ACM International Conference on Mult
imodal Interaction
ER  - 
TY  - BOOK
CY  - Manaus, Brazil
DA  - 2024///
PY  - 2024
ID  - 10.1145/3691573
PB  - Association for Computing Machinery
SN  - 9798400709791
TI  - SVR '24: Proceedings of the 26th Symposium on Virtual and Augmented Re
ality
ER  - 
TY  - BOOK
CY  - Allahabad, India
DA  - 2023///
PY  - 2023
ID  - 10.1145/3578527
PB  - Association for Computing Machinery
SN  - 9798400700644
TI  - ISEC '23: Proceedings of the 16th Innovations in Software Engineering 
Conference
ER  - 
TY  - BOOK
CY  - Denpasar, Bali, Indonesia
DA  - 2023///
PY  - 2023
ID  - 10.1145/3629606
PB  - Association for Computing Machinery
SN  - 9798400716454
TI  - CHCHI '23: Proceedings of the Eleventh International Symposium of Chin
ese CHI
ER  - 
TY  - BOOK
CY  - Rennes, France
DA  - 2023///
PY  - 2023
ID  - 10.1145/3623264
PB  - Association for Computing Machinery
SN  - 9798400703935
TI  - MIG '23: Proceedings of the 16th ACM SIGGRAPH Conference on Motion, In
teraction and Games
ER  - 
TY  - BOOK
A3  - Lugrin, Birgit
A3  - Pelachaud, Catherine
A3  - Traum, David
AB  - The Handbook on Socially Interactive Agents provides a comprehensive o
verview of the research fields of Embodied Conversational Agents, Inte
lligent Virtual Agents, and Social Robotics. Socially Interactive Agen
ts (SIAs), whether virtually or physically embodied, are autonomous ag
ents that are able to perceive an environment including people or othe
r agents, reason, and decide how to interact, and express attitudes su
ch as emotions, engagement, or empathy. They are capable of interactin
g with people and each other in a socially intelligent manner using mu
ltimodal communicative behaviors with the goal to support humans in va
rious domains.Written by international experts in their respective fie
lds, the book summarizes research in the many important research commu
nities pertinent for SIAs, while discussing current challenges and fut
ure directions. The handbook provides easy access to modeling and stud
ying SIAs for researchers and students and aims at further bridging th
e gap between the research communities involved.In two volumes, the bo
ok clearly structures the vast body of research. The first volume star
ts by introducing what is involved in SIAs research, in particular res
earch methodologies and ethical implications of developing SIAs. It fu
rther examines research on appearance and behavior, focusing on multim
odality. Finally, social cognition for SIAs is investigated by differe
nt theoretical models and phenomena such as theory of mind or pro-soci
ality. The second volume starts with perspectives on interaction, exam
ined from different angles such as interaction in social space, group 
interaction, or long-term interaction. It also includes an extensive o
verview summarizing research and systems of human-agent platforms and 
of some of the major application areas of SIAs such as education, agin
g support, autism or games.
CY  - New York, NY, USA
DA  - 2022///
PY  - 2022
ET  - 1
ID  - 10.1145/3563659
PB  - Association for Computing Machinery
SN  - 9781450398961
TI  - The Handbook on Socially Interactive Agents: 20 years of Research on E
mbodied Conversational Agents, Intelligent Virtual Agents, and Social 
Robotics Volume 2: Interactivity, Platforms, Application
VL  - 48
ER  - 
TY  - BOOK
CY  - Tokyo, Japan
DA  - 2024///
PY  - 2024
ID  - 10.1145/3678726
PB  - Association for Computing Machinery
SN  - 9798400717611
TI  - ICEMT '24: Proceedings of the 2024 8th International Conference on Edu
cation and Multimedia Technology
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3702163
PB  - Association for Computing Machinery
SN  - 9798400717819
TI  - ICETC '24: Proceedings of the 2024 16th International Conference on Ed
ucation Technology and Computers
ER  - 
TY  - BOOK
CY  - Virtual Event, USA
DA  - 2023///
PY  - 2023
ID  - 10.1145/3591196
PB  - Association for Computing Machinery
SN  - 9798400701801
TI  - C&amp;C '23: Proceedings of the 15th Conference on Creativity and Cogn
ition
ER  - 
TY  - BOOK
CY  - Tokyo, Japan
DA  - 2023///
PY  - 2023
ID  - 10.1145/3625704
PB  - Association for Computing Machinery
SN  - 9798400709142
TI  - ICEMT '23: Proceedings of the 7th International Conference on Educatio
n and Multimedia Technology
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3696593
PB  - Association for Computing Machinery
SN  - 9798400707292
TI  - DSAI '24: Proceedings of the 11th International Conference on Software
 Development and Technologies for Enhancing Accessibility and Fighting
 Info-exclusion
ER  - 
TY  - BOOK
CY  - Tampere, Finland
DA  - 2023///
PY  - 2023
ID  - 10.1145/3616961
PB  - Association for Computing Machinery
SN  - 9798400708749
TI  - Mindtrek '23: Proceedings of the 26th International Academic Mindtrek 
Conference
ER  - 
TY  - BOOK
CY  - Sydney, NSW, Australia
DA  - 2023///
PY  - 2023
ID  - 10.1145/3581754
PB  - Association for Computing Machinery
SN  - 9798400701078
TI  - IUI '23 Companion: Companion Proceedings of the 28th International Con
ference on Intelligent User Interfaces
ER  - 
TY  - BOOK
CY  - Swansea, United Kingdom
DA  - 2024///
PY  - 2024
ID  - 10.1145/3687272
PB  - Association for Computing Machinery
SN  - 9798400711787
TI  - HAI '24: Proceedings of the 12th International Conference on Human-Age
nt Interaction
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3715335
PB  - Association for Computing Machinery
SN  - 9798400714849
TI  - COMPASS '25: Proceedings of the 2025 ACM SIGCAS/SIGCHI Conference on C
omputing and Sustainable Societies
ER  - 
TY  - BOOK
AB  - Talks highlight the latest developments before publication, present id
eas that are still in progress, or showcase how computer graphics and 
interactive techniques are actually implemented and used, in graphics 
production or other fields. Talks take you behind the scenes and into 
the minds of SIGGRAPH 2017 creators in all areas of computer graphics 
and interactive techniques, including art, design, animation, visual e
ffects, interactivity, research, and engineering.
CY  - Los Angeles, California
DA  - 2017///
PY  - 2017
ID  - 10.1145/3084363
PB  - Association for Computing Machinery
SN  - 9781450350082
TI  - SIGGRAPH '17: ACM SIGGRAPH 2017 Talks
ER  - 
TY  - BOOK
CY  - Vancouver, BC, Canada
DA  - 2023///
PY  - 2023
ID  - 10.1145/3587819
PB  - Association for Computing Machinery
SN  - 9798400701481
TI  - MMSys '23: Proceedings of the 14th ACM Multimedia Systems Conference
ER  - 
TY  - BOOK
CY  - Guangzhou, China
DA  - 2023///
PY  - 2023
ID  - 10.1145/3615522
PB  - Association for Computing Machinery
SN  - 9798400707513
TI  - VINCI '23: Proceedings of the 16th International Symposium on Visual I
nformation Communication and Interaction
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3721238
PB  - Association for Computing Machinery
SN  - 9798400715402
TI  - SIGGRAPH Conference Papers '25: Proceedings of the Special Interest Gr
oup on Computer Graphics and Interactive Techniques Conference Confere
nce Papers
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3701100
PB  - Association for Computing Machinery
SN  - 9798400718120
TI  - ADMIT '24: Proceedings of the 2024 3rd International Conference on Alg
orithms, Data Mining, and Information Technology
ER  - 
TY  - BOOK
CY  - Vienna, Austria
DA  - 2022///
PY  - 2022
ID  - 10.1145/3543712
PB  - Association for Computing Machinery
SN  - 9781450396226
TI  - ICCTA '22: Proceedings of the 2022 8th International Conference on Com
puter Technology Applications
ER  - 
TY  - BOOK
CY  - Lisbon, Portugal
DA  - 2023///
PY  - 2023
ID  - 10.1145/3582515
PB  - Association for Computing Machinery
SN  - 9798400701160
TI  - GoodIT '23: Proceedings of the 2023 ACM Conference on Information Tech
nology for Social Good
ER  - 
TY  - BOOK
CY  - Irsee, Germany
DA  - 2022///
PY  - 2022
ID  - 10.1145/3551902
PB  - Association for Computing Machinery
SN  - 9781450395946
TI  - EuroPLop '22: Proceedings of the 27th European Conference on Pattern L
anguages of Programs
ER  - 
TY  - BOOK
CY  -  
DA  - 2025///
PY  - 2025
ID  - 10.1145/3713043
PB  - Association for Computing Machinery
SN  - 9798400714733
TI  - IDC '25: Proceedings of the 24th Interaction Design and Children
ER  - 
TY  - BOOK
CY  - Wellington, New Zealand
DA  - 2023///
PY  - 2023
ID  - 10.1145/3638380
PB  - Association for Computing Machinery
SN  - 9798400717079
TI  - OzCHI '23: Proceedings of the 35th Australian Computer-Human Interacti
on Conference
ER  - 
TY  - BOOK
CY  -  
DA  - 2024///
PY  - 2024
ID  - 10.1145/3700297
PB  - Association for Computing Machinery
SN  - 9798400707100
TI  - ISAIE '24: Proceedings of the 2024 International Symposium on Artifici
al Intelligence for Education
ER  - 
TY  - BOOK
CY  - Edinburgh, United Kingdom
DA  - 2023///
PY  - 2023
ID  - 10.1145/3597512
PB  - Association for Computing Machinery
SN  - 9798400707346
TI  - TAS '23: Proceedings of the First International Symposium on Trustwort
hy Autonomous Systems
ER  - 
TY  - BOOK
CY  - Athens, Greece
DA  - 2022///
PY  - 2022
ID  - 10.1145/3575879
PB  - Association for Computing Machinery
SN  - 9781450398541
TI  - PCI '22: Proceedings of the 26th Pan-Hellenic Conference on Informatic
s
ER  - 
TY  - BOOK
CY  - Sydney, NSW, Australia
DA  - 2023///
PY  - 2023
ID  - 10.1145/3610548
PB  - Association for Computing Machinery
SN  - 9798400703157
TI  - SA '23: SIGGRAPH Asia 2023 Conference Papers
ER  - 
TY  - BOOK
AB  - We are delighted to welcome you to Melbourne, Australia for ACM Multim
edia 2024, the 32nd ACM International Conference on Multimedia. ACM Mu
ltimedia is the premier international conference series in the area of
 multimedia within the field of computer science. Since 1993, ACM Mult
imedia has been bringing together worldwide researchers and practition
ers from academia and industry to present their innovative research an
d to discuss recent advancements in multimedia.For the first time sinc
e the end of the COVID-19 pandemic, this year's conference returns to 
the Asia-Pacific region and resumes as a full-fledged, inperson event.
 With no travel restrictions or significant visa challenges, we are ex
cited to once again experience the warmth of face-to-face gatherings, 
where we can reconnect with colleagues and friends.The enthusiasm and 
support from the community have been incredible. ACM Multimedia 2024 r
eceived over 4,300 main conference submissions, accepting more than 1,
100 papers (please refer to the TPC Chairs' message for details). In a
ddition, 10 Grand Challenges were selected from 22 submissions, 18 wor
kshops from 30 submissions, and 8 tutorials from 13 proposals. We've p
repared an exciting five-day program: workshops, grand challenges, and
 tutorials will be held on the 1st and 5th days, with the main confere
nce occupying the middle three days. All accepted papers will be acces
sible online prior to the conference, and we are working to ensure pro
ceedings are available through the ACM Digital Library around the conf
erence period.This year's conference features three distinguished acad
emic keynote speeches, several prestigious SIGMM award talks, a panel 
discussion on Generative AI in Multimedia, a refreshed Brave New Idea 
(BNI) session, and our inaugural industry program.The opening keynote 
will be delivered by Prof. Pascale Fung from HKUST, a Fellow of AAAI, 
ACL, and IEEE. Her talk will explore the pressing topic of Agents in t
he Large Language Model (LLM) Era. Prof. Judy Kay from the University 
of Sydney, a renowned expert in HCI, user modeling, and ubiquitous com
puting, will give the second keynote on how to empower individuals to 
harness and control their multimodal data. The final academic keynote 
will be presented by Prof. Jiebo Luo from the University of Rochester,
 a Fellow of ACM, AAAI, IEEE, SPIE, and IAPR, as well as a member of A
cademia Europaea and the US National Academy of Inventors. He will dis
cuss leveraging LLMs as social multimedia analysis engines.This year, 
we continue using OpenReview to ensure an open and transparent review 
process. Thanks to the exceptional efforts of the technical program co
mmittee, every paper received at least three reviews before the review
 announcement. The BNI track has also revamped its review process to a
lign with the main conference, promoting visionary papers. Additionall
y, we are excited to introduce the industry program to ACM Multimedia 
for the first time, featuring industry keynote speeches, expert talks,
 and demonstrations (please refer to the industry chairs' message for 
further details).We are also committed to making the conference inclus
ive and accessible. To support students with financial constraints, we
 have awarded travel grants to at least 25 students from the ACM Multi
media 2024 budget, with an additional 20+ students receiving SIGMM tra
vel grants. Over 20 local students have also been recruited as volunte
ers, benefiting from complimentary registration. Furthermore, we have 
arranged childcare facilities to accommodate attendees with young chil
dren. A welcome reception will take place on the 2nd day of the confer
ence, followed by a gala dinner on the 3rd day, featuring exciting cul
tural performances.We hope you find this year's program engaging and t
hought-provoking and that it offers valuable opportunities to exchange
 ideas with fellow researchers and practitioners from around the globe
. We also encourage you to take time to explore the beautiful city of 
Melbourne and its surrounding regions.
CY  - Melbourne VIC, Australia
DA  - 2024///
PY  - 2024
ID  - 10.1145/3664647
PB  - Association for Computing Machinery
SN  - 9798400706868
TI  - MM '24: Proceedings of the 32nd ACM International Conference on Multim
edia
ER  - 
TY  - BOOK
CY  - Taipei, Taiwan
DA  - 2024///
PY  - 2024
ID  - 10.1145/3657054
PB  - Association for Computing Machinery
SN  - 9798400709883
TI  - dg.o '24: Proceedings of the 25th Annual International Conference on D
igital Government Research
ER  - 
TY  - BOOK
CY  - Kyoto, Japan
DA  - 2024///
PY  - 2024
ID  - 10.1145/3636555
PB  - Association for Computing Machinery
SN  - 9798400716188
TI  - LAK '24: Proceedings of the 14th Learning Analytics and Knowledge Conf
erence
ER  - 
TY  - BOOK
AB  - Welcome to ACM SenSys 2022, the 20th ACM Conference on Embedded Networ
ked Sensor Systems, the premier computer systems conference focused on
 networked sensing systems and applications.
CY  - Boston, Massachusetts
DA  - 2022///
PY  - 2022
ID  - 10.1145/3560905
PB  - Association for Computing Machinery
SN  - 9781450398862
TI  - SenSys '22: Proceedings of the 20th ACM Conference on Embedded Network
ed Sensor Systems
ER  - 