"title";"abstract";"cleaned_year";"author";"source";"link"
"HoloBots: Augmenting holographic telepresence with mobile robots for tangible remote collaboration in mixed reality";"This paper introduces HoloBots, a mixed reality remote collaboration system that augments holographic telepresence with synchronized mobile robots. Beyond existing mixed reality telepresence, HoloBots lets remote users not only be visually and spatially present, but also physically engage with local users and their environment. HoloBots allows the users to touch, grasp, manipulate, and interact with the remote physical environment as if they were co-located in the same shared space. We achieve this by synchronizing holographic user motion (Hololens 2 and Azure Kinect) with tabletop mobile robots (Sony Toio). Beyond the existing physical telepresence, HoloBots contributes to an exploration of broader design space, such as object actuation, virtual hand physicalization, world-in-miniature exploration, shared tangible interfaces, embodied guidance, and haptic communication. We evaluate our system with twelve participants by comparing it with hologram-only and robot-only conditions. Both quantitative and qualitative results confirm that our system significantly enhances the level of co-presence and shared experience, compared to the other conditions.";"2023";"Ihara, Keiichi and Faridan, Mehrad and Ichikawa, Ayumi and Kawaguchi, Ikkaku and Suzuki, Ryo";"Proceedings of the 36th annual ACM symposium on user interface software and technology";"https://doi.org/10.1145/3586183.3606727"
"A haptic-enabled, distributed and networked immersive system for multi-user collaborative virtual reality";"Virtual Reality (VR) is gaining attention in various domains such as entertainment, industry, mental healthcare and VR training. Al- though most of these use-cases are still limited to single-user tasks, a lot of applications are heavily depending on multi-user collaboration. Existing multi-user VR systems are most often created in a classic server-client architecture, however, which induces unpredictable network behaviour which can affect the end-user's Quality-of-Experience (QoE) and performance. In addition, the interaction methods in these systems are often constrained to either traditional VR controllers or very use-case specific interaction methods, such that general purpose haptic gloves form a somewhat under-explored part of literature. Therefore, we (i) present a networked, distributed multi-user VR system with synchronization of environments over a low-bandwidth networked connection. In addition, we (ii) enhance the experience by adding haptic gloves to the system, which we compare to the traditional VR controllers in a subjective experiment. As a proof-of-concept, a use case is implemented in which two users have to prepare and bake a virtual pizza. The results show that high framerates (&gt; 90 Frames Per Second (FPS)) can be obtained while keeping network throughput to a minimum ( &lt; 1 Mbps). The accompanying user study shows that haptic gloves are preferred when immersiveness is the main emphasis of the virtual environment, while controllers are more suited when performance is in the center of attention. In objective terms, the applicability of haptic feedback is highly dependent on the task at hand.";"2023";"Van Damme, Sam and Van de Velde, Fangio and Sameri, Mohammad Javad and De Turck, Filip and Vega, Maria Torres";"Proceedings of the 2nd international workshop on interactive extended reality";"https://doi.org/10.1145/3607546.3616804"
"HexTouch: Affective robot touch for complementary interactions to companion agents in virtual reality";"There is a growing need for social interaction in Virtual Reality (VR). Current social VR applications enable human-agent or interpersonal communication, usually by means of visual and audio cues. Touch, which is also an essential method for affective communication, has not received as much attention. To address this, we introduce HexTouch, a forearm-mounted robot that performs touch behaviors in sync with the behaviors of a companion agent, to complement visual and auditory feedback in virtual reality. The robot consists of four robotic tactors driven by servo motors, which render specific tactile patterns to communicate primary emotions (fear, happiness, disgust, anger, and sympathy). We demonstrate HexTouch through a VR game with physical-virtual agent interactions that facilitate the player-companion relationship and increase the immersion of the VR experience. The player will receive affective haptic cues while collaborating with the agent to complete the mission in the game. The multisensory system for affective communication also has the potential to enhance sociality in the virtual world.";"2020";"Zhou, Ran and Wu, Yanzhe and Sareen, Harpreet";"Proceedings of the 26th ACM symposium on virtual reality software and technology";"https://doi.org/10.1145/3385956.3422100"
"Citizen-centered design in urban planning: How augmented reality can be used in citizen participation processes";"Most participation processes in urban planning offer poor incentives, especially for young citizens, hence important citizen's needs are excluded. Our work aims at identifying the degree to which Augmented Reality (AR) might motivate young people. We developed an AR-app with Unity3D to create new interaction concepts for use cases in urban planning. Building projects and environment changes are visualized, so citizens can contribute design ideas to the process. Using a human-centered design approach, we invited different stakeholders to participate. We conducted 40 interviews and a survey, then interaction concepts were evolved by citizens in four participatory design workshops. Our findings show that AR can motivate increased participation in urban planning. We also demonstrate a new approach to engaging low-tech users in designing high-tech solutions such as AR systems by using haptic 3D-tools like Lego or clay. Furthermore, we propose ways in which AR could be used collaboratively and embedded in existing participation processes.";"2021";"Saßmannshausen, Sheree May and Radtke, Jörg and Bohn, Nino and Hussein, Hassan and Randall, Dave and Pipek, Volkmar";"Proceedings of the 2021 ACM designing interactive systems conference";"https://doi.org/10.1145/3461778.3462130"
"I’m in control! Transferring object ownership between remote users with haptic props in virtual reality";"Virtual Reality (VR) remote collaboration is becoming more and more relevant in a wide range of scenarios, such as remote assistance or group work. A way to enhance the user experience is using haptic props that make virtual objects graspable. But physical objects are only present in one location and cannot be manipulated directly by remote users. We explore different strategies to handle ownership of virtual objects enhanced by haptic props. In particular, two strategies of handling object ownership – SingleOwnership and SharedOwnership. SingleOwnership restricts virtual objects to local haptic props, while SharedOwnership allows collaborators to take over ownership of virtual objects using local haptic props. We study both strategies for a collaborative puzzle task regarding their influence on performance and user behavior. Our findings show that SingleOwnership increases communication and enhanced with virtual instructions, results in higher task completion times. SharedOwnership is less reliant on verbal communication and faster, but there is less social interaction between the collaborators.";"2021";"Auda, Jonas and Busse, Leon and Pfeuffer, Ken and Gruenefeld, Uwe and Rivu, Radiah and Alt, Florian and Schneegass, Stefan";"Proceedings of the 2021 ACM symposium on spatial user interaction";"https://doi.org/10.1145/3485279.3485287"
"HexTouch: a wearable haptic robot for complementary interactions to companion agents in virtual reality";"We propose a forearm-mounted robot that performs complementary touches in relation to the behaviors of a companion agent in virtual reality (VR). The robot consists of a series of tactors driven by servo motors that render specific tactile patterns to communicate primary emotions (fear, happiness, disgust, anger, and sympathy) and other notification cues. We showcase this through a VR game with physical-virtual agent interactions that facilitate the player-companion relationship and increase user immersion in specific scenarios. The player collaborates with the agent to complete a mission while receiving affective haptic cues with the potential to enhance sociality in the virtual world.";"2020";"Zhou, Ran and Wu, Yanzhe and Sareen, Harpreet";"SIGGRAPH asia 2020 emerging technologies";"https://doi.org/10.1145/3415255.3422881"
"Development of MirrorShape: High fidelity large-scale shape rendering framework for virtual reality";"Today there is a high variety of haptic devices capable of providing tactile feedback. Although most of existing designs are aimed at realistic simulation of the surface properties, their capabilities are limited in attempts of displaying shape and position of virtual objects. This paper suggests a new concept of distributed haptic display for realistic interaction with virtual object of complex shape by a collaborative robot with shape display end-effector. MirrorShape renders the 3D object in virtual reality (VR) system by contacting the user hands with the robot end-effector at the calculated point in real-time. Our proposed system makes it possible to synchronously merge the position of contact point in VR and end-effector in real world. This feature provides presentation of different shapes, and at the same time expands the working area comparing to desktop solutions. The preliminary user study revealed that MirrorShape was effective at reducing positional error in VR interactions. Potentially this approach can be used in the virtual systems for rendering versatile VR objects with wide range of sizes with high fidelity large-scale shape experience.";"2019";"Fedoseev, Aleksey and Chernyadev, Nikita and Tsetserukou, Dzmitry";"Proceedings of the 25th ACM symposium on virtual reality software and technology";"https://doi.org/10.1145/3359996.3365049"
"Towards bare-hand interaction for whiteboard collaboration in virtual reality";"Whiteboard collaboration in virtual reality (VR) is an important task in collaborative virtual environments. The current research mainly relies on the use of controllers or dedicated pens but additional devices will cause inconvenience to users. Bare-hand writing offers rich collaborative semantics through natural gestures but remains underexplored. This paper addresses challenges and solutions for bare-hand whiteboard collaboration. We analyze the input process and identify key challenges in determining pen-drop, writing, and pen-lift intentions while maintaining user control over their avatar. Our approach addresses two VR scenarios: one without and one with physical planes. The method for the first case is called Air-writing, which dynamically adjusts the distance between the avatar's torso and the virtual whiteboard during the processes of pen-drop and pen-lift to ensure a consistent writing experience in VR. The method for the second case is called Physical-writing, which allows users to write smoothly with passive haptic feedback and physical constraints provided by the real surface by remapping the whiteboard in VR with a plane in reality. A comprehensive user study is conducted to evaluate communication efficiency, input accuracy, collaboration efficiency, and user experience of the two methods. The experimental results indicate that bare-hand interaction improves communication efficiency by 8";"2025";"Liu, Guangtian and Su, Haonan and Wang, Jingyu and Qi, Qi and Sun, Haifeng and Zhuang, Zirui and Ren, Pengfei and Liao, Jianxin";"Proc. ACM Hum.-Comput. Interact.";"https://doi.org/10.1145/3711092"
"Zenbu Koko - A mixed reality platform for inward contemplation";"We present the first showcase of Zenbu Koko, a XR meditation platform, developed by All Here and designed in collaboration with Kengo Kuma and Associates. This platform presents a 5 minute immersive experience that guides participants on a journey focused on self-awareness and inner sensations. It features immersive visuals and audio, meditation guidance, haptic feedback, and a tool for reconstructing and displaying participants’ bodies in virtual environments using depth sensor cameras. Originally conceived as a project bridging neuroscience and meditation, this platform has been accepted for a talk presentation at SIGGRAPH Denver in 2024. We aim to provide a first public demonstration here.";"2024";"Vuarnesson, Loup and Nelson, Richard David and Bek, Erkin";"SIGGRAPH asia 2024 XR";"https://doi.org/10.1145/3681759.3688915"
"ColabAR: a toolkit for remote collaboration in tangible augmented reality laboratories";"Current times are accelerating new technologies to provide high-quality education for remote collaboration, as well as hands-on learning. This is particularly important in the case of laboratory-based classes, which play an essential role in STEM education. In this paper, we introduce ColabAR, a toolkit that uses physical proxies to manipulate virtual objects in Tangible Augmented Reality (TAR) laboratories. ColabAR introduces haptic-based customizable interaction techniques to promote remote collaboration between students. Our toolkit provides hardware and software that enable haptic feedback to improve user experience and promote collaboration during learning. Also, we present the architecture of our cloud platform for haptic interaction that supports information sharing between students in a TAR laboratory. We performed two user studies (N=40) to test the effect of our toolkit in enriching local and remote collaborative experiences. Finally, we demonstrated that our TAR laboratory enables students' performance (i.e., lab completion rate, lab scores) to be similar to their performance in an in-person laboratory.";"2022";"Villanueva, Ana and Zhu, Zhengzhe and Liu, Ziyi and Wang, Feiyang and Chidambaram, Subramanian and Ramani, Karthik";"Proc. ACM Hum.-Comput. Interact.";"https://doi.org/10.1145/3512928"
"PhyShare: Sharing physical interaction in virtual reality";"We present PhyShare, a new haptic user interface based on actuated robots. Virtual reality has recently been gaining wide adoption, and an effective haptic feedback in these scenarios can strongly support user's sensory in bridging virtual and physical world. Since participants do not directly observe these robotic proxies, we investigate the multiple mappings between physical robots and virtual proxies that can utilize the resources needed to provide a well rounded VR experience. PhyShare bots can act either as directly touchable objects or invisible carriers of physical objects, depending on different scenarios. They also support distributed collaboration, allowing remotely located VR collaborators to share the same physical feedback.";"2017";"He, Zhenyi and Zhu, Fengyuan and Perlin, Ken";"Adjunct proceedings of the 30th annual ACM symposium on user interface software and technology";"https://doi.org/10.1145/3131785.3131795"
"ShareHaptics: a modular haptic feedback system using shape memory alloy for mixed reality shared space applications";"We present ShareHaptics, a novel modular system to provide tactile and pressure feedback in mixed reality applications using a novel actuator: shape memory alloy (SMA). We apply it to fingers, wrist and foot ankle. Although it can be used for haptic feedback in a diverse set of use cases, we specifically focus on collaborative applications: ShareHaptics allows to haptically jack-in to a remote environment via a custom glove and ankle braces. We demonstrate a wide range of applications: watching sports, gaming, and collaborative discussions and skill transfer.";"2019";"Nakao, Takuro and Santana, Stevanus Kevin and Isogai, Megumi and Shimizu, Shinya and Kimata, Hideaki and Kunze, Kai and Pai, Yun Suen";"ACM SIGGRAPH 2019 posters";"https://doi.org/10.1145/3306214.3338597"
"INC-hg: An intelligent collaborative haptic-gripper virtual reality system";"Collaborative Virtual Environments (CVE) have shown potential to be an effective social skill training platform for children with Autism Spectrum Disorders (ASD) to learn and practice collaborative and communication skills through peer interactions. However, most existing CVE systems require that appropriately matched partners be available at the same time to promote interaction, which limits their applicability to some community settings due to scheduling constraints. A second shortcoming of these more naturalistic peer-based designs is the intensive resources required to manually code the unrestricted conversations that occurred during the peer-based interactions. To preserve the benefits of CVE-based platforms and mitigate some of the resource limitations related to peer availability, we developed an Intelligent Collaborative Haptic-Gripper System (INC-Hg). This system provides an intelligent agent partner who can understand, communicate, and haptically interact with the user, without requiring the presence of another human peer. The INC-Hg operates in real time and thus is able to perform collaborative training tasks at any time and at the user's pace. INC-Hg can also record the real-time data regarding spoken language and task performance, thereby greatly reducing the resource burden of communication and interaction performance analysis. A preliminary usability study with 10 participants with ASD (ages 8–12 years) indicated that the system could classify the participant's utterances into five classes with an accuracy of 70.34";"2022";"Zhao, Huan and Zaini Amat, Ashwaq and Migovich, Miroslava and Swanson, Amy and Weitlauf, Amy S. and Warren, Zachary and Sarkar, Nilanjan";"ACM Trans. Access. Comput.";"https://doi.org/10.1145/3487606"
"Neural functional analysis in virtual reality simulation: example of a human-robot collaboration tasks";"Human-robot collaboration has gained its popularity with the fast evolution of the Industry 4.0. One of the challenges of HRC is human-robot interface design that adapts to the personalized needs. This paper presents a method of using Virtual Reality (VR) simulation as a testbed and data collector for examining and modeling personal reactions to different human-robot interface designs. To obtain real-time leading indicator of human performance, this study focuses on the neural functional analysis in VR. An integrated system is presented using eye-tracking and force input data as event makers for Neuroimaging technique, i.e., Functional Near Infrared Spectroscopy (fNIRS). The real-time hemodynamic responses in subjects' brains are analyzed based on the general linear model (GLM) for modeling neural functional changes under different levels of haptic designs. Our results indicate that the neurobehavioral data collected from the VR environment can be used directly as a personalized model for human-robot interface optimization.";"2021";"Zhu, Qi and Du, Jing";"2020 Winter Simulation Conference (WSC)";"https://doi.org/10.1109/WSC48552.2020.9384065"
"Investigating a combination of input modalities, canvas geometries, and inking triggers on on-air handwriting in virtual reality";"Humans communicate by writing, often taking notes that assist thinking. With the growing popularity of collaborative Virtual Reality (VR) applications, it is imperative that we better understand aspects that affect writing in these virtual experiences. On-air writing in VR is a popular writing paradigm due to its simplicity in implementation without any explicit needs for specialized hardware. A host of factors can affect the efficacy of this writing paradigm and in this work, we delved into investigating the same. Along these lines, we investigated the effects of a combination of factors on users’ on-air writing performance, aiming to understand the circumstances under which users can both effectively and efficiently write in VR. We were interested in studying the effects of the following factors: (1) input modality: brush vs. near-field raycast vs. pointing gesture, (2) inking trigger method: haptic feedback vs. button based trigger, and (3) canvas geometry: plane vs. hemisphere. To evaluate the writing performance, we conducted an empirical evaluation with thirty participants, requiring them to write the words we indicated under different combinations of these factors. Dependent measures including the writing speed, accuracy rates, perceived workloads, and so on, were analyzed. Results revealed that the brush based input modality produced the best results in writing performance, that haptic feedback was not always effective over button based triggering, and that there are trade-offs associated with the different types of canvas geometries used. This work attempts at laying a foundation for future investigations that seek to understand and further improve the on-air writing experience in immersive virtual environments.";"2022";"Venkatakrishnan, Roshan and Venkatakrishnan, Rohith and Chung, Chih-Han and Wang, Yu-Shuen and Babu, Sabarish";"ACM Trans. Appl. Percept.";"https://doi.org/10.1145/3560817"
"Pain distraction for children through VR- or audio-haptic soundscapes in situ";"In this pilot study we compare two prototype applications developed in collaboration with Rigshospitalet, the main hospital in Denmark, aimed to evaluate the effectiveness of a virtual reality (VR)- versus an audio-haptic based solution, as a pain distraction tool for children aged 5 to 8 during needle-related medical procedures. Both prototypes were developed with a narrative where children help a farmer find hidden animals. The final prototype underwent testing in situ, at Rigshospitalet’s clinic for blood tests. Here, participants’ pain levels were assessed using the Wong-Baker FACES Scale [9] and the Visual Analogue Scale [5]. Both prototypes saw participants report reduced pain perception, skewing more in favor of the VR prototype. However, the audio-haptic prototype showed similar levels of reduction in pain perception when effective. The study concludes that both VR- and audio-haptic based distraction are viable methods, that each cover a group’s needs within medical procedures involving young children (those who need to not see the procedure, and those who do), and that these should be further developed and implemented in said medical procedures.";"2023";"Bordum, Maya and Engberg, Emil and Hansen, Peter Blomsgård and Jensen, Nickolai Frederik Schouborg and Jægerlund, Martin Fritzbøger and Mouritzen, Jeppe Nygaard and Poulsen, Hannibal Hjelming and Ravnsborg, Lukas Gade and Rybak, Celine Zeh and Stappert, Frederik Hald and Troldahl, Bjørn and Winther, Julius Ebenau and Nordahl, Rolf";"Proceedings of the 29th ACM symposium on virtual reality software and technology";"https://doi.org/10.1145/3611659.3617220"
"Low-cost VR collaborative system equipped with haptic feedback";"In this paper, we present a low-cost virtual reality (VR) collaborative system equipped with a haptic feedback sensation system. This system is composed of a Kinect sensor for bodies and gestures detection, a microcontroller and vibrators to simulate outside interactions, and smartphone powered cardboard, all of this are put into a network implemented with Unity 3D game engine.";"2018";"Benbelkacem, Samir and Bellarbi, Abdelkader and Zenati-Henda, Nadia and Bentaleb, Ahmed and Bellabaci, Ahmed Nazim and Otmane, Samir";"Proceedings of the 24th ACM symposium on virtual reality software and technology";"https://doi.org/10.1145/3281505.3281615"
"Visuo-haptic collaborative augmented reality ping-pong";"In our current work we examine the development of visuohaptic augmented reality setups and their extension to collaborative experiences in entertainment settings. To this end, an expandable system architecture supporting multiple users is one of the most indispensable prerequisites. In addition, system stability, low latency, accurate calibration and stable overlay of the virtual objects have to be assured. In this paper we provide an overview of our framework and present our collaborative example application, an augmented reality visuo-haptic ping-pong game for two players. The users play with a virtual ball in a real environmentwhile, by using virtual bats colocated with haptic devices, they are able to feel the impact of the simulated ball on the bat.";"2007";"Knoerlein, Benjamin and Székely, Gábor and Harders, Matthias";"Proceedings of the international conference on advances in computer entertainment technology";"https://doi.org/10.1145/1255047.1255065"
"Haptic collaboration with augmented reality";"We describe a (face-to-face) collaborative environment that provides a coherent mix of real world video, computer haptics, graphics and audio. This system is a test-bed for investigating new collaborative affordances and behaviours.";"2004";"Adcock, Matt and Hutchins, Matthew and Gunn, Chris";"ACM SIGGRAPH 2004 posters";"https://doi.org/10.1145/1186415.1186463"
"Demonstrating HapticBots: Distributed encountered-type haptics for VR with multiple shape-changing mobile robots";"HapticBots introduces a novel encountered-type haptic approach for Virtual Reality (VR) based on multiple tabletop-size shape-changing robots. These robots move on a tabletop and change their height and orientation to haptically render various surfaces and objects on-demand. Compared to previous encountered-type haptic approaches like shape displays or robotic arms, our proposed approach has an advantage in deployability, scalability, and generalizability—these robots can be easily deployed due to their compact form factor. They can support multiple concurrent touch points in a large area thanks to the distributed nature of the robots. We propose and evaluate a novel set of interactions enabled by these robots which include: 1) rendering haptics for VR objects by providing just-in-time touch-points on the user’s hand, 2) simulating continuous surfaces with the concurrent height and position change, and 3) enabling the user to pick up and move VR objects through graspable proxy objects. Finally, we demonstrate HapticBots with various applications, including remote collaboration, education and training, design and 3D modeling, and gaming and entertainment.";"2021";"Suzuki, Ryo and Ofek, Eyal and Sinclair, Mike and Leithinger, Daniel and Gonzalez-Franco, Mar";"Adjunct proceedings of the 34th annual ACM symposium on user interface software and technology";"https://doi.org/10.1145/3474349.3480202"
"Haptic network protocols: a comprehensive review and directions for next-gen metaverse applications";"This paper presents a systematic review of haptic network protocols, in the context of the Metaverse. With the increasing integration of haptic technologies into applications like remote collaboration and robotic surgery, the need for reliable, low-latency data transmission has intensified. This work provides a comprehensive analysis of existing haptic protocols and frameworks, focusing on their development, implementation, and the methods employed to optimize Quality of Service (QoS) parameters such as latency, delay, packet loss, jitter, throughput, and bandwidth. By examining the strengths and limitations of these protocols in real-time applications, this paper identifies critical areas for improvement and suggests future directions, including the potential for incorporating machine learning (ML) and artificial intelligence (AI) to enable next-generation haptic communication suited for high-demand environments like the Metaverse.";"2025";"Faisal, Mohd and Martinez-Velazquez, Roberto Alejandro and Laamarti, Fedwa and Al Osman, Hussein and El Saddik, Abdulmotaleb";"ACM Trans. Multimedia Comput. Commun. Appl.";"https://doi.org/10.1145/3759459"
"Sustainable haptic design: Improving collaboration, sharing, and reuse in haptic design research";"Haptic devices have been around for decades, providing critical information, usability benefits and improved experiences across tasks from surgical operations to playful applications in Mixed Reality. We see more and more software and hardware solutions emerging that provide design tools, design approaches and platforms, both in academia and industry. However, we believe that designers often re-invent the wheel, and must spend an inordinate amount of time doing their work, which is not sustainable for long-term research. This workshop aims at gathering people from academia and industry to provide a common ground to discuss various insights on and visions of the field. We aim to bring together the various strands of haptics—devices, software, and design—to assess the current state-of-the-art and propose an agenda towards haptics as a united design discipline. We expect the outcome of the workshop to be a comprehensive overview of existing tools and approaches, along with recommendations on how to move the field forward, together.";"2022";"Schneider, Oliver and Fruchard, Bruno and Wittchen, Dennis and Joshi, Bibhushan Raj and Freitag, Georg and Degraen, Donald and Strohmeier, Paul";"Extended abstracts of the 2022 CHI conference on human factors in computing systems";"https://doi.org/10.1145/3491101.3503734"
"A wearable smart glove for tactile interaction";"Haptic interaction plays an indispensable role in human-computer interaction. By simulating tactile sensations and providing vivid tactile feedbacks, it enriches the interaction experience between users and digital interfaces. We designed a wearable haptic interaction glove that utilizes a dual-layer cooperative conductive structure of flexible resistive bending sensors to detect the degree of finger flexion, combined with a vibratory tactile actuator array to deliver tactile feedback. To enhance the effectiveness of tactile interaction delivery, we encoded tactile feedback based on vibration frequency, intensity, and duration, and designed a virtual scenario simulating the opening of a spacecraft door. Our glove showed its potential as a low-cost and advanced solution for human-computer interaction, with significant prospects in remote operation, rehabilitation medicine, and virtual reality applications.";"2024";"Zhu, Jiahang and Song, Aiguo and Shang, Ke and Wei, Zhikai";"Proceedings of the 2024 4th international conference on robotics and control engineering";"https://doi.org/10.1145/3674746.3674771"
"HapticPuppet: a kinesthetic mid-air multidirectional force-feedback drone-based interface";"Providing kinesthetic force-feedback for human-scale interactions is challenging due to the relatively large forces needed. Therefore, robotic actuators are predominantly used to deliver this kind of haptic feedback; however, they offer limited flexibility and spatial resolution. In this work, we introduce HapticPuppet, a drone-based force-feedback interface which can exert multidirectional forces onto the human body. This can be achieved by attaching strings to different parts of the human body such as fingers, hands or ankles, which can then be affixed to multiple coordinated drones - puppeteering the user. HapticPuppet opens up a wide range of potential applications in virtual, augmented and mixed reality, exercising, physiotherapy, remote collaboration as well as haptic guidance.";"2022";"Feick, Martin and Tang, Anthony and Krüger, Antonio";"Adjunct proceedings of the 35th annual ACM symposium on user interface software and technology";"https://doi.org/10.1145/3526114.3558694"
"Collaborative experience prototyping of automotive interior in VR with 3D sketching and haptic helpers";"Technological advances and socioeconomic disruptions such as self-driving cars, car-sharing services and artificial intelligence assistance may fundamentally alter interactions inside the future car. However, existing design tools and processes geared toward static physical authoring are ill-equipped for such interaction design. We propose a new design workflow that combines experience prototyping methods typically used by the user interface and product design communities with 3D sketching and haptic helper techniques to help automotive designers ideate, prototype, experience and evaluate multi-sensory interactions in a collaborative manner. Using our workflow, designers use 3D sketching to quickly and expressively author 3D shape and motion ideas in space; augment them with tactile and other sensory feedback through physical proxies and other available gadgets; and immediately enact and immersively experience them to progressively explore and develop them.";"2017";"An, Sang-Gyun and Kim, Yongkwan and Lee, Joon Hyub and Bae, Seok-Hyung";"Proceedings of the 9th international conference on automotive user interfaces and interactive vehicular applications";"https://doi.org/10.1145/3122986.3123002"
"HapticBots: Distributed encountered-type haptics for VR with multiple shape-changing mobile robots";"HapticBots introduces a novel encountered-type haptic approach for Virtual Reality (VR) based on multiple tabletop-size shape-changing robots. These robots move on a tabletop and change their height and orientation to haptically render various surfaces and objects on-demand. Compared to previous encountered-type haptic approaches like shape displays or robotic arms, our proposed approach has an advantage in deployability, scalability, and generalizability—these robots can be easily deployed due to their compact form factor. They can support multiple concurrent touch points in a large area thanks to the distributed nature of the robots. We propose and evaluate a novel set of interactions enabled by these robots which include: 1) rendering haptics for VR objects by providing just-in-time touch-points on the user’s hand, 2) simulating continuous surfaces with the concurrent height and position change, and 3) enabling the user to pick up and move VR objects through graspable proxy objects. Finally, we demonstrate HapticBots with various applications, including remote collaboration, education and training, design and 3D modeling, and gaming and entertainment.";"2021";"Suzuki, Ryo and Ofek, Eyal and Sinclair, Mike and Leithinger, Daniel and Gonzalez-Franco, Mar";"The 34th annual ACM symposium on user interface software and technology";"https://doi.org/10.1145/3472749.3474821"
"Haptic enhancements for collaborative scenarios in virtual environment";NA;"2003";"Daly, Jason and Washburn, Don and Lazarus, Todd and Reeder, John and Martin, Glenn A.";"ACM SIGGRAPH 2003 sketches &amp; applications";"https://doi.org/10.1145/965400.965496"
"A platform for bimanual virtual assembly training with haptic feedback in large multi-object environments";"We present a virtual reality platform which addresses and integrates some of the currently challenging research topics in the field of virtual assembly: realistic and practical scenarios with several complex geometries, bimanual six-DoF haptic interaction for hands and arms, and intuitive navigation in large workspaces. We put an especial focus on our collision computation framework, which is able to display stiff and stable forces in 1 kHz using a combination of penalty- and constraint-based haptic rendering methods. Interaction with multiple arbitrary geometries is supported in realtime simulations, as well as several interfaces, allowing for collaborative training experiences. Performance results for an exemplary car assembly sequence which show the readiness of the system are provided.";"2016";"Sagardia, Mikel and Hulin, Thomas and Hertkorn, Katharina and Kremer, Philipp and Schätzle, Simon";"Proceedings of the 22nd ACM conference on virtual reality software and technology";"https://doi.org/10.1145/2993369.2993386"
"Modeling the effects of delayed haptic and visual feedback in a collaborative virtual environment";"Collaborative virtual environments (CVEs) enable two or more people, separated in the real world, to share the same virtual “space.” They can be used for many purposes, from teleconferencing to training people to perform assembly tasks. Unfortunately, the effectiveness of CVEs is compromised by one major problem: the delay that exists in the networks linking users together. Whilst we have a good understanding, especially in the visual modality, of how users are affected by delayed feedback from their own actions, little research has systematically examined how users are affected by delayed feedback from other people, particularly in environments that support haptic (force) feedback. The current study addresses this issue by quantifying how increasing levels of latency affect visual and haptic feedback in a collaborative target acquisition task. Our results demonstrate that haptic feedback in particular is very sensitive to low levels of delay. Whilst latency affects visual feedback from 50 ms, it impacts on haptic task performance 25 ms earlier, and causes the haptic measures of performance deterioration to rise far more steeply than visual. The “impact-perceive-adapt” model of user performance, which considers the interaction between performance measures, perception of latency, and the breakdown of perception of immediate causality, is proposed as an explanation for the observed pattern of performance.";"2007";"Jay, Caroline and Glencross, Mashhuda and Hubbold, Roger";"ACM Trans. Comput.-Hum. Interact.";"https://doi.org/10.1145/1275511.1275514"
"Revealing the realities of collaborative virtual reality";"We look at differences between the experience of virtual environments and physical reality, and consider making the technical limitations which cause these differences 'visible', aiming to provide resources to enhance communication between users. Three causes of such discrepancies are considered to illustrate this idea: field-of-view; haptic feedback; and network delays. For each, we examine ways of revealing the limitations of the virtual world as resources to better understand the intricacies of system and co-user behaviour. These examples introduce a broader discussion of design issues involved in producing interfaces for day-to-day collaboration through virtual environments. Issues include: the application and activity undertaken through the virtual world; the ability to focus on the business at hand rather than the system in use; and extent of users' familiarity with application and system.";"2000";"Fraser, Mike and Glover, Tony and Vaghi, Ivan and Benford, Steve and Greenhalgh, Chris and Hindmarsh, Jon and Heath, Christian";"Proceedings of the third international conference on collaborative virtual environments";"https://doi.org/10.1145/351006.351010"
"Collaborative hands-on training on haptic simulators";"Medical trainees are required to acquire sufficient skills before touching a real patient. Nowadays, haptic simulators provide an effective solution but they do not facilitate an active supervision by a trainer who should show the right gestures in terms of motions and forces to apply, in the simulated environment. Dual user training systems aim at this purpose. Even though they permit a cooperative training, they generally dot not enable efficient demonstration/evaluation modes where the user who observes the person performing a manipulation is also able to feel the interaction forces, not only the motion. We earlier introduced the Energy Shared Control (ESC) architecture aiming at providing the latter function. It is modeled with the Port Hamiltonian framework and it embeds a Time Domain Passivity Controller, to compose a one degree-of-freedom (dof) dual-user haptic system for hands-on training. In this paper, we extend it to three dof with three identical haptic devices. Experiments bring information about its performance.";"2019";"Licona R., Angel R. and Liu, Fei and Lelevé, Arnaud and Pham, Minh Tu";"Proceedings of the 2019 3rd international conference on virtual and augmented reality simulations";"https://doi.org/10.1145/3332305.3332318"
"Groovy assignment: the VR ride: a cross disciplinary assignment in computer graphics and interactivity";"In this Groovy Assignment submission, we present a VR Ride assignment that challenges students to create a fully interactive VR computer graphics experience integrated with a themed ride. For this assignment, a ride is an apparatus that fully supports the users weight, utilizes the user's body motions as a primary input for computer interactivity, and provides haptic feedback relevant to the VR experience.The assignment is designed to inspire and motivate creative thinking and cross disciplinary collaboration with faculty and students from outside the scope of those traditionally involved in programs focused on computer graphics and interaction.The assignment can be easily scaled, by utilizing wholly existing, found or purchased platforms (exercise equipment such as a rowing machine or stationary bike) for use with small groups of students if desired. In the example presented, students from Electrical Engineering, Mechanical Engineering, Industrial Design, Game Design, VR &amp; Immersive Media, Animation &amp; VFX and Game Design programs collaborated using primarily found or recycled components to build a bespoke, human powered \"VR Cycle\" ride, integrated with original VR experiences developed for the ride.";"2019";"Jushchyshyn, Nick and Lloyd, Robert and Sundquist, Erik";"ACM SIGGRAPH 2019 educators forum";"https://doi.org/10.1145/3326542.3328018"
"Tangible construction kit for blind and partially sighted drawers: Co-designing a cross-sensory 3D interface with blind and partially sighted drawers during covid-19";"Drawing as an activity aids problem solving, collaboration, and presentation in design, science, and engineering and artistic creativity as well as expression in the arts. Unfortunately, blind, and partially sighted learners still lack an inclusive and effective drawing tool, even in the digital age. In response, this research aims to explore what an effective drawing tool for blind and partially sighted individuals (BPSI) would be. Raised-line drawing kits aim to provide this, but in prior work, our usability tests of raised line graphics with blind and partially sighted participants rated the raised line graphics that we tested as barely comprehensible relative to 3D models, which they rated as highly comprehensible. Semi-structured interviews with our participants afterward suggest that they found 3D models to be more comprehensible because these are consistent with haptic principles of perception whereas conventions of raised line graphics, such as a line representing a surface edge, replicate visual cues of source images and thereby violate haptic principles of perception. Therefore, we hypothesize that a drawing tool for blind and partially sighted drawers could be effective by recruiting affordances of 3D models. Through co-design sessions conducted during the Covid-19 pandemic with blind and partially sighted drawers (BPSD), we prototyped a tangible 3D model construction kit for non-visual haptic drawing with a digital interface to a 3D virtual environment. Our current investigation of user needs is informing us of our ongoing iterative development of an accessible 3D scanning application that is enabling blind and partially sighted individuals to build and scan in 3D models constructed from a more flexible range of materials beyond what was possible with our previous prototype.";"2022";"Kamat, Mitali and Uribe Quevedo, Alvaro and Coppin, Peter";"Proceedings of the sixteenth international conference on tangible, embedded, and embodied interaction";"https://doi.org/10.1145/3490149.3505580"
"Collaborative stretcher carrying: a case study";"This paper describes a simulation of a collaborative task in a shared virtual environment — two users carrying a shared object (a stretcher) in a complex chemical plant. The implementation includes a haptic interface for each user, so that forces transmitted through the stretcher from one user to the other can be experienced. Preliminary experiments show that the addition of haptic feedback significantly enhances the sense of sharing and each user's perception of the actions of the other user. The implementation is described, and some conclusions about the value of haptics, and plans for future work are given.";"2002";"Hubbold, Roger J.";"Proceedings of the workshop on virtual environments 2002";NA
"Gesture and audio-haptic guidance techniques to direct conversations with intelligent voice interfaces";"Advances in large language models (LLMs) empower new interactive capabilities for wearable voice interfaces, yet traditional voice-and-audio I/O techniques limit users’ ability to flexibly navigate information and manage timing for complex conversational tasks. We developed a suite of gesture and audio-haptic guidance techniques that enable users to control conversation flows and maintain awareness of possible future actions, while simultaneously contributing and receiving conversation content through voice and audio. A 14-participant exploratory study compared our parallelized I/O techniques to a baseline of voice-only interaction. The results demonstrate the efficiency of gestures and haptics for information access, while allowing system speech to be redirected and interrupted in a socially acceptable manner. The techniques also raised user awareness of how to leverage intelligent capabilities. Our findings inform design recommendations to facilitate role-based collaboration between multimodal I/O techniques and reduce users’ perception of time pressure when interleaving interactions with system speech.";"2025";"Rajaram, Shwetha and Surale, Hemant Bhaskar and McConkey, Codie and Rognon, Carine and Mehta, Hrim and Glueck, Michael and Collins, Christopher";"Proceedings of the 2025 CHI conference on human factors in computing systems";"https://doi.org/10.1145/3706598.3714310"
"Haptic exploration of remote environments with gesture-based collaborative guidance";"We present a collaborative haptic interaction method for exploring a remote physical environment with guidance from a distant helper. Spatial information, which is represented by a point cloud, of the remote environment is directly rendered as a contact force without reconstruction of surfaces. On top of this, the helper can selectively exert an attractive force for reaching a target or a repulsive force for avoiding a forbidden region to the user by using free-hand gestures.";"2016";"Kim, Seokyeol and Park, Jinah";"Proceedings of the 2016 symposium on spatial user interaction";"https://doi.org/10.1145/2983310.2989201"
"Haptic communication to enhance collaboration in virtual environments";"Motivation – To study haptic communication in collaborative virtual environments.Research approach – An experimental study was conducted, in which 60 students were asked to perform in dyads a shared manual task after a training period.Findings/Design – The results show that haptic communication can influence the common frame of reference development in a shared manual task.Research limitations/Implications – Deeper verbalization analyses are needed to evaluate the common frame of reference development.Originality/Value – This study highlights haptic interactions importance when designing virtual environment that support shared manual tasks.Take away message – Haptic communication, combined with visual and verbal communication, enriches interactions in collaborative virtual environments.";"2010";"Chellali, Amine and Dumas, Cédric and Milleville, Isabelle";"Proceedings of the 28th annual european conference on cognitive ergonomics";"https://doi.org/10.1145/1962300.1962319"
"Haptic collaboration: biomedical engineering meets digital design";"This talk presents results of ongoing research and educational collaboration between the School of Art + Design (SoA+D) and the Department of Biomedical Engineering (BME) at New Jersey Institute of Technology. This collaboration began when researchers from BME became aware of a series of projects by digital design students from SoA+D producing virtual games that interface with fabricated physical design prototypes with microcontrollers through the use of the Unity 3D game engine as an application hub to connect the virtual and real worlds. The BME researchers had developed a novel admittance-controlled haptic robotic exoskeleton for assisting the upper extremity motions of people with stroke and cerebral palsy and were seeking to integrate it with an engaging and challenging virtual environment that can retain a user's interest. The result is a user-controlled haptic manipulator that allows individuals with neurological impairment to be therapeutically assisted by the exoskeleton (BME) while haptically interacting with virtual objects in a 3-D animated environment (SoA+D). The talk also introduces a new cross-disciplinary educational approach employing expertise of both academic units.";"2015";"Narahara, Taro and Abbruzzese, Kevin M. and Foulds, Richard A.";"SIGGRAPH 2015: Studio";"https://doi.org/10.1145/2785585.2792520"
"Role negotiation in a haptic shared control framework";"Haptic shared control is a promising means for combining the best of human manual control with automatic control, keeping the human in the loop while avoiding automation pitfalls. In this study, we consider a situation in which both human and the automation system recognize an obstacle but choose different paths of avoidance. While the driver and automation have similar perceptions of the situation, the commands they issue are incompatible and their simple sum is most likely dangerous. To resolve this issue, this study is focused on exploring how roles (i.e. leader and follower) in a haptic collaboration can be negotiated and exchanged between the two partners. Specifically, we test the influence of the timing of cues to promote adoption of leader and follower roles in a shared control task. Preliminary results suggest that haptic feedback can enhance drivability and prevent accidents.";"2016";"Ghasemi, Amir H. and Johns, Mishel and Garber, Benjamin and Boehm, Paul and Jayakumar, Paramsothy and Ju, Wendy and Gillespie, R. Brent";"Adjunct proceedings of the 8th international conference on automotive user interfaces and interactive vehicular applications";"https://doi.org/10.1145/3004323.3004349"
"Supporting parent-child collaborative learning through haptic feedback displays";"Haptic feedback displays are an emerging technology that have the potential to enhance how children and their parents interact with and learn about science concepts. Yet, we know little about how to design haptic feedback applications for science learning or how children and their parents make use of these interactive features. This paper presents the design and evaluation of TCircuit, an application for a variable friction touch-screen display (i.e., Tanvas Tablet) that enables parent-child dyads to feel electric current flowing through a circuit diagram by touching the display. We describe results from a formative design study with 10 parent-child dyads that reveal which texture patterns and mappings are most appropriate for representing the concept of electrical current through haptic feedback. We also report results of a comparative study with 40 parent-child dyads in a museum setting. Our analysis shows that dyads in the haptic condition performed slightly better when predicting their answers to learning tasks. However, we found that haptic feedback introduced new complexities for how dyads perceived and discussed the exhibit content. We discuss the potential for haptic feedback displays to support science learning, particularly in collaborative settings, and design considerations for future systems.";"2019";"Beheshti, Elham and Borgos-Rodriguez, Katya and Piper, Anne Marie";"Proceedings of the 18th ACM international conference on interaction design and children";"https://doi.org/10.1145/3311927.3323137"
"Explicit task representation based on gesture interaction";"This paper describes the role and the use of an explicit task representation in applications where humans interact in non-traditional computer environments using gestures. The focus lies on training and assistance applications, where the objective of the training includes implicit knowledge, e.g., motor-skills. On the one hand, these applications require a clear and transparent description of what has to be done during the interaction, while, on the other hand, they are highly interactive and multimodal. Therefore, the human computer interaction becomes modelled from the top down as a collaboration in which each participant pursues their individual goal that is stipulated by a task. In a bottom up processing, gesture recognition determines the actions of the user by applying processing on the continuous data streams from the environment. The resulting gesture or action is interpreted as the user's intention and becomes evaluated during the collaboration, allowing the system to reason about how to best provide guidance at this point. A vertical prototype based on the combination of a haptic virtual environment and a knowledge-based reasoning system is discussed and the evolvement of the task-based collaboration becomes demonstrated.";"2006";"Müller-Tomfelde, Christian and Paris, Cécile";"Proceedings of the 2005 NICTA-hcsnet multimodal user interaction workshop - volume 57";NA
"What is happening behind the wall? Towards a better understanding of a hidden robot's intent by multimodal cues";"Research in human-robot collaboration explores aspects of using interaction modalities and their effect on human perception. Particular attention is paid to intent communication, which is essential for successful interaction and collaboration. This work investigates the effect of using audio, visual, and haptic feedback on intent communication in a human-robot collaboration task where the collaborators do not share a direct line of sight. A user study was conducted in virtual reality with 20 participants. Qualitative and quantitative feedback was collected from all participants. When compared with a baseline of no feedback given to the participants, results show that using visual feedback had a significant impact on task efficiency, user experience, and cognitive load. Audio feedback was slightly less impactful, while haptic feedback had a divisive effect. Multimodal feedback combining the three modalities showed the highest impact compared to the individual modalities, leading to the highest task efficiency and user experience, and the lowest cognitive load.";"2022";"Kassem, Khaled and Ungerböck, Tobias and Wintersberger, Philipp and Michahelles, Florian";"Proc. ACM Hum.-Comput. Interact.";"https://doi.org/10.1145/3546731"
"Demo: a multi-modal training environment for surgeons";"This demonstration presents the current state of an on-going team project at Simon Fraser University in developing a virtual environment for helping to train surgeons in performing laparoscopic surgery. In collaboration with surgeons, an initial set of training procedures has been developed. Our goal has been to develop procedures in each of several general categories, such as basic hand-eye coordination, single-handed and bi-manual approaches and dexterous manipulation. The environment is based on an effective data structure that offers fast graphics and physically based modeling of both rigid and deformable objects. In addition, the environment supports both 3D and 5D input devices and devices generating haptic feedback. The demonstration allows users to interact with a scene using a haptic device.";"2003";"Payandeh, Shahram and Dill, John and Wilson, Graham and Zhang, Hui and Shi, Lilong and Lomax, Alan and MacKenzie, Christine";"Proceedings of the 5th international conference on multimodal interfaces";"https://doi.org/10.1145/958432.958489"
"MMT+AVR: enabling collaboration in augmented virtuality/reality using ISO's MPEG media transport";"Augmented Reality (AR) and Augmented Virtuality (AV) systems have been used in various fields such as entertainment, broadcasting, gaming [1], etc. Collaborative AR or AV (CAR/CAV) systems are a special kind of such system in which the interaction happens through the exchange of multi-modal data between multiple users/sites. Multiple sensors capture the real objects and enable interaction with shared virtual objects in a customizable virtual environment. Haptic devices can be added to introduce force feedback when the virtual objects are manipulated. These applications are demanding in terms of network resources to support low latency media delivery and media source switching similar to broadcast applications. Enabling real time interaction with multiple modalities with high volume data requires an advanced media transport protocol that supports low latency media delivery and fast media source (channel) switching. To enable such collaboration over a stochastic network like the Internet requires a combination of technologies from data design, synchronization to real time media delivery. MPEG Media Transport (MMT) [ISO/IEC 23008-1] is a new standard suite of protocols designed to work with demanding, real-time interactive multimedia applications, typically in the context of one-to-one and one-to-many communication. In this paper, we identify the augmentations that are required for the many-to-many nature of CAR/CAV applications and propose MMT+AVR as a middle ware solution for use in CAV applications. Through an example CAV application implemented on top of MMT+AVR, we show how it provides efficient support for developing CAV applications with ease.";"2015";"Venkatraman, Karthik and Tian, Yuan and Raghuraman, Suraj and Prabhakaran, Balakrishnan and Nguyen, Nhut";"Proceedings of the 6th ACM multimedia systems conference";"https://doi.org/10.1145/2713168.2713170"
"The MADE-axis: a modular actuated device to embody the axis of a data dimension";"Tangible controls-especially sliders and rotary knobs-have been explored in a wide range of interactive applications for desktop and immersive environments. Studies have shown that they support greater precision and provide proprioceptive benefits, such as support for eyes-free interaction. However, such controls tend to be expressly designed for specific applications. We draw inspiration from a bespoke controller for immersive data visualisation, but decompose this design into a simple, wireless, composable unit featuring two actuated sliders and a rotary encoder. Through these controller units, we explore the interaction opportunities around actuated sliders; supporting precise selection, infinite scrolling, adaptive data representations, and rich haptic feedback; all within a mode-less interaction space. We demonstrate the controllers' use for simple, ad hoc desktop interaction,before moving on to more complex, multi-dimensional interactions in VR and AR. We show that the flexibility and composability of these actuated controllers provides an emergent design space which covers the range of interactive dynamics for visual analysis. In a user study involving pairs performing collaborative visual analysis tasks in mixed-reality, our participants were able to easily compose rich visualisations, make insights and discuss their findings.";"2021";"Smiley, Jim and Lee, Benjamin and Tandon, Siddhant and Cordeil, Maxime and Besançon, Lonni and Knibbe, Jarrod and Jenny, Bernhard and Dwyer, Tim";"Proc. ACM Hum.-Comput. Interact.";"https://doi.org/10.1145/3488546"
"Exploring feedback modality designs to improve young children's collaborative actions";"Tangible user interfaces offer the benefit of incorporating physical aspects in the interaction with digital systems, enriching how system information can be conveyed. We investigated how visual, haptic, and audio modalities influence young children’s joint actions. We used a design-based research method to design and develop a multi-sensory tangible device. Two kindergarten teachers and 31 children were involved in our design process. We tested the final prototype with 20 children aged 5-6 from three kindergartens. The main findings were: a)&nbsp;involving and getting approval from kindergarten teachers in the design process was essential; b)&nbsp;simultaneously providing visual and audio feedback might help improve children’s collaborative actions. Our study was an interdisciplinary research on human-computer interaction and children’s education, which contributed an empirical understanding of the factors influencing children collaboration and communication.";"2023";"Melniczuk, Amy and Vrapi, Egesa";"Proceedings of the 25th international conference on multimodal interaction";"https://doi.org/10.1145/3577190.3614140"
"Verbal communication during cooperative object manipulation";"Cooperation between multiple users in a virtual environment (VE) can take place at one of three levels, but it is only at the highest level that users can simultaneously interact with the same object. This paper describes a study in a straightforward real-world task (maneuvering a large object through a restricted space) was used to investigate object manipulation by pairs of participants in a VE, and focuses on the verbal communication that took place. This communication was analyzed using both categorizing and conversation analysis techniques. Of particular note was the sheer volume of communication that took place. One third of this was instructions from one participant to another of the locomotion and manipulation movements that they should make. Another quarter was general communication that was not directly related to performance of the experimental task, and often involved explicit statements of participants' actions or requests for clarification about what was happening. Further research is required to determine the extent to which haptic and auditory feedback reduce the need for inter-participant communication in collaborative tasks.";"2002";"Ruddle, Roy A. and Savage, Justin CD and Jones, Dylan M.";"Proceedings of the 4th international conference on collaborative virtual environments";"https://doi.org/10.1145/571878.571897"
"Pseudo-haptics interfaces for robotic teleoperation";"When remotely operating robotic systems, the situation awareness and the absence of the possibility of direct human touch in such a remote environment constitute major challenges in telerobotics. Haptic feedback has been playing an important role when people interact with remote environments (e.g., in robotic teleoperation) or provide more immersive experiences in virtual environments. Like haptic devices, pseudo-haptic techniques aim to simulate haptic sensations in human-computer interaction between real and remote or virtual worlds, by exploring multimodal feedback, mainly the visual, and the brain's capabilities and limitations, without needing a haptic device to be attached or applied to the body. The authors discuss the possibility of exploring pseudo-haptic techniques, notably combined multimodal techniques, to improve robotic teleoperation, in remote vehicle driving, object maneuvering, situation awareness, and collaborative tasks, which as per the best authors' knowledge has not been explored in the literature.";"2024";"Xavier, Rui and Silva, José Luı́s and Ventura, Rodrigo";"Companion of the 2024 ACM/IEEE international conference on human-robot interaction";"https://doi.org/10.1145/3610978.3640704"
"Visual immersive haptic rendering on the web";"We propose how to define complex geometry, appearance and tangible physical properties of the X3D and VRML objects using mathematical functions straight in the scene definition code or in loadable libraries. We can also touch and feel surfaces of X3D and VRML objects as well as convert them to solid tangible objects. We can define tangible density and force fields associated with standard and function-defined geometries. Since the function-defined models are small in size, it is possible to perform their collaborative interactive modifications with concurrent synchronous visualization at each client computer with any required level of detail. We illustrate this concept with several application examples based on our plug-in to X3D and VRML browser.";"2008";"Sourin, Alexei and Wei, Lei";"Proceedings of the 7th ACM SIGGRAPH international conference on virtual-reality continuum and its applications in industry";"https://doi.org/10.1145/1477862.1477890"
"Exploiting perception in high-fidelity virtual environments (Additional presentations from the 24th course are available on the citation page)";"The objective of this course is to provide an introduction to the issues that must be considered when building high-fidelity 3D engaging shared virtual environments. The principles of human perception guide important development of algorithms and techniques in collaboration, graphical, auditory, and haptic rendering. We aim to show how human perception is exploited to achieve realism in high fidelity environments within the constraints of available finite computational resources.In this course we address the challenges faced when building such high-fidelity engaging shared virtual environments, especially those that facilitate collaboration and intuitive interaction. We present real applications in which such high-fidelity is essential. With reference to these, we illustrate the significant need for the combination of high-fidelity graphics in real time, better modes of interaction, and appropriate collaboration strategies.After introducing the concept of high-fidelity virtual environments and why these convey important information to the user, we cover the main issues in two parts linked by the common thread of exploiting human perception. First we explore perceptually driven techniques that can be employed to achieve high-fidelity graphical rendering in real-time, and how incorporating authentic lighting effects helps to convey a sense of realism and scale in virtual re-constructions of historical sites.Secondly, we examine how intuitive interaction between participants, and with objects in the environment, also plays a key role in the overall experience. How perceptual methods can be used to guide interest management and distribution choices, is considered with an emphasis on avoiding potential pitfalls when distributing physically-based simulations. An analysis of real network conditions and the implications of these for distribution strategies that facilitate collaboration is presented. Furthermore, we describe technologies necessary to provide intuitive interaction in virtual environments, paying particular attention to engaging multiple sensory modalities, primarily through physically-based sound simulation and perceptually high-fidelity haptic interaction.The combination of realism and intuitive compelling interaction can lead to engaging virtual environments capable of exhibiting skills transfer, an illusive goal of many virtual environment applications.";"2006";"Glencross, Mashhuda and Chalmers, Alan G. and Lin, Ming C. and Otaduy, Miguel A. and Gutierrez, Diego";"ACM SIGGRAPH 2006 courses";"https://doi.org/10.1145/1185657.1185814"
"Effects of network delay on a collaborative motor task with telehaptic and televisual feedback";"The incorporation of haptic interfaces into collaborative virtual environments is challenging when the users are geographically distributed. Reduction of latency is essential for maintaining realism, causality and the sense of co-presence in collaborative virtual environments during closely-coupled haptic tasks. In this study we consider the effects of varying amounts of simulated constant delay on the performance of a simple collaborative haptic task. The task was performed with haptic feedback alone or with visual feedback alone. Subjects were required to make a coordinated movement of their haptic displays as rapidly as possible, while maintaining a target simulated spring force between their end effector and that of their collaborator. Increasing simulated delay resulted in a decrease in performance, either in deviation from target spring force and in increased time to complete the task. At large latencies, there was evidence of dissociation between the states of the system that was observed by each of the collaborating users. This confirms earlier anecdotal evidence that users can be essentially seeing qualitatively different simulations with typical long distance network delays.";"2004";"Allison, Robert S. and Zacher, James E. and Wang, David and Shu, Joseph";"Proceedings of the 2004 ACM SIGGRAPH international conference on virtual reality continuum and its applications in industry";"https://doi.org/10.1145/1044588.1044670"
"Trans-world haptic collaboration";"This sketch describes a collaborative virtual environment application involving haptic interaction over long Internet distances. We have developed algorithms to accommodate significant latency for certain applications, notably in the medical domain. The results have shown that we can manipulate simulated human body organs, as well as guide each other's 'hands' (and shake hands!) over 22,000 km.";"2003";"Gunn, Chris and Hutchins, Matthew and Adcock, Matt and Hawkins, Rhys";"ACM SIGGRAPH 2003 sketches &amp; applications";"https://doi.org/10.1145/965400.965495"
"Compensating the effect of communication delay in client-server–based shared haptic virtual environments";"Shared haptic virtual environments can be realized using a client-server architecture. In this architecture, each client maintains a local copy of the virtual environment (VE). A centralized physics simulation running on a server calculates the object states based on haptic device position information received from the clients. The object states are sent back to the clients to update the local copies of the VE, which are used to render interaction forces displayed to the user through a haptic device. Communication delay leads to delayed object state updates and increased force feedback rendered at the clients. In this article, we analyze the effect of communication delay on the magnitude of the rendered forces at the clients for cooperative multi-user interactions with rigid objects. The analysis reveals guidelines on the tolerable communication delay. If this delay is exceeded, the increased force magnitude becomes haptically perceivable. We propose an adaptive force rendering scheme to compensate for this effect, which dynamically changes the stiffness used in the force rendering at the clients. Our experimental results, including a subjective user study, verify the applicability of the analysis and the proposed scheme to compensate the effect of time-varying communication delay in a multi-user SHVE.";"2015";"Schuwerk, Clemens and Xu, Xiao and Chaudhari, Rahul and Steinbach, Eckehard";"ACM Trans. Appl. Percept.";"https://doi.org/10.1145/2835176"
"Supporting presence in collaborative environments by haptic force feedback";"An experimental study of interaction in a collaborative desktop virtual environment is described. The aim of the experiment was to investigate if added haptic force feedback in such an environment affects perceived virtual presence, perceived social presence, perceived task performance, and task performance. A between-group design was employed, where seven pairs of subjects used an interface with graphic representation of the environment, audio connection, and haptic force feedback. Seven other pairs of subjects used an interface without haptic force feedback, but with identical features otherwise. The PHANToM, a one-point haptic device, was used for the haptic force feedback, and a program especially developed for the purpose provided the virtual environment. The program enables for two individuals placed in different locations to simultaneously feel and manipulate dynamic objects in a shared desktop virtual environment. Results show that haptic force feedback significantly improves task performance, perceived task performance, and pereceived virtual presence in the collaborative distributed environment. The results suggest that haptic force feedback increases perceived social presence, but the difference is not significant.";"2000";"Sallnäs, Eva-Lotta and Rassmus-Gröhn, Kirsten and Sjöström, Calle";"ACM Trans. Comput.-Hum. Interact.";"https://doi.org/10.1145/365058.365086"
"Function-based haptic collaboration in X3D";"We seek to further expand X3D by augmenting it with function-based definitions of geometry, appearance and tangible physical properties. Besides using alone, the introduced nodes can augment and enrich the standard X3D shapes by function-defined geometry, appearance and tangible physical properties. These new virtual objects can be explored haptically with various desktop force-feedback devices. We also propose a general visual and haptic collaborative framework for using it with X3D. We implement it as new pilot versions of BS Collaborate server and BS Contact VRML/X3D viewer. In our collaborative framework, two pipelines—visual and haptic—complement each other to provide a simple and efficient solution to problems requiring collaboration in shared virtual spaces on the web.";"2009";"Wei, Lei and Sourin, Alexei and Stocker, Herbert";"Proceedings of the 14th international conference on 3D web technology";"https://doi.org/10.1145/1559764.1559767"
"A haptic tool for group work on geometrical concepts engaging blind and sighted pupils";"In the study presented here, two haptic and visual applications for learning geometrical concepts in group work in primary school have been designed and evaluated. The aim was to support collaborative learning among sighted and visually impaired pupils. The first application is a static flattened 3D environment that supports learning to distinguish between angles by means of a 3D haptic device providing touch feedback. The second application is a dynamic 3D environment that supports learning of spatial geometry. The scene is a room with a box containing geometrical objects, which pupils can pick up and move around. The applications were evaluated in four schools with groups of two sighted and one visually impaired pupil. The results showed the support for the visually impaired pupil and for the collaboration to be satisfying. A shared understanding of the workspace could be achieved, as long as the virtual environment did not contain movable objects. Verbal communication was crucial for the work process but haptic guiding to some extent substituted communication about direction. When it comes to joint action between visually impaired and sighted pupils a number of interesting problems were identified when the dynamic and static virtual environments were compared. These problems require further investigation. The study extends prior work in the areas of assistive technology and multimodal communication by evaluating functions for joint haptic manipulation in the unique setting of group work in primary school.";"2013";"Moll, Jonas and Pysander, Eva-Lotta Sallnäs";"ACM Trans. Access. Comput.";"https://doi.org/10.1145/2493171.2493172"
"Design of haptic interfaces for therapy";"Touch is fundamental to our emotional well-being. Medical science is starting to understand and develop touch-based therapies for autism spectrum, mood, anxiety and borderline disorders. Based on the most promising touch therapy protocols, we are presenting the first devices that simulate touch through haptic devices to bring relief and assist clinical therapy for mental health. We present several haptic systems that enable medical professionals to facilitate the collaboration between patients and doctors and potentially pave the way for a new form of non-invasive treatment that could be adapted from use in care-giving facilities to public use. We developed these prototypes working closely with a team of mental health professionals.";"2009";"Vaucelle, Cati and Bonanni, Leonardo and Ishii, Hiroshi";"Proceedings of the SIGCHI conference on human factors in computing systems";"https://doi.org/10.1145/1518701.1518776"
"HapticLib: a haptic feedback library for embedded platforms";"Mobile and wearable embedded devices connect the user with digital information in a continuous and pervasive way. A key benefit is given by the possibility to exploit multi-modal interaction capabilities that can dynamically act on different human senses and the cooperative capabilities of the small and pervasive devices.In this scenario we present HapticLib, a software library for the development and implementation of vibro-tactile feedback on resource-constrained embedded devices. It was designed to offer a high-level programming interface for the rendering of haptic patterns, accurately modeling the nature of vibro-tactile actuators and different touch experiences.";"2013";"Guardati, Leonardo and Vallorani, Silvio and Milosevic, Bojan and Farella, Elisabetta and Benini, Luca";"Proceedings of the ACM symposium on applied perception";"https://doi.org/10.1145/2492494.2501882"
"Designing for children's social play in responsive multi-sensory environments";"A responsive multi-sensory environment is designed to create an engaging experience by integrating various sensory stimuli such as sight, sound, and touch. Most prior research in the Human-computer Interaction (HCI) field has investigated its use for children with disabilities (e.g., autism) or for personal play or dyadic activities. Our work focuses on the use of responsive media for children without disabilities in primary education contexts and within a group of children. Our goal is to evaluate the capabilities of responsive multi-sensory environments, integrating wearable garments to foster children's social interaction behavior and collaboration. The enhanced garments we are developing will feature multi-channel haptic actuators, allowing players to feel tactile sensations corresponding to the proximity and activity of other peers. Additionally, virtual creatures will be projected visually an acoustic floor, which players will be able to interact with. Our design involves a series of aquatic creatures that display different \"greeting\" behaviors as participants stand in different proximity zones to each other.";"2023";"Lyu, Yanjun";"Companion proceedings of the 2023 conference on interactive surfaces and spaces";"https://doi.org/10.1145/3626485.3626552"
"SHRUG: stroke haptic rehabilitation using gaming";"In this paper we present SHRUG, an interactive shoulder rehabilitation exerciser. With this work-in-progress system, we intend to (1) explore the effectiveness of providing interactive and just-in-time feedback to the patients and therapists; (2) explore the effect of adding a gaming element on the motivation of the patients. The SHRUG prototype was developed in collaboration with the rehabilitation therapists by augmenting their existing exercising system. We present the implementation details of the system and some of the initial reactions from the therapists on various aspects of the SHRUG prototypes.";"2014";"Peiris, Roshan Lalintha and Janaka, Nuwan and De Silva, Deepthika and Nanayakkara, Suranga";"Proceedings of the 26th australian computer-human interaction conference on designing futures: The future of design";"https://doi.org/10.1145/2686612.2686669"
"Learning lab \"digital technologies\" keeps distance";"Over the last years the Learning Lab \"Digital Technologies\" has been developed as a growing platform for the education of digital technologies in the context of university teaching. It significantly increases the motivation and involvement of students through active and collaborative learning in combination with a haptic experience. Unfortunately, in the summer semester 2020 the concept of the haptic experience was suspended due to the corona pandemic and the associated online teaching.In this article we will describe and evaluate how the concept can be adapted to the current situation and implemented online. With new workshops and an adapted online working method the Learning Lab \"Digital Technologies\" overcomes the physical distance. The conversion to constructivism in an online environment presented in the article shows the new possibilities, but also the challenges. Compared to physical workshops, the aspects constructive and emotional do not show clear trends, social interactions become less and the aspect of self-regulation decreases. Nevertheless, the aspects of activity and situation are increasing.Using the example of the new virtual workshop \"Data Management Foundation\" (DMF) - design a solution for data management - based on the relational database Oracle Apex and a specific case \"Second Chance\", the procedure, bottlenecks, and positive results of the execution will be explained. This workshop is also accessible to the existing community which welcomes new lecturers and developers.";"2021";"Günzel, Holger and Brehm, Lars and Humpe, Andreas";"Proceedings of the 9th computer science education research conference";"https://doi.org/10.1145/3442481.3442506"
"Mazi: Tangible technologies as a channel for collaborative play";"This paper investigates how haptic and auditory stimulation can be playfully implemented as an accessible and stimulating form of interaction for children. We present the design of Mazi, a sonic Tangible User Interface (TUI) designed to encourage spontaneous and collaborative play between children with high support needs autism. We report on a five week study of Mazi with five children aged between 6 and 9 years old at a Special Education Needs (SEN) school in London, UK. We found that collaborative play emerged from the interaction with the system especially in regards to socialization and engagement. Our study contributes to exploring the potential of user-centered TUI development as a channel to facilitate social interaction while providing sensory regulation for children with SENs.";"2019";"Nonnis, Antonella and Bryan-Kinns, Nick";"Proceedings of the 2019 CHI conference on human factors in computing systems";"https://doi.org/10.1145/3290605.3300670"
"Iterative design of an audio-haptic drawing application";"This paper presents the ongoing design and evaluation of an audio-haptic drawing program that allows visually impaired users to create and access graphical images. The application is developed in close collaboration with a user reference group of five blind/low vision school children. The objective of the application is twofold. It is used as a research vehicle to investigate user interaction techniques and do basic research on navigation strategies and help tools, including e.g. sound fields, shape creation tools and beacons with pulling forces in the context of drawing. In the progress of the development, the preferred features have been implemented as standard tools in the application. The final aim of the application in its current form is to aid school work in different subjects, and part of the application development is also to create tasks relevant in a school setting.";"2007";"Rassmus-Gröhn, Kirsten and Magnusson, Charlotte and Eftring, HäWIP Ekan";"CHI '07 extended abstracts on human factors in computing systems";"https://doi.org/10.1145/1240866.1241053"
"Turn-by-wire: Computationally mediated physical fabrication";"Advances in digital fabrication have simultaneously created new capabilities while reinforcing outdated workflows that constrain how, and by whom, these fabrication tools are used. In this paper, we investigate how a new class of hybrid-controlled machines can collaborate with novice and expert users alike to yield a more lucid making experience. We demonstrate these ideas through our system, Turn-by-Wire. By combining the capabilities of a traditional lathe with haptic input controllers that modulate both position and force, we detail a series of novel interaction metaphors that invite a more fluid making process spanning digital, model-centric, computer control, and embodied, adaptive, human control. We evaluate our system through a user study and discuss how these concepts generalize to other fabrication tools.";"2019";"Tian, Rundong and Saran, Vedant and Kritzler, Mareike and Michahelles, Florian and Paulos, Eric";"Proceedings of the 32nd annual ACM symposium on user interface software and technology";"https://doi.org/10.1145/3332165.3347918"
"Human-robot medical interaction";"Advances in Soft Robotics, Haptics, AI and simulation have changed the medical robotics field, allowing robotics technologies to be deployed in medical environments. In this context, the relationship between doctors, robotics devices, and patients is fundamental, as only with the synergetic collaboration of the three parties results in medical robotics can be achieved. This workshop focuses on the use of soft robotics technologies, sensing, AI and Simulation, to further improve medical practitioner training, as well as the creation of new tools for diagnosis and healthcare through the medical interaction of humans and robots. The Robo-patient is more specifically the idea behind the creation of sensorised robotic patient with controllable organs to present a given set of physiological conditions. This is both to investigate the embodied nature of haptic interaction in physical examination, as well as the doctor-patient relationship to further improve medical practice through robotics technologies. The Robo-doctor aspect is also relevant, with robotics prototypes performing, or helping to perform, medical diagnosis. In the workshop, key technologies as well as future views in the field will be discussed both by expert and new upcoming researchers.";"2020";"Scimeca, Luca and Iida, Fumiya and Maiolino, Perla and Nanayakkara, Thrishantha";"Companion of the 2020 ACM/IEEE international conference on human-robot interaction";"https://doi.org/10.1145/3371382.3374847"
"A comparison of immersive HMD, fish tank VR and fish tank with haptics displays for volume visualization";"Although a wide range of virtual reality (VR) systems are in use, there are few guidelines to help system and application developers select the components most appropriate for the domain problem they are investigating. Using the results of an empirical study, we developed such guidelines for the choice of display environment for four specific, but common, volume visualization problems: identification and judgment of the size, shape, density, and connectivity of objects present in a volume. These tasks are derived from questions being asked by collaborators studying Cystic Fibrosis (CF). We compared user performance in three different stereo VR systems: (1) head-mounted display (HMD); (2) fish tank VR (fish tank); and (3) fish tank VR augmented with a haptic device (haptic). HMD participants were placed \"inside\" the volume and walked within it to explore its structure. Fish tank and haptic participants saw the entire volume on-screen and rotated it to view it from different perspectives. Response time and accuracy were used to measure performance. Results showed that the fish tank and haptic groups were significantly more accurate at judging the shape, density, and connectivity of objects and completed the tasks significantly faster than the HMD group. Although the fish tank group was itself significantly faster than the haptic group, there were no statistical differences in accuracy between the two. Participants classified the HMD system as an \"inside-out\" display (looking outwards from inside the volume), and the fish tank and haptic systems as \"outside-in\" displays (looking inwards from outside the volume). Including haptics added an inside-out capability to the fish tank system through the use of touch. We recommend an outside-in system because it offers both overview and context, two visual properties that are important for the volume visualization tasks we studied. In addition, based on the haptic group's opinion (80";"2006";"Qi, Wen and Taylor, Russell M. and Healey, Christopher G. and Martens, Jean-Bernard";"Proceedings of the 3rd symposium on applied perception in graphics and visualization";"https://doi.org/10.1145/1140491.1140502"
"An experimental study on the role of touch in shared virtual environments";"Investigating virtual environments has become an increasingly interesting research topic for engineers, computer and cognitive scientists, and psychologists. Although there have been several recent studies focused on the development of multimodal virtual environments (VEs) to study human-machine interactions, less attention has been paid to human-human and human-machine interactions in shared virtual environments (SVEs), and to our knowledge, no attention paid at all to what extent the addition of haptic communication between people would contribute to the shared experience. We have developed a multimodal shared virtual environment and performed a set of experiments with human subjects to study the role of haptic feedback in collaborative tasks and whether haptic communication through force feedback can facilitate a sense of being and collaborating with a remote partner. The study concerns a scenario where two participants at remote sites must cooperate to perform a joint task in an SVE. The goals of the study are (1) to assess the impact of force feedback on task performance, (2) to better understand the role of haptic communication in human-human interactions, (3) to study the impact of touch on the subjective sense of collaborating with a human as reported by the participants based on what they could see and feel, and (4) to investigate if gender, personality, or emotional experiences of users can affect haptic communication in SVEs. The outcomes of this research can have a powerful impact on the development of next-generation human-computer interfaces and network protocols that integrate touch and force feedback technology into the internet, development of protocols and techniques for collaborative teleoperation such as hazardous material removal, space station.";"2000";"Basdogan, Cagatay and Ho, Chih-Hao and Srinivasan, Mandayam A. and Slater, Mel";"ACM Trans. Comput.-Hum. Interact.";"https://doi.org/10.1145/365058.365082"
"Sound forest: Evaluation of an accessible multisensory music installation";"Sound Forest is a music installation consisting of a room with light-emitting interactive strings, vibrating platforms and speakers, situated at the Swedish Museum of Performing Arts. In this paper we present an exploratory study focusing on evaluation of Sound Forest based on picture cards and interviews. Since Sound Forest should be accessible for everyone, regardless age or abilities, we invited children, teens and adults with physical and intellectual disabilities to take part in the evaluation. The main contribution of this work lies in its findings suggesting that multisensory platforms such as Sound Forest, providing whole-body vibrations, can be used to provide visitors of different ages and abilities with similar associations to musical experiences. Interviews also revealed positive responses to haptic feedback in this context. Participants of different ages used different strategies and bodily modes of interaction in Sound Forest, with activities ranging from running to synchronized music-making and collaborative play.";"2019";"Frid, Emma and Lindetorp, Hans and Hansen, Kjetil Falkenberg and Elblaus, Ludvig and Bresin, Roberto";"Proceedings of the 2019 CHI conference on human factors in computing systems";"https://doi.org/10.1145/3290605.3300907"
"Effects of Haptic Data compression on user performance in Collaborative Haptic Virtual Environment";"This paper presents an experimental study on the effects of haptic data compression on user performance in a Collaborative Haptic Virtual Environment (CHVE) using a Fitts' type task. Several compression methods have been implemented, including Position-Based Haptic Data (PBHD) and Position-Force Haptic Data (PFHD), and the Perception Deadband (PD). In this paper, we have also proposed and investigated a velocity-based Position Extrapolation (PE) method to improve the Perception Deadband technique. We have designed and developed a virtual Fitts' type task for this study. Experiments have been conducted using this task to objectively measure user performance in the CHVE, when the compression methods have been applied to the haptic data. Although, our focus has mostly been on the effects of the compression methods on user performance, associate user perception ratings have also been reported in this paper. Results show that subjects did higher errors when PBHD model were in use, compared to PFDB. In addition, the results show that applying PE method improved the subjects' perception rating with a small increase in the task error.";"2014";"L. Huynh and M. H. Zadeh";"2014 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE) Proceedings";"https://doi.org/10.1109/HAVE.2014.6954340"
"Experimental Internet Haptic Collaboration using Virtual Coupling Schemes";"In this paper we present the results from several global-scale haptic collaboration experiments that were performed using the Internet. These experiments consist of three virtual coupling schemes proposed to maintain position coherency in a networked haptic virtual environment (NHVE). We compared two of our virtual coupling schemes—which represent a peer-to-peer architecture—to the third—with a client-server architecture. We set up a packet reflector network at our collaborator servers (Italy, Canada and North Carolina, USA) to perform the experiments with subjects located within the same laboratory. Our largest one-way latency was in the order of 200 ms for the packet reflector situated in Italy. The virtual coupling parameters were chosen so that it resulted in stable operation for all the delay values that were tested. User datagram protocol (UDP) was used for haptic data communication because of the high transmission rate requirement for NHVEs. There were three experiments carried out in total: two of them at the packet transmission rate of 1000 Hz with a change in the virtual coupling parameters in scheme 2, and the third one, which tested the three virtual coupling schemes at two fixed transmission rates of 500 Hz and 100 Hz. Locally, the haptic update rate was maintained at 1000 Hz during all the experiments. Our results demonstrate that the peer-to-peer virtual coupling schemes can be used for maintaining position coherency in a NHVE. We also show that the position error and the force rendered to the users increase with the reduction in the packet transmission rate. Given that these experiments were performed through the actual Internet, this work proves valuable for global-scale stable haptic collaboration using the Internet.";"2008";"G. Sankaranarayanan and B. Hannaford";"2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems";"https://doi.org/10.1109/HAPTICS.2008.4479954"
"Audio makes a difference in haptic collaborative virtual environments";"In this paper a study is presented which aimed at exploring the effects of audio feedback in a haptic and visual interface supporting collaboration among sighted and people who cannot see. A between group design was used and the participants worked in pairs with one sighted and one blindfolded in each. The application used was a haptic 3D environment in which participants could build composed objects out of building blocks. The building blocks could be picked up and moved around by means of a touch feedback pointing device. In one version of the application, used by half of the groups, sound cues could be used to tell the other person where you were, and to get feedback on your own and the other person’s actions. Results showed that sound cues together with haptic feedback made a difference in the interaction between the collaborators regarding their shared understanding of the workspace and the work process. Especially, sound cues played an important role for maintaining awareness of ongoing work – you knew what was going on, and you got a response on your own actions.";"2010";"Moll, Jonas and Huang, Yingying and Sallnäs, Eva-Lotta";"Special Issue on Inclusion and Interaction: Designing Interaction for Inclusive Populations";"https://doi.org/10.1016/j.intcom.2010.06.001"
"A Multi-rate Control Approach to Haptic Interaction in Multi-user Virtual Environments";"High-fidelity haptic interaction in multi-user environments over general Ethernet-based local area networks (LAN) and metropolitan area networks (MAN) can be challenging but has promising applications. Under typical network traffic conditions, the 1kHz real-time control rate suggested in the literature for stable haptic simulation is well above that achievable by conventional network protocols such as the UDP and TCP/IP. To overcome this limitation, a decentralized multi-rate control approach is proposed in which local force-feedback loops are executed at higher rates than data packet transmission between the user workstations. Mathematical models for stability and performance analysis of such multi-rate haptic control systems are presented. Analytical and experimental results demonstrate improved performance and stability for the distributed control architecture when compared with a centralized controller.";"2007";"M. Fotoohi and S. Sirouspour and D. Capson";"Proceedings 2007 IEEE International Conference on Robotics and Automation";"https://doi.org/10.1109/ROBOT.2007.363771"
"Exploring Remote Collaborative Tasks: The Impact of Avatar Representation on Dyadic Haptic Interactions in Shared Virtual Environments";"This study is the first to explore the interplay between haptic interaction and avatar representation in Shared Virtual Environments (SVEs). Specifically, how these factors shape users’ sense of social presence during dyadic collaborations, while assessing potential effects on task performance. In a series of experiments, participants performed the collaborative task with haptic interaction under four avatar representation conditions: avatars of both participant and partner were displayed, only the participant’s avatar was displayed, only the partner’s avatar was displayed, and no avatars were displayed. The study finds that avatar representation, especially of the partner, significantly enhances the perception of social presence, which haptic interaction alone does not fully achieve. However, neither the presence nor the type of avatar representation impacts the task performance or participants’ force effort of the task, suggesting that haptic interaction provides sufficient interaction cues for the execution of the task. These results underscore the significance of integrating both visual and haptic modalities to optimize remote collaboration experiences in virtual environments, ensuring effective communication and a strong sense of social presence.";"2025";"G. Sasaki and H. Igarashi";"IEEE Transactions on Visualization and Computer Graphics";"https://doi.org/10.1109/TVCG.2025.3580546"
"Influences of Network Delay on Cooperative Work in Networked Virtual Environment with Haptics";"In this paper, we investigate influences of the network delay on haptic cooperative work in a networked virtual environment by experiment. In the work, two users carry an object cooperatively in a networked maze system by manipulating haptic interface devices. We handle two carrying methods in our experiment. In one method, the two users hold the object. In the other method, one user holds the object and the other user pushes it. We measure the operation time and reaction force, and we compare them between the two methods. Experimental results demonstrate that the former method has smaller average operation time than the latter method, but the average reaction force is larger in the former.";"2020";"S. T. Aung and Y. Ishibashi and K. T. Mya and H. Watanabe and P. Huang";"2020 IEEE REGION 10 CONFERENCE (TENCON)";"https://doi.org/10.1109/TENCON50793.2020.9293934"
"Multi-rate Control Architectures for Dextrous Haptic Rendering in Cooperative Virtual Environments";"This paper is concerned with haptic simulation in multi-user virtual environments in which the users can haptically interact in a shared virtual world from separate workstations over an Ethernet local-area network (LAN). High-fidelity haptic rendering requires a minimum control update rate of 1000Hz which is beyond the capability of popular network protocols such as the UDP and TCP/IP. Consequently, a multi-rate control strategy is adopted in which local force-feedback loops are executed at higher rates than data packet transmission between the user workstations. Two control architectures, i.e. centralized and distributed, are presented and their stability margins are compared. Two methods for mathematical modelling and analysis of the proposed multi-rate haptic control systems are examined. Analytical and experimental results demonstrate that the distributed control architecture is superior to the centralized controller from performance and stability perspectives. This is confirmed through experiments with a dual-user dual-finger haptic rendering platform";"2006";"M. Fotoohi and S. Sirouspour and D. Capson";"Proceedings of the 45th IEEE Conference on Decision and Control";"https://doi.org/10.1109/CDC.2006.377163"
"Supporting Collaborative Interaction with Real Time Force Feedback in Distributed Haptic Virtual Environments over IP Networks";"This paper presents an investigation into a new peer-to-peer network architecture for real time tele-haptic operation in distributed virtual environments (DVEs). A novel force collaboration and position synchronization algorithm is developed in order to support networked haptic interactions. Network impairments such as time delay, jitter and packet loss each have different (and severe) impacts on remote haptic collaborations. The new peer-to-peer architecture is able to support haptic interactions over IP networks. Experiments have been conducted to show the performance of this architecture in comparison with the currently available two algorithms that compensate for delay (TiDeC™), and position (dead reckoning) are examined. Experiments have been conducted to investigate the threshold levels of QoS required for networked haptic collaboration. Findings of the study are presented in this paper with recommendations for a set of network QoS parameter values that support haptic collaboration over IP networks.";"2010";"K. M. Yap";"2010 Fourth International Conference on Genetic and Evolutionary Computing";"https://doi.org/10.1109/ICGEC.2010.130"
"An experimental study of supporting collaborative haptic interaction in distributed virtual environments over wireless networks";"This paper presents an experimental investigation into a new peer-to-peer wireless network architecture for real time telehaptic operation in distributed virtual environments (DVEs). The new peer-to-peer architecture is able to support haptic interactions over different wireless network architecture. Experiments have been conducted to show the performance of different wireless architecture, i. e. wireless-B/G/N. Experiments have also been conducted to investigate the performance of this architecture. Findings of the study are presented in this paper and it shows the challenges in conducting haptic collaboration over wireless IP networks. This is especially true when the wireless hops increase. The wireless channel condition varies over time due to such factors as channel characteristics, the PHY scheme selected, time-varying interference, and channel width for the particular wireless architecture.";"2012";"K. M. Yap and H. A. A. Ai-Rawi and T. -H. Lee";"IET International Conference on Wireless Communications and Applications (ICWCA 2012)";"https://doi.org/10.1049/cp.2012.2089"
"Moderating Simulation Lag in Haptic Virtual Environments";"Simulation lag is a known issue in networked virtual environments where users are geographically distributed. When users collaborate across the network using haptics, there are always momentary lacks of synchronization due to packet delay, loss, and jitter. Many strategies exist for dealing with such scenarios, but these strategies concentrate on one aspect and don't adequately address the necessary realism, causality, and the sense of co-presence in the virtual environments during closely-coupled haptic tasks. In this paper, we propose an approach that uses two techniques to moderate the simulation lag in haptic-based virtual environments. A decorator, which is a visual cue embedded in the haptic virtual object, is used to inform the user about the sate of simulation lag. In addition, this decorator is controlled by an algorithm that predicts the users' most likely action in the very short term, and compensates delayed or lost packets by interpolating collaborative actions. In other words, this technique improvises the current state of the haptic virtual object and displays it to the local user, in addition to calculating the current network delay/loss and indicating it non-intrusively to the local user";"2006";"A. Boukerche and S. Shirmohammadi and A. Hossain";"39th Annual Simulation Symposium (ANSS'06)";"https://doi.org/10.1109/ANSS.2006.31"
"The Influence of Avatar Representation on Haptic Interaction in Virtual Environment";"Co-presence is the index that indicates the degree to which the observer believes he/she is not alone and secluded. The representation of avatars in virtual environments (VE) having an effect on co-presence was reported. However, these reports are only limited to visual interaction. This paper aims to clarify the influence of the avatar representation on cooperative haptic interaction. Haptic interaction in the VE is essential for teleoperation. A cooperative task with multilateral control was conducted, and the haptic interaction was analyzed by conducting a survey. In the experiment, the avatar representation was changed by three patterns of the avatar representation as follows; all of subjects’ avatars are displayed, only the subject’s avatar is displayed, and all of subjects’ avatar is not displayed. The experimental results showed that the avatar representation did not affect the haptic interaction. On the other hand, the subject’s impression was changed by the avatar representation. Therefore, it was concluded that the avatars are not always necessary in a cooperative task.";"2022";"G. Sasaki and H. Igarashi";"IECON 2022 – 48th Annual Conference of the IEEE Industrial Electronics Society";"https://doi.org/10.1109/IECON49645.2022.9968985"
"Recognition of Haptic Interaction Patterns in Dyadic Joint Object Manipulation";"The development of robots that can physically cooperate with humans has attained interest in the last decades. Obviously, this effort requires a deep understanding of the intrinsic properties of interaction. Up to now, many researchers have focused on inferring human intents in terms of intermediate or terminal goals in physical tasks. On the other hand, working side by side with people, an autonomous robot additionally needs to come up with in-depth information about underlying haptic interaction patterns that are typically encountered during human-human cooperation. However, to our knowledge, no study has yet focused on characterizing such detailed information. In this sense, this work is pioneering as an effort to gain deeper understanding of interaction patterns involving two or more humans in a physical task. We present a labeled human-human-interaction dataset, which captures the interaction of two humans, who collaboratively transport an object in an haptics-enabled virtual environment. In the light of information gained by studying this dataset, we propose that the actions of cooperating partners can be examined under three interaction types: In any cooperative task, the interacting humans either 1) work in harmony, 2) cope with conflicts, or 3) remain passive during interaction. In line with this conception, we present a taxonomy of human interaction patterns; then propose five different feature sets, comprising force-, velocity-and power-related information, for the classification of these patterns. Our evaluation shows that using a multi-class support vector machine (SVM) classifier, we can accomplish a correct classification rate of 86 percent for the identification of interaction patterns, an accuracy obtained by fusing a selected set of most informative features by Minimum Redundancy Maximum Relevance (mRMR) feature selection method.";"2015";"C. E. Madan and A. Kucukyilmaz and T. M. Sezgin and C. Basdogan";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2014.2384049"
"Collaborative haptic interaction in virtual environment of multi-operator multi-robot teleoperation systems";"In a multi-operator multi-robot (MOMR) teleoperation system, each human operator controls a remote slave robot via a corresponding master interface to jointly perform complex tasks. This paper provides a hardware-in-loop simulation to study collaborative haptic interaction of MOMR teleoperation systems based on decentralized control approach. This approach uses physically-based motion simulation for rendering cooperative virtual manipulation in haptic interfaces. The dynamic behavior including contact force and collision detection is calculated using Open Dynamics Engine and reflected on haptic interface to assist operators to implement cooperative tasks in graphic environment. The result of this study constitutes a significant step forward for distributed haptic collaboration.";"2012";"N. T. Thanh and X. Jiang and S. Abiko and T. Tsujita and A. Konno and M. Uchiyama";"2012 Proceedings of SICE Annual Conference (SICE)";NA
"Intention Recognition for Dynamic Role Exchange in Haptic Collaboration";"In human-computer collaboration involving haptics, a key issue that remains to be solved is to establish an intuitive communication between the partners. Even though computers are widely used to aid human operators in teleoperation, guidance, and training, because they lack the adaptability, versatility, and awareness of a human, their ability to improve efficiency and effectiveness in dynamic tasks is limited. We suggest that the communication between a human and a computer can be improved if it involves a decision-making process in which the computer is programmed to infer the intentions of the human operator and dynamically adjust the control levels of the interacting parties to facilitate a more intuitive interaction setup. In this paper, we investigate the utility of such a dynamic role exchange mechanism, where partners negotiate through the haptic channel to trade their control levels on a collaborative task. We examine the energy consumption, the work done on the manipulated object, and the joint efficiency in addition to the task performance. We show that when compared to an equal control condition, a role exchange mechanism improves task performance and the joint efficiency of the partners. We also show that augmenting the system with additional informative visual and vibrotactile cues, which are used to display the state of interaction, allows the users to become aware of the underlying role exchange mechanism and utilize it in favor of the task. These cues also improve the user's sense of interaction and reinforce his/her belief that the computer aids with the execution of the task.";"2013";"A. Kucukyilmaz and T. M. Sezgin and C. Basdogan";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2012.21"
"Influences of haptic communication on a shared manual task";"With the advent of new haptic feedback devices, researchers are giving serious consideration to the incorporation of haptic communication in collaborative virtual environments. For instance, haptic interactions based tools can be used for medical and related education whereby students can train in minimal invasive surgery using virtual reality before approaching human subjects. To design virtual environments that support haptic communication, a deeper understanding of humans′ haptic interactions is required. In this paper, human′s haptic collaboration is investigated. A collaborative virtual environment was designed to support performing a shared manual task. To evaluate this system, 60 medical students participated to an experimental study. Participants were asked to perform in dyads a needle insertion task after a training period. Results show that compared to conventional training methods, a visual-haptic training improves user′s collaborative performance. In addition, we found that haptic interaction influences the partners′ verbal communication when sharing haptic information. This indicates that the haptic communication training changes the nature of the users′ mental representations. Finally, we found that haptic interactions increased the sense of copresence in the virtual environment: haptic communication facilitates users′ collaboration in a shared manual task within a shared virtual environment. Design implications for including haptic communication in virtual environments are outlined.";"2011";"Chellali, Amine and Dumas, Cédric and Milleville-Pennel, Isabelle";"Cognitive Ergonomics for Situated Human-Automation Collaboration";"https://doi.org/10.1016/j.intcom.2011.05.002"
"Haptic negotiation and role exchange for collaboration in virtual environments";"We investigate how collaborative guidance can be realized in multi-modal virtual environments for dynamic tasks involving motor control. Haptic guidance in our context can be defined as any form of force/tactile feedback that the computer generates to help a user execute a task in a faster, more accurate, and subjectively more pleasing fashion. In particular, we are interested in determining guidance mechanisms that best facilitate task performance and arouse a natural sense of collaboration. We suggest that a haptic guidance system can be further improved if it is supplemented with a role exchange mechanism, which allows the computer to adjust the forces it applies to the user in response to his/her actions. Recent work on collaboration and role exchange presented new perspectives on defining roles and interaction. However existing approaches mainly focus on relatively basic environments where the state of the system can be defined with a few parameters. We designed and implemented a complex and highly dynamic multimodal game for testing our interaction model. Since the state space of our application is complex, role exchange needs to be implemented carefully. We defined a novel negotiation process, which facilitates dynamic communication between the user and the computer, and realizes the exchange of roles using a three-state finite state machine. Our preliminary results indicate that even though the negotiation and role exchange mechanism we adopted does not improve performance in every evaluation criteria, it introduces a more personal and human-like interaction model.";"2010";"S. O. Oguz and A. Kucukyilmaz and T. M. Sezgin and C. Basdogan";"2010 IEEE Haptics Symposium";"https://doi.org/10.1109/HAPTIC.2010.5444628"
"Analysis of virtual environment haptic robotic systems for a rehabilitation of post-stroke patients";"Haptic refers to feedback of a physical signal to a human user through touch. A haptic system realizes this feedback. In most of the applications today, the physical signal refers to force but not necessary. Virtual environment haptic systems refers to the situation where the force to be feedback from the objects in a virtual environment or computer. Virtual environment haptic robotic systems are widely used for rehabilitation and training of surgeon. However, currently, these systems seem to be qualitative; as such the training goal can never be precise. The root cause for this shortcoming is absence of theoretical analysis of virtual environment haptic robotic systems. This paper reports our work on a theoretical analysis of the virtual environment haptic robotic system. A commercial system Phantom Omni was taken as a case system to facilitate this research. This research has a generalized implication to any kind of virtual environment haptic robotic system as well as to general Human-Machine Cooperative Robot, a kind of which is the haptic system.";"2017";"T. T. Jiang and Z. Q. Qian and Y. Lin and Z. M. Bi and Y. F. Liu and W. J. Zhang";"2017 IEEE International Conference on Industrial Technology (ICIT)";"https://doi.org/10.1109/ICIT.2017.7915451"
"Using a 6 Degrees of Freedom Virtual Reality Input Device With An Augmented Reality Headset In A Collaborative Environment";"Augmented reality headsets have become increasingly consumer-available. Often gesture and speech are the main input modalities provided by these headsets. For some tasks, users may need a more precise input method. Tracked controllers can be added by using image tracking; however, this is not always the most accurate solution. This work outlines how to use off-the-shelf products to create a collaborative cross-device mixed reality experience. In that experience, the positionally tracked inputs from one headset can be used by another headset that may not natively support them.";"2021";"A. S. Williams and F. R. Ortega";"2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)";"https://doi.org/10.1109/VRW52623.2021.00045"
"Beaming: An Asymmetric Telepresence System";"The Beaming project recreates, virtually, a real environment; using immersive VR, remote participants can visit the virtual model and interact with the people in the real environment. The real environment doesn't need extensive equipment and can be a space such as an office or meeting room, domestic environment, or social space.";"2012";"A. Steed and W. Steptoe and W. Oyekoya and F. Pece and T. Weyrich and J. Kautz and D. Friedman and A. Peer and M. Solazzi and F. Tecchia and M. Bergamasco and M. Slater";"IEEE Computer Graphics and Applications";"https://doi.org/10.1109/MCG.2012.110"
"Prototype of Force Feedback Tool for Mixed Reality Applications";"This prototype demonstrates the viability of manipulating both physical and virtual objects with the same tool in order to maintain object permanence across both modes of interaction. Using oppositional force feedback, provided by a servo, and an augmented visual interface, provided by the user’s smartphone, this tool simulates the look and feel of a physical object within an augmented environment. Additionally, the tool is also able to manipulate physical objects that are not part of the augmented reality, such as a physical nut. By integrating both modes of interaction into the same tool, users can fluidly move between these different modes of interaction, manipulating both physical and virtual objects as the need arises. By overlaying this kind of visual and haptic augmentation onto a common tool such as a pair of pliers, we hope to further explore scenarios for collaborative telepresence in future work.";"2021";"I. Gonsher and Z. Lei";"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)";"https://doi.org/10.1109/ISMAR-Adjunct54149.2021.00123"
"3D Visual Component Based Development System for Medical Training Systems Supporting Haptic Devices and Their Collaborative Environments";"This paper treats a development system for medical training systems supporting haptic devices. The research group of the authors has already proposed a 3D software development system called Intelligent Box. Intelligent Box has provided various software components called boxes, which are 3D visible, reactive objects. Intelligent Box allows the user to develop 3D graphics applications by combining already existing boxes through direct manipulations on a computer screen without writing any text-based programs. This is the main feature of Intelligent Box, which is different from other conventional systems. Recently, the authors have been developing functionalities as boxes dedicated for medical training systems supporting hap tic devices like Phantoms. In this paper, the authors introduce such new boxes. Also, Intelligent Box has already provided a particular box called Room Box, which enables to build distributed 3D graphics applications. Using this box with the new boxes introduced in this paper, it will become possible to build collaborative environments for medical training systems. In this paper, the authors also explain how easily such collaborative environments of medical training systems can be built.";"2012";"Y. Kosuki and Y. Okada";"2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems";"https://doi.org/10.1109/CISIS.2012.131"
"A Study to Support Haptic Collaboration with Real Time Force Feedback over Wireless Networks";"This paper presents an investigation into a new peer-to-peer wireless network architecture for real time tele-haptic operation in distributed virtual environments (DVEs). A novel force collaboration and position synchronization algorithm is developed in order to support wireless networked haptic interactions. The new peer-to-peer architecture is able to support haptic interactions over wireless IP networkes. Experiments have been conducted to show the performance of this with different wireless hopping. Experiments have also been conducted to investigate the threshold levels of QoS required (i.e. number of wireless hopping) for wireless networked haptic collaboration. Findings of the study are presented in this paper and it shows the challenges in conducting haptic collaboration over wireless IP networks. The wireless channel condition varies over time due to such factors as channel characteristics, the PHY scheme selected, time-varying interference, and the priority of services (QoS demands) from MAC/PHY layers.";"2011";"K. M. Yap and T. -H. Lee";"2011 First International Conference on Robot, Vision and Signal Processing";"https://doi.org/10.1109/RVSP.2011.80"
"Supporting haptic collaboration across networked peers with real time force feedback in distributed virtual environments";"In this paper, we design and implement a new peer- to-peer network architecture for real time tele-haptic operation in distributed virtual environments (DVEs). We have also developed a novel force collaboration and position synchronization algorithm in order to support networked haptic interactions. In order to interact successfully in DVE with haptic devices, haptic applications require a stringent Quality of Service (QoS) service from the network. Impairments such as time delay, jitter and packet loss each have different (and severe) impacts on remote haptic collaborations. The new peer-to-peer architecture is able to support haptic interactions across time-varying networked peers. Experiments have been conducted to investigate the levels of QoS required for networked haptic collaboration. We also examine whether existing compensation algorithms can be used to enhance the performance of the system. The performance of two algorithms that compensate for delay (TiDeCtrade), and position (dead reckoning) are examined. Findings of the study, together with a set of network QoS parameter values obtained for supporting haptic collaboration over IP networks, are presented.";"2007";"K. M. Yap and A. Marshall and W. Yu";"2007 IEEE International Conference on Telecommunications and Malaysia International Conference on Communications";"https://doi.org/10.1109/ICTMICC.2007.4448687"
"Haptic Designation Tool to Improve Working Strategy in Collaborative Virtual Environment";"Coordinating team's work in a 3D Collaborative Virtual Environments is a real challenge. The communication constraints in such environments reduces the understanding between the partner's and thus complicates the team's coordintation. In order to facilitate the coordination, this paper proposes a hap tic tool for the designation of targets. This tool was experimented in a context of collaborative molecular design where one user designates tasks and coordinates the actions of two operators. The experimental results show an improvement of the working efficiency of the group and a better sharing of the activity between partners. Moreover, we observe that the hap tic guidance enables an accurate selection of targets which leads to an improvement of performance during the deformation process.";"2015";"A. Girard and M. Ammi";"2015 IEEE International Conference on Systems, Man, and Cybernetics";"https://doi.org/10.1109/SMC.2015.235"
"An Integrated Haptic Data Transmission in Haptic Collaborative Virtual Environments";"Haptic Collaboration Virtual Environment (HCVE) is an enhanced virtual reality space with haptic interface support. HCVE users are connected together over the network and are able to work together by using sense of touch, i.e. haptics as well as audio and visual interfaces. In HCVE, the communication of haptic data is challenging because of time-varying network conditions and extremely high data rate. To mitigate such difficulties, we propose a linear prediction algorithm and a buffering scheme which is an integrated scheme for haptic data transmission. The prediction algorithm is to minimize the negative effects from network delay, loss and jitter, while the buffering scheme is to easily synchronize haptic interaction. For the evaluation of our proposed schemes, we build an experimental test bed for HCVE. As the result, we observe that our schemes are effective in improving the quality of haptic experiences. The quantitative measurement results are presented";"2007";"Y. You and M. Y. Sung and K. Jun";"6th IEEE/ACIS International Conference on Computer and Information Science (ICIS 2007)";"https://doi.org/10.1109/ICIS.2007.58"
"Toward Volume-Based Haptic Collaborative Virtual Environment with Realistic Sensation";"In this paper, we propose a volume-based realistic communication system called Haptic Communication that allows participants to interact in real-time with others at remote locations on the network in haptic perception (sense of touch) of soft objects in virtual environments. To provide sense of touch at remote locations in real-time we construct the system as follows. At first virtual soft objects are represented by adaptive volume model in the PCs at the remote locations. Next, from the parameters of positions and forces at contacting points transmitted via network, at each PC the reflection force of the soft object is calculated rapidly and accurately. Eventually, as a result the haptic and visual information are rendered by means of a haptic device PHANToM and a volume graphic software at the PCs. We investigated the efficiency of our system via experiments on a simulation of needle insertion with high force feedback rates at remote locations on a WAN between Ritsumeikan University, Biwako Kusatsu Campus and Osaka University, Toyonaka Campus. The experiment results show that the delay due to network traffic is negligible.";"2008";"T. Tanaka and S. Yamaguchi and L. Jooho and N. Shimada and H. T. Tanaka";"2008 Second International Symposium on Universal Communication";"https://doi.org/10.1109/ISUC.2008.47"
"Effective Cooperative Haptic Interaction over the Internet";"We present a system that enables, for the first time, effective transatlantic cooperative haptic manipulation of objects whose motion is computed using a physically-based model. We propose a technique for maintaining synchrony between simulations in a peer-to-peer system, while providing responsive direct manipulation for all users. The effectiveness of this approach is determined through extensive user trials involving concurrent haptic manipulation of a shared object. A CAD assembly task, using physically-based motion simulation and haptic feedback, was carried out between the USA and the UK with network latencies in the order of 120ms. We compare the effects of latency on synchrony between peers over the Internet with a low latency (0.5ms) local area network. Both quantitatively and qualitatively, when using our technique, the performance achieved over the Internet is comparable to that on a LAN. As such, this technique constitutes a significant step forward for distributed haptic collaboration";"2007";"M. Glencross and C. Jay and J. Feasel and L. Kohli and M. Whitton and R. Hubbold";"2007 IEEE Virtual Reality Conference";"https://doi.org/10.1109/VR.2007.352471"
"Proactive haptic articulation for intercommunication in collaborative virtual environments";"In this paper, we look upon elements present in speech articulation to introduce proactive haptic articulation as a novel approach for communication in Collaborative Virtual Environments. We defend the hypothesis that elements present in natural language, when added to the design of the vibrotactile vocabulary, should provide an expressive medium for intercommunication. Moreover, the ability to render tactile cues to a teammate should encourage users to extrapolate a given vocabulary while using it. We implemented a collaborative puzzle task to observe the use of such vocabulary. Results show that participants autonomously adapted it to attend their communication needs during the assembly.";"2016";"V. A. de Jesus Oliveira and L. Nedel and A. Maciel";"2016 IEEE Symposium on 3D User Interfaces (3DUI)";"https://doi.org/10.1109/3DUI.2016.7460036"
"Social Presence and Cooperation in Large-Scale Multi-User Virtual Reality - The Relevance of Social Interdependence for Location-Based Environments";"Introduction. An increasing number of location-based entertainment centers offers the possibility of entering multi-user virtual reality (VR) scenarios. Until now, neither cognition and emotions of users nor team experience have been scientifically evaluated in such an application. The present study investigated the gain of positive social interdependence while experiencing an adventure on the Immersive Deck of Illusion Walk (Berlin, Germany). Method. The preliminary version of a VR group adventure of the company was enriched by a task establishing social interdependence (IDP condition). The impact of IDP on social presence and cooperation (i.e., mutual importance) was evaluated relative to a control task without interdependence (nIDP condition). Results. Social IDP increased social presence and cooperation among participants. Additionally, behavioral involvement (part of presence), certain aspects of the adventure experience, and the affective evaluation during the experience were positively influenced by IDP. Discussion. The present study showed that interdependence can substantially enhance social presence and cooperation (i.e., mutual importance) in a VR setting already characterized by social co-experience. Thus, it revealed one design option (social IDP) to improve the experience, particularly the social experience, of location-based entertainment. Conclusion. The present research addressed one goal of location-based VR hosts to scientifically established design principles for social and collective adventures by supporting the impact of “collectively mastering an adventurous challenge”. In addition, our evaluation demonstrated that the multi-modal tracking, the free movement, as well as the multi-user features enabled natural interaction with other users and the environment, and thereby engendered a comfortable social experience.";"2018";"C. Wienrich and K. Schindler and N. Döllinqer and S. Kock and O. Traupe";"2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)";"https://doi.org/10.1109/VR.2018.8446575"
"Speaking Haptics: Proactive haptic articulation for intercommunication in virtual environments";"Communication is crucial in collaborative tasks. Multimodal strategies are commonly applied to complement, reinforce and disam-biguate information exchange. However, although multimodal communication is commonplace in Collaborative Virtual Environments, the proactive use of touch for intercommunication is surprisingly neglected regardless its importance for communication. In this paper, we look up to elements present in speech articulation to introduce the proactive haptic articulation as a novel approach for communication in CVEs. We defend the hypothesis that elements present in natural language, when added to the design of the vibro-tactile vocabulary, should provide an expressive medium for intercommunication. Moreover, we hypothesize that the ability to render tactile cues to a teammate will encourage users to adapt a given vocabulary spontaneously during its use. We implemented a case study around a collaborative puzzle task to demonstrate the use of such vocabulary. Results show that the proactive haptic articulation provided a way for participants to autonomously and dynamically adapt the provided tactile vocabulary to attend their communication needs during the task.";"2016";"V. A. de Jesus Oliveira and L. Nedel and A. Maciel";"2016 IEEE Virtual Reality (VR)";"https://doi.org/10.1109/VR.2016.7504748"
"An Experimental Study on the Performance of Haptic Data Transmission in Networked Haptic Collaboration";"In this paper, we present preliminary results of our ongoing networked virtual reality project by discussing the implementation and performance of an experimental haptic collaboration system; a networked haptic basketball game. In this game, online players feel like handling a real basketball since they are able to feel the sense of touch by using haptic interfaces. One of challenging issues in this implementation is haptic data transmission over the Internet to allow online multi-user play. Since haptic information is extremely sensitive to delay, jitter, and loss, the provision of timely transmission is critical. We carry out some experiments to compare the performance of the haptic data transmission under various delays, jitters, and losses of packets for two models; one is the position transfer model and the other is the force transfer model. We observe that loss of packets may reduce the force feedback in the Position Transfer Model and jitters are more sensitive than delays for both models.";"2007";"Y. You and M. Y. Sung and N. -J. Kim and K. Jun";"The 9th International Conference on Advanced Communication Technology";"https://doi.org/10.1109/ICACT.2007.358441"
"An iterative approach to optimizing multi-user networked haptic simulations";"Network-based collaborative virtual environments have attracted a great deal of interest in recent years. Stability and performance of such systems can significantly degrade due to the network delay, delay jitter and limited packet transmission rate. Building on our recent work in this area, we propose a systematic approach for designing distributed multi-user haptic simulation control systems to improve their stability and transparency. Three distributed two-user control schemes are presented and optimized for a given communication delay. In addition, an iterative procedure is developed for extending these methods to simulation environments involving more than two users by solving an optimization problem in each step. The effectiveness of the proposed methods are examined in two and three-user haptic simulations.";"2010";"S. Niakosari and S. Sirouspour";"2010 IEEE Haptics Symposium";"https://doi.org/10.1109/HAPTIC.2010.5444661"
"Virtual reality simulator for scoliosis surgery training: Transatlantic collaborative tests";"Scoliosis is a complex deformation of the spine requiring, in severe cases, a highly delicate and invasive surgical instrumentation operation to correct the spinal deformities. Available traditional tools for surgical training have major drawbacks for which virtual reality (VR) technologies and computer simulation can offer solutions. In this paper, we introduce a surgical simulator integrating a complex patient-specific biomechanical model into a VR immersive environment in a collaborative context, the first of its kind for scoliosis surgery training. We present the results for the fully collaborative AVE (audio visual environment) aspects of the simulator. Haptic forces are computed in the biomechanical model, but not yet available as a haptic feedback because of the high forces and torques characteristic of scoliosis surgery, requiring the use of a specifically designed haptic device (in progress). Transatlantic collaborative tests showed that, with our simulator, users on different continents can train collaboratively for scoliosis surgery and visualise the forces and the resulting correction. With the eventual addition of haptic devices, they will also be able to feel the forces remotely.";"2008";"M. Cote and J. -A. Boulay and B. Ozell and H. Labelle and C. -E. Aubin";"2008 IEEE International Workshop on Haptic Audio visual Environments and Games";"https://doi.org/10.1109/HAVE.2008.4685289"
"[DC] CoboDeck Pro: Advanced Encounter-Typed Haptic Device for Collaborative Architectural Design in Walkable VR";"Haptic feedback has consistently shown its potential to enhance task performance in virtual environments. In architectural design, the ability to sketch and conceptualize directly in Virtual Reality (VR), rather than relying on traditional methods, offers a transformative shift in the design process. Integrating haptic feedback into this process can further improve design practices. This dissertation introduces CoboDeck Pro, an advanced haptic device designed to simulate structural deformation, enabling more informed decision-making during early design stages. Additionally, the research addresses multi-user haptic interactions to foster interdisciplinary collaboration while reducing system costs per user. The proposed platform integrates into architectural design frameworks, making the process more collaborative, interactive, and responsive.";"2025";"M. Ghazanfari";"2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)";"https://doi.org/10.1109/VRW66409.2025.00441"
"Improving transparency in network-based haptics";"This paper is concerned with network-based multi-user haptic interaction using a distributed peer-peer control architecture. It proposes new quantitative measures for quantifying the fidelity of haptic simulations in such environments. User's perceived admittance and discrepancy among local copies of virtual objects are considered in defining these measures. A state prediction scheme is proposed to compensate for the negative effects of the network communication delay on the transparency and stability of the haptic simulation. An optimization problem is formulated for selecting the control gains that can enhance the performance while maintaining system stability. Numerical analysis and haptic interaction experiments are carried out to demonstrate the effectiveness of the proposed approach.";"2009";"S. Niakosari and S. Sirouspour";"World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems";"https://doi.org/10.1109/WHC.2009.4810885"
"Tactical Training Using Augmented Reality/Virtual Reality and Haptics";"This study investigates the effects of these immersive technologies on military personnel's training efficacy, efficiency, and safety. Virtual reality (VR) immerses users in artificial surroundings, augmented reality (AR) superimposes digital data on the actual world, and haptics adds tactile input to improve realism. These technologies work together to create training simulations that are incredibly realistic, adaptable, and closely mimic real-world situations. Examples of these scenarios include military operations, emergency response protocols, and technical maintenance jobs. This research emphasizes the advantages of AR, VR, and haptics in military training, including higher information retention, improved skill learning, and enhanced preparation for operational difficulties. It does this by doing a thorough assessment of the available literature and case studies. By eliminating the need for live exercises and giving students practical experience in authentic settings, these immersive technologies provide a secure and affordable substitute for conventional training approaches. Furthermore, employees stationed in remote or inaccessible regions may receive training nearly anytime, anywhere, thanks to the scalability and mobility of AR and VR devices. In the future, this field of study will focus on developing increasingly complex simulation environments and on utilizing advances in machine learning and artificial intelligence to build intelligent and adaptable training systems. Furthermore, haptics, AR, and VR are being widely used by allied agencies and military groups, which has great potential for collaborative training platforms and more equitable access to excellent training materials. Incorporating immersive technology into tactical and technical training signifies a fundamental change in military readiness and education, with far-reaching effects on the 21st-century armed forces' efficacy and adaptability.";"2024";"S. Vashisht";"2024 4th International Conference on Technological Advancements in Computational Sciences (ICTACS)";"https://doi.org/10.1109/ICTACS62700.2024.10840957"
"A Study of Communication Modalities in a Virtual Collaborative Task";"This paper examined the relative effectiveness of three communication modalities in a collaborative virtual environment. Communication modalities of verbal only (V), haptic only (H), and both (HV), were used in a 2D pointing task. A total of 36 participants were paired into 18 dyads. In each dyad, there was a supervisor and an acting agent. The supervisor used one of the three modalities to guide the acting agent to reach the target location. The time to task completion and the trajectory were recorded and analyzed. The results indicate that subjects using verbal only and haptic+verbal communication performed equally well in the collaborative pointing task. Subjects using haptic only communication spent more time and had longer path lengths than verbal only and haptic+verbal communication. Nevertheless, all three modalities were effective in communicating in a virtual collaborative task.";"2013";"J. Wang and A. Chellali and C. G. L. Cao";"2013 IEEE International Conference on Systems, Man, and Cybernetics";"https://doi.org/10.1109/SMC.2013.98"
"An efficient hybrid multicast transport protocol for collaborative virtual environment with networked haptic";"In recent years, we have witnessed a growing interest in synchronous collaboration based class of applications. Several techniques for collaborative virtual environments CVE, haptic, audio and visual environments C-HAVE were designed. However several challenging issues remain to be resolved before CVE and C-HAVE become a common place. In this paper, we focus upon applications that are based on closely coupled and highly synchronized haptic tasks that require a high- level of coordination among the participants. Four main protocols were designed to resolve the synchronization issues in such environments: the synchronous collaboration transport protocol (SCTP), the selective reliable transmission protocol (SRTP), the reliable multicast transport protocol (RMTP) and the scalable reliable multicast (SRM). While these four protocols have shown good performance for CVE and C-HAVE class of applications, none of these protocols was able to meet all the of the basic CVE requirement i.e., scalability, reliability, synchronization and minimum delays. In this paper, we present a hybrid protocol that is able to satisfy all the CVE and C-HAVE requirements and discuss its implementation";"2006";"A. Boukerche and H. Maamar";"2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006)";"https://doi.org/10.1109/HAVE.2006.283778"
"Collaborative haptic environment assessment";"Collaborative virtual environments (CVE) allow users from different geographical locations to execute a shared task by acting upon the same entities in the virtual world. Most of these environments rely on visual and auditory senses. The advances in haptic technology have opened a path for the sense of touch to be integrated into CVE. The main issue in a haptic CVE is maintaining state consistency despite the existence of network delays. We focus this research on studying the effects of network latency on task performance and we report our preliminary results.";"2009";"F. G. Hamza-Lup and B. M. Lambeth and J. LaPlant";"World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems";"https://doi.org/10.1109/WHC.2009.4810903"
"Virtual Laboratory: a virtual distributed platform to share and perform experiments";"This paper presents a distributed platform that gives researchers a framework to develop and deploy multi modal enabled experiments (haptic, audio, 3d vision), share them on the network with other research institutes and cooperate or remotely teleoperate with partners during the experiments. It gives also the possibility to see and collect significant data to be analyzed so that it's possible to achieve scientific results. All the experiments performed within the platform are real-time and fully interactive distinguishing the proposed Virtual Laboratory from other virtual laboratories that is possible to find in literature. The purpose of such platform is to enhance the speed of development of multi modal haptic enabled applications and improve the whole scientific experiment workflow. In particular the Virtual Laboratory platform is intended to supply a common shared place to perform inter-laboratories experiments and enhance the production of scientific results.";"2008";"P. Tripicchio and E. Ruffaldi and C. A. Avizzano and M. Bergamasco";"2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems";"https://doi.org/10.1109/HAPTICS.2008.4479963"
"QoE Assessment of Cooperative Work in Networked Virtual Environment with Haptics";"This paper examines influences of the network latency on cooperative work in a networked virtual environment with haptics by QoE (Quality of Experience) subjective and objective assessment. As the work, two users cooperatively carry an object in a networked maze system by using haptic interface devices. Assessment results demonstrate that as the network latency becomes longer, MOS (Mean Opinion Score) as a subjective measure becomes higher. We also clarify the relations between MOS and several objective measures by regression analysis.";"2021";"K. Z. Win and S. Thandar Aung and Y. Ishibashi and K. T. Mya";"2021 IEEE International Conference on Consumer Electronics-Taiwan (ICCE-TW)";"https://doi.org/10.1109/ICCE-TW52618.2021.9602999"
"Haptic-Feedback Ring Enabled Human-Machine Interface (HMI) Aiming at Immersive Virtual Reality Experience";"A haptic-feedback ring enabled glove-based human-machine interface (HMI) using a ring-shaped triboelectric nanogenerator (TENG) for finger bending sensing, and a lead zirconate titanate (PZT) thin film for effective haptic sense simulating, is developed for advanced interaction and collaborative operation in robotic manipulation and virtual/augmented reality (VR/AR) area. With the novel voltage integration method, the continuous finger motion can be captured with the minimalistic sensor design, which is difficult to be achieved by conventional contact-separation mode TENGs. With the haptic feedback function enriched by the PZT stimulator, the real sense of touch, compress and force can be successfully simulated, showing great potential in next-generation virtual entertainment and educational training applications.";"2021";"Z. Sun and M. Zhu and Z. Chen and X. Shan and C. Lee";"2021 21st International Conference on Solid-State Sensors, Actuators and Microsystems (Transducers)";"https://doi.org/10.1109/Transducers50396.2021.9495698"
"The Effect of Prediction on Collaborative Haptic Applications";"Haptic Collaborative Virtual Environments suffer from setbacks due to network lag when the users are geographically distributed. In this paper we propose an approach based on prediction to compensate for this lag The predictor can improvise the current state of a shared object in the presence of packet loss, guess the current network delay, and anticipate remote user's interaction strategy and virtual object's position/orientation based on the history. We demonstrate that our prediction approach improves the quality of collaboration in the session, especially when combined with other methods such as networking-level solutions.";"2006";"A. Boukerche and S. Shirmohammadi and A. Hossein";"2006 14th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems";"https://doi.org/10.1109/HAPTIC.2006.1627096"
"QoE assessment of will transmission using haptics: Influence of network delay";"This paper deals with collaborative work in which two users lift and move an object cooperatively to eliminate a target in a 3-D virtual space. In the work, the users transmit their wills about the movement direction of the object to each other by haptics. By experiment, we investigate the influence of network delay on will transmission using haptics. As a result, we demonstrate that it becomes more difficult to transmit the wills accurately as the network delay increases.";"2013";"P. Huang and Q. Zeng and Y. Ishibashi";"2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE)";"https://doi.org/10.1109/GCCE.2013.6664889"
"Centralized multi-user multi-rate haptic cooperation using wave transformation";"This paper proposes a multi-rate control strategy for multi-user haptic cooperation. In the proposed architecture, the virtual environment simulation runs on a central server to which all users are connected as clients. Users send position commands to and receive forces from the centralized virtual object that they cooperatively manipulate via wave-based controllers. After deriving the passivity condition for the multi-rate wave transformation, the paper investigates the stability of the cooperation between two users within a multi-rate discrete-time state space framework. The analysis predicts that clients can cooperatively manipulate much stiffer centralized virtual objects when connected to the server using wave transformations than when connected using virtual coupling. Experiments performed in a 1 degree of freedom (DOF) virtual environment confirm the analytical results.";"2009";"N. Yasrebi and D. Constantinescu";"2009 International Conference on Mechatronics and Automation";"https://doi.org/10.1109/ICMA.2009.5246758"
"Networked Haptic Virtual Environments Supporting Ultra High Resolution Display";"With HPC (high performance computing) and scientific computing, it has been possible to produce a large amount of data. To easily analyze those data and collaborate on it, visualization in terms of ultra high resolution is desired. However, in order to combine a HPC system with a high resolution display system, high system resource is required. This paper shows an example of a system combining both a haptic system requiring high speed computing and a ultra high resolution display system. Thus, in this paper, we realize a networked haptic virtual environment system over ultra high resolution tiled display. With a networked haptic virtual environment supporting ultra high resolution display, users can feel sense of touch with haptic device and see visuals in ultra high resolution manner with network tiled display when users collaborate in shared virtual environment together. In addition, in this paper, a frame rate control scheme, making the networked haptic virtual environment system over ultra high resolution display stable, is proposed.";"2009";"S. Son and V. Ramachandra and J. Kim";"2009 11th IEEE International Conference on High Performance Computing and Communications";"https://doi.org/10.1109/HPCC.2009.92"
"A design aid and real-time measurement framework for Virtual collaborative simulation Environment";"Distributed Virtual Environment (DVE) has attracted much attention in recent years due to the rapid advances in the areas of E-learning, Internet gaming, human-computer interfaces, and etc. However, the complexity of designing an efficient DVE greatly challenges today's researchers. Indeed, how to effectively measure a DVE or the design of DVE plays an important role in progressively guiding the DVE design. Meanwhile, the performance of protocols and schemes used in an existing DVE cannot be easily measured straightforwardly. Traditionally, simulation tools are involved to predict the performance of the DVE system or any used protocols; however, existing tools have limited capabilities in terms of accurately capturing the real-world performance. This is due to the statically configured simulations, hard-to-model hardware devices (such as haptic devices, mobile devices), single processor's execution of the simulations, and etc. Moreover, there exists no integrated simulating and measuring framework that can effectively support model reuse, dynamic reconfiguration of a simulation, real devices in the simulation loop (statically or run-time), and distributed simulation execution, just to name a few. In this paper, we propose and implement an integrative simulation and measuring framework; in particular, we design a generic real-time service oriented virtual simulation system which can effectively measure the real time performance of distributed virtual environments and virtual reality based applications. The main goal of our proposed framework lies in providing accurate and near-real-world measurements of a DVE and any related protocols, so that a highly cost-efficient DVE system design can be achieved. Moreover, our framework uses the Experimental Frame concept to separate simulation services from design models so that model reuses, model formalization and model validation can all be done within one layer. The idea of using experimental frame also makes possible a hardware-in-the-loop type of simulation, which is quite useful in DVE including haptic virtual environment, sensor network based virtual environment, and etc. As a case study, we investigate a QoS-aware adaptive load balance algorithm using our framework; and our real-time simulation results clearly indicate that the algorithm outperforms others in a near real-world scenario.";"2010";"M. Zhang and H. Xie and A. Boukerche";"2010 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum (IPDPSW)";"https://doi.org/10.1109/IPDPSW.2010.5470791"
"Investigating Trainee Perspectives on Virtual Reality Environments: An In-Depth Examination of Immersive Experiences with Haptic Feedback Vibration";"This research investigates trainee reflections on Virtual Reality Environments (VREs) within educational training centers, aiming to understand their experiences, perceptions, and preferences. The study focuses on the impact of haptic feedback vibrations, examining both their general effects during VRE interactions and the specific influence of adaptable vibration configurations triggered by user errors. A convenience sample of 81 participants/trainees, 41 from the computer science and 40 from the aviation engineering departments of a major higher education institution in the U.A.E., was used to run four variations of the same VRE, with two from each field. Results indicate that participants largely embraced the VRE experience, reporting feelings of contentment, joy, and competence. Haptic feedback, particularly in non-adaptable forms, was acknowledged as enhancing the immersive experience. However, the study suggests that further research is needed to explore the nuanced role of adaptable vibration, especially in more complex interactions. Notably, participants expressed a preference for a blended approach, advocating for both VREs and physical labs in their training. The study acknowledges limitations, such as the predominantly single-user focus, and recommends future research extensions into collaborative VRE settings, more intricate interactions, and potential technical issues in multi-user scenarios. Overall, this research sheds light on the evolving landscape of educational training, emphasizing the importance of understanding trainee perspectives to optimize the integration of VREs in learning environments.";"2024";"O. K. Xanthidou and N. Aburumman and H. Ben-Abdallah";"2024 IEEE International Systems Conference (SysCon)";"https://doi.org/10.1109/SysCon61195.2024.10553420"
"The use of a proximity agent in a collaborative virtual environment with 6 degrees-of-freedom voxel-based haptic rendering";"The extension of software designed primarily for a single-user haptic environment to a multi-user collaborative environment presents challenges on several fronts. This paper discusses the use of a proximity agent to overcome problems associated with the time allowances for collision detection and subsequent force/torque generation between pairs of dynamic objects in a voxel-based collaborative haptic environment.";"2005";"A. Prior and K. Haines";"First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. World Haptics Conference";"https://doi.org/10.1109/WHC.2005.137"
"Haptic guides in cooperative virtual environments: Design and human performance evaluation";"In this paper we simulate the use of two string based parallel robots in cooperative manipulation task. Two users standing in front of a large screen operate each robot. We propose two haptic guide models, and investigate their effects on cooperation, co-presence and users performance. In addition we also examine the effect of object-based force feedback in cooperative work. Ten volunteer subjects had to cooperatively perform a peg-in-hole task. Results revealed that haptic guides have a significant effect on task execution. They not only increase users performance but also enhance the sense of co-presence and awareness. Our investigations will help in the development of VR systems for cooperative assembly, surgical training and rehabilitation.";"2010";"S. Ullah and P. Richard and S. Otmane and M. Naud and M. Mallem";"2010 IEEE Haptics Symposium";"https://doi.org/10.1109/HAPTIC.2010.5444616"
"Haptic-enabled Collaborative Training with Generalized Force and Position Mappings";"A control framework is introduced for collaborative training in haptic-enabled virtual environments. To increase the versatility of the proposed approach, the haptic interface control is separated from the virtual environment simulation, which can be of either impedance or admittance-type. Adaptive nonlinear controllers are developed to enforce desired linear-time-invariant and/or nonlinear static mappings among the users and the virtual task environment positions and forces. The controllers account for nonlinear models of the haptic devices and can cope with uncertainties present in the users and haptic devices dynamics. The performance and closed-loop stability of the proposed methods are demonstrated in two steps. First, using a Lyapunov analysis, the tracking behavior of the system is shown. Then given a priori known bounds on the users and environment parameters, the robust stability of the closed-loop system is analyzed based on the Nyquist envelops of interval plants and an off-axis circle criterion. Experimental results demonstrate the effectiveness of the proposed controllers.";"2008";"S. Moghimi and S. Sirouspour and P. Malysz";"2008 Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems";"https://doi.org/10.1109/HAPTICS.2008.4479960"
"Challenges in the Deployment of Visuo-Haptic Virtual Environments on the Internet";"Haptic sensory feedback has been shown to complement the visual and auditory senses, improve user performance and provide a greater sense of togetherness in collaborative and interactive virtual environments. However, we are faced with numerous challenges when deploying these systems over the present day Internet. The most significant of these challenges are the network performance limitations of the Wide Area Networks. In this paper, we offer a structured examination of the current challenges in the deployment of haptic-based distributed systems by analyzing the recent advances in the understanding of these challenges and the progress that has been made to overcome them.";"2010";"J. Norman and F. G. Hamza-Lup";"2010 Second International Conference on Computer and Network Technology";"https://doi.org/10.1109/ICCNT.2010.88"
"Spatial User Interfaces for Large-Scale Projector-Based Augmented Reality";"Spatial augmented reality applies the concepts of spatial user interfaces to large-scale, projector-based augmented reality. Such virtual environments have interesting characteristics. They deal with large physical objects, the projection surfaces are nonplanar, the physical objects provide natural passive haptic feedback, and the systems naturally support collaboration between users. The article describes how these features affect the design of spatial user interfaces for these environments and explores promising research directions and application domains.";"2014";"M. R. Marner and R. T. Smith and J. A. Walsh and B. H. Thomas";"IEEE Computer Graphics and Applications";"https://doi.org/10.1109/MCG.2014.117"
"Cooperation in virtual environments with individual views";"When users are interacting collaboratively in a virtual environment it cannot be guaranteed that every user has the same input device or that they have access to the same information. Our research aims at understanding the effects of such asymmetries on the user embodiment in collaborative virtual environments (CVEs). In order to do this, we have developed a prototyping platform for cooperative interaction between two users. To change the information a user has, we are incorporating “special views”[1] for each person. Also, an easily expandable array of input devices is supported, e.g. Mouse/Keyboard, Novint Falcon, Razer Hydra, ART Flightstick, Leap Motion, etc. Those devices can provide additional information to a user, like haptic feedback, but they can also be used to restrain a user, for example by providing a device with less degrees of freedom.";"2015";"V. Küszter and G. Brunnett and D. Pietschmann";"2015 IEEE Virtual Reality (VR)";"https://doi.org/10.1109/VR.2015.7223372"
"Virtual Reality with Haptic Gloves for Human-robot Collaborative Assembly";"Virtual reality (VR) is an emerging industry 4.0 technology to enhance flexibility, efficiency, and quality to everincreasing economic competition. Autonomous robots can enhance the efficiency significantly in human-robot collaborative (HRC) assembly via VR components. A hybrid automation is taking benefit from the synergistic effect of HRC and the use of continuous simulations offer safe virtual space for validation. However, conventional simulations don’t allow to experience the production system as an end-user in an immersive environment. This paper presents the robot experiment on user interface design in unified framework for HRC assembly in a shared workspace. The experiment aims to verify the effectiveness of visual and haptic cues in various forms that convey the robot intent to human. A virtual laboratory was set up containing sense gloves and virtual input and output devices. The sense gloves were integrated into Unity and the SteamVR to perform the 3D tasks. To ensure real time interaction when capturing virtual objects, the virtual glove from the Unity libraries was the preferred option to generate the required events. Finally, the developed gesture control system allows operators to control an industrial robot via the VR environment.";"2025";"C. -J. Lin and R. -S. Liu";"2025 IEEE International Conference on Advanced Robotics and its Social Impacts (ARSO)";"https://doi.org/10.1109/ARSO64737.2025.11124945"
"A Physics-Based Virtual Reality Haptic System Design and Evaluation by Simulating Human-Robot Collaboration";"Recent advancements in virtual reality (VR) technology facilitate tracking real-world objects and users' movements in the virtual environment (VE) and inspire researchers to develop a physics-based haptic system (i.e., real object haptics) instead of computer-generated haptic feedback. However, there is limited research on the efficacy of such VR systems in enhancing operators’ sensorimotor learning for tasks that require high motor and physical demands. Therefore, this study aimed to design and evaluate the efficacy of a physics-based VR system that provides users with realistic cutaneous and kinesthetic haptic feedback. We designed a physics-based VR system, named PhyVirtual, and simulated human–robot collaborative (HRC) sequential pick-and-place lifting tasks in the VE. Participants performed the same tasks in the real environment (RE) with human–human collaboration instead of human–robot collaboration. We used a custom-designed questionnaire, the NASA-TLX, and electromyography activities from biceps, middle, and anterior deltoid muscles to determine user experience, workload, and neuromuscular dynamics, respectively. Overall, the majority of responses (>65%) demonstrated that the system is easy-to-use, easy-to-learn, and effective in improving motor skill performance. While compared to tasks performed in the RE, no significant difference was observed in the overall workload for the PhyVirtual system. The electromyography data exhibited similar trends (p > 0.05; r > 0.89) for both environments. These results show that the PhyVirtual system is an effective tool to simulate safe human–robot collaboration commonly seen in many modern warehousing settings. Moreover, it can be used as a viable replacement for live sensorimotor training in a wide range of fields.";"2024";"S. T. Mubarrat and A. Fernandes and S. K. Chowdhury";"IEEE Transactions on Human-Machine Systems";"https://doi.org/10.1109/THMS.2024.3407109"
"Haptic Event Prioritization and Network Adaptation Scheme for Collaborative Virtual Environments";"In this paper, a network adaptation scheme that involves a haptic event prioritization concept is presented. It classifies the haptic events and efficiently adapts the transmission and error rate according to the importance of the haptic events. According to the experimental results, the proposed scheme provides higher haptic interaction quality with a shorter playout delay and a lower transmission rate compared to existing networked haptic transport schemes.";"2007";"S. Lee and J. Kim";"IEEE GLOBECOM 2007 - IEEE Global Telecommunications Conference";"https://doi.org/10.1109/GLOCOM.2007.411"
"Cooperative control with haptic visualization in shared virtual environments";"A distributed PHANToM-based system for collaborative haptic visualization of a VR crank is presented. Physical IDOF crank model providing realistic kinaesthetic sensations of inertia and viscosity is described. Theoretical and experimental kinematic trajectory patterns are compared for the case of cooperative two-arm human movements. Nonvisual visualization applications of the system are discussed.";"2004";"I. Goncharenko and M. Svinin and S. Matsumoto and Y. Masui and Y. Kanou and S. Hosoe";"Proceedings. Eighth International Conference on Information Visualisation, 2004. IV 2004.";"https://doi.org/10.1109/IV.2004.1320196"
"Haptic Communication to Support Biopsy Procedures Learning in Virtual Environments";"In interventional radiology, physicians require high haptic sensitivity and fine motor skills development because of the limited real-time visual feedback of the surgical site. The transfer of this type of surgical skill to novices is a challenging issue. This paper presents a study on the design of a biopsy procedure learning system. Our methodology, based on a task-centered design approach, aims to bring out new design rules for virtual learning environments. A new collaborative haptic training paradigm is introduced to support human-haptic interaction in a virtual environment. The interaction paradigm supports haptic communication between two distant users to teach a surgical skill. In order to evaluate this paradigm, a user experiment was conducted. Sixty volunteer medical students participated in the study to assess the influence of the teaching method on their performance in a biopsy procedure task. The results show that to transfer the skills, the combination of haptic communication with verbal and visual communications improves the novices’ performance compared to conventional teaching methods. Furthermore, the results show that, depending on the teaching method, participants developed different needle insertion profiles. We conclude that our interaction paradigm facilitates expert-novice haptic communication and improves skills transfer; and new skills acquisition depends on the availability of different communication channels between experts and novices. Our findings indicate that the traditional fellowship methods in surgery should evolve to an off-patient collaborative environment that will continue to support visual and verbal communication, but also haptic communication, in order to achieve a better and more complete skills training.";"2012";"A. Chellali and C. Dumas and I. Milleville-Pennel";"Presence";"https://doi.org/10.1162/PRES_a_00128"
"User's behaviours in a collaborative task - real vs. virtual environments";"This paper reports the results of a pilot study evaluating the performance of healthy volunteers working in pairs to fulfil a collaborative task in both real and virtual environments. The main aim of this study is to investigate how different environments (real vs. virtual) and communication modalities (with vs. without talking to each other) affect the quality of interaction between humans. The results suggest that doing the task in the virtual world was more difficult and required more effort to complete than doing it in the real world even though the virtual world task was reported to be more engaging. Participants employed different strategies in each environment in order to successfully complete each task. The results from this study could be used to develop a more elaborate model that predicts each user's behaviour in a collaborative task, which could in turn be used for remote interaction between users mediated by robotic/haptic interfaces.";"2016";"H. H. Le and M. J. Loomes and R. C. V. Loureiro";"2016 6th IEEE International Conference on Biomedical Robotics and Biomechatronics (BioRob)";"https://doi.org/10.1109/BIOROB.2016.7523745"
"Revolutionizing Inclusive STEM Education: A Virtual Reality Platform for Enhanced Learning Across All Disciplines";"STEM education refers to an integrated approach to teaching and learning in four specific disciplines: Science, Technology, Engineering, and Math. Instead of teaching all these as sections, STEM education just means the integration of these four in order to foster learning by making use of practical tasks or problems. The drawbacks of conventional STEM education can be implemented by a Virtual Reality (VR) that provides better learning solutions for everyone. Through this platform it is possible to create actual and virtual laboratories which are entirely interactive and immersive specifically within the context of STEM subjects. They include haptic feedback, tutor guided tutorials, and collaborative learning environments hence offering a poly-ed perspective. This way, the platform responds to the learners' impairments and grants deaf and mute students equal opportunities to gain practical experience side by side with theoretical knowledge application. This can go a long way in helping teachers accommodate learners, create better understanding of STEM and ultimately help ignite passion in the subject. Additionally, it develops students for competition in volatile disciplines, provides equal opportunities in STEM education and training for minorities.";"2025";"M. G and V. G and S. K and A. K and M. p. S. A";"2025 International Conference on Data Science and Business Systems (ICDSBS)";"https://doi.org/10.1109/ICDSBS63635.2025.11031660"
"The virtual reality simulator-based catheter training system with haptic feedback";"The endovascular surgery benefits patients due to the miniature wound and fast healing, but to achieve this kind of goal need the doctor with superb skill in order to not made damage to the patients. A training system is desperately in need. The training system is cooperated with VR simulator system, which could simulate the movement of the catheter. To get the novice surgeons get trained, a controlling device makes training system effective. At the same time, the feedback system also provides advantages for training. The performance is evaluated from the displacement in VR system and force feedback from haptic device. The results demonstrate that the operation error is less than 10%. The purposed training system provides a effective way which combined the VR catheter system and force feedback system.";"2017";"S. Guo and M. Yu and Y. Song and L. Zhang";"2017 IEEE International Conference on Mechatronics and Automation (ICMA)";"https://doi.org/10.1109/ICMA.2017.8015939"
"Virtual Reality and Haptic Cardiopulmonary Resuscitation Training Approaches: A Review";"Cardiac arrest is a leading cause of death worldwide preventable with timely application of cardiopulmonary resuscitation (CPR). The American Heart Association CPR guidelines recently have an increased focus on quality of consistent chest compressions and highlighted the need for frequent refresher courses. Literature has shown that standard training manikins do not accurately represent human torso compression forces. Virtual reality (VR) and augmented reality (AR) technologies can simulate or enhance training environments and have shown promise for CPR training. Haptics is the touch element of virtual experiences and the literature has suggested that haptics can produce higher fidelity force feedback over standard training manikins. This review aims to determine the state of research of virtual and AR and haptic-enabled CPR training systems. VR approaches examined feedback, visual kinesthetic manipulation, and gamification. Systems using AR have examined the potential benefits of real-time feedback and quick reference. Haptic approaches have examined different mechanisms and design principles for reproducing realistic human CPR. Hybrid systems explore collaborative training and methods for immersion. These systems offer the potential for immersive training and realistic haptic rendering. However, to reach widespread adoption they must overcome the limitations of cost and mechanical complexity.";"2022";"T. Everson and M. Joordens and H. Forbes and B. Horan";"IEEE Systems Journal";"https://doi.org/10.1109/JSYST.2020.3048140"
"Simulation and Performance Evaluation of a Distributed Haptic Virtual Environment Supported by the CyberMed Framework";"Performance evaluation on Distributed Haptic Virtual Environments (DHVEs) became important to understand the new Internet requirements for supporting multisensorial and real-time collaborative applications. This paper presents the results of simulation and performance analysis of the CyberMed framework. The main goal of this experiment is to evaluate the real conditions of CyberMed when executed over a non-dedicated hybrid network, like the Internet, comparing its results with other similar works found in the literature";"2011";"P. V. F. Paiva and L. S. Machado and J. C. d. Oliveira";"2011 XIII Symposium on Virtual Reality";"https://doi.org/10.1109/SVR.2011.16"
"Human-Computer Interaction: Innovations and Challenges in Virtual Reality";"In an effort to shed light on the advances and difficulties that are shaping the area of Virtual Reality (VR), this research paper digs into the ever-evolving world of Human-Computer Interaction (HCI) within the context of VR. We have found important insights with theoretical and practical applications via a careful research technique comprising mathematical modelling, data collecting, and empirical analysis. Through our investigation of new technologies, we have shown the revolutionary potential of haptic feedback systems in VR settings. Our results, backed by a solid mathematical model, provide light on the measurable effect of haptic feedback and suggest it has the potential to radically alter user experiences in fields as diverse as gaming, instruction, and treatment. At the same time, we have overcome a number of obstacles inherent to virtual reality human-computer interaction, including motion sickness. Our mathematical model of motion sickness and its treatment lays the groundwork for creating VR experiences that are both enjoyable and safe for a wider range of users. This study highlights the ethical implications of VR HCI, highlighting the importance of responsible development and deployment in addition to advances and problems. To make sure that the advantages of this gamechanging technology are used in a responsible manner, we discuss issues like privacy, informed consent, and the possibility for addiction in VR. Our results, as we reach the end of our trip, are both a celebration of potential and a guide for where VR HCI is headed. They motivate more research into inclusive and human-centered design, personalized motion sickness prevention, and cutting-edge haptic feedback technologies. To further lead the development of VR HCI, we advocate for continuous multidisciplinary cooperation and the adoption of thorough ethical rules and regulations.";"2024";"C. Anitha and P. l. Soundarraj and N. Geethanjali and C. Boopathy and A. N. Venkatesh and I. M. Krishna";"2024 Ninth International Conference on Science Technology Engineering and Mathematics (ICONSTEM)";"https://doi.org/10.1109/ICONSTEM60960.2024.10568875"
"On supporting collaborative haptic interactions with physically-based 3D deformations";"Haptic-enabled collaborative systems have long been limited to 3D rigid models only, primarily due to slow force calculations, long-time deformable simulations and large communication loads. In this paper, we propose a novel system to support real-time sharing of haptic feedbacks and deformable simulations of physically-based 3D models in a distributed virtual environment. Particularly, adopting a spectral method, we can effectively complete force calculation and deformable simulation based on user manipulations so as to achieve real-time streaming with low network loads. In addition, we explain how our system works under two different collaborative network architectures, and analyze them separately. The experimental results confirm the validity of our approach and prove its effectiveness. Our research has a wide range of applications in such fields as education (e.g., distributed, virtual class rooms) and entertainment (e.g., gaming).";"2010";"Z. Tang and Y. Yang and X. Guo and B. Prabhakaran";"2010 IEEE International Symposium on Haptic Audio Visual Environments and Games";"https://doi.org/10.1109/HAVE.2010.5623988"
"Passive shared virtual environment for distributed haptic cooperation";"For distributed haptic cooperation systems, this paper develops a framework for virtual environments such that the design of the coordinating controllers is decoupled from the network topology and the communication issues. The discrete-time n-port passivity of the shared virtual object (SVO) is presented when n SVO copies are distributed on an undirected and connected communication topology with unreliable data transmission. Wave nodes as passive network elements can be implemented on multilateral wave-based communication architecture to passively distribute power across the network. In this note, the wave node scheme introduced in [16] is employed to construct a passive wave-based network architecture in order to passively interconnect multiple discrete-time port-Hamiltonian local SVO copies alongside their coordinating controllers. The performance analysis shows that the proposed network architecture: (i) possesses n-port passivity over a network with time-varying delay and packet-loss; (ii) is lossless when subjected to communications with no time delay; and (iii) offers less dissipation comparing to the network structures built based on the node scheme proposed in [18]. Simulations in which a VO is shared among four peers across a network with constant and varying time-delay validate the analysis.";"2014";"R. Rakhsha and D. Constantinescu";"2014 IEEE Haptics Symposium (HAPTICS)";"https://doi.org/10.1109/HAPTICS.2014.6775458"
"Experiments for a Collaborative Haptic Virtual Reality";"In this paper, we present preliminary results of our ongoing networked virtual reality project by discussing the implementation and performance of a networked haptic game. In this game, online players feel like handling a real basketball since they are able to feel the sense of touch by using haptic interfaces. One of challenging issues in this implementation is haptic data transmission over the Internet to allow online multi-user play. Since haptic information is extremely sensitive to delay and jitter, the provision of timely transmission is critical. We carry out experiments to compare the performance of the haptic data transmission when using UDP (User Datagram Protocol) and TCP (Transmission Control Protocol), and observe that neither UDP nor TCP is able to satisfy QoS (Quality of Service) requirements of the haptic transmission. As a further study, we plan to investigate some alternative haptic data transmission schemes.";"2006";"M. Y. Sung and Y. Yoo and K. Jun and N. -j. Kim and J. Chae";"16th International Conference on Artificial Reality and Telexistence--Workshops (ICAT'06)";"https://doi.org/10.1109/ICAT.2006.60"
"Virtual Coupling Schemes for Position Coherency in Networked Haptic Environments";"In networked haptic environments, multiple users remotely collaborate sharing the same virtual space. Such environments are used in surgical simulation training, maintenance task training, etc. Maintaining position coherency between the copies of the virtual object in these environments is necessary to achieve consistency in collaboration, especially in the presence of time delays between users. Client-server architecture is widely used to maintain position coherency in networked haptic environments. Such methods introduce a round trip delay for each user and also the collaboration depends on the client's ability to maintain communication with the server. In peer-to-peer architecture where the information from each user is multicasted to all other users, time delay is reduced to half compared to client-server based methods. It is also the most difficult method for maintaining position coherency. Of the three virtual coupling schemes introduced to maintain position coherency in this paper, two utilize a peer-to-peer architecture. The performance of the schemes using peer-to-peer architecture for constant time delays was compared to the virtual coupling scheme representing the client-server method. Experimental results demonstrate that one of the virtual coupling schemes has a comparable performance to the server-based method";"2006";"G. Sankaranarayanan and B. Hannaford";"The First IEEE/RAS-EMBS International Conference on Biomedical Robotics and Biomechatronics, 2006. BioRob 2006.";"https://doi.org/10.1109/BIOROB.2006.1639197"
"Combining Contact Models With Perceptual Data Reduction for Efficient Haptic Data Communication in Networked VEs";"In cooperative networked virtual environments, haptic rendering enables joint haptic interaction with virtual objects and, thus, shared touch experiences among multiple users. In case of an underlying packet-based communication network (e.g., the Internet), minimizing the end-to-end delay, with the goal of preventing instability of the involved control loops, results in high packet rates. Previously proposed perceptual data reduction approaches address this challenge and satisfy the strict delay constraints. However, significantly increased packet rates still occur during contact events. We present a novel event-based coding scheme based on a distributed haptic-rendering framework that integrates model-based distributed haptic rendering with perceptual data reduction. We also present a comprehensive haptic contact model for signals with multiple degrees of freedom. Furthermore, we show that the integration of event-triggered force transient models from event-based haptics into our local contact model is instrumental for generating convincing haptic feedback. Psychophysical experiments reveal that the approach presented herein allows us to push the data reduction performance beyond what is normally achievable by perceptual data reduction schemes alone while significantly improving the quality of haptic contact feedback.";"2011";"J. Kammerl and R. Chaudhari and E. Steinbach";"IEEE Transactions on Instrumentation and Measurement";"https://doi.org/10.1109/TIM.2010.2065670"
"Discrimination of Virtual Environments Under Visual and Haptic Rendering Delays";"Many virtual reality systems have a distributed structure for certain purposes such as more computational power, tele-presence, collaboration, and portability. However, network delays are inevitable in the distributed structure and often make sensory information delivered behind time to the user. In the literature, the effect of network delays on the quality of virtual environments has been considered mostly with respect to task performances. In this paper, we pay attention to whether perceptual artifacts caused by network delays are perceptible by the user, which is a more stringent criterion than the degradation of task performance. We examined minimum perceptible visual and/or haptic rendering delays by measuring their discrimination thresholds between normal and delayed virtual environments with and without a task, and report the results in this paper. We also provide a simple guideline for determining whether some active delay compensation algorithms are required in a distributed virtual reality system by comparing representative network delays to the measured discrimination thresholds.";"2007";"I. Lee and S. Choi";"2007 Frontiers in the Convergence of Bioscience and Information Technologies";"https://doi.org/10.1109/FBIT.2007.124"
"Artistic Exploration of Stop-Motion Animation in Virtual Reality: Spatializing the Analog Techniques of 2D Replacement and Object Animation by Using Digital Cutout and Realtime Rendering";"The art-based research project VRinMotion explores the implemen-tation of analog stop-motion animation in virtual reality. ExperiMotion 1, the first of four workshops, focused on 2D replacement and object animation in VR, presenting a unique challenge in creating a 3D virtual space with flat animation techniques. The research team discussed and artistically tested various new ideas and methods focusing, i.a., on haptic properties and the role of stop-motion loops. Furthermore, it developed frameworks in Unity3D and TouchDe-signer for prototyping and implementing the project requirements. Finally, the team explored how the use of sound may improve spatial perception in VR and how separating the artistic process into dis-tinct modules allows several individuals to collaborate on the same project.";"2023";"F. Bruckner and J. Salhofer and C. Gürtler and M. Hattler and M. Husinsky";"2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)";"https://doi.org/10.1109/VRW58643.2023.00009"
"Scene Synchronization for Real-Time Interaction in Distributed Mixed Reality and Virtual Reality Environments";"Advances in computer networks and rendering systems facilitate the creation of distributed collaborative environments in which the distribution of information at remote locations allows efficient communication. One of the challenges in networked virtual environments is maintaining a consistent view of the shared state in the presence of inevitable network latency and jitter. A consistent view in a shared scene may significantly increase the sense of presence among participants and facilitate their interactivity. The dynamic shared state is directly affected by the frequency of actions applied on the objects in the scene. Mixed Reality (MR) and Virtual Reality (VR) environments contain several types of action producers including human users, a wide range of electronic motion sensors, and haptic devices. In this paper, we propose a novel criterion for categorization of distributed MR/VR systems and present an adaptive synchronization algorithm for distributed MR/VR collaborative environments. In spite of significant network latency, results show that for low levels of update frequencies the dynamic shared state can be kept consistent at multiple remotely located sites.";"2004";"F. G. Hamza-Lup and J. P. Rolland";"Presence";"https://doi.org/10.1162/1054746041422343"
"Using Industrial Robots as Haptic Devices for VR-Training";"Many VR-training application require the integration of haptics, i.e. for surgical training. However, surgical VR-training is still limited to minimal invasive surgeries. For surgeries where high forces occur, like hip replacement, no VR-training applications have been developed. One cause for this is the lack of appropriate haptic devices which can deliver high forces. Novel industrial collaborative robots can provide high forces. Although, they lack control interfaces allowing to use them as haptic devices. We present 4 approaches for using these robots as general, multipurpose haptic input and output devices. The implemented approach was integrated into a VR hip replacement training application. An initial assessment demonstrates the general feasibility of our solution.";"2018";"S. Knopp and M. Lorenz and L. Pelliccia and P. Klimant";"2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)";"https://doi.org/10.1109/VR.2018.8446614"
"Dynamic strategies of conflict resolution on human perception of equality within multi-user collaborative virtual environments";"Multi-user collaborative virtual environments (VEs) need strategies of conflict resolution to handle simultaneous interaction with shared objects. Current strategies are first-come-first-serve (FCFS) and predefined static priority of each user. These strategies cannot provide each user with a perceived equal opportunity of interaction and often lead to perceived unfairness to abandon collaboration. To offer an equal opportunity, we created a dynamic priority (DP) strategy and compared the strategy with the FCFS strategy based upon subjective perception of multiple users. Visual or haptic (pertinent to the sense of touch) cues assisted each user to perceive his/her gaining of interaction. We observed that the DP strategy yielded significantly an equal opportunity of interaction. The haptic cue offered lower variations in perceiving the equality than the visual cue under the DP strategy. These observations imply a potential application of the DP strategy in a VE, where various experts require equal opportunities in collaboration.";"2013";"A. Erfanian and T. Zeng and Y. Hu";"9th IEEE International Conference on Collaborative Computing: Networking, Applications and Worksharing";"https://doi.org/10.4108/icst.collaboratecom.2013.254052"
"Collaborative Haptic Exploration of Dynamic Remote Environments";"Haptic perception is an important modality in reinforcing the presence of virtual or remote targets, but providing haptic feedback of dynamic environments still remains a challenging task. We address the issue of haptic telepresence systems by improving and integrating two independent approaches: real-time haptic rendering of unstructured spatial data and collaborative interaction with a remote partner. Contact with physical constraints is directly estimated from streaming point-cloud data without surface reconstruction, and haptic guidance cues that restrict or promote the users motion can be provided by both predefined triggers and gesture-based input from a helper. Through a user study with a proof-of-concept prototype, the authors show that the proposed approach significantly improves the performance of remote exploration tasks while enabling stable haptic interaction with real-world spatial data.";"2018";"S. Kim and J. Park";"IEEE Computer Graphics and Applications";"https://doi.org/10.1109/MCG.2018.053491733"
"A haptic virtual environment for industrial training";"This paper presents a haptic virtual environment application for industrial training. A choice of haptic devices. (PHANTOM and CyberForce/CyberGrasp) is used to perform a training exercise with the possibility of sharing virtual scene states with remote users to allow collaboration and remote observation. Furthermore, the application employs video textured avatars to improve face-to-face communication, a novel area of interest management mechanism to reduce network bandwidth usage, standard encoding of state updates for compatibility and is used in conjunction with various projection technologies such as a head mounted display, CAVE configuration or regular PC monitor. The paper serves to underline the various components needed for the development of a haptic virtual environment and our experiences in doing so.";"2002";"M. Hosseini and F. Malric and N. D. Georganas";"IEEE International Workshop HAVE Haptic Virtual Environments and Their";"https://doi.org/10.1109/HAVE.2002.1106909"
"Effect of Packet Loss on Collaborative Haptic Interactions in Networked Virtual Environments: An Experimental Study";"It has been widely demonstrated that haptic interaction can enrich the sense of copresence of distributed users and improve their performance in collaborative virtual environments (CVEs). However, the influence of network traffic on haptic collaboration, particularly packet loss in haptic data streams, is still largely unknown. In order to investigate this effect, we designed and conducted a series of experiments on a simulated lossy network. First, a single-user interactive task was designed to estimate the just- noticeable packet loss threshold in terms of the length of burst loss (LBL). Second, a CVE was developed in which two users are required to work together on a goal-directed task through haptic collaboration. Experiments were performed to evaluate the users' task performance at different packet loss rates and their perception using subjective measurements. Finally, the effect of packet loss combined with network latency was investigated. The findings are: (1) the threshold LBL value for haptic discontinuity to become noticeable is 60.18 ms; (2) haptic collaboration performance is sensitive to packet loss rate; and (3) while the combined effect of packet loss and communication delay adversely affects collaborative haptic interactions, the influence due to packet loss rate is dominant when the delay is below a certain threshold. These results can serve as a guiding reference for the design and development of virtual telepresence systems with rich haptic collaborations.";"2013";"J. Qin and K. Choi and R. Xu and W. Pang and P. Heng";"Presence";"https://doi.org/10.1162/PRES_a_00132"
"Distributed Haptic Interactions with Physically Based 3D Deformable Models over Lossy Networks";"Researchers have faced great challenges when simulating complicated 3D volumetric deformable models in haptics-enabled collaborative/cooperative virtual environments (HCVEs) due to the expensive simulation cost, heavy communication load, and unstable network conditions. When general network services are applied to HCVEs, network problems such as packet loss, delay, and jitter can cause severe visual distortion, haptic instability, and system inconsistency. In this paper, we propose a novel approach to support haptic interactions with physically based 3D deformable models in a distributed virtual environment. Our objective is to achieve real-time sharing of deformable and force simulations over general networks. Combining linear modal analysis and corotational methods, we can effectively simulate physical behaviors of 3D objects, even for large rotational deformations. We analyze different factors that influence HCVEs' performance and focus on exploring solutions for streaming over lossy networks. In our system, 3D deformation can be described by a fairly small amount of data (several KB) using accelerations in the spectral domain, so that we can achieve low communication load and effective streaming. We develop a loss compensation and prediction algorithm to correct the errors/distortions caused by network problem, and a force prediction method to simulate force at users' side to ensure the haptic stability, and the visual and haptic consistency. Our system works well under both the client-server and the peer-to-peer distribution structures, and can be easily extended to other topologies. In addition to theoretical analysis, we have tested the proposed system and algorithms under various network conditions. The experimental results are remarkably good, confirming the effectiveness, robustness, and validity of our approach.";"2013";"Z. Tang and Y. Yang and X. Guo and B. Prabhakaran";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2013.47"
"Designing a reconfigurable multimodal and collaborative supervisor for Virtual Environment";"Virtual Reality (VR) systems cannot be promoted for complex applications (involving the interpretation of massive and intricate databases) without creating natural and ”transparent” user interfaces: intuitive interfaces are required to bring non-expert users to use VR technologies. Many studies have been carried out on multimodal and collaborative systems in VR. Although these two aspects are usually studied separately, they share interesting similarities. Our work focuses on the way to manage multimodal and collaborative interactions in a same process. We present here the similarities between these two processes and the main features of a reconfigurable multimodal and collaborative supervisor for Virtual Environments (VEs). The aim of such a system is to ensure the merge of pieces of information coming from VR devices (tracking, gestures, speech, haptics, etc.), to control immersive multi-user applications using the main communication and sensorimotor channels of humans. The framework's architecture of this supervisor wants to be generic, modular and reconfigurable (via an XML configuration file), in order to be applied to many different contexts.";"2011";"P. Martin and P. Bourdot";"2011 IEEE Virtual Reality Conference";"https://doi.org/10.1109/VR.2011.5759480"
"Haptic-Guided Teleoperation of a 7-DoF Collaborative Robot Arm With an Identical Twin Master";"In this article, we describe two techniques to enable haptic-guided teleoperation using 7-DoF cobot arms as master and slave devices. A shortcoming of using cobots as master-slave systems is the lack of force feedback at the master side. However, recent developments in cobot technologies have brought in affordable, flexible, and safe torque-controlled robot arms, which can be programmed to generate force feedback to mimic the operation of a haptic device. In this article, we use two Franka Emika Panda robot arms as a twin master-slave system to enable haptic-guided teleoperation. We propose a two layer mechanism to implement force feedback due to 1) object interactions in the slave workspace, and 2) virtual forces, e.g. those that can repel from static obstacles in the remote environment or provide task-related guidance forces. We present two different approaches for force rendering and conduct an experimental study to evaluate the performance and usability of these approaches in comparison to teleoperation without haptic guidance. Our results indicate that the proposed joint torque coupling method for rendering task forces improves energy requirements during haptic guided telemanipulation, providing realistic force feedback by accurately matching the slave torque readings at the master side.";"2020";"J. Singh and A. R. Srinivasan and G. Neumann and A. Kucukyilmaz";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2020.2971485"
"Evaluating Visual-Spatiotemporal Co-Registration of a Physics-Based Virtual Reality Haptic Interface";"This study aimed to evaluate the visual-spatiotemporal co-registration of the real and virtual objects’ movement dynamics by designing a low-cost, physics-based virtual reality (VR) system that provides actual cutaneous and kinesthetic haptic feedback of an object instead of using computer-generated haptic feedback. Twelve healthy participants performed three human-robot collaborative (HRC) sequential pick-and-place lifting tasks while both motion capture and VR systems, respectively, traced the movement of the real and virtual objects simultaneously. We used an iterative closest point algorithm to transform and align the 3D coordinates of VR point clouds with the 3D coordinates of the motion capture system. We introduced a new method to calculate and analyze the precision of visual and spatiotemporal co-registration between virtual and real objects. Results showed a high correlation ( $r >$ 0.96) between real and virtual objects’ movement dynamics and linear and angular co-registration errors of less than 5 cm and 8°, respectively. The trend also revealed a low temporal registration error of < 12 ms and was only found along the vertical axis. The visual registration data indicated that using real objects to provide cutaneous and kinesthetic haptics in the VR setting enhanced the users’ overall proprioception and visuomotor functions.";"2024";"S. T. Mubarrat and S. K. Chowdhury and A. S. Fernandes";"IEEE Access";"https://doi.org/10.1109/ACCESS.2024.3391186"
"A Shared Haptic Virtual Environment for Dental Surgical Skill Training";"Online learning has become an effective approach to reach students who may not be able to travel to university campuses for various reasons. Its use has also dramatically increased during the current COVID-19 pandemic with social distancing and lockdown requirements. But online education has thus far been primarily limited to teaching of knowledge and cognitive skills. There is yet almost no use of online education for teaching of physical clinical skills.In this paper, we present a shared haptic virtual environment for dental surgical skill training. The system provides the teacher and student with a shared environment containing a virtual dental station with patient, a dental drill controlled by a haptic device, and a drillable tooth. It also provides automated scoring of procedure outcomes. We discuss a number of optimizations used in order to provide the high-fidelity simulation and real-time performance needed for training of high-precision clinical skills. Since tactile, in particular kinaesthetic, sense is essential in carrying out many dental procedures, an important question is how to best teach this in a virtual environment. In order to support exploring this, our system includes three modes for transmitting haptic sensations from the user performing the procedure to the user observing.";"2021";"M. Kaluschke and M. S. Yin and P. Haddawy and N. Srimaneekarn and P. Saikaew and G. Zachmann";"2021 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)";"https://doi.org/10.1109/VRW52623.2021.00069"
"Packet-loss-resilient perception-based haptic data reduction and transmission using ACK packets";"Numerous studies have shown that haptic interaction plays a key role in enriching the sense of immersion and copresence of distributed users in collaborative virtual environments (CVEs). However, to ensure high-fidelity haptic interaction in CVEs, a high packet rate is required, resulting in considerable increase in overall traffic over the network. While perceptual deadband approach for haptic signals can successfully reduce high packet rates, this method is vulnerable to packet loss because the losing of single perceivable update packet results in a succession of wrong predictions. In this paper, we improve the perceptual deadband model by incorporating a packet loss resilient scheme using acknowledgement (ACK) packets. In case that an ACK packet is not returned to the sender within a trigger time, the sender will send an additional haptic data packet to the receiver to offset the effect caused by packet loss. By carefully selecting trigger time, buffer length and acknowledge time, the proposed scheme can be applied in a network environment with variable packet loss rates. The ACK-packets-based scheme is experimented by using different packet loss rates and lengthes of burst loss. Experimental results show that the proposed scheme can maintain stable and robust haptic interaction in terms of both objective and subjective measurements in a lossy network environment, and meanwhile perform well in haptic data reduction.";"2012";"J. Qin and K. -S. Choi and R. Xu and W. -M. Pang and P. -A. Heng";"2012 IEEE 11th International Conference on Signal Processing";"https://doi.org/10.1109/ICoSP.2012.6491784"
"Poster: Collaborative adjustment of selection areas for polygonal modelling";"Mutual awareness between users working in collaborative virtual environments is an important factor for efficient collaboration. Several studies have reported that haptic feedback improves performance in collaborative tasks. However, few researches have tried to evaluate the influence of haptic feedback on mutual awareness, and to link the corresponding measures with the performance and efficiency factors. This article presents a haptic collaborative modelling method dedicated to the dynamic adjustment of selection area. This modelling method intends to improve mutual awareness between the partners in order to improve the collaboration efficiency.";"2013";"A. Girard and Y. Bellik and M. Auvray and M. Ammi";"2013 IEEE Symposium on 3D User Interfaces (3DUI)";"https://doi.org/10.1109/3DUI.2013.6550215"
"Augmented reality haptics: using ARToolKit for display of haptic applications";"This paper described the integration of the ARToolKit with the Reachin Core Technology API. The result is a system capable of providing a coherent mix of real world video, computer haptics and computer graphics. A key feature is that new applications can be rapidly developed. Ultimately, this system is used to support rich object based collaboration between face-to-face and remote participants.";"2003";"M. Adcock and M. Hutchins and C. Gunn";"2003 IEEE International Augmented Reality Toolkit Workshop";"https://doi.org/10.1109/ART.2003.1320415"
"ViTAWiN - Developing Multiprofessional Medical Emergency Training with Mixed Reality";"Multi-user Virtual Reality (VR) has shown potential to provide a secure and collaborative environment for medical emergency training. The actual implementation and effective use of such technology depends on ergonomic (e.g., presence, usability) factors as well as solving challenges concerning the integration into existing training environments and multiple medical professions. This paper explores on how to extend a virtual training environment while addressing two professional groups, i.e., paramedics and emergency nurses. In an iterative and interdisciplinary development case we report on how a a comprehensive user-centered requirements analysis leads to the design of multi professional medical scenarios applied to an extended VR prototype. A user study with 30 paramedic students and 4 nursing trainees indicates adequate functionality with good usability and confirms effectiveness of our process. Based on our findings we propose a future research agenda concerning social and haptic interactions between trainees and patients for interprofessional medical mixed reality (MR) training.";"2021";"J. Schild and C. Elsenbast and G. Carbonell";"2021 IEEE 9th International Conference on Serious Games and Applications for Health(SeGAH)";"https://doi.org/10.1109/SEGAH52098.2021.9551890"
"Workshop on human-X haptic collaboration";"While haptic interaction with real, virtual, and remote environments is in the focus of the haptic community already since many years and implies the exchange of motion and force signals between two systems, haptic collaboration additionally requires the communication and negotiation of intentions, the building of mental models as well as the mutual adaptation of collaborating partners. Typical applications for haptic collaboration range from the manipulation and handling of heavy and large objects as required in industrial settings, the guidance of human limbs in rehabilitation, the assistance of humans in walking or performing complex manipulation tasks, the teaching of motor skills, to social interaction with virtual agents. This workshop will focus on haptic collaboration in human-X constellations where X stands for human, robot, or agent. Topics like haptic guidance, haptic shared control, mutual adaptation, learning as well as intention recognition and negotiation in haptically collaborating human-human, human-robot, and human-agent dyads will be discussed.";"2011";"A. Peer";"2011 IEEE World Haptics Conference";"https://doi.org/10.1109/WHC.2011.5945561"
"A Design and Analysis of a Hybrid Multicast Transport Protocol for the Haptic Virtual Reality Tracheotomy Tele-Surgery Application";"Nowadays, distributed collaborative virtual environments are used in many scenarios such as tele-surgery, gaming, and industrial training, however several challenging issues remain to be resolved before haptic virtual reality based class of applications become a common place. In this paper, we focus upon a tracheotomy tele-surgery application that is based on closely coupled and highly synchronized haptic tasks that require a high-level of coordination among the participants. We also propose a hybrid protocol that is able to satisfy all the collaborative and haptic virtual environment requirements in general and tracheotomy tele-surgery in particular. We discuss our C-HAVE tracheotomy tele-surgery framework and report on the performance results we have obtained to evaluate our protocol using an extensive set of experiments.";"2007";"A. Boukerche and H. Maamar and A. Hossain";"2007 IEEE International Parallel and Distributed Processing Symposium";"https://doi.org/10.1109/IPDPS.2007.370592"
"Tandem Canoeing over the Internet using Haptic Feedback";"A cooperative tandem canoeing task with haptic feedback is developed for internet application. A pair of InMotion2 robots provide stroke commands to the boat and force feedback to the operators while a flat screen panel displays the virtual environment to the participants. OpenInventor is used to generate the graphical environment while a realistic dynamics engine runs concurrently on an RT Linux box. Experimental results are presented for racing a straightline canoe course, and future work involving new input devices and virtual environments are discussed.";"2006";"J. Tang and C. Carignan and P. Olsson";"2006 14th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems";"https://doi.org/10.1109/HAPTIC.2006.1627130"
"CoboDeck: A Large-Scale Haptic VR System Using a Collaborative Mobile Robot";"We present CoboDeck - our proof-of-concept immersive virtual reality haptic system with free walking support. It provides prop-based encountered-type haptic feedback with a mobile robotic platform. Intended for use as a design tool for architects, it enables the user to directly and intuitively interact with virtual objects like walls, doors, or furniture. A collaborative robotic arm mounted on an omnidirectional mobile platform can present a physical prop that matches the position and orientation of a virtual counterpart anywhere in large virtual and real environments. We describe the concept, hardware, and software architecture of our system. Furthermore, we present the first behavioral algorithm tailored for the unique challenges of safe human-robot haptic interaction in VR, explicitly targeting availability and safety while the user is unaware of the robot and can change trajectory at any time. We explain our high-level state machine that controls the robot to follow a user closely and rapidly escape from him as required by the situation. We present our technical evaluation. The results suggest that our chasing approach saves time, decreases the travel distance and thus battery usage, compared to more traditional approaches for mobile platforms assuming a fixed parking position between interactions. We also show that the robot can escape from the user and prevent a possible collision within a mean time of 1.62 s. Finally, we confirm the validity of our approach in a practical validation and discuss the potential of the proposed system.";"2023";"S. Mortezapoor and K. Vasylevska and E. Vonach and H. Kaufmann";"2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)";"https://doi.org/10.1109/VR55154.2023.00045"
"Collaborative manual tasks in distributed virtual environments";"We often encounter many situations where we manually interact with others collaboratively. This allows us to solve tasks that we would otherwise not be able to do on our own. Handover tasks are an everyday interaction that we perform with others without thinking about it. However, these tasks are complex coordinated actions between two actors based on sensory feedback that are per-formed in a very short time. In this work, an overview of handover tasks will be provided from a perspective of the interdisciplinary fields of human-robot interaction (HRI), neuroscience, cognitive science and human-computer interaction (HCI). For this purpose, the structure and process of a handover interaction will be examined and the current state of research will be reflected. The ability to represent realistic manual interactions in an immersive collaborative scenario enables the simulation and training of complex workflows in a realistic context. The study design presented in this paper is intended to improve the understanding and design of handover inter-action techniques in virtual environments. Furthermore possibilities to substitute missing haptic feedback with other sensory stimuli will be evaluated.";"2022";"S. Keppler and J. Habakuk Israel and E. Wiese";"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)";"https://doi.org/10.1109/ISMAR-Adjunct57072.2022.00213"
"Multimodal multi-user human-robot interface for virtual collaboration";"We present a intuitive teleoperation scheme by using human gesture and multimodal multi-user human-robot interface. Further, in order to deal with the dynamic daily environment, we apply haptic point cloud rendering and virtual collaboration and all these functions are achieved by portable hardwares which is called “mobile iSpace”. First, a surrounding environment of a teleoperated robot is captured and reconstructed as the 3D point cloud using a depth camera. Virtual world is then generated from the 3D point cloud, and a virtual teleoperated robot model is placed in there. An user uses their own whole body gesture to teleoperate the humanoid type robot. The gesture is captured by the depth camera placed in user-side in real time. And the user has the visual and vibrotactile feedback at the same time by using a head mounted display and a vibrotactile glove. All these system components e.g. the human user, the teleoperated robot and the feedback devices are connected with the Internet-based virtual collaboration system to support a flexible accessibility. So eventually, this makes possible that users can access the remote placed robot whenever and wherever they want.";"2012";"Young Eun Song and M. Niitsuma and T. Kubota and H. Hashimoto and Hyoung Il Son";"2012 9th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)";"https://doi.org/10.1109/URAI.2012.6462920"
"Human-machine Collaboration System for Fine Assembly Process";"The assembly process of some fine parts such as semiconductor and MEMS (micro electro mechanical systems), is very difficult to conduct based on the operation of an automated system or a human, since the size of the fine parts are very small and fragile. This paper proposes the concept of conducting advanced assembly process and highly precise positioning operation based on a collaboration of human and machine, such that a high productivity can be achieved. An experimental system to realize and to confirm the effectiveness of the concept is constructed using tele-manipulation and augmented reality (AR) technologies. The experimental system is composed of a haptic device, an augmented reality monitor, a robot manipulator with hand in the end-effector for handling the fine part, a force sensor, some cameras, and a work jig. The effectiveness of the assembly process of fine parts using tele-manipulation and augmented reality is confirmed by some experiments. In the experiments, by adjusting the workspace in the operator side and the assembly area side using scaling factor in the motion command from haptic device to robot manipulator, and also reaction force occurred in the assembly area to haptic device, the assembly process can be conducted effectively. In addition, it is also confirmed that by putting some vector representations of motion command and force in the augmented reality monitor, it can assist human to conduct the assembly process. This paper describes the concept and the experimental system to realize the concept in more detail";"2006";"Y. Harada and N. Nazir and Y. Shiote and T. Ito";"2006 SICE-ICASE International Joint Conference";"https://doi.org/10.1109/SICE.2006.315459"
"Haptic Assistance Improves Tele-Manipulation With Two Asymmetric Slaves";"Tele-manipulation of heavy loads typically requires the simultaneous use of two asymmetric slaves: a crane for vertical weight support and a robot for accurate lateral positioning. The industrial standard prescribes a pair of operators for such tasks (one operator to control each slave), although in principle one operator might control both slaves with a single, hybrid interface. Accurate and safe co-operative handling of the expensive and fragile heavy components is difficult, presumably due to problems in the coordination of the subtasks and the lack of mutual awareness between the two operators. This study proposes a novel haptic assistance system to improve subtask coordination and task performance. Its novelty consists of haptically linking operators/interfaces through the joint task environment. The system's efficacy is evaluated with 15 pairs of co-operators and 15 individual uni-manual operators who maneuvered a heavy load through a bounded path in Virtual Reality. Haptic assistance improves task completion time for both groups. It also reduces control activity and self-reported workload without affecting a number of critical errors made by the operators. Moreover, without haptic assistance, uni-manual operators perform worse than co-operators, but this difference between the interfaces was not found with haptic assistance.";"2019";"J. van Oosterhout and C. J. M. Heemskerk and H. Boessenkool and M. R. de Baar and F. C. T. v. d. Helm and D. A. Abbink";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2018.2873350"
"Group Haptic Collaboration: Evaluation of Teamwork Behavior during VR Four-Person Rowing Task";"The assessment of multi-person group collaboration has garnered increasing attention in recent years. However, it remains uncertain whether haptic information can be effectively utilized to measure teamwork behavior. This study seeks to evaluate teamwork competency within four-person groups and differentiate the contributions of individual members through a haptic collaborative task. To achieve this, we propose a paradigm in which four crews collaboratively manipulate a simulated boat to row along a target curve in a shared haptic-enabled virtual environment. We define eight features related to boat trajectory and synchronization among the four crews' paddling movements, which serve as indicators of teamwork competency. These features are then integrated into a comprehensive feature, and its correlation with self-reported teamwork competency is analyzed. The results demonstrate a strong positive correlation (r>0.8) between the comprehensive feature and teamwork competency. Additionally, we extract two kinesthetic features that represent the paddling movement preferences of each crew member, enabling us to distinguish their contributions within the group. These two features of the crews with the highest and the lowest contribution in each group were significantly different. This work demonstrates the feasibility of kinesthetic features in evaluating teamwork behavior during multi-person haptic collaboration tasks.";"2024";"B. Tian and Y. Zheng and Z. Zhuang and H. Luo and Y. Zhang and D. Wang";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2023.3346683"
"A New Approach to Remote Health Monitoring using Augmented Reality with WebRTC and WebXR";"The domain of Augmented Reality (AR) focus with the realm of conveying interactive experience of the objects in the real-world environment with the enhancement towards system generated information. It also conveys different forms of modality, visual perception, auditory and haptic information about the object which is considered for analysis. The system is used to formulate significant collaborative experiences with superimposed experiences among the users. This research work focus on the remote assistance for diagnosis and collaboration among the people who are involved as workers in product confirmation and analysis. The mechanism also decreases the communication issues with the intention of making the users to have a good enough environment to have a complete set of interaction. Therefore, to give a remote diagnostic of the work and guidance for the site workers from an expert we propose WebRTC (AppRTC) for Real-Time Video Communication and Google ARCore/ WebAR/ WebXR for augmenting the Video call, will be used and integrated to enhance the proposed system. Thereby the assembly process in improved for service quality with timely communication among the workers of a specified group..";"2021";"A. Sheik Abdullah and A. Manoj and G. T. Tarun Kishore and S. Selvakumar";"2021 22nd International Arab Conference on Information Technology (ACIT)";"https://doi.org/10.1109/ACIT53391.2021.9677324"
"Design and assessment of haptic interfaces: An essay on proactive haptic articulation";"We looked up to elements present in speech articulation to introduce the proactive haptic articulation as a novel approach for intercommunication. The ability to use a haptic interface as a tool for implicit communication can supplement communication and support near and remote collaborative tasks in virtual and physical environments. In addition, the proactive articulation can be applied during the design process, including the user in the construction of more dynamic and optimized vibrotactile vocabularies. In this proposal, we discuss the thesis of the haptic proactive communication and our method to assess and implement it. Our goal is to understand the phenomena related to the proactive articulation of haptic signals and its use for communication and for the design of optimized tactile vocabularies.";"2017";"V. A. de Jesus Oliveira";"2017 IEEE Virtual Reality (VR)";"https://doi.org/10.1109/VR.2017.7892350"
"Influence of network delay on human perception of weight in virtual environment";"This paper investigates the influence of network delay on human perception of weight in virtual environment by experiment. In the environment, each of two users manipulates a haptic interface device, and the users collaboratively lift up a stick by holding two ends of the stick in a 3D virtual space. A weighted ball is placed on the stick, if one end of the stick is lower than the other end, the ball moves to the lower end. The users try to keep the ball at the center of the stick while lifting up the stick. We also implement the local lag control as QoS (Quality of Service) control and compare results with the control and those without it. Experiment results demonstrate that the local lag control is effective.";"2017";"P. Huang and R. Arima and Y. Ishibashi";"2017 3rd IEEE International Conference on Computer and Communications (ICCC)";"https://doi.org/10.1109/CompComm.2017.8322737"
"A network architecture supporting consistent rich behavior in collaborative interactive applications";"Network architectures for collaborative virtual reality have traditionally been dominated by client-server and peer-to-peer approaches, with peer-to-peer strategies typically being favored where minimizing latency is a priority and client-server where consistency is key. With increasingly sophisticated behavior models and the demand for better support for haptics, we argue that neither approach provides sufficient support for these scenarios nor, thus, a hybrid architecture is required. We discuss the relative performance of different distribution strategies in the face of real network conditions and illustrate the problems they face. Finally, we present an architecture that successfully meets many of these challenges and demonstrate its use in a distributed virtual prototyping application which supports simultaneous collaboration for assembly, maintenance, and training applications utilizing haptics";"2006";"J. Marsh and M. Glencross and S. Pettifer and R. Hubbold";"IEEE Transactions on Visualization and Computer Graphics";"https://doi.org/10.1109/TVCG.2006.40"
"Function-Based Haptic Interaction in Cyberworlds";"Polygon and point based models dominate in virtual reality. These models also affect haptic rendering algorithms which are often based on collision with polygons. We use mathematical functions to define and implement geometry (curves, surfaces and solid objects), visual appearance (3D colors and geometric textures) and various tangible physical properties (elasticity, friction, viscosity, and force fields). The function definitions are given as analytical formulas (explicit, implicit and parametric), function scripts and procedures. Since the defining functions are very small we can efficiently use them in collaborative virtual environments to exchange between the participating clients. We proposed an algorithm for haptic rendering of virtual scenes including mutually penetrating objects with different sizes and arbitrary location of the observer without a prior knowledge of the scene to be rendered. The algorithm is based on casting multiple haptic rendering rays from the Haptic Interaction Point (HIP), and it builds a stack to keep track on all colliding objects with the HIP. The algorithm uses collision detection based on implicit function representation of the object surfaces. The proposed approach allows us to be flexible when choosing the actual rendering platform. The function-defined objects and parts constituting them can be used together with other common definitions of virtual objects such as polygon meshes, point sets, voxel volumes, etc. We implemented an extension of X3D and VRML which allows for defining complex geometry, appearance and haptic effects in virtual scenes by functions and common polygon-based models, with various object sizes, mutual penetrations, arbitrary location of the observer and variable precision.";"2011";"L. Wei and A. Sourin";"2011 International Conference on Cyberworlds";"https://doi.org/10.1109/CW.2011.19"
"3D User Interfaces: New Directions and Perspectives";"Three-dimensional user interfaces (3D UIs) let users interact with virtual objects, environments, or information using direct 3D input in the physical and/or virtual space. In this article, the founders and organizers of the IEEE Symposium on 3D User Interfaces reflect on the state of the art in several key aspects of 3D UIs and speculate on future research.";"2008";"D. A. Bowman and S. Coquillart and B. Froehlich and M. Hirose and Y. Kitamura and K. Kiyokawa and W. Stuerzlinger";"IEEE Computer Graphics and Applications";"https://doi.org/10.1109/MCG.2008.109"
"On the collaboration of an automatic path-planner and a human user for path-finding in virtual industrial scenes";"This paper describes a global interactive framework enabling an automatic path-planner and a user to collaborate for finding a path in cluttered virtual environments. First, a collaborative architecture including the user and the planner is described. Then, for real time purpose, a motion planner divided into different steps is presented. First, a preliminary workspace discretization is done without time limitations at the beginning of the simulation. Then, using these pre-computed data, a second algorithm finds a collision free path in real time. Once the path is found, an haptic artificial guidance on the path is provided to the user. The user can then influence the planner by not following the path and automatically order a new path research. The performances are measured on tests based on assembly simulation in CAD scenes.";"2010";"N. Ladevèze and J. -Y. Fourquet";"2010 11th International Conference on Control Automation Robotics & Vision";"https://doi.org/10.1109/ICARCV.2010.5707861"
"Optimizing Setup Configuration of a Collaborative Robot Arm-Based Bimanual Haptic Display for Enhanced Performance";"A bimanual haptic display supporting the full range of human arm motion and providing a sufficient haptic feedback force/torque is essential for achieving human-like manipulation in remote or virtual environments. This letter proposes the use of redundant collaborative robot arms as a bimanual haptic display and introduces an optimization scheme to determine its optimal setup configuration. The scheme considers factors including human arm workspace coverage, redundancy, renderable haptic feedback force/torque, and potential collisions with a human arm. The proposed optimization scheme is applied to the Panda and iiwa 7 robot arms and the results are compared to the setup configurations of NimbRo and German Aerospace Center (DLR) HUG. The optimized setup configurations with the proposed scheme were observed to outperform the existing setup configurations.";"2024";"J. -K. Lee and J. -H. Ryu";"IEEE Robotics and Automation Letters";"https://doi.org/10.1109/LRA.2024.3355771"
"ChronoPilot — Modulating Time Perception";"Although time can be measured objectively, human time perception is remarkably subjective and influenced by cognitive states, individual motivations, and social factors. This malleability of perceived time can be evidenced, for instance, in stressful situations where one might experience a lack of time, while one might lose track of time in more relaxing circumstances. Based on fundamental knowledge from psychology and cognitive science, the ChronoPilot project aims at developing a prototype technology driven by artificial intelligence to extend or compress human subjective time adaptively and whenever required. Mediated-reality approaches, such as virtual and augmented reality, have enormous potential for presenting the users with visual, auditory, and haptic stimulation patterns that directly or indirectly influence their subjective time and which are difficult to reproduce in the real world. Going beyond individual settings, ChronoPilot will also investigate how to coordinate time plasticity in collaborative environments where one group member's actions may affect other members' perception. Different scenarios, where humans alone or humans and robots have to collaborate in realistic and virtual environments, will validate the planned research. In this paper, we present the fundamental concepts of our project ChronoPilot, which is a work in progress.";"2021";"J. Botev and K. Drewing and H. Hamann and Y. Khaluf and P. Simoens and A. Vatakis";"2021 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)";"https://doi.org/10.1109/AIVR52153.2021.00049"
"Online Identification of Interaction Behaviors From Haptic Data During Collaborative Object Transfer";"Joint object transfer is a complex task, which is less structured and less specific than what is existing in several industrial settings. When two humans are involved in such a task, they cooperate through different modalities to understand the interaction states during operation and mutually adapt to one another's actions. Mutual adaptation implies that both partners can identify how well they collaborate (i.e. infer about the interaction state) and act accordingly. These interaction states can define whether the partners work in harmony, face conflicts, or remain passive during interaction. Understanding how two humans work together during physical interactions is important when exploring the ways a robotic assistant should operate under similar settings. This study acts as a first step to implement an automatic classification mechanism during ongoing collaboration to identify the interaction state during object co-manipulation. The classification is done on a dataset consisting of data from 40 subjects, who are partnered to form 20 dyads. The dyads experiment in a physical human-human interaction (pHHI) scenario to move an object in an haptics-enabled virtual environment to reach predefined goal configurations. In this study, we propose a sliding-window approach for feature extraction and demonstrate the online classification methodology to identify interaction patterns. We evaluate our approach using 1) a support vector machine classifier (SVMc) and 2) a Gaussian Process classifier (GPc) for multi-class classification, and achieve over 80% accuracy with both classifiers when identifying general interaction types.";"2020";"A. Kucukyilmaz and I. Issak";"IEEE Robotics and Automation Letters";"https://doi.org/10.1109/LRA.2019.2945261"
"An Initial Study of Ingrown Toenail Removal Simulation in Virtual Reality with Bimanual Haptic Feedback for Podiatric Surgical Training";"An initial study was conducted to identify the strengths and weaknesses of an ingrown toenail removal simulation we developed in collaboration with the Kent State College of Podiatric Medicine. In this paper, we describe the methods used in 3D modeling and haptic rendering development of the simulation with virtual reality and bimanual haptic feedback. The simulation utilizes dual Geomagic Touch Devices. These stylus-based devices sense force magnitude and movement responding with motor resistance. Multiple tasks of ingrown toenail surgery were simulated including anesthesia, elevation, and cutting. An evaluation experiment was conducted and data was recorded through a post-simulation questionnaire accompanied by a NASA Task Load Index inquiry. The results demonstrate that the developed system is acceptable for training medical students who need to practice podiatric surgery procedures.";"2023";"J. Abounader and K. Kim and B. D. Caldwell and M. A. Hardy";"2023 IEEE Sensors Applications Symposium (SAS)";"https://doi.org/10.1109/SAS58821.2023.10253999"
"Haptic Tele-cooperation of Multiple Robots";"In this paper, a novel haptic tele-cooperation control scheme for a system consisting of multiple manipulators interacting with a physical or virtual object is proposed. The contact force between each manipulator and the object is decomposed into two independent forces, one of which is related to grasping the object and the other is related to the motion of the object including its interaction with the environment it is in. The Lyapunov's direct method is used for designing and stability analysis of the proposed controller. As a case study, the problem of robotic tele-rehabilitation is investigated where multiple human operators (e.g., one or more therapists, patients, and trainees in a tele-rehabilitation setting) control their user interfaces in order to tele-cooperatively manipulate an object in a virtual environment. Experimental results confirm the performance and effectiveness of the proposed control methodology.";"2017";"I. Sharifi and H. A. Talebi and S. A. R. Mousavi and S. Shemshaki and M. Tavakoli";"2017 5th RSI International Conference on Robotics and Mechatronics (ICRoM)";"https://doi.org/10.1109/ICRoM.2017.8466205"
"Homotopy switching model for dyad haptic interaction in physical collaborative tasks";"The main result of this paper is a new model based on homotopy switching between intrinsically distinct controllers that encompass most behaviors encountered in dyadic haptic collaborative tasks. The basic idea is to switch continuously between two distinct extreme behaviors (leader and follower) for each individual, which creates an implicit bilateral coupling within the dyad. The physical collaborative interaction is then described only with two distinct homotopy time-functions that vary independently. These functions can likely describe the signature of a collaborative task. A virtual reality haptic set-up is used to assess the proposed theory.";"2009";"P. Evrard and A. Kheddar";"World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems";"https://doi.org/10.1109/WHC.2009.4810879"
"Haptic simulation as a tool to explain the relationships between force, field, potential and energy for point electric charges";"As part of the academic training of an engineering student, the laws associated with electromagnetism represent a subject whose theory and practice represent the bases of understanding other training disciplines, alluding to electronics, telecommunications, digital and analog systems. The bases to understand the physics of electromagnetism correspond to electrostatics; to this end, the topics associated with force, field, potential and energy for point electric charges correspond to the topics addressed in this contribution. A technological platform is proposed, designed to strengthen the principles of electrostatics from visual and kinesthetic stimulation. Studies associated with neurophysiological perception, with a focus on the learning process, argue that involving a greater number of sensory channels strengthens the understanding of knowledge that typically considers conventional strategies such as presentations and blackboard management. The platform is proposed with two haptic devices whose dynamics are controlled based on the evaluation of physical laws, as well as the data modified online by the student. The virtual reality environment is based on a graphical representation of a system of electrical charges, associated with each of the end effectors of the haptic devices. To do this, Unity 3D is used as a cross-platform tool for the integration of the virtual environment; the force commands, calculated from the physical laws of electrostatics, are sent to the haptic devices from C# scripts in real time. The workload index was verified through the NASA TLX protocol, in which 10 engineering students with theoretical knowledge of electricity and magnetism were evaluated.";"2024";"J. D. Ramirez-Zamora and O. A. Dominguez-Ramirez and G. Sepulveda-Cervantes and J. C. Gonzalez-Islas and N. V. Mendoza-Diaz and A. Jarillo-Silva";"2024 XXVI Robotics Mexican Congress (COMRob)";"https://doi.org/10.1109/COMRob64055.2024.10777424"
"A prediction algorithm for haptic collaboration";"The incorporation of haptic interfaces into collaborative virtual environments suffers from setbacks due to some inherent technical problem when the users are geographically distributed. The main causes of such discrepancies are network delay, lack of view of individual participants' activities (awareness), and haptic feedback. Although some strategies exist for dealing with those concerns, they don't adequately address realism, causality, and the sense of co-presence in collaborative virtual environments during closely-coupled haptic tasks. We propose an approach based on prediction to compensate the limitations and to visualize the whole scenario for the users in order to help them cope with existing drawbacks intuitively. We introduce a predictor which can determine lost-update messages to improvise the current state, guess the current network delay, and anticipate remote user's interaction strategy and virtual object's position/orientation based on the history.";"2005";"A. Boukerche and S. Shirmohammadi and A. Hossain";"IEEE International Workshop on Haptic Audio Visual Environments and their Applications";"https://doi.org/10.1109/HAVE.2005.1545670"
"Virtual cooperating manipulator control for haptic interaction with NURBS surfaces";"Virtual manipulators are a new concept in the area of force feedback for virtual reality. This control approach does not make use of any specialized haptic display hardware but instead is formulated for implementation with any general industrial robot that allows six degree of freedom motion. Using this approach many commonly available manipulators can be used as an interface device to a virtual environment. This work extends the virtual manipulator concept, to allow haptic interaction with more complex virtual objects. The time varying virtual manipulator developed here constrains the end effector of a robot to trace along a NURBS surface. This virtual mechanism provides interaction forces consistent with the sensation of contacting the surface. These interaction forces can be coupled with a graphical display to provide a more complete feeling of immersion.";"1997";"G. R. Luecke and J. C. Edwards and B. E. Miller";"Proceedings of International Conference on Robotics and Automation";"https://doi.org/10.1109/ROBOT.1997.620024"
"Performance Issues in Collaborative Haptic Training";"This paper proposes a new multilateral position-position shared control architecture for dual-user haptic training. The proposed controller allows interaction between both users, the trainee and the trainer, as well as between the users and the virtual slave robot and environment. It also allows for the adjustment of the dominance of the trainer over the trainee in interaction with the virtual slave and environment through a dominance factor parameter. The issue of transparency in such collaborative haptic simulation system has been discussed. A performance index has also been defined to quantify the users' skill for a specific task under study. This metric is used to identify the maximum allowable dominance of the trainee over the trainer. Haptic simulation experiments have been carried out with two planar twin pantograph haptic devices and a simulated pantograph as the slave robot.";"2007";"B. Khademian and K. Hashtrudi-Zaad";"Proceedings 2007 IEEE International Conference on Robotics and Automation";"https://doi.org/10.1109/ROBOT.2007.363975"
"Combating Latency in Haptic Collaborative Virtual Environments";"Haptic (force) feedback is increasingly being used in surgical-training simulators. The addition of “touch” is important extra information that can add another dimension to the realism of the experience. Progress in networking these systems together over long distances has been held back, principally because the latency of the network can induce severe instability in any dynamic objects in the scene. This paper describes techniques allowing long-distance sharing of haptic-enabled, dynamic scenes. At the CSIRO Virtual Environments Laboratory, we have successfully used this system to connect a prototype of a surgical-simulation application between participants on opposite sides of the world in Sweden and Australia, over a standard Internet connection spanning 3 continents and 2 oceans. The users were able to simultaneously manipulate pliable objects in a shared workspace, as well as guide each other's “hands” (and shake hands!) over 22,000 km (13620 miles) of Internet connection. The main obstacle to overcome was the latency-induced instability in the system, caused by the delays and jitter inherent in the network. Our system involved a combination of an event-collection mechanism, a network event-forwarding mechanism and a “pseudophysics” mechanism. We found that the resulting behavior of the interconnected body organs, under simultaneous-user manipulation, was sufficiently convincing to be considered for training surgical procedures.";"2005";"C. Gunn and M. Hutchins and M. Adcock";"Presence";"https://doi.org/10.1162/105474605323384663"
"Emotional Engagement with Haptic Feedback in Virtual Scenarios: A Literature Review";"Virtual reality (VR) is a simulated environment that computer technology generates. Haptic feedback uses touch sensations to enhance user interaction within a VR. Exploring emotional engagement in VR has witnessed a surge in interest, particularly concerning the integration of haptic feedback. This study systematically reviews 26 primary studies published from 2013 to 2023. We identify nineteen emotional engagement techniques and support leveraging the impact of emotional engagement in collaboration with haptics. Then, we develop a relationship based on emotional engagement and haptic feedback, emphasizing the significance of sensory integration and haptic elements in augmenting emotional connections in a VR environment. The investigation unveils various techniques, encompassing multi-sensory emotion recognition, immersive VR environments, interactive digital narratives, and haptic feedback strategies. Our findings suggest that the researchers need to explore emotional engagement in multiple virtual environments for synchronous user interaction to advance immersive technologies.";"2024";"T. Qaisar and M. Mumtaz and H. Raza and M. M. Ali and K. Khalid and I. Bajwa";"2024 International Conference on Engineering & Computing Technologies (ICECT)";"https://doi.org/10.1109/ICECT61618.2024.10581267"
"Vibrotactile and Force Collaboration within 3D Virtual Environments";"In a three-dimensional (3D) virtual environment (VE), proper collaboration between vibrotactile and force cues - two cues of the haptic modality - is important to facilitate task performance of human users. Many studies report that collaborations between multi-sensory cues follow maximum likelihood estimation (MLE). However, an existing work finds that MLE yields a mean and an amplitude mismatches when interpreting the collaboration between the vibrotactile and force cues. We thus proposed mean-shifted MLE and conducted a human study to investigate the mismatches. For the study, we created a VE to replicate the visual scene, the 3D interactive task, and the cues from the existing work. Our participants were biased to rely on the vibrotactile cue for their tasks, departing from unbiased reliance on both cues in the existing work. Assessments of task completion time and task accuracy validated the replication. We found that based on task accuracy MLE explained the cue collaboration to certain degrees, agreed with the existing work. Mean-shifted MLE remedied the mean mismatch, but maintained the amplitude mismatch. Further examinations revealed that the collaboration between both cues may not be entirely additive. This sheds an insight for proper modeling of the collaboration between the vibrotactile and force cues to aid interactive tasks in VEs.";"2018";"S. Tarng and A. Erfanian and Y. Hu and F. Merienne";"2018 IEEE 22nd International Conference on Computer Supported Cooperative Work in Design ((CSCWD))";"https://doi.org/10.1109/CSCWD.2018.8465360"
"The evaluation of delay jitter for haptics collaboration over the Internet";"What we are concerned with in this paper is a shared virtual environment (SVE) on a non-dedicated network like the Internet. Especially, we address haptics on an SVE for the new generation of network applications. The goal of our research Is to build an SVE system in which multiple participants can collaborate using haptics feedback, even though the participants are located around the world. One of the problems for this system is network impairment, and we have examined the effect of constant network delay and packet loss on the haptics collaboration system. In this paper we examine and evaluate the effect of delay jitter on the system when using media synchronization and dead reckoning.";"2002";"K. Hikichi and H. Morino and I. Arimoto and K. Sezaki and Y. Yasuda";"Global Telecommunications Conference, 2002. GLOBECOM '02. IEEE";"https://doi.org/10.1109/GLOCOM.2002.1188447"
"Haptic Feedback of Front Vehicle Motion May Improve Driving Control";"This study investigates the role of haptic feedback in a two-vehicle following scenario, where information about the motion of the front vehicle is provided through a virtual elastic connection with it. Using a robotic interface in a simulated driving environment, we examined the impact of varying levels of such haptic feedback on the driver's ability to follow the road while avoiding obstacles. The results of an experiment with 15 subjects indicate that haptic feedback from the front vehicle's motion can significantly improve driving control (i.e., reduce motion jerk and deviation from the road) and reduce mental load (evaluated via questionnaire). This suggests that haptic communication, as observed between physically interacting humans, can be leveraged to improve safety and efficiency in automated driving systems, warranting further testing in real driving scenarios.";"2025";"X. Cheng and X. Geng and Y. Huang and E. Burdet";"IEEE Robotics and Automation Letters";"https://doi.org/10.1109/LRA.2024.3502063"
"Absolute Stability of Multi-DOF Multilateral Haptic Systems";"Multi-degree-of-freedom (DOF) multilateral haptic systems involve teleoperation of several robots in physical environments by several human operators or collaborative interaction of several human operators in a virtual environment. An m-DOF n-lateral haptic system can be modeled as an n-port network where each port (terminal) connects to a termination defined by m inputs and m outputs. The stability analysis of such systems is not trivial due to dynamic coupling across the different DOFs of the robots, the human operators, and the physical/virtual environments, and unknown dynamics of the human operators and the environments exacerbate the problem. Llewellyn's criterion only allows for absolute stability analysis of 1-DOF bilateral haptic systems (m = 1 and n = 2), which can be modeled as two-port networks. The absolute stability of a general m-DOF bilateral haptic system where m >1 cannot be obtained from m applications of Llewellyn's criterion to each DOF of the bilateral system. In addition, if we were to use Llewellyn's criterion for absolute stability analysis of a general 1-DOF n-lateral haptic system where n- 2, we would need to couple n > 2 terminations of the n-port network to (an infinite number of) known impedances to reduce it to an equivalent two-port network; this is a cumbersome process that involves an infinite number of applications of Llewellyn's criterion. In this brief, we present a straightforward and convenient criterion for absolute stability analysis of a class of m-DOF n-lateral haptic systems for any m ≥ 1 and n ≥ 2. As case studies, a 1-DOF trilateral and a 2-DOF bilateral haptic system are studied for absolute stability with simulations and experiments confirming the theoretical stability conditions.";"2014";"J. Li and M. Tavakoli and Q. Huang";"IEEE Transactions on Control Systems Technology";"https://doi.org/10.1109/TCST.2014.2301840"
"Mentor-Guided Learning in Immersive Virtual Environments: The Impact of Visual and Haptic Feedback on Skill Acquisition";"In the early stages of learning a technical skill, trainees require guidance from a mentor through augmented feedback to develop higher expertise. However, the impact of such feedback and the different modalities used to communicate it remain underexplored in immersive virtual environments (IVE). This paper presents a study in which 27 participants were divided into three groups to learn a tool manipulation trajectory in an IVE. Two experimental groups received guidance from an expert using visual and/or haptic augmented feedback, while the control group received no feedback. The results indicate that both experimental groups showed significantly greater improvement in tool trajectory performance than the control group from pre- to post-test, with no significant differences between them. Analysis of their learning curves revealed similar performance improvements in tool trajectory across trials, outperforming the control group. Additionally, the visual-haptic feedback condition was linked to lower task load in three out of six dimensions of the NASA-TLX and a higher perceived interdependence with the expert's actions. These findings suggest that augmented feedback from an expert enhances the learning of tool manipulation skills. Although adding haptic feedback did not lead to better learning outcomes compared to visual feedback alone, it did enhance the overall user experience. These results offer valuable insights for designing IVEs that support mentor-trainee interactions through augmented feedback.";"2025";"F. Lebrun and C. Simon and A. Boukezzi and S. Otmane and A. Chellali";"IEEE Transactions on Visualization and Computer Graphics";"https://doi.org/10.1109/TVCG.2025.3549547"
"Motion Prediction With Gaussian Processes for Safe Human–Robot Interaction in Virtual Environments";"Humans use collaborative robots as tools for accomplishing various tasks. The interaction between humans and robots happens in tight shared workspaces. However, these machines must be safe to operate alongside humans to minimize the risk of accidental collisions. Ensuring safety imposes many constraints, such as reduced torque and velocity limits during operation, thus increasing the time to accomplish many tasks. However, for applications such as using collaborative robots as haptic interfaces with intermittent contacts for virtual reality applications, speed limitations result in poor user experiences. This research aims to improve the efficiency of a collaborative robot while improving the safety of the human user. We used Gaussian process models to predict human hand motion and developed strategies for human intention detection based on hand motion and gaze to improve the time for the robot and human security in a virtual environment. We then studied the effect of prediction. Results from comparisons show that the prediction models improved the robot time by 3% and safety by 17%. When used alongside gaze, prediction with Gaussian process models resulted in an improvement of the robot time by 2% and the safety by 13%.";"2024";"S. Mugisha and V. Krishna Guda and C. Chevallereau and D. Chablat and M. Zoppi";"IEEE Access";"https://doi.org/10.1109/ACCESS.2024.3400604"
"Evaluating decorators for haptic collaboration over Internet";"One of the known problems with shared object manipulation in collaborative virtual environments (CVE) is the disruptive effect of network lag in collaboration sessions. It is widely recognized that delay and jitter cause significant problems for CVEs. Most solutions to this problem revolve around techniques to compensate for this lag at the networking level. More recently, the usage of visual queues indicating network lag to the user have shown to be effective. In this article we examine the latter for tele-haptic applications, and we find out an appropriate visual queue specifically for the low delay and jitter requirement necessary for closely-coupled collaborative tasks.";"2004";"S. Shirmohammadi and N. Ho Woo";"The 3rd IEEE International Workshop on Haptic, Audio and Visual Environments and Their Applications";"https://doi.org/10.1109/HAVE.2004.1391890"
"A Cloth Design System Using Haptic Device and Its Collaborative Environment";"This paper proposes a cloth design system that provides intuitive operations, e.g., sewing, cutting and fitting a cloth in a virtual 3D space through direct manipulations using a force-feedback device. This cloth design system also provides a collaborative environment that allows two users to design a common cloth collaboratively in a virtual 3D space through the Internet. A lot of cloth simulation algorithms and systems have been proposed and existed so far. However, there is no cloth design system that supports a force-feedback device and provides a networked-collaborative environment. So, the authors developed such a cloth design system. This paper describes what kinds of intuitive operations are implemented, how the collaborative environment is designed, and quantitative performances of the system to clarify its usefulness";"2006";"K. Miyahara and Y. Okada and K. Niijima";"2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006)";"https://doi.org/10.1109/HAVE.2006.283789"
"Design and implementation of a collaborative virtual haptic surgical training system";"The high level design of a hapto-visual telementoring virtual environment consisting of two networked stations allowing two users to collaborate within the learning environment is outlined. The physical implementation and the operation of the system are described. This system is designed to be used for remote surgical training. It would allow surgeons to remotely train students in a networked hapto-visual virtual environment to perform simple tasks. Moreover, the system provides a platform for studying many aspects of collaborative virtual environment (CVE) systems and their applications.";"2005";"B. Chebbi and D. Lazaroff and F. Bogsany and P. X. Liu and Liya Ni and M. Rossi";"IEEE International Conference Mechatronics and Automation, 2005";"https://doi.org/10.1109/ICMA.2005.1626566"
"3D Shape Understanding for the Visually Impaired by using Virtual Haptic Senses based on Fuzzy Logic";"This research aims to provide information accessibility support for visually impaired individuals perform actions and behaviors that recognize objects by themselves or reflect their understanding of the situation in the environment. For that reason, we will develop an object recognition method to them that improves the shape understanding of target object to be recognized by touching virtual haptic senses created from the pseudo object in a computer that mimics an object in the environment. In general, the shape information of objects is difficult to verbalize. Even if its information is transformed to spoken words, it is hard to understand the shape of an object with a one-dimensional transmission through hearing. Therefore, it is necessary to expand context awareness into two- or three-dimensions while collaborating with visually impaired individuals who rely on haptic sensation. In this report, for pseudo objects created by combining 2D and 3D basic shapes in a computer, we consider the process of shape understanding and object recognition under visual impairment based on virtual haptic senses. Presentation of these pseudo objects to visually impaired individuals is provided so that they can understand by touching a two-dimensional figure with a tactile display and by feeling a three-dimensional shape with a force feedback device.";"2020";"H. Tatsumi and Y. Murai and M. Kobayashi and I. Sekita and M. Miyakawa";"2020 IEEE 50th International Symposium on Multiple-Valued Logic (ISMVL)";"https://doi.org/10.1109/ISMVL49045.2020.00-23"
"Using a rendering engine to support the development of immersive virtual reality applications";"This work presents the features of a flexible realtime 3D graphics engine aimed at the development of multimedia applications and collaborative virtual environments. The engine, called EnCIMA (Engine for Collaborative and Immersive Multimedia Applications), enables a quick development process of applications by providing a high level interface, which has been implemented using the C++ object-oriented programming paradigm. Important characteristics of the engine are the integration of several real time graphics techniques needed by visualization applications; access to network connection management to support collaboration; 3D sound capability; the support to various specialized interaction equipments such as 3D mice, haptic devices, 3D motion trackers, data-gloves, joypads, force feedback joysticks, and; the capacity to have rendering computation and Physics simulation assigned to GPUs and PPUs, respectively. The engine also enables the developer to choose how the scene should be rendered to, i.e. using standard display devices, stereoscopy, or even several simultaneous projection for spatially immersive displays. As part of the evaluation process, we have compared the performance of EnCIMA to a game engine and two scene graph toolkits, through the use of a testbed application.";"2008";"S. R. dos Santos and J. C. de Oliveira and L. M. Fraga and P. R. Trenhago and S. M. Malfatti";"2008 IEEE Conference on Virtual Environments, Human-Computer Interfaces and Measurement Systems";"https://doi.org/10.1109/VECIMS.2008.4592756"
"Robot-Assisted Drilling on Curved Surfaces with Haptic Guidance under Adaptive Admittance Control";"Drilling a hole on a curved surface with a desired angle is prone to failure when done manually, due to the difficulties in drill alignment and also inherent instabilities of the task, potentially causing injury and fatigue to the workers. On the other hand, it can be impractical to fully automate such a task in real manufacturing environments because the parts arriving at an assembly line can have various complex shapes where drill point locations are not easily accessible, making automated path planning difficult. In this work, an adaptive admittance controller with 6 degrees of freedom is developed and deployed on a KUKA LBR iiwa 7 cobot such that the operator is able to manipulate a drill mounted on the robot with one hand comfortably and open holes on a curved surface with haptic guidance of the cobot and visual guidance provided through an AR interface. Real-time adaptation of the admittance damping provides more transparency when driving the robot in free space while ensuring stability during drilling. After the user brings the drill sufficiently close to the drill target and roughly aligns to the desired drilling angle, the haptic guidance module fine tunes the alignment first and then constrains the user movement to the drilling axis only, after which the operator simply pushes the drill into the workpiece with minimal effort. Two sets of experiments were conducted to investigate the potential benefits of the haptic guidance module quantitatively (Experiment I) and also the practical value of the proposed pHRI system for real manufacturing settings based on the subjective opinion of the participants (Experiment II). The results of Experiment I, conducted with 3 naive participants, show that the haptic guidance improves task completion time by 26% while decreasing human effort by 16% and muscle activation levels by 27% compared to no haptic guidance condition. The results of Experiment II, conducted with 3 experienced industrial workers, show that the proposed system is perceived to be easy to use, safe, and helpful in carrying out the drilling task.";"2022";"A. Madani and P. P. Niaz and B. Guler and Y. Aydin and C. Basdogan";"2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)";"https://doi.org/10.1109/IROS47612.2022.9982000"
"An area-of-interest based communication architecture for Shared Haptic Virtual Environments";"Communication architectures conceived for Shared Haptic Virtual Environments (SHVEs) are based on either the client-server or the peer-to-peer paradigms. High-rate rendering and communication between collaborating users quickly leads to performance bottlenecks, if the virtual environment's size and complexity or the number of collaborating users increases. We propose a decentralized communication architecture for SHVEs, which exploits areas of interest (AoI) of a user to dynamically form smaller communication groups. High-rate information exchange following the client-server paradigm is used within these groups to support satisfactory haptic collaboration and consistency. A single group member is selected to simulate the object states and to relay this state to the other group members. Peer-to-peer inter-group communication is also used, based on spatial proximity, to further reduce the overall communication load. We implemented a prototype based on our proposed architecture and present some first evaluation results. They serve as a proof-of-concept and show the effectiveness of dynamic group maintenance in conjunction with additional traffic control schemes.";"2013";"C. Schuwerk and N. Chaudhari and E. Steinbach";"2013 IEEE International Symposium on Haptic Audio Visual Environments and Games (HAVE)";"https://doi.org/10.1109/HAVE.2013.6679611"
"Peer-to-peer control architecture for multiuser haptic collaboration over undirected delayed packet-switching network";"We propose a novel peer-to-peer distributed control architecture for shared haptic collaboration among remotely-located users over undirected packet-switching network (e.g. Internet) with inter-user communication delay. The proposed architecture is distributed, in that each user simulates and interacts with its own local copy of the shared virtual environment. Spring connection among the local copies and local damping are used, which, together, under a certain condition, achieve configuration synchronization among the local copies while enforcing discrete-time passivity of the total peer-to-peer architecture, thereby, rendering the architecture portable/scalable for any (passive) users/devices and ensuring its interaction stability be user/device-invariant. The issue of optimizing communication network is also addressed with some relevant experimental results.";"2010";"D. Lee and K. Huang";"2010 IEEE International Conference on Robotics and Automation";"https://doi.org/10.1109/ROBOT.2010.5509578"
"Tool and object based synchronization in collaborative haptics";"Distributed collaborative virtual environments (CVEs) have traditionally utilized an object-based synchronization model. Avango (Tramberand, http://www.avango.org/paper/paper-final.pdf), for example, implements a distributed shared memory model and synchronizes nodes and fields. Similar models are used by CVEs based on MPEG-4 (Hosseini and Georganas, 2002). We discuss existing object-based synchronization models and the implications of extending these techniques for distributed haptic CVEs. We propose an alternative tool-based synchronization model that synchronizes the event(s) that cause change rather than their effects.";"2002";"F. Bogsanyi and M. L. Miller";"IEEE International Workshop HAVE Haptic Virtual Environments and Their";"https://doi.org/10.1109/HAVE.2002.1106923"
"Virtual reality telerehabilitation: an inter-disciplinary collaboration";"An interdisciplinary collaboration between engineering and allied health clinician-scientists forms the basis for the development and testing of virtual reality technology and it delivery. An overview of the development of the haptic interface used for lower extremity rehabilitation and its interface with web-based technology for the delivery of rehabilitation is described. Preliminary findings are discussed. Future endeavors are outlined.";"2003";"J. E. Deutsch and J. A. Lewis and R. Boian and G. Burdea";"2003 IEEE 29th Annual Proceedings of Bioengineering Conference";"https://doi.org/10.1109/NEBC.2003.1216104"
"Immersive Multiplayer VR: Unreal Engine’s Strengths, Limitations, and Future Prospects";"Virtual Reality (VR) has revolutionized digital interactions, particularly in multiplayer games, where players engage in immersive experiences that foster social connectivity and collaboration. Unreal Engine is at the core of this evolution, a powerful development platform known for its advanced networking tools, VR-specific capabilities, and seamless cross-platform support. Unreal Engine’s cross-platform support also ensures accessibility and scalability across diverse devices. This paper analyzes Unreal Engine’s role in advancing multiplayer VR development, focusing on its ability to create immersive environments that enhance user engagement and social interaction. We examined key features such as real-time networking for seamless communication, detailed avatar customization, and realistic environmental rendering, all contributing to an enhanced sense of presence. Beyond its technical features, this research identifies key challenges in multiplayer VR gaming, including latency, scalability, and ethical concerns related to inclusivity and user privacy. We propose future directions to address these issues, such as integrating artificial intelligence (AI), enhancing haptic feedback, and optimizing large-scale VR projects. By bridging these gaps, Unreal Engine can strengthen its role as a pioneering platform for social interaction, education, and collaboration in virtual spaces. This study also evaluates Unreal Engine’s effectiveness in facilitating social interaction and compares its capabilities with alternative platforms. The findings highlight best practices for VR game developers and provide recommendations to enhance user engagement and accessibility, ensuring that multiplayer VR continues to evolve as a transformative medium.";"2025";"S. Berrezueta-Guzman and S. Wagner";"IEEE Access";"https://doi.org/10.1109/ACCESS.2025.3570166"
"A haptic interface design for a VR-based unskilled doctor training system in Vascular Interventional Surgery";"Vascular Interventional Surgery (VIS) is a minimally invasive surgery technique (MIS) where guidewires and catheters are steered in the vascular system under X-ray imaging. In order to perform these procedures, a radiologist has to be correctly trained to master hand-eye coordination, instrument manipulation and procedure protocols. A tele-operative robotic catheter master system was designed for vascular interventional surgery, to reduce radiation-exposure times, and afford unskilled surgeons the opportunity to learn basic catheter/guidewire skills, while allowing experienced physicians to perform surgeries cooperatively. This paper focuses on the requirements, design and prototyping of the haptic device and the translational and rotational measurement part dedicated to catheters. Two cameras are used to track the translational and rotational displacements of the catheter in real time for the contactless measurement and four permanent magnets and coils are applied to generate the Ampere force in order to realize the haptic feedback. During the training process, novice doctors can drive the real catheter directly and carry out the intervention with haptic interfaces with force feedback, which provides the surgeon with a sense of touch. Additionally, the proposed master system can be used as the controller for not only the virtual reality training system but also the catheter manipulator of a slave system.";"2014";"J. Guo and S. Guo";"2014 IEEE International Conference on Mechatronics and Automation";"https://doi.org/10.1109/ICMA.2014.6885880"
"Proxy Importance Based Haptic Retargeting With Multiple Props in VR";"In virtual reality applications, in addition to visual feedback, real objects can be used as props for virtual objects to provide passive haptic feedback, which greatly enhances user immersion. Usually, real object props are not one-to-one correspondence with virtual objects. Haptic retargeting technique is proposed to establish the virtual-real correspondence by introducing an offset between the virtual hand and the real hand. Sometimes, the offset is too large to cause user discomfort, and it is necessary to introduce a reset between two haptic retargeting operations to force the virtual hand and the real hand to coincide in order to eliminate the offset. However, too many resets can interfere with this immersion. To address this problem, we propose a haptic retargeting method based on proxy importance calculation using multiple props in virtual reality. The concept of proxy importance for props is introduced first, and then a proxy importance based prop selection and placement method for moving virtual objects are proposed. We also improve the performance of our method by using the props’ weighted proxy importance strategy for multi-user collaboration. Compared to the state-of-the-art methods, our method significantly reduces the number of resets, the task completion time, hand movement distances, and task load without the cost of cybersickness in the single-user task. In the multi-user collaborative task, our method also achieves significant improvement using the strategy that weights the proxy importance of the props.";"2025";"Z. Liu and J. Wu and L. Wang and X. Li and S. K. Im";"IEEE Transactions on Visualization and Computer Graphics";"https://doi.org/10.1109/TVCG.2024.3392743"
"Transatlantic Touch: A Study of Haptic Collaboration over Long Distance";"The extent to which the addition of haptic communication between human users in a shared virtual environment (SVE) contributes to the shared experience of the users has not received much attention in the literature. In this paper we describe a demonstration of and an experimental study on haptic interaction between two users over a network of significant physical distance and a number of network hops. A number of techniques to mitigate instability of the haptic interactions induced by network latency are presented. An experiment to evaluate the use of haptics in a collaborative situation mediated by a networked virtual environment is examined. The experimental subjects were to cooperate in lifting a virtual box together under one of four conditions in a between-groups design. Questionnaires were used to report the ease with which they could perform the task and the subjective levels of presence and copresence experienced. This extends earlier work by the authors to consider the possibility of haptic collaboration under real network conditions with a number of improvements. Using the technology described in this paper, transatlantic touch was successfully demonstrated between the Touch Lab at Massachusetts Institute of Technology, USA and Virtual Environments and Computer Graphics (VECG) lab at University College London (UCL), UK in 2002. It was also presented at the Internet II demonstration meeting in 2002 between University of Southern California and the Massachusetts Institute of Technology.";"2004";"J. Kim and H. Kim and B. K. Tay and M. Muniyandi and M. A. Srinivasan and J. Jordan and J. Mortensen and M. Oliveira and M. Slater";"Presence";"https://doi.org/10.1162/1054746041422370"
"Virtual cooperating manipulators as a virtual reality haptic interface";"One central element in the focus on research into human-machine interfaces is the capability to interact physically with the computer model. The sense of touch and feel is vital for realistic manipulation and control of virtual objects. The research described here is the development and implementation of a new dynamic control strategy using a standard six-degree-of-freedom robot manipulator as a force interface to virtual reality systems. The haptic element of VR interfacing is currently the subject of abundant research, some addressing the stability and control of interactive systems but with much of the focus on the development of new hardware systems to support stable interaction between humans and VR graphics displays. However, general six-degree-of-freedom manipulators are well understood today and are known to have the capability for generating the general force and motion constraints necessary for the design interaction described in the story. This approach to haptic feedback capability is based on the concept of describing a virtual manipulator model that mimics the motion constraints imposed by a virtual surface. This virtual manipulator is conceptually linked to an actual manipulator to form a closed kinematic chain system. The closed chain system equations are used to define a set of constraints that control the actual robot manipulator so as to allow motion only in the free directions of the virtual manipulator. These free directions are also the free motion directions allowed by the virtual surfaces one tremendous advantage of the approach is that the control algorithm is formulated using local error feedback schemes at the robot level providing effective, stable, and simple control of the robotic hardware. Using the proposed control scheme will allow any six-degree-of-freedom manipulator to be used as a haptic interface device.";"1996";"G. R. Luecke and J. C. Edwards";"Proceedings Third Annual Symposium on Human Interaction with Complex Systems. HICS'96";"https://doi.org/10.1109/HUICS.1996.549503"
"Group synchronization control for haptic media in networked virtual environments";"This paper proposes a group (or inter-destination) synchronization control scheme for haptic media in networked virtual environments where multiple users manipulate CG objects collaboratively in a 3-D virtual space by using force feedback devices. For group synchronization of haptic media, we enhance the synchronization maestro scheme, which the authors previously proposed for voice and video, so as to adjust the output timing of haptic media among the users. The paper demonstrates the effectiveness of the proposed scheme by experiment.";"2004";"Y. Ishibashi and T. Hasegawa and S. Tasaka";"12th International Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2004. HAPTICS '04. Proceedings.";"https://doi.org/10.1109/HAPTIC.2004.1287184"
"Using collaborative haptics in remote surgical training";"We describe the design and trial of a remotely conducted surgical master class, using a haptic virtual environment. The instructor was located in the United States and the class was in Australia. The responses of the audience and participants are presented.";"2005";"C. Gunn and M. Hutchins and D. Stevenson and M. Adcock and P. Youngblood";"First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. World Haptics Conference";"https://doi.org/10.1109/WHC.2005.141"
"Real-time Interactions and Synchronization of Voxel-based Collaborative Virtual Environments";"Collaborative virtual environments (C-VE) facilitate team-oriented training on virtual reality-based surgical simulators. Many C-VEs replicate the VE on each user's machine to allow for real-time interactions. However, this solution does not work well when modifying voxel-based C-VEs because large and frequent volumetric updates make it difficult to synchronize the C-VE. This paper describes a hybrid depth-buffered image (DBI) and geometry-based rendering method created to simulate visual interactions between local virtual bone cutting tools and remotely maintained volumetric bone material for a craniotomy simulator. For real-time interactions, users only store a DBI of the volumetric C-VE and composite it with rendered images of surgical tools. Additionally, we describe methods to combat network bandwidth/latency to remotely simulate haptic and bone drilling interactions between users' tools and the volumetric VE. For haptic feedback, a multi-rate solution (Cavusoglu and Tendick, 2000) allows users to construct a local approximation of the volumetric C-VE to compute new forces. Only 2D DBI updates are required to synchronize different users when the bone changes due to drilling. Our approach provides an improved performance over a replicated VE that uses 3D model-based updates";"2007";"E. Acosta and A. Liu";"2007 IEEE Symposium on 3D User Interfaces";"https://doi.org/10.1109/3DUI.2007.340785"
"Stability analysis of trilateral haptic collaboration";"This paper presents a criterion for absolute stability of a general class of three-port networks. Trilateral haptic systems, which have recently found many interesting applications, can be modeled as three-port networks. Traditionally, existing criteria (Llewellyn‘s criterion) have facilitated the stability analysis of bilateral haptic systems modeled as two-port networks. If the same criteria were to be used for stability analysis of a three-port network, its third port would need to be assumed known for it to reduce to a two-port network. However, this is restrictive because, according to the definition of absolute stability, all three terminations of the three-port network must be allowed to be arbitrary (while passive). In this paper, extending Llewellyn's criterion, we present closed-form necessary and sufficient conditions for absolute stability of a general class of three-port networks — the three terminations need to be passive but are otherwise arbitrary. To this end, we first find a symmetrization condition under which a general asymmetric impedance (or admittance) matrix Z3×3 has an equivalent symmetric counterpart Zeq; this Zeq models a reciprocal three-port network with the same stability characterization as the general nonreciprocal three-port network modeled by Z. Then, based on the equivalence of passivity and absolute stability for the equivalent reciprocal network, an absolute stability condition for the original nonreciprocal network is derived. To show how the resulting absolute stability criterion can be utilized at the system design stage, we have applied it to the problem of designing controllers for triple-user collaborative haptic virtual environment systems. The validity of the resulting absolute stability conditions have been verified via simulations.";"2013";"J. Li and M. Tavakoli and Q. Huanq";"2013 World Haptics Conference (WHC)";"https://doi.org/10.1109/WHC.2013.6548478"
"Simultaneous Use of Autonomy Guidance Haptic Feedback and Obstacle Avoiding Force Feedback for Mobile Robot Teleoperation";"In teleoperation, force feedback is used not only for feedback on interactions with the environment such as contact but also as a method of providing a virtual guide to support the operator perform tasks efficiently. In particular, in shared teleoperation, which is a method of assisting the operator using autonomy to improve task efficiency and reduce fatigue, force feedback is used as a key means of haptically providing a guide of autonomy to the operator to achieve efficient collaboration. However, it is difficult to use these force guides concurrently with force feedback on interactions. This is because not only the interaction force and the virtual guidance force offset each other when those forces have different directions, but also the interaction force and the virtual guidance force cannot be distinguished, making it difficult for the operator to be aware of the situation. In this paper, we propose a method to solve this problem by assigning different force magnitudes through the different stiffness for each method and for the simultaneous use of both methods. The proposed method is verified through mobile robot teleoperation experiments on the simulation environment, and the experiment result shows that the proposed method performed better than when only one type of force feedback is used.";"2022";"K. -H. Lee and H. Singh and T. Hulin and J. -H. Ryu";"2022 22nd International Conference on Control, Automation and Systems (ICCAS)";"https://doi.org/10.23919/ICCAS55662.2022.10003886"
"Emulated haptic shared control for brain-computer interfaces improves human-robot cooperation";"Today, technology provides many ways for humans to exchange their points of view about pretty much everything. Visual, audio and tactile media are most commonly used by humans, and they support communication in such a natural way that we don't even actively think about using them. But what about people who have lost motor or sensory capabilities for whom it is difficult or impossible to control or perceive the output of such technologies? In this case, perhaps the only way to communicate might be to use brain signals directly. The goal of this study is therefore towards providing people with tetraplegia, who may be confined to their room or bed, with a telepresence tool that facilitates the daily interactions so many of us take for granted. In our case, the telepresence tool is a robot that is remotely controlled. It can act as a medium for the user in their everyday life with the design of a virtual link with friends and relatives located in remote rooms or places or with different environments to explore. Therefore, the objective is to design a Human-Machine System that enables the control of a robot using thoughts alone. The technological part is composed of a brain-computer interface and a visual interface to implement an “emulated haptic shared control” of the robot. Shared motion control is implemented between the user and the robot as well as an adaptive function allocation to manage the difficulty of the situation. The control schema that exploits this “emulated haptic feedback” has been designed and evaluated using a Human-Machine Cooperation framework and the benefit of this type of interaction has been evaluated with five participants. Initial results indicate better control and cooperation with the “emulated haptic feedback” than without.";"2020";"M. -P. Pacaux-Lemoine and L. Habib and N. Sciacca and T. Carlson";"2020 IEEE International Conference on Human-Machine Systems (ICHMS)";"https://doi.org/10.1109/ICHMS49158.2020.9209521"
"A Peer-to-peer Architecture for Collaborative Haptic Assembly";"Virtual environments using haptic devices have proved useful for assembly/disassembly simulation of mechanical components. To date most haptic virtual environments are stand-alone. Collaborative haptic virtual environments (CHVEs) are distributed across a number of users via a network, such as the Internet. These present new challenges to the designer, such as consistency of the virtual environments, user-user haptic interaction, and scalability. The system described in this paper considers the CHVEs to be distributed over a packet-switched network such as the Internet. It gives priority to the validation of interactions between objects grasped by users; guarantees consistency across different users' virtual environments. The paper explains the components used and the consistency-maintenance scheme that guarantees the consistency of the virtual scene in the remote nodes. Consistency and force feedback results are also discussed. Results presented show the system maintains a consistent and satisfactory response when network incurs delay or packet jitter";"2006";"R. Iglesias and S. Casado and T. Gutierrez and A. Garcia-Alonso and K. M. Yap and W. Yu and A. Marshall";"2006 Tenth IEEE International Symposium on Distributed Simulation and Real-Time Applications";"https://doi.org/10.1109/DS-RT.2006.3"
"Learning Based Artificially Assisted Manufacturing Workflow with Augmented Reality – a Comprehensive Study";"The integration of Artificial Intelligence (AI) and Augmented Reality (AR) is revolutionizing modern manufacturing by enhancing automation, efficiency, and human-machine collaboration. This proposal presents a Learning-Based Artificially Assisted Manufacturing Workflow leveraging Deep Reinforcement Learning (DRL) and Transformer-Based models to optimize real-time decision-making, predictive maintenance, and process automation. The system utilizes a combination of Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) for accurate object detection, defect identification, and quality assurance within an AR-enhanced workspace. A Deep Q-Network (DQN) with Transfer Learning is proposed to adaptively optimize robotic movements and resource allocation, ensuring real-time responsiveness to dynamic manufacturing conditions. Additionally, a hybrid AI model combining Long Short-Term Memory (LSTM) networks with Transformer architectures will enable predictive analytics for fault detection and workflow optimization. The AR interface will provide real-time visualization of AI-driven recommendations, guiding human operators through intelligent overlays and haptic feedback mechanisms for seamless human-AI collaboration. The approach aims to develop a scalable, adaptable, and self-learning manufacturing framework that enhances productivity, reduces downtime, and ensures high precision in industrial environments. The proposed AI-AR hybrid system will significantly advance Industry 4.0 and smart manufacturing, bridging the gap between human expertise and machine intelligence through a data-driven, learning-based approach.";"2025";"T. U. Mageswari and J. Raja";"2025 11th International Conference on Communication and Signal Processing (ICCSP)";"https://doi.org/10.1109/ICCSP64183.2025.11088622"
"Dual Purpose Multi-User Semi-Immersive Hapto-Acoustic Virtual Environment";"Our hapto-acoustic virtual environment we call the \"haptic-workbench\" [1], has remained unchanged since 1994. Recent changes in available projector hardware technology now means that the system can be modified to address some inherent limitations in terms of user participation. In addition, the proposed changes are now more viable, whereas only six months ago such modifications were prohibitively expensive or not possible. Up to now the system has used active stereo for 3D graphics visualization but this implementation limits effective participation to one person. The new dual purpose environment is a more versatile system which may be used in one of two ways; a) single user mode or b) large volume display mode where many users can simultaneously participate. The semi-immersive attributes of the former haptic-workbench are retained in single user mode and when in large volume display mode the system allows multiple user involvement and interaction. The new dual purpose multi-user environment removes some of the restrictions which effectively limit interaction to one person operating in a narrow viewing space, is not limited to rooms needing special seating or lighting and addresses the increasing need for a sense of presence and interaction with many persons simultaneously. Groups of up to 30 can now experience the collaborative virtual environment (CVE) [2] rather than single user at a time and when networked allows the system to be used for educational interaction in a classroom setting with the possibility of similar numbers at each end. Methodology and some traps and pitfalls are discussed in terms of differing technologies used in generating the real time 3D stereo models and the realisation of the new system is given.";"2005";"T. Adriaansen";"Digital Image Computing: Techniques and Applications (DICTA'05)";"https://doi.org/10.1109/DICTA.2005.32"
"Immerstar, a still evolving 25 years old VR research facility";"The two platforms Immersia and Immermove offer an immersive collaborative space called ImmerStar, intended for the scientific and industrial community, for international research projects. Immersia is a 3D virtual reality platform which, thanks to its exceptional dimensions, offers an environment for experimentation, particularly in the context of real-time and multi-modal interaction (vision, sound, haptics, brain-computer interface) between humans and virtual models. Immermove is a technological platform dedicated to motion capture, extended by a virtual reality space. It enables the precise capture of rapid movements (sports for example) or of a group of people, in order to study human behavior such as crowd-movement or sport gestures. This paper presents the history of the evolution of these two joint platforms, an overview of their technical specifications, associated research projects and perspective of evolutions.";"2025";"R. Gaugne";"2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)";"https://doi.org/10.1109/VRW66409.2025.00045"
"Encountered-type haptic interface for virtual interaction with real objects based on implicit surface haptic rendering for remote palpation";"The shortage of physicians afflicting developed countries encourages engineers and doctors to collaborate towards the development of telemedicine. In particular, robotic systems have the potential for helping doctors making examination. A very common examination that can be the goal of a robotic system is palpation. Most of the robotics systems that have been developed for palpation present interesting features such as integrating augmented reality environments or allowing for hand free interaction. In this paper we present a novel palpation system that allows us to perform virtual palpation of real objects by means of a haptic and an augmented reality feedback. This system features an encountered-type haptic interface in which the haptic feedback is calculated by a collision detection algorithm that is based on online recording of the surface to be touched. The system allows the users to remove their hand from the haptic interface end-effector that follows the user's hand thanks to the tracking performed by a Leap Motion. We show that the system provides a natural interaction during the contact-non contact switch, a suitable force during indentation, and it allows to discriminate objects within the body through the haptic channel.";"2015";"A. Filippeschi and F. Brizzi and E. Ruffaldi and J. M. Jacinto and C. A. Avizzano";"2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)";"https://doi.org/10.1109/IROS.2015.7354216"
"Mixed Reality based Robot Teleopeation with Haptic Guidance";"The current generation of Industry 4.0 emphasises human robot cooperation to perform the complex tasks. When they work together, the task completion depends on the effectiveness of the communication especially while they cooperate remotely. In this paper, we propose an Mixed Reality (MR) based information transfer method for Human-Robot Interaction (HRI) to assist users in remotely performing tasks. The effective path information gave to the user through haptic feedback, generated using the Artificial Potential Field (APF) method, aids users in controlling robots without collisions. We develop multimodal user interface with MR environment to enhance the communication between remote and local side. This seamless communication is facilitated through multiple modalities such as haptic, touch, speech, visual, and text. We analyse the system with user studies. The result reveals that the participants can able to successfully complete the task using the system and preferred proposed method compared to hand based robot teleoperation. In addition to that, we found that the user favoured audio, hologram, haptic based information exchange more than text base information exchange. The analysis of the different type of haptic feedback revealed that the user preferred dynamic haptic feedback.";"2024";"S. Raj and Y. Sinha and P. Biswas";"2024 IEEE Conference on Telepresence";"https://doi.org/10.1109/Telepresence63209.2024.10841737"
"Integrating Kinect and haptics for interactive STEM education in local and distributed environments";"Skill shortage is a realistic social problem that Australia is currently facing, especially in the fields of Science, Technology, Engineering and Mathematics (STEM). Various approaches have been proposed to soften this issue. By now the most successful approach is to attract pre-university youth and university freshmen into those fields before they make a decision on future subjects by introducing them with interactive, modifiable and inspiring virtual environments, which incorporates most essential knowledge of STEM. We propose to design a comprehensive virtual reality platform with immersive interactions, pluggable components and flexible configurations. It also involves haptics, motion capture and gesture recognition, and could be deployed in both local and distributed environments. The platform utilizes off the shelf low cost haptics and motion capture products, however the fidelity can be maintained at a good level. The proposed platform has been implemented with different configurations and has been tested on a group of users. Preliminary test results show that the interactivity, flexibility and fidelity of the platform are highly appreciated by users. User surveys also indicate that the proposed platform could help pre-university students and university freshmen build an overview of various aspects of STEM education. Besides, users are also positive on the fact that the platform enabled them to identify the challenges for higher education in STEM by providing them opportunities to interactively modify system configurations and instantly experience the corresponding results both visually and haptically.";"2013";"L. Wei and H. Zhou and A. K. Soe and S. Nahavandi";"2013 IEEE/ASME International Conference on Advanced Intelligent Mechatronics";"https://doi.org/10.1109/AIM.2013.6584234"
"Separate DOF control and mutual guidance in networked haptic collaboration maze game: Design and evaluation";"In this paper we study on haptic collaboration in a maze game over computer network. Two players located at separated places operate each haptic device to collaboratively finish the game task. Herein, a new collaboration mode of manipulation separate DOF control is proposed for the first time. Separate DOF control here means each player controls one DOF of an object or a task independently in collaborative virtual environment. Mutual guidance is also proposed which provides guidance force to each player. We setup an experiment to evaluate its efforts on cooperation performance and co-presence. Twelve participants did the experiment. The results revealed that this collaboration mode is effective. Ten of the twelve participants believed that they performed well in the experiment and thought the collaboration way was very interesting. The presented results motivated a new haptic collaboration mode in the fields of game design, education and cooperative assembly.";"2011";"Lingzhi Liu and Guanyang Liu and Yuru Zhang and Weidong Guo and Keke Lu and Moyuan Zhou";"2011 IEEE International Conference on Robotics and Automation";"https://doi.org/10.1109/ICRA.2011.5979832"
"Object manipulation in visuo-haptic augmented reality with physics-based animation";"We present an approach for visuo-haptic augmented reality, which is focused on object manipulation tasks. The interactive environment combines three-DOF haptic rendering and physics-based animation. A desktop haptic device with force feedback is driven by the user to interact with movable virtual objects that are superimposed upon a visual representation of the real workspace. Virtual objects coexist with real objects in the augmented reality space and are simulated in a physically plausible manner. The system supports both rigid and deformable objects with arbitrary shape. Accurate algorithms for camera calibration, registration, object manipulation and feedback computation have also been developed. Several experiments have been performed in order to test both single and dual-user collaborative tasks.";"2010";"J. Aleotti and F. Denaro and S. Caselli";"19th International Symposium in Robot and Human Interactive Communication";"https://doi.org/10.1109/ROMAN.2010.5598707"
"Proceedings 2nd IEEE International Workshop on Haptic, Audio and Visual Environments and their Applications - HAVE 2003 (Cat. No.03EX730)";"The following topics are dealt with: lip feature extraction; tele-haptics; augmented reality: panorama-based virtual environments; vision-based robot localization; haptic/graphic interface; neural network architecture; 3D object representation; artificial muscles; audio classification; VoIP; virtual interactive environments; musical noise reduction; image quality measurement; digital watermarking; haptic virtual environment; optical character recognition; dynamic signature verification system; audio watermarking; collaborative virtual environments; humanoid avatar; and surface reconstruction.";"2003";NA;"The 2nd IEEE Internatioal Workshop on Haptic, Audio and Visual Environments and Their Applications, 2003. HAVE 2003. Proceedings.";"https://doi.org/10.1109/HAVE.2003.1244714"
"Towards an Internal Process Model for Haptic Interactions within Virtual Environments";"Interactive human-machine systems (HMS), such as compute-based virtual environments (VEs), have been increasingly relied upon for decision-making. Building trust between human users and machines is crucial to enable a cooperative relationship. One aspect of building trust requires modeling sensory feedback from virtual objects in VEs to the users for appropriate understanding and utilization. In current VEs, of interest is modelling the integration of vibrotactile and force cues for providing sensory feedback to stimulate the haptic modality of the users. Behavioral models, such as maximum likelihood estimation, have failed to interpret the integration. Underlying this failure might be subtle internal processes of the human brain. Hence, we conducted an experiment to investigate the feasibility of modeling the integration using a drift-diffusion model (DDM), which is known to bridge observed behavioral outcomes and internal processes. In the experiment, human participants undertook a navigation and detection task within a 3D VE. Their task execution was aided by vibrotactile or/and force cues. Analyses on task accuracy and response time to the cues confirmed that DDM was feasible to interpret behavioral outcomes of the participants. The interpretation implies a link between the outcomes and the internal processes, paving a potential way to use DDM for elucidating the integration of vibrotactile and force cues.";"2021";"S. Tarng and J. Campbell and Y. Hu";"2021 IEEE International Conference on Systems, Man, and Cybernetics (SMC)";"https://doi.org/10.1109/SMC52423.2021.9659163"
"Virtual Palpation for Medical Training in Cyberworlds";"In this paper, we introduce a new approach to virtual palpation for medical training in cyber worlds. We analyze palpation as a medical procedure. Then, we survey the existing virtual palpation projects, which use haptic devices, and propose a new image-driven approach to haptic palpation that can be easily ported to any web-enabled and collaborative environments. We also introduce variable haptic interaction point that allows us to implement multiple-point haptic interaction while using a single-point desktop haptic device. Lastly, we prove our hypothesis by implementing the proposed approach for abdominal palpation and validating it with medical practitioners. We also discuss the advantages of our method over other existing works in terms of flexibility, simplicity and scalability.";"2012";"S. Yasmin and A. Sourin";"2012 International Conference on Cyberworlds";"https://doi.org/10.1109/CW.2012.36"
"Does vibrotactile intercommunication increase collaboration?";"Communication is a fundamental process in collaborative work. In natural conditions, communication between team members is multimodal. This allows for redundancy, adaptation to different contexts, and different levels of focus. In collaborative virtual environments, however, hardware limitations and lack of appropriate interaction metaphors reduce the amount of collaboration. In this poster, we propose the design and use of a vibrotactile language to improve user intercommunication in CVE and, consequently, to increase the amount of effective collaboration.";"2015";"V. A. d. J. Oliveira and W. J. Sarmiento and A. Maciel and L. Nedel and C. A. Collazos";"2015 IEEE Virtual Reality (VR)";"https://doi.org/10.1109/VR.2015.7223391"
"A Complementary Framework for Human–Robot Collaboration With a Mixed AR–Haptic Interface";"There is invariably a tradeoff between safety and efficiency for collaborative robots (cobots) in human–robot collaborations (HRCs). Robots that interact minimally with humans can work with high speed and accuracy but cannot adapt to new tasks or respond to unforeseen changes, whereas robots that work closely with humans can but only by becoming passive to humans, meaning that their main tasks are suspended and efficiency compromised. Accordingly, this article proposes a new complementary framework for HRC that balances the safety of humans and the efficiency of robots. In this framework, the robot carries out given tasks using a vision-based adaptive controller, and the human expert collaborates with the robot in the null space. Such a decoupling drives the robot to deal with existing issues in task space [e.g., uncalibrated camera, limited field of view (FOV)] and null space (e.g., joint limits) by itself while allowing the expert to adjust the configuration of the robot body to respond to unforeseen changes (e.g., sudden invasion, change in environment) without affecting the robot’s main task. In addition, the robot can simultaneously learn the expert’s demonstration in task space and null space beforehand with dynamic movement primitives (DMPs). Therefore, an expert’s knowledge and a robot’s capability are explored and complement each other. Human demonstration and involvement are enabled via a mixed interaction interface, i.e., augmented reality (AR) and haptic devices. The stability of the closed-loop system is rigorously proved with Lyapunov methods. Experimental results in various scenarios are presented to illustrate the performance of the proposed method.";"2024";"X. Yan and Y. Jiang and C. Chen and L. Gong and M. Ge and T. Zhang and X. Li";"IEEE Transactions on Control Systems Technology";"https://doi.org/10.1109/TCST.2023.3301675"
"A Scheme for Haptic Data Transmission Under Various Network Conditions";"Haptic Collaboration Virtual Environment (HCVE) is an enhanced virtual reality space that supports sense of touch, which is called \"haptic\". In HCVE, remote users connected over networks are able to collaborate by sharing touching experiences in addition to well-established audio and visual interfaces. The success of HCVE largely depends on timely transmission of haptic data despite time-varying network conditions such as delay, loss, and jitter. However, the fact that the data generation frequency of haptic interface devices is extremely high, e.g. 1 KHz, makes the realization of successful HCVE more challenging. For seamless haptic data communication even under adverse network conditions, we propose a linear prediction algorithm and a buffering scheme. The prediction algorithm, which is basically extrapolation, is to mitigate the negative effects of network delay, loss and jitter, and the buffering scheme is to help synchronization of haptic interaction between remote users. We build an experimental test bed for the evaluation of our proposed schemes, and as the results of analyzing quantitative measurement results, conclude that those are effective in improving the quality of haptic experiences.";"2007";"Y. You and M. Y. Sung and K. Jun";"2007 IEEE International Conference on Multimedia and Expo";"https://doi.org/10.1109/ICME.2007.4285131"
"Experimental QoS Optimization for Haptic Communication Over Tactile Internet";"So far, most haptic applications are standalone systems or endeavors to provide collaborated haptic virtual environments. With the emergence of the Tactile Internet (TI), ultra-low-delay and ultra-high-reliable communications will enable a paradigm shift from traditional content-oriented communication to control-oriented communication. Specifically, The human-in-the-loop Tactile Internet enables the vision of delivering human skills e.g, feeling and manipulating, in addition to the human knowledge e.g., seeing and hearing, remotely, adding more life to the Internet of skills. Within this paradigm, human multisensory information for interaction and communication with the remote environment needs to be exchanged. In this paper, we present an experimental study to optimize objective quality evaluation for multimodal communication especially haptic, over the Internet. For that purpose, a simulated haptic model based on the ALPHAN protocol was implemented on Riverbed modular to generate real haptic traffics over an infrastructure that mimics the TI, the model was used to select appropriate Diffserv QoS solutions in a large-scale collaborated haptic environment. The outcome of the study found that deploying custom queuing with low latency queue (LLQ) or Priority Queuing (PQ) in conjunction with ALPHAN protocol can be used to dramatically enhance the network performance of haptic communication.";"2018";"M. Al Ja'afreh and H. Adharni and A. El Saddik";"2018 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE)";"https://doi.org/10.1109/HAVE.2018.8547504"
"Touching Virtual Humans: Haptic Responses Reveal the Emotional Impact of Affective Agents";"Interpersonal touch is critical for social-emotional development and presents a powerful modality for communicating emotions. Virtual agents of the future could capitalize on touch to establish social bonds with humans and facilitate cooperation in virtual reality (VR). We studied whether the emotional expression of a virtual agent would affect the way humans touch the agent. Participants were asked to hold a pressure-sensing tube presented as the agent’s arm in VR. Upon seeing the agent’s emotional expression change, participants briefly squeezed the arm. The effect of emotional expressions on affective state was measured using self-reported valence and arousal as well as physiology-based indices. Onset, duration, and intensity of the squeeze were recorded to examine the haptic responses. Emotional expression of agents affected squeeze intensity and duration through changes in emotional perception and experience. Haptic responses may thus provide an implicit measure of persons’ experience towards their virtual companion.";"2023";"I. Ahmed and V. J. Harjunen and G. Jacucci and N. Ravaja and T. Ruotsalo and M. M. Spapé";"IEEE Transactions on Affective Computing";"https://doi.org/10.1109/TAFFC.2020.3038137"
"Haptic-Enabled Telementoring Surgery Simulation";"Medical surgery involves a high degree of skill and experience, making the learning curve for medical trainees quite long. For instance, in eye cataract surgery, despite it only taking around seven minutes for a well-trained surgeon to perform and having a success rate of 99 percent, medical residents need months to become proficient in this procedure to avoid its typical complications. Medical trainees traditionally have acquired surgical skills through apprenticeships in which trainees observe senior surgeons, then perform under guidance until they achieve mastery. Training often makes use of cadavers or laboratory animals, but this type of training is becoming increasingly difficult to do in many countries due to ethical reasons. An effective alternative is medical simulation, which can enhance understanding, improve performance, and assess competence; in preoperative settings, it assists surgeons in remaining at a high technical skill level. Surgical simulation can provide high-fidelity training that increases the diffusion of innovative and less- invasive procedures while decreasing the surgeon's learning curve.";"2008";"X. Shen and J. Zhou and A. Hamam and S. Nourian and N. R. El-Far and F. Malric and N. D. Georganas";"IEEE MultiMedia";"https://doi.org/10.1109/MMUL.2008.9"
"Normalizing Task-Oriented Human-Robot Interaction for Large-Scale Virtual Environments";"Physical simulation platforms, including haptic manipulanda and robotic rehabilitation systems, enable controlled human-robot interaction, but variability in users' physical attributes impacts consistency across individuals. Here, we present a method to standardize user effort in a physical tracking task, a common paradigm in rehabilitation and motor learning, where participants interact with a manipulator simulating a virtual environment. In addition to optimizing the initial configuration and scaling of the task trajectory, we analyze the effect of different scaling factors on the robot's virtual stiffness matrix, the impedance parameter that largely determines the effort required during the task. Simulations of nine virtual participants with varying heights and masses show that allometric scaling of robot's virtual stiffness by a factor of $(\mathrm{m} / \mathrm{h})^{2 / 3}$ best minimizes effort disparities. These findings advance the development of adaptive physical simulation platforms for rehabilitation, training, human motor control experiments, and human-robot collaboration.";"2025";"B. Balta and K. N. Hafiz and J. Realmuto";"2025 International Conference On Rehabilitation Robotics (ICORR)";"https://doi.org/10.1109/ICORR66766.2025.11063133"
"Environment Perception in the Presence of Kinesthetic or Tactile Guidance Virtual Fixtures";"During multi-lateral collaborative teleoperation, where multiple human or autonomous agents share control of a teleoperation system, it is important to be able to convey individual user intent. One option for conveying the actions and intent of users or autonomous agents is to provide force guidance from one user to another. Under this paradigm, forces would be transmitted from one user to another in order to guide motions and actions. However, the use of force guidance to convey intent can mask environmental force feedback. In this paper we explore the possibility of using tactile feedback, in particular skin deformation feedback, skin deformation feedback to convey collaborative intent while preserving environmental force perception. An experiment was performed to test the ability of participants to use force guidance and skin deformation guidance to follow a path while interacting with a virtual environment. In addition, we tested the ability of participants to discriminate virtual environment stiffness when receiving either force guidance or skin deformation guidance. We found that skin deformation guidance resulted in a reduction of path-following accuracy, but increased the ability to discriminate environment stiffness when compared with force feedback guidance.";"2015";"S. B. Schorr and Z. F. Quek and W. R. Provancher and A. M. Okamura";"2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)";NA
"Cartesian task allocation for cooperative, multilateral teleoperation under time delay";"Field robots used in unstructured and dynamic environments - and teleoperation have shifted into the focus of a variety of industrial branches in the past few years. The lack of space in the atomic industry, on oil platforms and in space applications demands additional adaptations to current robotic setups. In this paper a MMSS (Multi-Master-Single-Slave) haptic teleoperation system is proposed through which one operator using two master arms can manipulate objects in a cooperative way via one slave robot and a virtual gripping point. To ease the execution of a peg-in-hole task of big objects, a task allocation in the cartesian frame of the virtual gripping point is introduced additionally. The stability of this multilateral system with time delay is guaranteed by the Time Domain Passivity Approach. Therefore the system is divided into several modular subsystems which renders the system easily adaptable to other scenarios.";"2015";"M. Panzirsch and R. Balachandran and J. Artigas";"2015 IEEE International Conference on Robotics and Automation (ICRA)";"https://doi.org/10.1109/ICRA.2015.7139017"
"RecHap: An Interactive Recommender System for Navigating a Large Number of Mid-Air Haptic Designs";"Designing haptics is a difficult task especially when the user attempts to design a sensation from scratch. In the fields of visual and audio design, designers often use a large library of examples for inspiration, supported by intelligent systems like recommender systems. In this work, we contribute a corpus of 10 000 mid-air haptic designs (500 hand-designed sensations augmented 20x to create 10 000), and we use it to investigate a novel method for both novice and experienced hapticians to use these examples in mid-air haptic design. The RecHap design tool uses a neural-network based recommendation system that suggests pre-existing examples by sampling various regions of an encoded latent space. The tool also provides a graphical user interface for designers to visualize the sensation in 3D view, select previous designs, and bookmark favourites, all while feeling designs in real-time. We conducted a user study with 12 participants suggesting that the tool enables people to quickly explore design ideas and experience them immediately. The design suggestions encouraged collaboration, expression, exploration, and enjoyment, which improved creativity support.";"2024";"K. Theivendran and A. Wu and W. Frier and O. Schneider";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2023.3276812"
"Virtual environment for robotic tele-rehabilitation";"Haptic and visual displays are combined to realize cooperative, force-feedback tasks over the Internet. The operators \"exert\" forces on a virtual object which in turn generates a set of reaction forces to be displayed on the haptic devices. A novel cooperative control architecture based on wave variables is implemented to realize stable operation in the presence of time delays. The control scheme is validated experimentally for a manipulation task over the Internet using a pair of InMotion2 robots. Preliminary results are also presented for 3D tasks rendered on a head-mounted display equipped with a head tracker for changing viewing angles.";"2005";"J. Tang and C. Carignan and S. Gattewar";"9th International Conference on Rehabilitation Robotics, 2005. ICORR 2005.";"https://doi.org/10.1109/ICORR.2005.1501121"
"Real-Time Medical Training in Virtual Reality over 5G Open RAN: A Performance Study";"The convergence of immersive technologies and next-generation communication networks offers new potential for advancing surgical training. This paper presents the Magos Bakri Balloon Placement Training (MBBPT) system, a Virtual Reality (VR) simulation platform integrated with haptic feedback and 5th Generation (5G) Open Radio Access Network (O-RAN) connectivity. The system enables realistic and interactive medical training, leveraging submillimeter-precision hand tracking and kinesthetic feedback from Magos gloves. To evaluate the feasibility and performance of network-assisted VR training, MBBPT was tested across a disaggregated O-RAN-based private 5G testbed at University College Dublin (UCD), a standalone private 5G testbed at Patras, and a cross-site setup linking both. The setup assessed Key Performance Indicators (KPIs) and Key Value Indicators (KVIs) to show the system supports responsive, multiuser VR interactions across geographically distributed sites, with consistent performance. These findings highlight the role of 5G O-RAN as an enabler for scalable, collaborative, high-fidelity immersive medical education.";"2025";"V. Ravihansa and C. Sandeepa and O. Vasilapostolos and F. McAuliffe and E. Mangina and M. Liyanage";"2025 IEEE 50th Conference on Local Computer Networks (LCN)";"https://doi.org/10.1109/LCN65610.2025.11146288"
"Assessment of Environmental Effects on Collaborative Haptic Guidance";"This paper investigates the effect of environmental factors on user performance in a dual-user haptic guidance system. The system under study allows for interaction between both users, the trainee and the trainer, to collaboratively perform a common task in a shared virtual environment. User studies are carried out to experimentally evaluate the users' performance while following square and circular trajectories with two viewpoints of the environment (top view and front view), while the virtual manipulator tool moves in free motion or against forbidden-region virtual fixtures. The performance is measured and statistically evaluated against task completion time, tracking accuracy, and user energy exchange. The studies revealed that changing the environment geometry from a square to a circle results in reduced task completion time and tracking error. Changing the environment viewpoint from top to front decreases the task completion time in both geometries. Forbidden-region virtual fixtures increase energy exchange by both users and decrease task completion time while compromising the tracking performance in the square-following task. However, when visual feedback is removed in the presence of the fixtures, the square tracking performance improves. The results also indicate a strong relationship between user dominance and tracking error only when the experiment is time-limited.";"2011";"B. Khademian and J. Apkarian and K. Hashtrudi-Zaad";"Presence";"https://doi.org/10.1162/PRES_a_00044"
"Pseudo-Haptics Survey: Human-Computer Interaction in Extended Reality and Teleoperation";"Pseudo-haptic techniques are becoming increasingly popular in human-computer interaction. They replicate haptic sensations by leveraging primarily visual feedback rather than mechanical actuators. These techniques bridge the gap between the real and virtual worlds by exploring the brain’s ability to integrate visual and haptic information. One of the many advantages of pseudo-haptic techniques is that they are cost-effective, portable, and flexible. They eliminate the need for direct attachment of haptic devices to the body, which can be heavy and large and require a lot of power and maintenance. Recent research has focused on applying these techniques to extended reality and mid-air interactions. To better understand the potential of pseudo-haptic techniques, the authors developed a novel taxonomy encompassing tactile feedback, kinesthetic feedback, and combined categories in multimodal approaches, ground not covered by previous surveys. This survey highlights multimodal strategies and potential avenues for future studies, particularly regarding integrating these techniques into extended reality and collaborative virtual environments.";"2024";"R. Xavier and J. L. Silva and R. Ventura and J. A. P. Jorge";"IEEE Access";"https://doi.org/10.1109/ACCESS.2024.3409449"
"Co-Actuation: A Method for Achieving High Stiffness and Low Inertia for Haptic Devices";"Achieving high stiffness and low inertia is a big challenge for current haptic devices. Impedance-based devices are limited in providing high stiffness while, in contrast, admittance-based devices are limited in generating low inertia. Thus, it is difficult to simulate hard contact and small inertia simultaneously in virtual environments. In this paper, we introduce a co-actuation module to overcome this difficulty. The module is a one degree-of-freedom (DOF) revolute joint which consists of a link and a physical constraint with a clearance between the two components. A motor controls the physical constraint moving cooperatively with the link. In free space, the constraint has no contact to the link and thus, users can move the link freely without feeling the inertia of the motor. In constrained space, the constraint comes into contact with the link and thus, users can feel a resistance from the motor. By means of a direct physical contact between the link and the constraint, users can feel a hard virtual surface. This paper describes the principle and the implementation of the proposed co-actuation module. Performance evaluation was conducted using a two-DOF haptic device in a task workspace of 100 mm × 100 mm. The effective inertia of the device is 64-142 g within the task workspace. The device can stably render a virtual wall with stiffness as high as 65 N/mm. The penetration to the virtual wall was 0.02-0.41 mm when tapping the wall with a speed range of 80-320 mm/s. The maximum back driving force was about 0.19 N when moving within 4.5-8.6 mm/s. The experimental results demonstrate that the concept of co-actuation is feasible in achieving high force, high stiffness range and low inertia for haptic devices.";"2020";"R. Chu and Y. Zhang and H. Zhang and W. Xu and J. -H. Ryu and D. Wang";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2019.2944611"
"Force control with hybrid actuator for virtual needle insertion";"In virtual reality, some applications demand a fast, stable force response with high strength for use in haptic interfaces. While the existing active and passive actuators cannot fully satisfy these requirements alone, their cooperation could provide better results. This study aimed at the development of a hybrid actuator by combining a DC servomotor and a particle brake. The actuator was tested for multilayered tissue simulation, which required rendering abrupt changes and large forces. The designed controller adjusted the actuator inputs based on their capabilities. The brake provided an average force level while the motor superimposed the finer details on this profile. The hybrid actuator was able to track the force profile very well during virtual needle insertion and removal. It also provided a very rigid feeling when the needle touched the bone.";"2011";"B. Gonenc and H. Gurocak";"2011 IEEE World Haptics Conference";"https://doi.org/10.1109/WHC.2011.5945481"
"Design and Development of a Novel Haptic Device with Gravity Compensation for Teleoperation";"In the local portion of teleoperation system, haptic devices determine the reliability of the motion capture and the authenticity of virtual force feedback, which undertake the cooperation between the operator and remote environment. In order to perform large workspace of the local teleoperation robot, a novel haptic device with 6DOF force feedback is proposed in this paper. In addition, a synthetical gravity compensation system is applied for counterbalancing the gravity torques. Static balancing at arbitrary position is achieved observably which reinforces transparency in the teleoperation. Subsequently, idiographic performance including maximum exertable force and translational resolution are analyzed based on Jacobian matrix. For teleoperation application, the workspace of the master-slave based on kinematics is mapped and verified in the virtual environment. The demonstration is stably visualized to the operator and the result indicates that developed haptic device works and presents good performance.";"2022";"L. Meng and S. Kang and W. Chou";"2022 IEEE International Conference on Mechatronics and Automation (ICMA)";"https://doi.org/10.1109/ICMA54519.2022.9856150"
"A multimodal teleoperation interface for human-robot collaboration";"Human-robot collaboration provides an effective approach to combine human intelligence and the autonomy of robots, which can improve the safety and efficiency of the robot. However, developing an intuitive and immersive human-robot interface with multimodal feedback for human-robot interaction and collaboration is still challenging. In this paper, we developed a multimodal-based human-robot interface to involve humans in the loop. The Unity-based virtual reality (VR) environment, including the virtual robot manipulator and its working environment, was developed to simulate the real working environment of robots. We integrated the digital twin mechanism with the VR environment development, which provides a corresponding model with the physical task. The virtual environment could visualize the visual and haptic feedback through the multimodal sensors in the robot, which provides an immersive and friendly teleoperating environment for human operators. We conduct user study experiments based on NASA Task Load Index, through a physical contact scanning task. The result shows that the proposed multimodal interface improved by 31.8% in terms of the cognitive and physical workload, comparing with the commercial teleportation device Touch X.";"2023";"W. Si and T. Zhong and N. Wang and C. Yang";"2023 IEEE International Conference on Mechatronics (ICM)";"https://doi.org/10.1109/ICM54990.2023.10102060"
"Virtual Potential Field-Based Motion Planning for Human-Robot Collaboration via Kinesthetically Guided Teleoperation";"Driven by the evolving role of modern robots in collaboration with human operators, this paper proposes a virtual potential field-based motion planning and control strategy to realize effective human-robot collaboration through kinesthetic guidance via robot teleoperation. The motion of the teleoperated robot is determined by the human operator using a haptic device programmed to replicate movement under the influence of the virtual potential field constructed based on the obstacles and objectives in the environment. This approach facilitates seamless cooperation between the human and collaborative robot. It can also be readily generalized to include moving obstacles and goals in a dynamic environment. The results suggest that the virtual potential field can effectively enhance the safety and accuracy of human-robot cooperation. The developed method has promising applications in human-centric robotics fields such as medical robotics and robot-assisted surgeries.";"2023";"Y. Shi and T. Wang and J. Yu and S. Xiao and L. Xiong and L. Yang";"2023 7th International Conference on Robotics, Control and Automation (ICRCA)";"https://doi.org/10.1109/ICRCA57894.2023.10087678"
"VR-based dynamics learning system using haptic device and its evaluation";"The role of computer tools and facilities become quite important to support educational activity in the school. In this view, many e-learning software are investigated, such as CAI (computer assisted instruction), WBT (Web based training), ILE (interactive learning environment), micro-world, CSCL (computer supported collaborative learning) (Galcev et al., 2001) and so on conventionally. On the other hand, VR (virtual reality) technology is focused as a new multimedia paradigm and is introduced into a lot of application software. And the costs of those VR facilities are reduced recently. For instance, a haptic device which offers the user such as force feedback would be powerful support tool for education at school and gives the student a direct feeling and more real feeling. In this paper, the new e-learning framework which is combined micro-world style ILE and VR concept is proposed. Also the prototype system which treats physical knowledge as the learning domain and introduces the PHANToM (personal haptic interface mechanism) as a haptic device is described.";"2005";"M. Inoue and Y. Matsubara and N. Iwane and M. Nakamura and M. Ichitsubo";"Fifth IEEE International Conference on Advanced Learning Technologies (ICALT'05)";"https://doi.org/10.1109/ICALT.2005.306"
"I Feel You: Impact of Shared Body Sensations on Social Interactions in Virtual Reality";"While one’s facial expression and voice can be easily broadcasted from one to many via digital media, the sense of touch is limited to direct interactions. What happens if such body sensations can be shared across individuals, in which one feels a touch while watching someone else being touched? In this work, we investigated the impact of such shared body sensations on social interactions in virtual reality (VR). Building upon previous research that used psychophysics methods, our work explores the practical implications of shared body sensations in Social VR, which enables interactions beyond what’s physically possible. We conducted a withingroup user study ($\mathrm{n}=32$) in which participants observed conversations between two virtual agents and shared touch with one of the agents, as shown in Figure 1. Our results showed that even experiencing shared touch sensations several times during a conversation can affect social perception and behavior. Participants reported a stronger body illusion and empathy towards the virtual agent they shared touch with and stood closer to them. These results occurred both with and without a virtual mirror that made participants’ selfavatars more salient. The findings from this study introduce a new technique to enhance social connectedness in VR, and we discuss its applications in various contexts, such as asynchronous communication and collaboration.";"2024";"Y. Tao and J. Egelman and J. N. Bailenson";"2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)";"https://doi.org/10.1109/ISMAR62088.2024.00126"
"Impact of Multimodal Instructions for Tool Manipulation Skills on Performance and User Experience in an Immersive Environment";"With the mentoring model, a mentee can learn technical skills under the supervision of more experienced peers who demonstrate their knowledge through several communication modalities. Supporting the mentoring model within shared immersive training simulators holds promise in enhancing mentor-mentee interactions and learning outcomes in a safe environment. However, efficient communication within these spaces remains an open issue. This work presents a user study that explores the combination of communication modalities (verbal-visual, verbal-haptic, visual-haptic, and verbal-visual-haptic) to convey instructions to learners on the amplitude of movements to perform during a tool-handling task in an immersive environment. The study aims to examine the impact of the four modality combinations on performance (speed and accuracy of movement replication), mental workload, and participants’ user experience. The results show that participants achieved higher accuracy with the visual-haptic and verbal-visual-haptic conditions. Moreover, they performed the movements faster, and their movement trajectories were closer to the reference trajectories in the visual-haptic condition. Finally, the most preferred verbal-visual-haptic combination enhanced the users’ sense of presence, co-presence, social presence, and learning experience. No impact on the mental workload was observed. These results suggest that combining haptic and visual modalities is the best suited for enhancing learners’ performance. Adding the verbal modality can also improve the user experience in the immersive learning environment. These findings contribute to improving the design of immersive collaborative systems and pave the way for exploring novel avenues of research into the efficacy of multimodal communication for enhancing the mentoring-based acquisition of technical skills in VR. These tools hold promise for diverse applications, including medical simulation.";"2024";"C. Simon and M. Boukli-Hacene and F. Lebrun and S. Otmane and A. Chellali";"2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)";"https://doi.org/10.1109/VR58804.2024.00087"
"Toward Tactile Internet in Beyond 5G Era: Recent Advances, Current Issues, and Future Directions";"Tactile Internet (TI) is envisioned to create a paradigm shift from the content-oriented communications to steer/control-based communications by enabling real-time transmission of haptic information (i.e., touch, actuation, motion, vibration, surface texture) over Internet in addition to the conventional audiovisual and data traffics. This emerging TI technology, also considered as the next evolution phase of Internet of Things (IoT), is expected to create numerous opportunities for technology markets in a wide variety of applications ranging from teleoperation systems and Augmented/Virtual Reality (AR/VR) to automotive safety and eHealthcare towards addressing the complex problems of human society. However, the realization of TI over wireless media in the upcoming Fifth Generation (5G) and beyond networks creates various non-conventional communication challenges and stringent requirements in terms of ultra-low latency, ultra-high reliability, high data-rate connectivity, resource allocation, multiple access and quality-latency-rate tradeoff. To this end, this paper aims to provide a holistic view on wireless TI along with a thorough review of the existing state-of-the-art, to identify and analyze the involved technical issues, to highlight potential solutions and to propose future research directions. First, starting with the vision of TI and recent advances and a review of related survey/overview articles, we present a generalized framework for wireless TI in the Beyond 5G Era including a TI architecture, the main technical requirements, the key application areas and potential enabling technologies. Subsequently, we provide a comprehensive review of the existing TI works by broadly categorizing them into three main paradigms; namely, haptic communications, wireless AR/VR, and autonomous, intelligent and cooperative mobility systems. Next, potential enabling technologies across physical/Medium Access Control (MAC) and network layers are identified and discussed in detail. Also, security and privacy issues of TI applications are discussed along with some promising enablers. Finally, we present some open research challenges and recommend promising future research directions.";"2020";"S. K. Sharma and I. Woungang and A. Anpalagan and S. Chatzinotas";"IEEE Access";"https://doi.org/10.1109/ACCESS.2020.2980369"
"Virtual Reality Therapy for the Psychological Well-being of Palliative Care Patients in Hong Kong";"In this paper we introduce novel Virtual Reality (VR) and Aug-mented Reality (AR) treatments to improve the psychological well being of patients in palliative care, based on interviews with a clin-ical psychologist who has successfully implemented VR assisted interventions on palliative care patients in the Hong Kong hospital system. Our VR and AR assisted interventions are adaptations of traditional palliative care therapies which simultaneously facilitate patients communication with family and friends while isolated in hospital due to physical weakness and COVID-19 related restrictions. The first system we propose is a networked, metaverse platform for palliative care patients to create customized virtual environments with therapists, family and friends which function as immersive and collaborative versions of ‘life review’ and ‘reminiscence therapy’. The second proposed system will investigate the use of Mixed Real-ity telepresence and haptic touch in an AR environment, which will allow palliative care patients to physically feel friends and family in a virtual space, adding to the sense of presence and immersion in that environment.";"2022";"D. Eckhoff and R. Ng and A. Cassinelli";"2022 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)";"https://doi.org/10.1109/ISMAR-Adjunct57072.2022.00010"
"Exploring Worker-Drone Interaction in Mixed Reality: Balancing Distraction and Situational Awareness";"Mixed-reality (MR) technology has been widely used to simulate high-risk workplaces in order to minimize safety concerns. However, its use in understanding worker attentional allocation during interactions with drones in future construction environments remains underexplored. This study developed a futuristic bricklaying MR environment, where human-drone interaction was mandatory, to capture participants’ naturalistic behaviors (i.e., attention, productivity, and distraction) across different interaction levels (i.e., no interaction, coexistence, and collaboration). The core research question explored whether workers maintained situational awareness of the drones or were distracted by them. The results confirmed that participants experienced a high sense of presence in the MR environment, driven by the use of environmental modalities, passive haptics, and drones’ sounds and spinning blades. Moreover, the findings demonstrated that participants were distracted by the drones during coexistence, as evidenced by lower productivity and reflections indicating they felt they were over-allocating attention to the drones. Conversely, participants exhibited situational awareness of the drones during collaboration, deliberately allocating attention to ensure safety, despite a reduction in productivity. These findings highlight the value of immersive technology in investigating workers’ naturalistic behaviors in future construction scenarios where workers and robots must function as teammates.";"2025";"W. -C. Chang and L. -F. Yu and S. Hasanzadeh";"2025 IEEE Conference Virtual Reality and 3D User Interfaces (VR)";"https://doi.org/10.1109/VR59515.2025.00065"
"Conveying intentions through haptics in human-computer collaboration";"Haptics has been used as a natural way for humans to communicate with computers in collaborative virtual environments. Human-computer collaboration is typically achieved by sharing control of the task between a human and a computer operator. An important research challenge in the field addresses the need to realize intention recognition and response, which involves a decision making process between the partners. In an earlier study, we implemented a dynamic role exchange mechanism, which realizes decision making by means of trading the parties' control levels on the task. This mechanism proved to show promise of a more intuitive and comfortable communication. Here, we extend our earlier work to further investigate the utility of a role exchange mechanism in dynamic collaboration tasks. An experiment with 30 participants was conducted to compare the utility of a role exchange mechanism with that of a shared control scheme where the human and the computer share control equally at all times. A no guidance condition is considered as a base case to present the benefits of these two guidance schemes more clearly. Our experiment show that the role exchange scheme maximizes the efficiency of the user, which is the ratio of the work done by the user within the task to the energy spent by her. Furthermore, we explored the added benefits of explicitly displaying the control state by embedding visual and vibrotactile sensory cues on top of the role exchange scheme. We observed that such cues decrease performance slightly, probably because they introduce an extra cognitive load, yet they improve the users' sense of collaboration and interaction with the computer. These cues also create a stronger sense of trust for the user towards her partner's control over the task.";"2011";"A. Kucukyilmaz and T. M. Sezgin and C. Basdogan";"2011 IEEE World Haptics Conference";"https://doi.org/10.1109/WHC.2011.5945523"
"Low Latency Haptic Feedback for Battery Powered HCI for the Tactile Internet";"The Tactile Internet, which is considered by many to be the next generation of Internet of Things (IoT), will enable real time Human Computer Interaction (HCI) systems capable of delivering tactile experiences remotely from the machine to the operator. Tactile Internet application fields include the tactile robot teleoperation, which constitutes the next generation of collaborative robots, equipped with sensing capabilities to process humanlike tactile sensation in Augmented/Virtual Reality (AR/VR) applications, i.e. advanced AR/VR training or education environments, Automotive and other application domains where Human Machine Interfaces (HMI) are required [1]. Tactile Enabled battery powered HCI devices must satisfy ultra-low latency haptic media constraints which are an order of magnitude more sensitive to delays when compared to audio and visual media [2] as well as low power consumption constrains required by battery powered portable or wearable technology. This paper describes the design considerations for power efficient low latency tactile feedback technology and the modelling and characterization of the system level latency associated with a tactile piezoelectric actuator driver. Such a driver architecture is envisaged to be used to implement haptic feedback in HMI scenarios, with a focus on reducing the latency of, battery powered, piezoelectric based tactile enabled HCI devices.";"2021";"S. Kundu and B. O’Flynn and J. T. Sanchez and M. Walsh";"2021 Smart Systems Integration (SSI)";"https://doi.org/10.1109/SSI52265.2021.9466961"
"A Virtual Reality Enhanced Cyber-Human Framework for Orthopedic Surgical Training";"This paper discusses the adoption of information-centric systems engineering (ICSE) principles to design a cyber-human systems-based simulator framework to train orthopedic surgery medical residents using haptic and immersive virtual reality platforms; the surgical procedure of interest is a less invasive stabilization system plating surgery that is used to treat fractures of the femur. Developing such training systems is a complex task involving multiple systems, technologies, and human experts. The information-centric approach proposed provides a structured foundation to plan, design, and build the simulators using the ICSE approach; in addition, the information models of the surgical processes were built to capture the surgical complexities and relationships between the various systems/components in the simulator framework, along with the controlling factors, performing mechanisms, and decision outcomes at various levels of abstraction. The simulator platforms include a haptic-based training system and a fully immersive training system for six training environments. Next-generation networking principles were adopted to support the collaborative training activities within this framework. As part of the proposed approach, expert surgeons played an important role in the design of the training environments. The outcomes of the learning assessment conducted demonstrate the effectiveness of using such simulator-based cyber-human training frameworks.";"2019";"A. Gupta and J. Cecil and M. Pirela-Cruz and P. Ramanathan";"IEEE Systems Journal";"https://doi.org/10.1109/JSYST.2019.2896061"
"Connecting the dots: Networked mixed reality applications and transmission quality";"Networked mixed reality applications typically consist of several kinds of media objects, e.g. live video streams of real objects combined with 3D animations, download, chat and haptic interaction control. Even though it seems obvious that these applications are likely to profit from concepts as Quality of Service (QoS) or path diversity, there often seems to be a kind of gap between the world of the network people and the multimedia software engineer. The goal of our research project DISCOVER (Distributed, Cooperative VR-Applications) is to bridge this gap by supplying an interface which provides simplified access to QoS and path diversity support, both in the application's developing process and at run time.";"2012";"V. Popic and G. Dörries";"2012 International Conference on Telecommunications and Multimedia (TEMU)";"https://doi.org/10.1109/TEMU.2012.6294740"
"Toward \"Pseudo-Haptic Avatars\": Modifying the Visual Animation of Self-Avatar Can Simulate the Perception of Weight Lifting";"In this paper we study how the visual animation of a self-avatar can be artificially modified in real-time in order to generate different haptic perceptions. In our experimental setup, participants could watch their self-avatar in a virtual environment in mirror mode while performing a weight lifting task. Users could map their gestures on the self-animated avatar in real-time using a Kinect. We introduce three kinds of modification of the visual animation of the self-avatar according to the effort delivered by the virtual avatar: 1) changes on the spatial mapping between the user’s gestures and the avatar, 2) different motion profiles of the animation, and 3) changes in the posture of the avatar (upper-body inclination). The experimental task consisted of a weight lifting task in which participants had to order four virtual dumbbells according to their virtual weight. The user had to lift each virtual dumbbells by means of a tangible stick, the animation of the avatar was modulated according to the virtual weight of the dumbbell. The results showed that the altering the spatial mapping delivered the best performance. Nevertheless, participants globally appreciated all the different visual effects. Our results pave the way to the exploitation of such novel techniques in various VR applications such as sport training, exercise games, or industrial training scenarios in single or collaborative mode.";"2014";"D. A. G. Jauregui and F. Argelaguet and A. -H. Olivier and M. Marchal and F. Multon and A. Lecuyer";"IEEE Transactions on Visualization and Computer Graphics";"https://doi.org/10.1109/TVCG.2014.45"
"Human-centered robotics and haptic interaction: from assistance to surgery, the emerging applications";"Robots are moving towards applications beyond the structured environment of a manufacturing plant, making their way into the everyday world that people inhabit. The discussion focuses on the models, strategies, and algorithms associated with the basic capabilities needed for robots to work, interact, and cooperate with humans. In addition to the new capabilities they bring to the physical robot, these models and algorithms and more generally the overall body of developments in robotics is making a significant impact on the virtual world. Tactile or haptic interaction with an accurate dynamic simulation provides unique insights into the real-world behaviors of physical systems. The potential applications of this emerging technology include virtual prototyping, animation, surgery, teleoperation, cooperative work, and education among many others.";"2002";"O. Khatib";"Proceedings of the Third International Workshop on Robot Motion and Control, 2002. RoMoCo '02.";"https://doi.org/10.1109/ROMOCO.2002.1177098"
"Enhancing Contact Stability in Admittance-Type Haptic Interaction Using Bidirectional Time-Domain Passivity Control";"The present paper proposes a novel strategy to enhance admittance-type haptic interaction using bidirectional time-domain passivity control. While admittance-type haptic interaction is widely employed in human-robot collaboration, its ability to render low virtual inertia can be limited, leading to unstable interactions with rigid environments. The proposed strategy seeks to stabilize a lower range of virtual inertia while maintaining responsive behavior in free space. The Franka Emika Collaborative robot was utilized in various experiments to test the approach, and the results indicate that the bidirectional time-domain passivity controller can improve interaction performance relative to the conventional unidirectional time-domain passivity approach. This technique may aid in reducing operator fatigue during the manipulation of heavy, non-back drivable industrial robots while preserving a lightweight feel.";"2023";"S. -S. Park and H. T. Dinc and K. -H. Lee and J. -H. Ryu";"2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)";"https://doi.org/10.1109/RO-MAN57019.2023.10309365"
"The Characteristics Evaluation of a VR Simulator-based Catheter Training System";"So many patients get benefit from endovascular surgeries because of the miniature wound and fast healing, but how to achieve the goal of endovascular surgeries need the doctor to master their skill and ensure that not to made damage to the patients. A training system which cooperated with VR simulator system is in desperately indeed. The VR simulator could simulate the position and form of the catheter. A controlling device also could make the novice surgeons understand the insertion and rotation to the catheter. At the same time, the feedback system could also provides advantages for training. The performance is evaluated from the displacement in VR system and force feedback from haptic device. The results demonstrate that the enhance after training is about 38%. Based on the result we could announced that our VR simulator based catheter training system provide the a effective way for those surgeons under training";"2018";"M. Yu and S. Guo and Y. Song and L. Zhang";"2018 13th World Congress on Intelligent Control and Automation (WCICA)";"https://doi.org/10.1109/WCICA.2018.8630550"
"Auto-erecting agents for a collaborative learning environment";"A collaborative learning environment based on 3D media with interchangeable real and virtual components is introduced. This environment is supported by a special knowledge space, which allows the accumulation of concrete haptic as well as abstract physical and logical knowledge. Firstly we present the concept of complex objects, having a real part and various virtual parts of different levels of abstraction, These complex objects allow a synchronous generation and manipulation of real systems and their virtual counterparts. The concept is then extended by a mechanism of auto-erection, enabling these objects to simulate their own potential environment. With this mechanism we are able to freely exchange real and virtual parts of a system in a distributed real learning space. This kind of learning environment is expected to support new forms of interaction, suitable for individual traditions, cultures, norms and conventions of learning styles and pre-knowledge.";"1999";"F. W. Bruns and H. Gathmann";"Proceedings. IEEE 8th International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WET ICE'99)";"https://doi.org/10.1109/ENABL.1999.805214"
"Haptic-Based Serious Games";"Recently, new interactive devices such as hap tic devices became available for game development. 6DOF hap tic devices give the user an opportunity \"to feel\" the simulated virtual environment in the way similar to the real world. Hap tic-based interaction can add a new dimension to \"serious games\" development. The user can \"feel\" objects surfaces and complex objects interaction forces in a 3D virtual environment. In this paper, we propose two hap tic-based serious games. In the first \"T Puzzle\" game, the user can \"feel\" the weight of objects, rotate and move the 3D puzzle pieces in the virtual world. This game can be used to improve the user's spatial abilities. In the second \"Mol Docking\" game, the player can feel interaction forces between molecular systems and learn the process of molecular docking in collaborative virtual environment.";"2014";"X. Hou and O. Sourina and S. Klimenko";"2014 International Conference on Cyberworlds";"https://doi.org/10.1109/CW.2014.14"
"VEserver: a manager for input and haptic multi-sensorial devices";"The majority of current feedback within virtual environments (VE) are visual and auditory. However, to interact correctly with virtual objects, we must use haptic feedbacks. These devices require a lot of CPU power while they commonly process on operating systems (OS) other than those running on the powerful graphic calculators. Thus, it is necessary for VE applications to have a distributed architecture over a network which allows the cooperation of several computers with different OS. A fundamental part of this architecture is the VEserver, an event server to manage VE devices. Its structure allows the connection of devices like trackers, data gloves, voice or gesture recognition systems as well as input/output haptic devices.";"2001";"T. Damien and P. Bourdot";"Proceedings 10th IEEE International Workshop on Robot and Human Interactive Communication. ROMAN 2001 (Cat. No.01TH8591)";"https://doi.org/10.1109/ROMAN.2001.981868"
"Mobile multimodal human-robot interface for virtual collaboration";"This paper proposes an intuitive teleoperation scheme by using human gesture in conjunction with multimodal human-robot interface. Further, in order to deal with the complication of dynamic daily environment, the authors apply haptic point cloud rendering and the virtual collaboration to the system. all these functions are achieved by a portable hardware that is proposed by authors newly, which is called “the mobile iSpace”. First, a surrounding environment of a teleoperated robot is captured and reconstructed as the 3D point cloud using a depth camera. Virtual world is then generated from the 3D point cloud, which a virtual teleoperated robot model is placed in. Operators use their own whole-body gesture to teleoperate the humanoid robot. The Gesture is captured in real time using the depth camera that was placed on operator side. The operator recieves both the visual and the vibrotactile feedback at the same time by using a head mounted display and a vibrotactile glove. All these system components, the human operator, the teleoperated robot and the feedback devices, are connected with the Internet-based virtual collaboration system for a flexible accessibility. This paper showcases the effectiveness of the proposed scheme with experiment that were done to show how the operators can access the remotely placed robot in anytime and place.";"2012";"Y. E. Song and M. Niitsuma and T. Kubota and H. Hashimoto and H. I. Son";"2012 IEEE 3rd International Conference on Cognitive Infocommunications (CogInfoCom)";"https://doi.org/10.1109/CogInfoCom.2012.6422055"
"A Lightweight Accessible Wearable Robotic Interface for Bimanual Haptic Manipulations";"Wearable devices with bimanual force feedback enable natural and cooperative manipulations within an unrestricted space. Weight and cost have a great influence on the potential applications of a haptic device. This paper presents a wearable robotic interface with bimanual force feedback that has considerably reduced weight and cost. To make the reaction force less perceivable than the interaction force, a waist-worn scheme is adopted. The interface mainly consists of a belt, a fastening tape, two serial robotic arms, and two electronics units and batteries. The robotic arms located on both sides of the belt are capable of 3-DoF position tracking and force feedback for each hand. The whole interface is lightweight (only 2.4 kg) and accessible. Furthermore, it is also easy to wear and the operator can wear it only by putting the belt on the waist and fastening the tape, reducing his/her dependency on additional assistance. The interface is optimized to obtain desirable force output and a dexterous workspace without singularity. To evaluate its performance in bimanual cooperative manipulations, an experiment in the virtual environment was conducted. The experimental results showed the subjects had more efficient and stable cooperative manipulations with bimanual force feedback than without force feedback.";"2022";"Y. Mo and A. Song and H. Qin";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2021.3137902"
"Intention Estimation with Recurrent Neural Networks for Mixed Reality Environments";"Knowledge about human intention can be beneficial in many disciplines of robotics, such as collaborative manufacturing, prosthetics, or encountered-type haptics. Existing intention estimation approaches are either traditional and rely on handcrafted features and heuristics, or learning-based and tailored to very specific conditions. This paper attempts to combine the best of both worlds by making recurrent neural networks adaptable to different scenarios. To achieve this, the intention estimation problem is formulated as a probabilistic classification problem and two new data sets with real-world motion and eye-tracking data are presented. Based on this data, three real-time capable classifiers with different features regarding situational awareness and additional outputs are designed and evaluated against two competing approaches. The results show that two out of three classifiers lead to improved or equivalent performance compared to traditional approaches, while good generalization is maintained.";"2023";"M. Fennel and S. Garbay and A. Zea and U. D. Hanebeck";"2023 26th International Conference on Information Fusion (FUSION)";"https://doi.org/10.23919/FUSION52260.2023.10224151"
"Comparison of tracker-based to tracker-less haptic device calibration";"In our current work we explore the feasibility of using visuo-haptic augmented reality techniques for training and remote collaboration. Accurate calibration of system components is a key factor in this context. In this paper we deal with the calibration of the kinematic parameters of the haptic device. We compare a previously developed technique using an external optical tracker to a new approach not relying on additional devices. Simulated and real experiments are carried out to investigate the performance of the new technique. As will be shown, both methods yield reasonable results with average errors in the workspace below 2mm. It is found that the trackerless technique is an acceptable alternative to using a tracker for calibration, with only slightly reduced accuracy. It is straightforward to apply and allows to improve rendering fidelity.";"2011";"B. Knoerlein and M. Harders";"2011 IEEE World Haptics Conference";"https://doi.org/10.1109/WHC.2011.5945472"
"Motion constraints simulation based on MATLAB and haptic interface";"This paper proposes a system to simulate the motion constraints on the serial robotic arm in the virtual reality world. The concept of guidance virtual fixture is involved in the control law of the human-machine collaborative system, which guides the user's motion along the preferred direction while preventing the disturbance along the non-proffered direction. Haptic device, Phantom Desktop¿, is used as the master device to manipulate the virtual robot as the slave device in the MATLAB and feeds back the force to the user. We proposed this method and haptic assisted system to simulate the kinematics and trajectory of the robot when user doing the manipulation. The simulation results verify the validity of our scheme.";"2009";"L. Qi and M. Q. . -H. Meng";"2009 IEEE International Conference on Robotics and Biomimetics (ROBIO)";"https://doi.org/10.1109/ROBIO.2009.5420586"
"Touch My Heart: Navigating the Heart Models in MR with Haptic Feedback, 3D Sound, and Interactive Gamification";"Touch My Heart utilizes a mixed reality headset and digital twin technology for an immersive exploration of the heart. The system, integrating hand tracking and haptic feedback, offers a realistic simulation, enhancing spatial audio for a fusion of senses. Users can interact with a 3D heart model, providing a comprehensive understanding of structure, function, and abnormalities including cardiac arrhythmia's and valvular heart diseases. The initiative supports medical education, enabling detailed exploration of heart pathophysiology and collaborative discussions among healthcare professionals. Additionally, it facilitates patient engagement by educating on heart conditions.";"2024";"O. Terendii and S. Frish and T. Prokopiev and D. Hemmerling and T. Jadczyk and M. Janusz";"2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)";"https://doi.org/10.1109/VRW62533.2024.00389"
"Haptic Data Compression and Communication";"The past decade has witnessed how audio-visual communication has shaped the way humans interact with or through technical systems. In contemporary times, the potential of haptic communication has been recognized as being compelling to further augment human-to-human and human-to-machine interaction. In the context of immersive communication, video and audio compression are considered key enabling technologies for high-quality interaction. In contrast, the compression of haptic data is a field of research that is still relatively young and not fully explored. This disregards the fact that we as humans rely heavily on the haptic modality to interact with our environment. True immersion into a distant environment and efficient collaboration between multiple participants both require the ability to physically interact with objects in the remote environment. With recent advances in virtual reality, man-machine interaction, telerobotics, telepresence, and teleaction, haptic communication is proving instrumental in enabling many novel applications. The goal of this overview article is to summarize the state of the art and the challenges of haptic data compression and communication for telepresence and teleaction.";"2011";"E. Steinbach and S. Hirche and J. Kammerl and I. Vittorias and R. Chaudhari";"IEEE Signal Processing Magazine";"https://doi.org/10.1109/MSP.2010.938753"
"Role of haptics in teaching structural molecular biology";"Physical models such as ball-and-stick have long been used in teaching basic chemistry and structural molecular biology. As the size and complexity of known molecular structures increases, it is difficult if not impossible to show all of their features in a physical model alone. Recent advances in automated model fabrication technology now afford physical models of more complex molecular structures. In this multi-institutional collaborative project we are creating multi-modality enhancements of such tangible models by superimposing graphical (augmented reality) information on top of the fabricated physical models, by incorporating support for voice commands, and by providing haptic feedback. The user of such an interface can request a variety of overlay representations and can interact with these virtual enhancements haptically while manipulating the physical model. This multi-modality interface appears to be quite intuitive for observing complex molecular structure. We are currently evaluating its usefulness in teaching molecular biology to high school students.";"2003";"G. Sankaranarayanan and S. Weghorst and M. Sanner and A. Gillet and A. Olson";"11th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, 2003. HAPTICS 2003. Proceedings.";"https://doi.org/10.1109/HAPTIC.2003.1191312"
"Network lag mitigation methods in collaborative distributed simulations";"One of the known problems with shared object manipulation in collaborative virtual environments (CVE) is the disruptive effect of network lag in collaboration sessions. It is widely recognized that delay and jitter cause significant problems for CVEs. Most solutions to this problem revolve around techniques to compensate for this lag at the networking level. More recently, the usage of visual cues indicating network lag to the user have shown to be effective. In this article we examine both approaches using a collaborative tele-haptic application, during which we also introduce a novel technique for decorator-based mitigation for closely-coupled tasks. We conclude that while both techniques can be effective, the combination of both will lead to best results.";"2005";"S. Shirmohammadi and N. H. Woo and S. Alavi";"Proceedings of the 2005 International Symposium on Collaborative Technologies and Systems, 2005.";"https://doi.org/10.1109/ISCST.2005.1553319"
"The roles of haptic-ostensive referring expressions in cooperative, task-based human-robot dialogue";"Generating referring expressions is a task that has received a great deal of attention in the natural-language generation community, with an increasing amount of recent effort targeted at the generation of multimodal referring expressions. However, most implemented systems tend to assume very little shared knowledge between the speaker and the hearer, and therefore must generate fully-elaborated linguistic references. Some systems do include a representation of the physical context or the dialogue context; however, other sources of contextual information are not normally used. Also, the generated references normally consist only of language and, possibly, deictic pointing gestures. When referring to objects in the context of a task-based interaction involving jointly manipulating objects, a much richer notion of context is available, which permits a wider range of referring options. In particular, when conversational partners cooperate on a mutual task in a shared environment, objects can be made accessible simply by manipulating them as part of the task. We demonstrate that such expressions are common in a corpus of human-human dialogues based on constructing virtual objects, and then describe how this type of reference can be incorporated into the output of a humanoid robot that engages in similar joint construction dialogues with a human partner.";"2008";"M. E. Foster and E. G. Bard and M. Guhe and R. L. Hill and J. Oberlander and A. Knoll";"2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI)";"https://doi.org/10.1145/1349822.1349861"
"Consensus Based Networking of Distributed Virtual Environments";"Distributed virtual environments (DVEs) are challenging to create as the goals of consistency and responsiveness become contradictory under increasing latency. DVEs have been considered as both distributed transactional databases and force-reflection systems. Both are good approaches, but they do have drawbacks. Transactional systems do not support Level 3 (L3) collaboration: manipulating the same degree-of-freedom at the same time. Force-reflection requires a client-server architecture and stabilisation techniques. With Consensus Based Networking (CBN), we suggest DVEs be considered as a distributed data-fusion problem. Many simulations run in parallel and exchange their states, with remote states integrated with continous authority. Over time the exchanges average out local differences, performing a distribued-average of a consistent, shared state. CBN aims to build simulations that are highly responsive, but consistent enough for use cases such as the piano-movers problem. CBN’s support for heterogeneous nodes can transparently couple different input methods, avoid the requirement of determinism, and provide more options for personal control over the shared experience. Our work is early, however we demonstrate many successes, including L3 collaboration in room-scale VR, 1000’s of interacting objects, complex configurations such as stacking, and transparent coupling of haptic devices. These have been shown before, but each with a different technique; CBN supports them all within a single, unified system.";"2022";"S. Friston and E. Griffith and D. Swapp and S. Julier and C. Irondi and F. Jjunju and R. Ward and A. Marshall and A. Steed";"IEEE Transactions on Visualization and Computer Graphics";"https://doi.org/10.1109/TVCG.2021.3052580"
"Enhancing the sense of togetherness with vibrational feedback in virtual communication";"In interpersonal communication, nonverbal cues play a crucial role alongside verbal information. Haptic communication offers an affective dimension crucial for expressing emotions, yet it is notably absent in virtual environments. This absence can lead to drawbacks such as a diminished sense of another person’s social presence in virtual settings and a reduced sense of togetherness. To address this gap, our study explores the integration of vibrational feedback during virtual communication specifically within the context of collaborative tasks. In the experiment, participants engaged in a collaborative task with an avatar. Vibrational feedback was transmitted to participants whenever the avatar engaged in actions such as clicking or typing. This feedback aimed to enhance the avatar’s presence in virtual communication. Our findings indicate that such vibrational feedback can significantly enhance the sense of togetherness, potentially bridging the gap typically experienced in virtual interactions. These improvements suggest that incorporating haptic feedback into virtual communication platforms may foster a more immersive and emotionally connected experience.";"2024";"A. Yamashita and K. Sato and M. Fuyuno and H. -N. Ho";"2024 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)";"https://doi.org/10.1109/ISMAR-Adjunct64951.2024.00121"
"Architecture and Evaluation of Tele-Haptic Environments";"A collaborative, haptic, audio and visual environment (C-HAVE) consists of a network of nodes. Each node in the C-HAVE world contributes to the shared environment with some virtual objects. These can be static, e.g., a sculpture or the ground, or dynamic, e.g., an object that can be virtually manipulated. We aim at developing a heterogeneous scalable architecture for large collaborative haptics environments where a number of potential users participate with different kinds of haptic devices. The main objective of the presented research is the development of three prototypes to demonstrate quantitatively the effects of adding haptics to a task. The experimental results reveal the effects of the different implementations on the performance and time delay of a particular task through objective measurement results.";"2004";"Xiaojun Shen and Jilin Zhou and A. El Saddik and N. D. Georganas";"Eighth IEEE International Symposium on Distributed Simulation and Real-Time Applications";"https://doi.org/10.1109/DS-RT.2004.8"
"Tactile–Thermal Interactions: Cooperation and Competition";"This review focuses on the interactions between the cutaneous senses, and in particular touch and temperature, as these are the most relevant for developing skin-based display technologies for use in virtual reality (VR) and for designing multimodal haptic devices. A broad spectrum of research is reviewed ranging from studies that have examined the mechanisms involved in thermal intensification and tactile masking, to more applied work that has focused on implementing thermal-tactile illusions such as thermal referral and illusory wetness in VR environments. Research on these tactile-thermal illusions has identified the differences between the senses of cold and warmth in terms of their effects on the perception of object properties and the prevalence of the perceptual experiences elicited. They have also underscored the fundamental spatial and temporal differences between the tactile and thermal senses. The wide-ranging body of research on compound sensations such as wetness and stickiness has highlighted the mechanisms involved in sensing moisture and provided a framework for measuring these sensations in a variety of contexts. Although the interactions between the two senses are complex, it is clear that the addition of thermal inputs to a tactile display enhances both user experience and enables novel sensory experiences.";"2025";"L. A. Jones and H. -N. Ho";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2025.3549677"
"Movement strategy and EMG activities of the upper extremity at assisted reaching exercise with a 7 DOF collaborative robot";"Recovering of upper extremity functions is important for stroke patients to perform various tasks in daily life. For better rehabilitation outcomes and accurate measurement, robot assisted exercises have been developed. However, there are limited number of studies related to arm muscles activities corresponding to task complexity. We conducted a preliminary case study on strategy and activities of upper extremity muscles in a healthy volunteer at reaching exercise with haptic feedback by a robot with seven degree-of-freedom when a different target was presented in the virtual environment. Impedance control for Franka Emika Panda robot arm has been developed. The study protocol consisted of 4 sets of 40 reaching trials. The trials had two modes with two different feedback: big target task mode and the small target task mode. In each mode both options, with/without haptic feedback were tested. The preliminary results suggest that different distance to target and target's size is related to the change of activation order and intensity of muscle activities at reaching task. Additionally, the haptic feedback required different activation order and higher intensity regardless of the task difficulty.";"2020";"Y. Kato and A. Olenšek and M. Zadravec and Z. Matjačić and T. Tsuji and I. Cikajlo";"2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)";"https://doi.org/10.1109/EMBC44109.2020.9176181"
"Realtime Collision Avoidance for Mechanisms with Complex Geometries";"This video presents a collision avoidance framework for mechanisms with complex geometries. The performance of the framework is showcased with the haptic interface HUG [3]. We are able to avoid contacts with the robot links and with moving objects in the environment in 1 kHz. The main contribution of our approach is its generic and extensible nature; it can be applied to any mechanism consisting of arbitrarily complex rigid bodies, in contrast to common solutions that use simplified models [2], [7]. In the preprocessing phase, first, the kinematic chain of the mechanism is described [1]. Second, we generate voxelized distance fields and point-sphere hierarchies for the geometry of each mechanism link and each object in the environment [6]. After that, our system requires only the joint angles and information of the environment state (e.g., object poses tracked by optical sensors) to compute collision avoidance forces. At runtime, each link is artificially dilated by a safety isosurface. If a point of an object goes through this surface, a normal force scaled by its penetration depth is computed and applied to the corresponding link. If humans are generically modeled as mechanisms and properly tracked, our system can also prevent collisions with them, ensuring save human-machine collaboration. Figure 1 illustrates the framework and its basic components. The multi-body collision computation architecture was first developed for virtual maintenance simulations with haptic feedback [5], [4], and thereafter extended to collision avoidance of mechanisms. A first prototype was previously published in [8].";"2018";"M. Sagardia and A. M. Turrillas and T. Hulin";"2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)";"https://doi.org/10.1109/VR.2018.8446527"
"Active Constraints/Virtual Fixtures: A Survey";"Active constraints, also known as virtual fixtures, are high-level control algorithms which can be used to assist a human in man-machine collaborative manipulation tasks. The active constraint controller monitors the robotic manipulator with respect to the environment and task, and anisotropically regulates the motion to provide assistance. The type of assistance offered by active constraints can vary, but they are typically used to either guide the user along a task-specific pathway or limit the user to within a “safe” region. There are several diverse methods described within the literature for applying active constraints, and these are surveyed within this paper. The active constraint research is described and compared using a simple generalized framework, which consists of three primary processes: 1) constraint definition, 2) constraint evaluation, and 3) constraint enforcement. All relevant research approaches for each of these processes, found using search terms associated to “virtual fixture,” “active constraint” and “motion constraint,” are presented.";"2014";"S. A. Bowyer and B. L. Davies and F. Rodriguez y Baena";"IEEE Transactions on Robotics";"https://doi.org/10.1109/TRO.2013.2283410"
"Improvement of collaborative selection in 3D complex environments";"Closely coupled interactions in 3D Collaborative Virtual Environments present a new challenge for the design of Computer-Human Interfaces. Among emerging issues, the collaborative selection of artifact presents several constraints since it requires a good understanding of the workspace of the partner and a good coordination between their actions. However, existing Collaborative Virtual Environments inhibit some mechanisms of communication and interpersonal awareness processes, and this limits the efficiency of such collaborative tasks. To go beyond these constraints, we propose in this article a metaphor for the collaborative selection of 3D artifacts. The proposed approach exploits the haptic channel through a gestural guidance strategy. Once the target is selected by one partner, the second partner is attracted through a suitable force model toward the target. An experimental study was carried out in the context of molecular design, investigating different working strategies. The results show that the proposed metaphor significantly improves the efficiency of the group during the deformation of molecular structures. Moreover, the proposed approach provides a suitable learning support for beginners and enables the more experienced user to implicitly convey and explain some features of the molecular structures.";"2012";"A. Girard and M. Ammi and J. Simard and M. Auvray";"2012 IEEE Haptics Symposium (HAPTICS)";"https://doi.org/10.1109/HAPTIC.2012.6183803"
"Evaluation of Active Handrest performance using labyrinths with adaptive admittance control and virtual fixtures";"The Active Handrest is a large workspace, human-machine interface that provides ergonomic support for a user's hand and arm while allowing the user to retain complete control over a grasped tool. In this paper, we introduce methods to improve the base performance of the Active Handrest's linear admittance controller (V = Kα * F) based on knowledge of user intention, through adaptive admittance, and knowledge of the environment, via virtual fixtures. Herein, we present feasibility studies to apply adaptive admittance and virtual fixtures to the motion of the Active Handrest and measure user performance. We introduce a more relevant evaluation task for the Active Handrest by conducting experiments involving the navigation of virtual labyrinths. The results of these experiments show that adaptive admittance improves a user's ability to accurately navigate a narrow labyrinth, with less cost of time than using constant gains with a linear admittance controller. Additionally, a feasibility study on virtual fixtures shows that user performance for drawing straight lines with virtual fixtures applied directly to the Active Handrest is equivalent to user performance with virtual fixtures applied directly to the grasped tool, as has been done more traditionally. These results underscore the utility of the Active Handrest as they show the potential to achieve highly accurate motions without the need for a robotically enabled or co-manipulated tool.";"2012";"M. A. Fehlberg and R. J. King and A. J. Doxon and W. R. Provancher";"2012 IEEE Haptics Symposium (HAPTICS)";"https://doi.org/10.1109/HAPTIC.2012.6183802"
"Framework for haptic interaction with virtual avatars";"In this paper we present an integrative frame work centered on haptic interaction with virtual avatars. This framework is devised for general prototyping and collaborative scenario studies with haptic feedback. First we present the software architecture of the framework and give details on some of its components. Then we show how this framework can be used to derive in a short time a virtual reality simulation. In this simulation, a user directly interacts with a virtual avatar to collaboratively manipulate a virtual object, with haptic feedback and using fast dynamics computation and constraint based methods with friction.";"2008";"P. Evrard and F. Keith and J. -R. Chardonnet and A. Kheddar";"RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication";"https://doi.org/10.1109/ROMAN.2008.4600636"
"Study of communication modalities for teaching distance information";"We present an exploratory study to compare the haptic, visual, and verbal modalities for communicating distance information in a shared virtual environment. The results show that the visual modality decreased the distance estimation error while the haptic modality decreased the completion time. The verbal modality increased the sense of copresence but was the least preferred modality. These results suggest that a combination of modalities could improve communication of distance information to a partner. These findings can contribute to improving the design of collaborative VR systems and open new research perspectives on studying the effectiveness of multimodal interaction.";"2022";"F. Fastelli and C. Simon and A. Ricca and A. Chellali";"2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)";"https://doi.org/10.1109/VRW55335.2022.00204"
"The effect of network characteristics on e-health Telehaptics applications; Application of suture gestures in distributed virtual surgical environment";"The combination of surgical simulation and haptic interfaces provides a powerful platform for reproducing the visual and motor sensations that a surgeon experiences during a surgical operation. With the wide availability of information technologies and new, robust telecommunication technologies, remote tele-guidance for learning surgical procedures has become feasible for more effectively employing expertise through remote instruction. The current study employs an interaction analysis approach adapted to telehaptic collaboration/guidance solutions in surgical suturing task training, so we aim to identify not only the influence of the network parameters on telehaptic guidance but also on the e-learning of gestures.";"2008";"F. Al-Chama and S. Delaplace and E. Monacelli and D. Chene and N. Tarrin and C. Cornelius";"2008 3rd International Conference on Information and Communication Technologies: From Theory to Applications";"https://doi.org/10.1109/ICTTA.2008.4529939"
"Collaborative virtual training using force feedback devices";"Force feedback plays an important role in collaborative virtual reality environments, mainly for programmers of haptic visualization tools. Whereas a great deal of work has gone into graphical displays over the past years, little has changed on the input side. One of the problems that has slowed down development in this area is the difficulty of integrating the visualization of a scene, the interaction of the user with the scene, the feeling for the user to be immersed inside the scene, and finally, the input devices. We describe the architecture we have designed, implemented and tested for a collaborative virtual training using force feedback devices. In particular, it provides device independence and easy extensibility through a compartmentalized and multilayered model. We also present examples of how force feedback joysticks can be integrated into training exercises using our prototype.";"2004";"M. A. F. Rodrigues and R. R. C. Chaves and W. B. Silva";"Proceedings. 17th Brazilian Symposium on Computer Graphics and Image Processing";"https://doi.org/10.1109/SIBGRA.2004.1352978"
"Hapto-audio-visual environments for collaborative training of ophthalmic surgery over optical network";"This paper presents the results of a two-year project to develop a shared hapto-visual-audio-virtual environment (HAVE) with advanced multi-point video conferencing, new display and interface technologies, and distributed latency-compensated haptic technologies for collaborative medical research and training in ophthalmology. One of the goals of this project is to create collaborative training environment, in which residents can remotely learn, in real-time, cataract operations from real operations performed by teaching surgeons. The assumption of this work is that a trainee surgeon can learn the complex hand-eye coordination necessary for becoming a good ophthalmic surgeon by feeling and seeing every move the expert surgeon makes, through a complex haptic, auditory, and visual playback interface. Experimental results are presented";"2006";"P. Boulanger and G. Wu and W. F. Bischof and X. D. Yang";"2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006)";"https://doi.org/10.1109/HAVE.2006.283801"
"Integrate the BlindAid system in a traditional orientation and mobility rehabilitation program";"In the process of becoming blind, newly- blinded people participate in a rehabilitation program, which includes different skills that a newly- blinded person needs to adapt as a result of his or her lost of vision. The virtual system, the BlindAid, involves active collaboration between orientation and mobility instructors from the Carroll Center for the Blind in Newton, Massachusetts and engineers and cognitive scientists at the MIT Touch Lab in Cambridge, Massachusetts. The two teams collaborated in the integration of the BlindAid system in the traditional orientation and mobility rehabilitation program. In this study we will describe the model of the integration. The three main goals of this model were to study: (1) cognitive mapping process of newly-blinded when using the virtual environment; (2) mental support of the BlindAid system to the newly- blinded; and (3) enhancement of the BlindAid system for the orientation and mobility instructors. The findings supply strong evidence that interaction with the BlindAid system by people who are newly-blinded provides a robust foundation for the participants' development of comprehensive cognitive maps of actual unknown spaces during their rehabilitation program.";"2009";"O. Lahav and D. W. Schloerb and M. A. Srinivasan";"2009 Virtual Rehabilitation International Conference";"https://doi.org/10.1109/ICVR.2009.5174202"
"Increasing the Motivation to Train Through Haptic Social Interaction – Pilot study";"Motivation is crucial in stroke rehabilitation, as it enhances patient engagement, adherence, and recovery. Robots can be employed to improve motivation through multiplayer rehabilitation games, which allow patients to collaborate and interact in a virtual environment through multimodal sensory cues. This social interaction can provide social support and increase motivation, resulting in better therapy engagement. A hand rehabilitation robot (PLUTO) was used to investigate the potential of social interaction to implement haptic multiplayer games. Twelve unimpaired participants (6 dyads) played in solo, collaborative, and competitive game modes. Surprisingly, no difference was found in self-reported engagement, tension, or competence between solo and multiplayer games. However, the IMI scale indicated that engagement for multiplayer games was rated higher than for solo games. The collaborative game was preferred by 10 out of 12 participants, highlighting its potential for promoting behavioural involvement and engagement. This study indicates that using PLUTO with multiplayer game modes can enhance therapy engagement. This can potentially improve rehabilitation outcomes if translated to the patient population.";"2023";"A. Nehrujee and E. Ivanova and S. Srinivasan and S. Balasubramanian and E. Burdet";"2023 International Conference on Rehabilitation Robotics (ICORR)";"https://doi.org/10.1109/ICORR58425.2023.10304751"
"Teleoperation System of Internet-Based Multi-Operator Multi-Mobile-Manipulator";"A teleoperation system of Internet-based Multi-Operator Multi-Mobile-Manipulator is proposed in this paper. The system consists of master sides and slave side, which has the characteristics of mobility, cooperation, distribution, fault tolerance, redundancy etc.. In master sides, with the aid of Distributed Virtual Environment and multi-video image, operators use the haptic interface device to control the remote robots via Internet. The 9-DOF mobile-manipulators which combine the mobility of the omnidirectional mobile plat and the manipulability of the manipulator are located in the slave side. Modules of ultrasonic location and ultrasonic/infrared distance measurement are arranged on the mobile-manipulators, and six-axis force sensors are fixed on the wrist of mobile-manipulators. Six video cameras are installed in slave side to provide the operators multi-video image. A network server collects the information of the sensors by WLAN and sends them to operators through net. With the aid of real-time multi-video image and feedbacks, operators could control the robots to complete the task. Finally, the effectiveness of the teleoperation system is illustrated by experiments that the operators control the robots to complete the role of delivering and transporting via Internet, and achieve loose coordination, mobile tight coordination and operated tight coordination teleoperation.";"2010";"L. Ma and J. Yan and J. Zhao and Z. Chen and H. Cai";"2010 International Conference on Electrical and Control Engineering";"https://doi.org/10.1109/iCECE.2010.551"
"Decentralized Control of a Heterogeneous Human–Robot Team for Exploration and Patrolling";"We present a decentralized connectivity-maintenance control framework for a heterogeneous human–robot team. The algorithm is able to manage a team composed of an arbitrary number of mobile robots (drones and ground robots in our case) and humans, for collaboratively achieving exploration and patrolling tasks. Differently from other works on the subject, here the human user physically becomes part of the team, moving in the same environment of the robots and receiving information about the team connectivity through wearable haptics or audio feedback. Although human explores the environment, robots move so as to keep the team connected via a connectivity-maintenance algorithm; at the same time, each robot can also be assigned with a specific target to visit. We carried out three human subject experiments, both in virtual and real environments. Results show that the proposed approach is effective in a wide range of scenarios. Moreover, providing either haptic or audio feedback for conveying information about the team connectivity significantly improves the performance of the considered tasks, although users significantly preferred receiving haptic stimuli w.r.t. the audio ones. Note to Practitioners—Exploration, patrolling, and search-and-rescue are highly dynamic and unstructured scenarios. When considering the operative conditions of such environments, the benefits of multirobot systems are evident. Most tasks can be carried out faster and more robustly by a team of robots with respect to a single unit. There are also situations explicitly requiring the presence of a multirobot team, e.g., using one drone for surveillance of the ground team and one ground mobile robot for carrying supplies. Of course, if the operator(s) in charge of the operation could share the same environment of the robots (i.e., be together with the robots in the field), they would be provided with a level of situational awareness that no teleoperation technology can match as of today. This work presents a framework for controlling heterogeneous teams composed of one human operator and an arbitrary number of aerial and ground mobile robots. The operator moves together with the robotic team and, at the same time, he or she receives meaningful information about the status of the formation. The algorithm only uses the relative position of the drones and humans with respect to each other, and all computations are designed in a decentralized fashion. Decentralization avoids relying on any absolute positioning system (e.g., GPS) or centralized command centers. These features make the proposed framework ready for deployment in different high-impact applications, such as in surveillance, search-and-rescue, and disaster response scenarios.";"2022";"M. Aggravi and G. Sirignano and P. R. Giordano and C. Pacchierotti";"IEEE Transactions on Automation Science and Engineering";"https://doi.org/10.1109/TASE.2021.3106386"
"Design and Evaluation of a Wearable Fingertip Device for Three-Dimensional Skin-Slip Display";"Skin-slip provides crucial cues about the interaction state and surface properties. Currently, most skin-slip devices focus on two-dimensional tactile slip display and have limitations when displaying surface properties like bumps and contours. In this article, a wearable fingertip device with a simple, effective, and low-cost design for three-dimensional skin-slip display is proposed. Continuous multi-directional skin-slip and normal indentation are combined to convey the sensation of three-dimensional geometric properties in virtual reality during active finger exploration. The device has a tactile belt, a five-bar mechanism, and four motors. Cooperating with the angle-mapping strategy, two micro DC motors are used to transmit continuous multi-directional skin-slip. Two servo motors are used to drive the five-bar mechanism to provide normal indentation. The characteristics of the device were obtained through the bench tests. Three experiments were designed and sequentially conducted to evaluate the performance of the device in three-dimensional surface exploration. The experimental results suggested that this device could effectively transmit continuous multi-directional skin-slip sensations, convey different bumps, and display surface contours.";"2024";"Y. Mo and A. Song and L. Zhu and Q. Ji and T. Wang and H. Qin";"IEEE Transactions on Haptics";"https://doi.org/10.1109/TOH.2023.3312661"
"MPEG Media Transport (MMT) for 3D Tele-Immersion Systems";"3D Tele-Immersion (3DTI) environments are a new medium for highly interactive and immersive means of collaborations through a shared virtual 3D environment. They have many applications in the areas of education, entertainment, sports training, tele-medicine etc. The data in these systems are multi-modal, some high volume, some high frequency and all highly correlated. We identify three major challenges in a general 3DTI system, session management, synchronization and data format conversion. We discuss the shortcomings of some of the existing protocols/solutions to them. We describe some features relevant to 3DTI of the MPEG Media Transport (MMT) standard. In this paper we evaluate the use of MMT in a 3DTI application. We provide a feature comparison with the most popular protocols currently being used in such applications, RTP, RTSP, TCP and UDP etc. MPEG DASH was another protocol that was being considered, but that also fails to fully address some of the challenges that 3DTI applications face. Through this comparison study we advocate the use of MMT in 3DTI applications.";"2014";"K. Venkatraman and S. Vellingiri and B. Prabhakaran and N. Nguyen";"2014 IEEE International Symposium on Multimedia";"https://doi.org/10.1109/ISM.2014.65"
"Performance related energy exchange in haptic human-human interaction in a shared virtual object manipulation task";"In order to enable intuitive physical interaction with autonomous robots as well as in collaborative multi-user virtual reality and tele-operation systems a deep understanding of human-human haptic interaction is required. In this paper the effect of haptic interaction in single and dyadic conditions is investigated. Furthermore, an energy-based framework suitable for the analysis of the underlying processes is introduced. A pursuit tracking task experiment is performed where a virtual object is manipulated, jointly by two humans and alone. The performance in terms of the root-mean-square tracking error is improved in dyadic compared to individual conditions, even though the virtual object mass is reduced to one half in the latter. Our results indicate that the interacting partners benefit from role distributions which can be associated with different energy flows.";"2009";"D. Feth and R. Groten and A. Peer and S. Hirche and M. Buss";"World Haptics 2009 - Third Joint EuroHaptics conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems";"https://doi.org/10.1109/WHC.2009.4810854"
"Haptic Interfaces for Wheelchair Navigation in the Built Environment";"A number of countries have recently introduced legislation aimed at ending discrimination against disabled people; in the United Kingdom the Disability Discrimination Act (1995) provides the disabled community with new employment and access rights. The intention of the act is to help those who rely on wheelchairs for mobility and who frequently find that not all buildings provide conditions suited to easy access. Central to these new rights will be an obligation for employers and organizations to provide premises that do not disadvantage the disabled. This work reports on the development of instrumentation that allows wheelchair navigation within virtual buildings and can assist architects in identifying the needs of wheel-chair users at an early design stage. Central to this project has been the need to provide a platform that can accommodate a range of wheelchair types and will map intended wheelchair motion into a virtual space. This interface must have the capacity to provide feedback to the user reflecting constraints present in the physical world, including changes in floor surface characteristics, gradients, and collisions. Integrating visual and nonvisual sensory feedback correlating to the physical effort of wheelchair propulsion has been found to augment the perception of self-motion within the virtual world and so can create an effective instrument for use in the study of wheelchair accessibility within the built environment. This project represents a collaborative effort between architects and bioengineers engaged in research related to platform design, construction, and interfacing, while testing and evaluation has been accomplished with the assistance of user groups.";"2004";"C. S. Harrison and M. Grant and B. A. Conway";"Presence";"https://doi.org/10.1162/1054746042545265"
"Reactive and Safe Co-Navigation with Haptic Guidance";"We propose a co-navigation algorithm that enables a human and a robot to work together to navigate to a common goal. In this system, the human is responsible for making high-level steering decisions, and the robot, in turn, provides haptic feedback for collision avoidance and path suggestions while reacting to changes in the environment. Our algorithm uses optimized Rapidly-exploring Random Trees (RRT*) to generate paths to lead the user to the goal, via an attractive force feedback computed using a Control Lyapunov Function (CLF). We simultaneously ensure collision avoidance where necessary using a Control Barrier Function (CBF). We demonstrate our approach using simulations with a virtual pilot, and hardware experiments with a human pilot. Our results show that combining RRT* and CBFs is a promising tool for enabling collaborative human-robot navigation.";"2023";"M. Coffey and D. Zhang and R. Tron and A. Pierson";"2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)";"https://doi.org/10.1109/IROS55552.2023.10342042"
"Foundational elements of next generation cyber physical and IoT frameworks for distributed collaboration";"This paper discusses the foundational elements for Next Generation frameworks based on the emerging principles and technologies in the context of distributed collaboration in two diverse fields (manufacturing and surgery). The Next Generation `smart' collaborative frameworks discussed in this paper are influenced by several emerging fields and technologies; these include Advanced Virtual Reality and Haptic (Touch) based technologies to support collaborative interactions among distributed users along with emerging practices based on Internet of Things (IoT), Cyber Physical Systems (CPS), Cloud Computing and Future Internet networking approaches. The foundational elements revolve around 3 key facets of Information Centric Engineering (ICE) which include Modeling, Simulation and Exchange (MSE) of Information. We discuss the creation of such IoT based cyber physical frameworks using these MSE elements for two of these domains: one is advanced manufacturing; the other is the field of medical surgical training. The design of such IoT based Cyber Physical frameworks is discussed along with implementation aspects of two advanced Test Beds.";"2017";"J. Cecil and A. Cecil-Xavier and A. Gupta";"2017 13th IEEE Conference on Automation Science and Engineering (CASE)";"https://doi.org/10.1109/COASE.2017.8256200"
"RemoteTouch: Enhancing Immersive 3D Video Communication with Hand Touch";"Recent research advance has significantly improved the visual real-ism of immersive 3D video communication. In this work we present a method to further enhance this immersive experience by adding the hand touch capability (“remote hand clapping”). In our system, each meeting participant sits in front of a large screen with haptic feedback. The local participant can reach his hand out to the screen and perform hand clapping with the remote participant as if the two participants were only separated by a virtual glass. A key challenge in emulating the remote hand touch is the realistic rendering of the participant's hand and arm as the hand touches the screen. When the hand is very close to the screen, the RGBD data required for realistic rendering is no longer available. To tackle this challenge, we present a dual representation of the user's hand. Our dual representation not only preserves the high-quality rendering usually found in recent image-based rendering systems but also allows the hand to reach to the screen. This is possible because the dual representation includes both an image-based model and a 3D geometry-based model, with the latter driven by a hand skeleton tracked by a side view camera. In addition, the dual representation provides a distance-based fusion of the image-based and 3D geometry-based models as the hand moves closer to the screen. The result is that the image-based and 3D geometry-based models mutually enhance each other, leading to realistic and seamless rendering. Our experiments demonstrate that our method provides consistent hand contact experience between remote users and improves the immersive experience of 3D video communication.";"2023";"Y. Zhang and Z. Li and S. Xu and C. Li and J. Yang and X. Tong and B. Guo";"2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)";"https://doi.org/10.1109/VR55154.2023.00016"
"A multi-layer approach for interactive path planning control";"This work considers path-planning processes for manipulation tasks such as assembly, maintenance or disassembly in a Virtual Reality (VR) context. The approach consists in providing a collaborative system associating a user immersed in VR and an automatic path planning process. It is based on semantic, topological and geometric representations of the environment and the planning process is split in two phases: coarse and fine planning. The automatic planner suggests a path to the user and guides him trough a haptic device. The user can escape from the proposed solution if he wants to explore a possible better way. In this case, the interactive system detects the user's intention in real-time and computes a new path starting from the user's guess. Experiments illustrate the different aspects of the approach: multi-representation of the environment, path planning process, user's intent prediction and control sharing.";"2014";"S. Cailhol and P. Fillatreau and J. -Y. Fourquet and Yingshen Zhao";"2014 11th International Conference on Informatics in Control, Automation and Robotics (ICINCO)";"https://doi.org/10.5220/0005055200900101"
"Comparison of Solo and Collaborative Trimanual Operation of a Supernumerary Limb in Tasks With Varying Physical Coupling";"Through the use of robotic supernumerary limbs, it has been proposed that a single user could perform tasks like surgery or industrial assembly that currently require a team. Although validation studies, often conducted in virtual reality, have demonstrated that individuals can learn to command supernumerary limbs, comparisons typically suggest that a team initially outperforms a supernumerary limb operating individual. In this study, we examined (i) the impact of using a commercially available physical robot setup instead of a virtual reality system and (ii) the effect of limb couplings on user performance during a series of trimanual operations. Contrary to previous findings, our results indicate no clear difference in user performance when working as a trimanual user, in the pick and place of three objects, compared to when working as a team. Additionally, for this task we observe that while users prefer working with a partner when they control most limbs, we find no clear difference in their preference between solo trimanual operation and when they work with a partner and control the third limb. These findings indicate that factors typically not present in virtual reality such as visual occlusion and haptic feedback may be vital to consider for the effective operation of supernumerary limbs, and provide initial evidence to support the viability of supernumerary limbs for a range of physical tasks.";"2025";"J. Eden and M. Khoramshahi and Y. Huang and A. Poignant and E. Burdet and N. Jarrassé";"IEEE Robotics and Automation Letters";"https://doi.org/10.1109/LRA.2024.3515734"
"Creating Widely Accessible Spatial Interfaces: Mobile VR for Managing Persistent Pain";"Using widely accessible VR technologies, researchers have implemented a series of multimodal spatial interfaces and virtual environments. The results demonstrate the degree to which we can now use low-cost (for example, mobile-phone based) VR environments to create rich virtual experiences involving motion sensing, physiological inputs, stereoscopic imagery, sound, and haptic feedback. Adapting spatial interfaces to these new platforms can open up exciting application areas for VR. In this case, the application area was in-home VR therapy for patients suffering from persistent pain (for example, arthritis and cancer pain). For such therapy to be successful, a rich spatial interface and rich visual aesthetic are particularly important. So, an interdisciplinary team with expertise in technology, design, meditation, and the psychology of pain collaborated to iteratively develop and evaluate several prototype systems. The video at http://youtu.be/mMPE7itReds demonstrates how the sine wave fitting responds to walking motions, for a walking-in-place application.";"2013";"D. Schroeder and F. Korsakov and J. Jolton and F. J. Keefe and A. Haley and D. F. Keefe";"IEEE Computer Graphics and Applications";"https://doi.org/10.1109/MCG.2013.38"
"Cooperative control of a multi-arm system using semi-autonomous telemanipulation and adaptive impedance";"This paper addresses problems to achieve transparency and contact stability for Single Master Multi-Slave telemanipulation that consists of unconstrained and constrained motions. The adaptive bilateral control with a local force compensator is developed based on adaptive impedance control and contact force driven compensation with auto-switching functions. With a limited amount of knowledge about robotic and environment dynamics and a time-varying communication delay, the developed method guarantees good adaptive tracking performance in unconstrained motion and reduction of oscillating contacts to keep a balance of the system in constrained motion. Based on an actual haptic device and virtual robots, haptic simulations are presented to demonstrate adaptive transparency and contact stability in the presence of communication delays.";"2009";"Yushing Cheung and J. S. Chung";"2009 International Conference on Advanced Robotics";NA
"Designing an Extended Reality Application to Expand Clinic-Based Sensory Strategies for Autistic Children Requiring Substantial Support: Participation of Practitioners";"Extended Reality (XR) has already been used to support interventions for autistic children, but mainly focuses on training the socioemotional abilities of children requiring low support. To also consider children requiring substantial support, this paper examines how to design XR applications in order to expand clinic-based sensory strategies that are often used by practitioners to put them in a secure state, and how to maximize the acceptability of such applications among practitioners. To that respect, a \"Mixed Reality platform for Engagement and Relaxation of Autistic children\" was designed and developed, which allows to add audio, visual and haptic individualized or common stimuli onto reality. A first Augmented Reality freeplay use case called Magic Bubbles was created based on interviews with stakeholders and on a collaboration with three practitioners. A preliminary study with eleven practitioners confirmed its well-being potential and acceptability. XR design guidelines are finally derived.";"2021";"V. Bauer and T. Bouchara and P. Bourdot";"2021 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)";"https://doi.org/10.1109/ISMAR-Adjunct54149.2021.00059"
"Quantifying and Improving User Quality of Experience in Immersive Tele-Rehabilitation";"3D Tele-Immersion (3DTI) environments are emerging as a new medium for human interactions and collaborations in the areas of education, sports training, physical medicine and rehabilitation. By adding a tactile element to a visually centered 3DTI environment, such applications can be made even more engaging. But it also opens up a few challenges in terms of fusing the visual and tactile data streams in a synchronous way. In this paper we describe a 3DTI Tele-Rehabilitation system with Microsoft Kinect cameras and hap tic devices. We describe some of the challenges we face in providing as well as quantifying a good quality of experience (QoE) in this system. We propose a set of solutions that: (i) improve the user's QoE (by using multi-modal prediction for handling latencies, better synchronization that accounts for the global state of the system, etc.), (ii) quantify the QoE (by designing a controlled virtual environment and by defining appropriate user QoE metrics for immersive tele-rehabilitation). The experimental results show a marked improvement in the performance of the system, consequently improving the user-experience. This is also verified by the results of the user performance study.";"2014";"K. Venkatraman and S. Raghuraman and Y. Tian and B. Prabhakaran and K. Nahrstedt and T. Annaswamy";"2014 IEEE International Symposium on Multimedia";"https://doi.org/10.1109/ISM.2014.64"
"The Study of Using Eye Movements to Control the Laparoscope Under a Haptically-Enabled Laparoscopic Surgery Simulation Environment";"The purpose of this study is to investigate the possibility to use eye movements to control the laparoscope during a laparoscopic surgery. Laparoscopic surgery usually needs at least two doctors, a surgeon and a laparoscope assistant. The view of the operating surgeon is provided by the laparoscope assistant. As misunderstandings or conflicts of cooperation may happen, an ideal way is that the surgeon has a full control of all the instruments including the surgical tools and laparoscope. To achieve it, an eye based interaction method is introduced in this paper that allows surgeons to control the view by themselves. With recent developments in the eye tracker platforms and associated eye tracking technologies, many non-contact eye tracking systems are available. It can record where a person is looking at any time and a sequence of eye movements. This information can be used to know where is the attention and interest of the person on a display. As such, surgeon's attention can be captured and then be followed by moving the laparoscope to the region of interest. To have a safe and efficient evaluation on the usability, a virtual reality based laparoscopic surgery simulation is built. It is based on Unity with two haptic devices simulating the surgical tools, a 3D mouse providing 6 degrees-of-freedom control of the camera and an eye tracker capturing eyes' positions on a display. Experiments on moving a camera left, right, up, down, in, out and to specified locations using eyes are conducted, and moreover the performances of the proposed eye based self-control and the 3D mouse based other-control are compared. The results are promising where the proposed pointing method leads to 43.6% faster completion of the tasks against the traditional other-control method using the 3D mouse.";"2018";"H. Zhou and L. Wei and R. Cao and S. Hanoun and A. Bhatti and Y. Tai and S. Nahavandi";"2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)";"https://doi.org/10.1109/SMC.2018.00513"
"Bounded Rational Game-theoretical Modeling of Human Joint Actions with Incomplete Information";"As humans and robots start to collaborate in close proximity, robots are tasked to perceive, comprehend, and anticipate human partners' actions, which demands a predictive model to describe how humans collaborate with each other in joint actions. Previous studies either simplify the collaborative task as an optimal control problem between two agents or do not consider the learning process of humans during repeated interaction. This idyllic representation is thus not able to model human rationality and the learning process. In this paper, a bounded-rational and game-theoretical human cooperative model is developed to describe the cooperative behaviors of the human dyad. An experiment of a joint object pushing collaborative task was conducted with 30 human subjects using haptic interfaces in a virtual environment. The proposed model uses inverse optimal control (IOC) to model the reward parameters in the collaborative task. The collected data verified the accuracy of the predicted human trajectory generated from the bounded rational model excels the one with a fully rational model. We further provide insight from the conducted experiments about the effects of leadership on the performance of human collaboration.";"2022";"Y. Wang and P. Shintre and S. Amatya and W. Zhang";"2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)";"https://doi.org/10.1109/IROS47612.2022.9982108"
"Multicontact Bilateral Telemanipulation With Kinematic Asymmetries";"We propose a novel bilateral telemanipulation framework to tame master and slave devices having different structures. This condition applies to multicontact teleoperation scenarios where the number of contact points on the slave side and the number of interaction points on the master side are different. An example is a master device interacting with the thumb and the index fingertips of the human operator, and as slave device, a robotic arm with a multifingered robotic hand. In case of a manipulation task, it is not straightforward to transmit motion commands and reflect forces from the interaction with the environment. A general telemanipulation framework, that does not consider the specific kinematics of the devices involved, is needed. The main idea of this study is to take advantage of a virtual object as a mediator between the master and slave side. The arising forward and backward mapping algorithms are able to relate the motions and the exerted forces of very dissimilar systems. The approach has been evaluated in a case study consisting of two haptic interfaces used both to track the index and thumb motions and to render forces on the master side and a robotic arm with a multifingered hand as end effector on the slave side. The results presented in this paper can be extended to cooperative grasping scenarios where multiple robots telemanipulate the same object.";"2017";"G. Salvietti and L. Meli and G. Gioioso and M. Malvezzi and D. Prattichizzo";"IEEE/ASME Transactions on Mechatronics";"https://doi.org/10.1109/TMECH.2016.2606895"
"A Distributed Topology Control Algorithm for P2P Based Simulations";"Although collaborative distributed simulations and virtual environments (VE) have been an active area of research in the past few years, they have recently gained even more attention due to the emergence of online gaming, emergency simulation and planning systems, and disaster management applications. Such environments combine graphics, haptics, animations and networking to create interactive multimodal worlds that allows participants to collaborate in realtime. Massively Multiplayer Online Gaming (MMOG), perhaps the most widely deployed practical application of distributed virtual environments, allows players to act together concurrently in a virtual world over the Internet. IP Multicasting would be an optimal solution for the dissemination of updates among participants, but IP multicasting is not available to home users on the Internet, due to a number of technological, practical, and business reasons. In light of the lack availability of IP Multicasting on the global Internet, researchers have recently tended to shift multicasting from the networking layer to the application layer, known as Application Layer Multicasting, effectively constructing an overlay network among participants of the distributed simulation where end hosts themselves participate in the dissemination of update messages. In this paper, we propose a topology control architecture to support P2P based collaborative distributed simulations over the Internet by using AIM. We present our networking model and its rationale, theoretical proof, and simulation measurements in comparison with other methods as proof of concept.";"2007";"B. Hariri and S. Shirmohammadi and M. R. Pakravan";"11th IEEE International Symposium on Distributed Simulation and Real-Time Applications (DS-RT'07)";"https://doi.org/10.1109/DS-RT.2007.39"
"Multimedia and the Tactile Internet";"With the rapid development in the areas of multisensory hard- and software and the emergence of Tactile Internet, new media such as haptics, smell, olfaction, etc., nowadays, play a prominent role in making virtual objects physically tangible in a collaborative and/or networked virtual environment. By allowing users to feel each other's presence and physically manipulate objects from their interacted environments within 1 ms. The Tactile Internet facilitates fast multimodal interactions with multisensory information over the 5G network. 1 ms is a critical threshold in human perception of tactile response. For auditory response, this threshold is 100 ms and for visual response, it is 10 ms, which means delays above these thresholds are within the latency limit sensed by the human brain. In 4G, the round trip latency is 25 ms for an ideal environment. Clearly, that indicates 4G is not able to meet the requirements of tactile response. For this reason, the efforts to reduce latency in 5G are critical for Tactile Internet. Low-latency communications will also enable other digital twins’ applications such as real-time control of smart grid, self-driving car, and so on.";"2020";"A. E. Saddik";"IEEE MultiMedia";"https://doi.org/10.1109/MMUL.2020.2980098"
"Multisensory platform for surgical simulation";"Advanced display technologies have made the virtual exploration of relatively complex models feasible in many applications. Unfortunately, only a few human interfaces allow natural interaction with the environment. Moreover in surgical applications, such realistic interaction requires real time rendering of volumetric data-placing an overwhelming performance burden on the system. We report on a collaboration of a unique interdisciplinary group developing a virtual reality system that provides intuitive interaction with complex volume data by employing real time realistic volume rendering and convincing force feedback (haptic) sensations. We describe our rendering methods and the haptic devices in detail and demonstrate the utilization of this system in the real world application of Endoscopic Sinus Surgery (ESS) simulation.";"1996";"R. Yagel and D. Stredney and G. J. Wiet and P. Schmalbrock and L. Rosenberg and D. J. Sessanna and Y. Kurzion and S. King";"Proceedings of the IEEE 1996 Virtual Reality Annual International Symposium";"https://doi.org/10.1109/VRAIS.1996.490513"
"A Comparative Evaluation of Control Interfaces for a Robotic-Aided Endoscopic Capsule Platform";"Wireless capsule endoscopy offers significant advantages compared with traditional endoscopic procedures, since it limits the invasiveness of gastrointestinal tract screening and diagnosis. Moreover, active locomotion devices would allow endoscopy to be performed in a totally controlled manner, avoiding failures in the correct visualization of pathologies. Previous works demonstrated that magnetic locomotion through a robotic-aided platform would allow us to reach this goal reliably. In this paper, the authors present a comparative evaluation of control methodologies and user interfaces for a robotic-aided magnetic platform for capsule endoscopy, controlled through human-robot cooperative and teleoperated control algorithms. A detailed statistical analysis of significant control parameters was performed: teleoperated control is the more reliable control approach, and a serial kinematic haptic device results as the most suitable control interface to perform effective robotic-aided endoscopic procedures.";"2012";"G. Ciuti and M. Salerno and G. Lucarini and P. Valdastri and A. Arezzo and A. Menciassi and M. Morino and P. Dario";"IEEE Transactions on Robotics";"https://doi.org/10.1109/TRO.2011.2177173"
"Co-Simulation Environment for the Analysis of the Driving Simulator’s Actuation";"Driving simulators are providing the user realistic feedback regarding the required visual, auditory, haptic and kinesthetic information. The most common way of imposing the motion of the driving simulator is by the 6 degrees of freedom (DOF) Stewart hexapod platform. The actuation of the platform is performed through a mechatronic device, composed by a synchronous motor, belt drive, and a screw-ball mechanism. The simulation of the driving simulator’s actuation has to validate the motion platform characteristics. Combining different software packages and taking advantage of the strength of each of them, a collaborative co-simulation environment is opening the doors for powerful virtual prototyping and testing tools. In this paper, the co-simulation environment is using three powerful simulation software packages (Simcenter Amesim, Simcenter 3D Motion and Matlab/Simulink). In this environment were established the electromechanical model of the actuators, the dynamical model of the motion platform and the control module of the permanent magnet synchronous motors. The result of the co-simulation is confirming that the imposed motion of the platform can be achieved on the driving simulator. The motion of the platform was checked with an optical tracking device by attaching a reflective marker on the platform and recording its movement.";"2019";"C. Antonya and C. Irimia and M. Grovu and C. Husar and M. Ruba";"2019 7th International Conference on Control, Mechatronics and Automation (ICCMA)";"https://doi.org/10.1109/ICCMA46720.2019.8988628"
"Human-human physical interaction in the joint control of an underactuated virtual object";"Human-human physical interaction has proven to be advantageous especially in contexts with high coordination requirements. But under which conditions can haptic communication bring to performance benefits in a challenging cooperative environment? In this work we investigate which are the dynamics that intervene when two subjects are required to switch from a bimanual to a dyadic configuration in order to solve a complex reaching and stabilization task of a virtual tool in the presence of an unstable dynamics. Results show that dyadic cooperation can improve the performance respect to the individual condition, while minimizing the effort. However, in the joint task, when the stiffness of the system becomes harder to manipulate the feedback delays appear to be critical in determining the maximum achievable level of performance.";"2014";"D. De Santis and J. Zenzeri and L. Masia and V. Squeri and P. Morasso";"2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society";"https://doi.org/10.1109/EMBC.2014.6944601"
"Multi-Agent Reinforcement Learning-Based Distributed Channel Access for Next Generation Wireless Networks";"In the next generation wireless networks, more applications will emerge, covering virtual reality movies, augmented reality, holographic three-dimensional telepresence, haptic telemedicine and so on, which require the provisioning of high bandwidth efficiency and low latency services. In order to better support the aforementioned applications and services, novel distributed channel access (DCA) schemes are necessary. Therefore, we propose a new MAC protocol, QMIX-advanced Listen-Before-Talk (QLBT), based on the cutting-edge multi-agent reinforcement learning (MARL) algorithm. It employs a centralized training with decentralized execution (CTDE) framework to exploit the overall information of all agents during training, and ensure that each agent can independently infer the optimal channel access behavior based on its local observation. We enhance QMIX, a well-known MARL algorithm, by introducing an extra individual Q-value for each agent in the mixing network apart from the original total Q-value, which makes QLBT more stable. Moreover, delay to last successful transmission (D2LT) is first introduced in this work as a part of the observations of each QLBT agent, which facilitates agents to reach a cooperative policy that prioritizes the agent with the longest delay. Finally, extensive simulation experiments are provided to show that the proposed QLBT algorithm: 1) outperforms CSMA/CA and even its theoretical performance bound in various scenarios including saturated traffic, unsaturated traffic and delay-sensitive traffic; 2) is robust in dynamic environment; and 3) is able to friendly coexist with “legacy” CSMA/CA stations.";"2022";"Z. Guo and Z. Chen and P. Liu and J. Luo and X. Yang and X. Sun";"IEEE Journal on Selected Areas in Communications";"https://doi.org/10.1109/JSAC.2022.3143251"
"Dual-Driver Networked Fire Truck Simulator with Multimodal Display including Force Feedback Steering and Rotating Motion Platform";"We describe the integration of two pairs of force displays-- a force-feedback wheel (FFBW) and the S c haire (`Share Chair'), a rotary motion platform-- in a dual- driver networked driving simulator which navigates through virtual space using CVE ( collaborative virtual environment) groupware. We developed a double-driver (long ladder-style) fire-truck simulation with a tiller (rear steering), driven via an integrated pair of networked driving simulator stations. Such a dual-driver system is useful to turn narrow corners rapidly and smoothly in case of (simulated) emergencies. Its FFB steering wheels display simple collision force to both drivers separately when the vehicle collides with walls or other vehicles. The technique of feeding back the effect employs programs using C++ and DirectInput, escaping to an execution file called Force- Manager from the driving simulator, which is implemented with Java3D. Effect patterns are changed by arguments to ForceManager. The S c haire is rotated with a servo- motor, the rotation angle controlled via internet through the CVE. A demonstration video is posted at http: //sonic.u-aizu.ac.jp/spatial-media/ Videos/DualDrivingSimulator.mov . Keywords: dual-driver networked driving simulator, force feedback, haptic interface, rotary motion platform.";"2007";"T. Nagai and M. Cohen and Y. Moriguchi and Y. Murakami";"16th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE 2007)";"https://doi.org/10.1109/WETICE.2007.4407202"
"Guidance Priority Adaptation in Human-Robot Shared Control";"Demanded in highly unstructured environment like surgery, rehabilitation and teleoperation, shared control architecture allows operators to retain abilities and priority to control a human-robot interaction system (HRI), in which the robot provides stiffness and precision, and the human operator decides tactical maneuvering like obstacle avoidance and emergency takeover. By estimating haptic intention of human and adaptively restraining the operation force in unexpected direction, the adaptive shared control law is desired to continuously switch the lead priority to either the human or the robot. An adaptive admittance control strategy is thus developed based on the guidance virtual fixture (VF) /active constraint to promote the operation performance in collaborative tasks. By synthesizing adaptive admittance control and virtual fixture guidance, this comes true that the human operator’s intention and predefined guidance trajectory are combined in shared control. Both theoretical analysis and simulation results validate that the proposed control strategy has potential to provide stability and flexibility in the specific tasks for the HRI system.";"2022";"H. Ren and Z. Li and Q. Wu and D. Wu";"2022 IEEE International Conference on Mechatronics and Automation (ICMA)";"https://doi.org/10.1109/ICMA54519.2022.9856369"
"Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453)";"The following topics are dealt with: tactile sensing; aerial vehicles; legged robots; motion and path planning; learning systems; simultaneous localization and mapping; visual tracking; cooperative sensing; outdoor vehicles; biped walking; collision avoidance; reinforcement learning; visual servoing; sensor applications; underwater robots; legged locomotion; learning control; sensor-based planning; computational intelligence; mobile robot localization; robot vision; Internet robots; humanoid robots; fuzzy and neural control; sensing for mobile platforms; biologically inspired robots; trajectory planning; architecture and programming; vision-based monitoring; 3D sensing; cellular and modular robots; planning algorithms; mobiligence; multi-robot control; intelligent environment; sensor fusion; micro and nano robotic systems; task allocation; actuator systems; multi-robot systems; manufacturing systems; mechanism design; integrated MEMS sensors and actuators; force-responsive mechatronics in industry; medical robots and haptics; service robots; dexterous hands; sensing and navigation; telerobotics; personal robots; rescue and security robots; spaced robots; human/robot cooperation; compliant motion control; robot assisted surgery; grasping; human-robot interaction; intelligent robots; and virtual reality.";"2003";NA;"Proceedings 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003) (Cat. No.03CH37453)";"https://doi.org/10.1109/IROS.2003.1249176"
"Proceedings Seventh IEEE International Symposium on Distributed Simulation and Real-Time Applications";"The following topics are dealt with: high level architecture (HLA) and grid issues; real time systems; quality of service (QoS) and multimedia; parallel and distributed simulation; methodology and Web-based simulation; distributed simulation project management; and haptic audio visual collaborative virtual environments.";"2003";NA;"Proceedings Seventh IEEE International Symposium on Distributed Simulation and Real-Time Applications";"https://doi.org/10.1109/DISRTA.2003.1242989"
"Consumer Electronics Technologies for Enabling an Immersive Metaverse Experience";"The idea of the Metaverse as a virtual reality space where people can interact with computer-generated surroundings and each other in real time is gaining attention as this technology is roaring. Consumer electronics (CE) technology plays a crucial role in developing and using the metaverse. It offers the metaverse various devices like virtual reality headsets, augmented reality glasses, smartphones, and haptic feedback devices. These devices give users immersive experiences, improve communication and collaboration, and explore virtual worlds. In this article, we review several applications of consumer electronics technology in the metaverse, two case studies of consumer electronics in the metaverse, several challenges in the existing CE technology in adapting it to the metaverse, and some future directions for research. As a part of case studies, we analyze how CE technology impacts education and healthcare in the metaverse. In metaverse education and healthcare, CE provides opportunities for immersive learning experiences, virtual simulations, remote training, and improved patient care. Numerous challenges CE faces in the context of metaverse related to structure development, standardization efforts, privacy concerns, and ensuring security that must be addressed for its successful implementation have been identified. Despite its limitations, ongoing efforts are being made to enhance these devices and optimize the overall experience for the metaverse.";"2024";"S. Sai and D. Goyal and V. Chamola and B. Sikdar";"IEEE Consumer Electronics Magazine";"https://doi.org/10.1109/MCE.2023.3327530"
"Ultrareliable and Low-Latency Communication Techniques for Tactile Internet Services";"This paper presents novel ultrareliable and low-latency communication (URLLC) techniques for URLLC services, such as Tactile Internet services. Among typical use cases of URLLC services are teleoperation, immersive virtual reality, cooperative automated driving, and so on. In such URLLC services, new kinds of traffic such as haptic information including kinesthetic information and tactile information need to be delivered in addition to high-quality video and audio traffic in traditional multimedia services. Furthermore, such a variety of traffic has various characteristics in terms of packet sizes and data rates with a variety of requirements of latency and reliability. Furthermore, some traffic may occur in a sporadic manner but requires reliable delivery of packets of medium to large sizes within a low latency, which is not supported by current state-of-the-art wireless communication systems and is very challenging for future wireless communication systems. Thus, to meet such a variety of tight traffic requirements in a wireless communication system, novel technologies from the physical layer to the network layer need to be devised. In this paper, some novel physical layer technologies such as waveform multiplexing, multiple-access scheme, channel code design, synchronization, and full-duplex transmission for spectrally efficient URLLC are introduced. In addition, a novel performance evaluation approach, which combines a ray-tracing tool and system-level simulation, is suggested for evaluating the performance of the proposed schemes. Simulation results show the feasibility of the proposed schemes providing realistic URLLC services in realistic geographical environments, which encourages further efforts to substantiate the proposed work.";"2019";"K. S. Kim and D. K. Kim and C. -B. Chae and S. Choi and Y. -C. Ko and J. Kim and Y. -G. Lim and M. Yang and S. Kim and B. Lim and K. Lee and K. L. Ryu";"Proceedings of the IEEE";"https://doi.org/10.1109/JPROC.2018.2868995"
"A Comprehensive Survey of the Tactile Internet: State-of-the-Art and Research Directions";"The Internet has made several giant leaps over the years, from a fixed to a mobile Internet, then to the Internet of Things, and now to a Tactile Internet. The Tactile Internet goes far beyond data, audio and video delivery over fixed and mobile networks, and even beyond allowing communication and collaboration among things. It is expected to enable haptic communications and allow skill set delivery over networks. Some examples of potential applications are tele-surgery, vehicle fleets, augmented reality and industrial process automation. Several papers already cover many of the Tactile Internet-related concepts and technologies, such as haptic codecs, applications, and supporting technologies. However, none of them offers a comprehensive survey of the Tactile Internet, including its architectures and algorithms. Furthermore, none of them provides a systematic and critical review of the existing solutions. To address these lacunae, we provide a comprehensive survey of the architectures and algorithms proposed to date for the Tactile Internet. In addition, we critically review them using a well-defined set of requirements and discuss some of the lessons learned as well as the most promising research directions.";"2021";"N. Promwongsa and A. Ebrahimzadeh and D. Naboulsi and S. Kianpisheh and F. Belqasmi and R. Glitho and N. Crespi and O. Alfandi";"IEEE Communications Surveys & Tutorials";"https://doi.org/10.1109/COMST.2020.3025995"
"Adaptive attitude design with risk-sensitive optimal feedback control in physical human-robot interaction";"Anticipatory behavior based on the human behavior prediction enables the robot to improve the quality of its assistance in physical human-robot interaction (pHRI). However, predictions are partly afflicted with high uncertainties originating from the intrinsic variability in human behavior and the influence of the environment, requiring an attitude negotiation among partners. In this paper, we propose a novel control approach that dynamically adapts the robot's attitude to the disagreement level and the environmental situation in real time facilitating the negotiation between the human and the robot. The approach is based on risk-sensitive optimal feedback control. The adaptive design of the robot's attitude is realized through a dynamical changing risk-sensitivity parameter. The proposed approach is experimentally validated in a cooperative transport scenario in a two-dimensional visuo-haptic virtual environment.";"2012";"M. Saida and J. R. Medina and S. Hirche";"2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication";"https://doi.org/10.1109/ROMAN.2012.6343873"
"GAVRe2: Towards Data-Driven Upper-Limb Rehabilitation with Adaptive-Feedback Gamification";"This paper presents Game Adaptive Virtual Reality Rehabilitation (GAVRe2), a framework to augment upper limb rehabilitation using Virtual Reality (VR) gamification and haptic robotic manipulator feedback. GAVRe2 integrates independent systems in a modular fashion, connecting patients with therapists remotely to increase patient engagement during rehabilitation. GAVRe2 exploits VR capabilities to not only increase the productivity of therapists administering rehabilitation, but also to improve rehabilitation mobility for patients. Conventional rehabilitation requires face-to-face physical interactions in a clinical setting which can be inconvenient for patients. The GAVRe2 approach provides an avenue for rehabilitation in a domestic setting by remotely customizing a routine for the patient. Results are then reported back to therapists for data analysis and future training regime development. GAVRe2 is evaluated experimentally through a system that integrates a popular VR system, a RGB-D camera, and a collaborative industrial robot, with results indicating potential benefits for long-term rehabilitation and the opportunity for upper limb rehabilitation in a domestic setting.";"2018";"Y. Lai and S. Sutjipto and M. D. Clout and M. G. Carmichael and G. Paul";"2018 IEEE International Conference on Robotics and Biomimetics (ROBIO)";"https://doi.org/10.1109/ROBIO.2018.8665105"
"Realizing the Tactile Internet through Intelligent Zero Touch Networks";"The Internet of Things is expected to evolve and create numerous technological advances, paving the road for solutions that were once considered impossible. The Tactile Internet (TI), which is envisioned to enable real-time transmission of haptic and conventional data traffic, is creating that paradigm shift toward control-based communication between end users and machines. Tele-operation, augmented/virtual reality vehicle platooning, and industrial automation are all applications that can be supported by TI. The realization of TI over beyond fifth generation creates challenges for the current wireless communication and networking infrastructure. Network and communication reliability, ultra-high data rate connectivity, ultra-low latency, and stringent quality of service/experience (QoS/QoE) requirements must all be achieved for TI to effectively operate. Existing network infrastructures that require manual means of management and control cannot accommodate stringent TI constraints. With that said, the adaptation of advanced intelligent and cooperative solutions at the edge of the network is a crucial step toward guaranteed availability of resources and TI services. This article identifies and analyzes some of the technical issues that TI faces, then highlights and proposes potential solutions toward zero touch networks. We pay particular attention to the reliability performance gains achieved from cooperative edge devices, and their role in the provisioning of zero touch networking infrastructures that support TI applications.";"2022";"I. Al Ridhawi and M. Aloqaily and F. Karray and M. Guizani and M. Debbah";"IEEE Network";"https://doi.org/10.1109/MNET.001.2200016"
"Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292)";"The following topics are dealt with: localization; humanoid robots; flying robots; Petri nets; modular robots; calibration; programming; resource allocation; uncalibrated vision; virtual reality; motion planning; cooperating robots; sensing; binary actuation; mobile manipulation; industrial automation; fault tolerance; parallel robots; simulation; force-guided assembly; visual servo control; haptics; impedance control; omnidirectional robots; underwater robots; manufacturing; fixturing; cooperating manipulators; autonomous agents; Internet automation; micro locomotion; telerobotics; distributed manipulation; learning; biomedical robotics; micro assembly; hyper-redundant robots; skill acquisition; grasping; visual servo control; sensor-based planning; force control; nonholonomic robots; sensor fusion; SLAM human robot interaction; probabilistic roadmaps; fuzzy control; legged locomotion; space robotics; actuators; inspection; multirobot motion planning; robust control; navigation; aerial vehicles; CAD/CAM kinematics; pose detection; tracking; obstacle detection; obstacle avoidance; human assistance devices; teleoperator stability; stereo vision; service robots; multifinger hands; neural nets; learning; and jumping robots.";"2002";NA;"Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292)";"https://doi.org/10.1109/ROBOT.2002.1014684"
"Higher order sliding mode based impedance control for dual-user bilateral teleoperation under unknown constant time delay";"This paper presents a dual-user teleoperation scheme to perform a collaborative task using n-DOF nonlinear manipulators as masters and slave. Impedance controllers for the manipulators are implemented in order to achieve a desired dynamic behavior depending on the user's necessities. Furthermore, a sliding mode controller is introduced to cope with the time delay in the communication channels and the uncertainty in the slave. Since the slave teleoperator is in contact with a rigid environment, the slave controller requires a free of chattering control strategy, which makes first order sliding mode teleoperation control unsuitable. Then a higher order sliding mode based impedance controller is proposed to guarantee robust impedance tracking under constant, but unknown time delay. Therefore, a position scaling factor is incorporated to deal with the different workspaces among masters and slave. The validity of the proposed control scheme is demonstrated via experimentation on a 3-DOF dual-user teleoperation system. While the haptic devices Phantom Premium 1.0A and a Phantom Omni are used as masters, a virtual industrial manipulator Catalyst-5 is used as slave. The dual-user system is tested not only in presence of constant unknown time delay in each of the communication channels but also in free and constrained motion regime.";"2015";"H. Santacruz-Reyes and L. G. Garcia-Valdovinos and H. Jimenez-Hernandez and T. Salgado-Jimenez and L. A. Garcia-Zarco";"2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)";"https://doi.org/10.1109/IROS.2015.7354111"
"Exploring the potential of tangible user interface in classroom teaching — Learning";"Technology driven modern education system highly depends on the devices which is not an exception in the classrooms. These technological advancements pave new opportunities for creating innovative methods of collaboration depending on gesticulations, body-movements and management of real-objects enhancing higher degree of engagement in classroom. Tangible user interfaces can be noteworthy to the educational environment by empowering the students to interact with virtual objects augmented with the computing power. In this paper, we proposed a system specifying how TUI can be a better alternative in regular classroom teaching learning and explore various possibilities of TUI that can enhance the learning outcome with spontaneous learning zeal. The system also outlines the solution to various problems associated with quality learning in elementary classes. Investigative, design engrossed studies have shown that TUI's offer educational aids, due to the added haptic dimension, shared-space and improved approachability which could be used effectively in collective circumstances.";"2017";"S. Devi and S. Deb";"2017 3rd International Conference on Computational Intelligence & Communication Technology (CICT)";"https://doi.org/10.1109/CIACT.2017.7977368"
"ARGUS: Visualization of AI-Assisted Task Guidance in AR";"The concept of augmented reality (AR) assistants has captured the human imagination for decades, becoming a staple of modern science fiction. To pursue this goal, it is necessary to develop artificial intelligence (AI)-based methods that simultaneously perceive the 3D environment, reason about physical tasks, and model the performer, all in real-time. Within this framework, a wide variety of sensors are needed to generate data across different modalities, such as audio, video, depth, speech, and time-of-flight. The required sensors are typically part of the AR headset, providing performer sensing and interaction through visual, audio, and haptic feedback. AI assistants not only record the performer as they perform activities, but also require machine learning (ML) models to understand and assist the performer as they interact with the physical world. Therefore, developing such assistants is a challenging task. We propose ARGUS, a visual analytics system to support the development of intelligent AR assistants. Our system was designed as part of a multi-year-long collaboration between visualization researchers and ML and AR experts. This co-design process has led to advances in the visualization of ML in AR. Our system allows for online visualization of object, action, and step detection as well as offline analysis of previously recorded AR sessions. It visualizes not only the multimodal sensor data streams but also the output of the ML models. This allows developers to gain insights into the performer activities as well as the ML models, helping them troubleshoot, improve, and fine-tune the components of the AR assistant.";"2024";"S. Castelo and J. Rulff and E. McGowan and B. Steers and G. Wu and S. Chen and I. Roman and R. Lopez and E. Brewer and C. Zhao and J. Qian and K. Cho and H. He and Q. Sun and H. Vo and J. Bello and M. Krone and C. Silva";"IEEE Transactions on Visualization and Computer Graphics";"https://doi.org/10.1109/TVCG.2023.3327396"
"Robotic system for single incision laparoscopic surgery";"This paper proposes a robotic system to assist and collaborate with surgeons in Single Incision Laparoscopic Surgery (SILS) operations. The system, aim at solving the main drawbacks of this kind of surgery, is composed of a miniature camera robot and a redundant robotic grasper. Positioning of both robots inside the patient's abdomen is done by means of magnetic control. External magnetic sources are placed at the end effector of two robotic arms, and permanent magnets are integrated in the robots. Camera robot is provided with three permanent magnets, so both position and orientation can be controlled. Sliding control, which is robust against perturbations and parameter uncertainties, is chosen. Robotic grasper's redundancy makes possible autonomously obstacle avoidance and increases its workspace. The haptic device is designed so as surgeons can handle the grasper as if it were a conventional tool. In order to this aim, augmented reality is used to simulate a traditional tool in the visual feedback system, in substitution of the robotic grasper. Besides the telemanipulation, requirements for autonomously functions to assist surgeons in the specific tasks of suturing are discussed.";"2012";"I. Rivas-Blanco and P. del Saz-Orozco and I. García-Morales and V. Muñoz";"IECON 2012 - 38th Annual Conference on IEEE Industrial Electronics Society";"https://doi.org/10.1109/IECON.2012.6389138"
"New medical technologies of the future";"Over the last fifteen years OP 2000 has implemented various satellite-based networks for telemedicine (GALENOS, DELTASS, MEDASHIP, EMISPHER) using the high-end interactive video communication system WinVicos for telemedical applications like teleconsultation and second opinion at a moderate transmission bandwidth of 0.5-1 Mbps. This use of modern Information and Communication Technologies (ICT) as enabling tools for healthcare services (eHealth) has introduced new ways of creating ubiquitous access to high-level medical care for all, anytime and anywhere (uHealth). A virtual combination of applications serves as the basic concept for the development of a Virtual Hospital (VH). Analysis of the demands of the different user groups in (tele)medical collaboration has shown the need for real integration of the various technology platforms and medical services supporting the creation of ubiquitous virtual organisations for healthcare. OP 2000 has applied trend-setting technologies (high-resolution (HD) and stereoscopic visualisation; interactive real-time video communication with remote control of medical devices; virtual reality simulations with tracked visualisation and haptic feedback; optimised user interfaces, etc.) especially for surgical peri-operative research. The medical workplace 2020 represents a high-tech system configuration linking application-specific modules providing the users with all required information at the right time and place and most important in optimally processed form.";"2013";"G. Graschew and S. Rakowsky and T. A. Roelofs and P. M. Schlag";"The International Conference on Digital Technologies 2013";"https://doi.org/10.1109/DT.2013.6566293"
"High quality-oriented product cooperate design in virtual environments";"The integration of virtual reality and computer-aided design technologies is a revolution in the history of design. Virtual environments provide more information and feedback to designers than traditional desktop systems. Such information and feedback include immersive and stereoscopic visual information, haptic or tactile feedback, and auditory feedback. The multimodal information is in general rather intuitive and inspiring to designers, resulting in globally enhanced insights, creativity and productivity. Moreover, multimodal virtual reality technology excels at the visualization of complex scene and information, which is particularly difficult in desktop systems. In this talk, we present our recent research achievements on: (1) online synthesis of multi-channel visual signals, and the construction of multimodal virtual environments; (2) fusion of graphic, image and video signals in augmented reality environments; (3) synthesis of visual and haptic signals in virtual assembly applications; (4) virtual design and simulation in multimodal virtual environments, including surface deformation based on hand gesture interface, virtual assembly with haptic interactions, virtual maintenance in augmented reality environments; (5) demonstrations and examples.";"2010";"J. Tan";"The 2010 14th International Conference on Computer Supported Cooperative Work in Design";"https://doi.org/10.1109/CSCWD.2010.5472014"
"HAVE 2014 - 2014 IEEE International Symposium on Haptic, Audio and Visual Environments and Games";"Papers are being solicited on all aspects of multimodal haptic audio visual environment technologies and related haptic applications, including Haptic sensors and renderers. Hapto-audio-visual systems and applications, Hapto-surgical/medical systems, Haptic compression and prediction, multimodal perception and psychophysics, Haptic game interfaces, tele-haptics and tele-operation, augumented and virtualized reality, collaborative virtual environments, human-computer interaction in virtual environments, multi-sensor data fusion, object modeling, and soft computing techniques.";"2014";NA;"IEEE Instrumentation & Measurement Magazine";"https://doi.org/10.1109/MIM.2014.6782998"
"Welcome message from the chair";"We are very pleased to welcome you to the 14th edition of the IEEE IEEE International Symposium on Haptic Audio- Visual Environments and Games (HAVE), in Ottawa, Ontario, the National Capital of Canada. Similar to the previous editions, HAVE 2015 is a truly international event bringing together members of the Instrumentation and Measurement Society and the Haptics community from Canada, and the world. It promises to be an exciting and comprehensive symposium covering aspects of multimodal haptics, audio/visual virtual reality technologies, augments reality and telepresence, distributed collaborative environments and gaming, and all their related applications.";"2015";NA;"2015 IEEE International Symposium on Haptic, Audio and Visual Environments and Games (HAVE)";"https://doi.org/10.1109/HAVE.2015.7359442"
"Wip chairs";"New this year to ISMAR 2013, we are proud to present the Works In Progress (WIP) Program. Augmented Reality is rapidly growing into many new areas, so the WIP is a platform to present the field's latest, emerging results to the larger community before the work has reached its final form. This year, the program includes bread and butter AR technologies such as remote collaboration interfaces, fiducial marker design, and perceptual studies, to even loftier applications like AR interactions aboard the International Space Station. Passive haptics, bare-handed gesture interfaces, and realistic rendering round out the offerings. So come to the WIP sessions to hear about active AR research and find the spark of inspiration!";"2013";"S. Diverdi and J. Park";"2013 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)";"https://doi.org/10.1109/ISMAR.2013.6671753"
"A Collaborative Virtual Reality Escape Room with Passive Haptics";"Escape rooms have recently become a popular way to socialize and problem solve in an immersive environment. However, it can be difficult and expensive to create elaborate escape rooms with realistic props. Virtual reality (VR) technology allows developers to create and customize escape rooms more easily. However, to truly make the VR escape room immersive, physical and cooperative interactions are necessary. In this paper, the authors propose and demonstrate a two-player VR escape room developed for the HTC Vive. Physical interactions were made possible by using passive haptics in the form of simple props tracked using HTC Vive trackers and controllers. Additionally, the HTC Vives were networked, and players hands were tracked using the Leap Motion to provide head and hand position cues to teammates.";"2019";"A. Hanus and M. Hoover and A. Lim and J. Miller";"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)";"https://doi.org/10.1109/VR.2019.8798241"
"Proceedings IEEE Virtual Reality 2003";"The following topics are dealt with: clusters and system design for virtual reality; large display systems and augmented reality; applications; VR in medicine; human performance in VR; multi-user virtual environments and collaboration; tracking and user interfaces; haptic devices and object manipulation.";"2003";NA;"IEEE Virtual Reality, 2003. Proceedings.";"https://doi.org/10.1109/VR.2003.1191113"
"Proceedins of the 2006 IEEE International Workshop on Haptic Audio Visual Environments and Their Applications - HAVE 2006";"The following topics are dealt with: haptic audio visual environments and applications; haptic, audio & visual sensors and displays; multimodal perception and psychophysics; collaborative distributed virtual environments and applications; augmented and virtualized reality; object modeling and human-computer interaction";"2006";NA;"2006 IEEE International Workshop on Haptic Audio Visual Environments and their Applications (HAVE 2006)";"https://doi.org/10.1109/HAVE.2006.283546"
"Table of Contents";"Invited Papers Phone Guide: Adaptive Image Classification for Mobile Museum Guidance Oliver Bimber and Erich Bruns Computer Vision for 3DTV and Augmented Reality Hideo Saito Session 1: Connecting REAL and VIRTUAL Conceptualizing u-Content Ecosystem in Ubiquitous VR Environments Yoosoo Oh, Taejin Ha, Changgu Kang and Woontack Woo Estimation of Illuminants for Plausible Lighting in Augmented Reality Seokjun Lee, and Soon Ki Jung Real Time Vertex Based Deformation in Training Simulator Irshad Ahmad and Suziah Bt Sulaiman On Visual Artifacts of Physics Simulation in Augmented Reality Environment Sinyoung Kim, Yeonjoon Kim and Sung-Hee Lee Session 2: Connecting PEOPLE Collaboration between Tabletop and Mobile Device Jooyoung Lee, Ralf Doerner, Johannes Luderschmidt, HyungSeok Kim and Jee-In Kim Time-Efficient Data Congregation Protocols on Wireless Sensor Network A.K.M. Muzahidul Islam, Koichi Wada and Wei Chen mARGraphy: Mobile AR-based Dynamic Information Visualization Ahyoung Choi, Youngmin Park, Youngkyoon Jang, Changgu Kang, and Woontack Woo Barcode-Assisted Planar Object Tracking Method for Mobile Augmented Reality Nohyoung Park, Wonwoo Lee and Woontack Woo Session 3: Connecting HUMAN and COMPUTER ARWand: Phone-based 3D Object Manipulation in Augmented Reality Environment Taejin Ha and Woontack Woo Cartoon-like Stylization for Character Animation Ji-yong Kwon and In-Kwon Lee Effect of Active and Passive Haptic Sensory Information on Memory for 2D Sequential Selection Task Hojin Lee Gabjong Han In Lee Sunghoon Yim Kyungpyo Hong Seungmoon Choi Graphical Menus using Mobile Phone for Wearable AR Systems Hyeongmook Lee, Woontack Woo and Dongchul Kim";"2011";NA;"2011 International Symposium on Ubiquitous Virtual Reality";"https://doi.org/10.1109/VR.2009.4810976"
"[Front matter]";"The following topics are dealt with: electronic engineering; computer science; text analysis; document analysis; LTE; cellular automata; augmented reality; student learning; brain-computer interfaces; wireless networks; haptic rendering; cognition; WLAN; video streaming; collaborative robots; video games; and VANET.";"2008";NA;"2006 IEEE Symposium on Virtual Environments, Human-Computer Interfaces and Measurement Systems";"https://doi.org/10.1109/VECIMS.2006.250773"
"[Title page i]";"The following topics are dealt with: adaptive SIFT matching; flexible painting-based volume classification; fundamental matrix estimation algorithm; visual object contour tracking;information assisted visualization; marine main diesel propulsion remote control; deformation-aided virtual assembly system; motion data retrieval; very large motion databases; CUDA-based volume ray-casting; freehand tracking; multi-view stereo reconstruction; collaborative augmented reality; adaptive sampling based parallel volume rendering algorithm; Internet video search; view-dependent interactive visualization methods; smart compression scheme; image texture feature extraction method; radar network detection ability; tele-rehabilitation system; haptic rendering; fuzzy feature visualization; robust image registration algorithm and video semantic concept detection.";"2011";NA;"2011 International Conference on Virtual Reality and Visualization";"https://doi.org/10.1109/ICVRV.2011.1"
"HeXA: Haptic-enhanced eXtended reality framework for material-informed Architectural design";"Traditional architectural design processes are caught in sequential and isolated planning workflows, starting with pen-and-paper sketching, digitizing, visualizing for stakeholders, and refining. Only after the basic design has been established, structural engineers get involved and modify the structure, such that the design withstands all external loads. This segregated approach is driven by knowledge barriers associated with structural analysis and by lengthy feedback loops regarding structural design decisions involving finite element simulations. This paper presents research on a novel collaborative and digital design framework, labeled as HeXA, that lowers this knowledge barrier and enables all stakeholders to actively participate in structural design decisions. HeXA couples architecture, structural and material mechanics, computer science and graphics, as well as robotics in six modules: (1) a sketching interface for architectural design, (2) a geometric modeling module that translates the sketch to finite element meshes, (3) a material modeling module that predicts the mechanical properties of sustainable bio-composites, (4) a structural analysis module that assesses the mechanical performance using finite element simulations, and (5) an extended reality environment’s immersive visualization that is enhanced by (6) structural haptic feedback provided by a collaborative robot. This allows users to touch and push the envisioned structure in a virtual environment and experience realistic structural deformations provided by the robot and its arm in real-time while resulting stress fields are mapped onto the virtual structure. This way, architectural and structural design processes – particularly at the crucial early design stage – become collaborative, interactive, accessible, and responsive as demonstrated in the paper based on two use cases in theater stage design and building architecture.";"2025";"Senk, Valentin and Ghazanfari, Mohammad and Rasoulzadeh, Shervin and Vasylevska, Khrystyna and Kovacs, Balint Istvan and Mortezapoor, Soroosh and Vonach, Emanuel and Kovacic, Iva and Füssl, Josef and Kaufmann, Hannes and Königsberger, Markus";"Journal of Building Engineering";"https://doi.org/10.1016/j.jobe.2025.112707"
"Semi-Automated Control of AFM-based Micromanipulation using Potential Fields";"This paper proposes a truly interactive virtual environment (VE) system for 2-D assembly tasks at the microscale. It is based on the application of virtual potential fields as a control aid for performing safe and reliable path planning strategies. The planner covers a whole range of problems due to microscale effects in object assignment, obstacle detection and avoidance, path trajectory finding and sequencing. We investigated various paradigms for enabling the human operator and the automatic motion planner to cooperatively solve a motion planning task through the use of virtual potential fields. Communication between the operator and the planner is made through haptic/vision/sound modalities. First, we describe algorithms based on optimization theory and Voronoi graph construction taking into account the microscale effects. As automatic motion planners fail due to the difficulty of discovering critical configurations, we propose cooperation paradigms with operator skills in order to solve motion planning strategies. Then, potential fields are being used as a tool to generate velocity commands from an automatic path planner as well as allowing the human to interact. Finally, the ideas presented here are supported by experiments for efficient pushing-based manipulation constructing 2-D microparticle patterns.";"2008";"Ladjal, Hamid and Ferreira, Antoine";"17th IFAC World Congress";"https://doi.org/10.3182/20080706-5-KR-1001.02325"
"DISTRIBUTED WORKSPACES";"Collaborative work over remote sites is a challenge to developers of information- and communication technology as well as to the involved workforce. New developments on cost-effective connections are providing not only vision and auditory perception but also haptic perception. Research fields for improving remote collaboration are discussed. Social aspects as new requirements on the employees of networked and extended enterprises are considered.";"2006";"Erbe, Heinz-H.";"12th IFAC Symposium on Information Control Problems in Manufacturing";"https://doi.org/10.3182/20060517-3-FR-2903.00142"
"Enhancing Human-AI perceptual alignment through visual-haptic feedback system for autonomous drones";"Artificial Intelligence (AI) has emerged as an effective agent for controlling autonomous drones in navigation and target search tasks across various applications with minimal human intervention. Despite their advantages, significant challenges exist in aligning human operators' perceptual understanding with autonomous drone AI's assessment of environmental changes, particularly in dynamic and complex urban settings. This study addresses this issue by proposing a human-machine sensory sharing system that integrates visual and haptic feedback to enhance situational awareness, reduce cognitive load, and improve trust in the AI agent that controls the drones. By bridging the perceptual gap between humans and AI, our approach fosters a more cohesive and responsive interaction, enabling operators to make informed decisions in real-time. Through a human-subject experiment (N = 30) in a simulated urban environment, participants assessed environmental changes and adjusted drone AI parameters based on multimodal sensory feedback. Eye-tracking data were collected to evaluate cognitive load and engagement under different feedback conditions. Results show that combining visual and haptic feedback significantly enhances user performance, satisfaction, and decision-making speed, reducing perceptual misalignment between humans and AI. Participants using multimodal feedback demonstrated faster response times and higher environmental assessment accuracy than single-modality feedback. This research advances the design of intuitive human-drone interaction systems, emphasizing the role of multimodal sensory integration and physiological monitoring in improving human-machine collaboration. These findings have implications for applications in logistics, search and rescue, surveillance, and environmental monitoring, where operator engagement and performance are critical.";"2025";"Wu, Jiahao and Sun, Bowen and You, Hengxu and Du, Jing";"International Journal of Industrial Ergonomics";"https://doi.org/10.1016/j.ergon.2025.103780"
"Integration of an exoskeleton robotic system into a digital twin for industrial manufacturing applications";"Industry 4.0 has underscored the importance of human–robot collaboration (HRC), necessitating an efficient integration of human workers and robots to achieve high-productivity manufacturing. Traditional HRC-related teaching operations rely on intuitive tools, such as a teach pendant, but are effort-intensive and require personnel with specialized skills, particularly those who use collaborative robots in manufacturing. Thus, end-effector haptic devices that offer real-time tactile feedback and easy manipulation are being explored to address these issues. However, such devices have limitations in capturing the experiential movement of users and user-friendly haptic devices that are intuitive and convenient to operate are required. Recently, the integration of HRC and digital twins for human-involved manufacturing processes is being studied. Digital twin technology is used to seamlessly connect the physical and virtual domains using virtual models for monitoring the production process and enhancing the accuracy of operational process reconfiguration. However, most teaching devices that are interfaced with digital twins in manufacturing process still demand personnel with specialized training for their operation. To address these challenges, a novel framework is proposed herein that links an exoskeleton-type robotic system with the digital twin of a collaborative robot in manufacturing processes, effectively expediting robotic task instructions. The interactions between human users and digital twins, and that between digital twins and a collaborative robot, considerably enhance our understanding of human involvement in manufacturing processes and the execution of tasks by collaborative robots. This framework comprises three subsystems: a human operator outfitted with an exoskeleton-type robot and a virtual reality (VR) device, a digital twin, and a collaborative robot. The human operator interacts with the virtual robot within the digital twin via the VR device and exoskeleton robot, whereas the collaborative robot executes the given task and transmits the measured sensor information into the digital twin. Robot tracking in the experiment and usability study of a pick-and-place process performed on the proposed framework indicates that the proposed system enhances the ease of learning and intuitiveness to human operators than the traditional teaching methods in manufacturing processes.";"2024";"Park, Hoonmin and Shin, Minchul and Choi, Gyubok and Sim, Yuseop and Lee, Jiho and Yun, Huitaek and Jun, Martin Byung-Guk and Kim, Gyuman and Jeong, Younghun and Yi, Hak";"Robotics and Computer-Integrated Manufacturing";"https://doi.org/10.1016/j.rcim.2024.102746"
"Virtual Cerebral Aneurysm Clipping with Real-Time Haptic Force Feedback in Neurosurgical Education";"Objective Realistic, safe, and efficient modalities for simulation-based training are highly warranted to enhance the quality of surgical education, and they should be incorporated in resident training. The aim of this study was to develop a patient-specific virtual cerebral aneurysm-clipping simulator with haptic force feedback and real-time deformation of the aneurysm and vessels. Methods A prototype simulator was developed from 2012 to 2016. Evaluation of virtual clipping by blood flow simulation was integrated in this software, and the prototype was evaluated by 18 neurosurgeons. In 4 patients with different medial cerebral artery aneurysms, virtual clipping was performed after real-life surgery, and surgical results were compared regarding clip application, surgical trajectory, and blood flow. Results After head positioning and craniotomy, bimanual virtual aneurysm clipping with an original forceps was performed. Blood flow simulation demonstrated residual aneurysm filling or branch stenosis. The simulator improved anatomic understanding for 89% of neurosurgeons. Simulation of head positioning and craniotomy was considered realistic by 89% and 94% of users, respectively. Most participants agreed that this simulator should be integrated into neurosurgical education (94%). Our illustrative cases demonstrated that virtual aneurysm surgery was possible using the same trajectory as in real-life cases. Both virtual clipping and blood flow simulation were realistic in broad-based but not calcified aneurysms. Virtual clipping of a calcified aneurysm could be performed using the same surgical trajectory, but not the same clip type. Conclusions We have successfully developed a virtual aneurysm-clipping simulator. Next, we will prospectively evaluate this device for surgical procedure planning and education.";"2018";"Gmeiner, Matthias and Dirnberger, Johannes and Fenz, Wolfgang and Gollwitzer, Maria and Wurm, Gabriele and Trenkler, Johannes and Gruber, Andreas";"World Neurosurgery";"https://doi.org/10.1016/j.wneu.2018.01.042"
"Auditory feedback in haptic collaborative interfaces";"The combined effect of haptic and auditory feedback in shared interfaces on the cooperation between visually impaired and sighted persons is under-investigated. A central challenge for cooperating group members lies in obtaining a common understanding of the elements of the workspace and maintaining awareness of the other members' actions, as well as one's own, during the group work process. The aim of the experimental study presented here was to investigate if adding audio cues in a haptic and visual interface makes collaboration between a sighted and a blindfolded person more efficient. Results showed that task performance was significantly faster in the audio, haptic and visual feedback condition compared to the haptic and visual feedback condition. One special focus was also to study how participants utilize the auditory and haptic force feedback in order to obtain a common understanding of the workspace and to maintain an awareness of the group members' actions. Results from a qualitative analysis showed that the auditory and haptic feedback was used in a number of important ways to support the group members' action awareness and in the participants' grounding process.";"2012";"Huang, Ying Ying and Moll, Jonas and Sallnäs, Eva-Lotta and Sundblad, Yngve";"International Journal of Human-Computer Studies";"https://doi.org/10.1016/j.ijhcs.2011.11.006"
"Interactive path planning for haptic assistance in assembly tasks";"This paper describes a global interactive framework including fast motion planning and a real-time guiding force for 3D CAD part assembly or disassembly tasks. To begin with, a collaborative architecture including the user and the planner is described. Then, for real-time purposes, a motion planner divided into two steps is presented: firstly, a preliminary workspace discretization is carried out with no time limitations at the beginning of the simulation, secondly, using this computed data, a second algorithm tries to find a collision-free path in real-time. Once the path has been found, haptic artificial guidance on the path is provided to the user. The user can subsequently influence the planner by following—or choosing not to follow—the path and automatically order new path research. The performance of this haptic assistance is measured on tests based on an ALSTOM power component assembly simulation.";"2010";"Ladeveze, N. and Fourquet, Jean-Yves and Puel, Bernard";"Computers & Graphics";"https://doi.org/10.1016/j.cag.2009.10.007"
"Visual and haptic collaborative tele-presence";"The core of a successful sense of presence is a visually, aurally, and haptically compelling experience. In this paper, we introduce the integration of vision and haptics for the purposes of remote collaboration. A remote station acquires a 3D-model of an object of interest which is transmitted to a local station. A user in the local station manipulates a virtual and the remote object as if he/she is haptically and visually at the remote station. This tele-presence feeling is achieved by visually registering the head-mounted display of the local user to the remote world and by dynamically registering the local object both visually and haptically with respect to the remote world. This can be achieved by adequate modeling and feedforward compensation including gravity compensation for the robotic manipulator with which the operator interacts. We present multiple scenarios where such a capability will be useful. One is remote design where a user tests a remotely designed docking station by inserting a virtual laptop into a model of the 3D docking station transmitted from a remote site. Medical robotics provides another possible scenario in which a resident is given surgical training to perform a virtual laparoscopy on a 3D exterior model of a patient, including tomographic registration of anatomical structures. We present results from numerous experiments from both the visual and haptic aspects as well as in integrated form.";"2001";"Ansar, Adnan and Rodrigues, Denilson and Desai, Jaydev P. and Daniilidis, Kostas and Kumar, Vijay and Campos, Mario F.M.";"Mixed realities - beyond conventions";"https://doi.org/10.1016/S0097-8493(01)00121-2"
"Developing a needle guidance virtual environment with patient-specific data and force feedback";"We present a simulator for guided needle puncture procedures. Our aim is to provide an effective training tool for students in interventional radiology (IR) using actual patient data and force feedback within an immersive virtual environment (VE). Training of the visual and motor skills required in IR is an apprenticeship which still consists of close supervision using the model: (i) see one, (ii) do one, and (iii) teach one. Training in patients not only has discomfort associated with it, but provides limited access to training scenarios, and makes it difficult to train in a time efficient manner. Currently, the majority of commercial products implementing a medical VE still focus on laparoscopy where eye–hand coordination and sensation are key issues. IR procedures, however, are far more reliant on the sense of touch. Needle guidance using ultrasound or computed tomography (CT) images is also widely used. Both of these are areas that have not been fully addressed by other medical VEs. This paper provides details of how we are developing an effective needle guidance simulator. The project is a multi-disciplinary collaboration involving practising interventional radiologists and computer scientists.";"2005";"Vidal, Franck P. and Chalmers, Nicholas and Gould, Derek A. and Healey, Andrew E. and John, Nigel W.";"CARS 2005:  Computer Assisted Radiology and Surgery";"https://doi.org/10.1016/j.ics.2005.03.200"
"Haptic Shared Control for Human-Robot Collaboration: A Game-Theoretical Approach";"Complementing human and robot capabilities is essential for many tasks, e.g. rehabilitation and collaborative manufacturing. However, it is still not clear how control between humans and robots should be shared in order to ensure efficient task execution and intuitive interaction. Game theory seems as a promising mathematical framework that allows: i) posing this challenge as a dynamic negotiation (game) among human and robot (players) and ii) solving it to obtain optimal solution. In this work, we propose a differential game-theoretic shared control approach for human-robot haptic collaboration with Nash equilibrium optimal solution. We validate the proposed approach experimentally in a scenario where human is physically coupled with a haptic device and interacts with a virtual reality to perform a trajectory tracking task.";"2020";"Musić, Selma and Hirche, Sandra";"21st IFAC World Congress";"https://doi.org/10.1016/j.ifacol.2020.12.2751"
"Cut and Suture Support on Volumetric Models in the CyberMed Framework";"The need of applications for realistic training to medical professionals motivated the development of the framework CyberMed. Since 2006, this framework provides a set of features that allow users to freely build interactive virtual environments for realistic medical training. Thus, simulations composed by 3D visualization and interaction with haptic feedback can be created for different areas of medicine. In order to allow using data obtained from real exams, such as CT and MRI, the CyberMed had its kernel recently expanded. Now the framework enables working with volumetric data to build more realistic medical simulations. The aim of this paper is to present this process of expansion realized in a cooperation work between two countries, emphasizing the new possibilities offered by this integration for further works related to simulations with cut and suture of tissues.";"2012";"Cunha, Ícaro L.L. and Xia, Ping Jung and Machado, Liliane S. and Restivo, Teresa and Moraes, Ronei M. and Lopes, Antonio M.";"4th Conference of ENTERprise Information Systems – aligning technology, organizations and people (CENTERIS 2012)";"https://doi.org/10.1016/j.protcy.2012.09.085"
"Architectures for shared haptic virtual environments";"The lack of force feedback in visual-only simulations may seriously hamper user proprioception, effectiveness and sense of immersion while manipulating virtual environments. Haptic rendering, the process of feeding back force to the user in response to interaction with the environment is sensitive to delay and can become unstable. In this paper we will describe various techniques to integrate force feedback in shared virtual simulations, dealing with significant and unpredictable delays. Three different implementations are investigated: static, collaborative and cooperative haptic virtual environments.";"1997";"Buttolo, Pietro and Oboe, Roberto and Hannaford, Blake";"Haptic Displays in Virtual Environments and Computer Graphics in Korea";"https://doi.org/10.1016/S0097-8493(97)00019-8"
"VR–CAD integration: Multimodal immersive interaction and advanced haptic paradigms for implicit edition of CAD models";"This paper presents an approach for the integration of Virtual Reality (VR) and Computer-Aided Design (CAD). Our general goal is to develop a VR–CAD framework making possible intuitive and direct 3D edition on CAD objects within Virtual Environments (VE). Such a framework can be applied to collaborative part design activities and to immersive project reviews. The cornerstone of our approach is a model that manages implicit editing of CAD objects. This model uses a naming technique of B-Rep components and a set of logical rules to provide straight access to the operators of Construction History Graphs (CHG). Another set of logical rules and the replay capacities of CHG make it possible to modify in real-time the parameters of these operators according to the user’s 3D interactions. A demonstrator of our model has been developed on the OpenCASCADE geometric kernel, but we explain how it can be applied to more standard CAD systems such as CATIA. We combined our VR–CAD framework with multimodal immersive interaction (using 6 DoF tracking, speech and gesture recognition systems) to gain direct and intuitive deformation of the objects’ shapes within a VE, thus avoiding explicit interactions with the CHG within a classical WIMP interface. In addition, we present several haptic paradigms specially conceptualized and evaluated to provide an accurate perception of B-Rep components and to help the user during his/her 3D interactions. Finally, we conclude on some issues for future researches in the field of VR–CAD integration.";"2010";"Bourdot, P. and Convard, T. and Picon, F. and Ammi, M. and Touraine, D. and Vézien, J.-M.";"Advanced and Emerging Virtual and Augmented Reality Technologies in Product Design";"https://doi.org/10.1016/j.cad.2008.10.014"
"Exploring the synergies between collaborative robotics, digital twins, augmentation, and industry 5.0 for smart manufacturing: A state-of-the-art review";"Industry 5.0 aims at establishing an inclusive, smart and sustainable production process that encourages human creativity and expertise by leveraging enhanced automation and machine intelligence. Collaborative robotics, or “cobotics”,is a major enabling technology of Industry 5.0, which aspires at improving human dexterity by elevating robots to extensions of human capabilities and, ultimately, even as team members. A pivotal element that has the potential to operate as an interface for the teaming aspiration of Industry 5.0 is the adoption of novel technologies such as virtual reality (VR), augmented reality (AR), mixed reality (MR) and haptics, together known as “augmentation”. Industry 5.0 also benefit from Digital Twins (DTs), which are digital representations of a physical assets that serves as their counterpart — or twins. Another essential component of Industry 5.0 is artificial intelligence (AI), which has the potential to create a more intelligent and efficient manufacturing process. In this study, a systematic review of the state of the art is presented to explore the synergies between cobots, DTs, augmentation, and Industry 5.0 for smart manufacturing. To the best of the author’s knowledge, this is the first attempt in the literature to provide a comprehensive review of the synergies between the various components of Industry 5.0. This work aims at increasing the global efforts to realize the large variety of application possibilities offered by Industry 5.0 and to provide an up-to-date reference as a stepping-stone for new research and development within this field.";"2024";"Zafar, Muhammad Hamza and Langås, Even Falkenberg and Sanfilippo, Filippo";"Robotics and Computer-Integrated Manufacturing";"https://doi.org/10.1016/j.rcim.2024.102769"
"Simulation-based learning in orthopaedics: A qualitative systematic review";"Background Simulation-based learning has emerged as a transformative tool in orthopaedic education, significantly improving surgical training and patient safety. This systematic review examines the role of simulation in enhancing technical skills, decision-making, and clinical competence among orthopaedic trainees. Methods A systematic review was conducted to assess the effectiveness of simulation-based training in orthopaedics. Various simulation modalities, including virtual reality (VR), augmented reality (AR), haptic feedback systems, and task-based trainers, were analyzed for their impact on skill acquisition and retention. The study was registered with PROSPERO (ID: CRD420250652679). Results Key findings suggest that simulation-based training leads to reduced surgical errors, faster learning curves, and better skill retention. However, challenges such as high costs, limited access to advanced simulation tools, and difficulties in integrating these technologies into traditional curricula persist. Conclusion Simulation is expected to play a crucial role in modernizing orthopaedic education by providing safe, repeatable practice opportunities. Future directions include AI-driven training modules and collaborative VR platforms to further enhance training efficacy and patient outcomes.";"2025";"Roy, Mainak and T, Priyadarshini and Ashika, M.S. and Das, Gurudip and Patro, Bishnu Prasad and Bharadwaj, Sanjeevi";"Journal of Clinical Orthopaedics and Trauma";"https://doi.org/10.1016/j.jcot.2025.102986"
"Preliminary realization of immersive EAST system using virtual reality";"Aiming at the complex and confined environments of experimental advanced superconducting tokamak (EAST) and the need to improve the ability of resident and visiting scientists to access and understand EAST, the immersive EAST system based on virtual reality is developed. Compared to previous virtual EAST systems, model reality, rendering speed, immersion and interaction functions are greatly increased. In the previous system, models were transformed from CATIA and imported to 3DS Max for subsequent processing. While those models have the advantages of being very precise and easily generated, they come at the price of decreased rendering speed and poor rendering quality because of a large loss of triangle faces. In this regard, EAST models are rebuilt and materials created by photos of EAST device are assigned to models. Moreover, because virtual reality is quite effective at creating experiment scenarios thanks to their ability to provide the feeling of immersive operation and collaborative environments, model libraries are built during this research for future scheme generation and hardware installation training. The immersive EAST system is developed in the Unity3D environment using a Client/Server architecture, the HTC Vive and handheld devices are used to provide the immersive scene, intuitive controls and realistic haptic feedback. Users can roam in the virtual scene and interact with the immersive EAST using the handheld devices and communicate with other users in the system. The establishment of the system provides the framework for a comprehensive and cooperative experiment and training environment for EAST.";"2018";"Li, Dan and Xiao, B.J. and Xia, J.Y. and Wang, K.R.";"Fusion Engineering and Design";"https://doi.org/10.1016/j.fusengdes.2018.02.031"
"Augmented reality user interface design and experimental evaluation for human-robot collaborative assembly";"Artificial intelligence (AI) has been applied to a wide spectrum of industrial sectors, but manual operations remain indispensable in most manufacturing systems due to high complexity or costs involving in automation. A more practical approach is enabling humans to collaborate with machines complementary to each other. One critical issue in human-robot collaboration (HRC) is to assure the operator's productivity, safety, and trust while interacting with the robot. This paper presents an experimental study on user interface design in augmented reality (AR) for human-robot collaborative assembly in a shared workspace. The experiment aims to verify and cross-compare the effectiveness of visual and haptic cues in various forms that convey the robot intent to human. Analysis of the work performance and gazing behavior of participants shows that both cues can reduce their visual attention on the moving robot during the collaboration. The interface that provides the proximity of robot using visual cues is considered most useful. It is not intuitive to recognize complex information by vibration on different parts of the human hand in the experiment. Finally, human trust to robot has a higher correlation on the usability of a user interface than the work performance assisted by the interface. These findings may work as design guidelines for AR assisted human-robot interaction in smart manufacturing.";"2023";"Chu, Chih-Hsing and Liu, Yu-Lun";"Journal of Manufacturing Systems";"https://doi.org/10.1016/j.jmsy.2023.04.007"
"The roles of sensory modalities in collaborative virtual environments (CVEs)";"This study was conducted to assess the effects of sensorial modalities on user performance, perception, and behavior in collaborative virtual environments (CVEs). Participants played a CVE game, air hockey, together with a remote partner under different sensory modality conditions, depending on the type of sensory feedback provided: visual-only (V), visual–haptic (V+H), and visual–haptic–audio feedback (V+H+A). Three types of measurements were used as dependent variables: (1) task performance measured as playing time, (2) user perception including the sense of presence, the sense of togetherness, and perceived collaboration, and (3) behavior measurement including the amount of force applied and the mallet deviation. Results of the study indicated that the task performance, perception, and user behavior in CVEs can be affected due to supported sensory modalities. Therefore, the multiple sensory information types that are required to perform the task at hand should be provided to effectively support collaboration between people in CVEs. The outcomes of this research should have a broad impact on multimodal user interaction, including research on physiological, psychophysical, and psychological mechanisms underlying human perception on multisensory feedback in CVEs.";"2008";"Nam, Chang S. and Shu, Joseph and Chung, Donghun";"Including the Special Issue: Integration of Human Factors in Networked Computing";"https://doi.org/10.1016/j.chb.2007.07.014"
"“IOMaster 7D”—a new device for virtual neuroendoscopy";"Purpose: Within a scope of a cooperative project called “HapticIO” (funded by the German Ministry of Education and Research (BMBF)), a completely new force feedback device “IOMaster 7D” was intended to be developed for simulation of endoscopic ventriculo-cisternostomy (VCS). Methods: A VR model for endoscopic ventriculostomy was generated based on a MRI data set of a real hydrocephalic brain. Different software modules were used for segmentation (VESUV), modelling (KisMo) and visualization (KISMET). The software modules were implemented on a WIN32 platform and are running on Windows-NT, Win2000 or WinXP. A force feedback system for capturing of the position of both the trocar and the acting instrument was developed. Large arms are counterbalanced to reduce gravitational forces and torques. The position and orientation of the input handle is determined by taking the joint angles of the linkages and using the forward kinematics calculation. Force data returned by the simulation is mapped to a set of torques to be produced by the motors by using a so-called Jacobian transformation. Real microsurgical instruments (MINOP, Aesculap, Germany) were used and adapted to the simulator to provide for a design and haptic properties close to real situation in the OR. The system was evaluated in a pilot series. Results: The force feedback system IOMaster 7D offers 7 degrees of freedom and consists of two coupled force feedback elements. Both the trocar and the acting instruments (scissor, bipolar coagulation, forceps, inflatable balloon catheter) are captured separately. In this way, the trocar's position determines the view of the endoscopic 30° lens camera, the access to the target and the possible operating range of the instruments. A complex elastodynamic hydrocephalic configured ventricular system with realistic proportions and anatomical structures could be modelled. An interactive virtual preparation with force feedback was implemented coupling real surgical instruments (MINOP) with the force feedback system. The VR system provides different interactions like axial movement or rotation of the instruments, cutting, grasping as well as realistic elastodynamic deformations of the ventricle wall. First evaluations proved a reduction of the median failure rate and a reduction of the median required time to reach the target. Analysis of the total distance of instruments movement also showed a reduction. Conclusion: VR systems can simulate realistic and real-time surgical procedures and may open new perspectives for the neurosurgical training. The training of potentially hazardous procedures can be uncoupled from the patient resulting in a reduction of surgical morbidity. The integration of haptic information increases the quality of these training systems. The definition of no-touch areas and targets and the possibility of automatic registration of both kinetic parameters, failure rate and the time course of the procedure provide objective criteria for the appreciation of a learning effect.";"2004";"Trantakis, C and Meixensberger, J and Strauß, G and Nowatius, E and Lindner, D and Cakmak, H.K and Maaß, H and Nagel, C and Kühnapfel, U";"CARS 2004 - Computer Assisted Radiology and Surgery. Proceedings of the 18th International Congress and Exhibition";"https://doi.org/10.1016/j.ics.2004.03.273"
"Original computer aided support system for safe and accurate implant placement—Collaboration with an university originated venture company";"Summary An original implant surgery support system with computer simulation to determine the position of implant placement and fabrication of a surgical guide that helps in bone drilling was developed by collaboration of Osaka University Faculty of Dentistry and Dental Prostheses Fabrication Company. A virtual reality haptic device that gives the sense of touch was used for simulation and a surgical template was fabricated by CAD/CAM method. A patented technology enabled to remove artifact due to metallic prostheses by replacing the damaged teeth of CT image by precise 3D measured image of dental cast. Surgical guide was designed using haptic device and fabricated including bone model by a computer-aided rapid prototyping modeling machine with a UV-cured acrylic-based resin material. Two clinical cases with implant placement on the three lower molars by flap operation using bone supported surgical guide and flapless operation with teeth supported surgical guide and immediate loading with provisional prostheses prepared beforehand are introduced. The present simulation and drilling support using the surgical guide may help to perform safe and accurate implant surgery.";"2010";"Sohmura, Taiji and Kumazawa, Yoich";"Japanese Dental Science Review";"https://doi.org/10.1016/j.jdsr.2010.01.002"
"Usability of VR-Systems in Cross-Cultural Product Development: A Case Study";"Software tools have become essential in contemporary product development. It is now commonplace to use computer-aided design (CAD) for designing and the finite element method (FEM) for confirming structural integrity. Since the year 2016, virtual reality (VR) has gained importance as a novel software tool in development departments, a compound growth of US$3.6B to over US$40B to date. Although VR is already used in design reviews, it is yet to be fully integrated into other areas. However, to increase acceptance, it is particularly important for new, versatile software tools to allow widespread use throughout the entire development process. To broaden the application spectrum of VR, this paper presents a hetero-cultural case study that shows how VR can support distributed development teams in identifying and then verifying ergonomic requirements. The test groups consist of students from Ostfalia University of Applied Sciences and Tshwane University of Technology. Once the case study concludes, proposals for forthcoming measures to further develop and utilize VR systems in the area of requirement identification will be created, and cultural discrepancies identified, including harmonies.";"2024";"Balzerkiewitz, Hans-Patrick and Dlamini, Nokulunga and Stechert, Carsten and Mpofu, Khumbulani";"34th CIRP Design Conference";"https://doi.org/10.1016/j.procir.2024.03.019"
"HUMAN-HUMAN COLLABORATION";"Collaborative work over remote sites is a challenge to developers of information- and communication technology as well as to the involved workforce. New developments on cost-effective connections are providing not only vision and auditory perception but also haptic perception. Research fields for improving remote collaboration are discussed. Social aspects as new requirements on the employees of networked and extended enterprises are considered.";"2005";"Erbe, Heinz-H.";"16th IFAC World Congress";"https://doi.org/10.3182/20050703-6-CZ-1902.01394"
"Impacts of VR 3D sketching on novice designers’ spatial cognition in collaborative conceptual architectural design";"Conventional Computer Aided Design tools lack intuitivity for being used in conceptual architectural design process. This paper identifies the impact of using a haptic based VR 3D sketching interface for integrating novice designers’ cognitions and actions to improve design creativity. This study employs protocol analysis for comparing the collective cognitive and collaborative design protocols of three pairs of novice architectural designers in both 3D and manual sketching sessions. Results show that the simple and tangible haptic based design interface improved designers’ cognitive and collaborative activities. These improvements also increased their engagement with ‘problem-space’ and ’solution-space’ that led towards more artefact maturity. Research findings from this study can help the development of cutting-edge haptic-based collaborative virtual environments in architectural education and associated professions.";"2011";"Rahimian, Farzad Pour and Ibrahim, Rahinah";"Design Studies";"https://doi.org/10.1016/j.destud.2010.10.003"
"Implementation of virtual reality systems for simulation of human-robot collaboration";"A collaboration between human and robot can implicate many advantages for complex industrial assembly processes, especially as increased flexibility and adaptability become a key feature of production systems. The use of virtual reality (VR) systems has the potential to simulate cooperative processes in advance and to include workers and their individual behavior into the simulation. The use of VR simulations makes it possible to secure processes and reduce physical and mental barriers between human and robot. This paper presents a methodical approach for the implementation of systems for the virtual testing of collaborative assembly processes. Following the aim of replicating the assembly process with the highest possible immersion, a specific VR system is derived from an analysis of the assembly process. Core features of the system are the physical simulation of the assembly process, the integration of the robot control and a haptic feedback for the operator.";"2018";"Rückert, Patrick and Wohlfromm, Laura and Tracht, Kirsten";"Proceedings of the 6th International Conference in Through-life Engineering Services, University of Bremen, 7th and 8th November 2017";"https://doi.org/10.1016/j.promfg.2018.01.023"
"Improved interaction with collaborative robots - evaluation of event-specific haptic feedback in virtual reality";"Industry 5.0 adopts a human-centric approach that views humans as a natural part of introducing new technology, such as collaborative robots. However, one of the main challenges in implementing collaborative robots is safety, including the sense of safety. Trust is also a primary challenge when establishing functional collaboration. Influencing factors includes experience and expertise, and research shows that Virtual Reality has the potential to perform such training. This research aims to investigate whether using virtual reality with appropriate feedback can be an effective platform for familiarization and training. In our experiment, we utilized haptic feedback from commercial Virtual Reality controllers to simulate physical interactions with collaborative robots. The experiment involved the participation of fifteen individuals. The results showed that participants regarded haptic feedback while moving as the most appropriate representation. This research aims to identify whether Virtual Reality with suitable feedback can serve as a familiarization and training platform.";"2024";"Andersson, My and Syberfeldt, Anna";"5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)";"https://doi.org/10.1016/j.procs.2024.01.104"
"Robot-assisted shoulder arthroplasty";"Robotic assistance has demonstrated to provide value in the field of hip and knee arthroplasty. As a result, it is becoming increasingly popular. On the contrary, robot-assisted shoulder arthroplasty is in its infancy. The various commercially available robots for arthroplasty applications are quite different regarding the features they provide. For shoulder arthroplasty, the Rosa system is already available to selected users, and the Mako system will be available soon. Rosa is considered a collaborative robot that positions cutting guides and reamers as a combined effort between the robot and the surgeon; once the desired position of the guide or reamer is achieved, the robot enters static mode, and the surgeon performs the humerus osteotomy or reams the glenoid in collaboration with the robot; currently, augment preparation is not provided. Mako provides an effector end that prepares bone and uses haptic boundaries to avoid error; details on the Mako shoulder application have not been released. The main theoretical benefits of robot-assisted shoulder arthroplasty include accuracy and precision, data acquisition, and with certain robots, the promise to avoid soft-tissue injury with haptic boundaries, prepare a bone through minimally invasive or cuff-preserving exposures, and the potential for motion assessment and soft-tissue balance. The disadvantages include cost, a certain learning curve, complications related to array insertion, potential for cognitive bias, need for a larger operating room space, and the potential for malfunction. Although adoption is likely to happen in many centers, cost and space constrains may favor alternative technologies, such as mixed reality navigation, especially in ambulatory surgery centers.";"2025";"Sanchez-Sotelo, Joaquin";"JSES International";"https://doi.org/10.1016/j.jseint.2025.02.004"
"An experimental study on the effects of Network delay in Cooperative Shared Haptic Virtual Environment";"A cooperative shared haptic virtual environment (CSHVE), where the users can kinesthetically interact and simultaneously feel each other over the network, is beneficial for many distributed VR simulations. A little is known about the influences of the network delay on the quality of haptic sensation and the task performance in such environments. This paper has addressed these issues by conducting a subjective evaluation to the force feedback and the task performance in a tele-handshake cooperative shared haptic system for different delay setting. Also, four subjective measures to evaluate the quality of haptic in CSHVEs have been proposed. These measures are the feeling of force, the consistency between the haptic-visual feedback, the vibration, and the rebound in the haptic device. In addition, a detailed description of the haptic sensation for different time delays is also described. A network emulator was utilized to simulate the real network cloud. An objective evaluation of the force feedback and the performance showed that there was no effect of the delay on the force feedback. It had a negative impact on the task performance. In general, the quality of haptic deteriorated as the delay increased and vibration and rebound hampered the users for large time delay. The haptic-visual consistency was robust in the presented system even for large time delays. Nevertheless, the examined tele-handshake system was able to deliver a high quality of haptic sensation, good performance, and stability for large time delay over the network.";"2003";"Alhalabi, M.Osama and Horiguchi, Susumu and Kunifuji, Susumu";"Computers & Graphics";"https://doi.org/10.1016/S0097-8493(02)00277-7"
"Hybrid client–server architecture and control techniques for collaborative product development using haptic interfaces";"In this paper, a collaborative product development and prototyping framework is proposed by using distributed haptic interfaces along with deformable objects modeling. Collaborative Virtual Environment (CVE) is a promising technique for industrial product development and virtual prototyping. Network control problems such as network traffic and network delay in communication have greatly limited collaborative virtual environment applications. The problems become more difficult when high-update-rate haptic interfaces and computation intensive deformable objects modeling are integrated into CVEs for intuitive manipulation and enhanced realism. A hybrid network architecture is proposed to balance the computational burden of haptic rendering and deformable object simulation. Adaptive artificial time compensation is used to reduce the time discrepancy between the server and the client. Interpolation and extrapolation approaches are used to synchronize graphic and haptic data transmitted over the network. The proposed techniques can be used for collaborative product development, virtual assembly, remote product simulation and other collaborative virtual environments where both haptic interfaces and deformable object models are involved.";"2010";"Lin, Shiyong and Narayan, Roger J. and Lee, Yuan-Shin";"Computers in Industry";"https://doi.org/10.1016/j.compind.2009.07.004"
"On Multi-Agent Cognitive Cooperation: Can virtual agents behave like humans?";"Individuals tend to cooperate or collaborate to reach a common goal when the going gets tough creating a common frame of reference that is a common mental representation of the situation. Information exchange among people is fundamental for building a shared strategy through the grounding process that exploits different communication channels like vision, haptic, or voice. Indeed, human perception is typically multi-modal. This work proposes a two-fold study investigating the cognitive collaboration process both among humans and virtual agents of a multi-agent reinforcement learning (MARL) system. The experiment with humans consists of an interactive virtual shared environment that uses multi-modal channels (visual and haptics) as interaction cues. Haptic feedback is fundamental for a good sense of presence and for improving the performance in completing a task. In this manuscript, an experiment, consisting of escaping a virtual maze trying to get the best score possible, is introduced. The experiment is meant to be performed in pairs, and the perceptual information is split among the participants. A custom haptic interface has been used for the interaction with the virtual environment. The machine learning case, instead, proposes two virtual agents implemented using a tabular Q-learning paradigm to control a single avatar in a 2D labyrinth, introducing a new form of MARL setting. As it is known, it is not easy to get familiar with haptics for people that have never used it, and that if not properly transmitted, the cognitive workflow does not produce any improvements. However, the main findings of the proposed work are that haptic-driven multi-modal feedback information is a valuable means of collaboration since it allows to establish a common frame of reference between the two participants. The machine learning experiments show that even independent agents, implemented with properly designed rewards, can learn the intentions of the other participant in the same environment and collaborate to accomplish a common task.";"2022";"D’Avella, Salvatore and Camacho-Gonzalez, Gerardo and Tripicchio, Paolo";"Neurocomputing";"https://doi.org/10.1016/j.neucom.2022.01.025"
"A framework using cluster-based hybrid network architecture for collaborative virtual surgery";"Research on collaborative virtual environments (CVEs) opens the opportunity for simulating the cooperative work in surgical operations. It is however a challenging task to implement a high performance collaborative surgical simulation system because of the difficulty in maintaining state consistency with minimum network latencies, especially when sophisticated deformable models and haptics are involved. In this paper, an integrated framework using cluster-based hybrid network architecture is proposed to support collaborative virtual surgery. Multicast transmission is employed to transmit updated information among participants in order to reduce network latencies, while system consistency is maintained by an administrative server. Reliable multicast is implemented using distributed message acknowledgment based on cluster cooperation and sliding window technique. The robustness of the framework is guaranteed by the failure detection chain which enables smooth transition when participants join and leave the collaboration, including normal and involuntary leaving. Communication overhead is further reduced by implementing a number of management approaches such as computational policies and collaborative mechanisms. The feasibility of the proposed framework is demonstrated by successfully extending an existing standalone orthopedic surgery trainer into a collaborative simulation system. A series of experiments have been conducted to evaluate the system performance. The results demonstrate that the proposed framework is capable of supporting collaborative surgical simulation.";"2009";"Qin, Jing and Choi, Kup-Sze and Poon, Wai-Sang and Heng, Pheng-Ann";"Computer Methods and Programs in Biomedicine";"https://doi.org/10.1016/j.cmpb.2009.06.008"
"Toward a Frontierless Collaboration in Neurosurgery: A Systematic Review of Remote Augmented and Virtual Reality Technologies";"Objective Augmented reality (AR) and virtual reality (VR) technologies have been introduced to neurosurgery with the goal of improving the experience of human visualization. In recent years, the application of remote AR and VR has opened new horizons for neurosurgical collaboration across diverse domains of education and patient treatment. Herein, we aimed to systematically review the literature about the feasibility of this technology and discuss the technical aspects, current limitations, and future perspectives. Methods Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines, 4 databases (PubMed, Embase, Scopus, and Cochrane Library) were queried for articles discussing the use of remote AR and VR technologies in neurosurgery. Data were collected in various fields, including surgery type, application type, subspecialty, software and hardware descriptions, haptic device utilization, visualization technology, internet connection, remote site descriptions, technical outcomes, and limitations. Data were summarized as counts and proportions and analyzed using IBM SPSS software. Results Our search strategy generated 466 records, out of which 9 studies satisfied the inclusion criteria. The majority of AR and VR applications were used in cranial procedures (77.8%), mainly in education (63.6%), followed by telesurgical assistance (18.2%), patient monitoring (9.1%), and surgical planning (9.1%). Local collaborations were established in 55.6% of the studies, while national and international partnerships were formed in 44.4% of the studies. AR was the main visualization technology, and 3G internet connection was predominantly used (27.5%). All studies subjectively reported the utility of remote AR and VR for real-time interaction. The major technical challenges and limitations included audiovisual latency, the requirement for higher-fidelity and resolution image reconstructions, and the level of proficiency of the patient with the software. Conclusions The results from this systematic review suggest that AR and VR technologies are dynamically advancing to offer remote collaboration in neurosurgery. Although still incipient in development and with an imperative need for technical improvement, remote AR and VR hold a frontierless potential for patient monitoring, neurosurgical education, and long-distance surgical assistance.";"2024";"Bocanegra-Becerra, Jhon E. and Acha Sánchez, José Luis and Castilla-Encinas, Adriam M. and Rios-Garcia, Wagner and Mendieta, Cristian D. and Quiroz-Marcelo, Diego A. and Alhwaishel, Khaled and Aguilar-Zegarra, Luis and Lopez-Gonzalez, Miguel Angel";"World Neurosurgery";"https://doi.org/10.1016/j.wneu.2024.04.048"
"Design and evaluation of UltRASim: An immersive simulator for learning ultrasound-guided regional anesthesia basic skills";"Virtual reality shows great promise as a technology for training healthcare professionals within a secure simulated environment. This work presents the design, development, and assessment of UltRASim: an immersive simulator for ultrasound-guided regional anesthesia. First, task and skills analyses were performed with domain experts to build the task model of the procedure and determine the simulator’s learning objectives and design constraints. Then, a face and content validity study was conducted with eighteen anesthesiologists to assess the simulator’s prototype. The responses to seven of eleven face validity questions were predominantly positive, indicating a favorable reception. The primary concerns pertained to the fidelity of haptic feedback during needle insertion. This suggests incorporating a higher fidelity haptic device in future design iterations. Conversely, responses to all six questions related to the content validity were predominantly positive. Participants found that the simulator held significant potential as a training tool, particularly for developing hand–eye coordination skills. These findings validate several design choices and highlight areas for improvement in subsequent iterations of UltRASim before its formal validation as a training tool.";"2024";"Simon, Cassandre and Herfort, Lucas and Lebrun, Flavien and Brocas, Elsa and Otmane, Samir and Chellali, Amine";"Computers & Graphics";"https://doi.org/10.1016/j.cag.2024.01.005"
"How to Assess the Usability of Virtual Reality (VR) systems for Implementation in Product Development Processes";"In modern product development, software tools have become indispensable. CAD-supported design or calculations using FEM software are commonplace. Since around 2016, HMD based virtual reality (VR), has been pushing its way into development departments. Especially with new software tools like VR, it is important to take a close look at usability. Only with usable software tools is it possible to work efficiently and reduce usage barriers (such as lack of acceptance by employees). VR in particular poses a challenge, as there are no standardized input devices for controlling the software. In addition, VR software dialogs are explicitly excluded in existing usability guidelines. This paper is intended to be the starting point for the development of a framework for the usability design of VR software systems. First, the existing literature is systematically classified using keywords. The most significant publications are thoroughly analyzed to clearly identify gaps in the research landscape. Second, existing guidelines such as ISO 9142 are examined and analyzed. Gaps and problems in the usage of these guidelines in the field of VR are identified. Subsequently, possible solutions and recommendations for the development of a VR-specific guideline are presented.";"2024";"Balzerkiewitz, Hans-Patrick and Stechert, Carsten";"34th CIRP Design Conference";"https://doi.org/10.1016/j.procir.2024.03.027"
"Characterizing the untapped potential of virtual reality in plastic and reconstructive surgical training: A systematic review on skill transferability";"Virtual reality (VR) integration into surgical education has gained immense traction by invigorating skill-building in ways that are unlike the traditional modes of training. This systematic review unites current literature relevant to VR in surgical education to showcase tool transferability, and subsequent impact on knowledge acquisition, skill development, and technological innovation. This review followed the PRISMA guidelines and included three databases. Among the 1926 studies that were screened, 31 studies met the inclusion criteria. ChatGPT assisted in generating variables for data extraction, and the authors reached unanimous consensus on 13 variables that provided a framework for assessing VR attributes. Surgical simulation was examined in 26 studies (83.9%). VR applications incorporated anatomy visualization (83.9%), procedure planning (67.7%), skills assessment (64.5%), continuous learning (41.9%), haptic feedback (41.9%), research and innovation (41.9%), case-based learning (22.6%), improved skill retention (19.4%), reduction of stress and anxiety (16.1%), and remote learning (12.9%). No instances of VR integration addressed patient communication or team-based training. Novice surgeons benefited the most from VR simulator experience, improving their confidence and accuracy in tackling complex procedural tasks, as well as decision-making efficiency. Enhanced dexterity compared to traditional modes of surgical training was also notable. VR confers significant potential as an adjunctive teaching method in plastic and reconstructive surgery (PRS). Studies demonstrate the utility of virtual simulation in knowledge acquisition and skill development, though they lack targeted approaches for augmenting training related to collaboration and patient communication. Given the underrepresentation of PRS among surgical disciplines regarding VR implementation in surgical education, longitudinal curriculum integration and PRS-specific technologies should be further investigated.";"2024";"Landau, Madeleine and Comeaux, Marie and Mortell, Tatjana and Boyle, Rebecca and Imbrescia, Kory and Chaffin, Abigail E.";"JPRAS Open";"https://doi.org/10.1016/j.jpra.2024.06.015"
"Robot-enabled tangible virtual assembly with coordinated midair object placement";"The assembly in Virtual Reality (VR) enables users to fit virtual parts into existing 3D models immersively. However, users cannot physically feel the haptic feedback when connecting the parts with the virtual model. This work presents a robot-enabled tangible interface that dynamically moves a physical structure with a robotic arm to provide physical feedback for holding a handheld proxy in VR. This enables the system to provide force feedback during virtual assembly. The cooperation between the physical support and the handheld proxy produces realistic physical force feedback, providing a tangible experience for various virtual parts in virtual assembly scenarios. We developed a prototype system that allowed the operator to place a virtual part onto other models in VR by placing the proxy onto the matched structure attached to a robotic arm. We conducted a user evaluation to explore user performance and system usability in a virtual assembly task. The results indicated that the robot-enabled tangible support increased the task completion time but significantly improved the system usability and sense of presence with a more realistic haptic experience.";"2023";"Zhang, Li and Liu, Yizhe and Bai, Huidong and Zou, Qianyuan and Chang, Zhuang and He, Weiping and Wang, Shuxia and Billinghurst, Mark";"Robotics and Computer-Integrated Manufacturing";"https://doi.org/10.1016/j.rcim.2022.102434"
"An IoMT based cyber training framework for orthopedic surgery using Next Generation Internet technologies";"Internet of Things based approaches and frameworks hold significant potential in changing the way in which engineering activities are accomplished. The information centric revolution underway has served as a catalyst in the design of innovative methods and practices in several engineering and other domains. In this paper, an Internet of Medical Things based framework for surgical training is discussed in the broader context of Next Generation frameworks. The design and development of this Internet of Medical Things based framework involving adoption of Global Environment for Network Innovations based networking principles is elaborated. The Virtual Reality based simulation environments incorporate haptic based interfaces which support collaborative training and interactions among expert surgeons and residents in orthopedic surgery from distributed locations. The impact of using this Internet of Medical Things based framework for medical education has also been studied; the outcomes underscore the potential of adopting such Internet of Medical Things based approaches for medical education.";"2018";"Cecil, J. and Gupta, Avinash and Pirela-Cruz, Miguel and Ramanathan, Parmesh";"Informatics in Medicine Unlocked";"https://doi.org/10.1016/j.imu.2018.05.002"
"Collaborative software design and modeling in virtual reality";"Context: Software engineering is becoming more and more distributed. Developers and other stakeholders are often located in different locations, departments, and countries and operating within different time zones. Most online software design and modeling tools are not adequate for distributed collaboration since they do not support awareness and lack features for effective communication. Objective: The aim of our research is to support distributed software design activities in Virtual Reality (VR). Method: Using design science research methodology, we design and evaluate a tool for collaborative design in VR. We evaluate the collaboration efficiency and recall of design information when using the VR software design environment compared to a non-VR software design environment. Moreover, we collect the perceptions and preferences of users to explore the opportunities and challenges that were incurred by using the VR software design environment. Results: We find that there is no significant difference in the efficiency and recall of design information when using the VR compared to the non-VR environment. Furthermore, we find that developers are more satisfied with collaboration in VR. Conclusion: The results of our research and similar studies show that working in VR is not yet faster or more efficient than working on standard desktops. It is very important to improve the interface in VR (gestures with haptics, keyboard and voice input), as confirmed by the difference in results between the first and second evaluation.";"2024";"Stancek, Martin and Polasek, Ivan and Zalabai, Tibor and Vincur, Juraj and Jolak, Rodi and Chaudron, Michel";"Information and Software Technology";"https://doi.org/10.1016/j.infsof.2023.107369"
"Neurobehavioral assessment of force feedback simulation in industrial robotic teleoperation";"Telerobotic operation, i.e., a human operator to manipulate remote robotic systems at a distance, has started to gain its popularity in the construction industry. It is expected to help tackle operational challenges in dynamic construction workplaces. The success of telerobotic operation builds on the effective design of the human-robot interface to provide human operators with necessary senses about the remote workplaces, involving multimodal sensory cues, such as visual, audio and haptic feedback. Especially the force feedback design in telerobotic control interface is of central interest and is becoming the main feature of the bilateral control system for teleoperation, as it helps provide feedback about heavy physical interactions and processes in typical construction operations. Nonetheless, how force feedback simulation solutions affect the human operator's perceptional and behavioral reactions is less understood. This paper investigates the neurobehavioral performance of operators with a bilateral control system in a typical industrial valve operation experiment (n = 21). The experiment tested two force feedback conditions: Realistic (the system replicates the exact same feeling of the torque in valve manipulation operations) and Mediated (the simulation reduces the force on the human operator end by 50% to enable more flexible controls). The performance of the participants was evaluated via various metrics, including task performance, human performance and operational velocity uniformity. Data was collected with eye-tracking, neuroimaging (functional near-infrared spectroscopy, fNIRS), motion analysis, and NASA TLX surveys. The results indicated that the mediated force feedback in bilateral telerobotic operation helped more accurate operation, increased dual tasking, reduced cognitive load and more efficient neural functions; yet it encouraged participants to engage in more irregular actions, showing as dramatic changes in valve rotating speeds. The findings suggest that the force feedback design of telerobotic systems should be more carefully thought through to balance the advantages and disadvantages.";"2021";"Zhu, Qi and Du, Jing and Shi, Yangming and Wei, Paul";"Automation in Construction";"https://doi.org/10.1016/j.autcon.2021.103674"
"Platform Technology for Extended Reality Biofeedback Training Under Operant Conditioning for Functional Limb Weakness: Protocol for the Coproduction of an at-Home Solution (React2Home)";"Background Functional neurological disorder (FND), including functional movement disorders (FMDs), arises from disruptions in the perception-action cycle, where maladaptive cognitive learning processes reduce the sense of agency and motor control. FND significantly impacts quality of life, with patients often experiencing physical disability and psychological distress. Extended reality (XR) technologies present a novel therapeutic opportunity by leveraging biofeedback training to target sensory attenuation and amplification mechanisms, aiming to restore motor function and the sense of agency. Objective This study aims to coproduce and evaluate the usability of an XR technology platform for FND rehabilitation, focusing on functional limb weakness. The platform integrates biofeedback training with haptic and visual feedback to support motor relearning and control. Methods We propose to use an experience-based co-design framework to engage patients with FND, caregivers, and health care professionals in collaboratively designing the XR platform. Stakeholders can share their experiences through narrative interviews and co-design workshops, which can identify emotional touchpoints and prioritized patient-centered needs. Insights will be synthesized through qualitative analysis and used to guide the development of system requirements via quality function deployment, ensuring that the platform aligns with user needs. XR training tasks—virtual reality relaxation, XR position feedback, and XR force feedback—will be integrated as needed into a unified therapeutic game experience through 4-week Agile sprints. Usability will be assessed using the System Usability Scale and qualitative feedback, with themes analyzed in NVivo to identify key areas for subsequent improvement. Results High usability scores (>85) were recorded for the XR position feedback tasks in the predesign study, reflecting excellent usability and participant satisfaction. However, the virtual reality relaxation and XR force feedback tasks exhibited interindividual variability, underscoring the need for personalization. Key themes included customization, comfort, accessibility, and XR technological quality, ensuring that the XR platform effectively addressed diverse patient needs. The predesign study highlighted the potential of XR technology for FMD rehabilitation by integrating biofeedback training into a patient-centered game design framework. Approaches such as experience-based co-design and quality function deployment can support coproduction by systematically addressing usability and accessibility challenges. Brain-based metrics may further strengthen this evaluation. Accordingly, this study will use portable brain imaging to capture dynamic functional connectivity in key brain regions, enabling personalized interventions. Conclusions Through coproduction and iterative refinement, this study aims to demonstrate the promise of personalized XR gaming technology as a scalable, at-home solution for FMD rehabilitation. In this context, personalization and accessibility are critical for optimizing usability and long-term clinical outcomes, paving the way for at-home implementation within the FND stepped care model. International Registered Report Identifier (IRRID)";"2025";"Dutta, Anirban and Das, Abhijit";"JMIR Research Protocols";"https://doi.org/10.2196/70620"
"Exploring Immersive Multimodal Virtual Reality Training, Affective States, and Ecological Validity in Healthy Firefighters: Quasi-Experimental Study";"Background Firefighters face stressful life-threatening events requiring fast decision-making. To better prepare for those situations, training is paramount, but errors in real-life training can be harmful. Virtual reality (VR) simulations provide the desired realism while enabling practice in a secure and controlled environment. Firefighters’ affective states are also crucial as they are a higher-risk group. Objective To assess the impact on affective states of 2 simulated immersive experiences in a sample of healthy firefighters (before, during, and after the simulation), we pursued a multivariate approach comprising cognitive performance, situational awareness, depression, anxiety, stress, number of previous adverse events experienced, posttraumatic stress disorder (PTSD) severity, and emotions. The efficacy and ecological validity of an innovative VR haptic system were also tested, exploring its impact on performance. Methods In collaboration with the Portuguese National Fire Service School, we exposed 22 healthy firefighters to 2 immersive scenarios using the FLAIM Trainer VR system (neutral and arousing scenarios) while recording physiological data in a quasi-experimental study. Baseline cognitive performance, depression, anxiety, stress, number of adverse events, and severity of PTSD symptoms were evaluated. Positive and negative affective states were measured before, between, and after each scenario. Situational awareness, sense of presence, ecological validity, engagement, and negative effects resulting from VR immersion were tested. Results Baseline positive affect score was high (mean 32.4, SD 7.2) and increased after the VR tasks (partial η2=0.52; Greenhouse-Geisser F1.82,32.78=19.73; P<.001). Contrarily, mean negative affect score remained low (range 11.0-11.9) throughout the study (partial η2=0.02; Greenhouse-Geisser F2.13,38.4=0.39; P=.69). Participants’ feedback on the VR sense of presence was also positive, reporting a high sense of physical space (mean score 3.9, SD 0.8), ecological validity (mean score 3.8, SD 0.6), and engagement (mean score 3.8, SD 0.6). Engagement was related to the number of previously experienced adverse events (r=0.49; P=.02) and positive affect (after the last VR task; r=0.55; P=.02). Conversely, participants reported few negative effects (mean score 1.7, SD 0.6). The negative effects correlated positively with negative affect (after the last VR task; r=0.53; P=.03); and avoidance (r=0.73; P<.001), a PTSD symptom, controlling for relevant baseline variables. Performance related to situational awareness was positive (mean 46.4, SD 34.5), although no relation was found to metacognitively perceived situational awareness (r=–0.12; P=.59). Conclusions We show that VR is an effective alternative to in-person training as it was considered ecologically valid and engaging while promoting positive emotions, with few negative repercussions. This corroborates the use of VR to test firefighters’ performance and situational awareness. Further research is needed to ascertain that firefighters with PTSD symptomatology are not negatively affected by VR. This study favors the use of VR training and provides new insights on its emotional and cognitive impact on the trainee.";"2024";"Oliveira, Joana and Aires Dias, Joana and Correia, Rita and Pinheiro, Raquel and Reis, Vítor and Sousa, Daniela and Agostinho, Daniel and Simões, Marco and Castelo-Branco, Miguel";"JMIR Serious Games";"https://doi.org/10.2196/53683"
"Painting++: Human–computer collaborative painting in VR with multisensory interaction";"Extensive human–computer collaborative painting systems have been explored to assist people in ideating and creating the content of paintings. Recently, the popularity of virtual reality (VR) has opened up the novel possibility of facilitating painting by providing an immersive virtual environment. To create immersion, previous VR painting systems mainly focused on simulating real painting environments. However, our preliminary study revealed that the lack of multisensory interaction in existing VR painting applications detracted from the fully immersive experience. Grounded in the findings of the preliminary study, we developed Painting++, a human–computer collaborative painting system that synthetically integrates visual, audio, haptic, and smell feedback to enhance the sense of immersion. Particularly, the content generation ability of artificial intelligence (AI) is also adopted to assist users in obtaining completed stereo paintings from rough sketches. Painting++ has been evaluated in a comparative study with two mainstream VR painting applications (N=18). The results illustrate that multisensory interaction and AI assistance make Painting++ succeed in creating a highly immersive painting experience. Our work further reveals the distinct impact of VR painting systems on painting behavior and demonstrates the multiple roles that Painting++ plays in supporting human–computer collaborative painting.";"2025";"Li, Zhuoshu and Chen, Pei and Zhang, Hongbo and Wu, Yexinrui and Liu, Xuanhui";"Design and Artificial Intelligence";"https://doi.org/10.1016/j.daai.2025.100019"
"Exploring the role of artificial intelligence in orthopedic medical education: A narrative review";"Artificial intelligence (AI) is transforming orthopedic medical education by enhancing diagnostic accuracy, surgical training, and personalized learning. This narrative review explores AI's applications, including machine learning (ML) and computer vision for interpreting imaging studies, virtual reality (VR) and augmented reality (AR) for immersive surgical simulations, and natural language processing (NLP) for streamlining clinical workflows. AI-powered tools offer objective feedback, adaptive learning modules, and risk-free environments for skill acquisition, bridging gaps in traditional training methods. However, challenges such as data privacy, algorithmic bias, and the need for robust validation remain. Ethical considerations, including patient trust and trainee over-reliance on AI, must also be addressed. Despite these barriers, AI democratizes access to high-quality education, particularly in resource-limited settings, through cloud-based platforms and mobile applications. The future of AI in orthopedics is promising, with advancements in predictive analytics, robotic-assisted surgery, and haptic feedback technologies poised to further revolutionize training. Collaborative efforts among educators, clinicians, and developers are essential to ensure responsible integration. This review highlights AI's potential to reshape orthopedic education while emphasizing the importance of preserving the mentor-trainee relationship and fostering evidence-based adoption.";"2025";"Das, Lakshmana S. and Das, Deepanjan and Chandrakar, Denish and Bhavani, Prashant and Dubepuria, Amol and Barik, Sitanshu";"Journal of Clinical Orthopaedics and Trauma";"https://doi.org/10.1016/j.jcot.2025.103100"
"An efficient and scalable deformable model for virtual reality-based medical applications";"Modeling of tissue deformation is of great importance to virtual reality (VR)-based medical simulations. Considerable effort has been dedicated to the development of interactively deformable virtual tissues. In this paper, an efficient and scalable deformable model is presented for virtual-reality-based medical applications. It considers deformation as a localized force transmittal process which is governed by algorithms based on breadth-first search (BFS). The computational speed is scalable to facilitate real-time interaction by adjusting the penetration depth. Simulated annealing (SA) algorithms are developed to optimize the model parameters by using the reference data generated with the linear static finite element method (FEM). The mechanical behavior and timing performance of the model have been evaluated. The model has been applied to simulate the typical behavior of living tissues and anisotropic materials. Integration with a haptic device has also been achieved on a generic personal computer (PC) platform. The proposed technique provides a feasible solution for VR-based medical simulations and has the potential for multi-user collaborative work in virtual environment.";"2004";"Choi, Kup-Sze and Sun, Hanqiu and Heng, Pheng-Ann";"Atificial Intelligence in Medicine in China";"https://doi.org/10.1016/j.artmed.2004.01.013"
"Smart Manufacturing and Tactile Internet Powered by 5G: Investigation of Current Developments, Challenges, and Future Trends";"Communication latency has been a significant barrier for many applications deployed in manufacturing networks. Despite the constant development of improved communication protocols and standards during Industry 4.0, the latency problem still exists, decreasing the Quality of Services (QoS) and Quality of experience (QoE). Therefore, high availability, security and ultra-low latency offered by Tactile Internet (TI), will create a new dimension to human-to-machine interaction (HMI) by enabling haptic and tactile sensations. The 5G mobile communication systems will support this emerging Internet at the wireless edge. Consequently, TI can be used as backbone for delay mitigation in cooperation with 5G networks, for ultra-reliable low-latency applications such as Smart Manufacturing, Virtual and Augmented Reality. Therefore, the aim of this paper is to present the state-of-the-art of 5G and TI, the challenges, the trends for 5G networks beyond 2020 and to provide a conceptual framework integrating 5G and TI to existing industrial case studies.";"2021";"Mourtzis, Dimitris";"54th CIRP CMS 2021 - Towards Digitalized Manufacturing 4.0";"https://doi.org/10.1016/j.procir.2021.11.331"
